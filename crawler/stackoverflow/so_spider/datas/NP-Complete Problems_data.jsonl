{"Question": "What is an NP-complete in computer science? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is not about programming or software development. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about a specific programming problem, a software algorithm, or software tools primarily used by programmers. If you believe the question would be on-topic on another Stack Exchange site, you can leave a comment to explain where the question may be able to be answered.\r\n                \r\n                    \r\n                        Closed 7 months ago.\r\n                    \r\n                \r\n            The community reviewed whether to reopen this question 2 months ago and left it closed:\r\n            \r\n                    Original close reason(s) were not resolved\r\n            \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nWhat is an NP-complete problem? Why is it such an important topic in computer science?\n    ", "Answer": "\r\nWhat is NP?\nNP is the set of all decision problems (questions with a yes-or-no answer) for which the 'yes'-answers can be verified in polynomial time (O(nk) where n is the problem size, and k is a constant) by a deterministic Turing machine. Polynomial time is sometimes used as the definition of fast or quickly.\nWhat is P?\nP is the set of all decision problems which can be solved in polynomial time by a deterministic Turing machine. Since they can be solved in polynomial time, they can also be verified in polynomial time. Therefore P is a subset of NP.\nWhat is NP-Complete?\nA problem x that is in NP is also in NP-Complete if and only if every other problem in NP can be quickly (ie. in polynomial time) transformed into x.\nIn other words:\n\nx is in NP, and\nEvery problem in NP is reducible to x\n\nSo, what makes NP-Complete so interesting is that if any one of the NP-Complete problems was to be solved quickly, then all NP problems can be solved quickly.\nSee also the post What's \"P=NP?\", and why is it such a famous question?\nWhat is NP-Hard?\nNP-Hard are problems that are at least as hard as the hardest problems in NP. Note that NP-Complete problems are also NP-hard. However not all NP-hard problems are NP (or even a decision problem), despite having ```\nNP```\n as a prefix. That is the NP in NP-hard does not mean non-deterministic polynomial time. Yes, this is confusing, but its usage is entrenched and unlikely to change.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "how were the first NP-complete problems shown to be NP-complete?\r\n                \r\nFrom the wikipedia entry on NP-Complete:\n\n\"The easiest way to prove that some new problem is NP-complete is first to prove that it is in NP, and then to reduce some known NP-complete problem to it\"\n\nI'm pretty sure that I understand this:  If I have a problem, I can show that it is NP-Complete if I: \n\n\nshow that it is in NP (a solution to\nthe problem can be verified in\npolynomial time on a\nnon-deterministic Turing machine)\nShow that a problem already known to be NP-Complete can be\n'reduced' to the new problem\n\n\nSo, my question is, how were the first NP-complete problems 'proven' to be NP-complete?  At one time, the set of known NP-complete problems must have been zero, and this would have made it impossible to resort to step 2 in the above process.  \n\nThis makes me think that there is a different method for proof which I'm not aware of.  Either that, or maybe the whole NP-complete property is 'assumed' for certain problems due to lack of a known polynomial time solution. (actually, having written this, I wouldn't be surprised if this is the case, but I'd like some guru-feedback either way). \n    ", "Answer": "\r\nCook's Theorem\n\nThe class NP can be defined as the class of problems decidable by a nondeterministic Turing machine in polynomial time. This theorem shows that SAT is NP-complete by encoding the operation of any nondeterministic Turing machine by a boolean formula, in such a way that the machine accepts if and only if that formula is SATisfiable.\n\nHistorically speaking, the notion of NP-completeness was introduced in Richard Karp's seminal paper (Reducibility Among Combinatorial Problems), where he defined NP-completeness, used Cook's theorem, and in one big shot, proved 21 problems NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to prove that a problem is NP complete?\r\n                \r\nI have problem with scheduling. I need to prove that the problem is NP complete. What can be the methods to prove it NP complete?\n    ", "Answer": "\r\nTo show a problem is NP complete, you need to:\nShow it is in NP\nIn other words, given some information ```\nC```\n, you can create a polynomial time algorithm ```\nV```\n that will verify for every possible input ```\nX```\n whether ```\nX```\n is in your domain or not.\nExample\nProve that the problem of vertex covers (that is, for some graph ```\nG```\n, does it have a vertex cover set of size ```\nk```\n such that every edge in ```\nG```\n has at least one vertex in the cover set?) is in NP:\n\nour input ```\nX```\n is some graph ```\nG```\n and some number ```\nk```\n (this is from the problem definition)\n\nTake our information ```\nC```\n to be \"any possible subset of vertices in graph ```\nG```\n of size ```\nk```\n\"\n\nThen we can write an algorithm ```\nV```\n that, given ```\nG```\n, ```\nk```\n and ```\nC```\n, will return whether that set of vertices is a vertex cover for ```\nG```\n or not, in polynomial time.\n\n\nThen for every graph ```\nG```\n, if there exists some \"possible subset of vertices in ```\nG```\n of size ```\nk```\n\" which is a vertex cover, then ```\nG```\n is in ```\nNP```\n.\nNote that we do not need to find ```\nC```\n in polynomial time. If we could, the problem would be in `P.\nNote that algorithm ```\nV```\n should work for every ```\nG```\n, for some ```\nC```\n. For every input there should exist information that could help us verify whether the input is in the problem domain or not. That is, there should not be an input where the information doesn't exist.\nProve it is NP Hard\nThis involves getting a known NP-complete problem like SAT, the set of boolean expressions in the form:\n\n(A or B or C) and (D or E or F) and ...\n\nwhere the expression is satisfiable, that is there exists some setting for these booleans, which makes the expression true.\nThen reduce the NP-complete problem to your problem in polynomial time.\nThat is, given some input ```\nX```\n for ```\nSAT```\n (or whatever NP-complete problem you are using), create some input ```\nY```\n for your problem, such that ```\nX```\n is in SAT if and only if ```\nY```\n is in your problem. The function ```\nf : X -> Y```\n must run in polynomial time.\nIn the example above, the input ```\nY```\n would be the graph ```\nG```\n and the size of the vertex cover ```\nk```\n.\nFor a full proof, you'd have to prove both:\n\nthat ```\nX```\n is in ```\nSAT```\n => ```\nY```\n in your problem\n\nand ```\nY```\n in your problem => ```\nX```\n in ```\nSAT```\n.\n\n\nmarcog's answer has a link with several other NP-complete problems you could reduce to your problem.\nFootnote: In step 2 (Prove it is NP-hard), reducing another NP-hard (not necessarily NP-complete) problem to the current problem will do, since NP-complete problems are a subset of NP-hard problems (that are also in NP).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-hard problems that are not NP-complete are harder?\r\n                \r\nFrom my understanding, all NP-complete problems are NP-hard but some NP-hard problems are known not to be NP-complete, and NP-hard problems are at least as hard as NP-complete problems.\n\nIs that mean NP-hard problems that are not NP-complete are harder? And how it is harder?\n    ", "Answer": "\r\nTo answer this question, you first need to understand which NP-hard problems are also NP-complete. If an NP-hard problem belongs to set NP, then it is NP-complete. To belong to set NP, a problem needs to be\n\n(i) a decision problem, \n(ii) the number of solutions to the problem should be finite and each solution should be of polynomial length, and \n(iii) given a polynomial length solution, we should be able to say whether the answer to the problem is yes/no\n\nNow, it is easy to see that there could be many NP-hard problems that do not belong to set NP and are harder to solve. As an intuitive example, the optimization-version of traveling salesman where we need to find an actual schedule is harder than the decision-version of traveling salesman where we just need to determine whether a schedule with length <= k exists or not.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If np-complete problems are the hardest problems in np, why are there multiple np-complete problems?\r\n                \r\nIf np-complete problems are the hardest problems in np, why are there multiple np-complete problems?\nHow can there be multiple hardest problems?\nIs it like the top 10 hardest problems hard np-complete?\nAre np-complete problems the hardest types of problems?\n    ", "Answer": "\r\n\nIf np-complete problems are the hardest problems in np.\n\nThe definition of an np-complete problem is: If a problem is NP and all other NP problems are polynomial-time reducible to it, the problem is NP-complete.\n\nWhy are there multiple np-complete problems?\n\nThere are multiple np-complete problems because people have found multiple problems comply with the definition of NP-complete problems.\n\nHow can there be multiple hardest problems?\n\nThere are more problems that are polynomial-time reducible to each other and are NP.\n\nIs it like the top 10 hardest problems hard np-complete?\n\nThe criterium isn't the top 10 hardest, but they should be NP, and all other NP problems have to be polynomial-time reducible to them.\n\nAre np-complete problems the hardest types of problems?\n\nI think that minimally unsolvable problems are harder.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-complete problems\r\n                \r\nI have come into NP-complete problems and I can't tell when the problem is NP-complete.\nIs there a shortcut to know whether a given problem is NP-complete or not so that I don't waste time thinking about a fast algorithm?\n    ", "Answer": "\r\nThe only easy way to show that a problem is NP-Hard is to convert an already known NP-complete problem into this problem in polynomial time. Meaning the conversion should be calculated in polynomial time with respect to the size of the input. In this case, you know that the problem you have is NP-Hard, which means it is at least as hard as NP-Complete but may be more difficult.\nAt this point, you could stop trying to find a solution for it.\nBut if you also need to show that it is NP-complete, then you need to show that a solution could be check in polynomial time.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What are NP and NP-complete problems? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and  cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened,  visit the help center.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 11 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI am struggling to understand what are nondeterministic polynomial-time problems and NP-complete problems. I understand what polynomial-time solvable problems are, and saw in Wikipedia about NP problems.  After reading about this I tried to think about some example problems.  As I understand it, depth-first search in an undirected is NP-complete, since each decisions can be made nondeterministically (i.e if I made the wrong decision, I could instead try some other choice) if the graph is large (cit an be polynomial if graph size is small.)\n\nCan anyone briefly explain all these NP terms with simple examples without using much maths?\n    ", "Answer": "\r\nThere are many ways of thinking about NP and NP-completeness.  I'll start with a definition of NP, then will talk about NP-hardness, and finally NP-completeness.\n\nAt a high level, P and NP are classes of problems. A problem is in P if is a yes-or-no question (a decision problem) and there is some algorithm that solves the problem in polynomial time. For example, the question of \"can you get from node u to node v in this graph?\" belongs to P because you can solve it with depth-first search. (Note that DFS itself is not in P, since DFS is an algorithm rather than a problem). Another example of a problem in P would be checking whether a sequence is in sorted order.\n\nA problem is in NP if it is a yes-or-no question (a decision problem) where a correct answer can be verified in polynomial time.  For example, a classic NP problem is seeing whether, given a set of weights of known weight, you can pick a set of weights that weighs exactly some amount k (this is called the subset sum problem).  It might be tricky to figure out whether a set of weights with that property exists, but if I were to give you a set of weights that I said I knew was correct, you could very easily check whether or not I had given you the correct set of weights by just adding them up and seeing if they totaled k.\n\nThe reason that NP is called \"nondeterministic polynomial\" is that a different way of thinking about NP is to think about a magic algorithm that can somehow guess the correct answer to a problem in polynomial time.  That is, if you can write an algorithm that is allowed to make guesses about the answer to a problem and runs in polynomial time, then the problem you are solving is in NP.  To go back to our weights example, we could write such a guessing algorithm for the problem as follows.  Start off by, in linear time, guessing which set of weights is the correct set of weights, then add them all up and see if they total k.  If so, report that the answer is \"yes.\" Otherwise, say \"no.\" If this program is always guaranteed to make correct guesses, then given any input to the problem that has a solution it will always find one and report \"yes,\" and if there is no solution it will always guess wrong and report \"no.\"\n\nOne of the most fundamental and important questions in computer science right now is whether any problem that is known to be in NP is also in P.  That is, if we can easily verify the answer to a problem efficiently (in polynomial time), can we always solve that problem efficiently (in polynomial time)?  It is known that any problem in P is also a problem in NP, since you can use the polynomial time algorithm to produce an answer and then check whether it's correct, but no one has ever found a way to solve arbitrary problems in NP in polynomial time.\n\nThe reason for this is that some problems in NP are known as NP-complete, meaning that (informally) they are at least as hard as every other problem in NP.  If we could solve these problems efficiently (polynomial time), then we could solve every problem in NP in polynomial time.  This would be a huge deal, since there are a lot of problems in NP that are extremely important that we currently have no good, fast algorithms for.  This is also the allure of the P = NP question, since all it would take would be one algorithm to show that an enormous class of problems presumed to be impractically hard to solve would actually be solvable efficiently.\n\nMore formally, a problem in NP is called NP-complete if, in polynomial time, you can transform any instance of any other NP problem into an instance of that problem.  The above problem with weights is such a problem, as is the problem of determining whether a boolean formula has a satisfying assignment, solving certain optimization problems over the integers (integer programming), determining the fastest route to visit a set of locations (traveling salesman), or determining how to assign cell towers in a city using the smallest number of frequencies (graph coloring).  Even determining whether it's possible to solve a game like Sudoku and minesweeper are known to be NP-complete for arbitrary board sizes.\n\n(Some problems have this latter property - that any problem in NP can be converted efficiently into that problem - but aren't themselves in NP. Those problems are called NP-hard.)\n\nFrom a practical perspective, if you are ever asked to solve a problem that is known to be NP-complete or NP-hard, don't expect to find an exact solution in any reasonable time.  In some cases, it's not even possible to approximate solutions to within any precision efficiently.  You are best off looking for an alternative problem to try to solve or to resign yourself to a heuristic solution that does well in most but not all cases.\n\nAs to your original thoughts about DFS being NP-complete, only problems can be in NP or be NP-complete; algorithms cannot. DFS is an algorithm for solving the graph reachability problem - given two nodes in a graph, is there a path from the first to the second? That problem is in NP because if there is a path it's easy to check, but it's (probably) not NP-complete because we know we can solve it in polynomial time using DFS.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are all NP problems also NP-complete?\r\n                \r\nThe definition of NP-complete is\n\nA problem is NP-complete if\n\n\nit belongs to class NP  \nall the other problems in NP polynomially transform to it\n\n\nSo, if all other problems in NP transform to an NP-complete problem, then does that not also mean that all NP problems are also NP-complete?  What is the point of classifying the two if they are the same?\n\nIn other words, if we have an NP problem then through (2) this problem can transform into an NP-complete problem. Therefore, the NP problem is now NP-complete, and NP = NP-complete. Both classes are equivalent.\n\nJust trying to clarify this up for myself.\n    ", "Answer": "\r\n\n  Are all NP problems also NP-complete?\n\n\nOnly if P = NP.\n\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What's \"P=NP?\", and why is it such a famous question? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is off-topic. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.\r\n                \r\n                    \r\n                        Closed 10 years ago.\r\n                    \r\n                \r\n            The community reviewed whether to reopen this question last year and left it closed:\r\n            \r\n                    Original close reason(s) were not resolved\r\n            \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nThe question of whether P=NP is perhaps the most famous in all of Computer Science. What does it mean? And why is it so interesting?\n\nOh, and for extra credit, please post a proof of the statement's truth or falsehood. :)\n    ", "Answer": "\r\nP stands for polynomial time.  NP stands for non-deterministic polynomial time.  \n\nDefinitions:\n\n\nPolynomial time means that the complexity of the algorithm is O(n^k), where n is the size of your data (e. g. number of elements in a list to be sorted), and k is a constant.\nComplexity is time measured in the number of operations it would take, as a function of the number of data items.\nOperation is whatever makes sense as a basic operation for a particular task.  For sorting, the basic operation is a comparison.  For matrix multiplication, the basic operation is multiplication of two numbers.\n\n\nNow the question is, what does deterministic vs. non-deterministic mean?  There is an abstract computational model, an imaginary computer called a Turing machine (TM).  This machine has a finite number of states, and an infinite tape, which has discrete cells into which a finite set of symbols can be written and read.  At any given time, the TM is in one of its states, and it is looking at a particular cell on the tape.  Depending on what it reads from that cell, it can write a new symbol into that cell, move the tape one cell forward or backward, and go into a different state.  This is called a state transition.  Amazingly enough, by carefully constructing states and transitions, you can design a TM, which is equivalent to any computer program that can be written.  This is why it is used as a theoretical model for proving things about what computers can and cannot do.\n\nThere are two kinds of TM's that concern us here: deterministic and non-deterministic.  A deterministic TM only has one transition from each state for each symbol that it is reading off the tape.  A non-deterministic TM may have several such transition, i. e. it is able to check several possibilities simultaneously.  This is sort of like spawning multiple threads.  The difference is that a non-deterministic TM can spawn as many such \"threads\" as it wants, while on a real computer only a specific number of threads can be executed at a time (equal to the number of CPUs).  In reality, computers are basically deterministic TMs with finite tapes.  On the other hand, a non-deterministic TM cannot be physically realized, except maybe with a quantum computer.  \n\nIt has been proven that any problem that can be solved by a non-deterministic TM can be solved by a deterministic TM.  However, it is not clear how much time it will take. The statement P=NP means that if a problem takes polynomial time on a non-deterministic TM, then one can build a deterministic TM which would solve the same problem also in polynomial time.  So far nobody has been able to show that it can be done, but nobody has been able to prove that it cannot be done, either.\n\nNP-complete problem means an NP problem X, such that any NP problem Y can be reduced to X by a polynomial reduction.  That implies that if anyone ever comes up with a polynomial-time solution to an NP-complete problem, that will also give a polynomial-time solution to any NP problem. Thus that would prove that P=NP. Conversely, if anyone were to prove that P!=NP, then we would be certain that there is no way to solve an NP problem in polynomial time on a conventional computer. \n\nAn example of an NP-complete problem is the problem of finding a truth assignment that would make a boolean expression containing n variables true.\nFor the moment in practice any problem that takes polynomial time on the non-deterministic TM can only be done in exponential time on a deterministic TM or on a conventional computer.\nFor example, the only way to solve the truth assignment problem is to try 2^n possibilities.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why do we say that NP complete problems are NP?\r\n                \r\nI have gone through all the links regarding this topic but still confused that why do we consider NP Complete to be NP. Is it only that we can verify it in polynomial time that we say that NP complete problems are NP, but we have some NP problems which can be solved in polynomial time as well but NP complete problems can't be solved in polynomial time so then doesn't this contradict the property of calling NP complete problems to be NP?\n    ", "Answer": "\r\nThere's the set P of decision problems that can be solved by a deterministic Turing machine in polynomial time.\n\nThen there's the set NP of decision problems that can be solved by a non-deterministic Turing machine in polynomial time, i.e. those whose solution can be verified in polynomial time given some witness string.\n\nA deterministic Turing machine can simulate a non-deterministic one, so we know that there is an exponential-time algorithm to solve NP problems. We don't know however whether we don't in fact have P = NP.\n\nAn NP-complete problem is an NP problem that is at least as hard as any other NP problem. For example, SAT is NP-complete because it can effectively encode a non-deterministic Turing machine and solving SAT means simulating that machine. You can show NP-completeness of a problem decision problem A by demonstrating that a previously known to be NP-complete problem B can be reduced to A in polynomial time. This means that if A can be solved in polynomial time, B can be solved in polynomial time too, thus in a sense A is at least as hard as B.\n\n\n  but we have some NP problems which can be solved in polynomial time as well\n\n\nExactly, because P is a subset of NP.\n\n\n  NP complete problems can't be solved in polynomial time\n\n\nWe don't know that for sure.\n\n\n  doesn't this contradict the property of calling NP complete problems to be NP\n\n\nNot at all. Yes there are problems in NP that we know to be also in P. That doesn't mean that there are no problems in NP that are not in P. But of course we don't know the latter. It could even be the case that every NP-complete problem is in P, in the case P = NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Relating NP-Complete problems to real world problems\r\n                \r\nI have a decent grasp of NP Complete problems; that's not the issue.  What I don't have is a good sense of where they turn up in \"real\" programming.  Some (like knapsack and traveling salesman) are obvious, but others don't seem obviously connected to \"real\" problems.\n\nI've had the experience several times of struggling with a difficult problem only to realize it is a well known NP Complete problem that has been researched extensively.  If I had recognized the connection more quickly I could have saved quite a bit of time researching existing solutions to my specific problem.\n\nAre there any resources (online or print) that specifically connect NP Complete to real world instances?\n\nEdit:\nFor example, I was working on a program that tried to divide students into groups based on age, grade, and school of origin, which is essentially a graph partitioning problem. It took me a while to realize the connection.\n    ", "Answer": "\r\nI have found that Computers and Intractability is the definitive reference on this topic.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What makes an NP-hard problem not to be an NP-complete problem?\r\n                \r\nI am having confusion about NP-hard problems.\nSome NP-hard problems are in NP which are called NP-Complete and some are not in NP.\nFor ex : Halting problem is only NP-hard, not NP-complete.\nBut why it is not NP-complete ? I mean what property should a problem have to qualify as\n\"NP-hard but not NP-complete problem\" ?\n    ", "Answer": "\r\nI think the shortest answer is: NP-complete = NP-hard AND in NP.\n\nThus, to show that a problem is NP-complete you must show that it is both NP-hard and in NP.  Typically, showing that a problem is in NP is pretty easy (just give a non-deterministic polynomial time algorithm).  Showing that a problem is NP-hard is, well, hard.  Thus, even in a proof of NP-completeness, most of the proof is dedicated to the NP-hardness.\n\nAs for the halting problem, it fails to be in NP, and thus is not NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Example problems not in P nor in NP-complete but in NP\r\n                \r\nI have a course called Algorithm Analysis at college, where we're currently studying the different complexity classes -- P, NP, NP-hard etc.\n\nWe've already discussed NP-complete problems as the intersection between NP and NP-hard, and P problems, contained in NP. We've also talked about some examples, mainly of NP-complete problems (k-coloring, k-clique, SAT).\n\nMost of the time, we prove a problem is NP-complete by:\n\na. Finding a nondeterministic algorithm to solve it (that uses choice, success, fail);\n\nb. Reducing a known NP-complete problem to it.\n\nThe thing is that these problems, when run on a deterministic machine (sequentially, instead of simultaneously branching when encountering a choice) have exponential-time solutions.\n\nMy question is this -- I've never encountered problems that were solvable neither in polynomial time neither in exponential time; polynomial time problems are in P and exponential-time problems are usually in NP-complete.\n\nThere's a helpful Venn diagram here:\nhttp://en.wikipedia.org/wiki/Np_complete\n\n\nI'd like to know an example of a problem that is neither in P, neither in NP-complete, but in NP.\nAlso, are intrinsically exponential problems, like generating the power set of a set NP-complete? Or does that name only apply for problems for which an exponential time algorithm is used only because there's no other obvious method for solving it?\n\n\nOk, so I gave the answer to Rosh Oxymoron because he actually listed some examples of problems suspected to be between P and NPC. Thanks for your help guys, and I actually noticed that I put this question in the wrong place.\nThere's also:\nhttps://cstheory.stackexchange.com/\n\nwhere I found the following very useful answers to my question:\nhttps://cstheory.stackexchange.com/questions/79/problems-between-p-and-npc\nwhich is specifically about what I asked, and:\nhttps://cstheory.stackexchange.com/questions/52/hierarchies-in-np-under-the-assumption-that-p-np\nwhich is generally interesting, if not exactly related to the initial question.\n\nThanks a lot,\n\nDan\n    ", "Answer": "\r\n\nI'd like to know an example of a problem that is neither in P, neither in NP-complete, but in NP.\n\nMe too; if you find one go ahead and visit this web page to claim your $1M prize:  https://www.claymath.org/millennium-problems/p-vs-np-problem\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are all problems in NP which are not P NP-complete?\r\n                \r\n\nAre all problems in NP which are not P NP-complete?\nTo make myself more clear, is NP-P=NPC? If not, can you give an example of an NP problem that is neither P nor NP-complete?\nAre all NP-complete problems NP-hard?\n\n\nThank you very much in advance. \n    ", "Answer": "\r\nFirst, a picture\n\n \n\n\nProblems in NP not known to be in P or NP-complete \n\n\n\n  It was shown by Ladner that if ```\nP ≠ NP```\n then there exist problems in ```\nNP```\n\n  that are neither in ```\nP```\n nor ```\nNP-complete```\n. Such problems are called\n  ```\nNP-intermediate```\n problems. The graph isomorphism problem, the discrete\n  logarithm problem and the integer factorization problem are examples\n  of problems believed to be ```\nNP-intermediate```\n. They are some of the very\n  few ```\nNP```\n problems not known to be in ```\nP```\n or to be ```\nNP-complete```\n.\n\n\n\n```\nNP-hard```\n is a class of problems which are at least as hard as the hardest problems in ```\nNP```\n. Thus, yes, every ```\nNP-complete```\n problem is ```\nNP-hard```\n. \n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How can some NP-Complete problems be also NP-Hard?\r\n                \r\nI'm trying wrap my heard around P, NP, NP-Complete and NP-Hard in an intuitive way so that I don't have to remember their definitions.\n\nIn the following image (the left hand scenario, P != NP), there's an overlapping area between NP-Complete and NP-Hard. Does it mean that some problems are both NP-Complete and NP-Hard? I find that contradictory, according to this particular answer: What are the differences between NP, NP-Complete and NP-Hard?.\n\nThe table in the above link says an NP-Complete problem is verifiable in polynomial time and an NP-Hard problem is not. So how can there be an overlap?\n\n\n    ", "Answer": "\r\nPart of the definition of NP-completeness is being NP hard. Therefore, every NP-complete problem is NP-hard. This is also reflected by both of your graphs.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why all NP-complete problems can be reducible to 3-SAT?\r\n                \r\nWhen I tried to figure out why halting-problem is NP-hard, I found this.\nHowever, there is a statement confuse me\n\n\n  We begin by noting that all NP-complete problems are reducible to 3SAT.\n\n\nWhy all NP-Complete problems can be reducible to 3-SAT?\n\nHope for your answer :-)\n    ", "Answer": "\r\nBy definition, an NP-complete problem X has the property that every problem Y &in; NP reduces to X. (This is what NP-hardness means.) Similarly, by definition every NP-complete problem is in NP. Putting these two together, every NP-complete problem reduces to every other, so all NP-complete problems reduce to 3SAT.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Numberlink/Flow Game: How to spot NP-Complete problems?\r\n                \r\nI was trying to find a way to solve the problem in the famous game Flow. http://moh97.us/flow/\n\nAfter googling I find out that this is a NP-complete problem. A good solution would make use of heuristics and cuts. How can I spot a NP-complete problem easily? Sometimes when I block, I can't see the obvious solution. When this happens with an NP-complete, it's better to recognise it quickly and move on to the next problem.\n    ", "Answer": "\r\nWhen you have an explosion of objects (say objects whose count grows\nexponentially based on some parameter or parameters), this should point \nyou in the direction that it's an NP-complete problem. When you\nhave to inspect, check too many objects (combinatorial or others).\nUsually these objects are subsets or sub-spaces of some initial\nobject space. You should build some intuition for this. But as usual, \nthe intuition lies sometimes (I've been lied like this by my intuition\non 2-3 occasions).\n\nThen once you suspect some problem is NP-complete, just\nGoogle for it and try finding more information about\nthe same or about a similar problem.\n\nThis is what I do at least and I've been\nsolving quite a few algorithmic problems\nsome time ago.\n\nHere is a nice problem which I am pretty sure\nis NP-complete but which can be solved through\na genetic algorithm for example.\n\nhttp://uva.onlinejudge.org/index.php?option=com_onlinejudge&Itemid=8&page=show_problem&problem=973\n\nAnd as Dukeling said, there's no generic way of doing this.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How do we know NP-complete problems are the hardest in NP?\r\n                \r\nI get that if you can do a polynomial time reduction from \"every\" problem then it proves that the problem is at least as hard as every problem in NP. Except, how do we know that we've discovered every problem in NP? Can't there exist problems that we may not have discovered or proven exist in NP but CANNOT be reduced to any np-complete problem? Or is this still an open question?\n    ", "Answer": "\r\nAs others have correctly stated, the existence of the problem that is NP, but is not NP-complete would imply that P != NP, so finding one would bring you a million dollar and eternal glory. One famous problem that is believed to belong in this class is integer factorization. However, your original question was\n\n\n  Can't there exist problems that we may not have discovered or proven\n  exist in NP but CANNOT be reduced to any np-complete problem?\n\n\nThe answer is no. By definition of NP-completeness, one of two \nnecessary conditions for a problem A to be NP-complete is that every NP problem needs to be reducible in polynomial time to A. If you want to find out how to prove that every single NP problem can be reducible in polynomial time to some NP-complete problem, have a look at the proof of Cook-Levin theorem that states that 3-SAT problem is NP-complete. It was the first proven NP-complete problem and many other NP-complete problems are later proven to be NP-complete by finding the appropriate reduction from 3-SAT to these problems.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "The subsets-sum problem and the solvability of NP-complete problems\r\n                \r\nI was reading about the subset-sums problem when I came up with what appears to be a general-purpose algorithm for solving it:\n\n```\n(defun subset-contains-sum (set sum)\n    (let ((subsets) (new-subset) (new-sum))\n        (dolist (element set)\n            (dolist (subset-sum subsets)\n                (setf new-subset (cons element (car subset-sum)))\n                (setf new-sum (+ element (cdr subset-sum)))\n                (if (= new-sum sum)\n                    (return-from subset-contains-sum new-subset))\n                (setf subsets (cons (cons new-subset new-sum) subsets)))\n            (setf subsets (cons (cons element element) subsets)))))\n```\n\n\n\"set\" is a list not containing duplicates and \"sum\" is the sum to search subsets for. \"subsets\" is a list of cons cells where the \"car\" is a subset list and the \"cdr\" is the sum of that subset. New subsets are created from old ones in O(1) time by just cons'ing the element to the front.\n\nI am not sure what the runtime complexity of it is, but appears that with each element \"sum\" grows by, the size of \"subsets\" doubles, plus one, so it appears to me to at least be quadratic.\n\nI am posting this because my impression before was that NP-complete problems tend to be intractable and that the best one can usually hope for is a heuristic, but this appears to be a general-purpose solution that will, assuming you have the CPU cycles, always give you the correct answer. How many other NP-complete problems can be solved like this one?\n    ", "Answer": "\r\nNP-complete problems are solvable, just not in polynomial time (as far as we know). That is, an NP-complete problem may have an ```\nO(n*2^n)```\n algorithm that could solve it, but it won't have, for example, an ```\nO(n^3)```\n algorithm to solve it.\n\nInterestingly, if a quick (polynomial) algorithm was found for any NP-complete problem, then every problem in NP could be solved in polynomial time. This is what P=NP is about.\n\nIf I understand your algorithm correctly (and this is based more on your comments than on the code), then it is equivalent to the ```\nO(n*2^n)```\n algorithm here. There are ```\n2^n```\n subsets, and since you also need to sum each subset, the algorithm is ```\nO(n*2^n)```\n.\n\nOne more thing about complexity - the ```\nO(whatever)```\n only indicates how well a particular algorithm scales. You cannot compare two algorithms and say that one is faster than the other based on this. Big-O notation doesn't care about implementation details and optimisations - it is possible to write two implementations of the same algorithm with one being much faster than the other, even though they might both be ```\nO(n^2)```\n. One woman making babies is an ```\nO(n)```\n operation, but the chances are that this is going to take a lot longer than most ```\nO(n*log(n))```\n sorts you perform. All you can say based on this is that sorting will be slower for very large values on n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Best-case Running-time to solve an NP-Complete problem?\r\n                \r\nWhat is the fastest algorithm that exists up with to solve a particular NP-Complete problem? For example, a naive implementation of travelling salesman is O(n!), but with dynamic programming it can be done in O(n^2 * 2^n). Is there any perhaps \"easier\" NP-Complete problem that has a better running time?\n\nI'm curious about exact solutions, not approximations.\n    ", "Answer": "\r\n\n  [...] with dynamic programming it can be done in O(n^2 * 2^n). Is there any perhaps \"easier\" NP-Complete problem that has a better running time?\n\n\nSort of. You can get rid of any polynomial factor by creating an artificial problem that encodes the same solution in a polynomially larger input. As long as the input is only polynomially larger, the resulting problem is still NP-complete. Since the complexity is by definition the function that maps input size to running time, if the input size grows the function gets into lower O classes.\n\nSo, the same algorithm running on TSP with the input padded with n^2 useless bits, will have complexity O(1 * 2^sqrt(n)).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proving PATH problem is not a NP-complete problem\r\n                \r\nPATH refers to the question of whether a directed path exists from s to t in a graph G. I know that PATH∈P but I find it hard to prove that it's not an \nNP-complete problem. If this was proven somehow, would that mean P≠NP?\n    ", "Answer": "\r\nFor a problem to be NP-complete: \n\n\nit needs to be NP-hard\nit needs to be in NP\n\n\nFor a problem to be NP-hard, it must be at least as hard as the hardest problems in NP.\nThat means it must be possible to use an NP-hard problem to solve any other problem in NP in polynomial time.\n\nWe want to prove that PATH isn't NP-complete, but we already know it's in P, so it is definitely in NP too (trivially, every deterministic Turing Machine can be simulated by a non-deterministic Turing Machine).\n\n\n\nHence, the only way to prove that PATH is not NP-complete is proving that there is at least one NP problem that cannot be reduced to PATH in polynomial time.\nUnfortunately, you will find that this depends on the P vs NP open problem.\n\nProof by contradiction\n\nLet us use the The Traveling salesman problem (TSP), which is an NP-complete problem that seems to be quite relevant to PATH.\nAssume that TSP reduces to PATH, i.e. there exists a polynomial time modification for instances of the TSP problem so that they could then be correctly solved by a PATH Turing Machine.\n\nWe know all P problems are reducible to each other in polynomial time. \nAlso, we know all NP problems are reducible to TSP in polynomial time.\n\nSo by transitivity, all NP problems reduce to TSP, TSP would reduce to PATH, and PATH reduces to all other P problems. \nThis yields P = NP = NP-complete.\n\nPATH is an NP-complete problem if and only if P = NP = NP-complete.\n\nSimilarly, proving that PATH isn't an NP-complete problem would be equivalent to proving P ≠ NP ≠ NP-complete. If PATH isn't an NP-complete problem, then no problem in P is, because all P problems are reducible to each other in polynomial time. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is it correct to ask to solve an NP-complete problem on a job interview? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is off-topic. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.\r\n                \r\n                    \r\n                        Closed 11 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nToday there was a question on SO, where the author was given an NP-complete problem during an interview and he obviously hadn't been told that it was one.\n\nWhat is the purpose of asking such questions?  What behavior does the interviewer expect when asking such things?  Proof?  Useful heuristics?  And is it even legitimate to ask one if it's not a well-known NP-complete problem everyone should know about?  (there's a plenty of them)\n    ", "Answer": "\r\nCompletely legitimate to me. If you are Computer Science professional there are good chances that you can either argument informally why the problem seems to be hard, or (even better) provide a sketch of reduction from a known NP-hard problem.\n\nMany real world problems eventually turn out to be NP-hard, and stackoverflow also has now and then questions about the complexity of a problem which turns out to be a difficult one (NP-hard, for instance). It is an important part of a CS professionals toolbox to be able to recognize and to argue for problems which are known to be difficult to solve.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Prove a problem that is NP-hard and not NP-complete in not in P\r\n                \r\nIf A is not NP-hard, but not NP-complete, then prove that A in not in P.  \n\nA is NP-hard if there is an NP-complete problem B such that B is reducible to A in polynomial time.  A is NP-complete if A is in NP and all NP problems are reducible to A in polynomial time. But A is not NP-complete, so one one or both of those conditions must be false.  If A is not in NP, then A is not in P.  The other case is that there exists at least one NP problem that is not reducible to A in polynomial time.  This is where I am stuck. How do I get from knowing that there is an NP-complete problem that is reducible and an NP problem that is not reducible to A is not in P?\n    ", "Answer": "\r\nIf a problem A is NP-hard, then all NP problems are reducible to A in polynomial time.\n\nProof:\nSince the problem A is not NP-Complete, then there exists problem B as defined above.  All problems C in NP can be reduced to B in polynomial time, then B can be reduced to A in polynomial time.  Composition of polynomial time algorithms is polynomial, so C can be reduced to A in polynomial time.\n\n--\n\nSince A is NP-Hard but not NP-Complete, A must not be in NP, therefore A is not in P either.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete VS NP-Hard\r\n                \r\nI am trying to understand the difference between NP-Complete and NP-Hard. \n\nBelow is my understanding \n\n\n  An NP-Hard problem is one that is not solvable in polynomial time but can be verified in polynomial time.\n  An NP-Complete problem is one that is in NP and is also NP-Hard. \n\n\nIs the above definition correct? If so, What about problems not In NP but NP-Hard. Wouldn't they be harder than NP-Complete problem, say they can only be solved and verified in exponential time? \n    ", "Answer": "\r\nA ```\nNP```\n problem (not ```\nNP-Hard```\n problem) is a decision problem which can be verified in polynomial time. Maybe they are solvable in polynomial time, since all problems in ```\nP```\n are also in ```\nNP```\n. \n\nA ```\nNP-complete```\n problem is a decision problem, which all ```\nNP```\n problems can reduced to in polynomial time. They are the hardest problems in the class ```\nNP```\n.\n\nThe ```\nNP-hard```\n class is the class  of the problems which are at least as hard as the ```\nNP-complete```\n problem. They are not necessarily a decision problem. Given that we don't know whether ```\nNP = P```\n or not, it would be hard to say whether we can verify a ```\nNP-hard```\n problem in polynomial time.\n\nFor example, the decision problem of maximum clique (Give a graph ```\nG```\n an integer ```\nK```\n, to tell whether there is a complete graph with at least ```\nK```\n vertices ) is ```\nNP```\n problem. It is also ```\nNP-complete```\n and ```\nNP-hard```\n. However, maximum clique problem (Find the maximum clique in the given Graph) is not ```\nNP```\n or ```\nNP-complete```\n, since it is not decision problem. We can say it is ```\nNP-hard```\n, since it is at least as hard as the decision version of maximum clique problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Every np-complete problem reduces to the Halting problem. Is this true?\r\n                \r\nI guess that every np-complete problem reduces to the np-hard problem, so the given statement is true. But don't know how to prove it.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this problem np-complete?\r\n                \r\nSay there is a line of x bins filled with trinkets (random amount), in plain-sight (you can see how many trinkets there are in each bin). Now there are two players who can when it's their turn pick a bin from either end. They cannot forgo a turn. Come up with a strategy for a player to get the maximum amount of trinkets.\n\nx is even.\n\nIs this a np-complete problem? Is it similar to boolean SAT?\n    ", "Answer": "\r\nIt is very simple problem, and it is not NP complete.\nHere is short description of algorithm, it is based on dynamic programming.\n\nCan[i] - array which stores number of trinkets.\nF[i,j] - array determining what is best move if only cans from i to j are avaible. 0 means take from the left side, 1 means take from the right side.\nG[i,j] - array where 'goodness'  of move is stored.  \n\n```\nfor (i=1 to n) F[i,i] = 0\nfor (i=1 to n) G[i,i] = Can[i]\n\nfor (i=1 to n-1)\n   for (j=1 to n-i)\n       tmp1 = Can[j] - G[j+1,j+i]\n       tmp2 = Can[j+i] - G[j,j+i-1]\n       if (tmp1>tmp2)\n       {\n             F[j,j+i] = 0;\n             G[j,j+i] = tmp1;\n       }\n       else\n       {\n             F[j,j+1] = 1;\n             G[j,j+i] = tmp2;\n       }\n```\n\n\nSorry for lack of comments, but if you read some articles about dynamic programming You will get it without any problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Every np-complete problem reduces to the Halting problem. Is this true?\r\n                \r\nI guess that every np-complete problem reduces to the np-hard problem, so the given statement is true. But don't know how to prove it.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete problems to Partition Problem reductions\r\n                \r\nAccording to Wikipedia, Partition Problem (PP) is NP-Complete (NPC) problem with existing pseudo-polynomial time dynamic programming (DP) solution. If a problem is NPC any NP problem can be reduced to instance of such problem in polynomial-time, i.e. Traveling salesman problem (TSP) instance to PP instance. Now there is no algorithm, DP or otherwise, for TSP to have better bound than ```\nO(2^n)```\n.\nNow, why is that if I can take TSP instance, create PP instance out of it, solve PP instance in pseudo-polynomial time and reduce it back? The reductions only costing me something polynomial.\n    ", "Answer": "\r\nThe question here is “pseudopolynomial in what quantity?” For the knapsack problem, the pseudopolynomial-time algorithm runs in time O(nW), where W is the maximum weight of any of the items. If you actually try running through the details of reducing TSP (or most other NP-complete problems) to knapsack using the “standard” reductions known today, you’ll find that the weights on the items are enormous and typically exponential in the size of the inputs to those problems. For example, the typical reduction from set packing to knapsack works by building items whose weights are on the order of 2n, where n is the number of distinct items across all sets. That makes the runtime of first using this reduction and then applying knapsack O(n · 2n), which isn’t pseudopolynomial time.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Can a problem be in NP but not NP-Complete or P?\r\n                \r\nI am looking at the graphs in:\nhttps://en.wikipedia.org/wiki/P_versus_NP_problem\n\nIt seems like, there is gap between P and NP-complete. So are there a class of problems that are in NP but neither in P or NP-Complete.\n\nIn other words, do the classes P, NP-complete completely cover NP?\n\nAnd if so, an example is appreciated.\n    ", "Answer": "\r\nIf P = NP, the answer to your question is that all problems in NP are both in P and in NP-Complete.\n\nIf P != NP, the answer to your question is that there are problems known to be in NP, which are known not to be NP-complete but for which no polynomial-time algorithm is yet known. I say there is none yet known because if you knew (1) the problem is in NP and (2) the problem is not in P, well then you'd know P != NP, which we don't.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are these two definitions of an NP-Complete problem equivalent?\r\n                \r\nDefinition 1 (usual definition)\nA problem B is NP-Complete if\n\nB is in NP\nFor C in NP, C is polynomal-time reducible to B\n\nDefinition 2 (in a few documents)\nA problem B is NP-Complete if\n\nB is in NP\nif B  admits a polynomial-time algorithm, then all problems in NP  also admit a polynomial-time algorithm\n\n(as in \"On the Inherent Intractability of Certain Coding Problems,..., Berlekamp, McEliece and Tilborg\" and other documents\n    ", "Answer": "\r\nDefinition 1 is the definition of NP-completeness you get if you define reducibility to be polynomial-time mapping reducibility (sometimes called polynomial-time many-one reducibility). That is, you’re allowed to reduce one problem to another by doing polynomial work to transform the input, then make a single call to the target problem. This is the standard definition of NP-completeness.\nDefinition 2 is the (nonstandard) definition of NP-completeness you get if you use polynomial-time Turing reducibility (called Cook reductions), in which you are allowed to spend polynomial time including an arbitrary number of calls to an oracle (solver) for the problem you’re reducing to.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "polynomial time reduction from a problem to a NP-complete problem\r\n                \r\nI have problems to solve the following question:\nIf there are two problems p1 and p2, p2 is NP-complete and there is a polynomial reduction from p1 to p2, then p1 ...\na) is NP-hard but not necessarily NP-complete\nb) could be in P, even if P!=NP\nc) is NP-complete\nd) none of the above\nI think c) is correct, but I am not sure and how can I justify ist?\n    ", "Answer": "\r\nIf there is a polynomial-time reduction from p1 to p2 it means that if you get an instance of problem p1, then you can transform it (in polynomial time) to an instance of problem p2. What does that tell us about problem p1?\nWell, not very much. It means it's decidable, but it doesn't tell us a lot about its time complexity. For all we know, it might be the problem \"What is 1+1?\".\nHad it been the other way around, then it would imply that p1 is NP-hard because otherwise we could solve p2 in polynomial time by reducing it to p1 and solving that in polynomial time.\nSo, since we don't know anything else about p1, the answer should be b).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What are the examples of NP problems that is reducible to a NP-complete but not the other way round?\r\n                \r\nWhat are the examples of NP problems that is reducible to NP-complete problem but not the other way round? When I read about NP and NP-complete, I thought the mapping will be one-one such that it is stupid to categorize them. However, surely there are problems where it can only be reducible in one direction. I am interested to know them.\n    ", "Answer": "\r\nAll NP problems can be reduced to NP-complete problems. NP-complete problems are a special type of NP problems. Therefore, NP-complete problems don't need to be reduced to be considered to be in NP; they're already in NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is there an optimization problem that is NP-Complete?\r\n                \r\nIs there such a thing as an NP-complete optimization (not decision) problem?\nWhat is an example of an NP-complete optimization problem?\nThe decision versions of optimization problems are the ones in NP-complete.\nI can't think of any NP-hard optimizations that can be confirmed in polynomial time. I need verification/correction on this.\nThank you.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is it possible to find the probability to a solution of NP-complete problems?\r\n                \r\nThe title covers the entirety of the question. Is it possible to derive a function to say with certainty that a proposed solution to a NP-complete problem has a m percent chance of being correct?\n    ", "Answer": "\r\nI doubt it. For example a random function's probability to be optimal is ```\nnumberOfOptimalSolutions / searchSpace```\n. So if you know the answer to that, you can deduce the numberOfOptimalSolutions (which is IIRC always harder to know than finding 1 optimal solution to an NP complete problem).\n\nThe book \"In pursuit of the traveling salesman\" lists for each construction heuristic in TSP how close (or far) it is in the worst case scenario from the optimal solution. It also mentions the average percentage of being correct for (some of) those algo's, but IIRC it's probably based on sampling and it gets worse as the problem scales out. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why are NP problems called that way (and NP-hard and NP-complete)?\r\n                \r\nReally.. I'm having the last test for graduation this Tuesday, and that's one of the things I just never could understand.\nI realize that a solution for NP problem can be verfied in polynomial time. But what does determinism has to do with that?\nAnd if you could explain me where NP-complete and NP-hard got their names, that would be great (I'm pretty sure I get the meaning of them, I just don't see what their names have to do with what they are).\nSorry if that's trivial, I just can't seem to get it (-:\nThanks all!\n    ", "Answer": "\r\nP\n\nClass of all problems which can be solved by a deterministic Turing machine in polynomial time.\n\nNP\n\nClass of all problems which can be solved by a non-deterministic Turing machine in polynomial time (they can also be verified by a deterministic Turing machine in polynomial time.)\n\nNP-Hard\n\nA class of problems which are \"at least as hard as the hardest problems in NP\". Formally, a problem is in NP-Hard iff there is an NP-complete problem that is polynomial time Turing-reducible to it; (also: iff it can be solved in polynomial time by an oracle machine with an oracle for the problem). It is pretty obvious where the name comes from.\n\nNPC\n\nThe class of problems which are both NP as well as NP-Hard. Regarding the naming, even wikipedia is not sure why it's named as it is.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Solving the NP-complete problem in XKCD\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                Locked. This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n\r\n\r\n    \r\n\r\nThe problem/comic in question: http://xkcd.com/287/\n\n\n\nI'm not sure this is the best way to do it, but here's what I've come up with so far. I'm using CFML, but it should be readable by anyone.\n\n```\n<cffunction name=\"testCombo\" returntype=\"boolean\">\n    <cfargument name=\"currentCombo\" type=\"string\" required=\"true\" />\n    <cfargument name=\"currentTotal\" type=\"numeric\" required=\"true\" />\n    <cfargument name=\"apps\" type=\"array\" required=\"true\" />\n\n    <cfset var a = 0 />\n    <cfset var found = false />\n\n    <cfloop from=\"1\" to=\"#arrayLen(arguments.apps)#\" index=\"a\">\n        <cfset arguments.currentCombo = listAppend(arguments.currentCombo, arguments.apps[a].name) />\n        <cfset arguments.currentTotal = arguments.currentTotal + arguments.apps[a].cost />\n        <cfif arguments.currentTotal eq 15.05>\n            <!--- print current combo --->\n            <cfoutput><strong>#arguments.currentCombo# = 15.05</strong></cfoutput><br />\n            <cfreturn true />\n        <cfelseif arguments.currentTotal gt 15.05>\n            <cfoutput>#arguments.currentCombo# > 15.05 (aborting)</cfoutput><br />\n            <cfreturn false />\n        <cfelse>\n            <!--- less than 15.05 --->\n            <cfoutput>#arguments.currentCombo# < 15.05 (traversing)</cfoutput><br />\n            <cfset found = testCombo(arguments.currentCombo, arguments.currentTotal, arguments.apps) />\n        </cfif>\n    </cfloop>\n</cffunction>\n\n<cfset mf = {name=\"Mixed Fruit\", cost=2.15} />\n<cfset ff = {name=\"French Fries\", cost=2.75} />\n<cfset ss = {name=\"side salad\", cost=3.35} />\n<cfset hw = {name=\"hot wings\", cost=3.55} />\n<cfset ms = {name=\"moz sticks\", cost=4.20} />\n<cfset sp = {name=\"sampler plate\", cost=5.80} />\n<cfset apps = [ mf, ff, ss, hw, ms, sp ] />\n\n<cfloop from=\"1\" to=\"6\" index=\"b\">\n    <cfoutput>#testCombo(apps[b].name, apps[b].cost, apps)#</cfoutput>\n</cfloop>\n```\n\n\nThe above code tells me that the only combination that adds up to $15.05 is 7 orders of Mixed Fruit, and it takes 232 executions of my testCombo function to complete.\n\nIs there a better algorithm to come to the correct solution? Did I come to the correct solution?\n    ", "Answer": "\r\nIt gives all the permutations of the solutions, but I think I'm beating everyone else for code size.\n\n```\nitem(X) :- member(X,[215, 275, 335, 355, 420, 580]).\nsolution([X|Y], Z) :- item(X), plus(S, X, Z), Z >= 0, solution(Y, S).\nsolution([], 0).\n```\n\n\nSolution with swiprolog:\n\n```\n?- solution(X, 1505).\n\nX = [215, 215, 215, 215, 215, 215, 215] ;\n\nX = [215, 355, 355, 580] ;\n\nX = [215, 355, 580, 355] ;\n\nX = [215, 580, 355, 355] ;\n\nX = [355, 215, 355, 580] ;\n\nX = [355, 215, 580, 355] ;\n\nX = [355, 355, 215, 580] ;\n\nX = [355, 355, 580, 215] ;\n\nX = [355, 580, 215, 355] ;\n\nX = [355, 580, 355, 215] ;\n\nX = [580, 215, 355, 355] ;\n\nX = [580, 355, 215, 355] ;\n\nX = [580, 355, 355, 215] ;\n\nNo\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete and some decision problems on graph?\r\n                \r\nWe know about NP-Complete and NP-Hard, and NP Class. I want to conclude some tips on following problem, that take from 2008 Mid exam on MIT. \n\nDecision Version of which of the following problem for a connected undirected weighted graph G is NP-Complete?\n\n\n  a) finding maximal matching.\n  \n  b) finding maximum Hamiltonian cycle\n  \n  c) finding maximum Eulelrian cycle\n  \n  d) finding maximum cut\n\n\nHow can categorized these problem in a simple manner for me? i.e. NP or NP-Complete or NP-Hard. \n    ", "Answer": "\r\nThere are poly-time algorithms for computing maximal matchings (e.g., greedy; Edmonds's Blossom algorithm computes a maximum matching in poly-time) and Eulerian cycles. The decision versions trivially belong to NP (P, in fact).\n\nHamilton cycle and max cut are well-known NP-hard problems. The decision versions are in NP so thus are NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is the integer-factorization problem (used for many cryptographic applications) NP-Complete?\r\n                \r\nAs the question states, does the integer-factorization problem fall into the class of NP-Complete problems?\n    ", "Answer": "\r\nFactoring:\n\n\nIt is not known to be NP-complete. (No reduction from an NP-complete problem has been found.)\nIt is not known not to be NP-complete either (if we knew the latter about some nontrivial problem in NP, it would mean P≠NP, so the latter is not surprising). \nNo polynomial factoring algorithm is known (or believed to exist), so it is believed not to be in P either.\n\n\nThe informal consensus/belief is that this is one of the \"in-between\" problems that are not in P and are not NP-complete. Of course, this belief is less strong and widely held than P≠NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is there an NP problem that is not NP-complete or P?\r\n                \r\nI am trying to understand the relationships between P, NP, NP-Complete and NP-Hard.  \n\nI believe I am starting to understand the general idea but, I am hung up on this question(see title).\n\nWhat is an example of a problem that is not solvable in P time, is verifiable in P time but is not NP-Complete?\n\nIf there is some piece of understanding I am missing please fill me in.\n\nThanks in advance\n    ", "Answer": "\r\nAs noted in the comments, this is the wrong site for this question. However, it can be answered briefly:\n\n\n  What is an example of a problem that is not solvable in P time, is verifiable in P time but is not NP-Complete?\n\n\nIf I understand you, what you want are problems that are (1) not in P, (2) in NP, and (3) not in NPC. Such problems are the NP-intermediate (NPI) problems.\n\nIt is not known if there is any such problem, because it is not known if P=NP.\n\nIf P=NP then clearly there are no such problems; if P=NP then also P=NPC, and therefore every problem which can be verified in P time is in all of P, NP and NPC because they are equal.\n\nIf P!=NP then it is known that there are such problems; at least one exists.  Unfortunately we do not know if any real-world problems we face are in NPI provided that P!=NP. A list of likely candidates can be found here: \n\nhttps://en.wikipedia.org/wiki/NP-intermediate \n\nIn short: knowing whether NPI is empty or not is equivalent to solving proving P!=NP, so get cracking! If you can find a problem that is definitely in NP but definitely not in P or NPC, then there's a big money prize awaiting you.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If a polynomial time algorithm for an NP-Complete problem is found, does this imply that it is the same time complexity for all NP problems?\r\n                \r\nIf a polynomial time algorithm for an NP-Complete problem is found, lets say its O(n^2) hypothetically, does this imply that there is an O(n^2) solution for all NP problem? I know this would imply that there is a polynomial solution for all NP-problems, but would it necessarily be O(n^2)? \n    ", "Answer": "\r\nNot necessarily \n\n\n  A problem x that is in NP is also in NP-Complete if and only if every\n  other problem in NP can be quickly (ie. in polynomial time)\n  transformed into x.\n\n\nTherefore an algorithm that solves one NP-Complete problem means we can solve any other problem in NP by transforming it to an instance of that problem and solving it. But the transformation could be any complexity as long as its polynomial we satisfy the condition. \n\nSo the answer to your question in no, an O(N^2) algorithm to solve an NP-Complete problem does not imply all NP problems can be solved in O(N^2) time, it only guarantees there exists a polynomial time algorithm to solve it. \n\nie O(N^2) + T(N) where T(N) is the complexity to transform the problem instance \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete vs. NP-hard [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is off-topic. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.\r\n                \r\n                    \r\n                        Closed 11 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nIf a problem A known to be NP-Complete can be reduced to another problem B in polynomial time then B is\n(A) NP-Complete\n(B) NP-hard\n\nNothing is given about problem B whether it is in NP or not. I'm confused because in Hopcraft and Ullman book there is theorem given if a NP-complete problem P1 can be reduced to problem P2 in polynomial time then P2 is NP-complete. But it also required for a problem to be NP-Complete that it should belong to NP class. Guys help in understanding this concept.\n    ", "Answer": "\r\nIf A can be reduced to B in polynomial time all you know is that B is harder than A. In your case, if A is NP-complete, B is NP-hard.\nIf B also happens to be in NP then B will be NP-complete (since NP-complete means being both in NP and being NP-hard at the same time).\nHowever, nothing stops you from reducing A to a problem that is not in NP. For example, it is trivial to reduce any problem in NP to the halting problem - a problem that is undecideable in addition to being NP-hard:\n```\nConstruct the following program:\n    Test all possible solutions for A.\n    If one of them is successful halt and otherwise enter an infinite loop.\nA has a solution if-and-only if that program halts\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why is the NP-complete set restricted to only decision problems?\r\n                \r\nAmong P, NP, NP hard and NP-complete, only the NP-complete set is restricted to decision problems (those that have a binary solution). What is the reason for this? Why not define it simply as the intersection of NP and NP-hard? And this leads to another question - there must be problems that are not necessarily decision problems and also have the property that any problem in NP can be reduced to them in polynomial time. Is this then a set encompassing NP-complete? Is there already a name for this set?\n\nEDIT: Per the comment by Matt and also the post: What are the differences between NP, NP-Complete and NP-Hard?, its seems P and NP are defined only for decision problems. That would resolve this question apart from why they would be defined this way. But, this seems to be in contradiction to the book Introduction to Algorithms by Cormen et.al. In chapter 34, the section titled \"NP-completeness and the classes P and NP\", they simply say: \"P consists of those problems that are solvable in polynomial time\". They even say later, \"NP-completeness applies directly not to optimization problems, but to decision problems\" but say no such thing about P and NP.\n    ", "Answer": "\r\nThe classes P and NP are indeed classes of decision problems. I don’t have my copy of CLRS handy, but if they’re claiming that P and NP are all problems solvable in polynomial time or nondeterministic polynomial time, respectively, they are incorrect.\nThere are some good theoretical reasons why it’s helpful to define P and NP as sets of decision problems. Working with decision problems makes reducibility much easier (reducing one problem to another doesn’t require transforming output), simplifies the model by eliminating issues of how big the answer to a question must be, makes it easier to define nondeterministic computation, etc.\nBut none of those are “dealbreakers” in the sense that you can define analogous complexity classes that involve computing functions rather than just coming up with yes or no answers. For example, the classes FP and FNP are the function problem versions of P and NP, and the question of whether FP = FNP is similarly open.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete reduction (in theory)\r\n                \r\nI want to embed 3 NP-Complete problems(2 of them are known to be NP-Complete, 1 of them is my own idea). I saw \"this question\" and got idea about reinterpreting embedding problems in theory:\n\n\nThe Waiter is The Thief.\nTables are store.\nFoods are valued items which has different weight.\nThief know all the items' price and weight before the robbery.\nHis target is most efficient robbery(max capacity of knapsack used, most valued items got) with robbing(getting at least 1 item) all stores(shortest way to completing robbery tour, also visit each store 1 time).\n\n\nThis part is embedding 2 NP-Complete problems.\n\nMy idea is, that more items mean more bag weight. More bag weight slow downs the thief exponentially. So another target of the thief should be finishing the robbery as quickly as he/she can.\n\nAt this time, I'm not sure that my idea is actually NP-Complete. Maybe, \"gravity\" is not a NP-Complete Problem alone. But maybe it is in this context of the travelling salesman and knapsack problem.\n\nSo my questions are:\n\n\nIs the slowing down of the thief NP-complete, too?\nIs it possible to reduce those three embedded problems to a simple NP-complete problem?\n\n    ", "Answer": "\r\nOkay, that was just a bit tough to follow, but I think I'm getting the gist.\n\nThe XKCD cartoon is showing you how easy it is to make a real-life problem NP-complete.  (Of course, since most menus have a small number of items and a uniform set of prices, it's also easy to show that there is a trivial answer.)  \n\nThe idea of \"embedding\" an NP-complete problem I think you're referring to is finding a poly-time reduction; I've written that up pretty completely elsewhere on SO.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is an NP-complete pr0blem also an NP-hard?\r\n                \r\nWe can say that an NP-complete problem is one which is in NP and in NP-hard, but can we argue exclusively that a problem is NP-hard solely due to the fact that it is NP-complete.\n\nExample: I reduce an NP-complete problem ```\na```\n to a problem ```\nb```\n. Therefore, problem ```\nb```\n is now proven to be NP-complete. Can I actually say that it is also NP-hard?\n    ", "Answer": "\r\nThe definition of NP completeness is:\n\n\n  A problem Q is NP-complete if and only if Q is in NP and Q is NP-hard.\n\n\nTherefore, yes, we can most definitely say that any NP-complete problem is NP-hard, by definition.\n\nNote that you have a slight misstatement in your question:\n\n\n  Example: I reduce an NP-complete problem ```\na```\n to a problem ```\nb```\n. Therefore, problem ```\nb```\n is now proven to be NP-complete.\n\n\nThe above conclusion only holds if you've shown ```\nb```\n to be in NP. If ```\nb```\n is \"harder\" than NP, then it is not NP-complete. Note, however, that the reduction is enough to prove that ```\nb```\n is NP-hard.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Classifying NP Completeness and Hardness\r\n                \r\nChoose the correct statement(s):\n\n(A) If ```\nX```\n is an NP-complete problem, then ```\nX```\n is an NP problem\n(B) If ```\nX```\n is an NP-complete problem, then ```\nX```\n is an NP-hard\n(C) Let ```\nX```\n be an NP-complete problem. If ```\nX```\n can polynomial reduce to a problem ```\nY```\n, then ```\nY```\n is an NP-complete.\n(D) Let ```\nX```\n be an NP-complete problem. If ```\nY```\n can polynomial reduce to a problem ```\nX```\n, then ```\nY```\n is an NP-complete.\n(E) Let ```\nX```\n be an NP-complete problem. If ```\nX```\n can polynomial reduce to a problem ```\nY```\n, then ```\nY```\n is an NP-hard.\n\nMy answer is (A)(B)(C)(E):\n\n(A)(B) : X belongs to NP-complete, means X belongs to NP and NP-hard\n(C) true\n(D) Y may be P, NP-hard or NP-complete\n(E) Y is an NP-complete, and it also is an NP-hard\n\n\nIs answer true?\n    ", "Answer": "\r\nHere are some corrections:\n(C) False. Y is NP-hard, but not necessarily in NP.\n(D) False. Y is in NP, not necessarily NP-complete.\n(E) True, but Y is no necessarily NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP complete - solvable in non-deterministic polynomial time\r\n                \r\nIt is written in a book that --\"If a problem A is NP-Complete, there exists a non-deterministic polynomial time algorithm to solve A\" . But as far I know 'yes' -answer for NP complete problems can be \"verified\" in polynomial time. I am really confused. Can a NP-complete problem be \"solved\" using non-deterministic polynomial time algorithm?\n    ", "Answer": "\r\nThe two things are basically identical and are based on two different though equivalent definition of NP.\n\nEvery problem (language) in NP must be:\n\n\nVerified in polynomial time by a deterministic turing machine. (given a problem and a 'verification', you can answer if the verification is correct for the problem in a polynomial time).\nExample: Given a graph, and you want to check if there is a hamiltonian path in it - the verifier can be the path. You can easily check if the path is indeed hamiltonian once you have it.\nSolved in polynomial time by a non deterministic turing machine. (there exists non deterministic Turing Machine ```\nM```\n that can solve the problem polynomially)\n\n\nSince by definition of NP-Complete - a problem is NP Complete if it is NP-Hard AND in NP, every NP-Complete problem is also NP - and both are correct.\n\n\n\nNote that those two claims are basically based on the two equivalent definitions for NP:\n\n\nA language ```\nL```\n is in NP if for each ```\nx```\n in ```\nL```\n there is a word ```\nz```\n such that ```\n|z|```\n is polynomial in ```\n|x|```\n, and there exists some deterministic turing machine that runs in polynomial time ```\nM```\n - such that for each ```\nx```\n and its matching ```\nz```\n,: ```\nM(x,z) = true if and only if x is in L```\n\nA problem is in NP if there is a non deterministic turing machine that can solve the problem in polynomia time. Formally, a language ```\nL```\n is in NP if there is a non deterministic turing machine such that ```\nM(x) = true if and only if x is in L```\n\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If these problems are NP-Complete, how are there polynomial time algorithms for solving them?\r\n                \r\nI'm studying P, NP, and NP-Complete problems and I've encountered some questions.\n\nI understand that a problem is P if you can solve it in polynomial time, and a problem is NP if it is verifiable in polynomial time. I also understand that a problem is NP-Complete if it is NP and can be reduced from an existing NP-Complete problem.\n\nI know that SAT, 3-SAT, Independent Set, Vertex Cover, Hamiltonian Cycle, Subset Sum, and Traveling Salesman are all NPC. But I encountered a problem where I was told that deciding whether an independent set of 5 vertices exists in a graph is actually polynomial time solvable instead of NPC. This then confused me because I thought independent set problems were NPC.\n\nSo then it made me wonder, in what scenarios are these \"NPC\" problems not NPC and are in fact P? When given a problem, how do I determine whether a problem is P or NPC? What if the problem does have a poly time solvable solution I just wasn't able to come up with it and therefore went down the NPC path. How do I know that I've made a mistake?\n    ", "Answer": "\r\nThe problem of finding a maximal independent set of a graph is NP-hard, just like the travelling salesman problem. They are both optimisation problems, and they both involve enumerating a number of cases which is greater than polynomial in the input size.\n\nGiven a number ```\nk```\n, and a graph of ```\nn```\n vertices, the problem of finding an independent set of ```\nk```\n vertices is a separate problem, for which there is a polynomial-time solution. This is not an optimisation problem.\n\nThe solution is bounded by the fact that there are at most ```\nC(n, k)```\n subsets of five vertices, and for each subset, you need to check at most ```\nC(k, 2)```\n edges. Each of these is polynomial in ```\nn```\n for constant ```\nk```\n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Possible NP-complete problem?\r\n                \r\nI'd just like someone to verify whether the following problem is NP-complete or if there is actually a better/easier solution to it than simple brute-force combination checking.\n\nWe have a sort-of resource allocation problem in our software, and I'll explain it with an example.\n\nLet's say we need 4 people to be at work during the day-shift. This number, and the fact that it is a \"day-shift\" is recorded in our database.\n\nHowever, we don't require just anyone to fill those spots, there's some requirements that needs to be filled in order to fit the bill.\n\nOf those 4, let's say 2 of them has to be a nurse, and 1 of them has to be doctors.\n\nOne of the doctors also has to work as part of a particular team.\n\nSo we have this set of information:\n\n\n  Day-shift: 4\n     1 doctor\n     1 doctor, need to work in team A\n     1 nurse  \n\n\nThe above is not the problem. The problem comes when we start picking people to work the day-shift and trying to figure out if the people we've picked so far can actually fill the criteria.\n\nFor instance, let's say we pick James, John, Ursula and Mary to work, where James and Ursula are doctors, John and Mary are nurses.\n\nUrsula also works in team A.\n\nNow, depending on the order we try to fit the bill, we might end up deducing that we have the right people, or not, unless we start trying different combinations.\n\nFor instance, if go down the list and pick Ursula first, we could match her with the \"1 doctor\" criteria. Then we get to James, and we notice that since he doesn't work in team A, the other criteria about \"1 doctor, need to work in team A\", can't be filled with him. Since the other two people are nurses, they won't fit that criteria either.\n\nSo we backtrack and try James first, and he too can fit the first criteria, and then Ursula can fit the criteria that needs that team.\n\nSo the problem looks to us as we need to try different combinations until we've either tried them all, in which case we have some criteria that aren't filled yet, even if the total number of heads working is the same as the total number of heads needed, or we've found a combination that works.\n\nIs this the only solution, can anyone think of a better one?\n\n\n\nEdit: Some clarification.\n\nComments to this question mentions that with this few people, we should go with brute-force, and I agree, that's probably what we could do, and we might even do that, in the same lane that some sort optimizations look at the size of the data and picks different sort algorithms with less initial overhead if the data size is small.\n\nThe problem though is that this is part of a roster planning system, in which you might have quite a few number of people involved, both as \"We need X people on the day shift\" as well as \"We have this pool of Y people that will be doing it\", as well as potential for a large \"We have this list of Z criteria for those X people that will have to somehow match up with these Y people\", and then you add to the fact that we will have a number of days to do the same calculation for, in real-time, as the leader adjusts the roster, and then the need for a speedy solution has come up.\n\nBasically, the leader will see a live sum information on-screen that says how many people are still missing, both on the day-shift as a whole, as well as how many people is fitting the various criteria, and how many people we actually ned in addition to the ones we have. This display will have to update semi-live while the leader adjusts the roster with \"What if James takes the day-shift instead of Ursula, and Ursula takes the night-shift\".\n\nBut huge thanks to the people that has answered this so far, the constraint satisfaction problem sounds like the way we need to go, but we'll definitely look hard at all the links and algorithm names here.\n\nThis is why I love StackOverflow :)\n    ", "Answer": "\r\nWhat you have there is a constraint satisfaction problem; their relationship to NP is interesting, because they're typically NP but often not NP-complete, i.e. they're tractable to polynomial-time solutions.\n\nAs ebo noted in comments, your situation sounds like it can be formulated as an exact cover problem, which you can apply Knuth's Algorithm X to.  If you take this tack, please let us know how it works out for you.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is it compulsory that the 'reduction of p‌r‌o‌b‌l‌e‌m be done in polynomial time' for it to be NP complete?\r\n                \r\nFor a problem to be NP complete, it must belong to the class NP and there must be a polynomial time algorithm to reduce it to an NP complete problem . \n\nNow what if we only have an exponential time algorithm for reduction . Will this problem still be called NP-complete ? Or are there no such existing problems? \n\nEDIT : Also please tell me whether there is any such problem and if it exists then to which class does it belong ? \n    ", "Answer": "\r\nIt can only be consider NP-complete if other NP problems can be reduced to it in polynomial time.  The reason this is a useful definition is that if we find a polynomial time algorithm for one, it automatically gives one for all NP problems.  If we allowed an exponential time reduction, but found a polynomial time solution to the reduced problem, that wouldn't actually help us solve the one we reduced it to.\n\nHope this helps.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Confusion about NP-hard and NP-Complete in Traveling Salesman problems\r\n                \r\nTraveling Salesman Optimization(TSP-OPT) is a NP-hard problem and Traveling Salesman Search(TSP) is NP-complete. However, TSP-OPT can be reduced to TSP since if TSP can be solved in polynomial time, then so can TSP-OPT(1). I thought for A to be reduced to B, B has to be as hard if not harder than A. As I can see in the below references, TSP-OPT can be reduced to TSP. TSP-OPT is supposed to be harder than TSP. I am confused...\n\nReferences: (1)Algorithm, Dasgupta, Papadimitriou, Vazirani Exercise 8.1 http://algorithmics.lsi.upc.edu/docs/Dasgupta-Papadimitriou-Vazirani.pdf https://cseweb.ucsd.edu/classes/sp08/cse101/hw/hw6soln.pdf\n\nhttp://cs170.org/assets/disc/dis10-sol.pdf\n    ", "Answer": "\r\nI took a quick look at the references you gave, and I must admit there's one thing I really dislike in your textbook (1st pdf) : they address NP-completeness while barely mentioning decision problems. The provided definition of an NP-complete problem also somewhat deviates from what I'd expect from a textbook. I assume that was a conscious decision to make the introduction more appealing...\n\nI'll provide a short answer, followed by a more detailed explanation about related notions.\n\n\n\nShort version\n\nIntuitively (and informally), a problem is in NP if it is easy to verify its solutions.\n\nOn the other hand, a problem is NP-hard if it is difficult to solve, or find a solution.\n\nNow, a problem is NP-complete if it is both in NP, and NP-hard. Therefore you have two key, intuitive properties to NP-completeness. Easy to verify, but hard to find solutions.\n\nAlthough they may seem similar, verifying and finding solutions are two different things. When you use reduction arguments, you're looking at whether you can find a solution. In that regard, both TSP and TSP-OPT are NP-hard, and it is difficult to find their solutions. In fact, the third pdf provides a solution to excercise 8.1 of your textbook, which directly shows that TSP and TSP-OPT are equivalently hard to solve.\n\nNow, one major distinction between TSP and TSP-OPT is that the former is (what your textbook call) a search problem, whereas the latter is an optimization problem. The notion of verifying the solution of a search problem makes sense, and in the case of TSP, it is easy to do, therefore it is NP-complete. For optimization problems, the notion of verifying a solution becomes weird, because I can't think of any way to do that without first computing the size of an optimal solution, which is roughly equivalent to solving the problem itself. Since we do not know an efficient way to verify a solution for TSP-OPT, we cannot say that it is in NP, thus we cannot say that it is NP-complete. (More on this topic in the detailed explanation.)\n\n\n\nThe tl;dr is that for TSP-OPT, it is both hard to verify and hard to find solutions, while for TSP it is easy to verify and hard to find solutions.\nReductions arguments only help when it comes to finding solutions, so you need other arguments to distinguish them when it comes to verifying solutions.\n\n\n\nMore details\n\nOne thing your textbook is very brief about is what a decision problem is.\nFormally, the notion of NP-completeness, NP-hardness, NP, P, etc, were developed in the context of decision problems, and not optimization or search problems.\n\nHere's a quick example of the differences between these different types of problems.\n\nA decision problem is a problem whose answer is either YES or NO.\n\n\n  TSP decision problem\n  \n  Input: a graph G, a budget b\n  \n  Output: Does G admit a tour of weight at most b ? (YES/NO)\n\n\nHere is the search version\n\n\n  TSP search problem\n  \n  Input: a graph G, a budget b\n  \n  Output: Find a tour of G of weight at most b, if it exists.\n\n\nAnd now the optimization version\n\n\n  TSP optimization problem\n  \n  Input: a graph G\n  \n  Output: Find a tour of G with minimum weight.\n\n\nOut of context, the TSP problem could refer to any of these. What I personally refer to as the TSP is the decision version. Here your textbook use TSP for the search version, and TSP-OPT for the optimization version.\n\nThe problem here is that those various problems are strictly distinct. The decision version only ask for existence, while the search version asks for more, it needs one example of such a solution. In practice, we often want to have the actual solution, so more practical approaches may omit to mention decision problems.\n\nNow what about it? The definition of an NP-complete problem was meant for decision problems, so it technically does not apply directly to search or optimization problems. But because the theory behind it is well defined and useful, it is handy to still apply the term NP-complete/NP-hard to search/optimization problem, so that you have an idea of how hard these problems are to solve. So when someone says the travelling salesman problem is NP-complete, formally it should be the decision problem version of the problem.\n\nObviously, many notions can be extended so that they also cover search problems, and that is how it is presented in your textbook. The differences between decision, search, and optimization, are precisely what the exercises 8.1 and 8.2 try to cover in your textbook. Those exercises are probably meant to get you interested in the relationship between these different types of problems, and how they relate to one another.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Polynomial time reduction from NP Complete to other problems\r\n                \r\nCan any one clear my doubt please?\n\nsuppose I have a problem A which is known to be in NP-complete. and I have a another problem B for which we don't know the complexity class.\n\nif I reduce A to B in polynomial time . we can say B also is in NP-Complete.\n\nbut..\nif I reduce B to A in polynomial time . why can't I say B also in NP-Complete?\n    ", "Answer": "\r\n\n  if I reduce A to B in polynomial time . we can say B also is in NP-Complete.\n\n\nNo, we can say that B is NP-hard. Completeness requires membership in NP as well, which does not follow from the assumptions.\n\nFor example, we can reduce 3SAT to the Halting Problem. The Halting Problem is not in NP (it's not even decidable).\n\n\n  if I reduce B to A in polynomial time . why can't I say B also in NP-Complete?\n\n\nWe can say that B is in NP. One algorithm for B is to use the reduction and then solve A. B might be an easy problem like \"length of the input is odd\".\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Which of these languages is NP-complete?\r\n                \r\nI was searching the difference between NP and NP-complete problems. I came upon this great answer in  StackOverflow by Jason. About NP-complete problems, he said\n\n\n  An NP problem X for which it is possible to reduce any other NP problem Y to X in polynomial time. Intuitively this means that we can solve Y quickly if we know how to solve X quickly. Precisely, Y is reducible to X if there is a polynomial time algorithm f to transform instances x of X to instances y = f(x) of Y in polynomial time with the property that the answer to x is yes if and only if the answer to f(x) is yes.\n\n\nMy question is: which one is the NP-complete problem, X or Y?\n    ", "Answer": "\r\nThe NP-complete language is X.  The idea is that you can start with an arbitrary NP language Y and, in polynomial time, reduce it to X.\n\nFormally, the definition of NP-completeness is as follows: A language X is called NP-complete iff\n\n\nX &in; NP.  That is, X can't be \"harder\" than the \"hardest NP problem,\" since X is itself a member of NP.\nFor any Y &in; NP, there is a polynomial-time mapping reduction from Y to X.  That is, X is \"at least as hard\" as any problem in NP, since a polynomial-time algorithm for X gives a polynomial-time algorithm for Y.  The fact that Y is polynomial-time reducible to X is sometimes denoted Y ≤p X, by the way.\n\n\nThat said, it is possible to reduce any NP-complete language to any other NP-complete language, so if Y polynomial-time reduces to X and X is NP-complete, it is possible (but not necessary) for Y to be NP-complete.  However, it is known that if Y reduces in polynomial time to X, that Y has to be an element of NP.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Definition of NP Complete\r\n                \r\nI'm trying to understand the formal definition of NP Complete and had some questions. I was wondering if someone can provide more insight.\n\nThe Jon Kleinberg algorithms book says that if every NP problem can be reduced to a problem X, then problem X is in the set NP Complete.\n\nNow since P is a subset of NP, it follows that we can reduce any problem in P to an NP Complete problem in polynomial time. This leads to a contradiction that since the reduction is in polynomial time, we can solve this NP Complete problem in polynomial time. This cannot be true. So I'm not sure where this reasoning is wrong.\n\nAlso if we are able to reduce any NP problem in polynomial time to NP Complete, then why do we say that NP Complete is harder. Since the reduction is in polynomial time, asymptotically speaking, it should not make a difference. \n    ", "Answer": "\r\n\n  Now since P is a subset of NP, it follows that we can reduce any\n  problem in P to an NP Complete problem in polynomial time. This leads\n  to a contradiction that since the reduction is in polynomial time, we\n  can solve this NP Complete problem in polynomial time.\n\n\nYou get the direction of the reduction wrong.  If you can reduce any NP-complete problem to a given P problem, then P = NP, because that means this P problem is harder than or equivalent to any NP-Complete problem. The fact that a P problem can be reduced to NP problems doesn't show that it is harder than NP -- it shows that it's easier than NP, which is not surprising or contradictory. \n\nPretend that we can reduce shortest path to 1 run of TSP, and pretend that TSP can only be solved by by enumeration (exponential complexity). Then, shortest path is polynomial, the reduction is polynomial (O(1)), but the TSP is not polynomial. This is a hypothetical example. But hopefully, it shows that the fact TSP can solve SP in one run doesn't mean TSP is easy by any measure. The complexity of TSP is not constrained by the fact that it can easily solve SP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "what is the class of the combination of two problems which one of them is NP-Complete problem?\r\n                \r\nI have an optimization problem with a minimization cost function and two constraints to meet. Without considering one of the constraints, I can reduce the optimization problem to an NP-Complete problem. But with both constraints, I don't have any idea to reduce the problem to a known NP-Complete or NP-hard problem.\nSuppose in a graph, I want to select the minimum number of nodes that address two different conditions. These conditions are independent. For example one of them is addressing the minimum dominating set problem and another is ensuring that nodes with some structural features are selected. So, I should find the minimum number of nodes that both dominant all nodes of the network, and also ensure nodes with specific structural features are selected. Without the second constraint, I can prove that the optimization model is an NP-hard problem. But with both of them, I can't find any known problem to reduce.\nTherefore, I want to know that, is it possible to say that as the optimization problem with one of the constraints is NP-hard or NP-Complete, so with both constraints has also the same complexity class?\n    ", "Answer": "\r\nIf you are asking if this is true in general, the answer is no.\nExample 1: Satisfiability problem (3-SAT) is NP-Complete. Add a constraint that the clauses have atmost one positive literal (Horn clause), we get Horn-satisfiability (HORN-SAT) problem which is solvable in polynomial time. Here, adding a constraint made the problem less complex and easier to solve.\nExample 2: Minimum Spanning Tree (MSP) is of complexity O(E log(V)). If we add the constraints that there can be no branches in the tree, we get the Traveling Salesman Problem (TSP) which is NP-Complete. Here, adding a constraint made the problem more complex and difficult to solve.\nSo, adding a constraint can either increase or decrease complexity. Therefore, the answer to your question is - No.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Does solving a NP-hard problem in polynomial time make it NP-complete?\r\n                \r\nI am trying to understand the process so that P = NP. Consider a problem L which is reducible to a problem that is NP-Complete, meaning L is NP-hard. Now, if we solve L in polynomial time, will it be NP-complete? Making P = NP to be true. Am I missing something?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "example of reduction a polynomial decision to an NP-complete\r\n                \r\nI know if I reduce an NP-complete problem to a unknown problem P then I'm sure that P is itself NP-complete. And I know if I reduce a Problem P to an NP-complete problem there is no conclusion. So I want to give an example to show that we can reduce a Polynomial solvable problem P to an NP-complete one.\n    ", "Answer": "\r\n\n  If I reduce an NP-complete problem to a unknown problem P then I'm\n  sure that P is itself NP-complete\n\n\nNo, this is not well formulated. If an NP-complete problem A is reducible to a problem P all we can say is that any problem in NP is reducible to P. To say that P is NP-complete we need to know additionally that P is itself in NP.\n\nWhat you probably intended to say was\n\n\n  If I reduce an NP-complete problem to some a unknown  problem P in NP then I'm\n  sure that P is itself NP-complete\n\n\nNow to your original question. \n\n\n  give an example to show that we can reduce a Polynomial solvable\n  problem P to an NP-complete one\n\n\nConsider the problem known as 2-SAT: Given a boolean formula in conjunctive normal form such that each disjunction contains at most two variables tell it if is satisfiable.\n\nSolving this problem following an algorithm by Aspvall, Plass & Tarjan (1979) involves building an implication graph and finding all its strongly connected components. The paper proves that the formula is satisfiable if and only if the implication graph does not contain a strongly connected component that include some variable together with its negation. It also shows that this algorithm is linear in the size of the formula encoding.\n\nSo \n\n\nthere exists a linear algorithm for 2-SAT.\n2-SAT is reducible to unrestricted boolean satisfiability problem known as SAT.\n\n\nThis gives an example of a polynomially solvable problem (2-SAT) that is reducible to an NP-complete problem (SAT).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "example of reduction a polynomial decision to an NP-complete\r\n                \r\nI know if I reduce an NP-complete problem to a unknown problem P then I'm sure that P is itself NP-complete. And I know if I reduce a Problem P to an NP-complete problem there is no conclusion. So I want to give an example to show that we can reduce a Polynomial solvable problem P to an NP-complete one.\n    ", "Answer": "\r\n\n  If I reduce an NP-complete problem to a unknown problem P then I'm\n  sure that P is itself NP-complete\n\n\nNo, this is not well formulated. If an NP-complete problem A is reducible to a problem P all we can say is that any problem in NP is reducible to P. To say that P is NP-complete we need to know additionally that P is itself in NP.\n\nWhat you probably intended to say was\n\n\n  If I reduce an NP-complete problem to some a unknown  problem P in NP then I'm\n  sure that P is itself NP-complete\n\n\nNow to your original question. \n\n\n  give an example to show that we can reduce a Polynomial solvable\n  problem P to an NP-complete one\n\n\nConsider the problem known as 2-SAT: Given a boolean formula in conjunctive normal form such that each disjunction contains at most two variables tell it if is satisfiable.\n\nSolving this problem following an algorithm by Aspvall, Plass & Tarjan (1979) involves building an implication graph and finding all its strongly connected components. The paper proves that the formula is satisfiable if and only if the implication graph does not contain a strongly connected component that include some variable together with its negation. It also shows that this algorithm is linear in the size of the formula encoding.\n\nSo \n\n\nthere exists a linear algorithm for 2-SAT.\n2-SAT is reducible to unrestricted boolean satisfiability problem known as SAT.\n\n\nThis gives an example of a polynomially solvable problem (2-SAT) that is reducible to an NP-complete problem (SAT).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "how is sudoku np-complete?\r\n                \r\nhow is Sudoku an np-complete problem? according to wiki, to be classed as an np-complete problem it must satisfy 2 conditions\n\n\nproblem must be in np\nevery other problem in np must be reducible to given problem in polynomial time\n\n\nhow is the second condition satisfied? can you give an example? for instance, I don't see any correlation between Sudoku problem and the travelling salesman problem or knapsack problem\n\n(kindly forgive poor formatting as I'm typing this question on my mobile device)\n    ", "Answer": "\r\nNP-completeness of SUDOKU notes in part:\n\n\n  This result was first shown in this master’s thesis by reduction from\n  the NP-complete problem LATIN SQUARE COMPLETION. Sudoku wikipedia\n  page. \n  \n  Here is how it works (simplified, without reference to\n  ASP-completeness, which I don’t cover in this course).\n  \n  Suppose we have a n×n instance of LATIN SQUARE COMPLETION. We\n  construct a n2×n2 instance of SUDOKU, that encodes the instance of\n  LATIN SQUARE COMPLETION. Moreover, the encoding is very direct.\n\n\nhttp://www-imai.is.s.u-tokyo.ac.jp/~yato/data2/MasterThesis.pdf being a link to the thesis in PDF.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Cook's theorem and NP complete reductions\r\n                \r\nBased on Cook's theorem, \n\n\n  Any NP problem can be converted to SAT in polynomial time\n\n\nI know that SAT is a NP-complete problem. Therefore, is it accurate to say:\nIf we can reduce a search problem A (which is in NP) to problem B in a polynomial number of steps, then problem B must be NP-complete? \n    ", "Answer": "\r\nYou are on the right track, but there is a little bit more that must be done to show that problem A is in fact NP hard. If you have already proven that problem A is in NP (reword as a decision problem, describe a yes certificate, and show that it can be verified in polynomial time), then what you must do is show that if you were to hypothetically find an algorithm that solves problem A in polynomial time, then that algorithm could be used to solve any SAT problem in polynomial time as well. \n\nThis shows that your problem requires you to solve SAT (as well as other possible inputs for problem A) in polynomial time, and since SAT has yet to be solved in polynomial time, you can explain to whoever is asking you to solve the problem that this is an unreasonable request. To show this, find a way to convert SAT into input for your problem A (think how to transform the edges and vertices into the input of problem A). \n\nNow, show that this transformation from SAT to problem A is done in polynomial time, and then show that the answer from problem A can be transformed back into an answer for SAT (again, in polynomial time). Lastly, make sure to explain that an answer to problem A is equivalent to an answer to SAT (the answer to SAT is correct IFF the answer to problem A is correct).\n\nFor all of these steps, treat the hypothetical algorithm for problem A as a black box that magically solves the problem in polynomial time. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is there any well-known NP-complete problem that I can reduce a 'node placement' problem to?\r\n                \r\nI have the following NP-complete problem:\n\nGiven:\n\n\na set of locations in a N × N field,\na set of m nodes, and \na connectivity graph of the nodes (i.e. an undirected graph whose edges represent every pair of nodes in contact with each other), and\ncontact range R (in the same length unit as the N × N field),\n\n\nfind a placement of the nodes in the field respecting the connectivity graph (i.e. place nodes such that any pair in contact is nearer than R and any pair not in contact is farther than R), or show that such placement does not exist.\n\nIs the a well-known NP-complete problem that this problem can be reduced to?\n\n(Also an optimization version of the problem can be considered, i.e. to find the most optimal placement)\n    ", "Answer": "\r\nSet cover sounds alot like this problem. In fact, it may be almost precisely this problem. Even better: it has an approximation algorithm guaranteed to be within O(log n) of the optimal solution.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What is a \"Natural\" NP-Complete prob?\r\n                \r\nI think I have a pretty decent understanding of NP-Complete, NP-Hard, etc. in general, but all of a sudden, stumbling upon some literature, I found someone saying a \"natural\" NP-complete problem -- explicitly with those quotes. I didn't understand what they meant, so I tried to google it -- it popped up several more times, but no one ever bothered explaining what they meant by \"natural\".\n\nCan someone explain to me what the context is for putting quotes around \"natural\" -- what does one mean when they say a \"natural\" NP-complete problem?\n    ", "Answer": "\r\nIn the context of CS theory, you often see someone prove that there are problems with certain properties by defining highly contrived problems that no one would likely actually encounter in practice. For example, Ladner's theorem shows that if P ≠ NP, then there is a problem in NP that isn't in P but also isn't NP-complete, but the specific problem devised is highly contrived and, essentially, was constructed for the sole purpose of having the indicated property. These problems, subjectively, are referred to as \"unnatural\" problems because the problem was invented to have some property.\n\nA \"natural\" problem is a problem that, subjectively, is interesting in its own right - usually, something that's been studied before - that is later shown to have some interesting theoretical property. In that context, a \"natural\" NP-complete problem would be an NP-complete problem that actually arises in practice - say, something like 3-colorability, the Hamiltonian cycle problem, or boolean satisfiability.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to prove this josephus problem variation is a np-complete problem?\r\n                \r\nI have a problem that is a Josephus problem variation. It is described below:\nThere are m cards with number from 1 to m，and each of them has a unique number. The cards are dispatched to n person who sit in a circle. Note that m >= n.\nThen we choose the person \"A\" who sits at the position \"p\" to out of the circle, just like the Josephus problem does. Next step we skip \"k\" person at the right of p while k is the number of the card toked by the person \"A\", and we do the same thing until only one person left in the circle.\nQuestion is given n person and m cards, can we choose n cards and allocate them to the n person, to make that whether start at which position(exclude the first position), the person survival at the end is always the first person in the circle.\nFor example, m = n = 5, the only solution is (4, 1, 5, 3, 2).\nI think this problem is a np-complete problem, but I can't prove it. Anybody has a good idea to find a polynomial time solution or prove it's np-hard?\n--- example solutions ---\n```\n 2: [ 1,  2]\n 2: [ 2,  1]\n 3: [ 1,  3,  2]\n 3: [ 3,  1,  2]\n 4: [ 4,  1,  3,  2]\n 5: [ 4,  1,  5,  3,  2]\n 7: [ 5,  7,  3,  1,  6,  4,  2]\n 9: [ 2,  7,  3,  9,  1,  6,  8,  5,  4]\n 9: [ 3,  1,  2,  7,  6,  5,  9,  4,  8]\n 9: [ 3,  5,  1,  8,  9,  6,  7,  4,  2]\n 9: [ 3,  9,  2,  7,  6,  1,  5,  4,  8]\n 9: [ 6,  1,  8,  3,  7,  9,  4,  5,  2]\n10: [ 3,  5,  6, 10,  1,  9,  8,  7,  4,  2]\n10: [ 4,  5,  2,  8,  7, 10,  6,  1,  9,  3]\n10: [ 5,  1,  9,  2, 10,  3,  7,  6,  8,  4]\n10: [ 6,  3,  1, 10,  9,  8,  7,  4,  5,  2]\n10: [ 8,  5,  9, 10,  1,  7,  2,  6,  4,  3]\n10: [10,  5,  2,  1,  8,  7,  6,  9,  3,  4]\n11: [ 2,  1, 10, 11,  9,  3,  7,  5,  6,  8,  4]\n11: [ 3,  7, 11, 10,  9,  8,  1,  6,  5,  4,  2]\n11: [ 3, 11, 10,  9,  8,  1,  7,  2,  4,  5,  6]\n11: [ 4,  1, 10,  2,  9,  8,  7,  5, 11,  3,  6]\n11: [ 4,  2,  7, 11,  5,  1, 10,  9,  6,  3,  8]\n11: [ 4,  7,  2,  3,  1, 10,  9,  6, 11,  5,  8]\n11: [ 4,  7,  3,  9, 11, 10,  1,  8,  6,  5,  2]\n11: [ 4, 11,  7,  2,  1, 10,  9,  6,  5,  3,  8]\n11: [ 5, 11,  3,  9,  8,  7,  6,  1, 10,  4,  2]\n11: [ 6,  1, 10,  2,  9,  8,  7,  5, 11,  3,  4]\n11: [ 6,  2,  7, 11,  5,  1, 10,  9,  4,  3,  8]\n11: [ 6, 11,  1,  3, 10,  2,  7,  5,  4,  9,  8]\n11: [ 9,  5,  3,  1, 10,  2,  8,  7, 11,  6,  4]\n12: [ 1,  7, 11, 10,  4,  9,  2, 12,  6,  5,  8,  3]\n12: [ 3,  7, 12,  2, 11, 10,  9,  1,  6,  5,  4,  8]\n12: [ 3,  8, 11,  2, 12,  9,  1,  7,  5, 10,  4,  6]\n12: [ 4,  2,  5,  1, 11, 10,  9,  8, 12,  7,  3,  6]\n12: [ 4,  3,  7,  6,  1, 11, 10,  9,  8, 12,  5,  2]\n12: [ 5,  1,  6, 11,  9,  2, 10,  7, 12,  8,  3,  4]\n12: [ 5,  2,  3, 12,  9, 10,  7,  6,  1, 11,  4,  8]\n12: [ 5,  7, 12,  2, 10,  9,  8, 11,  1,  4,  6,  3]\n12: [ 7,  1,  2,  3,  5,  9, 10,  8, 11,  6, 12,  4]\n12: [ 8,  7,  1, 11,  9,  3,  5, 10,  6,  4, 12,  2]\n12: [ 8,  7, 11, 10, 12,  3,  1,  9,  6,  5,  4,  2]\n12: [12,  3, 11,  5,  1, 10,  8,  7,  6,  4,  9,  2]\n12: [12,  7, 11,  1,  9,  3,  2, 10,  6,  5,  4,  8]\n13: [ 2,  1,  4,  7, 11,  6,  3, 10, 13,  5,  8, 12,  9]\n13: [ 2,  5, 13, 12,  4, 11,  3,  1,  9,  7,  8,  6, 10]\n13: [ 2, 13, 12, 11,  3,  1,  9,  4,  8,  7, 10,  5,  6]\n13: [ 3,  5,  2,  1, 12,  9, 11, 10,  7,  6, 13,  4,  8]\n13: [ 3,  5, 13,  1, 11,  2,  9,  8,  7, 12,  6,  4, 10]\n13: [ 4, 13,  3,  1, 12, 11, 10,  9,  7,  2,  5,  6,  8]\n13: [ 6,  4,  3,  1, 10, 11, 13,  5,  9, 12,  7,  8,  2]\n13: [ 6,  4, 13,  7,  5,  1, 12, 11, 10,  9,  8,  3,  2]\n13: [ 6,  7,  3, 13, 12, 11, 10,  2,  1,  9,  5,  4,  8]\n13: [ 6,  7, 13, 11,  2, 10,  9,  1,  8, 12,  5,  3,  4]\n13: [ 6, 11,  7, 13,  1, 10,  2, 12,  9,  8,  5,  4,  3]\n13: [ 7,  3,  2,  1, 11, 10,  9,  8, 13,  5, 12,  4,  6]\n13: [ 7,  5, 13,  3, 10, 11,  2,  9,  1,  6,  8,  4, 12]\n13: [ 7,  5, 13,  3, 11,  2,  9,  8,  1,  6, 12,  4, 10]\n13: [ 7,  5, 13,  3, 11, 12,  2,  1,  9,  8,  6,  4, 10]\n13: [ 7,  9,  1, 11,  3, 13,  2, 10, 12,  6,  5,  4,  8]\n13: [ 8,  3,  5, 11, 13,  9, 10,  7,  1,  6,  4, 12,  2]\n13: [ 8,  3, 13,  1,  5, 11, 10,  9, 12,  7,  6,  4,  2]\n13: [ 9,  3, 13,  2, 10,  4,  1,  7,  6,  5, 12, 11,  8]\n13: [ 9,  4,  7,  5,  1, 11, 13, 10, 12,  8,  6,  3,  2]\n13: [ 9,  5,  4, 13,  2, 11,  8, 10,  1,  7, 12,  3,  6]\n13: [ 9,  5, 13,  4, 11,  1,  8,  3,  7, 12,  6, 10,  2]\n13: [10,  4,  3,  5, 13,  1,  9, 11,  7,  6,  8, 12,  2]\n13: [11,  2,  7,  3, 12,  1, 10,  9,  6,  5, 13,  4,  8]\n13: [11, 13,  5,  2, 10,  9,  8,  7,  1,  6,  4,  3, 12]\n13: [11, 13,  7,  1, 12,  9,  2,  3, 10,  5,  4,  6,  8]\n13: [12,  1,  3,  5, 11, 13,  4, 10,  9,  8,  7,  6,  2]\n13: [12,  7, 13,  3, 11,  1,  9,  8,  6,  5, 10,  4,  2]\n13: [12, 13,  7, 11,  2,  5,  1,  9, 10,  6,  4,  3,  8]\n13: [13,  3,  1, 12, 11,  2,  9, 10,  7,  6,  4,  5,  8]\n13: [13,  3,  7,  1,  5, 12,  4, 10,  9,  8, 11,  6,  2]\n14: [ 3,  5, 13, 14,  1, 12, 11, 10,  9,  8,  7,  6,  4,  2]\n14: [ 3,  9,  1, 13, 11, 10,  2,  4,  7, 14,  6,  8,  5, 12]\n14: [ 3, 14,  4, 12, 11,  1,  9,  8,  2, 13,  7,  5, 10,  6]\n14: [ 4, 11,  1, 13,  7, 10, 12,  2, 14,  9,  8,  5,  6,  3]\n14: [ 4, 14,  2,  5, 13,  1, 12, 11,  7,  6, 10,  9,  3,  8]\n14: [ 5,  7,  1, 13, 12, 11, 10,  2,  9,  8, 14,  6,  4,  3]\n14: [ 6,  3, 14,  5, 11, 13,  2, 12,  9,  1,  7,  4,  8, 10]\n14: [ 6, 14,  1, 12,  5, 13,  2, 11,  9,  7,  8,  4,  3, 10]\n14: [ 7,  5, 13, 12,  1, 11,  4, 10,  2, 14,  9,  8,  6,  3]\n14: [ 7, 11,  5, 13,  1,  3,  2,  4, 10,  9, 14,  6,  8, 12]\n14: [ 7, 14,  1, 13,  2,  5, 11, 12, 10,  9,  8,  4,  3,  6]\n14: [ 8,  7,  5, 13,  2, 11,  3,  9, 10, 12,  1, 14,  4,  6]\n14: [11,  2, 10,  5,  8,  7,  9,  1, 13, 14, 12,  4,  3,  6]\n14: [11,  3, 14,  2, 13,  1, 10,  8,  9,  7,  5, 12,  4,  6]\n14: [11,  5,  3, 14,  2,  1, 13, 10,  8,  7,  6, 12,  4,  9]\n14: [11, 14,  5,  3, 13,  1, 10,  2,  9,  4,  7,  8, 12,  6]\n14: [12,  1, 14,  3, 13,  4, 10,  9,  2,  7,  6,  5, 11,  8]\n14: [12, 11,  7,  5, 13,  3,  2, 14,  1,  9,  8,  4,  6, 10]\n14: [12, 14,  7, 13,  6,  5, 11,  1, 10,  9,  8,  4,  3,  2]\n14: [13,  1,  7,  2, 11,  3,  9, 14,  8,  6,  5, 10,  4, 12]\n14: [13, 11,  3,  1,  4,  2,  7, 10,  9,  6, 14, 12,  5,  8]\n14: [14,  1, 13,  3, 11,  5, 10,  9,  2,  6,  8,  7,  4, 12]\n14: [14, 5, 1, 13, 12, 2, 11, 3, 7, 9, 6, 8, 4, 10]\n```\n\n--- possibly helpful for a mathematical solution ---\nI noticed that starting with length 9, at least one solution for every length has a longish sequence of integers that decrement by 1.\n```\n 9: [3,  1,  2,                               7, 6, 5,    9, 4, 8]  \n10: [6,  3,  1,                     10, 9, 8, 7,          4, 5, 2] \n11: [3,  7,                     11, 10, 9, 8,             1, 6, 5, 4, 2]\n11: [3,                         11, 10, 9, 8,             1, 7, 2, 4, 5, 6]\n11: [5, 11,  3,                         9, 8, 7, 6,       1, 10, 4, 2]\n12: [4,  2,  5,  1,             11, 10, 9, 8,            12, 7, 3, 6] \n12: [4,  3,  7,  6, 1,          11, 10, 9, 8,            12, 5, 2] \n13: [6,  4, 13,  7, 5, 1,   12, 11, 10, 9, 8,             3, 2]\n14: [3,  5, 13, 14, 1,      12, 11, 10, 9, 8, 7, 6,       4, 2] \n```\n\n    ", "Answer": "\r\nI noticed that for every length I tested except the very small, at least one solution contains a relatively long run of descending\nnumbers. So far this answer only considers m = n. Here are a few examples; note that excess is n - run_len:\n```\nn = 3, run_len = 2, excess = 1: [1] + [3-2] + []\nn = 4, run_len = 2, excess = 2: [4, 1] + [3-2] + []\nn = 5, run_len = 2, excess = 3: [4, 1, 5] + [3-2] + []\nn = 6, no solution\nn = 7, run_len = 1, excess = 6: [5] + [7-7] + [3, 1, 6, 4, 2]\nn = 8, no solution\nn = 9, run_len = 3, excess = 6: [3, 1, 2] + [7-5] + [9, 4, 8]\nn = 10, run_len = 4, excess = 6: [6, 3, 1] + [10-7] + [4, 5, 2]\nn = 11, run_len = 4, excess = 7: [3, 7] + [11-8] + [1, 6, 5, 4, 2]\nn = 12, run_len = 4, excess = 8: [4, 2, 5, 1] + [11-8] + [12, 7, 3, 6]\nn = 13, run_len = 5, excess = 8: [6, 4, 13, 7, 5, 1] + [12-8] + [3, 2]\nn = 14, run_len = 7, excess = 7: [3, 5, 13, 14, 1] + [12-6] + [4, 2]\nn = 15, run_len = 8, excess = 7: [3, 15, 2] + [13-6] + [1, 5, 4, 14]\nn = 16, run_len = 6, excess = 10: [6, 3, 1, 10] + [16-11] + [2, 9, 7, 4, 5, 8]\nn = 17, run_len = 8, excess = 9: [2, 5, 17, 15, 14, 1] + [13-6] + [4, 3, 16]\nn = 18, run_len = 10, excess = 8: [6, 3, 17, 18, 1] + [16-7] + [5, 4, 2]\nn = 19, run_len = 10, excess = 9: [4, 19, 3, 17, 18, 1] + [16-7] + [5, 6, 2]\nn = 20, no solution found with run_length >= 10\nn = 21, run_len = 14, excess = 7: [3, 21, 2] + [19-6] + [1, 5, 4, 20]\nn = 22, run_len = 14, excess = 8: [22, 3, 2, 1] + [20-7] + [5, 21, 4, 6]\nn = 23, run_len = 14, excess = 9: [7, 1, 23, 3] + [21-8] + [6, 5, 22, 4, 2]\nn = 24, run_len = 16, excess = 8: [6, 5, 24, 2] + [22-7] + [3, 1, 23, 4]\nn = 25, run_len = 17, excess = 8: [25, 3, 2, 1] + [23-7] + [5, 24, 4, 6]\nn = 26, run_len = 17, excess = 9: [26, 3, 25, 2, 1] + [23-7] + [5, 24, 4, 6]\nn = 27, run_len = 20, excess = 7: [3, 27, 2] + [25-6] + [1, 5, 4, 26]\nn = 28, run_len = 18, excess = 10: [28, 1, 27, 2, 3] + [25-8] + [6, 5, 7, 4, 26]\nn = 29, run_len = 20, excess = 9: [2, 5, 29, 27, 26, 1] + [25-6] + [4, 3, 28]\nn = 30, run_len = 23, excess = 7: [30, 5, 2, 1] + [28-6] + [29, 3, 4]\nn = 31, run_len = 24, excess = 7: [5, 31, 3] + [29-6] + [1, 30, 4, 2]\nn = 32, run_len = 23, excess = 9: [7, 32, 31, 2, 1] + [30-8] + [5, 4, 3, 6]\nn = 33, run_len = 26, excess = 7: [3, 33, 2] + [31-6] + [1, 5, 4, 32]\nn = 34, run_len = 27, excess = 7: [3, 5, 33, 34, 1] + [32-6] + [4, 2]\nn = 35, run_len = 27, excess = 8: [5, 35, 3, 33, 34, 1] + [32-6] + [4, 2]\nn = 36, run_len = 26, excess = 10: [35, 7, 3, 1, 36, 2] + [34-9] + [6, 5, 4, 8]\nn = 37, run_len = 29, excess = 8: [6, 5, 2, 1] + [35-7] + [36, 37, 3, 4]\nn = 38, run_len = 29, excess = 9: [3, 7, 37, 38, 1] + [36-8] + [6, 4, 5, 2]\nn = 39, run_len = 32, excess = 7: [3, 39, 2] + [37-6] + [1, 5, 4, 38]\nn = 40, run_len = 31, excess = 9: [5, 2, 1] + [38-8] + [3, 7, 40, 4, 6, 39]\nn = 41, run_len = 33, excess = 8: [3, 5, 1, 40, 2] + [38-6] + [41, 39, 4]\nn = 42, run_len = 33, excess = 9: [42, 3, 41, 2, 1] + [39-7] + [5, 4, 40, 6]\nn = 43, run_len = 34, excess = 9: [6, 5, 7, 43, 1] + [41-8] + [42, 4, 3, 2]\nn = 44, run_len = 35, excess = 9: [5, 3, 2, 1] + [42-8] + [43, 7, 4, 44, 6]\nn = 45, run_len = 38, excess = 7: [3, 45, 2] + [43-6] + [1, 5, 4, 44]\nn = 50, run_len = 43, excess = 7: [50, 5, 2, 1] + [48-6] + [49, 3, 4]\nn = 100, run_len = 91, excess = 9: [5, 2, 1] + [98-8] + [3, 7, 100, 4, 6, 99]\nn = 201, run_len = 194, excess = 7: [3, 201, 2] + [199-6] + [1, 5, 4, 200]\n```\n\n20 is missing from the above table because the run length is at most 10, and is taking a long time to compute. No larger value that I've tested has such a small max run length relative to n.\nI found these by checking run lengths from n-1 descending, with all possible starting values and permutations of the run & surrounding elements. This reduces the search space immensely.\nFor a given n, if the max run in any solution to n is length n-k, then this will find it in O(k! * n). While this looks grim, if k has a constant upper bound (e.g. k <= some threshold for all sufficiently large n) then this is effectively O(n). 'Excess' is what I'm calling k in the examples above. I haven't found any greater than 10, but I don't have a solution yet to n = 20. If it has a solution then its excess will exceed 10.\nUPDATE: There are a lot of patterns here.\nIf n mod 6 is 3 and n >= 9, then [3, n, 2, [n-2, n-3, ..., 6], 1, 5, 4, n-1] is valid.\nIf n mod 12 is 5 and n >= 17 then [2, 5, n, n-2, n-3, 1, [n-4, n-5, ..., 6], 4, 3, n-1] is valid.\nIf n mod 20 is 10, then [n, 5, 2, 1, [n-2, n-3, ..., 6], n-1, 3, 4] is valid.\nIf n mod 60 is 7, 11, 31, or 47, then [5, n, 3, [n-2, n-3, ..., 6], 1, n-1, 4, 2] is valid.\nIf n mod 60 is 6 or 18 and n >= 18 then [6, 3, n-1, n, 1, [n-2, n-3, ..., 7], 5, 4, 2] is valid.\nIf n mod 60 is 1, 22, 25 or 52 and n >= 22 then [n, 3, 2, 1], [n-2, n-3, ..., 7], 5, n-1, 4, 6] is valid.\nIf n mod 60 is 23 then [7, 1, n, 3, [n-2, n-3, ..., 8], 6, 5, n-1, 4, 2] is valid.\nIf n mod 60 is 14 or 34 then [3, 5, n-1, n, 1, [n-2, n-3, ..., 6], 4, 2] is valid.\nIf n mod 60 is 24 then [6, 5, n, 2, [n-2, n-1, ..., 7], 3, 1, n-1, 4] is valid\nIf n mod 60 is 2, 6, 26, 42 and n >= 26 then [n, 3, n-1, 2, 1, [n-3, n-4, ..., 7], 5, n-2, 4, 6] is valid.\nIf n mod 60 is 16 or 28 then [n, 1, n-1, 2, 3, [n-3, n-4, ..., 8], 6, 5, 7, 4, n-2] is valid.\nIf n mod 60 is 32 then [7, n, n-1, 2, 1, [n-2, n-3, ..., 8], 5, 4, 3, 6] is valid.\nIf n mod 60 is 35 or 47 then [5, n, 3, n-2, n-1, 1, [n-3, n-4, ..., 6], 4, 2] is valid.\nIf n mod 60 is 37 then [6, 5, 2, 1, [n-2, n-1, ..., 7], n-1, n, 3, 4]\nIf n mod 60 is 38 then [3, 7, n-1, n, 1] + [n-2, n-3, ..., 8] + [6, 4, 5, 2]\nIf n mod 60 is 40 then [5, 2, 1, [n-2, n-3, ..., 8], 3, 7, n, 4, 6, n-1] is valid\nIf n mod 60 is 0 and n >= 60 then [3, 5, n, 2, [n-2, n-3, ..., 7], 1, 6, n-1, 4] is valid\nIf n mod 60 is 7, 19, or 31 and n >= 19 then [4, n, 3, n-2, n-1, 1, [n-3, n-4, ..., 7], 5, 6, 2] is valid\nIf n mod 60 is 23, 38, or 43 then [7, 3, n, 1, [n-2, n-3, ..., 8], 6, 5, n-1, 4, 2] is a valid solution\nIf n mod 60 is 14 or 44 and n >= 74 then [3, 5, n-1, n, 1, [n-3, n-4, ..., 6], n-2, 4, 2] is valid.\nIf n mod 60 is 1 or 49 and n >= 49 then [3, 5, n, 1, [n-2, n-3, ..., 7], 2, n-1, 4, 6] is valid.\nIf n mod 60 is 6, 18, 30, 42, or 54 and n >= 18 then [n, 3, n-1, 2, 1, [n-3, n-4, ..., 7], 5, 4, n-2, 6] is valid.\nIf n mod 60 is 10, 18, 38 or 58 and n >= 18 then [n-1, 7, 5, n, 1, [n-2, n-3, ..., 8], 2, 6, 4, 3] is valid.\nCurrently solved for n mod 60 is any of the following values:\n```\n 0,  1,  2,  3,      5,  6,  7,      9, \n10, 11,         14, 15, 16, 17, 18, 19,\n    21, 22, 23, 24, 25, 26, 27, 28, 29, \n30, 31, 32, 33, 34, 35,     37, 38, 39, \n40, 41, 42, 43, 44, 45,     47,     49,\n50, 51, 52, 53, 54,         57, 58\n```\n\nAlso,\nIf n mod 42 is 31 then [n, 3, 2, 1, [n-2, n-3, ..., 8], n-1, 5, 4, 7, 6] is valid.\nIf n mod 420 is 36 or 396 then [n-1, 7, 3, 1, n, 2, [n-2, n-3, ..., 9], 6, 5, 4, 8] is valid.\n--- Example for n=21, using the first pattern listed above, and all starting indices.\n```\n1:  [21,  2, 18, 19, 16, 17, 14, 15, 12, 13, 10, 11,  8, 9, 6, 7, 5,  4, 20,  1]\n2:  [ 2, 18, 21, 16, 19, 14, 17, 12, 15, 10, 13,  8, 11, 6, 9, 5, 1,  4, 20,  7]\n3:  [19, 21, 18,  2, 16, 17, 14, 15, 12, 13, 10, 11,  8, 9, 6, 7, 5,  4, 20,  1]\n4:  [18, 21, 19, 17,  2, 15, 16, 13, 14, 11, 12,  9, 10, 7, 8, 1, 5,  4, 20,  6]\n5:  [17, 21, 19, 18, 16,  2, 14, 15, 12, 13, 10, 11,  8, 9, 6, 7, 5,  4, 20,  1]\n6:  [16, 21, 19, 18, 17, 15,  2, 13, 14, 11, 12,  9, 10, 7, 8, 1, 5,  4, 20,  6]\n7:  [15, 21, 19, 18, 17, 16, 14,  2, 12, 13, 10, 11,  8, 9, 6, 7, 5,  4, 20,  1]\n8:  [14, 21, 19, 18, 17, 16, 15, 13,  2, 11, 12,  9, 10, 7, 8, 1, 5,  4, 20,  6]\n9:  [13, 21, 19, 18, 17, 16, 15, 14, 12,  2, 10, 11,  8, 9, 6, 7, 5,  4, 20,  1]\n10: [12, 21, 19, 18, 17, 16, 15, 14, 13, 11,  2,  9, 10, 7, 8, 1, 5,  4, 20,  6]\n11: [11, 21, 19, 18, 17, 16, 15, 14, 13, 12, 10,  2,  8, 9, 6, 7, 5,  4, 20,  1]\n12: [10, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11,  9,  2, 7, 8, 1, 5,  4, 20,  6]\n13: [ 9, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  8, 2, 6, 7, 5,  4, 20,  1]\n14: [ 8, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9, 7, 2, 1, 5,  4, 20,  6]\n15: [ 7, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9, 8, 6, 2, 5,  4, 20,  1]\n16: [ 6, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9, 8, 7, 1, 5,  4, 20,  2]\n17: [ 1,  5,  2, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9, 8, 7, 6, 4, 19, 20, 21]\n18: [ 5,  2, 18, 19, 16, 17, 14, 15, 12, 13, 10, 11,  8, 9, 6, 7, 4,  1, 20, 21]\n19: [ 4,  2, 18, 19, 16, 17, 14, 15, 12, 13, 10, 11,  8, 9, 6, 7, 5, 20, 21,  1]\n20: [20,  4, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9, 8, 7, 6, 1,  5, 21,  2]\n```\n\nYou can observe the same relationship between elements from the decrementing run and other elements for all values of n that the pattern applies to. This isn't a proof, but you can turn this into a proof, though I think the work would need to be done for each pattern separately and it's beyond the scope of what I'm going to spend time on for an S/O question.\n--- We can fill in the blanks by using m > n. ---\nThe pattern [n-1, n, 1, [n-2, n-3, ..., 3], n+5] is valid for n mod 4 is 1 and n >= 9.\nThe pattern [n, 2, 1, [n-2, n-3, ..., 3], n+4] is valid for n mod 2 is 0 and n >= 6.\nWith these two, plus what we already found, we get nearly everything. I found these by checking a single replacement value in a limited range.\n```\n 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, \n10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \n30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n50, 51, 52, 53, 54,     56, 57, 58\n```\n\nIf n mod 30 is 29, then [3, n, 2, [n-2, n-3, ..., 4], n-1, n+15) is valid, giving us n mod 60 is 59. We're left with just one unknown: n mod 60 is 55.\n...And finally! If n mod 12 is 7 (i.e. n mod 60 is 7, 19, 31, 43, or 55) then [n-1, n, 1, [n-2, n-3, ..., 6], 2, 5, 3, n+4] is valid for all n >= 19.\nWe now have solutions for all n mod 60, using m=n in most cases, and m=n+15 in the worst case.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP COMPLETE and NP HARD\r\n                \r\nI have to check out whether my logic is on the right path.\n\nNP-HARD: these are the hardest problems which may/may not be in NP class. If you have an efficient algorithm for these problems you have one for every problem in class NP.\n\nNP COMPLETE: these are the hardest problems in class NP and also if you solve one of these you could solve any problem in class NP. So, NP COMPLETE problem is an NP-HARD problem.\n\nCOOK'S THEOREM: If SAT(NP-HARD) has a polynomial time algorithm then so does every problem in class NP.\n\nNow, suppose we have to prove that CDP(clique decision problem) is NP COMPLETE.\n\n->Step 1: Prove that CDP is in the class NP.\n  It is in class NP because the prover can generate a proof for yes inputs which would enable the verifier to check that it is a CDP (has a clique of size k).\n\n->Step 2: Prove that CDP is NP HARD.\n For that, we can convert the SAT to CDP by constructing a graph from clauses and supplying k.\n We supply(G,k) to the clique subroutine which would verify is there a clique of size k or not. If it can figure this out in polynomial time then SAT has a polynomial time algorithm as CDP had a polynomial time algorithm and we converted SAT to CDP. So, now we proved that if there is a polynomial time algorithm for CDP then there is for the SAT. Now if we can find a polynomial time algorithm for CDP then it would imply that there is a polynomial time algorithm for SAT. This would imply that there is a polynomial time algorithm for every problem in  NP by COOK'S THEOREM.\n\nSo we proved that CDP is NP COMPLETE. Once we have added CDP to NP COMPLETE class and now we come up with a new problem which we have again to prove that it is NP COMPLETE we can prove that problem to be in NP and then we could prove that if there is an efficient algorithm for given problem then that implies that there is an efficient algorithm for SAT/CDP(as we have added this to NP COMPLETE). Then as said above we can convert this problem to CDP/SAT and then prove that if there is an efficient algorithm for our problem then there is one for CDP/SAT and then by COOK'S THEOREM again we have that if there is a solution to NP-HARD problem (in this case CDP/SAT) then there is one for every problem in NP. So we again proved our problem as NP-HARD and as now it also belongs to NP as said above it is NP COMPLETE.\n\nSo we can add as many problems to the NP COMPLETE class as long as we can convert some problem which is already in NP-HARD class(in this case SAT/CDP) into our problem and we should find an efficient algorithm to our problem  which would indirectly find an efficient algorithm to the NP-HARD problem and by COOK's theorem we can say that as some NP-HARD problem has an efficient algorithm we have an efficient algorithm to solve all problems in NP.\n    ", "Answer": "\r\nYou're on the right path, but there your logic is a little incomplete.\n\nThe general structure of your proof is correct: First prove a problem is in NP, then prove the problem is NP-Hard. Those two bits of information together prove that a problem is NP-Complete. \n\nYour proof for proving a problem is in NP is incomplete. Here are the key components to proving a problem is in NP:\n\n\nReword the problem as a decision problem that can be answered with a yes or a no.\nDescribe what a \"certificate\" would be. NOTE: a certificate is an output that can be checked to verify the answer to the decision problem. For CDP it could be a list of vertices and edges that make up the clique of size k.\nProve that this certificate can be verified in polynomial time.\n\n\nYour proof for proving NP-Hard is incomplete. Here are the key components to proving a problem is NP-Hard:\n\n\nTransform the input of the known NP-Hard problem into the input for the problem you are trying to prove.\nProve that this transformation can be done in polynomial time.\nTransform the output of the problem your trying to prove into the output of the known NP-Hard problem.\nDemonstrate how this can be done in polynomial time.\nProve that if you get an answer for the problem you are trying to prove, then you have an answer for the known problem.\nProve that if you get an answer for the known problem you have an answer for the problem you are trying to prove.\n\n\nOnly by meeting those 6 criterion can you say you have completely proven that a problem is NP-Hard. \n\nBesides the specifics on that your logic is sound. Be careful when saying \"efficient\" if you really mean \"can be solved in polynomial time\".\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why we cant have FPTAS for Strong NP complete problems [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI understood that we can apply FPTAS to the weak NP problems like 0-1 knapsack.\n\nBut why we cant apply the same principal to the strong NP problems like bin packing.I also checked wiki page about the same but understood very less.\n    ", "Answer": "\r\nIf a stongly NP complete problem had an FPTAS, you could \"trick\" the approximation algorithm into giving an optimal solution.  Details are here: http://www.idi.ntnu.no/~mlh/algkon/complexity.pdf\n\nThe existence of this FPTAS would give a polynomial time algorithm for NP-complete problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is the resolution problem in OSGi NP-Complete?\r\n                \r\nThe resolution problem is described in the modularity chapter of the OSGi R4 core specification. It's a constraint satisfaction problem and certainly a challenging  problem to solve efficiently, i.e. not by brute force. The main complications are the uses constraint, which has non-local effects, and the freedom to drop optional imports to obtain a successful resolution.\n\nNP-Completeness is dealt with elsewhere on StackOverflow.\n\nThere has already been plenty of speculation about the answer to this question, so please avoid speculation. Good answers will include a proof or, failing that, a compelling informal argument.\n\nThe answer to this question will be valuable to those projects building resolvers for OSGi, including the Eclipse Equinox and Apache Felix open source projects, as well as to the wider OSGi community.\n    ", "Answer": "\r\nYes.\n\nThe approach taken by the edos paper Pascal quoted can be made to work with OSGi. Below I’ll show how to reduce any 3-SAT instance to an OSGi bundle resolution problem. This site doesn’t seem to support mathematical notation, so I’ll use the kind of notation that’s familiar to programmers instead.\n\nHere’s a definition of the 3-SAT problem we’re trying to reduce:\n\nFirst define A to be a set of propositional atoms and their negations A = {a(1), … ,a(k),na(1), … ,na(k)}. In simpler language, each a(i) is a boolean and we define na(i)=!a(i)\n\nThen 3-SAT instances S have the form:  S = C(1) & … & C(n)\n\nwhere C(i) = L(i,1) | L(i,2) | L(i,3) and each L(i,j) is a member of A\n\nSolving a particular 3-SAT instance involves finding a set of values, true or false for each a(i) in A, such that S evaluates to true.\n\nNow let’s define the bundles we’ll be use to construct an equivalent resolution problem. In the following all bundle and package versions are 0 and import version ranges unrestricted except where specified. \n\n\nThe whole expression S will be represented by Bundle BS \nEach clause C(i) will be represented by a bundle BC(i) \nEach atom a(j) will be represented by a bundle BA(j) version 1 \nEach negated atom na(j) will be represented by a bundle BA(j) version 2\n\n\nNow for the constraints, starting with the atoms:\n\nBA(j) version 1\n-export package PA(j) version 1\n-for each clause C(i) containing atom a(j) export PM(i) and add PA(j) to PM(i)’s uses directive  \n\nBA(j) version 2\n-export package PA(j) version 2\n-for each clause C(i) containing negated atom na(j) export PM(i) and add PA(j) to PM(i)’s uses directive  \n\nBC(i)\n-export PC(i)\n-import PM(i) and add it to the uses directive of PC(i)\n-for each atom a(j) in clause C(i) optionally import PA(j) version [1,1] and add PA(j) to the uses directive of the PC(i) export\n-for each atom na(j) in clause C(i) optionally import PA(j) version [2,2] and add PA(j) to the uses directive of the PC(i) export  \n\nBS\n-no exports\n-for each clause C(i) import PC(i)\n-for each atom a(j) in A import PA(j) [1,2]  \n\nA few words of explanation:\n\nThe AND relationships between the clauses is implemented by having BS import from each BC(i) a package PC(i) that is only exported by this bundle.\n\nThe OR relationship works because BC(i) imports package PM(i) which is only exported by the bundles representing its members, so at least one of them must be present, and because it optionally imports some PA(j) version x from each bundle representing a member, a package unique to that bundle.\n\nThe NOT relationship between BA(j) version 1 and BA(j) version 2 is enforced by uses constraints. BS imports each package PA(j) without version constraints, so it must import either PA(j) version 1 or PA(j) version 2 for each j. Also, the uses constraints ensure that any PA(j) imported by a clause bundle BC(i) acts as an implied constraint on the class space of BS, so BS cannot be resolved if both versions of PA(j) appear in its implied constraints. So only one version of BA(j) can be in the solution.\n\nIncidentally, there is a much easier way to implement the NOT relationship - just add the singleton:=true directive to each BA(j). I haven’t done it this way because the singleton directive is rarely used, so this seems like cheating. I’m only mentioning it because in practice, no OSGi framework I know of implements uses based package constraints properly in the face of optional imports, so if you were to actually create bundles using this method then testing them could be a frustrating experience.\n\nOther remarks:\n\nA reduction of 3-SAT that doesn't use optional imports in also possible, although this is longer. It basically involves an extra layer of bundles to simulate the optionality using versions. A reduction of 1-in-3 SAT is equivalent to a reduction to 3-SAT and looks simpler, although I haven't stepped through it.\n\nApart from proofs that use singleton:=true, all of the proofs I know about depend on the transitivity of uses constraints. Note that both singleton:=true and transitive uses are non-local constraints.\n\nThe proof above actually shows that the OSGi resolution problem is NP-Complete or worse. To demonstrate that it’s not worse we need to show that any solution to the problem can be verified in polynomial time. Most of the things that need to be checked are local, e.g. looking at each non-optional import and checking that it is wired to a compatible export. Verifying these is O(num-local-constraints). Constraints based on singleton:=true need to look at all singleton bundles and check that no two have the same bundle symbolic name. The number of checks is less than num-bundlesnum-bundles. The most complicated part is checking that the uses constraints are satisfied. For each bundle this involves walking the uses graph to gather all of the constraints and then checking that none of these conflict with the bundle’s imports. Any reasonable walking algorithm would turn back whenever it encountered a wire or uses relationship it had seen before, so the maximum number of steps in the walk is (num-wires-in-framework + num-uses-in framework). The maximum cost of checking that a wire or uses relationship hasn't been walked before is less than the log of this. Once the constrained packages have been gathered the cost of the consistency check for each bundle is less than num-imports-in-bundlenum-exports-in-framework. Everything here is a polynomial or better.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-complete or NP-hard?\r\n                \r\nGiven a list of n positive integers (n even), divide the list into two sublists such that the difference between  the sums of the integers in the two sublists is minimized. Would this be a NP-complete problem or a NP-hard problem?\n    ", "Answer": "\r\nTL;DR - it's np hard.\n\nthis is the optimization version of the partition problem.\nthe partition problem is deciding if a given list of positive integers can be divided into 2 subsets so that the sums of the subsets are equal.\nthe optimization version asks for the minimized difference (like you asked).\n\nthe partition problem is np-complete but the optimization is np hard.\n\nyou can read more on these problems in wiki:\nhttps://en.wikipedia.org/wiki/Partition_problem\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What would a P=NP proof be like, hypothetically?\r\n                \r\nWould it be an polynomial time algorithm to a specific NP-complete problem, or just abstract reasonings that demonstrate solutions to NP-complete problems exist?\n\nIt seems that the a specific algoithm is much more helpful. With it, all we'll have to do   to polynomially solve an NP problem is to convert it into the specific NP-complete problem for which the proof has a solution, and we are done.\n    ", "Answer": "\r\nP = NP: \"The 3SAT problem is a classic NP complete problem. In this proof, we demonstrate an algorithm to solve it that has an asymptotic bound of (n^99 log log n). First we ...\"\n\nP != NP: \"Assume there was a polynomial algorithm for the 3SAT problem. This would imply that .... which by ..... implies we can do .... and then ... and then ... which is impossible. This was all predicated on a polynomial time algorithm for 3SAT. Thus P != NP.\"\n\nUPDATE: Perhaps something like this paper (for P != NP).\n\nUPDATE 2: Here's a video of Michael Sipser sketching out a proof for P != NP\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "When asked if two graphs are the same, is the problem P, NP, NP-hard, NP-complete? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs details or clarity. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Add details and clarify the problem by editing this post.\r\n                \r\n                    \r\n                        Closed 2 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI was given a question where two graphs are given and the questions asks if the two graphs are the same and whether the problem was a P, NP, NP-hard or NP-complete. By looking at the two graph, the graphs are not the same. However, I don't know what type of problem it is.\n    ", "Answer": "\r\nFirst of all, you have to define what you mean by \"the same\". There are several ways of defining equality, but the most likely one in this context is graph isomorphism, where two graphs are equal if there is an edge-preserving bijection between them.\nNext, if the problem is just to decide if your two given graphs are the same or not (and this is how you stated it), the problem is trivially in O(1) (and therefore in P and NP).\nIf, however, the problem is to decide whether any two graphs are isomorphic, the problem is in NP. It is currently neither known whether it is in P nor whether it is NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How does NP-Complete compare to NP-Hard?\r\n                \r\nSo from what I understand:\n\nNP are problems that can be easy to solve and verify (ie: multiplication)\n\nNP-Hard are problems that are hard to solve but easy to verify (factoring)\n\nWhat is NP-Complete? The answers I find online say it's almost like NP-hard but I'm having trouble distinguishing the two.\n\nRelated: NP-Complete VS NP-Hard\n    ", "Answer": "\r\nNP-complete problems are decision problems and belong to NP (and every problem in NP can be reduced in polynomial time to them, but these details I guess you already saw online).\n\nNP-hard are problems to which any problem in NP can be reduced, but not necessarily belong to NP or are decision problems.\n\nObviously, every NP-complete problem is also NP-hard (by definition of NP-hard). The opposite is not true, there are problems that are NP-hard but do not belong to NP. \n\nFor example, finding count of all solutions to a SAT instance (#SAT) is NP-hard but does not belong to NP-complete class, at least because it is not a decision problem and hence does not belong to NP. \n\nOn the other hand, SAT, the problem of deciding if count of satisfying solutions is greater than zero, belongs to NP and every problem in NP can be reduced to it, hence it is NP-complete.\n\nNote, every problem in NP can be reduced to (#SAT) (because SAT can be reduced to #SAT, just find a count and output true if it is non-zero). It is \"hard\" at least as SAT; this is the intuition behind the name NP-hard. \n\nI would also like to point to an excellent and detailed answer covering more details.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Some clarification regarding P-NP ness\r\n                \r\nQ1> All NP problems are polynomial time reducible to an NP-COMPLETE Problem.\nSo are all NP-COMPLETE problems polynomial time reducible to an NP Problem?\n\nQ2> All NP-COMPLETE problems and NP problems are polynomial time reducible to an NP-HARD Problem.\nSo are all NP-HARD problems polynomial time reducible to an NP/NP-COMPLETE Problem?\n\nQ3> An NP-HARD problem need not be in NP, so why is NP-Hard definition on NP ?\n\n\nEDIT :\n\nNot a duplicate of np-vs-np-complete-vs-np-hard-what-does-it-all-mean: \n\nI am asking something else here- like, are the reductions One-way, or both way possible ? And my 1st question on NP-Hard is building over what had been discussed there.\n    ", "Answer": "\r\nNo, reductions are one-way, not both-ways. If you can solve problem A using a solution to problem B, this does not always mean that you can solve problem B using a solution to problem A.\n\nThis is very well illustrated by your first question,\n\n\n  Q1. So are all NP-COMPLETE problems polynomial time reducible to an NP\n  Problem?\n\n\nDefinitely not, unless P=NP. Note that even P problems are NP (you do not need any certificate to check the answer for P problems), but you can not reduce an NP-complete problem to a P problem unless P=NP (if a NP-complete problem is reduced to a P-problem, this immediately means that P=NP).\n\nNote that it all stands only unless P=NP. If it turns out that P=NP, than it is easy to see that any NP problem can be reduced to any other NP problem.\n\nBTW, your questions are not quite clear when you say \"...polynomial time reducible to an NP Problem\". Do you mean any NP-problem or at least one NP-problem? If you mean any, my answer above stands. If you mean \"are all NP-COMPLETE problems polynomial time reducible to at least one NP Problem?\", that the answer is yes, definitely: every problem can be reduced to itself.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Have you ever had a business requirement that turned out to be an NP-Complete problem?\r\n                \r\nNP-completeness seems to me like one of those things that's mostly just theoretical and not really something you'd run into in a normal work environment.  \n\nSo I'm kind of curious if anyone's ever run into a problem at their job that turned out to be NP-complete, and that the design needed to be changed to accommodate for it?\n    ", "Answer": "\r\nAs the others have stated, the knapsack (for packing cargo) and traveling salesmen problem are probably the most common \"real world\" NP-complete problems.\n\nI tend to run into problems at work that can't be proven to be NP complete or incomplete because they're not very well defined.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If X is NP-complete and Y is in NP, why Y must also be NP-complete\r\n                \r\nSuppose X and Y are decision problems for which X≤ P ​ Y, i.e., X is polynomial-time reducible to Y . If X is NP-complete and Y is in NP, why Y must also be NP-complete.\n    ", "Answer": "\r\nIf X is NP complete, in particular it is NP hard, that is, every NP problem Z is polynomial-time reducible to X, which in turn is polynomial-time reducible to Y, thus Y is also NP hard. Being both NP and NP hard means you're NP complete, therefore Y is NP complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proving NP-Completeness of a problem\r\n                \r\nWe are given a set A = {a1,a2,...,an}\n\nGiven subsets of A named B1,B2, ..., Bm. If a subset of A named H has intersection with all given B's, we call H \"Covering subset\". Is there any \"covering subset\" of size K (cardinality of H is K) for given A and Bs?  Prove that this problem is NP-Complete. \n\nWe should reduce some known problem to \"covering subset\" problem.\n    ", "Answer": "\r\nupdate  This is called a hitting set. You can read the same answer in wikipedia article.  \n\nThis problem is, in a way, dual to set cover problem.  \n\nWe'll change some terminology. Let ```\n{B1, B2, ...}```\n be elements and ```\n{a1, a2, ...}```\n be sets. 'Set' ```\nai```\n contains 'element' ```\nBj```\n in a new problem if set ```\nBj```\n contains ```\nai```\n in original problem.  \n\nNow, you just need to select minimum number of 'sets' ```\nai```\n covering all 'elements' ```\nBj```\n. And that problem is NP-complete, as shown in the link above.\n\nTo clarify the transformation, one problem definition can be produced from another just by replacing set/element and contains/contained. Compare following  \n\nEvery set ```\nBj```\n contains some selected element ```\nai```\n\nEvery 'element' ```\nBj```\n is contained by some selected 'set' ```\nai```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-complete vs NP-hard (why are they unequal?)\r\n                \r\nWhy is NP-hard unequal to NP-complete?\n\nMy informal understanding of definitions being used:\n\nNP - all problems that can be verified in polynomial time\n\nNP-complete - all problems that are NP and NP-hard\n\nNP-hard - at least as hard as the hardest problem in NP\n\nDecision Problem - A problem that asks a question with regards to an input and outputs a bool value\n\nConfusion:\n\nThe problem with unknown solution of P vs NP arises from the fact that we cannot prove or disprove all problems in NP can be solved in polynomial time. It feels like a similar question arises from NP-complete vs NP-hard. How do we know all problems in NP-hard cannot be verified in polynomial time and thus result in NP-hard=NP-complete?\n\nHere is my line of reasoning \n\nFrom online research the distinction seems that this has something to do with decision problems (a concept I'm entirely new to but seem simple enough). I think this means that problems in NP have complementary decision problems that ask if an input is the solution to the problem. Let's say the problem is to find an optimal solution. I believe the complementary decision problem to be \"is the given input the optimal solution?\"and I believe that if this decision problem is verifiable in polynomial time then the problem is NP-complete (or in NP). So this means that NP-hard problems that aren't NP-complete problems are those that either have no decision problem (which I believe is never true since any brute force solution can answer this) or a problem is NP-hard and not NP-complete if it has a decision problem that's not verifiable in polynomial time. If it is the latter then it feels like we have the same problem from P vs NP. That is, how do we confirm all decision problems in NP-hard do not have polynomial time solutions?\n\nSorry if the above phrasing is weird. I will try and clarify any confusion in my question.\n\nnotes\n\nI am interested in both an intuitive explanation and a formal explanation (a proof if it's a complicated answer). The formal explanation can certainly be a link to an academic paper. I don't want anyone to invest a significant amount of time into an overly complicated proof that may be beyond the scope of my understanding (I've found complexity theory to become very quickly... complex).\n\nIf it helps for the sake of explanation I have done work on the traveling salesman problem and I am currently working on a paper for the nurse scheduling problem (I believe these are NP-hard problems).\n    ", "Answer": "\r\nNP-Hard includes all problems whose solutions can be used to derive solutions to problems in NP with polynomial overhead.\n\nThis includes lots of problems that aren't in NP. For instance, the halting problem - an undecidable problem - is NP-Hard, because any problem in NP can be reduced to it in polynomial time:\n\n\nReduce any problem in NP to an instance of the NP-Complete problem 3-SAT\nConstruct in polynomial time a TM which checks all assignments and halts iff a satisfying assignment is found.\nUse a solution to the halting problem to tell whether the TM halts.\nIf it halts, accept; otherwise, reject.\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Prove specific decision problem is NP-complete\r\n                \r\n\nGiven: graph G\nInput: k\nReturn: \"YES\" if there exists a set of k nodes, such that no two nodes are connected and no two nodes are connected to the same node. For example if (A,B) and (B,C) then A and C are not allowed in the set of k nodes.\nHow would we prove this problem is NP-complete?\n\n\nEDIT: I imagine we could use Independent Set/Vertex Cover?\n    ", "Answer": "\r\nI'm assuming (?) this is a homework problem.\n\nAs a hint, start with the dominating set problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Would an exponential lower bound on an NP-complete language prove P does not equal NP?\r\n                \r\nIf someone were able to prove an exponential lower bound for a NP-complete problem, would that prove that P ≠ NP?\n    ", "Answer": "\r\nYes, that would prove that P is not equal to NP. All polynomials are bounded from above by any exponential function, so an exponential lower bound on any NP problem would prove that the problem is not in P, and thus would prove that P cannot equal NP.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is MAX 3 SAT NP-complete or co-NP-complete? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 8 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI'm seeing a lot conflicting info about this problem. With some saying sites it is NP-complete and others saying that it is co-NP-complete. The only real consistent info I can find is that is definitely NP-hard. Which is it? And why?\n    ", "Answer": "\r\nI think this depends on how you define MAX-3SAT.\n\nIf you define MAX-3SAT as the function problem \"given a 3CNF formula, produce a variable assignment maximizing the number of satisfied clauses,\" then it's neither NP-complete nor co-NP-complete. NP and co-NP are classes of decision problems and therefore no function problem can belong to them. Therefore, MAX-3SAT can't belong to NP or co-NP, so it can't be a complete problem for either class. This function problem is NP-hard via a reduction from vanilla 3SAT - if you could find the maximally satisfying assignment, you could check if the original formula was satisfiable by seeing if all clauses were satisfied.\n\nYou could also define MAX-3SAT as the decision problem \"given a 3CNF formula and a number n, determine whether there's a variable assignment to the formula that makes at least n clauses true.\" This is definitely in NP and also NP-complete via a reduction from 3SAT.\n\nOn the other hand, if you define MAX-3SAT as the decision problem \"given a 3CNF formula and a variable assignment to that formula, is that assignment the one that maximizes the number of satisfied clauses?,\" then it would belong to co-NP (if the answer is no, you could confirm this by exhibiting a better satisfying assignment). I'm not sure if it would be NP-hard, though, and I'm also not sure whether it's co-NP-hard either.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If P = NP, why does P = NP = NP-Complete? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 8 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nIf ```\nP = NP```\n, why does ```\nP = NP```\n also then equal ```\nNP-Complete```\n?\n\nI.e. Why would it then be the case that ```\nP = NP = NP-Complete```\n?\n\nAssuming ```\nP != NP```\n , there were problems in NP not in NP - Complete.\nWhen ```\nP = NP```\n, all NP problems are actually now P.\n\nShouldn't there still be ```\nP = NP```\n problems not in ```\nNP - Complete```\n?\n\n\n    ", "Answer": "\r\nfor future reference, no code = does not belong in stackoverflow...\n\nas for your answer, http://en.wikipedia.org/wiki/NP-complete provides a full explanation. In 'layman' terms, all NP problems can be converted to an NP-C problem with a polynomial converter. that means that if P=NP, all of NP can be converted to NP-C which by definition can be converted to another NP-C etc. so P=NP=NP-C.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If A is NP-complete and if there is a reduction from A to B, does it imply that B is also NP-complete? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nSuppose that A, B, and C are decision problems. Suppose also that A is polynomial-time reducible to B and that B is polynomial-time reducible to C. If both A and C are NP-complete, then does it imply that B is also NP-complete? \n\nI know that, if A is NP-complete and it is polynomial-time reducible to B, then B is NP-hard. However, in order for a problem to be NP-complete, it must meet (1) it's in NP, and (2) it's NP-hard.\n\nI have no idea how to prove the first requirement of NP-complete.\n    ", "Answer": "\r\nIf A is NP-complete and it is polynomial time reducible to B, then B is NP-hard.\n\nIf B is polynomial time reducible to C and C is NP-complete, then B is in NP.\n\nA problem in NP which is in NP-hard is NP-complete.\n\nAnother way to show B is NP-complete is to notice that any two NP-complete problems (e.g A and C) are polynomially reducible to each other, and thus B is equivalent (two-way polynomially reducible) to any NP-complete problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why do we get to pick the source in an NP-completeness reduction?\r\n                \r\nWe know that to prove that problem A is NP-complete, we have to \nfind a polynomial time reduction from NP-complete problem B to this problem A.\n\nFor example, we can do these reductions:\n\n```\n SAT ---> clique\n SAT ---> independent set\n Independent set ---> Vertex Cover\n```\n\n\nWhy is it that we get to choose which NP-complete problem we use as the source of the reduction? Are all NP-complete problems reducible to each other, and we just need to choose the one that is easier to show the reduction?\n\nI mean it was easy to show the reduction from SAT to clique. However, I don't know how to show the reduction from SAT to Vertex Cover, but I know how to reduce from Independent Set to Vertex Cover. Is it in principle possible reduce each NP-Complete to every other NP-Complete, but we just use the easiest one?\n    ", "Answer": "\r\nA problem is NP-complete if\n\n\nit's in NP, and\nevery problem in NP is polynomial-time reducible to it.\n\n\nThis means that if you take any two NP-complete problems, you're guaranteed that they're polynomial-time reducible to one another, even if you don't know precisely what that reduction is going to look like.\n\nYou asked why you get to pick which NP-complete problem to use as the source of a reduction when proving NP-completeness. The reason is that once you've shown that some NP-complete problem A reduces to an NP problem B, you can conclude that every NP-complete problem C reduces to B, since C reduces to A and A reduces to B. In other words, if you prove that a problem is NP-complete by reducing any known NP-complete problem to it, you could have in principle reduced every NP-complete problem to it. You're just keeping things easy by reducing from a problem that makes the reduction easiest to do.\n\nIt can be pretty tough in practice to do a reduction if you pick the wrong NP-complete language as your source. To get a sense of why this is, think about how the proof of Cook-Levin theorem (that SAT is NP-complete) works. To show that you can reduce any NP problem to SAT, you start with a polynomial-time, nondeterministic Turing machine for that problem, then use that to construct a massive propositional formula that basically says \"there is some computation of this TM that accepts its input string.\" This is great in theory, but in practice this is a horrid reduction that would be almost utterly incomprehensible to anyone who looked at it. Any time you're proving NP-completeness of a problem by doing a reduction from a known NP-complete problem, think of it as finding a shortcut to skip a really tough proof - if you can find something nice and simple, you're skipping a behemoth of a reduction.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Can it be proven no polynomial algorithm exists for an NP-Complete prob.?\r\n                \r\nI can't really seem to grasp what it really means to say a problem is NP-Complete. Could anyone help me with the following question?\n\nAn NP-complete problem is a problem for which one can prove that an algorithm for solving it in polynomial time does not exist. Is the statement true?\n\nI would want to say this statement isn't true, because can anyone actually prove that such an algorithm doesn't exist for any NP-Complete problem? From looking around on various sources, I understand that no polynomial time algorithm is known for any NP-Complete problem; however, it can't be proven.\n\nAny help would be greatly appreciated. Thanks.\n    ", "Answer": "\r\nIt is possible in some situations to prove that no algorithm exists that is better than a certain limit.\n\nFor example the ```\nO(n log n)```\n bound for a comparison sort has been proven. No matter how clever we become in the future, we can be sure that no-one will ever invent an ```\nO(n)```\n comparison sort.\n\nIn this case though, no-one has found a proof. But that doesn't mean it can't be proven. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is GAP (graph accessibility) NP-Complete?\r\n                \r\nIs the GAP (graph accessibility problem) NP-Complete ?\nIt has polynomial and non-deterministic polynomial algorithms that solve it, but I don't think this is a criteria that overrides the basic way of showing it's NP-Complete, by showing it is NP and NP-Hard => NP-Complete.\nI heard both versions from older students than me.\nSo in the end, is it or not NP-Complete?\n    ", "Answer": "\r\nWikipedia says that the problem is ```\nNL-Complete```\n, which means that it’s also in ```\nP```\n. This makes it extremely unlikely that it is ```\nNP-Complete```\n. If it was, that would prove that P=NP, which is a very old and unsolved question. And it is widely assumed that ```\nP≠NP```\n.\n\nYou won’t be able to prove that it is not ```\nNP-Complete```\n either, because that would prove ```\nP≠NP```\n. \n\nIf you can prove that it is ```\nNP-Complete```\n or that it is not ```\nNP-Complete```\n, you will recieve an award of one million dollars.\n\nSo in summary the answer is: It seems very unlikely, but it is just as unlikely that you can prove anything in that direction :).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-complete to determine vertex cover\r\n                \r\nIs it right that \"it is NP-complete to determine if a graph contains a vertex cover of size 99\"???\n\nand\n\nis it right that \" it takes linear time to determine if a graph contains a vertex cover of size 99\"???\n\nOne more, is it right to say that \" No NP-complete problem can be solved in polynomial time unless the VERTEX COVER problem admits a polynomial-time algorithm.\"???\n    ", "Answer": "\r\n\"is it NP-complete to determine if a graph contains a vertex cover of size 99\"\n\nPedantically: no.\n\nThis problem can be solved in polynomial time.  However, the following algorithm is completely useless in practice.\n\nThe approach for a graph with n vertices is simply to test all C(n,99) possible choices of vertex cover.  For each choice, we test all edges (at most n*(n-1) edges in the graph) to see if either of their vertices are included.\n\nThere are fewer than ```\nn^99```\n ways of choosing the vertex cover, so overall this algorithm has polynomial complexity of ```\nn^101```\n. \n\nAs noted by j_random_hacker, this answer assumes that the vertex size of 99 is a known constant.  If the 99 is meant to be a variable and is part of the input, then the problem become the standard NP-complete vertex cover problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-complete, no efficient algorithm?\r\n                \r\nI don't know much about NP-complete but read about it here and there. The book Introduction to Algorithm, I'm studying(by myself) states \"Although no efficient algorithm for an NP-complete problem has ever been found, nobody has ever proven that an efficient algorithm for one cannot exist.\" I'm just wondering, how does one know that the algorithm they have is not the most efficient...if that's the efficient one out of all set of algorithms?\n\nThanks,\n\nSam\n    ", "Answer": "\r\nGreat question. I'm curious what the answers will be to this question, but here's my try.\n\nIt's surprisingly difficult to know if a better algorithm exists then the one you come up with (if you did know that, then your algorithm would be the better one). The question then becomes when should you stop trying to look for a better algorithm. The primary approaches involve coming up with lower bounds for the problem, and then successively making them stronger and stronger.\n\nImagine you're a researcher\n\nA good start to further investigating this problem is to think about the standard comparison based sorting problem. We are given a list of n elements and want to sort it. So the worst algorithm, is come up with all n! lists, and check which is sorted. Then a more intuitive approach is to use something like bubble sort, which is O(n^2). We wonder if we can still do better though. Well say we use divide and conquer and we come up with merge sort which is O(n log n). Now we are interested in knowing if merge sort is NOT the most efficient. So we spend more time thinking of an even better algorithm, but cannot come up with one. So we get frustrated, and switch our approach and think about proving that there cannot be a comparison sort better than O(n log n).\n\nNow intuitively, a naive lower bound is O(n), simply because in order to sort the list, we at least need O(n) time to read it. But, let us try to improve this lower bound. See if you can come up with the lower bound improvement to O(n log n) if you haven't seen it before. If you can't get it check out this great article that proves that n log n is a lower bound for comparison sorts: http://www.cs.uiuc.edu/~jeffe/teaching/algorithms/notes/19-lowerbounds.pdf\n\nNow let us start thinking about NP Complete problems. Consider vertex cover problem (does there exist a set of k vertices in a graph s.t. each edge is incident to at least one vertex) which is NP Complete. We come up with the most intuitive brute force method for solving it (making all (n choose k) vertex choices and test each possible solution). Now the question is, does something more efficient exist? Well, after much effort, suppose we cannot come up with anything faster. So we take the same approach as before of trying to find good lower bounds and successively improving them. clearly O(n) is one lower bound, but we cannot prove a O(n choose k) time lower bound (if we did prove such a lower bound, then that brute force is the best way to solve vertex cover). So we take a break, and work on other problems.\n\nThen one day we are working on the max independent set problem on graphs (does there exist a set S of k vertices such that no two vertices in S are adjacent). We come up with a brute force solution, but we want to know if this is NOT the most efficient algorithm. However we cannot come up with something better and we can't come up with a tight lower bound, so we cannot say if something faster exists.\n\nThen many days later we see that these problems are actually equivalent, in the sense that an efficient algorithm for one gives an efficient algorithm for the other: http://www.cs.cmu.edu/~ckingsf/bioinfo-lectures/npcomplete.pdf\n\nSo although we don't know if the algorithm we have for vertex cover or independent set is the most efficient, we can compare relative degrees of hardness by reducing problems to one another, so that if we find a good algorithm for one we can apply that to the other problem.\n\nTL;DR\n\nEssentially it boils down to the Feynmann approach:\n\n\n\nIn all seriousness, in order to show that our algorithm is or is not the best one:\n\n\nFind a better algorithm or prove its existence (possibly by reduction to another problem you have seen)\nProve that a better algorithm cannot exist. Possibly by finding Lower Bounds that our algorithm realizes.\n\n\nIf the above two fail, rather then answering definitively, try to come up with a notion of how difficult the problem you are working on is by looking at problems which you can reduce to and thinking about their hardness.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is a reduction enough for proving NP-complete or do I need a transformation?\r\n                \r\nIf I have a decision problem A, and wish to show that it is NP-complete.  Is it enough to prove that another NP-complete problem polynomially reduces to A, or must I show that another NP-complete problem polynomially transforms to A? \n\nThat is, can I show that\n\n```\nprocedure solve_SAT\n...\ncall solve_A\ncall solve_A\ncall solve_A\n...\nend\n```\n\n\nor am I only limited to a single use of solve_A, as shown\n\n```\nprocedure solve_SAT\ninput  = ...\nresult = call solve_A(input)\nreturn result\nend\n```\n\n\nI find some sources say the former while other sources say the latter, and it is a bit confusing to me.\n    ", "Answer": "\r\nSuppose you have a decision problem A and you wish to prove that it is NP-Complete then the way to do it is, take an existing NP-Complete problem and reduce it to A.\nWhat I mean by reduction here is a polynomial time reduction.\n\nSo suppose you wanted to show that 3-SAT is NP-Complete then you can show a reduction from the SAT problem.\n\nThe important thing to note here is that the reduction must be poly-time. It doesn't matter whether you call solve_A() multiple times. You can choose to call solve_A() multiple times as long as you make a polynomial number of calls to solve_A().\n\nWhy does it work? You can prove it by contradiction.\nSuppose you had a poly-time algorithm for 3SAT. Then you could solve SAT also in poly-time. Since a polynomial number of calls to a polynomial function is still polynomial. \nSo unless P=NP, this would imply that SAT can also be solved in polynomial time using the newly discovered poly-time algorithm for 3SAT. But we know that SAT is NP-Complete, hence 3SAT must also be NP-Complete.\n\nIn short, to show NP-Completeness two things are required.\n\nExistence of a certificate.\nA reduction from an existing NP-Complete problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "To prove something is NP-hard, why do you need to reduce to it from an NP-complete?\r\n                \r\nFrom wikipedia: \n\n\n  A problem H is NP-hard if and only if there is an NP-complete problem L that is polynomial time Turing-reducible to H (i.e., L ≤ TH).\n\n\nWhy does the problem(call it W) being reduced from need to be NP-complete? Why can't it just also be NP-hard? It seems like what you care about W being \"hard\" not that its in NP.\n\nThoughts? \n    ", "Answer": "\r\nIt can. In fact, your second paragraph implies the first paragraph.\n\nAssume NP-hard problem H is polynomially reducible to problem X. By definition, there exists an NP-complete problem C that is polynomially reducible to H.  Since both reductions are polynomial, you can reduce C to X in polynomial time.  Therefore, NP-complete problem C is reducible to X in polynomial time. Therefore problem X is NP-hard.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "np-completeness in the bounded degree spanning tree\r\n                \r\nI understand why the Bounded Degree Spanning Tree is considered NP Complete with a degree or 2 (it is an instance of the Hamiltonian Path Problem), but I do not understand why this applies to degrees > 2. If someone could please explain why this is an NP Complete problem for degree > 2, It would be most helpful\n    ", "Answer": "\r\nWell, I think that you can make a simple reduction from the instance of bounded by 2, to the instance of General k.\n\nIntuitivly, we will connect to each node of the original graph new k-2 nodes. Therefore every spanning tree will have to contain the k-2 edges from the original node to the new nodes that we connected to him, and a spanning tree from degree at most k exists if there is a spanning tree of degree at most 2 for the original graph.\n\nThe formal reduction will be:\n\nF(V,E)=(V',E'), when : V'={(v,i)|v is in the original graph, 0 < i < k+1), E' = E U {((v,0),(v,i))}, and I don't write a formal proof for the correctness because after all we are not in a math forum.\n\nGood luck and hope that it helped :)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proof that the halting problem is NP-hard?\r\n                \r\nIn this answer to a question about the definitions of NP, NP-hard, and NP-complete, Jason makes the claim that\n\n\n  The halting problem is the classic NP-hard problem. This is the problem that given a program P and input I, will it halt? This is a decision problem but it is not in NP. It is clear that any NP-complete problem can be reduced to this one.\n\n\nWhile I agree that the halting problem is intuitively a much \"harder\" problem than anything in NP, I honestly cannot come up with a formal, mathematical proof that the halting problem is NP-hard.  In particular, I cannot seem to find a polynomial-time many-to-one mapping from instances of every problem in NP (or at least, any known NP-complete problem) onto the halting problem.\n\nIs there a straightforward proof that the halting problem is NP-hard?\n    ", "Answer": "\r\nWe begin by noting that all NP-complete problems are reducible to 3SAT. Now we have a Turing machine that iterates over all possible assignments, and if a satisfying assignment is not found then it runs forever. This machine halts if and only if the 3SAT instance is satisfiable.\n\nCompleting the proof - we can, in polynomial time, reduce any instance of an NP-complete problem to 3SAT.  From there, we can reduce this problem to an instance of the halting problem by pairing the input with a description of the Turing machine described above (which has constant size).  This pairing can be done in polynomial time, because the Turing machine has only constant size.  Then, the original NP-complete problem has answer \"yes\" iff 3SAT instance is satisfiable iff the Turing machine halts on the given input.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Obtaining all possible states of an object for a NP-Complete(?) problem in Python\r\n                \r\nNot sure that the example (nor the actual usecase) qualifies as NP-Complete, but I'm wondering about the most Pythonic way to do the below assuming that this was the algorithm available.\n\nSay you have :\n\n```\nclass Person:\n  def __init__(self):\n    self.status='unknown'\n  def set(self,value):\n    if value:\n      self.status='happy'\n    else :\n      self.status='sad'\n  ... blah . Maybe it's got their names or where they live or whatev.\n```\n\n\nand some operation that requires a group of Persons. (The key value is here whether the Person is happy or sad.)\n\nHence, given PersonA, PersonB, PersonC, PersonD - I'd like to end up a list of the possible 2**4 combinations of sad and happy Persons. i.e.\n\n```\n[\n[ PersonA.set(true), PersonB.set(true), PersonC.set(true), PersonD.set(true)], \n[ PersonA.set(true), PersonB.set(true), PersonC.set(true), PersonD.set(false)], \n[ PersonA.set(true), PersonB.set(true), PersonC.set(false), PersonD.set(true)], \n[ PersonA.set(true), PersonB.set(true), PersonC.set(false), PersonD.set(false)], \netc..\n```\n\n\nIs there a good Pythonic way of doing this? I was thinking about list comprehensions (and modifying the object so that you could call it and get returned two objects, true and false), but the comprehension formats I've seen would require me to know the number of Persons in advance. I'd like to do this independent of the number of persons.\n\nEDIT : Assume that whatever that operation that I was going to run on this is part of a larger problem set - we need to test out all values of Person for a given set in order to solve our problem. (i.e. I know this doesn't look NP-complete right now =) ) \nany ideas?\n\nThanks!\n    ", "Answer": "\r\nI think this could do it:\n\n```\nl = list()\nfor i in xrange(2 ** n):\n    # create the list of n people\n    sublist = [None] * n\n    for j in xrange(n):\n        sublist[j] = Person()\n        sublist[j].set(i & (1 << j))\n    l.append(sublist)\n```\n\n\nNote that if you wrote ```\nPerson```\n so that its constructor accepted the value, or such that the ```\nset```\n method returned the person itself (but that's a little weird in Python), you could use a list comprehension. With the constructor way:\n\n```\nl = [ [Person(i & (1 << j)) for j in xrange(n)] for i in xrange(2 ** n)]\n```\n\n\nThe runtime of the solution is ```\nO(n 2**n)```\n as you can tell by looking at the loops, but it's not really a \"problem\" (i.e. a question with a yes/no answer) so you can't really call it NP-complete. See What is an NP-complete in computer science? for more information on that front.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why is TSP NP-hard while the Hamiltonian path NP-complete?\r\n                \r\nWhy aren't these 2 problems, namely TSP and Hamiltonian path problem, both NP-complete?\n\nThey seem identical.\n    ", "Answer": "\r\nFor a problem X to be NP-complete, it has to satisfy:\n\n\nX is in NP, given a solution to X, the solution can be verified in polynomial time.\nX is in NP-hard, that is, every NP problem is reduceable to it in polynomial time (you can do this through a reduction from a known NP-hard problem (e.g. Hamiltonian Path)).\n\n\nThere are two versions of the The Travelling Salesman Problem (TSP):\n\n\nThe optimization version (probably the one you are looking at), namely, find the optimum solution to the TSP. This is not a decision problem, and hence cannot be in NP, but it is however in NP-hard which can be proven via a Hamiltonian Path reduction. Therefore this isn't an NP complete problem.\nThe decision version - given an integer K is there a path through every vertex in the graph of length < K? This is a decision (yes/no) problem, and a solution can be verified in polynomial time (just traverse the path and see if it touches every vertex) and so it is in NP, but it is also in NP-hard (by an identical proof as above). Since it satisfies both requirements for NP-completeness, it is an NP-complete problem.\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are there public key cryptography algorithms that are provably NP-hard to defeat? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is off-topic. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.\r\n                \r\n                    \r\n                        Closed 10 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nShould practical quantum computing become a reality, I am wondering if there are any public key cryptographic algorithms that are based on NP-complete problems, rather than integer factorization or discrete logarithms.\n\nEdit:\n\nPlease check out the \"Quantum computing in computational complexity theory\" section of\nthe wiki article on quantum computers.  It points out that the class of problems quantum computers can answer (BQP) is believed to be strictly easier than NP-complete. \n\nEdit 2:\n\n'Based on NP-complete' is a bad way of expressing what I'm interested in.\n\nWhat I intended to ask is for a Public Key encryption algorithm with the property that any method for breaking the encryption can also be used to break the underlying NP-complete problem.  This means breaking the encryption proves P=NP.\n    ", "Answer": "\r\nI am responding to this old thread because it is a very common and important question, and all of the answers here are inaccurate.\n\nThe short answer to the original question is an unequivocal \"NO\".  There are no known encryption schemes (let alone public-key ones) that are based on an NP-complete problem (and hence all of them, under polynomial-time reductions).  Some are \"closer\" that others, though, so let me elaborate.\n\nThere is a lot to clarify here, so let's start with the meaning of \"based on an NP-complete problem.\"  The generally agreed upon interpretation of this is: \"can be proven secure in a particular formal model, assuming that no polynomial-time algorithms exist for NP-complete problems\".  To be even more precise, we assume that no algorithm exists that always solves an NP-complete problem.  This is a very safe assumption, because that's a really hard thing for an algorithm to do - it's seemingly a lot easier to come up with an algorithm that solves random instances of the problem with good probability.\n\nNo encryption schemes have such a proof, though.  If you look at the literature, with very few exceptions (see below), the security theorems read like the following:\n\n\n  Theorem: This encryption scheme is provably secure, assuming that no\n  polynomial-time algorithm exists for\n  solving random instances of some problem X.\n\n\nNote the \"random instances\" part.  For a concrete example, we might assume that no polynomial-time algorithm exists for factoring the product of two random n-bit primes with some good probability.  This is very different (less safe) from assuming that no polynomial-time algorithm exists for always factoring all products of two random n-bit primes.\n\nThe \"random instances\" versus \"worst case instances\" issue is what is tripped up several responders above.  The McEliece-type encryption schemes are based on a very special random version of decoding linear codes - and not on the actual worst-case version which is NP-complete.\n\nPushing beyond this \"random instances\" issue has required some deep and beautiful research in theoretical computer science.  Starting with the work of Miklós Ajtai, we have found cryptographic algorithms where the security assumption is a \"worst case\" (safer) assumption instead of a random case one.  Unfortunately, the worst case assumptions are for problems that are not known to be NP complete, and some theoretical evidence suggests that we can't adapt them to use NP-complete problems.  For the interested, look up \"lattice based cryptography\".\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is there an algorithm to solve this problem efficiently? Is it NP-Complete?\r\n                \r\nI have two arrays.  One array represents items.  The other array represents customers with money.  I need to find if all items can be purchased.  An item can only be purchased by one person.  But multiple items can be purchased by a single customer.\nExample,\n```\nItems: [10, 20, 30]\nCustomers: [40, 20]\nYes. Customer 1 can purchase items 1 and 3.  Customer 2 can purchase item 2.\n\nItems: [10, 20]\nCustomers: [15, 15]\nNo. Customer 1 can purchase item 1, but Customer 2 cannot purchase item 2.\n```\n\nEdit: I think this may be np-complete since it seems like a variation of the bin packing problem.\n    ", "Answer": "\r\nYou can solve it by use of iteration over Knapsack problem with same value and weight  for each element.\n```\nLet E as elements\nLet V as item values for all elements\nLet M the number of Customers\nfor i = 0 to M\n   W = Customers[i]\n   Knapsack(E,V,W)\n   E = E - {funded elements for this W}  \n   i= i +1\nend for\n\nIf E is empty print YES\nelse print NO\n```\n\nIf Items has N element and Customers has M elements the time complexity for recursive method is M * O(2N). But you can use dynamic programming to solve it roughly in O(M * N * WM) Which WM is the average of customer budgets (in you first example 30). So you can solve it in polynomial time complexity.\nI provide you a dynamic programming sample to solve your problem in Java. This code may have bug and you can improve this code as well.\n```\nimport java.util.*;\n\nclass Main {\n\n    // A utility function that returns\n    // maximum of two integers\n    static int max(int a, int b)\n    {\n        return (a > b) ? a : b;\n    }\n  \n    static void knapSack(int W, ArrayList<Integer> wtArr, int n)\n    {\n        int i, w;\n        int K[][] = new int[n + 1][W + 1];\n        \n        int wt[] = wtArr.stream().mapToInt(ix -> ix).toArray();\n        int[] val = new int[n];\n        System.arraycopy(wt, 0, val, 0, n);\n\n\n        // Build table K[][] in bottom up manner\n        for (i = 0; i <= n; i++) {\n            for (w = 0; w <= W; w++) {\n                if (i == 0 || w == 0)\n                    K[i][w] = 0;\n                else if (wt[i - 1] <= w)\n                    K[i][w] = Math.max(val[i - 1] +\n                              K[i - 1][w - wt[i - 1]], K[i - 1][w]);\n                else\n                    K[i][w] = K[i - 1][w];\n            }\n        }\n \n        // stores the result of Knapsack\n        int res = K[n][W];\n        //System.out.println(\"\\nres = \"+res);\n \n        int j=0;\n        w = W;\n        for (i = n; i > 0 && res > 0; i--) {\n \n            // either the result comes from the top\n            // (K[i-1][w]) or from (val[i-1] + K[i-1]\n            // [w-wt[i-1]]) as in Knapsack table. If\n            // it comes from the latter one/ it means\n            // the item is included.\n            if (res == K[i - 1][w]) {\n                //System.out.print(wt[i - 1] + \"<< \");\n                continue;\n            }\n            else {\n \n                // This item is included.\n                System.out.print(wt[i - 1] + \" \");\n                wtArr.remove(i-1);\n                // Since this weight is included its\n                // value is deducted\n                res = res - val[i - 1];\n                w = w - wt[i - 1];\n            }\n        }\n        System.out.println(wtArr);\n    }\n    \n\n    // Driver code\n    public static void main(String args[])\n    {\n        ArrayList<Integer> wt = new ArrayList<Integer>();\n        wt.addAll(Arrays.asList(10, 20 , 30));\n        int cu[] = new int[] {40 , 20};\n        for (int i=0; i<cu.length; i++) {\n            int n = wt.size();\n            int W = cu[i];\n            \n            knapSack(W, wt, n);\n        }\n        \n        if(wt.size() > 0)\n            System.out.println(\"NO\");\n        else \n            System.out.println(\"YES\");\n        \n    }\n}\n```\n\nSee Java Online Demo for test by yourself.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proof of NP Completeness of set-partition problem\r\n                \r\nI have reduced subset sum problem to set partition problem but do not know whether it is correct and so I need your help.\nMY METHOD:\nIn subset sum problem we have to find a subset S1 of set S so that it sums to a number t and in set partition problem we need to find a subset X1 of set X such that summation of numbers in set X1 is half of that in X.\nSo let us take instance of subset sum problem where t = sum of numbers in X / 2. If we can solve the set partition problem than we solved the subset sum problem too. But we know that subset sum id NP Complete so subset sum problem is also NP Complete( I know how to prove it is NP).\nI am having doubt whether we can make a choice of t like that or not. Please help.\n    ", "Answer": "\r\nYour logic is sound, that is a valid reduction. \n\nWe know this is valid because the proof is for the known problem to the unknown problem. You need to prove that EVERY instance of the known problem can be reduced into SOME instance of the unknown problem. So putting restrictions on your unknown problem is perfectly acceptable. \n\nSome notes: Your description is not sufficient for a proper proof. You noted that you knew this but for any readers here: to prove a problem is NP-Complete, you first prove it is in NP, and then you prove it is NP-Hard. This question only addresses a small portion of what an NP-Hard proof should contain.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity measurement of NP-complete\r\n                \r\nFor example, the set-cover decision problem is known to be a NP-complete problem. The input of this problems is a universe U, a family S of subsets of U, and an integer k (). \n\nOne thing that I'm confused with is that if we let k=1, then obviously the problem can be solved in time |S|, by simply checking each element in S. More generally, when k is a constant, the problem can be solved in polynomial time of |S|. In such a way, the time complexity becomes exponentially high only when k also increases with |S|, like |S|/2, |S|/3...\n\nSo here're my questions:\n\n\nMy current understanding is that the time complexity measurement of a NP-complete problem is measured in terms of the WORST case. Can anybody please tell me if the understanding is right?\nI saw somebody proved that another problem is NP-hard by showing that a set-covering desicion problem with input ```\n<U,S,|U|/3>```\n can be reduced to that problem. I'm just wondering why did he only prove for ```\n<U,S,|U|/3>```\n, instead of ```\n<U,S,ARBITRARY k>```\n?? Is such a proof reliable?\n\n\nMany thanks!\n    ", "Answer": "\r\nTime complexity is measured as a function of the input instance size. The input instance size can be measured in bits. The input instance size increases as any of the inputs ```\nU```\n, ```\nS```\n, and ```\nk```\n increase. So the question that one is trying to answer is how much more time does it take to solve the problem of instance size for example ```\n2n```\n bits vs the problem of instance size ```\nn```\n. \n\nSo simply the size of the whole input instance has to increase and in this particular case it means increasing the size of ```\nU```\n and/or ```\nS```\n and/or ```\nk```\n. \n\nTo answer your two questions:\n\n\nYes, the worst case time complexity is used: you are looking for the hardest problem of input size ```\nn```\n and you correctly noticed that the problem (of the same size) probably becomes harder as you increase more parameters than just one.\nIt would be better to see the proof you are referring to but the thinking probably goes like: \n\n\n  I give a polynomial reduction of the set-covering decision problem instance of size ```\nn```\n to my problem's instance of size ```\nm```\n. If the size of the set-covering decision problem's input instance increases to ```\n2n```\n then the result of the reduction will be my problem's instance of size ```\n2m```\n because there is a direct correspondence between the input size of ```\nU```\n, ```\nS```\n, and ```\nk```\n and the input size of my problem.\n\n\nSo all set-covering decision problem instances of size ```\nn```\n map to my problem instances of size ```\nm```\n. Thus if I am looking for the hardest instance of the set-covering decision problem using this reduction I will find the hardest instance of my problem of size ```\nm```\n. \n\n\nEDIT\n\nFrom the proof in your linked paper:\n\n\n  Proof. We reduce an arbitrary 3-cover problem instance—in which we are\n  given a universe U, a family S of subsets of U, such that each subset\n  contains 3 elements, and we are asked whether we can (exactly) cover\n  all of U using |U|/3 elements of S—to a game with homogeneous\n  resources and schedules of size 3.\n\n\nAs you correctly say, they need to convert all instances of the set-cover problem to their problem. But they are using a reduction from a different problem: the Exact 3-cover problem that is proven to be NP-complete in \"Computers and intractability - MR Garey, DS Johnson, 1979\".\n\nThe Exact 3-Cover problem is like the set cover decision problem but with ```\n|U| = 3t```\n and ```\nS```\n is a set of 3-element subsets of ```\nU```\n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete Reduction for Subset Sum\r\n                \r\nI'm studying for a final exam and one of the practice problems given to us from a past exam is as follows:\n\n\n\nMy instinct says to reduce this problem to the Subset Sum problem. \n\nMy initial solution is:\n\nLet 'A' be the Subset Sum NP-Complete problem.\n\nLet 'B' be the Partition Problem that we are trying to prove is NP-Complete\n\n'A' takes an instance alpha that is: a set S and a value 'b'\n\n'B' takes an instance beta that is: a set S' and a k value for the decision\n\nWe want to polynomially reduce alpha to an instance beta\n\nI would take b from alpha, put it into the set S to make S', then set k = 0 making\nbeta equal to: S'=S union 'b', K = 0\n\nLet's assume 'B' can solve for this instance. Since it can, it produces an output using beta which was formed from alpha.\n\nSince 'B' can solve that instance, it means that 'A' is solvable in polynomial time, however we know this not to be true since 'A' is NP-Complete. We have a contradiction. Because of this contradiction, we know that 'B' is at least as 'hard' as 'A', therefore it too is NP complete. \n\nPlease let me know what's wrong with my solution or if it is valid.\n\nThanks\n    ", "Answer": "\r\nActually this problem is (minimizing difference) is NP-hard. The decision version (not to be confused with decision problem, which you are) is whether there exists a solution that partitions so that the difference is zero, which is a NP-complete problem.\n\nSee http://en.wikipedia.org/wiki/Partition_problem\n\nExcerpt from wiki page:\nThere is an optimization version of the partition problem, which is to partition the multiset S into two subsets S1, S2 such that the difference between the sum of elements in S1 and the sum of elements in S2 is minimized. The optimization version is NP-hard.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Relationship between NP-hard and undecidable problems\r\n                \r\nAm a bit confused about the relationship between undecidable problems and NP hard problems. Whether NP hard problems are a subset of undecidable problems, or are they just the same and equal, or is it that they are not comparable?\n\nFor me, I have been arguing with my friends that undecidable problems are a superset to the NP hard problems. There would exist some problems that are not in NP hard but are undecidable. But i am finding this argument to be weak and am confused a bit. Are there NP-complete problems that are undecidable.? is there any problem in NP hard which is decidable.??\n\nSome discussion would be of great help! Thanks!\n    ", "Answer": "\r\nUndecidable = unsolvable for some inputs.  No matter how much (finite) time you give your algorithm, it will always be wrong on some input.\n\nNP-hard ~= super-polynomial running time (assuming P != NP).  That's hand-wavy, but basically NP-hard means it is at least as hard as the hardest problem in NP.\n\nThere are certainly problems that are NP-hard which are not undecidable (= are decidable).  Any NP-complete problem would be one of them, say SAT.\n\nAre there undecidable problems which are not NP-hard?  I don't think so, but it isn't easy to rule it out - I don't see an obvious argument that there must be a reduction from SAT to all possible undecidable problems.  There could be some weird undecidable problems which aren't very useful.  But the standard undecidable problems (the halting problem, say) are NP-hard.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Simple reduction (NP completeness)\r\n                \r\nI'm looking for a means to prove that the bicriteria shortest path problem is np complete.\nThat is, given a graph with lengths and weights, I need to know if a there exists a path in the graph from s to t with total length <= L and weight <= W.\n\nI know that i must take an NP complete problem and reduce it to this one. We have at our disposal the following problems to choose from: 3-SAT, independent set, vertex cover, hamiltonian cycle, and 3-dimensional matching.\n\nAny ideas on which may be viable?\n\nthanks\n    ", "Answer": "\r\nDid you try Google?  3rd hit is:\n\nhttp://www.jstage.jst.go.jp/article/ieejeiss/128/3/128_416/_article\n\nThe article is pay-per-view, but the Google cache supplies the important bit upfront:\n\n\"Unfortunately, the multiobjective case ( including the bicriteria case) is NP-complete(3).\n\nand the reference points to:\n\n(3) M. Garey and D. Johnson : Computers, and Intractability : A Guide to the theory of NP-Completeness, New York: Freeman (1979)\n\nwhich is the standard reference for questions of this form.\n\nSo ... have you looked at Garey and Johnson?  I don't have a copy here to check, but it was my go-to when I did comps.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Question about NP-Completeness of the Independent Set Problem\r\n                \r\nI thought that, when proving that a problem P is NP-Complete, we were supposed to reduce a known NPC problem to P. But, looking at the solution to the Independent Set problem, it seems to not go this way.\n\nTo prove that Independent Set is NP-Complete, you take a graph G, find its inverse G', and then compute CLIQUE(G'). But, this is doing the other way around: it's taking a problem P I DON'T know if it's NPC and then reduces it to a know NPC problem.\n\nHere's an example of the solution.\n\nWhat am I missing here? Isn't this wrong, since it's doing it the other way around?\n    ", "Answer": "\r\nTo prove that P is NP-complete, we need to show two things:\n\n\nThat P exists in NP.\nThat there's a polytime reduction algorithm to reduce some NP-complete problem Q to P.\n\n\nIf we know that CLIQUE is in NPC, then we can easily prove that IS is in NPC.\n\n\nWe can verify IS trivially in polytime. Iterate vertices, ensure that each has an edge not in the candidate solution.\nWe now need to reduce CLIQUE to IS. Given a graph ```\nG```\n and an integer ```\nn```\n, for CLIQUE we want to check if there's a CLIQUE of size ```\nn```\n. Let ```\nH```\n be the inverse of ```\nG```\n. If you find an IS in ```\nH```\n of size ```\nn```\n, you have a CLIQUE of size ```\nn```\n in ```\nG```\n with the same vertices. We've reduced CLIQUE to IS.\n\n\nIf you were to reduce IS to CLIQUE, you wouldn't prove that either is in NPC unless you could reduce some other problem in NPC to IS. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Effect of number base when proving NP completeness of numerical problems\r\n                \r\nI am reading about NP completeness from the algorithm design book of tardos, In the section of proving subset sum is NP complete, it is written that -\nThe algorithm developed for subset sum has running time of O(nW). If an instance of 100 numbers is given, each of which is 100 bits long then the input is only 100 * 100 = 10000 digits, but W is roughly 2^100.\nI dont understand this claim, why is W 2^100 ? what is the effect of base on this problem, I mean if we change it to some other base x, would W be x^100 ? what if we change it into unary base ?\nthanks.\n    ", "Answer": "\r\nTo understand this you need to think about how the running time of the algorithm changes as the size of the numbers in the problem set grows.  I'm assuming that your textbook describes the usual dynamic programming attack on subset sum.  That algorithm's run time grows linearly with the width of the problem set.  (The problem set width is the sum of the positive numbers in the set minus the sum of the negative numbers.)  This width grows exponentially as you increase the size of the numbers in the set.  For example, if you use 101 bit numbers instead of 100 bit numbers, the width of the problem set doubles.  Move to 102 bit numbers and the problem set width doubles again.  And since the algorithm's run time grows linearly with the problem set width, that run time doubles each time as well.  This doubling is exponential growth in run time as the input size grows linearly, so this is not a polynomial-time algorithm.\n\nIf the numbers were written in a different base > 1, then yes, you would see exponential growth of the problem width in that base.  For example, in base 10 adding another digit makes the problem width ten times larger.  If you switch to unary, you lose the exponential growth in the problem set size, but instead the input size for any given problem is exponentially larger than it would be in bases > 1, so you gain nothing.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Deterministic solutions to Minimal Vertex cover problems - NP complete is fine\r\n                \r\nA vertex cover problem is to find a set ψ for an undirected graph G = (V, E) for ψ ∈ V such that if {u, v} ∈ E then either u ∈ ψ or v ∈ ψ or both. This Problem is defined and proved to be NP complete.\n\nAre there Deterministic Algorithms that can solve this problem? An exponential running time is acceptable but are there any better deterministic algorithms? I found a similar question and only one approach Using Binary search. I am not looking for approximate solutions which can be run in lesser time - as I understand the one listed in Chapter 35 of Cormen, Leiserson, Rivest, and Stein (CLRS) text is an Approximation Algorithm.\n    ", "Answer": "\r\nYou can use a search-tree for this problem. For every edge {v, w}, there are 3 options.\n\nv is included\nw is included\nboth are included.\n\nYou can also apply some pruning rules, like the following:\n\nIf a vertex v has degree 1, include the neighbour of v in the VC.\nIf for two neighbours v and w the neighbour-set of v is a subset of the neighbours of w, include w in the VC.\n\nBoth of these rules can be proven in the sense that the choice you make by these rules are at least as good as any other choice you could make for the considered edge.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Authentic List of NP, NP Complete and NP Hard problems\r\n                \r\nAfter wading through multiple sources, fol list has been prepared by me. But this seems confusing and overlapping. Pl validate or share a resource with authentic list:-\n```\n    NP Problems:\n1.  Hamiltonian Path Problem\n2.  Subset Sum Problem\n3.  Graph Isomorphism Problem\n4.  Boolean Satisfiability Problem (SAT)\n5.  Vertex Cover Problem\n6.  Knapsack Problem\n7.  3-SAT Problem\n8.  Clique Problem\n9.  Traveling Salesman Problem (TSP)\n10. Maximum Independent Set Problem\n\nNP-Complete Problems:\n1.  Boolean Satisfiability Problem (SAT)\n2.  Traveling Salesman Problem (TSP)\n3.  Knapsack Problem\n4.  Graph Coloring Problem\n5.  Hamiltonian Cycle Problem\n6.  Subset Sum Problem\n7.  3-SAT Problem\n8.  Steiner Tree Problem\n9.  Bin Packing Problem\n10. Vehicle Routing Problem\n\n NP-Hard Problems:\n1.  Halting Problem\n2.  Post Correspondence Problem\n3.  Knapsack Problem\n4.  Graph Coloring Problem\n5.  Hamiltonian Cycle Problem\n6.  Steiner Tree Problem\n7.  Bin Packing Problem\n8.  Vertex Cover Problem\n9.  Independent Set Problem\n10. Partition Problem\n```\n\n    ", "Answer": "\r\nBy definition, every NP-complete problem is also NP, and NP-hard. And many problems (but not all) in NP are NP-hard. So overlap is not only allowed, but also expected.\nFor example, the clique (decision) problem is NP-complete, meaning it is also NP and NP-hard, so it should be in all of your lists.\nHowever, that doesn't make your list of examples incorrect, unless you claim it to be a complete and exhaustive list of all problems in these categories. This would be impossible because there exists an infinite number of problems so you cannot list them.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Whats the difference between NP and co-NP\r\n                \r\nI know their complete counterparts mean that\nNP - complete is the hardest in the NP problems and co-NP-complete means the hardest in co-NP problems but whats the difference between the two? My textbook said \"The yes and no are reversed\" which doesn't leave that much of a clue to me. \n    ", "Answer": "\r\nWhen you want to prove the difficulty of a problem, you have to turn it into something called a decision problem, which means a \"yes/no\" answer type problem. For example, in Set Cover, we may ask \"can we cover all elements using only X subsets?\" where X is some arbitrary number. We can show that this problem exists in NP because a solution to it is easily verifiable; you provide the X subsets, and I check to see if all elements are covered in polynomial time. If we can answer efficiently answer \"yes\" to the decision problem, then we can minimize X and thus solve the entire Set Cover problem efficiently (thereby proving P=NP). \n\nCo-* (Co-NP, Co-NP-complete) focuses on answering \"no\" to the complemented decision problem. For example, the complemented decision problem of Set Cover would be \"For every combination of X subsets, is it impossible to cover all elements?\" Answering \"no\" to this question requires you to provide a counter-example.\n\nIn summary: NP is concerned with a \"yes\" answer to some decision problem. Co-NP is concerned with a \"no\" answer to the same, but complemented, decision problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Judge:Some N P -complete problems have polynomial time algorithms, but some others do not\r\n                \r\nHere is the context of the question:\nFor each of the following statements, indicate whether it is true, false, or unknown, where 'unknown' indicates that scientists have not conclusively determined whether the statement is true or false. For example, the correct answer for the statement P=NP is unknown. But the correct answer for the best algorithm for the maximum flow problem in n-vertex graphs takes time at least 2^n'' is ``false''.\nGive a short justification for your answer (i.e. explain why the\nstatement is true, or false, or not known to be either true or false).\nAnd here is the statement I am unsure:\nSome N P -complete problems have polynomial time algorithms, but some others do not..\nI came up with two solutions which I think both make sense to me:\nUnknown:If\nany NP-complete problem can be solved by a polynomial time algorithm, then all of them can\nbe by the reduction. So NP = P OR\nFalse: if some NP-complete algorithms have polynomial time\nalgorithms, we can reduce them to the NP-complete problems which don’t have polynomial\ntime algorithms, which means they have polynomial time algorithms as well.\nI wonder which is true.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is the board game \"Go\" NP complete?\r\n                \r\nThere are plenty of Chess AI's around, and evidently some are good enough to beat some of the world's greatest players.\n\nI've heard that many attempts have been made to write successful AI's for the board game Go, but so far nothing has been conceived beyond average amateur level.\n\nCould it be that the task of mathematically calculating the optimal move at any given time in Go is an NP-complete problem?\n    ", "Answer": "\r\nChess and Go are both EXPTIME complete.  IIRC, Go has more possible moves, so I think it a higher multiple of that complexity class than chess.  Wikipedia has a good article on the complexity of Go.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How do I prove a class-room scheduling issue to be NP complete correctly?\r\n                \r\nI am given a problem, that is about scheduling n classes in k rooms at a school, and it is a decision problem, because we want to ask if we can arrange these n classes in those k rooms so that a given timelimit t is not exceeded (the total time of classes in a certain scheduled way should not exceed t).\n\nI am aware about to firstly show that every solution to the problem can be verified in polynomial time, but when it comes to reducing some known NP complete problem to the class-room scheduling problem then I do not know which NP-complete problem I should take.\n\nI was thinking about using Traveling Salesman Problem to reduce, but I am not sure about how to interpret my class-room scheduling problem into a graph considering the symbolics. My first attempt to interpret my problem as a graph is to consider the classes as vertices, rooms as colours and the time for a class denoted by a weighted edge between two classes (the latter two interpretations completely unsure). But I don't know if this follows a standard pattern for some scheduling problem or I don't even know if Traveling Salesman Problem is a good NP-complete problem to reduce to the class-room scheduling problem. In the latter case, then I would like to know examples of more suitable NP-complete problems to reduce in my case.\n\nThanks in advance!\n    ", "Answer": "\r\nYou can use map-coloring (graph-coloring) for it. You just need to define rules for edges and nodes. Nodes will be classes, rooms will be colors and you connect classes that can't be in same time. This is actually k-coloring problem, where you need to color specific graph with k colors in order to minimize number of classes per color. However in this special case, you just need to have less or equal to t per color. You can achieve this by going by standard rule of coloring, and switch to new color as soon as it has t number of classes. \n\nThis is still a NP-complete problem. Only exception is when you have 1 or 2 classes, then its in polynomial time. When you have 1 room, you just need to check if ```\nn<=t```\n. When you have 2 rooms, you just need to check if it can be colored by 2 colors. You can achieve this by DFS (but first check if n <= 2t) and color odd steps with first color and even steps with second color. If it is possible to color all nodes with this tactic, you have a positive solution. When ```\nk>=3```\n, its NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What is the Big-O worst case running time for constraint satisfaction problems in general?\r\n                \r\nSince intractable constraint satisfaction problems in general are considered NP-complete problems, what is the Big-O worst case running time of NP-complete constraint satisfaction problems?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Confusion about why NP is contained in PSPACE, EXPTIME etc\r\n                \r\nHere's something that has puzzled me lately, and perhaps someone can explain what I'm missing. \n\nProblems in NP are those that can be solved on a NDTM in polynomial time. Now assuming P /= NP, PSPACE /= NP etc. this means that there are NP-complete problems that cannot be solved in polynomial time on a DTM. Which means that either they have some complexity that lies between polynomial and exponential (which I am not sure what that might be) or they must take exponential time on a DTM (and no more than polynomial space). If its the latter, then consider the PSPACE-complete problems. A problem is in PSPACE if it can be solved using a polynomial amount of space. Since NP \\subseteq PSPACE \\subseteq EXPTIME, PSPACE-complete problems must also take exponential time on a DTM. Then what is the practical difference between NP-complete and PSPACE-complete problems?\n    ", "Answer": "\r\nWell as far as I see it. The practical difference is the functionality of time.\nThe closer to the halting problem the longer the run....even if they equate.\nUnless provided with infinite time and space which wouldn't even be feasible let alone practical.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Does Reducing P or NP instance to NP-Complete make that instance also NP-Hard?\r\n                \r\nIf a Problem X lying in P or NP can be reduced to NP-Complete, is that problem X automatically an NP-Hard problem?\n    ", "Answer": "\r\nQuick reply: No, it does not.\n\nRecall the definition of NP-hard problems. \n\n\n  A problem X is NP-Hard if every problem in NP can be polynomially\n  reduced to X.\n\n\nIf on the other hand a problem X can be polynomially reduced to some NP-complete problem Y, it means that Y is at least as hard as X, not the other way around.\n\nFinally, if an NP-complete problem Z can be polynomially reduced to X, then indeed X is NP-hard as every problem W in NP can be reduced to Z and by combining the two reductions we can reduce W to X, so the definition is satisfied.\n\nQ: If a Problem X lying in P or NP can be reduced to NP-Complete, is that problem X automatically an NP-Hard problem?\n\nA: No\n\nQ: If a Problem X lying in P or NP is such that an NP-Complete problem can be reduced to it, is that problem X automatically an NP-Hard problem?\n\nA: Yes\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is the problem of finding the chromatic number of this modified interval graph NP-Complete?\r\n                \r\nFew days ago I was working on interval graphs to solve the known problem of resource allocation, as we know there is a greedy approach that solves this problem (chromatic number) in polynomial time and gives us the colors of each vertex in the interval graph (the problem of finding the chromatic number in general graphs is NP-Complete (3-satisfiability reduction by Karp)).\n\nI was wondering: if had a graph that is not an interval graph but it is because it has one and only one chordless cycle of length > 3 (there is an edge that, when you remove it, the graph becomes an interval graph), does it makes the problem of finding the chromatic number on this kind of graph NP-Complete?\n    ", "Answer": "\r\nKind of hand-wavey, if there's just a single edge which prevents the interval graph coloring algorithm from working, then remove it.  Run the interval graph algorithm.  If the two endpoints of the removed edge have different colors, you're done.  Otherwise, Let C be the number of colors that the algorithm used.  Try all (C choose 2) fixed colors for the two endpoints, and try the interval graph algorithm again.  If it succeeds with C colors, you're done.  Otherwise, you'll need C+1 colors so just pick one of the endpoints and give it a unique color.\n\nI'm assuming you can find the removable edge in poly time.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Please explain how the logic behind defining a new problem as NP-Complete is correct\r\n                \r\nThe logic used goes like this - we have an existing class of problems that are NP-Complete. Now a new problem \"Q\" comes up.\n\nStep 1 - We prove Q is in NP, well and good.\n\nStep 2 - We show that a problem in NP-C(say O) is reducible to Q. (O - > Q)\n\nNow we say that because O is NP-Hard, and because it is reducible to Q, Q must also be NP-hard since there is no simpler solution for O, and were Q a simpler solution, then we could just reduce O -> Q and solve Q.\n\nHowever, we don't know for sure yet that P!=NP. Maybe this new problem Q was the problem that could actually be solved in polynomial time, and that to solve each of the problems in NPC we only need to convert them to Q and then Q needs to be solved. If so, how is step 2 a valid proof for Q being NP-Hard?\n    ", "Answer": "\r\n```\nNP-hard```\n is a definition involving certain complexity classes, namely ```\nNP```\n and ```\nNP-complete```\n. The definitions do not refer to the complexity class ```\nP```\n. Poly-time reduction in itself does not refer to ```\nP```\n. Think of using a vocabulary from which the notion ```\nP```\n has been stripped.\n\nThe definitions and theorems thus remain valid when notion ```\nP```\n is introduced to the vocabulary. It may be the case that the notion ```\nP```\n is actually mathematically equivalent to the notion ```\nNP```\n. That still does not invalidate definitions and theorems phrased in terms of ```\nN```\n-notions, it would just open up a richer theory to discuss them.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "String to string correction problem np-completeness proof\r\n                \r\nI have this assignment to prove that this problem:\n\n\n  Finite alphabet £, two strings x,y €\n  £*, and a positive integer K.  Is\n  there a way to derive the string y\n  from the string x by a sequence  of K\n  or fewer operations of single symbol\n  deletion or adjacent symbol\n  interchange?\n\n\nis np-complete. I already figured out I have to make transformation from decision version of set covering problem, but I have no clue how to do this. Any help would be appreciated.\n    ", "Answer": "\r\nIt looks like modified Levenshtein distance. Problem can be solved with DP in quadratic time.\n\nTransformation from minimum set cover (MSC) to this string correction problem is described in:\n\n```\nRobert A. Wagner\nOn the complexity of the Extended String-to-String Correction Problem\n1975, Proceedings of seventh annual ACM symposium on Theory of computing \n```\n\n\nIn short with MSC problem:\n\nGiven finite sets x_1, ..., x_n, and integer L, does there exists a subset J of {1,...,n} such that |J| <= L, and\n\nunion_{j in J} x_j = union all x_i ?\n\nLet w = union all x_i, let t = |w| and r = t^2, and choose symbols Q, R, S not in w.\n\nTake strings:\n\n```\nA = Q^r R x_1 Q^r S^(r+1) ... Q^r R x_n Q^r S^(r+1)\nB = R Q^r ... R Q^r w S^(r+1) ... S^(r+1)   <- each ... is n times\nand\nk = (l+1)r - 1 + 2t(r+1)(n-1) + n(n-1)(r+1)^2/2 + (r*n + |x_1 ... x_n| - t)*W_d\n[W_d is delete operation weight, can be 1.]\n```\n\n\nIt is shown that string-string correction problems (A,B,k) is satisfiable iff source MSC problem is.\n\nFrom strings construction it is clear that proof is not trivial :-) But it isn't too complex to manage.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How is TSP NP-Hard?\r\n                \r\nI read the following in one of the answer on SO :\n\nThe Traveling Salesman Problem, as normally posed, is to find the cheapest route connecting all cities. That isn't a decision problem, and we can't verify any proposed solution directly. We can restate it as a decision problem: given a cost C, is there a route that's cheaper than C? This problem is NP-complete, and with a little work we can solve the original TSP about as easily as the modified, NP-complete, form. Therefore, the TSP is NP-hard, since it's at least as hard as an NP-complete problem.\n\nI understand that a TSP is NP-Complete but  how the problem is NP-Hard ? I read that problems that are in NP but not in P are NP-Hard. I cannot relate this thing to the TSP . Please explain this. \n    ", "Answer": "\r\nNP-Hard problems are those problems for which every problem in NP has a polynomial time (Cook or Karp, multiple definitions) reduction to. These could contain problems which are not in NP and in fact need not even contain decideable problems (like the Halting problem).\n\nNP-Complete problems are those problems in NP which are also NP-Hard.\n\nIf P is not equal to NP, then there are infinitely many problems in NP which are neither in P, nor NP-Complete (Ladner's theorem).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why does the formal procedure prove NP-Completeness? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI know how to show that a problem X is NP-Complete.\n\n\nShow that X ∈ NP.\nShow Y ≤p X: show a problem Y known to be NP-Complete can be reduced to X in polynomial time. \n\n\nHowever, I'm stuck on why this procedure proves that X is NP-Complete. Could someone explain this  in a relatively simple way?\n    ", "Answer": "\r\nNP Complete problem is defined to be a problem that is both NP-Hard and in NP (definition), so you basically need to show 2 things:\n\n\nThe problem is in NP (same as your 1)\nThe problem is NP-Hard\n\n\nYou can show (2) by 2 ways:\n\n\nProve directly that there is a reduction from every problem in NP to it (hard to do)\nShow a reduction from any known NP-Hard problem to your problem.\n\n\nThe thing is, reduction is transitive, so if you prove there is a reduction from some NP-Hard problem (let it be ```\nL1```\n) to your problem (Let it be ```\nL2```\n), you basically showed that there is a reduction from EVERY ```\nL```\n in NP to ```\nL1```\n (definition of NP-Hard), and from ```\nL1```\n to ```\nL2```\n (your reduction), thus the chain of these reductions (which is itself polynomial, neat things about polynoms), is a reduction by itself from every ```\nL```\n in NP to ```\nL2```\n (your problem).\n\nIn other words, since ```\nL <=p L1 <=p L2```\n for every ```\nL```\n, it follows that ```\nL <=p L2```\n for every ```\nL```\n as well, and this is the exact definition of NP-Hardness.\n\nThis way, you showed there is a reduction from every problem in NP to your problem, and this is the definition of NP-Hardness.\n\n\n\nSince showing directly that there is a reduction from EVERY ```\nL```\n in NP to a language, it was done once on SAT (Cook-Levin theorem) [twice actually...], and now you can use reductions to increase the number of known NP-Hard Problems.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Understanding Poly-time Reduction/NP-complete\r\n                \r\n\n\nHi there, I am having trouble understanding the relation of X and Y when problem X is reducible to Y. \n\nIn the question in the picture, I especially don't understand why a and b are not correct, if X is no harder than Y, then Y is at least as hard as X (?), then if X is NP-complete, wouldn't Y be at least NP-complete too?\n\nThank you\n\n(question source: https://introcs.cs.princeton.edu/java/55intractability/) \n    ", "Answer": "\r\nIt might help to reason by analogy here. Rather than thinking about problems and reducibility, let’s talk about people and how fast they run.\n\nLet’s define SO to be all the people who use Stack Overflow, and then define someone to be SO-fast if they can run at least as fast as anyone who uses Stack Overflow. We can then say that someone is SO-complete if they use Stack Overflow (they’re in SO) and also can run at least as fast as anyone on Stack Overflow (they’re SO-fast).\n\nNow, suppose that X can run no faster than Y and that Y is SO-complete. Does that mean that X is definitely SO-fast? Probably not. All we know that X can’t outrun someone who can run as fast as everyone on Stack Overflow. Maybe that means X can run just as fast as Y and is therefore also SO-fast, but it’s more likely that X isn’t nearly that fast. So, reasoning by analogy, do you see why option (a) is incorrect?\n\nNext, suppose X can run no faster than Y and that X is SO-complete. Does that mean that Y is SO-complete? The answer is no. I’m going to assume that Usain Bolt is not a Stack Overflow user, but I can guarantee you that Usain Bolt can outrun anyone on Stack Overflow. That means that Usain Bolt is SO-fast, but not SO-complete. Remember that SO-completeness has two components: you have to be fast, but you also have to be a Stack Overflow user. Knowing you can outrun the fastest Stack Overflow users says nothing about whether you yourself are on Stack Overflow. Does that account for why option (b) is incorrect?\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reduction from / to clique problem to prove problem is NP Complete\r\n                \r\nI've the following problem:\nGiven a set of males and a set of females, with rank between any two people equal to 0 or 1. Pick a subset of people such that:\n\n\nI want to maximize the number of liked people (total sum of all the ranks between any two people in the subset) over the total number people in the subset.\nIn the picked subset of people there must be an equal number of males and females.\n\n\nMy questions are: in order to show np-completeness of this problem I know clique problem reduction can be used... Does anyone can provide an example on how to carry out this reduction? Do I need a reduction FROM or TO clique problem? \nMany thanks \n    ", "Answer": "\r\nTo answer your question, you need a reduction FROM clique problem to the problem you are currently dealing with since clique is a known NP-complete problem.\n\nAs for your hints with your transformation process (from known Clique problem to your Ranking problem), a good way to think of this is how would you reduce the scenario of clique to your problem. I am assuming 1 means \"linked people\" and 0 means \"unliked people\" in your problem.\n\nTake each person as our vertex in graph G(assumed given graph in clique problem). To distinguish between male and female, we would mark male group as A1,A2,A3...Am, female group as B1,B2,B3...Bf. Now we can draw edges to each pair of people whose rank is 1 between them(liked people). Suppose N(N>=1) cliques formed after the graph is done. \n\nNow, we remove the vertices in each clique that makes the clique has unequal number of As and Bs(to provide equal number of vertices in both genders). Now the largest clique with number K is the one you will be looking for.\n\nThis transformation is supposed to be done in polynomial time since what we are doing is sheerly reconstructing our clique graph and labelling them(and removing them). It would be of O(V+E) to perform such transformation.\n\nLater, you will be required to prove the answers works both way between your problem's answer and the clique problem answer if you want to prove that your problem is NP-complete. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Question about nSudoku if we assume that it is NP-complete\r\n                \r\nExplain why each of the following statements is correct. You may assume that nSudoku is NP-complete.\nIf nSudoku can be reduced in polynomial time to factorization, then factorization is NP-complete.\nIf nSudoku can be reduced in polynomial time to the problem of sorting an integer array, then P = NP.\nAny ideas how to explain? Thank you!!!\n    ", "Answer": "\r\nIn order to determine if a problem (A) is NP-Complete, we must take four steps:\n\n\nProve that A is in NP\nTransform a known NP Complete problem (B) into A in polynomial time\nProve that an answer to A is an answer to B\nProve that an answer to B is an answer to A\n\n\nIn your problem, you start with the known NP-Complete problem nSudoku, with the goal to first show that factorization is also NP-Complete. To do this, we would first show that factorization is in NP. You then provide the information that nSudoku can be transformed to factorization in polynomial time. If we then show that an answer to nSudoku is an answer to factorization and vice versa, then we have proven that factorization is NP-Complete.\n\nWe will then follow this same pattern for factorization and the problem of sorting an integer array to prove that the problem of sorting an integer array is NP Complete (starting with the fact that factorization is in NP). This, however, complicates things, because the problem of sorting an integer array is actually in P, as you can sort an integer array in O(nlogn), which is polynomial time.\n\nAt the core of this question is the \"P versus NP problem\", which is an unsolved problem that asks whether every problem in NP is really in P (in other words if every problem that has a decision problem that can be verified in polynomial time can ALSO be solved in polynomial time). To this date, there is no answer to the problem.\n\nHowever, in your problem we prove that a problem that is known to be P is also NP complete, which then results in the conclusion stated in your problem that P=NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Np class of problems\r\n                \r\nAre All problems in NP are known to be reducible to one another.\nI know if a problem X is in NP and any NP problem Y in NP is reducible to X then X is NP-complete. So by this assumption can we state that all NP problems are reducible to one another?\n    ", "Answer": "\r\n```\nA decision problem C is NP-complete if:\n\nC is in NP, and\nEvery problem in NP is reducible to C in polynomial time. \n```\n\n\nSource: https://en.wikipedia.org/wiki/NP-completeness\n\nIf all NP problems are reducible to one another, it would mean that all NP problems are NP complete, which we can not say since we still can't prove whether ```\nP = NP```\n\nRefer to the image below for a better understanding.\n\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "proof NP-complete\r\n                \r\nHi guys I have a question. I am wondering if anyone know how to proof it.\nHere is the question:\nThe Subset Sum problem is shown to be NP-complete. The input is a sequence of positive numbers w1, ... ,wn, W, where W is the target weight. The problem is to decide whether there is a set of weights F ⊆ {1, ... ,n} such that the the sum of some weights equal to the target weight (i.e. w1 + ... + wi = W)\nLet the Restricted Subset Sum problem be defined like Subset Sum, but with the extra requirement that the target weight is less than half the sum of all weights. (If this fails then the input must be rejected right away.) Show that Restricted Subset Sum is NP-complete.\nThank you.  \n    ", "Answer": "\r\nYou have to show (a) your problem is in NP and (b) your problem is NP hard. For (a), show that a solution to some problem in NP would make solving your problem easy (if you think about it, showing this is trivial). For (b), you need to show that a solution to your problem would make solving any problem in NP easy (in other words, find another NP-complete problem whose solution can be rephrased in terms of a solution to your problem).\n\nThis is already practically half the proof - (a) is trivial now - I'd prefer not to do the rest.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Heuristics for this (probably) NP-complete puzzle game\r\n                \r\nI asked whether this problem was NP-complete on the Computer Science forum, but asking for programming heuristics seems better suited for this site. So here it goes.\n\nYou are given an NxN grid of unit squares and 2N binary strings of length N. The goal is to fill the grid with 0's and 1's so that each string appears once and only once in the grid, either horizontally (left to right) or vertically (top down). Or determine that no such solution exists. If N is not fixed I suspect this is an NP-complete problem. However are there any heuristics that can hopefully speed up the search to faster than brute force trying all ways to fill in the grid with N vertical strings?\n    ", "Answer": "\r\nI remember programming this for my friend that had the 5x5 physical version of this game, but I used brute force back then. I can only think of this heuristic:\n\nConsider a 4x4 map with these 8 strings (read each from left to right):\n\n```\n1 1 0 1\n1 0 0 1\n1 0 1 1\n1 0 1 0\n\n1 1 1 1\n1 0 0 0\n0 0 1 1\n1 1 1 0\n```\n\n\n(Note that this is already solved, since the second 4 is the first 4 transposed)\n\nFirst attempt:\n\nWe will choose columns from left to right. Since 7 of 8 strings start with ```\n1```\n, we will try to put the one with most ```\n1```\ns to the first column (so that we can lay rows more easily when columns are done).\n\nIn the second column, most string have 0, so you can also try putting a string with most zeros to the second row, and so on.\n\nThis i would call a wide-1 prediction, since it only looks at one column at a time\n\n(Possible) Improvement:\n\nYou can look at 2 columns at a time (a ```\nwide-2```\n prediction, if i may call it like that). In this case, from the 8 strings, the most common combination of first two bits is ```\n10```\n (5/8), so you would like to choose first two columns so the the combination ```\n10```\n occurring as much as possible (in this case, ```\n1111```\n followed by ```\n1000```\n has 3 of 4 ```\n10```\n at start).\n\n(Of course you don't have to stop at 2)\n\nWeaknesses:\n\n\nI don't know if this would work. I just made it up and thought it might work.\nIf you choose to he ```\nwide-X```\n prediction, the number of possibilities is exponential with ```\nX```\n\nThis can absolutely fail if the distribution of combinations if even.\n\n\nWhat you can do:\n\nAs i said, this game has physical 5x5 adaptation, only there you can also lay the string from right-to-left and bottom-to-top, if you found that name, you could google further. I unfortunately don't remember it.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Example of longest path problem having a NP complexity?\r\n                \r\nI saw on the internet that finding the longest path problem is NP-Complete problem.\n\nFor some reason, my teacher tells me that it isn't an NP-complete problem.\nSo now I am looking for an example that shows the amount of computation needed for getting the longest path is bigger then polynomial time.\n\nfor now, I saw only examples of it having a polynomial complexity time.\n\nanyone can bring me a proof for this problem being NP-complete?\n    ", "Answer": "\r\nFor starters, depending on how you phrase the longest path problem, it may actually be the case that the problem is NP-hard but not NP-complete. The NP-complete version of this problem is the following:\n\n\n  Given a graph G and a length k, does G have a simple path of length k or more?\n\n\nThis problem is known to be NP-complete for reasons I'll detail later on. However, this closely-related problem is not actually NP complete:\n\n\n  Given a graph G, what is the longest simple path in G?\n\n\nThis second problem is NP-hard but not NP-complete. For a problem to be NP-complete, the problem has to be a decision problem, a problem whose answer is a boolean \"yes\" or \"no.\" This second version of the problem, however, isn't a decision problem, and so it can't be in NP, and so it can't be NP-complete. It's entirely possible that your teacher was thinking about this when saying that the longest path problem isn't NP-complete, though I can't say for certain.\n\nAs for why the longest path problem is NP-complete, we need to argue two points:\n\n\nThis problem is in NP. Intuitively, there's an efficient way to check yes answers to the problem.\nThis problem is NP-hard. That is, there's an NP-hard problem that reduces to it.\n\n\nFor point (1), the intuition is that if the answer to the question \"does this graph have a simple path of length 137 or more?\" is \"yes,\" there's some easy way to demonstrate this to someone. Just give them that simple path. Once they have the path, it's easy for them to check that, indeed, it meets the requirements. (Now, finding that path might be really hard. But once we've somehow isolated it, it's not hard to convince people that it works.)\n\nFor point (2), the general way to do this is to start with an existing NP-hard problem and to reduce it to our problem. Here, we'll start with the Hamiltonian path problem, which is the following:\n\n\n  Given a graph G, is there a simple path that passes through every node in G once and exactly once?\n\n\nHere's how we reduce that problem to the longest path problem. Start with the graph G. Now, ask the question: does G have a simple path of length at least n - 1, where n is the number of nodes in G? If so, then that simple path has to visit every node once and exactly once, since otherwise there aren't enough nodes in the path to make its length at least n - 1. And conversely, if not, then there's no Hamiltonian path, since any Hamiltonian path would fit the bill. Therefore, if we can solve the longest path problem efficiently, we can solve the Hamiltonian path problem efficiently. Since the Hamiltonian path problem is NP-hard, so is the longest path problem.\n\nNow, the fact that this problem is NP-complete doesn't mean that there is no polynomial-time solution for it. The P versus NP problem still hasn't been resolved, and without knowing whether P = NP or P ≠ NP we can't say whether there's a polynomial-time algorithm for the longest path problem. What we can say is that no known algorithms for it run in polynomial time (you mentioned some sites claim they have polynomial-time algorithms for this problem, but that doesn't sound right; if so, whoever found that algorithm would be a millionaire).\n\nNow, there's a follow-up question you can ask: why is the Hamiltonian path problem NP-hard? The usual way to prove this is to start with 3SAT and to do a clever, gadget-based reduction. That's way too long to explore here, but most intro theory textbooks (including Sipser's famous one) do a great job of explaining this.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Bounded PCP NP-Complete Proof\r\n                \r\nI'm looking for a simple proof that shows that the Bounded-PCP problem belongs to NP-Complete as many text books say so. It is clear to me that the problem is decidable but I cannot find any reduction from an NP-Hard problem to this one.\n\nMoreover, the verifying algorithm might go through a series of N indexes which is exponential in comparison to the input size (N) which is logN, so how can this problem be in NP?\n\nThanks.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If Y is reducible to X in polynomial time, then how is it true that X is at least as hard as Y?\r\n                \r\nI am having difficulty understanding the relationship between the complexity of two classes of problems, say NP-hard and NP-complete problems.\nThe answer at https://stackoverflow.com/a/1857342/ states:\n\nNP Hard\nIntuitively, these are the problems that are at least as hard as the NP-complete problems. Note that NP-hard problems do not have to be in NP, and they do not have to be decision problems.\nThe precise definition here is that a problem ```\nX```\n is NP-hard, if there is an NP-complete problem ```\nY```\n, such that ```\nY```\n is reducible to ```\nX```\n in polynomial time.\n\nIf a problem ```\nY```\n can be reduced to ```\nX```\n in polynomial time, should we not say that ```\nY```\n is at least as hard as ```\nX```\n? If a problem ```\nY```\n is reducible to ```\nX```\n in polynomial time, then the time required to solve ```\nY```\n is polynomial time + the time required to solve ```\nX```\n. So it appears to me that problem ```\nY```\n is at least as hard as ```\nX```\n.\nBut the quoted text above says just the opposite. It says, if an NP-complete problem ```\nY```\n is reducible to an NP-hard problem ```\nX```\n, then the NP-hard problem is at least as hard as the NP-complete problem.\nHow does this make sense? Where am I making an error in thinking?\n    ", "Answer": "\r\nYour error is in supposing that you have to solve X in order to solve Y. Y might be actually much easier, but one way to solve it is to change it to an instance of X problem. And since we are in big O notation and in NP class we are way past linear algorithms, you can always safely discard any linear parts of an algorithm. Heck you can almost safely discard any polynomial parts until P=NP problem is solved. That means ```\nO(f(n) + n) = O(f(n))```\n where ```\nn=O(f(n))```\n.\n\nExample (which is obviously with neither NP-hard or NP-complete problems but just a mere illustration): You are to find the lowest number in an unsorted array of n numbers. There is obvious solution to iterate over the whole list and remember the lowest number you found, pretty straight-forward and solid O(n).\n\nSomeone else comes and says, ok, let's change it to sorting the array, then we can just take the first number and it will be the lowest. Note here, that this conversion of the problem was O(1), but we can for example pretend there had to be some preprocessing done with the array that would make it O(n). The overall solution is O(n + n*log(n)) = O(n * log(n)).\n\nHere you too changed easy problem to a hard problem, thus proving that the hard problem is indeed the same or harder as the easy one.\n\nBasically what the NP-hard problem difinition means is, that X is at least as hard as an NP-complete Y problem. If you find an NP-complete Y problem that you can solve by solving X problem, it means either that X is as hard or harder than Y and then it is indeed NP-hard, or if it is simpler, it means you found an algorithm to solve Y faster than any algorithm before, potentially even moving it out of NP-complete class.\n\nAnother example: let's pretend convolution is in my set of \"complete\", and normally takes O(n²). Then you come up with Fast Fourier Transformation with O(n * log(n)) and you find out you can solve convolution by transforming it to FFT problem. Now you came up with a solution for convolution, which is o(n²), more specifically O(n * log(n)).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What are NP-Intermediate problems?\r\n                \r\nAssuming P != NP\n\nThe euler diagram shows a part not part of P and NP-complete. I read on wikipedia that this set is called NP-Intermediate.\n\nEuler Diagram\n\nI have some doubts as to how are NPI problems defined?\n    ", "Answer": "\r\nAn NP-intermediate problem is a decision problem that\n\n\nis in NP (that is, \"yes\" answers can be verified in polynomial time),\nis not in P (that is, there is no polynomial-time algorithm for solving the problem), and\nis not NP-complete.\n\n\nThat last criterion can be stated in a number of different ways. One way to say this is that there is no polynomial-time mapping reduction from SAT to that particular problem.\n\nThese problems are primarily of theoretical interest right now because we don't know if any NP-intermediate problems exist - if we could find one, we'd have a problem in NP that's not in P, meaning that P ≠ NP! However, they're interesting because if we can prove that P ≠ NP, then we know that there are some problems in NP that are too hard to be solved in polynomial time, but which aren't among the \"hardest\" of the hard problems in NP (the problems that are NP-complete).\n\nIn the event that P = NP, then there would not be any NP-intermediate problems because you couldn't have a problem in NP but not in P. If P ≠ NP, then Ladner's theorem guarantees at least one NP-intermediate problem exists, but does so by specifically constructing a problem that is highly artificial and designed solely to be NP-intermediate in that case. Right now, with a few exceptions (notably the graph isomorphism problem), all the problems we know of in NP are either squarely in P or known to be NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity of Some problems in NP?\r\n                \r\nI want to summarize some problem on Complexity. Which of them can be solved in poly-time? \n\n\n  I) finding maximal sub complete graph of given graph = Clique Problem\n  \n  II) select some elements among ```\nn```\n objects in which value and weights\n  are given, such that sum of weights of selected elements is not bigger\n  than an specific bound and sum of value being maximum\n  \n  III) finding all cycles of a graph\n  \n  IV) Finding a path that visit each vertex exactly once = Determine a graph is Hamiltonian \n\n\nI think IV is Hamiltonian path that is NP-Complete, III is NP-Hard and NP-Complete, II is NP-Complete, and I is NP-Complete. so 0 of these solved in poly-time. \n\nWho can more clearer me about NP-Hard and NP-Complete of these problem in a nice way? Am I right?\n    ", "Answer": "\r\nAs you've noted, parts (1), (2), and (4) are all famous NP-hard problems (max clique, knapsack, and Hamiltonian path). These problems are not in NP, though, because NP consists of decision problems (questions for which the answer is either \"yes\" or \"no\") and these are not decision problems.\n\nPart (3) is more nuanced. This problem is a counting problem - the goal is to determine how many objects of some type exist - rather than a decision problem, so it can't be in NP. To the best of my knowledge, it's not really known how hard this problem is. It's known that if it can be solved in polynomial time, then P = NP (see this link for details), and the specific proof shows that it's NP-hard as well.\n\nIf P ≠ NP, then none of these can be solved in polynomial time. If any of these can be solved in polynomial time, then P = NP. They are all NP-hard.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "what is the Non-cyclical definition of NP-hard?\r\n                \r\nI am trying to comprehend the concepts NP, NP complete and NP hard according to Wikipedia. \n\nIf I inderstand the given text correctly:\n\nEDIT: corrected according to David\n\nNP == decision problem whose answer can be verified in polynomial time (given the solution)\n\nNP complete == NP and NP hard simultaneously\n\nNP hard == there is a NP complete problem which is polynomial time Turing reducible to it.\n\nSo in order to understand the concept of NP completeness, I need to understand the NP hardness first. So I try to analyze what is NP hard according to the above statements. So I get:\n\nNP hard == there is a problem which is NP hard  and NP simultaneously, which is reducible to it. But there is a cycle in the definition. What is the noncyclical definition?\n    ", "Answer": "\r\nYou can also define NP-complete as a problem such that any NP-problem can be reduced to it in polynomial time. That definition should remove your cycle.\n\nYour definition of NP-hard seems backwards. It should be that a problem is NP hard if some NP-complete problem (thus any NP problem) can be reduced to it in polynomial time.\n\nYou can see more detail here: http://en.wikipedia.org/wiki/P_versus_NP_problem\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this bipartite graph optimization task NP-complete?\r\n                \r\nI have been trying to find out a polynomial-time algorithm to solve this problem, but in vain. I'm not familiar with the NP-complete thing. Just wondering whether this problem is actually NP-complete, and I should not waste any further effort trying to come up with a polynomial-time algorithm.\n\nThe problem is easy to describe and understand. Given a bipartite graph, what is the minimum number of vertices you have to select from one vertex set, say A, so that each vertex in B is adjacent to at least one selected vertex.\n    ", "Answer": "\r\nUnfortunately, this is NP-hard; there's an easy reduction from Set Cover (in fact it's arguably just a different way of expressing the same problem).  In Set Cover we're given a ground set F, a collection C of subsets of F, and a number k, and we want to know if we can cover all n ground set elements of F by choosing at most k of the sets in C.  To reduce this to your problem: Make a vertex in B for each ground element, and a vertex in A for each set in C, and add an edge uv whenever ground element v is in set u.  If there was some algorithm to efficiently solve the problem you describe, it could solve the instance I just described, which would immediately give a solution to the original Set Cover problem (which is known to be NP-hard).\n\nInterestingly, if we are allowed to choose vertices from the entire graph (rather than just from A), the problem is solvable in polynomial time using bipartite maximum matching algorithms, due to Kőnig's Theorem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Can a genetic algorithm optimize my NP-complete problem?\r\n                \r\nI have an array that stores a large collection of elements.\nAny two elements can be compared in some function with the result being true or false.\nThe problem is to find the largest or at least a relatively large subgroup, where every element with all the others in that subgroup is in a true relationship.\nFinding the largest subgroup from an array of size N requires N! operations, so the iterative way is out.\nRandomly adding successive matching elements works, but the resulting subgroups are too small.\nCan this problem be significantly optimised using a genetic algorithm and thus find much larger subgroups in a reasonable time?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Showing NP, NP-Completeness, or NP-Hardness\r\n                \r\nIs my understanding of the three categories correct?\n\nTo show a problem X is NP:\n\n\nShow that X can be verified deterministically in polynomial time (Or\nX is solvable using a NTM)\n\n\nTo show a problem X is NP-Complete:\n\n\nShow that X can be verified deterministically in polynomial time(Or\nX is solvable using a NTM) \nShow that given a known NP-C problem L, L ≤p X \nShow that given a known NP-C problem L, X ≤p L (Is this step\nnecessary? If so, is this what differentiates a purely NP-Hard\nproblem from a NP-C problem?)\n\n\nTo show a problem X is NP-Hard:\n\n\nShow that given a known NP-C problem L, L ≤p X\n\n    ", "Answer": "\r\nYou almost got it.\n\nGiven a problem ```\nX```\n, to show it is NPC, you don't need to show ```\nX ≤p L```\n, for some NPC problem ```\nL```\n.\n\nIn fact, this is guaranteed, since you already showed that ```\nX```\n is in NP (in 1), and you know ```\nL```\n is NP-Complete. By definition of NP-Complete, this means there is a polynomial time reduction from ALL problems in NP to ```\nL```\n, including from ```\nX```\n, so basically your step (3) in proving NPC is redundant.\n\n\n\nA more elegant way to show the statements of what needs to be done to prove each property:\n\nTo show ```\nX```\n is NP:\n\n\nShow that X can be verified deterministically in polynomial time (Or X is solvable using a NTM)\n\n\nTo show ```\nX```\n is NP-Hard:\n\n\nShow that given a known NP-Hard problem L, L ≤p X\n\n\nOR\n\n\nShow that for any problem ```\nL```\n in NP, L ≤p X (this is done only once actually, for SAT, and is the definition of NP-Hard).\n\n\nTo show a problem X is NP-Complete:\n\n\nShow X is NP-Hard\nShow X is in NP\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Steiner Minimal Trees and NP-completeness\r\n                \r\nWhat is the difference between the following Steiner trees: (Non-)Metric Steiner Minimal Tree, Euclidean Steiner Minimal Tree, Graph Steiner Minimal Tree, etc? Which of these are NP-complete and which are NP-hard? Some of the online resources I found suggest that Steiner trees are NP-hard, and others suggest it's NP-complete, but I believe they are referring to different versions/variants of the problem.\n\nUpdate: nevermind, I've figured it out. The decision problem of SMT is NP-complete because, given a Steiner tree and an integer k, it is easy to verify in polynomial time whether the cost of the tree is less than or equal to k. But the optimization problem of SMT does not have a polynomial time verifier (we can still find the cost of the tree, but we cannot verify that it is the optimal solution), so it's NP-hard.\n    ", "Answer": "\r\nI was confused by NP-completeness and NP-hardnesses of problems a lot, especially since it sometimes looks like they are used interchangeably. \n\nThe catch is very simple. NP-complete is a subclass of NP which is the class of polynomial time verifiable decision problems. So only decision problems can be NP-complete, and an optimization problem is never NP-complete. \n\nNP-Hard means just any problem that's at least as hard as NP-complete, including both decision and optimization problems. Therefore all NP-Complete decision problems are also NP-Hard. If a decision problem is NP-Complete the optimization version is NP-Hard because if you have a solution to the optimization, you can also use it to answer the decision problem. However the converse is not necessarily true. \n\nSo technically per definition, even if the optimization problem had a polynomial time verifier it would still not be NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "3-OCC-MAX SAT np-complete?\r\n                \r\nAssuming 3-OCC-MAX SAT is the language of all CNF formulas in which every variable appears in at most 3 clauses.\nIs this problem NP-Complete? I'm trying to find a karp reduction between SAT and this problem, but I couldn't find it.\n    ", "Answer": "\r\nThis problem is NP-complete. It is easy to see that it is in NP (guessing a model; check it in polynomial time).\nFirst Attempt (Failure)\nTo show NP-hardness, I propose the following construction:\nConsider a 3-SAT instance F over n variables.\nConsider a clause ```\n[L1, L2, L3]```\n.\nDefine fresh variables p1, p2, p3.\nDefine Li equivalent to pi.\nAfterwards, replace the original clause using the fresh variables.\nThis results in clauses of the form:\n```\n[p1, p2, p3]\n[-p1, L1]\n[-L1, p1]\n[-p2, L2]\n[-L2, p2]\n[-p3, L3]\n[-L3, p3]\n```\n\nDo this for all clauses and always use fresh variables.\nNote that the variables p1 to p3 are used exactly three times, whereas L1 till L3 are used twice.\nThis construction is polynomial.\nEDIT: I currently see that this is not a valid solution yet: The original literals may exceed the maximum occurence of 3.\nSecond Attempt\nThe idea is to use fresh variables for every apperance of a literal.\nLet M be the number of appearences of variables in the 3SAT formula (this can be improved).\nFor every atom A in the 3SAT CNF, add the following to the resulting the 3-OCC-MAX SAT formula:\n```\nq0 <- A\nq1 <- q0\nq2 <- q1\nq3 <- q2     \nq4 <- q3\n...\nq_M <- q_M-1\nq_M+1 <- q_M\nq0 <- q_M+1\n```\n\nDo the same for the occurences of -A.\n```\np0 <- -A\np1 <- p0\np2 <- p1\np3 <- p2     \np4 <- p3\n...\np_M <- p_M-1\np_M+1 <- p_M\np0 <- p_M+1\n```\n\nFurthermore, add the following to ensure that either the q-row or the p-row is true.\n```\n-p0 <- qM+1\n-q0 <- pM+1\n```\n\nNow, add the clauses of the original 3SAT CNF, in which the n-th occurence of the literal L is replaced by qn.\nThere is no \"0-th occurence\", i.e. we start counting by 1; therefore q0 and p0 as well as qM and pM are not used in this context.\nNote that A and -A appears 2x, the variable p0, q0, p_M+1, q_M+1 three times and the variables p_i, q_i, where i is between 1 and M at most three times.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Looking for a model to represent this problem, which I suspect may be NP-complete\r\n                \r\n(I've changed the details of this question to avoid NDA issues. I'm aware that if taken literally, there are better ways to run this theoretical company.)\n\nThere is a group of warehouses, each of which are capable of storing and distributing 200 different products, out of a possible 1000 total products that Company A manufactures. Each warehouse is stocked with 200 products, and assigned orders which they are then to fill from their stock on hand.\n\nThe challenge is that each warehouse needs to be self-sufficient. There will be an order for an arbitrary number of products (5-10 usually), which is assigned to a warehouse. The warehouse then packs the required products for the order, and ships them together. For any item which isn't available in the warehouse, the item must be delivered individually to the warehouse before the order can be shipped.\n\nSo, the problem lies in determining the best warehouse/product configurations so that the largest possible number of orders can be packed without having to order and wait for individual items.\n\nFor example (using products each represented by a letter, and warehouses capable of stocking 5 product lines):\n\n```\nWarehouse 1: [A, B, C, D, E]\nWarehouse 2: [A, D, F, G, H]\n\nOrder: [A, C, D] -> Warehouse 1\nOrder: [A, D, H] -> Warehouse 2\nOrder: [A, B, E, F] -> Warehouse 1 (+1 separately ordered)\nOrder: [A, D, E, F] -> Warehouse 2 (+1 separately ordered)\n```\n\n\nThe goal is to use historical data to minimize the number of individually ordered products in future. Once the warehouses had been set up a certain way, the software would just determine which warehouse could handle an order with minimal overhead.\n\nThis immediately strikes me as a machine learning style problem. It also seems like a combination of certain well known NP-Complete problems, though none of them seem to fit properly.\n\nIs there a model which represents this type of problem?\n    ", "Answer": "\r\nIf I understand correctly, you have to separate problems :\n\n\nPredict what should each warehouse pre-buy\nGet the best warehouse for an order\n\n\nFor the first problem, I point you to the netflix prize : this was almost the same problem, and great solutions have been proposed. (My datamining handbook is at home and I can't remember for precise keyword to google, sorry.Try \"data mining time series\" )\n\nFor the second one, this is a problem for Prolog.\n\n\nSet a cost for separately ordering an item\nSet a cost, for, idk, proximity to the customer\nSet the cost for already owning the product to 0\nMake the rule to get a product : buy it if you don't have it, get it if you do\nMake the rule to get all products : foreach product, rule above\nget the cost of this rule\nGently ask Prolog to get a solution. If it's not good enough, ask more.\n\n\nIf you don't want to use Prolog, there are several constraints libraries out there. Just google \"constraint library ```\n<insert your programming language here```\n>\"\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is Shortest Hamiltonian path NP-hard?\r\n                \r\nHamiltonian Path is a path that connects all nodes without repeat and it is an NP-complete problem.\n\n\nIs the Shortest Hamiltonian Path (SHP) NP-hard?\nWhat is the difference between travelling salesman problem with SHP?\n\n    ", "Answer": "\r\nI assume the SHP problem is the Hamiltonian problem on the edge weighted graph. It is NP-hard because it is at least as hard as the Hamiltonian problem. Assume you have an algorithm to solve the SHP problem, then you apply the algorithm on a weighted graph with all edge weights are 1, it will solve the Hamiltonian problem with the same time complexity. \n\nTSP requires to return to the original vertex and you can visit each vertex more one once. SHP asks for the path which visits every vertex exactly once.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "np-completeness in the bounded degree spanning tree\r\n                \r\nI understand why the Bounded Degree Spanning Tree is considered NP Complete with a degree or 2 (it is an instance of the Hamiltonian Path Problem), but I do not understand why this applies to degrees > 2. If someone could please explain why this is an NP Complete problem for degree > 2, It would be most helpful\n    ", "Answer": "\r\nWell, I think that you can make a simple reduction from the instance of bounded by 2, to the instance of General k.\n\nIntuitivly, we will connect to each node of the original graph new k-2 nodes. Therefore every spanning tree will have to contain the k-2 edges from the original node to the new nodes that we connected to him, and a spanning tree from degree at most k exists if there is a spanning tree of degree at most 2 for the original graph.\n\nThe formal reduction will be:\n\nF(V,E)=(V',E'), when : V'={(v,i)|v is in the original graph, 0 < i < k+1), E' = E U {((v,0),(v,i))}, and I don't write a formal proof for the correctness because after all we are not in a math forum.\n\nGood luck and hope that it helped :)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reduction between problems in NP\r\n                \r\nBy definition, any problem in NP can be reduced to a problem in NP-Complete. However, let's say we have two arbitrary problems X and Y in NP. Is it necessarily true that X is reducible to Y?\n\nI'm unclear on the aspect of reduction between two arbitrary problems of a particular complexity class, so any guidance would be appreciated.\n    ", "Answer": "\r\nIn principle there is no reason why an arbitrary problem should be reducible to another.\n\nFor a concrete example, it is known that factorization of an arbitrary integer with ```\nn```\n bits is in ```\nNP```\n, but it is is believed to both not be in ```\nP```\n and not to be ```\nNP```\n-complete.  Therefore traveling salesman is not reducible to integer factorization.\n\nhttps://en.wikipedia.org/wiki/NP-intermediate has a list of other problems that are in the same category, and there is no reason to believe that, for example, graph isomorphism is reducible to factoring or vice versa.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this a correct understanding of proving something is NP Complete?\r\n                \r\nAs I understand it there are two steps to proving that a problem is NP complete:\n\n\nGive an algorithm that can verify a solution to the problem in polynomial time. That is, an algorithm whose input is a proposed solution to the problem and whose output is either \"yes\" or \"no\" based on whether the input is a valid solution to the problem.\nProve the problem is NP hard - eg, assume you have an oracle that can compute another known NP complete problem in one step.  Using that, write an algorithm that solves this problem in polynomial time.\n\n\nFor example, suppose we want to prove that the following problem is NP Complete:\n\nGiven a set of integers, ```\nS```\n, is it possible to isolate a subset of elements, ```\nS'```\n, such that the sum of the elements in ```\nS'```\n is exactly equal to the sum of the remaining elements in ```\nS```\n that are not included in ```\nS'```\n?\n\nStep 1: Verification algorithm\n\n```\nVerify_HalfSubset(Set S, Solution sol):\n    accum = 0\n    for each element i in sol:\n        accum+=i\n        linear search for an element with the same value as i in S.\n        if found, delete it from s, if not found, return false\n    end for\n    accum2 = 0\n    for each element i in S:\n        accum2+=i\n    end for\n    if accum==accum2 return true, else return false\n```\n\n\nClearly this runs in polynomial time: The first for loop runs in ```\nO(nm)```\n and the second runs in ```\nO(n)```\n.\n\nStep 2: Reduction\n\nAssume we have an oracle ```\nO(Set S, int I)```\n that computes the subset sum problem in a single step (that is, is there a subset of elements in S that sum up to I)?\n\nThen, we can write a polynomial time algorithm that computes our half-subset problem:\n\n```\nHalfSubset(Set S):\n    accum = 0\n    for each s in S:\n        accum+=S\n    end for\n    if(accum%2==1) \n    // this question forbids \"splitting\" values to non-integral parts\n        return NO_ANSWER\n    end if\n    half1 = O(S, accum/2)\n    if(half1 == NO_ANSWER)\n        return NO_ANSWER\n    end if\n    for each i in half1:\n        linear search for an element with the same value as half1[i] in S\n        delete it from S.\n    end for\n    half2 = S\n    return (half1 and half2)\n```\n\n\nCan someone please tell me if I've made any mistakes in this process? This is the one question on my final exam review that I'm not entirely sure I understand completely.\n    ", "Answer": "\r\nThe second portion of your answer is a bit off. What you are saying in step two is that you can reduce this problem to a known NP-complete problem in polynomial time. That is, you are saying that this problem is at most as hard as the NP-complete problem. \n\nWhat you want to say is that the NP-complete problem can be reduced to your example problem in polynomial time. This would show that, if you could solve this problem in polynomial time, then you could also solve the NP-complete problem in polynomial time, proving that your example problem is NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "proof of SAT np completeness\r\n                \r\nI know if we want to prove the np completeness of some problem we must show these :\n\nthere is a nondeterministic polynomial solution for the problem\nall other np problems are reducible to the problem\nin the case of sat problem it's easy to show \"there is a nondeterministic polynomial solution for the SAT problem\" but I don't know how to prove \"all other np problems are reducible to the SAT problem\"\n\n    ", "Answer": "\r\n\nbut I don't know how to prove \"all other np problems are reducible to the SAT problem\"\n\nThis is known as the Cook Levin Theorem: https://en.wikipedia.org/wiki/Cook%E2%80%93Levin_theorem .\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are all scheduling problems NP-Hard?\r\n                \r\nI know there are some scheduling problems out there that are NP-hard/NP-complete ... however, none of them are stated in such a way to show this situation is also NP.\n\nIf you have a set of tasks constrained to a startAfter, startBy, and duration all trying to use a single resource ... can you resolve a schedule or identify that it cannot be resolved without an exhaustive search?\n\nIf the answer is \"sorry pal, but this is NP-complete\" what would be the best heuristic(s?) to use and are there ways to decrease the time it takes to a) resolve a schedule and b) to identify an unresolvable schedule.\n\nI've implemented (in prolog) a basic conflict resolution goal through recursion that implements a \"smallest window first\" heuristic. This actually finds solutions rather quickly, but is exceptionally slow at finding invalid schedules. Is there a way to overcome this?\n\nYay for compound questions!\n    ", "Answer": "\r\nThe hardest part of most scheduling problems in real life is getting hold of a reliability and complete set of constraints. If we take the example of creating a university timetable:\n\n\nProfessor A will not get up in the morning, he is on a lot of committees, but  no-one will tell the timetable office about this sort of constraint\nDepartment 1 needs the timetable by the start of term, however, Department 2 that uses the same rooms is unwilling to decide on the courses that will be run until after all the students have arrived\nEtc\n\n\nThen you need a schedule system that can cope with changes, so when one constraint is changed at the last minute you don’t have to change the complete timetable.\n\nAll of the above is normally ignored in research papers about scheduling systems.  As to NP completeness of a given scheduling problem, in real life you don’t care as even if it is not NP complete you are unlikely to even be able to define what the “best solution” is, so good enough is good enough.\n\nSee http://www.asap.cs.nott.ac.uk/watt/resources/university.html for a list of papers that may help get you started; there are still many PHDs to be had in scheduling software.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is generating all strings permutation NP Complete?\r\n                \r\nCalculating all string permutations of a given string can be solved in O(n!) by trying all possibilities.\n\nNow, looking at the Travel Salesman Problem, we can solve it by trying all permutations of cities. Lets say we have cities A, B and C.\nLets say we start at city A. By calculating all permutations of BC string we get ABC ACB, then we just sum (in polynomial time the distance between AB, CB and CA for the first case...)\n\nSo isnt this a reduction of the all strings permutation to the travel salesman problem and isnt it a NP Complete problem?\n    ", "Answer": "\r\nI think you're confusing some concepts:\n\nWhat you describe is not \"reducing the all permutations problem to TSP\", but the opposite: reducing TSP to the all permutations problem.\nWhat that proves is that generating all permutations is NP-Hard (at least as hard as the hardest NP problem).\n\nTo prove something is NP-Complete, you would also have to prove that it's in NP. But this is not true, right out of the gate: NP is a set of decision problems, and the problem you described isn't a decision problem.\n\nSee also: What are the differences between NP, NP-Complete and NP-Hard?\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is generating all strings permutation NP Complete?\r\n                \r\nCalculating all string permutations of a given string can be solved in O(n!) by trying all possibilities.\n\nNow, looking at the Travel Salesman Problem, we can solve it by trying all permutations of cities. Lets say we have cities A, B and C.\nLets say we start at city A. By calculating all permutations of BC string we get ABC ACB, then we just sum (in polynomial time the distance between AB, CB and CA for the first case...)\n\nSo isnt this a reduction of the all strings permutation to the travel salesman problem and isnt it a NP Complete problem?\n    ", "Answer": "\r\nI think you're confusing some concepts:\n\nWhat you describe is not \"reducing the all permutations problem to TSP\", but the opposite: reducing TSP to the all permutations problem.\nWhat that proves is that generating all permutations is NP-Hard (at least as hard as the hardest NP problem).\n\nTo prove something is NP-Complete, you would also have to prove that it's in NP. But this is not true, right out of the gate: NP is a set of decision problems, and the problem you described isn't a decision problem.\n\nSee also: What are the differences between NP, NP-Complete and NP-Hard?\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Does every NP-complete prob. admit a polynomial-time restriction?\r\n                \r\nI have to answer this question as a homework assignment but I am finding very little material to work with. I understand what is a NP-complete problem and what is a restriction. In my opinion, this statement is true, because you can always restrict the problem in order to \"make the problem easier\". But I'm looking at it with a bird's eye view... Can anyone help me make some progress finding the answer to this question?\nAny help will be much appreciated. \n    ", "Answer": "\r\nConverting my comment into an answer - consider the \"empty problem,\" a problem whose instance set is empty. Since the empty set is a subset of every set, this problem technically counts as a restriction of any language (including languages not in NP). It's also a problem in P; you can build a polynomial-time TM that always rejects its input. Therefore, every problem in NP has a polynomial-time restriction.\n\nWhat I'm still curious about, though, is whether every NP problem whose instance set is infinite has a polynomial-time restriction whose instance set is also infinite. That's a more interesting question, IMHO, and I don't currently have an answer.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Showing that the decison version of an NP-complete language is NP-complete\r\n                \r\nSay you are given a combinatorial optimization problem A. Let us assume WLOG that the problem is the clique problem.\n\nHow can I show that if clique is NP-complete, then the decision version of clique is NP-complete, where the decision version is of course the following problem B: is there a clique of size equal to k?\n\nI think I have the intuition in mind but not sure if it suffices as a proof:\n\nStep I: \n\nif I am given a set of vertices C of size k, I can verify in polynomial time that there is a clique of size k (assuming that the answer to B is yes i.e. there exists a clique of size k). Hence, B is in NP.\n\nStep II: reduce A to B.\n\n-Since A asks for the clique of maximum size, we can break the problem down into pieces, B1: is there a clique of size 1?, ..., BN: is there a clique of size N? \n\n-If A is solvable, say there is a clique of size k*, then every Bk, k=1,...,N can be easily answered by comparing k to k*\n\n-If all of the Bks are solvable, we can tell what is the maximum clique size.\n\nI'm really not sure that this is a reduction although it's in polynomial time. Maybe because one problem is broken down into many problems. Moreover, I'm not sure I should be using the the word \"all\" above.\n\nThanks for the help! :)\n    ", "Answer": "\r\nA combinatorial optimization problem cannot be NP-complete. Only decision problems can be NP-complete (see, e.g, http://en.wikipedia.org/wiki/NP-complete).\n\nThe Clique optimization problem (given a graph, find a maximal set of vertices that form a clique) is NP-hard, because its decision version (given a graph and a k, is there a clique of size >= k?) is NP-complete. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Problems formerly in NP but now in P\r\n                \r\nAre there any problems that used to be in NP (not NP-complete and not P) but since then have been proven to be in P? I saw this video which states that people sometimes find ways of doing NP problems as quickly as P, thus proving that the problem is actually in P. Does anyone know of any examples?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Show np-completeness of Disjoint Hamiltonian Path\r\n                \r\nConsider the problem of Disjoint Hamiltonian Path: \n\nInput: A graph which may be directed or undirected\n\nOutput: Does this graph exist at least 2 Hamiltonian Paths that are edge-disjoint? \nEdge-disjoint means that no single edge is shared by two paths. \n\nShow that Disjoint Hamiltonian Path is np-complete.\n\nI have been told that this problem is np-complete, but I couldn't prove it is np-hard. I tried reducing the original Hamiltonian Path and Hamiltonian Cycle to this problem but I couldn't think of a solution.\n    ", "Answer": "\r\nI came up with the following reduction, not sure if it's the simplest but it is simple.\n\nSuppose G is an undirected graph corresponding to an instance of HP.\nNow construct a new graph G' in the following way:\n\n\nKeep every vertex from G.\nFor every edge (u,v) in G, create 4 additional vertices and connect them in the following way : \n\n\n\nNow it is easy to see that if G has a Hamiltonian path, G' will have two edge-disjoint Hamiltonian paths, because every edge was replaced by some subgraph which itself has two edge-disjoint Hamiltonian paths (go straight or take the curvy edges). And if G' has a HP, then so does G because once you enter the subgraph corresponding to one of the original edges you have no choice but to get out of it on the other end, which corresponds to taking the original edge in G. The only \"problem\" that could occur is if the path were to start or end inside one of these subgraphs, but then we can just ignore the small part of the path which is inside and still get a HP for G.\n\nAnd notice that G' has a HP => G has a HP => G' has two edge-disjoint HPs. Thus, G has a HP <=> G' has two edge-disjoint HPs.\n\nThe transformation can obviously be done in poly-time, thus your problem is NP-Hard.\n\nThe directed case is similar, just direct the edges in the transformed graph accordingly.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this prob on weighted bipartite graph solvable in polynomial time or it is NP-Complete\r\n                \r\nI encounter this problem recently and I want to know whether it is NP-Complete or solvable in polynomial time:\n\nGiven a weighted bipartite graph G=(V,E) where V can be partitioned into two sets A and B and E is a set of edges connecting A and B. The weight of an edge (v,u) is denoted as w(v,u).\n\nDo the following sequentially:\n\n\nPick a node v∈A,\nremove all node u∈B for every (v,u)∈E and,\nadd the weight w(v,u) to the total score for every edges deleted.\n\n\nThe goal is to find the sequence of nodes v1,…,vn∈A that maximizes the total score.\n\nI have searched for the bank of NP-Complete problems to find something possible can reduce to this problem but I haven't found anything useful yet. Any suggestions would be extremely helpful!\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proving NP hard by polynomial reduction to 3SAT\r\n                \r\nI know the correct way of proving NP hard of a problem X is to reduce a known NP-Hard problem to X i.e. the direction is from the known, harder problem to the problem we want to prove is NP-Hard. But all NP-Complete problems are polynomially related (one can be transformed into the other in polynomial time), so I would like to ask if it's correct to assert that a problem is NP-Hard when it can be polynomially reduced to 3SAT? \n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proving NP completeness of optimal path cover\r\n                \r\nThis paper solves the optimal path cover problem for block graphs or bipartite permutation graph. In the third line of its introduction it's written that optimal path cover problem is NP-Complete and has given reference to \"Computer and intractability: a guide to the theory of NP-completeness by David S. Johnson, Michael R. Garey\". But I couldn't find its proof in the book. If anyone knows how to prove NP-Completeness of this problem then share your solution.\n\n\n  Optimal path cover problem:\n  Given a graph G, find a minimum number of\n  vertex disjoint paths which together cover all the vertices of the\n  graph.\n\n    ", "Answer": "\r\nConsidering the obvious decision variant (ie given k, is there a cover with k paths)\n\nOPC(k=1) detects Hamiltonian paths, so clearly it's NP-hard.\n\nIt's also in NP because given the paths, checking whether they're disjoint and covering is easy.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Prove NP-Completeness clique + independent set graph\r\n                \r\n\"Prove that it is NP-Complete to determine given input G and k whether G has both a clique of size k and an independent set of size k. Note that this is 1 problem, not 2; the answer is yes if and only if G has both of these subsets.\"\n\nWe were given this problem in my algorithms course and a large group of students could not figure it out. Here is what we have so far...\n\nWe know that both the clique and independent set problems are NP-Complete in of themselves. We also know that the verification of this problem, given some \"certificate\" is in NP.\n\nThe problem is somehow performing a reduction on the above problem (which contains both independent sets and cliques) to either a problem consisting entirely of cliques or independent sets (at least that's what we think we need to do). We don't know how to perform this reduction without losing information needed to reduce the reduction back to its original form.\n    ", "Answer": "\r\nHint: Reduce CLIQUE to this problem, by adding some vertices.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is mapping array elements to perfect hash indexes NP Complete?\r\n                \r\nAssuming I have a set of integers that can range from 0 to INT64MAX, but I know the set in its entirety so I can generate a perfect hash.\n\nIf I want to use these hashes as array indices, I need to modulus with the size of the array I want to store this in.\n\nThis brings a problem where I want to find a non-colliding set for my hashes that map to integers such that minimal array size is needed and I still have no collisions.\n\nIs this NP complete? It \"feels\" NP Complete.\n    ", "Answer": "\r\nNo.\n\nThere exist algorithms that construct perfect hashes (even minimal perfect hashes) in linear time. See for example the CMPH docs which list a couple of them.\n\nLinear time means deterministic polynomial problem, thus the problem lies in ```\nP```\n. P is contained in ```\nNP```\n, but the problem certainly is not at least as hard as the hardest problems in ```\nNP```\n, thus it is not in ```\nNP-hard```\n.\n\n```\nNP-complete```\n is defined as being in both ```\nNP```\n and ```\nNP-hard```\n. Therefore, it is not NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to show that a prob is in NP and that it is NP-complete\r\n                \r\nLongest Path\n\nWe have a graph G=(V,E), lengths l(e) in Z^(+) for each e in E, a positive integer K and two nodes s,t in V.\n\nThe question is if  there is a simple path in G from s to t of length at least K ?\n\n\nShow that the problem Longest Path belongs to NP.\nShow that the problem Longest Path is NP-complete, reducing Hamiltonian Path to it.\nShow that if the graph is directed and acyclic then the problem can be solved in time O(|V|+|E|).\n\n\nCould you give me a hint how we could show that the problem belongs to NP?\nAlso, how can we reduce a problem to an other, in order to show that the latter is NP-complete?\n\nEDIT:\n\nSo in order to show that the problem belongs to NP, do we have to draw a simple and count the sum of the lengths of the edges?\n\nDo we say for example the following?\n\n\n\nWe see that the length of the path from the node s to the node t is equal to l((s,w))+l((w,t))=3+12=15, so there is no simple path in G from s to t of length at least K.\n\nOr does it suffice the following?\n\n\"Given a a simple path , we can easily check if its length is at least K(by simply computing the sum of lengths of all edges in it). Thus, it is in NP.\"\n\nEDIT 2: Also could you explain me further why  we reduce the Hamiltonian path problem to this one in polynomial time by  setting all edges' lengths equal to one and set K = |V| - 1 ?\n\nEDIT 3: Suppose that we have a problem A and a problem B and it is known that B is NP-complete. If we want to show that A is also NP-complete, do we change the data of A in that way so that we have the same problem as the problem B and so we deduce that A is also NP-complete? Or have I understood it wrong? \n\nEDIT 4: Also how can we show that if the graph is directed and acyclic then the problem can be solved in time O(|V|+|E|)?\n\nEDIT 5: All edges'lengths of a Hamiltonian path are equal to 1, right? And if we have V vertices, the length of the longest path is at V-1, yes? But in our problems, the lengths of the edges aren't specific and K is also not a fixed number. So if we set all edges' lengths equal to one and set K = |V| - 1, don't we reduce our problem to the Hamiltonian path problem? Or have I understood it wrong?\n    ", "Answer": "\r\n\nTo show that a problem is in NP, we need to show that it can be verified in polynomial time. Given a certificate(a simple path in this case), we can easily check that it length is at least K(by simply computing the sum of lengths of all edges in it). Thus, it is in NP.\nReduction from A to B means: given an instance of A, create an instance of B(to be more precise, we are interested in polynomial time reduction here) and solve it in order to solve the original problem. So how can we reduce the Hamiltonian path problem to this one in polynomial time? It is pretty straightforward: we can set all edges' lengths equal to one and set ```\nK = |V| - 1```\n. Then we should try all pairs of vertices in the graph ```\n(s, t), s != t```\n and if the solution for this problem returns true for at least one pair, return true. Otherwise, we should return false(checking that we have a path of length ```\n|V| - 1```\n in a graph where all edges have unit length is exactly the same thing as checking that a Hamiltonian path exists by its definition). \n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Array search NP complete [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 8 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nGiven an unsorted array of size n, it's obvious that finding whether an element exists in the array takes O(n) time.\n\nIf we let m = log n then it takes O(2^m) time. \n\nNotice that if the array is sorted, a binary search actually takes O(m) time (which is polynomial) but the binary search cannot apply to an unsorted array.\n\nIs it possible to prove that the problem to find an element in an array (yes or no) is NP complete in terms of m. What problem should I reduce from and how to reduce?\n\nAny idea would be appreciated.\n\nEDIT:\n\nMy description above probably did not express clearly what I was trying to say.\n\nLet's reword the problem in the following way.\n\n\nWe have an oracle, which is a binary tree of height h with each node having random values. I.E. a tree that DOES NOT have the property that all values in the left subtree of a node must be smaller than the value in the node or all values in the right subtree of a node must be greater than the value in the node. However all nodes in the oracle tree are guaranteed to have value between 0 and 2^h-1.\nThe input is a number to be searched. The input is guaranteed to have value between 0 and 2^h-1. (The input has h bits)\n\n\n(Let's say we are searching through the same array every time and hence we have the same oracle every time so the tree is not a part of input.)\n\n\nThe output is YES or NO, indicating whether the input is in a node of the tree or not.\n\n\nQuestion: whether this problem is NP complete or not in terms of h.\nThis problem is NP because if a path to the YES node in the tree is given it can be verified in O(h) time.\n\n(Note that if the oracle tree has the property that left subtree of a node is less than the node and right subtree of a node is greater than the node then the problem is NOT NP complete because binary search can be applied.)\n    ", "Answer": "\r\n\n  Finding an element in an array is NOT NP-complete as it can be done in linear time. (Assuming P ≠ NP)\n\n\nIn fact, the naive brute-force search algorithm you mentioned in your question is a linear time algorithm!\n\nWhen we are talking about the complexity of a computational problem, we always measure the time with respect to the size of the input. You claimed the input size of our algorithm is ```\nm = log(n)```\n, but in our case, the size of our input is determined by the number of elements in the array, which is ```\nn```\n.\n\nFor your reference, testing whether a given number ```\nn```\n is a prime number is an example computational problem that takes input of size ```\nlog(n)```\n. The input of the problem is ```\nn```\n, and it is of size ```\nlog(n)```\n because we need to use ```\nlog(n)```\n bits to represent ```\nn```\n in binary form.\n\nUpdate\n\n\n  Deterministic search algorithm requires Ω(n) time for unsorted array.\n\n\nAny search algorithm must read through the entire input (i.e. the n entries of the array). We are going to prove this by contradiction.\n\nSuppose there is a search algorithm that does not read all n input entries, then there is an entry that is not read by this algorithm. you can then construct a case that the search item is at the entry that is not read by this hypothetical algorithm, this violates the correctness of the algorithm. Hence such algorithm does not exist.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "np-complete and turing reductions\r\n                \r\nI have some difficulties with a complexity proof : \nI work with 3 problems : A, B and C\nI know :\n\n\nA-> B \nA-> C\nC -> B \n\n\nA-> B meaning : if I have a \"yes answer \" for A , then I have a \"yes answer\" for B.\nI know that A belongs to NP,\nB and C are NP-complete. Moreover I can write an algorithm for A with a quadratic number of calls to C.\ncan I deduce something about the complexity of A? \n\nTo be more precise : I have a set P of k objects.\nThe problem A answer yes if all these objects are removed, no otherwise.\nThe problem C answer yes if one of these objects can be removed, no otherwise.\nWe have the constraint that at least one objects has to be removed at each step. In worst we make P steps.\nSo algorithm for A : \n\n```\n    for( i = 0 ; i < k){\n    for each object p of P \n    { \n    if C(p,P)=true then \n      remove p of P}\n    }\n    return P = emptyset\n```\n\n    ", "Answer": "\r\nAs you don't state that B -> A, it could be the case that A only requires yes answers in trivial cases or cases that can be determined in polynomial time while determining answers for B requires more time as more complex cases might require a Yes answer.\nShorter answer to your question: no.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Subset Inference NP-complete?\r\n                \r\nConsider the following problem:\n\nThere are N coins numbered 1 to N.\n\nYou can't see them, but are given M facts about them of the form:\n\n```\nstruct Fact\n{\n    set<int> positions\n    int num_heads\n}\n```\n\n\n```\npositions```\n identifies a subset of the coins, and ```\nnum_heads```\n is the number of coins in that subset that are heads.\n\nGiven these M facts you need to work out the maximum number of heads there could possibly be.\n\nIs this problem NP-complete?  If yes, what is the reduction?  If no, what is a polynomial time solution?\n\nFor example:\n\n```\nN = 5\nM = 3\nfact1 = { {1, 2}, 1 } // Either coin 1 or coin 2 is a head\nfact2 = { {4}, 0 } // Coin 4 is a tail\nfact3 = { {2, 4, 5}, 2 } // Out of coins 2, 4 and 5, two are heads\n```\n\n\nA configuration with the most heads that matches the facts is:\n\n```\nT H H T H\n```\n\n\nSo the answer is 3 heads.\n    ", "Answer": "\r\nLet's say you have a 3-SAT problem. You can map every boolean variable v in that problem to two coins. Call them 'true(v)' and 'false(v)'. The idea is that if v in a solution to the 3-SAT problem is true, then 'true(v)' is heads; otherwise 'false(v)' is heads. For every v you add the coin constraint\n\n```\n{true(v), false(v)} has 1 heads, and has 1 tails\n```\n\n\nAfter this, you can translate a 3-SAT clause with literals l1, l2, l3\n\n```\nl1 or l2 or l3\n```\n\n\nto the coin constraint\n\n```\n{t/f(l1), t/f(l2), t/f(l3)} has at least 1 heads\n```\n\n\nwhere t/f(l1) is either 'true(l1)' or 'false(l1)' depending on if l1 is positive (not negated) or negative (negated) in the clause. We just need to show that 'at least 1 heads' can be implemented in the coin problem as 'at least 1 heads' is not expressible directly. This can be done with the following device. Let C1, C2, C3 be three coins for which we want to state the constraint 'at least one of them is heads'. Create three other coins X1, X2, X3 and put in constraint\n\n```\n{X1, X2, X3, C1, C2, C3} has 4 heads\n```\n\n\nbut no other constraints for X1, X2, X3. This constraint is satisfied only if at least one of C1, C2, C3 is heads; the coins X1..3 can be used to provide the remaining needed heads.\n\nNote that this reduction does not use the \"maximum number of heads\" aspect of the problem at all; it is plainly impossible to choose heads/tails status for the coins that represent boolean variables at all if the 3-SAT formula is unsatisfiable.\n\nThis is a polynomial reduction FROM 3-SAT TO your coin problem, showing it is NP-hard. To show it is NP-complete, just observe that a solution to your coin problem can be checked in polynomial time, QED.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "With all the available problems that have been categorized and their time complexities deduced, so why haven't anyone solved NP vs P yet?\r\n                \r\nWe have problems proved to be in classes P, NP, co-NP, NP-Complete, and NP-Hard. These problems have their time complexities deduced too. I am wondering if I am missing any key information on the topic.\n    ", "Answer": "\r\nOne of the standard tricks for solving this sort of problem is what's called using an \"oracle\".  Suppose we could ask the oracle a question about a specific class of problems, and in one step it would answer \"yes\" or \"no\".  It becomes reasonable to ask \"What sort of problems are in P for a machine with this oracle\"?  \"What sort of problems are in NP for a machine with this Oracle.\nIt has been shown that there are oracles for which P=NP.  It has been shown that there are oracles for which P≠NP.  Most of the techniques we know for proving hardness should give the same result, no. matter what oracle is used.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to prove a prob is np complete and is in np?\r\n                \r\nGiven a department needs a committee to select the department’s head. The committee cannot include people who have conflicts of interest with each other. The input consists of:\n\n\nthe desired committee size\na list of all people\na list of all pairs of people that are conflicted. \n\n\nThe goal is to determine whether there’s a conflict-free committee of that size.\n\nHow can I show that this problem is NP-complete and is in NP?\n    ", "Answer": "\r\nAs this is 99.99% homework, so I only give you a very brief \"answer\":\nTry to reduce\nIndepedent Set Decision Problem to your problem.\nAlso a useful note is that if you prove the problem is NPC, then it is NP\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If a NP solved in polynomial time, can Satisfiability solved in polynomial time\r\n                \r\nBased on the below link , I can know that solving of Satisfiability(NP Complete) in polynomial time means any other NP problem can be solved in polynomial time.\nBut is Vice - Versa true?\n\nAlso, If there is a polynimial for any other NP-Complete problemt does it mean , all the other NP-Complete can be solved in polynomial time?\n\nWhat are the differences between NP, NP-Complete and NP-Hard?\n    ", "Answer": "\r\nThe 'complete' in NP-complete means that if a problem is in NP-complete, a solution for that problem gives a solution to any problem in NP with a polynomial amount of conversion processing.\n\nIn layman's terms - if you solve a single NP-complete problem in polynomial time you have proven that NP = P.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is k -rainbow coloring of a hypergraph NP-complete or not?\r\n                \r\n**A hypergraph is k-rainbow colorable if there exists a vertex coloring using k colors such that each hyperedge has all the k colors. Is k-rainbow coloring of a hypergraph is NP-complete or not? The problem is also called \"polychromatic coloring\" **\n\nI looked at some reference papers such as \"Hardness of Rainbow Coloring Hypergraphs by Venkatesan Guruswami and Rishi Sakety\" and \"Strong Inapproximability Results on Balanced Rainbow-Colorable Hypergraphs by Venkatesan Guruswami and Euiwoong Lee\". But these are the only reference I found discuss the problem but the authors foucs on generating balance rainbow coloring for K-uniform hypergraph where each color has to appear the same number of times in the hypergraph. It has been proved that K-rainbow coloring for planer graph is P for K= 2 and NP complete for K=3,4 according to this reference \"Polychromatic Colorings of Plane Graphs\".\n\nMy question \" Is k-rainbow coloring of a hypergraph NP-complete or not?\" in general for any hypergraph. I think this problem is related to vertex cover problem.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete reduction\r\n                \r\nThe problem states that we want to show that Independent Set poly-time reduces to Relative Prime Sets, more formally ```\nIndependent Set <p Relative Prime Sets```\n.\n\nI need to provide a reduction f from ind.set to rel. prime sets, where\n\n- input of f must be a Graph G and an integer k, where k denotes the size of an independent set.\n\n- output of f must be a set S of integers and an integer t, where t denotes the number of pairwise relative prime numbers in the set S.\n\nDefinition of relative prime sets (decision version):\n\n\n  it takes a set P of n-integers and an integer t from 1 to n.\n  \n  returns yes if there's a subset A of P, with t-many pairwise relative\n  primes. That is, for all a, b in A, it must be true that gcd(a, b) =\n  1.\n  \n  returns no otherwise\n\n\nSo far I have come-up with what I believe is a reduction, but I am not sure if it is valid and I want to double check it with someone who knows how to do this. \n\nReduction:\n\n\n  Let G be a graph.Let k indicate the size of an independent set. Then we\n  want to find-out if there exists an independent set of size k in G.\n  Since this problem is NP-Complete, if we can solve another NP-Complete\n  problem in poly-time, we know that we can also solve Independent Set\n  in poly-time. So we chose to reduce independent set to Relative Prime\n  Sets.\n  \n  We take the graph G and label its vertices from 1 to n as pr the\n  definition of the input for relative prime sets. Then we find the gcd\n  of each node to every other node in G. We draw an edge between the\n  nodes that have gcd(a, b) = 1. When the graph is complete, we look at\n  the nodes and determine which nodes are not connected to each other\n  via an edge. We create sets for those nodes. We return the set\n  containing the most nodes along with an integer t denoting the number\n  of integers in the set. This is the set of the most relative prime\n  numbers in the graph G and also the greatest independent set of G.\n\n    ", "Answer": "\r\nSuppose two graphs, each of four nodes. On graph one, the nodes are connected in a line so that the max-independent set is 2. Graph two is a complete graph each node is connected to each other node, so the max-independent set is 1. \n\nIt sounds like your reduction would result in the same set for each graph, leading to an incorrect result for independent set. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Factorial-time algorithms and P/NP\r\n                \r\nIt's quite easy to see that n! grows slower than almost anything to the N power (say, 100^N) and so, if a problems is considered NP complete and one happened upon a n! algorithm that approximates the solution, one would do the Snoopy dance.\n\nI have 2 questions about this situation:\n\n\nWould the n! algorithm be considered a solution in polynomial time? A factorial certainly doesn't appear to be a term raised to a power.\nIf finding a n! solution means we have a decently fast algorithm and since n! grows faster than 2^N, then does this mean that some NP-complete problems do not need heuristic/approximation algorithms (except for obscure cases)?\n\n\nOf course, these two questions rely on the first paragraph being true; if I've erred, please let me know.\n    ", "Answer": "\r\n\nNo. factorial time is not polynomial time. Polynomial time normally means an equation of the form O(Nk), where N = number of items being processed, and k = some constant. The important part is that the exponent is a constant -- you're multiplying N by itself some number of that's fixed -- not dependent on N itself. A factorial-complexity algorithm means the number of multiplications is not fixed -- the number of multiplications itself grows with N.\nYou seem to have the same problem here. N2 would be polynomial complexity. 2N would not be. Your basic precept is mistaken as well -- a factorial-complexity algorithm does not mean \"we have a decently fast algorithm\", at least as a general rule. If anything, the conclusion is rather the opposite: a factorial algorithm may be practical in a few special cases (i.e., where N is extremely small) but becomes impractical very quickly as N grows.\n\n\nLet's try to put this in perspective. A binary search is O(log N). A linear search is O(N). In sorting, the \"slow\" algorithms are O(N2), and the \"advanced\" algorithms O(N lg N). A factorial-complexity is (obviously enough) O(N!).\n\nLet's try to put some numbers to that, considering (for the moment) only 10 items. Each of these will be roughly how many times longer processing should take for 10 items instead of 1 item:\n\nO(log N): 2\nO(N):10\nO(N log N): 23\nO(N2): 100\nO(N!): 3,628,800\n\nFor the moment I've cheated a bit, and use a natural logarithm instead of a base 2 logarithm, but we're only trying for ballpark estimates here (and the difference is a fairly small constant factor in any case).\n\nAs you can see, the growth rate for the factorial-complexity algorithm is much faster than for any of the others. If we extend it to 20 items, the difference becomes even more dramatic:\n\nO(log N): 3\nO(n): 20\nO(N log N): 60\nO(N2): 400\nO(N!): 2,432,902,008,176,640,000\n\nThe growth rate for N! is so fast that they're pretty much guaranteed to be impractical except when the number of items involves is known to be quite small. For grins, let's assume that the basic operations for the processes above can each run in a single machine clock cycle. Just for the sake of argument (and to keep the calculations simple) let's assume a 10 GHz CPU. So, the base is that processing one item takes .1 ns. In that case, with 20 items:\n\nO(log N) = .3 ns\nO(N) = 2 ns\nO(N log N) = 6 ns\nO(N2) = 40 ns\nO(N!) = 7.7 years.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Algorithm to maximize profit: ways to solve/approach? (Advanced NP-Complete)\r\n                \r\nThis one's hard, so all help really appreciated!\n\nI know it is NP-Complete and thus cannot be solved in polynomial time, but looking for help in analysis, what type of NP-Complete problem it reduces to, similar problems it reminds you of, etc.\n\nThe story goes as follows. I own an ice cream truck business with n trucks. There are m stops where I make deliveries. Each location mi has pi people waiting for me. After buying their ice cream, everyone leaves. pi increases over time as more people line up to get ice cream.\n\nHow can I figure out where to send the trucks next in order to maximize my profit in any given day?\n\nThings to keep in mind:\n\n\nTwo trucks that stop in the same spot at similar times will only get the profit once, i.e. the people leave after one truck arrives\nThe trucks take time to get from one location to another\npi increases over time at each stop, but some stops increase faster than others, i.e. some locations are near malls (location, location, location)\n\n\nI've tried reducing this to a multimachine scheduling problem, traveling sales person problem, ILP etc., but the main issue is that the pi at every location (i.e. the distance in the TSP or the job length in the scheduling problem) is constantly increasing.\n\nThanks in advance!\n    ", "Answer": "\r\nSounds like a variant of the Assignment Problem. So one approach you may not have considered is an Auction Algorithm (which has the advantage it can be parallelized easily) or Hungarian algorithm. \n\nI realize there are complications in your problem (there always are!) but the Auction algorithm is pretty flexible. You can have quite a complicated cost function between your trucks and customers. You can also tweak the algorithm to have multiple trucks service multiple customers subject to capacity constraints. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How a shortest path problem with negative cost cycles can be polynomially reduced to the Hamiltonian cycle problem to demonstrate NP-completeness\r\n                \r\nI know that if there are negative cost cycles in a graph, the relative shortest path problem belongs to the np-complete class. I need to prove this by performing a polynomial reduction using the Hamiltonian cycle problem. Could anyone explain it? It would be very helpful.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity for converting any propositional formula to CNF format\r\n                \r\nWhat is the complexity for converting any propositional formula to CNF format? Is it an NP-complete problem?\n    ", "Answer": "\r\nThe standard algorithm to transform a general Well-Formed Formula to an equivalent CNF has an exponential run time, since in the worst case a n-clauses WFF is equivalento to a 2^n-clauses CNF. \n\nHowever, you can transform in polynomial time an arbitrary boolean formula into a CNF that is not stricty equivalent, but satisfable only if the boolean formula is satisfable. This is the standard reduction used to prove that 3CNF is NP-complete, givent that the more general SAT is NP-complete. See here.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Non deterministic Polynomial(NP) vs Polynomial(P)?\r\n                \r\nI am actually looking for description what NP alogrithm actually means and what kind of algo/problem can be classified as NP problem\n\nI have read many resources on net . I liked\n\n\nhttps://www.quora.com/What-are-P-NP-NP-complete-and-NP-hard\nWhat are the differences between NP, NP-Complete and NP-Hard?\nNon deterministic Turing machine\nWhat are NP problems?\nWhat are NP and NP-complete problems?\n\n\nPolynomial problem :-\nIf the running time is some polynomial function of the size of the input**, for instance if the algorithm runs in linear time or quadratic time or cubic time, then we say the algorithm runs in polynomial time . Example can be binary search\n\nNow I do understand Polynomial problem . But not able to contrast it with NP.\n\nNP(nondeterministic polynomial Problem):-\n\nNow there are a lot of programs that don't (necessarily) run in polynomial time on a regular computer, but do run in polynomial time on a nondeterministic Turing machine.  These programs solve problems in NP, which stands for nondeterministic polynomial time.  \n\nI am not able to to understand/think of example that does not run in polynomial time on a regular computer. Per mine current understanding, Every problem/algo can be solved\nin some polynomial function of time which can or can't be proportional to time. I know i am missing something here but really could not grasp this concept. Could someone\ngive example of problem which can not be  solved in polynomial time on regular computer but can be verified in polynomial time ?\n\nOne of the example given at second link mentioned above is ```\nInteger factorization is in NP. This is the problem that given integers n and m, is there an integer f with 1 < f < m, such that f divides n (f is a small factor of n)?```\n why  this can't be solved in some polynomial time on regular computer ? we can check for all number from 1 to n if they divide n or not. Right ?\nAlso where verification part come here(i mean if it can be solved in polynomial time but then how the problem solution can be verified in polynomial time)?\n    ", "Answer": "\r\nIt's probably worth noting how the idea of \"checking a solution in polynomial time\" relates to a nondeterministic Turing Machine solving a problem: in a normal (deterministic) Turing Machine, there is a well-defined set of instructions telling the machine exactly what to do in any situation (\"if you're in state 3 and see an 'a', move left, if you're in state 7 and see a 'c', overwrite it with a 'b', etc.\") whereas in a nondeterministic Turing Machine there is more than one option for what to do in some situations (\"if you're in state 3 and see an 'a', either move right or overwrite it with a 'b'\"). In terms of algorithms, this lets us \"guess\" solutions in the sense that if we can encode a problem into a language on an alphabet* then we can use a nondeterministic Turing Machine to generate strings on this alphabet, and then use a standard (deterministic) Turing Machine to ensure that it is correct. If we assume that we always make the right guess, then the runtime of our algorithm is simply the runtime of the deterministic checking part, which for NP problems runs in polynomial time. This is what it means for a problem to be 'decidable in polynomial time on a nondeterministic Turing Machine', and why it is often simply phrased as 'checking a solution/ certificate in polynomial time'. \n\n*\nExample: The Hamiltonian Path problem could be encoded as follows:\n\nLabel the vertices of the graph 1 through n, where n is the number of vertices. Our alphabet is then the numbers 1 through n, and our language consists of all words such that \n\na) every integer from 1 to n appears exactly once\n\nand\n\nb) for every consecutive pair of integers in a word, the vertices with those labels are connected\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "theory about p, np problems\r\n                \r\nI am reading about P , NP and NP-Complete problems theory. Here is text snippet.\n\n\n  The class NP includes all problems that have polynomial-time\n  solutions, since obviously the solution provides a check. One would\n  expect that since  it is so much easier to check an answer than to\n  come up with one from scratch,  there would be problems in NP that do\n  not have polynomial-time solutions. To date no such problem has been\n  found, so it is entirely possible, though  not considered likely by\n  experts, that nondeterminism is not such an important improvement. The\n  problem is that proving exponential lower bounds  is an extremely\n  difficult task. The information theory bound technique, which we used\n  to show that sorting requires (n log n) comparisons,  does not seem to\n  be adequate for the task, because the decision trees are not nearly\n  large enough.\n\n\nMy question is what does author mean by\n\n\nby statement \"To date no such problem has been found, so it is entirely possible, though\nnot considered likely by experts, that nondeterminism is not such an important improvement.\" ?\nAnother question what does author mean by in last statement by \"because the decision trees are not nearly large enough.\" ?\n\n\nThanks!\n    ", "Answer": "\r\n(1) I think the author means that no NP problem has been found, for which it is proven that it is not in P. Certainly there are problems in NP for which no polynomial solution is known, but that's not the same as knowing that none exists.\n\nIf in fact ```\nP = NP```\n (that is to say, if in fact there are no NP problems that don't have a polynomial solution), then in some sense a nondeterministic machine is no \"more powerful\" than a deterministic machine, since they solve the same problems in polynomial time. Then we'd say \"nondeterminism is not such an important improvement\".\n\n(2) The way that the ```\nn log n```\n proof works is that there are ```\nn!```\n possible outputs from a sorting function, any one of which might be the correct one according to what order the input was in. Each comparison adds a two-legged branch to the tree of all possible states that a given comparison sort algorithm can get into. In order to sort any input, this \"decision tree\" must have enough branches to produce any of the ```\nn!```\n possible re-orderings of the input, and hence there must be at least ```\nlog(n!)```\n comparisons. So, the lower bound on runtime comes from the size of the tree.\n\nThe author is saying that there are no known NP problems for which we've proved they require a tree so large that it implies a lower bound that is super-polynomial. Any such proof would prove ```\nP != NP```\n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why using linear integer programming (ILP) though it is NP-Complete?\r\n                \r\nThe question may be stupid but it really confuses me for a long time.\n\nI read a lot of papers in wireless sensor network. Many researchers model their problems into the form of ILP. However, ILP is NP-Complete so it is not efficient for solving a problem.\n\nSo why people write their problems into the form of ILP? Do they do that to make their problem clear to see and easy to understand? Or do I make some mistakes understanding the relations between ILP and NPC?\n\nI am really appreciated that you can help me to solve this question.\n    ", "Answer": "\r\nAlthough the question might be considered off-topic, there are basically a few points to address.\n\n\nYou are right that general integer linear programming is ```\nNP```\n-hard.\nIf a specific problem needs to be solved and general integer linear programming is the most specific way to formulate it, then nothing can be done about it; some problems are just hard to solve.\nIn some cases, it is possible to use the LP relaxation instead, either as a heuristic or some approximation ratio can be proven.\n\n\nThe key point here is that integer linear programming is a widespread formalism for expressing problems. Basically I understand your question as the follwing one.\n\n\n  \"Why do people use a model that is algorithmically hard to solve to\n  describe practical problems?\"\n\n\nWell, if that shortcoming could be circumvented in general, it would be a good idea to express every problem there is in terms of sorting, which is algorithmically easy.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this geometric cover NP-Complete and how can I prove it?\r\n                \r\nI have the following problem which I believe to be NP-Complete but I would like to prove it to be so:\n\nGiven a set of M points on a plane where circles can be centered and a set of N points which need to be covered by the circles, find the minimum area circle cover for the points. That is, find the radii of the circles and the centers (chosen from the M points) such that all the N points are covered and the total area of the circles is minimized. A given point is covered if it is inside at least one circle in cover.\n\nI have been looking through various geometric cover NP-Complete results but they all involve using polygons for cover.\n\nAny ideas of a suitable problem that this can be reduced to? \n\nThanks in advance for any clues. \n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Prove for every i includes exactly 3 vertices in the path from subset Ti is NP-Complete\r\n                \r\nThe directed graph G is given. Several subsets of vertices are specified – T1, . . . , Tk (these subsets could intersect). Does there exist a path in G which\n• does not contain cycles\n• and for every i includes exactly 3 vertices from Ti?\nProve that this problem is NP-complete.\nI am considering from 3SAT reducing to this problem to prove it is NP-Hard, but I don't know how...\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reducing from Vertex Cover to prove NP-complete\r\n                \r\nWe define ROMAN-SUBSET as the following problem:\n\n\n  INPUT: Directed graph  G = ( V , E )  and a positive integer  k\n  \n  OUTPUT: If there is a subset  R  of  V  such that  | R | <= k  , and\n  such that every directed circuit in G includes at least one vertex\n  from  R , then the output should be \"TRUE\", otherwise, it should be\n  \"FALSE\".\n\n\nAssuming that the Vertex Cover (VC) problem is NP-complete, I must prove that ROMAN-SUBSET is also NP-complete. From what I understand, that means taking the VC input, modifying it, and then showing that plugging it into the ROMAN-SUBSET algorithm will yield the result of the VC problem.\n\nI'm having a really tough time coming up with the transformation. I know that the VC input is a graph G and an integer k, and the problem is whether or not there exists a subset R of V that covers every edge in G, such that |R| <= k. So clearly, the R and k are similar from ROM to VC, but my difficulty is identifying how to transform the graph so that 1 vertex in every directed cycle (for ROM) corresponds to every edge (for VC). How can I go about modifying the graph to prove that VC can be reduced to ROM?\n\nThanks!\n    ", "Answer": "\r\nHere is the construction.\n\nTake undirected graph ```\nG = (V, E)```\n as in VC.\nNow define the directed graph ```\nG1 = (V, E1)```\n, where for every edge ```\n(u,v)```\n in ```\nE```\n there are two edges ```\n(u,v)```\n and ```\n(v,u)```\n in ```\nE1```\n.\n\nIn other words the new graph is the same as the old one, but every undirected edge is replaced with two directed edges that form a 2-cycle.\n\nThe claim is that from ROM on ```\nG1```\n follows VC on ```\nG```\n.\n\nIndeed, suppose that the answer for ROM on ```\nG1```\n is FALSE. Then for every choice of a set of less than ```\nk```\n vertices there exists a cycle not in this set. So there exists an edge whose endpoints are not in the set. But this means that for the same choice of the set of less than ```\nk```\n vertices in ```\nG```\n there exists an edge whose endpoints are not in the set, so VC's answer is FALSE.\n\nConversely, suppose that the answer for ROM on ```\nG1```\n is TRUE. Then there exists a subset of ```\nV```\n containing less than ```\nk```\n vertices, so that given any cycle there exists at least one vertex in the cycle, which is in the set. But this means that for any edge in ```\nE```\n one of its endpoints in in the set, because an edge in ```\nE```\n corresponds to a 2-cycle in ```\nE1```\n. Thus the answer for VC is TRUE.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to prove that the language $E_{tm}$ is $NP-Hard$\r\n                \r\nConsider the language $E_{tm}={ \\langle M \\rangle: M\\text{is a Turing Machine that accepts nothing}$ \n\nI am not sure how to even start.\nMy idea is to provide poly time reduction from some NP - Complete problem.\nE_tm\n\nWhat I don't understand is that, knowing that E_tm is not decidable, but NP-Hard class is decidable. \n    ", "Answer": "\r\nsolution:\n\nDF:  A problem is NP-hard if all problems in NP are polynomial time reducible to it, even thoughit may not be in NP itself ( p326 Sipser) (the only definition our book has  ).\nFor any language L' that is in NP if we show that we can poly-time reduce to Etm.\nThis will prove that that Etm is NP - hard.\nSince L' is in NP by definition there exist a TM ( NTM but since they are equivalent in power I write TM ) M' such that decides L'.\n\n```\nTM M'' that takes as an input <M,w> constructs\nTM M' such that\n on arbitrary x\nif w = x\n  run M on w if accept => reject\n                     if reject => accept\nelse reject.\n```\n\n\nTherefore M accepts w iff M'' rejects all the input.\nLet's confirm that. First assume that M accepts w, then M'' reject on any input therefore L(M'') = empty.\nNow assume that M rejects w, then M'' accept, therefore L(M'') is not empty.\nNote that to construct the M'' takes polynomial time.\nThat completes the proof.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP hard but not NPC\r\n                \r\nI have seen couple of scheduling problem which says that the problem is NP hard. My question is that \n1)when we say a problem is NP hard does it mean that it is not in NP?because if it is NP we say the problem is NP complete.\nI know that a problem is in NPC if\na)it is in NP\nb)it is NP hard.\n    ", "Answer": "\r\nIf a problem is NP Hard, it may be in NP(then it's a NP complete), but it could also be not in NP. The following is a Venn diagram of these classes:\n\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is the problem of finding the simple path with maximum cost in a weighted undirected graph with the same number of vertex and edges NP-Complete?\r\n                \r\nHello and thanks again for reading this.\n\nI need to know now if the problem of finding the simple path with maximum cost in a weighted undirected graph with the same number of vertex and edges is NP-Complete or not?\n\nInput: Graph G = (V,E) with V (vertex) = E (edges)\n\nOutput: The cost of the most expensive path in the graph G.\n\nCould you provide any reference to an article where I can review this.\n\nThank you very much for your time.\n\nSincerely,\n\nAlex.\n    ", "Answer": "\r\nIf the graph is not necessarily connected,  then any instance of the longest path problem can be reduced to this problem by adding extra isolated vertices to the input graph to make the number of nodes and edges the same.  If this isn't thyroid case, and the graph must be connected, then the input graph must have exactly one cycle, since a graph with n-1 edges is a tree.  IF you find this cycle with a DFS and contract it to a single node, you then have a tree.  It's easy to do longest path computations here; just consider all pairs of edges and get the cost of the unique path between them.  If you take this path ans then expand it in the original graph by walking around the cycle where you originally went through the contracted node, I think you get the longest path in polynomial time.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Np completeness - Need some clarification in reduction\r\n                \r\nI wanted some clarification in a concept.\nFor proving that a problem is NP complete, we use reductions. \n\nNow suppose I have L<=L'. has the reduction to be from L to L' or can I do it it the reverse way also? i.e Can I show that if L can be solved using L', then L' is NP-complete??\n\nI am pretty confused regarding this.\n\nFor example. for a reduction from ham cycle to ham path, we so it the backward way.\n\nAlso, I am not able to solve the problem that I have to show that \"is there a path from s to t in a graph with at least k edges\" by reduction from ham cycle. \n\nPlease give me a clarification and guide me with the above problem. Thanks\n    ", "Answer": "\r\nTo show that a language L is NP-complete you actually need to prove two things, L is in NP and L is NP-hard. Usually, proving L is in NP is easy, but don't forget to do it.\n\nThe normal way of showing L is NP-hard is to show, in effect, that a polynomial-time decider for L could be used to build a polynomial-time decider for a language L' that has been proved to be NP-complete.\n\nIt has to be that way round. There are many cases of a polynomial-time decidable language L for which a polynomial time decider could be built from a polynomial time decider for an NP-complete language. For example, consider the polynomial time decidable problem of coloring a graph with two colors, vs. the NP-complete general graph coloring problem.\n\nI gave you a hint in a comment on your question about Hamiltonian Cycle. Have you read the hint and thought about it? If so, please respond in that question.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Cook's Theorem (in plain English)\r\n                \r\nI read the book Computers and Intractability - A Guide to the Theory of NP-Completeness by Garey and Johnson for my algorithms course; however, upon reviewing the material a year later, I realized that I never really understood Cook's Theorem.  \n\nIn regards to the proof, I understand why SAT is first shown to be in NP first (first requirement of NP-complete), but am struggling through the technicalities of showing that the \"other\" NP-complete problems under a \"genetic\" polynomial transform to SAT.  \n\nI was wondering if someone could explain this in a more watered down manner, that would perhaps clarify an additional reading of this section.  \n    ", "Answer": "\r\nThe proof that SAT is NP-hard (that is, that there's a polynomial-time reduction from every NP problem to SAT) is nontrivial. I'm going to try to give an intuition for how it works, but I'm not going to attempt to go over all the details. For that, you probably want to consult a textbook.\n\nLet's start off by taking any NP language L. By definition, the fact that L is an NP language means that there is a nondeterministic, polynomial-time Turing machine M for the language L. This means that the machine M accepts a string w if and only if w belongs to L, and on top of this the runtime of M is some polynomial p(n). The reduction from L to SAT will work by showing that you can build a propositional formula that essentially simulates the operation of M on some particular string w. That formula has the property that M accepts w (that is, w belongs to L) if and only if the resulting propositional formula is satisfiable.\n\nIt's not at all clear that it's possible to do this at all. To see how it works, we'll use a standard technique for reducing problems involving TMs to one another. Think about the operation of M on the string w. Since M is a Turing machine, when we start up M with w, it begins with w written on the tape (surrounded by infinitely many blanks), in some state q0, and with the tape head over the first character of w. Each step of the Turing machine causes the machine to move the tape head left or right, to replace the symbol under the tape head, and to move the tape head left or right.\n\nRight before each step of the TM, we can take a \"snapshot\" of the state of the machine. That snapshot will include the tape after trimming off the infinitely many blanks from both sides, the position of the tape head, and the current state of the TM. This \"snapshot\" is more properly called an instantaneous description or ID of the machine. You can think of it as a tuple of (tape contents, state, position).\n\nBecause M is a polynomial-time NTM, we know that it can't run for more than p(|w|) steps when run on the input string w, where p is some polynomial. Therefore, when M runs, the computation will have at most p(|w|) + 1 instantaneous descriptions, one for each step. Consequently, you can think of any execution of M as a series of this ID's, written out one after the other, as (tape0, state0, position0), (tape1, state1, position1), ..., (tapeK, stateK, positionK).\n\nTwo observations are in order about these IDs. First, these IDs can't be totally arbitrary. We know what the first ID is going to be - it's going to be an ID where the tape holds w, the state is q0, and the tape head is over the start of string w. As a result, there are only a few possible choices for what the second ID will be, based on each of the nondeterministic choices that the TM can make for its first step. Similarly, the number of choices for the third ID is finite, since that ID has to be formed by starting with some legal second ID and applying one move of the TM. More generally, each ID has to follow from a legal TM move starting with the previous ID.\n\nSecond, notice that if M accepts w, then there is some possible chain of IDs such that the last ID in the chain will be on in which the state is the machine's accepting state. Conversely, if M doesn't accept w, then no possible chain of IDs will legally end with the machine in accepting state.\n\nThe reduction from L to SAT therefore works by, essentially, building up a gigantic propositional formula. Each variable corresponds to some piece of one of the IDs in the chain (either the contents of some specific tape cell, or what state the machine would be in, or where the tape head would be). The formula then encodes the rules about the IDs: the first ID has to be one where the machine starts up state q0 with the tape head scanning the first character of the input string w, each ID has to follow from the previous one, etc. There's one last part to the formula - the machine has to end in an accepting state. Actually building up all of these pieces of the formula is pretty tricky (that's why you should look at a textbook). However, the net result is that if the formula is satisfiable, there's a series of IDs that show that M accepts w (so w is in L(M)), and if it's unsatisfiable then there is no way for M to accept w.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this a special case of the NP-complete set packing?\r\n                \r\nI'm almost certain that my problem is equivalent to set packing, and thus, NP-complete, but I would like someone to verify.\n\nI have the following situation:\nThere is a set of pens (i.e. universe).\nA store sells bundles of these pens, which are subsets of that universe.\nI know a guy who has certain pens (also a subset of the universe) from the store, but I have no idea which bundles he bought.\nHe might have lost some pens and gotten others from other bundles that his friends gave him.\n\nWhat I want to do is map the bundles sold by the store into the subset of pens that my friend has so that I cover the highest amount of pens and the chosen bundles must not contain any pen which my friend doesn't have.\nFor example:\n\n```\nPossible Pens: {0, 1, 2, 3, 4, 5}\nBundles sold by store: {0, 1} | {0, 1, 2} | {2, 3} | {3} | {3, 4, 5} | {4, 5}\nMy friend has: {0, 1, 2, 3}\nHere, there are perfect matches: {{0, 1, 2}, {3}} and {{0, 1}, {2, 3}}. \nThese would be equivalent\n\nFriend 2 has: {0, 2, 3}\nIn this case, there is no perfect match.\nPossible matches are {{3}} and {{2, 3}}.\nThe best match is {{2, 3}}.\n```\n\n\nI this problem NP-complete given a number ```\nm```\n of pens, a number ```\nn```\n of bundles and a number ```\nl```\n of my friend's pens ?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Booking System is NP Complete\r\n                \r\nI have to show that the following problem is NP-Complete and need some helpful hints on how to proceed. \n\nThe problem:\n\nWe're looking at a meeting booking system. The input is a list n of possible times as well as m lists (where m <= n), one list per person containing their choice of possible meeting times. For each possible time, a priority number is also given. For each reservation time in the list of n, a cost is also given. (Cost of booking the room). The algorithm should assign times so that the combined priority for those who have booked should be as small as possible while the total cost of booking should not be higher than M. \n\nNP\n\nSo first to show that it's in NP we should show that given a correct solution it can be verified that it is indeed correct. I guess it should verify that that the cost is below the threshold of K and that the priority of the correct solution is indeed the minimum - both of which can be done in Polynomial time I assume. We traverse through the lists of people, assert that each one has a time granted to them, add up the cost in a variable and at the end of this list assert that the cost is below K. The priority can be dealt with in similar fashion I suppose? \n\nNP Hard\n\nThen to show it's NP Hard I can use the Knapsack Problem since they're rather similar. With input S, size of bag, a list of items with weight w and value v as well as the goal W which is the goal-value. I guess it's clear that S can correlate to cost and that W correlate to the priority? So we want S, the size, to be below S i.e we have the similar condition for the problem above where the cost has to be below K. Then W, the total value should generally exceed W, but in our case we want it to be as low as possible which seems doable.\n\nI'm afraid I might've gone the wrong way when it comes to verifying the problem. Also the reduction to show it's NP Hard is perhaps not thought out all the way. Some pointers would be very helpful! Thanks\n    ", "Answer": "\r\nNP\n\nWhen you are proving the problem is in NP, you must first turn your problem into a decision problem. Then you can verify your certificate in polynomial time as you started to describe.\n\nNP Hard\n\nYou need to transform the Knapsack problem into your meeting problem. You are going the right way because you are transforming size and weight from Knapsack into the meeting problem. Once you figure out the transformation, you must verify that it can be done in polynomial time. Finally, you can show that the solution to Knapsack is a solution to meeting problem and vice versa.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "3 partition np completeness\r\n                \r\nI want to know how 3 partition problem is NP complete ? We have to find triplets in set which sums to target. So isn't time complexity will be O(n^3) which is polynomial ?\nsolution: https://www.geeksforgeeks.org/find-a-triplet-that-sum-to-a-given-value\noriginal question: https://en.wikipedia.org/wiki/3-partition_problem\nAlso, can someone explain the reduction from partition to 3 partition by example.\n    ", "Answer": "\r\nThe problem is not to find a triplet (which would be O(n^3)) but a way to split the set into triplets which all have the same sum; the brute-force approach would be to test all such partitions, which would not be polynomial.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proof of np-completeness\r\n                \r\nShow that the following problem is NP-complete.\n\n\n  The tv problem is to select tv shows for a weekly tv night so that\n  everyone in a group of people sees something that they like. You are\n  given a list of people (P1, . . . , Pn) in the group and a list of\n  possible shows (S1, . . . , Sk). For each show Si, there is a subset\n  of the people who would like that show choice. You also get w, the\n  number of weeks for which you can select shows. The question is\n  whether there are these many movies so that every person likes at\n  least one of them.\n\n\nI can't figure out which np problem can be reduced to this and how to establish the certificate. \n    ", "Answer": "\r\nYou can model this as the Set cover problem. You have elements {P1, ..., Pn}, and k subsets of these, T1, ..., Tk, defined as Ti = {Pj : Pj likes Si}. You then want to find the smallest collection of subsets such that their union is the whole set of people. Deciding whether the number of necessary subsets is less than or equal to a number is NP-complete. Finding the actual optimal collection of subsets is NP-hard.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Some inference about NP [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 8 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nthis is my first question on this site. \n\nI‌ recently, study on NP. I have some confusion about this Topic, and want to propose my inference and some one verify me.\n\n\n  I) each NP problem can be solved in Exponential Time. \n  \n  II) if P=NP then NP=NP-Complete.\n  \n  III) Problem of factorization into 2-prime factor, is NP.\n  \n  IV) if problem X can reduce to a known NP-Hard problem, then X must be\n  NP-HARD.\n\n\nanyone can verify my inference and learn me?‌ \n    ", "Answer": "\r\n\n  I) each NP problem can be solved in Exponential Time.\n\n\nYes, this because it can be solved in polynomial time on Non Determinisitc Machine (definition of NP), and thus can be solved on a Deterministic Machine in exponential time.\n\n\n  II) if P=NP then NP=NP-Complete.\n\n\nYes, because if P=NP, \"yes\" and \"no\" answers for all NP problems are equivalently easy to achieve, run the polynomial time algorithm for the \"yes\" problem, and answer like it. Result is always correct and runs in polynomial time, assuming such a polynomial time machine exists.\n\n\n  III) Problem of factorization into 2-prime factor, is NP.\n\n\nYes. Given an number and its prime factorization - it is easy to verify if this is the correct answer (this is equivalent definition of problem being in NP).\n\n\n  IV) if problem X can reduce to a known NP-Hard problem, then X must be\n  NP-HARD.\n\n\nNo, it should be the other way around. You need to reduce a known NP-Hard Problem to X, and then you can tag X as NP-Hard.\nRememeber that every problem in NP has a reduction to SAT (Cook Levin theorem), and yet P != NP-Complete (or so we think at least)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Polynomial time algorithm for a NP-hard [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 11 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\n\n  Possible Duplicate:\n  NP vs NP-Complete vs NP-Hard — what does it all mean?  \n\n\n\n\nEuler circuit problem can be easily solved in polynomial time\nHamilton circuit problem is proved to be NP-hard\nnobody in the world can give a polynomial time algorithm for a NP-hard problem\n\nWhat is meant by polynomial time and NP-hard? I know what is O(n).\n    ", "Answer": "\r\nPolynomial time means that there exist a constant ```\na```\n, such that the complexity of your algorithm is ```\nO(n^a)```\n.\n\nHere is an explanation about ```\nNP-hard```\n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Coin distribution exercise - is it NP-Complete?\r\n                \r\nI want to know if the following problem is NP-Complete or if there's a specific algorithm that solves it:\n\nImagine you have a certain amount of money, 30€ for example, in coins and bills of specific values (0.01€, 0.05€, 5.00€...). \n\nThe quantity of the coins and bills we have is given and you have to distribute it amongst some people A, B, C, etc.\n\nYou want A to have a certain amount of money (10€, for example), B to have a different or equal amount, and so on. \n\nThe sum of the \"demanded\" money is not greater than the money we have.\n\nSo, the question is: ```\nis there a distribution of coins and bills such that every person has the quantity of money that belongs to him?```\n\n\nThanks in advance!\n    ", "Answer": "\r\nOne can reduce instances of this problem to Bin Packing (by having A=B=C=...) or to Knapsack (by having only A and B, with B=total-A). Both Bin Packing and Knapsack are known to be NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this \"Valid mathematical expression\" problem P, or NP?\r\n                \r\nThis question is purely out of curiosity. I am off school for the summer, and was going to implement an algorithm to solve this just for fun. That led to the above question, how hard is this problem?\n\nThe problem: you are given a list of positive integers, a set of mathematical operators and the equal sign(=). can you create a valid mathematical expression using the integers (in the same order) and the operators (any number of times)? \n\nAn example will should clarify any questions:\n\ngiven: {2, 3, 5, 25} , {+, -, *, /} , {=}\n   output: YES\n\nthe expression (only one i think) is (2 + 3) * 5 = 25. you only need to output YES/NO.\n\nI believe the problem is in NP. I say this because it is a decision problem (YES/NO answer) and I can find a non-deterministic poly time algorithm that decides it. \n\na. non-deterministically select a sequence of operators to place between the integers.\n   b. verify you answer is a valid mathematical expression (this can be done in constant\n      time). \n\nIn this case, the big question is this: Is the problem in P? (i.e. Is there a deterministic poly time algorithm that decides it?) OR Is the problem NP complete? (i.e. Can a known NP Complete problem be reduced to this? or equivalently Is every NP language poly time reducable to this problem?) OR neither? (i.e. problem in NP but not NP Complete)\n\nNote: This problem statement assumes P not equal to NP. Also, although I am new to Stack Overflow, I am familiar with the homework tag. This is indeed just curiosity, not homework :)\n    ", "Answer": "\r\nAn straightforward reduction from the Partition problem (which is NP-Complete) - given a set of N integers S, the input to the \"Valid Math\" problem would be - the elements of S, N-2 '+' operators and an '=' sign.  \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Trying to proof NP-completeness\r\n                \r\nImagine I have an equation like\n\nA + B + C + D + E + F + G + H + … = Some Value\n\nAnd every summand has an upper limit\n\nA ≤ 500,\nB ≤ 200,\nC ≤ 300,\nD ≤ 600,\n…\n\nIf i want a program to determine every possible combination of the summands, would the problem be NP-complete?\nHow would the mathematical proof look like?\n\nIf not, how would an efficient algorithm for this problem look like?\n    ", "Answer": "\r\nTo determine whether the problem is NP complete, you must first figure out if it is in NP. We need to create a decision question from the problem. \n\nIf you wanted to set a limit on the sum without actually having to determine all the combinations of the summands, the decision question could be: Are there limits for A, B, C... such that the sum is ≤ k? Then your certificate could be a set of limits on the summands.\n\nHere, the decision question is unclear and a certificate cannot be verified. This problem, as it is phrased, is not in NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "understanding this NP-complete optimization?\r\n                \r\nHas anyone seen this problem before? It's supposed to be NP-complete.\n\n\n  We are given vertices V_1,...,V_n and possible parent sets for each vertex. Each parent set has an associated cost. Let O be an ordering (a permutation) of the vertices. We say that a parent set of a vertex V_i is consistent with an ordering O if all of the parents come before the vertex in the ordering. Let mcc(V_i, O) be minimum cost of the parent sets of vertex V_i that are consistent with ordering O. I need to find an ordering O that minimizes the total cost: mcc(V_1, O), ... ,mcc(V_n, O).\n\n\nI don't quite understand the part \"...if all of the parents come before the vertex in the ordering.\" What does it mean?\n    ", "Answer": "\r\nNo, I haven't seen that problem before. \n\nAs for the bit you're not sure about - an ordering is just an order of all the vertices, so I think \"if all the parents come before the vertex in the ordering\" just means exactly what it says. For instance, say (A, B) is one parent set of D: that parent set is consistent with the ordering [A,B,C,D], since A and B are before D, and not consistent with the ordering [A,D,B,C], since B is after D; however, say (A) is another parent set of D - that one is consistent with both those orderings.  Does that make sense?\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity class of problems solvable in polynomial-time which are not decision problems\r\n                \r\nComplexity class P ~ set of all decision problems that can be solved by a deterministic Turing machine in polynomial time.\nA decision problem is a problem which can be stated as a yes/no question.\n\nSo how would you formally classify problems such as:\n\n\nfind the maximum number in an unsorted list of length n?\nwhat is the shortest path in a weighted, undirected graph?\n\n\nClearly these problems can be solved in polynomial time, but they are not decision problems. \n\nThis however is different for NP-complete versus NP-hard problems. Example (TSP):\n\n\nTSP (decision version): does there exist a tour that visits all cities, and costs less than L? (NP-complete)\nTSP (optimization version): what is the shortest tour that visits all cities? (NP-hard).\n\n\nIn other words, the class of NP-hard problems is not restricted to decision problems; it can also contain search or optimization problems. So why do most (all?) definitions of complexity class P limit the definition to decision problems?\n    ", "Answer": "\r\nBecause any optimization problem can be converted into multiple decision problems in P. If your question is what is the shortest tour that visits all cities, you can convert this into n decision problems. \n\nDoes there exist a tour that visits all cities, and costs less than n?\n\nDoes there exist a tour that visits all cities, and costs less than n-1?  \n\nDoes there exist a tour that visits all cities, and costs less than n-2? \n\nBecause there are at most n different options, converting an optimization problem into a decision problem can take place in polynomial time. Therefore, if a decision problem is in P, the corresponding optimization problem is also in P.\n\nAlso, an NP-complete problem is just an NP-hard problem that is also in NP. It has nothing to do with whether or not the problem is a decision problem or an optimization problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are virtually all major distributed computing projects attempting to solve problems in NP? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs to be more focused. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\r\n                \r\n                    \r\n                        Closed 8 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nHere's a huge list of distributed computing projects: http://distributedcomputing.info/projects.html\n\nAfter a quick skim, I couldn't find any projects which weren't attempting to solve problems in NP (the search problem version). Does anyone know of any projects tackling things outside of NP?\n\nAlso, are there any distributed computing projects that are attempting to solve problems in classes faster than NP, like in P perhaps?\n\nI'm trying to figure out if there's some very general class of search problem which all or virtually all major distributed computing projects are polynomial-time reducible too. I wonder if the answer to this question is \"anything that's NP-complete.\"\n\nI wasn't sure if this should be on here, but since it involves understanding real-world software, I thought it would be within scope.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Radix Sort is an example of complexity algorithm P or NP?\r\n                \r\nThe problem of ordering a vector by Radix Sort is an example of a complexity algorithm P?\n\nI do not know if it can be NP-Complete or just NP.\n\n```\nvoid radixsort(int vector[], int size) {\n    int i;\n    int *b;\n    int bigger= vector[0];\n    int exp = 1;\n\n    b = (int *)calloc(size, sizeof(int));\n\n    for (i = 0; i < size; i++) {\n        if (vetor[i] > bigger)\n            size= vector[i];\n    }\n\n    while (bigger/exp > 0) {\n        int bucket[10] = { 0 };\n        for (i = 0; i < size; i++)\n            bucket[(vetor[i] / exp) % 10]++;\n        for (i = 1; i < 10; i++)\n            bucket[i] += bucket[i - 1];\n        for (i = size- 1; i >= 0; i--)\n            b[--bucket[(vector[i] / exp) % 10]] = vector[i];\n        for (i = 0; i < size; i++)\n            vector[i] = b[i];\n        exp *= 10;\n    }\n\n    free(b);\n}\n```\n\n    ", "Answer": "\r\nOf course, it is in P! as its complexity is polynomial. Answer the other questions is related to the relation of these class of complexities. P is in NP. Hence, radix sort is in NP. As we do not know any polynomial agorithm for NP-Complete problems, hence, we do not know it is in NP-Complete or not and it is related to the known problem that is P = NP?\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is it NP-complete to find a sub-maximal clique which is at least max clique size - 1?\r\n                \r\nIt is well-known that it is a NP-complete problem to find a maximal clique in a graph. But I wonder know if it possible to find a sub-maximal clique in a graph in polynomial time. That is, given that we don't know whether ```\nP=NP```\n or not, is there a polynomial algorithm that would give me a clique whose size is at least the maximal clique size minus 1?\nI guess the answer is \"no\", because I know that there isn't a polynomial-time algorithm that gives me a clique whose size is exactly maximal clique size minus 1 - otherwise I would know the size of max clique by this algorithm in polynomial time, which is impossible if ```\nP!=NP```\n.\nBut I just don't know how to prove it when we expect the algorithm to return a clique with size at least maximal clique size minus 1 - say, it may randomly return a clique, whose size may be maximal, or may be maximal-1.\nIs there any approach to prove its NP-completeness? Or such an algorithm really exists?\n    ", "Answer": "\r\nI just got the answer by myself. The maximal clique problem can be reduced to this problem.\nGiven a maximal clique problem with graph ```\nG```\n, we can duplicate the graph ```\nG```\n to a new graph ```\nG'```\n. Then combine the two graphs in the following manner: if there is an edge between two vertices in graph ```\nG```\n, connect each pair of the two vertices in ```\nG```\n and ```\nG'```\n; and for each vertex in ```\nG```\n, connect it and its duplication in ```\nG'```\n.\nThen, each clique in ```\nG```\n of size ```\nm```\n with its duplication in ```\nG'```\n consist of a larger clique of size ```\n2m```\n. So, there is a clique of size ```\nm```\n if and only if there is a clique of size ```\n2m```\n in ```\nG'```\n.\nSo, to find the maximum clique in ```\nG```\n, we just find the sub-maximum clique in ```\nG'```\n and the clique must contains all vertices in the maximum clique of ```\nG```\n. Thus, we know the maximum clique in ```\nG```\n in polynomial time, which is only possible when ```\nP=NP```\n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete Graph optimization: minimal node selection?\r\n                \r\nSuppose you have a graph ```\nG = (V, E)```\n that represents the floor plan of a one-story shopping mall.  The individual stores are represented by vertices, and the edges between vertices represent some arbitrary definition of stores being close to each other.\n\nRecently, there has been an increase in the amount of shoplifting that occurs in this mall, so management decides to make it so that every store either:\n\n\nHas a security guard stationed in it\nOr is close to a store that has a security guard stationed in it\n\n\nWhile hiring as few security guards as possible.\n\nHow would you prove this optimization problem is NP-complete?  I feel like it's a simple reduction from the independent set problem, but I want to make sure.\n    ", "Answer": "\r\nThis is exactly the minimum vertex cover problem which is known to be NP-complete. The key insight in seeing that computing the size of a minimum vertex cover is equivalent to computing the size of a maximum independent set is the following:\n\n```\nA set of vertices is a vertex cover, if and only if its complement is an independent set.```\n\n\nIn particular, this means that the total number of vertices is equal to the size of a minimum vertex cover plus the size of a maximum independent set. This illustrates nicely how computing one number reduces to computing the other.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reducing 3-Coloring to 10-Coloring (NP-completeness)\r\n                \r\nI am trying to show that the NP-Complete problem of 3-coloring a graph reduces to the problem of 10-coloring a graph.I have already shown how 10-coloring can be verified in polynomial time, and is thus in NP. Now I just need to show it indeed can be reduced to 3-coloring.\n\nMy thinking was to essentially prove a bi-conditional: given a graph G, we have that G has a 3-coloring iff G has a 10-coloring. Now, I am not sure how to go about showing this since, fairly obviously, G could have a 10-coloring and not a 3-coloring. So this leads me to believe that there must be some reduction that alters G in some way that lets me see that, yes, 3-coloring does reduce to 10-coloring. Problem is, I am having a difficult time visualizing this.\n\nCan anyone help me out?\n    ", "Answer": "\r\nTake your given Graph ```\nG```\n and complement it with an instance of ```\nK_7```\n such that for each vertex pair ```\n(u, v) \\in G x K_7```\n an edge be added to form a new Graph ```\nG'```\n. This enhancement can obviously be done in polynomial time.\n\n\nIf ```\nG```\n is 3-colorable, ```\nG'```\n is 10-colorable:\nTake a 3-coloring of ```\nG```\n, use 7 other colors to color the ```\nK_7```\n instance.\nIf ```\nG```\n is not 3-colorable, ```\nG'```\n is not 10-colorable:\nThe instance of ```\nK_7```\n in ```\nG'```\n consumes 7 colors. None of these colors may occur in ```\nG```\n, as there is an edge between each pair of vertices from ```\nG```\n and the ```\nK_7```\n instance, respectively. \nConsider an arbitrary 3-color assignment on ```\nG```\n. Since ```\nG```\n is not 3-colorable, there must be edges ```\n((x_i, y_i)_i=1..m```\n whose vertices are given the same color under this assignment.\nAssume that we re-color all vertices ```\n{x_i, y_i}_i=1..m```\n simultaneously. However, no vertex' new color may be among the colors used for the ```\nK_7```\n instance nor among the 3 colors used for vertices of ```\nG```\n ( in the latter case the assignment restricted to ```\nG```\n still would not be admissible after the recoloring). Therefore we would need an 11th color.\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reduction of A to B : True or False\r\n                \r\nThere are two statements:\nIf a decision problem A is polynomial-time reducible to a decision problem B (i.e., ```\nA≤ pB```\n ), and B is NP-complete, then A must be NP-complete.\n\nAnd: \n\nIf a decision problem B is polynomial-time reducible to a decision problem A (i.e., ```\nB≤ pA```\n ), and B is NP-complete, then A must be NP-complete.\n\nWhich of the above statements are true?\n\nCan you also give explanation?\n    ", "Answer": "\r\nthe first statement is false because it means that by solving B and then applying some polynomial time algorithm you can solve A but maybe there is another way to solve A that doesn't require solving B and maybe it's only polynomial.\n\nthe second statement is true because it means that you can solve B by first solving A then apply some polynomial time algorithm to solve B but B is NP-complete so A has to be NP-complete \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP problems can be solved in deterministically EXPONENTIAL time?\r\n                \r\nany problem in NP can be solved in deterministically exponential time,\nor we can say that \nany language in NP can be decided by an algorithm running in time 2^O(n^k)\ni.e., NP  ⊆ EXP\n\ninformally speaking, we just try each one of the possible solutions and then decide it\n\nHowever, there is a simple example that I can not figure out what's wrong with the idea i made\n\nHere it is..\n\nThe Traveling Salesman problem : given a undirected graph G=(V,E)  V=|n|\n\nThis is a well-known NP-complete problem, therefore, indeed belongs to NP\n\nAnd I try to analyse the running time..like this:\n\nI simply list out all the possible solutions, and there are (n-1)! possible tours in total\n\nThen I check each one of them, it takes O(n) for each possible tour\n\nThe total running time will be O(n!)\n\nIt doesn't look like can be bounded above by 2^O(n^k), i.e., exponential time\n\nwhere is the pitfall of this analysis?\n\nor in the other word, how can we explain traveling salesman problem indeed can be decided by an algorithm running in time 2^O(n^k)\n    ", "Answer": "\r\nNote that\n\n\n  n! ≤ nn = (2log n)n = 2n log n ≤ 2n2\n\n\nSo n! = 2O(n2), so n! &in; EXP.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Implementation of Graph Coloring Algorithms [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is seeking recommendations for books, tools, software libraries, and more. It does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     We don’t allow questions seeking recommendations for books, tools, software libraries, and more. You can edit the question so it can be answered with facts and citations.\r\n                \r\n                    \r\n                        Closed 6 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI came to know that graph colouring algorithms are NP-Complete problems. Still, I want to know whether any implementation is possible using heuristic approach or not, especially the distinguishing graph colouring? If possible then is there any suitable resource to learn about that ?\n    ", "Answer": "\r\nAs discussed in a somewhat related post:\n\nConstraint solvers like MiniZinc are able to solve a broad range of graph colouring problems.\n\nThis MiniZinc example demonstrates colouring of the Petersen graph:\n\n```\n%  Petersen Graph\nset of int: Colors = 1..3;\nset of int: Nodes = 1..10;\nset of int: Edges = 1..15;\narray[Edges] of Nodes: aFrom = [ 1, 2, 3, 4, 1, 1, 2, 3, 4,  5, 6,  7, 7,  8, 6 ];\narray[Edges] of Nodes: aTo   = [ 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 8, 10, 9, 10, 9 ];\n\narray[int] of string: colorName = [ \"red\", \"green\", \"blue\", \"purple\", \"yellow\", \"brown\", \"black\" ];\n\narray[Nodes] of var Colors: nodeColor;\n\nconstraint\n  forall(e in Edges) (\n      nodeColor[aFrom[e]] != nodeColor[aTo[e]]\n  );\n\nsolve satisfy;\n\noutput [ show(colorName[nodeColor[n]]) ++ \"\\n\" | n in Nodes ];    \n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "how do I construct np-reduction for this matching problem?\r\n                \r\nI have a matching problem, which I think is np-hard:\n```\nWe need to arrange a dinner for a group of n people, some of the people are friends with eachother, some are not. We need to sit everyone at a table, but they should never sit with someone that they are not friends with. There are *k* tables K = r1+r2+···+rk=n.\n\n**Input**\ninput is formatted as one first line k, then follow one line of k numbers, where each number represents a table and it's capacity. Then comes n lines of people, where we can see friendships of person i. All friendships are mutual.\n\n**Output**\n\nOutput the formations of people that can be seated together, without having to sit with someone that they are not friends with\n\n example: \n Input:\n 2\n 3, 3\n Alice:  Bob, Claire, Eric, Juliet, Romeo\n Bob:  Alice, Claire, Juliet, Romeo\n Claire:  Alice, Bob, Juliet\n Eric:  Alice, Romeo\n Juliet:  Alice, Bob, Claire\n Romeo:  Alice, Bob, Eric\n\n Output:\n Romeo, Eric, Alice \n Bob, Claire, Juliet\n```\n\nIm fairly certain that this problem is np-complete, but I am having some problems finding a proper reduction.\nThe example corresponds to the following (badly drawn)graph:\n\nI have a loose idea around using a complimentary graph to reduce to independent set. but i would be very gratefull for any ideas for solutions\n    ", "Answer": "\r\nClique problem reduction\nFirst off, note that NP is a class for decision problems, so we'll adjust the question to \"is there a table arrangement?\" instead of \"output the table arrangement\". In practice there is of course no real difference.\nNow, given a graph, let's say we want to know if there is a clique of at least size ```\nk```\n. This is the (decision) clique problem, which is one of the famous NP-complete problems.\nThis graph will have at least one clique of size ```\nk```\n if and only if your matching problem has a solution for the same graph, with a table of size ```\nk```\n. The seating for all the others should be unconstrained, so we have ```\nn-k```\n one-seat tables.\nThus, we can create an instance of the matching problem that is equivalent to any instance of a known NP-complete problem. This instance is roughly the same size (no exponential blow-up), so this constitutes a reduction, proving that the matching is NP-hard. As it is also (clearly?) in NP, it is also NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Performance difference between \"int a, b;\" and \"int a; int b;\"?\r\n                \r\nIt's an easily described in question as the title says.\n\nThis question came to my mind every time I can put two separate statements together in a block. Especially when I code for CPU cost problems like NP-complete problems.\n\nIs there any, necessary to combine two separate statements together?.\n    ", "Answer": "\r\n\n  Performance difference between “int a, b;” and “int a; int b;”?\n\n\nThose declarations are semantically equivalent, and there is no reason why either would generate different program from the other, and therefore no reason why there would be difference in performance.\n\nHowever, the first declaration is shorter by a few characters, so the compilation process might be a few micro-seconds faster for the time that's needed to load the source file from the disk.\n\n\n  Is there any necessary to combine two separate statements together?\n\n\nIn general, no.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Venn Diagram Drawing Algorithms\r\n                \r\nSomeone asked about overlapping subclusters in GraphViz and got the following response:\n\n\n  Sorry, no. General subgraphs can share nodes without implying subset\n  containment but not clusters. The problem is in the drawing.\n  If clusters can overlap arbitrarily, drawing them becomes the problem\n  of drawing Venn diagrams, for which there are no good algorithms.\n\n\nWhat is a formal definition or example of the \"problem of drawing Venn diagrams\"?, and why is it (I assume NP-complete/hard) hard ?  (Extra points: Sketch a reduction to a well-known NP-complete problem)\n    ", "Answer": "\r\nYou have N points and a binary relation R on them, and you need to represent the relation graphically so that every node is represented by a circle on Euclidean plane so that two circles overlap if and only if for the corresponding nodes n and n' it holds that n R n'.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Pick one item of each type with highest value without exceeding budget\r\n                \r\nGiven the list of items below, a budget B and a list of item types (T1, T2, T3...TN), pick 1 item of each type that provides the most value (most expensive) without exceeding the budget.\n\n```\n[\n  {\n    \"id\": \"1\",\n    \"types\": \"T1\",\n    \"price\": 1000,\n  },\n  {\n    \"id\": \"2\",\n    \"types\": \"T2\",\n    \"price\": 109292,\n  },\n  {\n    \"id\": \"3\",\n    \"types\": \"T3\",\n    \"price\": 7228,\n  },\n  {\n    \"id\": \"4\",\n    \"types\": \"T4\",\n    \"price\": 1000,\n  },\n]\n```\n\n\nExplored knapsack problems and not sure if this is a NP-complete problem.\n    ", "Answer": "\r\nJust use ```\nfilter```\n to find all items that do not exceed budget, then ```\nsort```\n it in descending order and take the first element:\n\n\r\n\r\n```\nconst array = [{\r\n    \"id\": \"1\",\r\n    \"types\": \"T1\",\r\n    \"price\": 1000,\r\n  },\r\n  {\r\n    \"id\": \"2\",\r\n    \"types\": \"T2\",\r\n    \"price\": 109292,\r\n  },\r\n  {\r\n    \"id\": \"3\",\r\n    \"types\": \"T3\",\r\n    \"price\": 7228,\r\n  },\r\n  {\r\n    \"id\": \"4\",\r\n    \"types\": \"T4\",\r\n    \"price\": 1000,\r\n  },\r\n];\r\n\r\nconst budget = 9000;\r\n\r\nvar budgetMatch = array.filter(({ price }) => price <= budget);\r\nbudgetMatch.sort(({ price: a}, { price: b}) => b - a);\r\n\r\nvar highestPrice = budgetMatch[0];\r\n\r\nconsole.log(highestPrice);```\n\r\n\r\n\r\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "List of O(n^2) and O(n^3) algorithms that aren't linear algebra? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and  cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened,  visit the help center.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 10 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI've been reading a lot of papers on performance optimizations for matrix-vector multiplication (BLAS2) and matrix-matrix multiplication (BLAS3). I'd like to think about if/how these optimizations would apply to O(n^2) and O(n^3) algorithms that don't cleanly reduce to dense or sparse linear algebra.  \n\nIt's easy to find lists of NP-complete or NP-hard algorithms, but I haven't found a good breakdown of common (and not-so-common) polynomial time algorithms. Can anyone suggest a list of polynomial-time problems for which the best known algorithm is O(n^2) or O(n^3)?\n\nEdit: To make this more concrete, I'm looking for something like this list of NP-complete problems, but for polynomial problems with n^2 or n^3 algorithms instead. \n    ", "Answer": "\r\nFirst: It's worth noting that the complexity of level-two and level-three BLAS operations are actually formally O(n) and O(n^3/2); the input matrices are themselves quadratic in what people usually think of as \"n\".\n\nThe techniques commonly used for dense linear algebra do not really apply directly to other problem domains, because they tend to make heavy use of linearity of the problem.\n\nNext: some of the most common examples of O(n^2) algorithms are the naive algorithms for sorting, integer multiplication, and computing discrete Fourier transforms.  In all of these cases, better algorithms with lower complexity exist.  Similarly, there is a large number of naive O(n^3) algorithms.\n\nOne can apply dense linear algebra techniques to computing the DFT (since it is also linear), but you can do much better still by using one of the FFT algorithms, so in practice no one does this.\n\nAs far as non-naive algorithms go, it's been far too long since I had to teach a complexity course; IIRC, the best known algorithm for deciding if a string is in a context-free language is O(n^3).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Which of the following problems can be reduced to the Hamiltonian path problem?\r\n                \r\nI'm taking the Algorithms: Design and Analysis II class, one of the questions asks:\n\n\n  Assume that P ≠ NP. Consider undirected graphs with nonnegative edge\n  lengths. Which of the following problems can be solved in polynomial\n  time?\n  \n  Hint: The Hamiltonian path problem is: given an undirected graph with\n  n vertices, decide whether or not there is a (cycle-free) path with n\n  - 1 edges that visits every vertex exactly once. You can use the fact that the Hamiltonian path problem is NP-complete. There are relatively\n  simple reductions from the Hamiltonian path problem to 3 of the 4\n  problems below.\n  \n  \n  For a given source s and destination t, compute the length of a shortest s-t path that has exactly n - 1 edges (or +∞, if no such path\n  exists). The path is allowed to contain cycles.\n  Amongst all spanning trees of the graph, compute one with the smallest-possible number of leaves.\n  Amongst all spanning trees of the graph, compute one with the minimum-possible maximum degree. (Recall the degree of a vertex is the\n  number of incident edges.)\n  For a given source s and destination t, compute the length of a shortest s-t path that has exactly n - 1 edges (or +∞, if no such path\n  exists). The path is not allowed to contain cycles.\n  \n\n\nNotice that a Hamiltonian path is a spanning tree of a graph and only has two leaf nodes, and that any spanning tree of a graph with exactly two leaf nodes must be a Hamiltonian path. That means that the NP-Complete problem of determining whether a Hamiltonian path exists in a graph can be solved by finding the minimum-leaf spanning tree of the graph: the path exists if and only if the minimum-leaf spanning tree has exactly two leaves. Thus, problem 2 is NP-Complete.\n\nProblem 3 is NP-Hard; here is a paper that proves that.\n\nThat means, between 1 and 4, one is NP-Complete, another is in P. It seems like problem 4 reduces trivially to the the Hamiltonian path problem, but I'm not able to understand how having a cycle makes it solvable? Or is it the other way?\n    ", "Answer": "\r\nFor the first one you can use Dijkstra to get shortest even and odd distances possible. To this end for every vertex you need to store not a single minimum number, but two of them. One is minimum weight of an odd path, another one is for minimum weight of an even path. After you have these two lengths you can easily increase path length by even number of edges if cycles are allowed. So, the first problem is from P. Step-be-step algorithm would be:\n\n\nFind shortest even and odd length paths.\nIncrease length of one of these paths which has the same parity as ```\nn-1```\n to ```\nn-1```\n by adding cycle of length 2 required number of times.\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete? Optimal graph embedding for a graph with specific constraints\r\n                \r\nI have a grid based graph, where nodes and edges occupy cells. Edges can cross, but cannot travel on top of each other in the same direction. \n\nLets say I want to optimize the graph so that the distance covered by edges is minimized.\nI am currently using A* search for each connection, but the algorithm is greedy and does not plan ahead. Consider the diagram below, where the order in which connections are made is changed (note also that there can be multiple shortest paths for any given edge, see green and \npurple connections). \n\n\n\nMy intuition says this is NP-Complete and that an exhaustive search is necessary, which will be extremely expensive as the size of the graph grows. However, I have no way of showing this, and it is not quite the same as other graph embedding problems which usually concern minimization of crossing.\n    ", "Answer": "\r\nYou didn't really describe your problem and your image is gone, but your problem sounds like the minimum T-join problem.\n\nThe minimum T-join problem is defined on a graph G.  You're given a set T of even size, and you're trying to find a subgraph of the graph where the vertices of T have odd degree and the other vertices have even degree.  You've got weights on the edges and you're trying to minimise the sum of the weights of edges in the subgraph.\n\nSurprisingly, the minimum T-join problem can be solved in polynomial time thanks to a very close connection with the nonbipartite matching problem.  Namely, if you find all-pairs shortest paths between vertices of T, the minimum T-join is attained by the minimum-weight perfect matching of vertices in T, where there's an edge between two vertices whose length is the length of the shortest path in G.\n\nThe minimum T-join will be a collection of paths.  If two distinct paths, say a->b and c->d, use the same edge uv, then they can be replaced by a->u->c and b->v->d and reduce the cost of the T-join.  So it won't use the same edge twice.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "class NP, polynomial-time verification CLIQUE\r\n                \r\nThe CLIQUE problem-- problem of finding the \nmaximum clique in a graph is NP-complete. \nThat is, CLIQUE is \n\na.) in NP and \nb.) there is an NP complete problem, 3-SAT for one, \nthat reduces to CLIQUE in polynomial time. \n\nPart (b) above is fine-- all over in every resource and very well explained. \nFor Part (a), from what i know, we need to have the following:\nGiven a specific solution instance, we need to show that \nit can be verified, in polynomial time, that that solution is an answer to this problem. \nSo for instance, given a specific graph and a subgraph of it, we should be \nable to check whether that subgraph is a clique of maximum size in that graph. \n\nThe resources I've read so far are phrasing this \nPart (a) here as \"easy, straightforward, etc\" or \n\"it can be shown in O(n^2) time that the given subgraph is a clique/not\". \nHowever, the verification here is not just whether it's a clique, but also is whether it is a maximum clique in the graph. \nHow can this be decided in polynomial time?\n\nWhat am i missing here?\n    ", "Answer": "\r\nYou are confusing the optimization version of the problem with the decision version of the problem.   \n\nThe decision version of clique asks if the graph has a clique of size k.  Given a candidate solution, you can test its feasibility in polynomial time. Focus on the decision versions for NP-completeness proofs.\n\nCertificates of optimality for the optimization problems are indeed harder to come by.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-hardness. Is it average case or worst-case?\r\n                \r\nDo we measure the NP-hardness in terms of average-case hardness or worst-case hardness?\nI've found this here:\n\"However, NP-completeness is defined in terms of worst-case complexity\".\nDoes it remain true to NP-hardness?\nI don't know what the term \"worst-case complexity\" means. What is the difference between worst-case complexity and worst-case problems?\n    ", "Answer": "\r\nAn interesting nuance here is that NP-hardness, by itself, doesn’t speak about worst-case or average case complexity. Rather, the formal definition of NP-hardness purely says that there’s a polynomial-time reduction from every problem in NP to any NP-hard problem. That reduction means that any instance of any problem in NP could be solved by applying the reduction and then solving the NP-hard problem. But because this applies to “any instance” and the specific transform done by the reduction isn’t specified, that definition by itself doesn’t say anything about average-case complexity.\nWe can artificially construct NP-hard problems that are extremely easy to solve on average. Here’s an example. Take an NP-hard problem - say, the problem of checking whether a graph is 3-colorable. We can solve this in time (roughly) O(3n) by simply trying all possible colorings. (The actual time complexity is a bit higher because we need to check edges in each step, but let’s ignore that for now). Now, we’ll invent a contrived problem of the following form:\n\nGiven a string of 0s, 1s, and 2s, determine whether\n\nThe first half of the string contains a 1 or a 2, or\nWhether it doesn’t and the back half of the string is a base-3 encoding of a graph that’s 3-colorable.\n\n\nThis problem is NP-hard because we can reduce graph 3-colorability to it by just prepending a bunch of 0s to any input instance of 3-colorability. But on average it’s very easy to solve this problem. The probability that a string’s first half is all 0s is 1 / 3n/2, where n is the length of the string. This means that even if it takes O(3n/2) time to check the coloring of the graph encoded in the back half of a suitable string, mathematically the average amount of work required to solve this problem is O(1). (I’m aware I’m conflating the meaning of n as “the number of nodes in a graph” and “how long the string is,” but the math still checks out here.)\nWhat’s worrisome is that we still don’t have a very well-developed theory of average-case complexity for NP-hard problems. Some NP-hard problems, like the one above, are very easy on average. But others like SAT, graph coloring, etc. are mysteries to us, where we legitimately don’t know how hard they are for random instances. It’s entirely possible, for example, that P ≠ NP and yet the average-case hardness of individual NP-hard problems are not known.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Constructing a permutation graph\r\n                \r\nI have read about how permutation graphs make many NP-complete problems a lot easier to solve. For example, the maximal clique problem, tree width problem etc. However, I am unable to understand the process of creating a permutation graph from a given graph G(V,E). How would one go about doing this?\n    ", "Answer": "\r\nYou do not create a permutation graph from a graph, but from a permutation. The process is quite simple: \n\n\nwrite numbers 1 to n on a line, then \nwrite them again on a separate, parallel line according to the order in which they appear in your permutation;\nconnect each element from the first line to the same element on the second line (1 to 1, 2 to 2, ..., n to n), \nlabel each such connection with the numbers that it connects (e.g. connection 2 to 2 receives label 2);\nthe resulting permutation graph is obtained by treating each connection as a vertex and connecting two vertices whenever the corresponding connections intersect.\n\n\nIf that's still unclear, see the nice example on Wikipedia.\n\nIt is clear from the process that such a graph can always be constructed from any permutation; however, having a permutation graph may lead you to deduce several permutations that correspond to it.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this NP-Complete\r\n                \r\nMy problem is similar to the problem here https://cs.stackexchange.com/questions/2244/need-a-np-complete-proof-on-an-example , but it is a little different.\n\nHere is my problem:\n\nThere are three islands, A, B and C, and a lot of fan-shaped rafts. We must build a bridge from A-->B-->C, and the number of rafts required for each part is already known, say, four rafts are required for connecting AB and three rafts are required for connecting BC. \n\nThese rafts are at different positions originally and they can rotate without cost. An interesting thing is that they can overlap with each other if necessary. The distance of moving one raft can be calculated as the distance between the center of mass's original position and its deployed position.\n\nThe objective is to find the solution having the minimum total distance of moving rafts in order to have bridge A-->B-->C and using the exact number of rafts for each part of bridge.\n\nI used to the following figure to show my question.\n\n\n\nWe can see from this figure that the arrangement might not be a straight line, and the rafts can overlap with another one.\n\nThere are too many candidates locations for these rafts. It seems the problem is NPC. I do not know whether I am right and how to prove it to be NPC. Anyone know how to solve it? Thanks!\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Difference between C-SAT and SAT?\r\n                \r\nWhat exactly is the difference between these two NP-complete problems? It seems to me that they are both asking if a boolean formula can be satisfied (i.e. output 1) but one is in the context of a circuit and the other just a formula. However couldnt one write a boolean formula from a boolean circuit? \n    ", "Answer": "\r\nYou are right, they are very close to each other. Any C-SAT problem could be represented as SAT, any SAT problem could be represented as C-SAT. There is a question how to translate C-SAT <-> SAT in the most efficient way. Some tasks are better to represent as SAT, some of them 'looks' better as C-SAT.\n\nIn addition, there are SAT solvers that use circuit representation internally, instead of more popular clausal form.\n\nFurther, you can read this great survey: M. Bjork, 2009, Successful SAT encoding techniques\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "complexity of printing all possible paths on a graph\r\n                \r\nIn an undirected, unweighted graph, and I'm trying to print (store in file) all possible connecting paths between given 2 vertices on the graph, not including cycles. \n\nwhen you consider a complete graph this problem is a NP-complete. because there are ```\n\"(V-2)!\"```\n different paths between 2 vertices. \n\nHowever,seems it is possible to do it with one of graph traversal (DFS-BFS) algorithm with time complexity of ```\nO(|V|+|E|)```\n which is pretty polynomial.\n\nI got confuse about solving a NP-Complete problem in polynomial time?\nany idea about what is missing here ?\n    ", "Answer": "\r\nIf you want all possible paths, and the graph has V vertices, and E edges, then the number of paths will be dependent upon the number of connects.  Consider a fully connected graph, where every point connects to every other point.  Then there are ```\n(v-2)!```\n possible paths, right?  Well ```\n(v-2)! > V+E```\n (much greater).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What is nondeterministic in NP exactly?\r\n                \r\nI am studying NP-Completeness and I have a question about the definition of the NP problems.\n\nMaterial says  \n\n\n  nondeterministic refers to the fact that a solution can be guessed out\n  of polynomially many options in O(1) time\n\n\nHere, what does it mean by ```\npolynomially many options in O(1) time```\n?\n\nFor example, in the case of famous ```\n3SAT```\n problem, isn't there a exponentially many options?\n(b.c. each literal can be ```\ntrue```\n or ```\nfalse```\n and if there are are n literals, total number of options are ```\n2*2*2* ... * 2 = 2^n```\n)\n\nHowever, it says ```\n3SAT```\n problem is NP problem. How can it be NP problem even though there are exponentionally many certificates?\n\nThanks\n    ", "Answer": "\r\nThat quote seems to be a weird way of phrasing it, but it might refer to something similar to being able to pick a random number between 1 and n in O(1) - there are n possibilities, but only picking one of them takes O(1).\n\nSee also: nondeterministic algorithms.\n\n\"Nondeterministic polynomial time\" is the full definition of NP - \"polynomial time\" is important - each decision you make might take O(1), but there are polynomially many such decisions, leading to something that can theoretically be solved in polynomial time, if you can make the right choice at every step or execute all options at the same time.\n\nPicture a k-ary tree with height p(n). You can get to the correct leaf in O(p(n)) if you (randomly) pick the correct child at each step from the root, or if you can somehow visit all paths concurrently.\n\nOf course, in practice, you can't rely on making correct random choices, nor do you have infinitely many processors - if you were to visit all nodes sequentially, that will take O(kp(n)).\n\n\n\nFor 3SAT, we can randomly pick true or false for every literal, which leads us to a polynomial time algorithm which would produce the correct result if all our random choices were correct.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Prove that the subset sum with fixed size and number reusability is NP complete\r\n                \r\nI'm trying to solve the following problem:\n\nThere are B (B is allowed to vary) lists of unspecified size containing integers. Pick a number from each list so that the sum of all the picks is exactly A. Prove that this problem is NP complete by reducing the known NP complete subset sum problem.\n\nMy thinking on how to solve this: First one has to \"limit\" the normal subset sum problem by only making subsets of size B acceptable, so one has to start by reducing the common subset problem to a fixed size subset problem in polynomial time. I'm not quite sure how to do this tough.\n\nSecondly I was thinking that you could make all the lists in the problem copies of the set (e.g. if the set is {1,2,3,4,5}, all the lists will be {1,2,3,4,5}), so that each list pick represents a number in the set. The problem with this thinking is that there is nothing preventing you from picking the same number twice, while the normal subset sum problem only allows you to use the same number once. I also dont think that there is a way to arrange the lists so that this is impossible to do. Because of this, I'm not sure that I'm on the right track in my thinking. It is also possible that the subset sum problem can be reduced to allowing choosing the same number more than once, but I'm not sure how that can be done. Ideas?\n    ", "Answer": "\r\nLet ```\nI={a_1,...,a_n}```\n be an instance of Subset Sum, let ```\nB```\n be the target capacity. Define an instance ```\nI'```\n of Subset Sum with Fixed Size and Number Reusability as follows. Let ```\nA=B```\n be the target number and define ```\nn```\n lists ```\nl_1={0,a_1},...,l_n={0,a_n}```\n. Given a solution of ```\nI'```\n yields a solution for instance ```\nI```\n by for each ```\ni```\n in ```\n[1,...n]```\n either chosing ```\n0```\n (which corresponds to not chosing item ```\na_i```\n) or chosing ```\na_{i}```\n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Advantage of Using backtracking and branch and bound\r\n                \r\nI understand that DP gives a better performance for many NP complete problems like TSP. Though the space needed is large, it reduces the complexity well.\n\nBut I couldn't understand the efficiency of branch and bound and backtracking as compared to an brute force search.\n\nIn worst case whether brute force equals b&b or backtracking ?\n    ", "Answer": "\r\nWith exhaustive search, you would compute all N! possible routes between the nodes. With backtracking, you might compute a route visiting half the nodes, notice that it is already more expensive than the best route found so far, and stop investigating that partial route at that point. By doing so, you have skipped computing all of the routes that are produced by completing that partial route, thus saving time over exhaustive search, which would have continued to check them all.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "P=NP in Exponential Space?\r\n                \r\nSuppose that we find that, for any NP-complete problem, there is an algorithm that can solve it in P time. However, the algorithm takes exponential space. For example, the algorithm to revert SHA256 would only take 256 steps. But you would need 2^256 bits to write the algorithm. Is the time complexity of this algorithm P? Would P equal NP?\nThe Clay Math Institute says that \"Informally the class P is the class of decision problems solvable by some algorithm within a number of steps bounded by some fixed polynomial in the length of the input.\"\nIt makes no limitations to the space taken by this algorithm.\nWe also commonly say that a binary decision tree with depth d can be executed in time-complexity O(d), even if the tree's length might be 2^d.\nOn the other hand, we know that P is contained within PSPACE.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Can abstract models for solving NP-hard problems be built in reality?\r\n                \r\nThis paper proofs, that NP-hard problems can be solved efficiently through abstract geometrical computations. These computations are based on signals, which are dimensionless and can move uniformly on a hypothetical real axis in time and space.\n\nThe authors claim the model to be only abstract and \n\n\n  ...with no apriori ambition to be physically realizable.\n\n\nIn fact, this paper shows, that the practical limitation is due to the need for a black hole to absorb emerging limit points within calculations.\n\nActually, there exist several black hole analogues and the first one was created in 2009, based on a rubidium Bose–Einstein condensate using a technique called density inversion (1). A further method by lasing the phonons also detected self-amplifying Hawking radiation in 2014 (2).\n\nCan such analogues of black holes be used to build the signal machines described above? In effect, such a machine could be able to solve NP-complete problems efficiently.\n\nIf not, what exactly are the physically limitations for building such signal machines. If it could be possible to built them, what would be the implications for complex theory and the N versus NP Problem?\n\n\n\n(1) Lahav, et. al. \"Realization of a sonic black hole analogue in a Bose-Einstein condensate\", 2009 (see doi: 10.1103/PhysRevLett.105.240401)\n\n(2) J. Steinhauer, \"Observation of self-amplifying Hawking radiation in an analogue black-hole laser\", 2014 (see doi:10.1038/nphys3104)\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Problem related to Completeness : Is P = PC?\r\n                \r\nI am learning computational complexity. So, i took some practise problems from internet. I came across 1 problem which I am not sure whether my solution is correct or not. The question is : \n\nLet us define a complexity class PC as follows : A decision problem A belongs to PC if and only if the following 2 conditions hold :\n\n1) A belongs to P\n2) For every problem B belongs to P, B is polynomial time reducible to A. Now we need to prove that PC = P.\n\nMy argument is that, PC is not equal to P. Because, this conditions are similar to NP-Complete conditions right. So, there are some problems in NP which are not NP-Complete right. So, NP is not equal to NP-Complete. Similarly, we can argue here that assuming C in PC is for completeness, P is not equal to PC.\n\nIs my argument correct ? Please clarify me on this.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Algorithm for checking if a string was built from a list of substrings\r\n                \r\nYou are given a string and an array of strings. How to quickly check, if this string can be built by concatenating some of the strings in the array?\n\nThis is a theoretical question, I don't need it for practical reasons. But I would like to know, if there is some good algorithm for this.\n\nEDIT\nReading some answer I have noticed, that this is probably NP-Complete problem. Even finding a subset of strings, that will together have same length, as a given string is a classic subset sum problem.\n\nSo I guess there is no easy answer to this.\n\nEDIT\n\nNow it seems, that it is not a NP-Complete problem after all. That's way cooler :-)\n\nEDIT\n\nI have came up with a solution that passes some tests:\n\n```\ndef can_build_from_substrings(string, substrings):\n    prefixes = [True] + [False] * (len(string) - 1)\n    while True:\n        old = list(prefixes)\n        for s in substrings:\n            for index, is_set in enumerate(prefixes):\n                if is_set and string[index:].startswith(s):\n                    if string[index:] == s:\n                        return True\n                    prefixes[index + len(s)] = True\n        if old == prefixes: # nothing has changed in this iteration\n            return False\n```\n\n\nI believe the time is ```\nO(n * m^3)```\n, where ```\nn```\n is length of ```\nsubstrings```\n and ```\nm```\n is length of ```\nstring```\n. What do you think?\n    ", "Answer": "\r\nNote: I assume here that you can use each substring more than once. You can generalize the solution to include this restriction by changing how we define subproblems. That will have a negative impact on space as well as expected runtime, but the problem remains polynomial.\n\nThis is a dynamic programming problem. (And a great question!)\n\nLet's define ```\ncomposable(S, W)```\n to be true if the string ```\nS```\n can be written using the list of substrings ```\nW```\n.\n\n```\nS```\n is composable if and only if:\n\n\n```\nS```\n starts with a substring ```\nw```\n in ```\nW```\n.\nThe remainder of ```\nS```\n after ```\nw```\n is also composable.\n\n\nLet's write some pseudocode:\n\n```\nCOMPOSABLE(S, W):\n  return TRUE if S = \"\" # Base case\n  return memo[S] if memo[S]\n\n  memo[S] = false\n\n  for w in W:\n    length <- LENGTH(w)\n    start  <- S[1..length]\n    rest   <- S[length+1..-1]\n    if start = w AND COMPOSABLE(rest, W) :\n      memo[S] = true # Memoize\n\n  return memo[S]\n```\n\n\nThis algorithm has O(m*n) runtime, assuming the length of the substrings is not linear w/r/t to the string itself, in which case runtime would be O(m*n^2) (where m is the size of the substring list and n is the length of the string in question).  It uses O(n) space for memoization.\n\n(N.B. as written the pseudocode uses O(n^2) space, but hashing the memoization keys would alleviate this.)\n\nEDIT\n\nHere is a working Ruby implementation:\n\n\n\n```\ndef composable(str, words)\n  composable_aux(str, words, {})\nend\n\ndef composable_aux(str, words, memo)\n  return true if str == \"\"                # The base case\n  return memo[str] unless memo[str].nil?  # Return the answer if we already know it\n\n  memo[str] = false              # Assume the answer is `false`\n\n  words.each do |word|           # For each word in the list:\n    length = word.length\n    start  = str[0..length-1]\n    rest   = str[length..-1]\n\n    # If the test string starts with this word,\n    # and the remaining part of the test string\n    # is also composable, the answer is true.\n    if start == word and composable_aux(rest, words, memo)\n      memo[str] = true           # Mark the answer as true\n    end\n  end\n\n  memo[str]                      # Return the answer\nend\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Completeness in Task Scheduling\r\n                \r\nSo this is a bit of a thought provoking question to get across the idea of NP-Completeness by my professor. I get WHY there should be a solution, due to the rules of NP-Completeness, but I don't know how to find it. So here is the problem:\n\nThe problem is a simple task scheduling problem with two processors. Each processor can handle one of the ```\nn```\n tasks, and any two tasks can be done simultaneously. Each task has an end time ```\ne```\n, it must be completed by this time. Each task also has a duration ```\nd```\n. All time values, such as end time, duration, and the current time in the system (the time will start at 0), are all integers. So we are given a list of ```\nn```\n tasks and we need to use these two processors to schedule them ALL. If any one can not be scheduled, the algorithm has to return no solution. Keep in mind that the order does not matter and it doesn't matter which processor gets which task, as long as there is no overlap and each task finishes before its deadline. \n\nSo here is where the problem gets conceptual/abstract, say we have access to a special little function, we have no idea how it works, all we know is this: given a list of ```\nn```\n tasks and the current schedule, it will return ```\ntrue```\n or ```\nfalse```\n based on whether or not the algorithm is solvable from this point. This function assumes that the already scheduled tasks are set in stone, and it will only change the times of the unscheduled tasks. However, all this function does is return true or false, it will not give you the proper schedule if it does find a solution. The point is that you can use the special function in the implementation of the scheduling problem. The goal is to solve the scheduling problem, and return a working schedule with every job scheduled properly, using a polynomial number of calls to the special function. \n\nEDIT: To clarify, the question is this: Create a solution to schedule all ```\nn```\n tasks without any going over deadline, using a polynomial number of calls to the \"special function.\"\n\nI think this problem is to show that verifying a solution is polynomial, but finding it is nonpolynomial. But my professor is insistent that there is a way to solve this using a polynomial number of calls to the special function. Since the problem as a whole is NP-Complete, this would prove that the nonpolynomial aspect of the runtime comes in during the \"decision portion of the algorithm. \n\nIf you would like me to clear up anything just leave a comment, I know this wasn't a perfect explanation of the problem. \n    ", "Answer": "\r\nGiven an oracle ```\nM```\n that returns ```\ntrue```\n or ```\nfalse```\n only:\n\ninput:\ntasks - list of tasks\noutput:\nschedule: a triplet(task,processor,start) for each task\nalgorithm:\n\n```\nWhile there is some unscheduled task:\n   let p be the processor that currently finished up his scheduled tasks first\n   let x be the first available time on x\n   for each unscheduled task t:\n      assign t with the triplet: (t,p,x)\n      run M on current tasks\n      if M answers true:\n            break the for loop, continue to next iteration of while loop\n      else:\n            unassign t, and continue to next iteration of for loop\n    if no triplet was assigned, return NO_SOLUTION\nreturn all assigned triplets\n```\n\n\n\nThe above runs in polynomial time - it needs ```\nO(N^2)```\n calls to ```\nM```\n.\nCorrectness of the above algorithm can be proved by induction, where the induction hypothesis is After round ```\nk```\n of the while loop, if there was a solution before it, there is still a solution after it (and after the assignment of some task). After proving this claim, correctness of the algorithm is achieved trivially for ```\nk=#tasks```\n\n\n\nFormally proving the above claim:\n\n\nBase of induction is trivial for k=0.\nHypothesis: for any k < i, the claim \"if there was a solution before round k, there is still one after round k\", is correct\nProof:\n\n\nAssume there is some solution ```\n{ (tj,pj,xj)  | j=1,...,n}```\n, ordered by ```\nj<u <-> xj<xu```\n, and also assume that t1,t2,...,ti-1 is assigned same as the algorithm yielded (induction hypothesis).\nNow, we are going to assign ```\nti```\n, and we'll be able to do it, since we are going to find the smallest available time stamp (```\nxi```\n), and place some task on it. We are going to find some task, and since ```\nti```\n is a possibility - it will not \"fail\" and yield \"NO_SOLUTION\".\nAlso, since the algorithm does not yields \"NO_SOLUTION\" in iteration ```\ni```\n, from correctness of ```\nM```\n, it will yield some task ```\nt```\n, that by assigning ```\n(t,p,x)```\n - there will still be a solution, and the claim for step ```\ni```\n is proven.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Minimal addition-chain exponentiation\r\n                \r\nI know it has been proven NP-complete, and that's ok. I'm currently solving it with branch and bound where I set the initial upper limit at the number of multiplications it would take the normal binary square/multiply algorithm, and it does give the right answers, but I'm not satisfied with the running time (it can take several seconds for numbers around 200). This being an NP-complete problem, I'm not expecting anything spectacular; but there are often tricks to get the Actual Time under control somewhat. \n\nAre there faster ways to do this in practice? If so, what are they?\n    ", "Answer": "\r\nThis looks like section 4.6.3 \"Evaluation of Powers\" in Knuth Vol 2 Seminumerical Algorithms. This goes into considerable detail to give various approaches, which look much quicker than branch and bound but do not all provide the absolutely best solution.\n\nKnuth states in the discussion after Theorem F that he uses backtrack search to prove that l(191) = 11, so I doubt if you will find a short-cut answer for this. He defers explanation of the backtrack search to section 7.2.2, which is I think still unpublished, although there are traces of work on this at http://www-cs-faculty.stanford.edu/~uno/programs.html.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Cuda optimization techniques\r\n                \r\nI have written a CUDA code to solve an NP-Complete problem, but the performance was not as I suspected.    \n\nI know about \"some\" optimization techniques (using shared memroy, textures, zerocopy...)  \n\nWhat are the most important optimization techniques CUDA programmers should know about?\n    ", "Answer": "\r\nYou should read NVIDIA's CUDA Programming Best Practices guide: http://developer.download.nvidia.com/compute/cuda/3_0/toolkit/docs/NVIDIA_CUDA_BestPracticesGuide.pdf \n\nThis has multiple different performance tips with associated \"priorities\". Here are some of the top priority tips:\n\n\nUse the effective bandwidth of your device to work out what the upper bound on performance ought to be for your kernel\nMinimize memory transfers between host and device - even if that means doing calculations on the device which are not efficient there\nCoalesce all memory accesses\nPrefer shared memory access to global memory access\nAvoid code execution branching within a single warp as this serializes the threads\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Find the class of the problem PP1 and PP2 using the information given below\r\n                \r\nAssume that P1, P2,..., Pn are NP-class problems. PP1 and PP2 are unknown problems (i.e., we don't know whether they belong to the P or NP classes). If \"P1, P2,...., Pn\" problems can be reduced to PP1 in polynomial time, then PP1 can be reduced to PP2, and PP2 can be reduced to another NP problem in polynomial time. Specify the PP1 and PP2 classes with clear justification?\nThis was the question asked in one of my algorithms exam. I thought the answer for both the problems would be NP-hard, the logic which I thought of is that since all P1, P2, ...., Pn are NP problems and using the definition of NP-hard we can derive that PP1 is NP-Hard.\nAfter this for finding the class of PP2, since PP1 can be reduced to PP2. Therefore, we can say that PP2 is also NP-Hard.\nThe next bit of the question mentions about PP2 further being reducible to a NP problem but I don't feel that this information would be useful in finding the class of PP2. Let's assume the problem after reducing PP2 is some 'X' problem. This 'X' problem would be NP-Complete because it is NP-hard and NP as well.\nMy teacher says that PP1 is NP-Hard and PP2 is NP-Complete. Please clarify my doubt.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Find the class of the problem PP1 and PP2 using the information given below\r\n                \r\nAssume that P1, P2,..., Pn are NP-class problems. PP1 and PP2 are unknown problems (i.e., we don't know whether they belong to the P or NP classes). If \"P1, P2,...., Pn\" problems can be reduced to PP1 in polynomial time, then PP1 can be reduced to PP2, and PP2 can be reduced to another NP problem in polynomial time. Specify the PP1 and PP2 classes with clear justification?\nThis was the question asked in one of my algorithms exam. I thought the answer for both the problems would be NP-hard, the logic which I thought of is that since all P1, P2, ...., Pn are NP problems and using the definition of NP-hard we can derive that PP1 is NP-Hard.\nAfter this for finding the class of PP2, since PP1 can be reduced to PP2. Therefore, we can say that PP2 is also NP-Hard.\nThe next bit of the question mentions about PP2 further being reducible to a NP problem but I don't feel that this information would be useful in finding the class of PP2. Let's assume the problem after reducing PP2 is some 'X' problem. This 'X' problem would be NP-Complete because it is NP-hard and NP as well.\nMy teacher says that PP1 is NP-Hard and PP2 is NP-Complete. Please clarify my doubt.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reduction from Maximum independent set to Dominating set to prove the Dominating set is NP-complete\r\n                \r\nI know of the reduction from the Vertex cover to Dominating set. \n\nHowever, I was seeing if I could get a reduction from the maximum independent set problem straight to the Dominating set problem in order to prove the latter NP-complete.\n\nDoes anyone know if this has been done? I can't find anything online.\n\nI was hoping to find something along the lines of a proof like:\n\nIf there is a dominating set of size k -> there is a maximum independent set of size k.\n\nAND\n\nIf there is a maximum independent set of size k -> then there is a dominating set of size k.\n    ", "Answer": "\r\nYes you can get a reduction from the maximum independent set problem straight to the Dominating set problem -- but not that straight, you need to construct another graph in the following manner. We then can prove that if the original graph has an independent set of size ```\nk```\n iff the new graph has a dominating set of some size related to k. The construction is polynomial. \n\nGiven a graph ```\nG = (V, E)```\n  we can construct another graph ```\nG' = (V', E')```\n where for each edge ```\ne_k = (v_i, v_j)```\n in ```\nE```\n, we add a vertex ```\nv_{e_k}```\n and two edges ```\n(v_i, v_{e_k})```\n and ```\n(v_{e_k}, v_j)```\n. \n\nWe can prove ```\nG```\n has an independent set of size ```\nk```\n iff ```\nG'```\n has a dominating set of size ```\n|V|-k```\n.\n\n(=>) Suppose I is a size-```\nk```\n independent set of ```\nG```\n, then ```\nV-I```\n must be a size-```\n(|V|-k)```\n dominating set of ```\nG'```\n. Since there is no pair of connected vertex in ```\nI```\n, then each vertex in ```\nI```\n is connected to some vertex in ```\nV-I```\n. Moreover, every new added vertex are also connected to some vertices in ```\nV-I```\n. \n\n(<=) Suppose ```\nD```\n is a size-```\n(|V|-k)```\n independent set of ```\nG'```\n, then we can safely assume that all vertices in ```\nD```\n is in ```\nV```\n (since if ```\nD```\n contains an added vertex we can replace it by one of its adjacent vertex in ```\nV```\n and still have a dominating set of the same size). \n\nWe claim ```\nV-D```\n is a size-```\nk```\n independent set in ```\nG```\n and prove it by contradiction: suppose ```\nV-D```\n is not independent and contains a pair of vertices ```\nv_i```\n and ```\nv_j```\n and the edge ```\ne_k = (v_i, v_j)```\n is in ```\nE```\n. Then in ```\nG'```\n the added vertex ```\nv_{e_k}```\n need to be dominated by either ```\nv_i```\n or ```\nv_j```\n, that is at least one of ```\nv_i```\n and ```\nv_j```\n is in ```\nD```\n. Contradiction. Therefore ```\nV-D```\n is a size-```\nk```\n independent set in ```\nG```\n.\n\nCombining the two directions you get what you want. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is \"house coloring with three colors\" NP?\r\n                \r\nConsider the problem described here (reproduced below.)  Can some better known NP-complete problem be reduced to it? \n\nThe problem:\n\nThere are a row of houses.  Each house can be painted with three colors: red, blue and green. The cost of painting each house with a certain color is different.  You have to paint all the houses such that no two adjacent houses have the same color. You have to paint the houses with minimum cost. How would you do it?\n\nNote: The cost of painting house 1 red is different from that of painting house 2 red. Each combination of house and color has its own cost.\n    ", "Answer": "\r\nNo, it is not NP-hard (technically, \"NP-complete\" is the wrong term for this, as this is not a decision problem).\n\nDynamic programming works, and gives you an O(n) time algorithm. (n is the number of houses).\n\nYou maintain three arrays ```\nR[1..n], B[1..n], G[1..n]```\n, where ```\nR[i]```\n is the minimum cost of painting houses 1, 2, 3 ... ```\ni```\n such that ```\ni```\n is colored Red. Similarly ```\nB[i]```\n is min cost of painting 1, 2 ... ```\ni```\n with ```\ni```\n being colored Blue, and ```\nG[i]```\n is with ```\ni```\n being colored Green.\n\nYou can compute ```\nR[i+1]```\n:\n```\nR[i+1]= (Cost of painting house i+1 Red) + minimum {G[i], B[i]}```\n. \n\nSimilarly ```\nB[i+1]```\n and ```\nG[i+1]```\n can be computed.\n\nUltimately you take the minimum of ```\nR[n], B[n] and G[n]```\n.\n\nThis is O(n) time and O(n) space.\n\nFor example consider the following cost matrix for the houses:\n\n\nHouse #: 1   2   3\nR      : 1   4   6\nG      : 2  100  2\nB      : 3  100  4\n\n\nThe algorithm is building the following matrix to get the answer:\n\n\nHouses : 0  1   2    3\nR      : 0  1   6   107\nG      : 0  2  101   8\nB      : 0  3  101  10\n\n\nFrom the last column, where all 3 houses are painted, we can find the minimum cost, which is equal to 8 and corresponds to the combination [Green (2), Red (4), Green (2)].\n\nQuick Python:\n\n```\n# rc = costs of painting red, bc of blue and gc of green.\ndef min_paint(rc, bc, gc):\n    n, i = len(rc), 1\n    r, b, g = [0]*n, [0]*n, [0]*n\n    r[0], b[0], g[0] = rc[0], bc[0], gc[0]\n    while i < n:\n        r[i] = rc[i] + min(b[i-1], g[i-1])\n        b[i] = bc[i] + min(r[i-1], g[i-1])\n        g[i] = gc[i] + min(b[i-1], r[i-1])\n        i += 1\n\n    return min(r, b, g)\n\ndef main():\n    print min_paint([1, 4, 6], [2, 100, 2], [3, 100, 4])\n\nif __name__ == \"__main__\":\n    main()\n```\n\n\nThe output will be ([1, 6, 107], [2, 101, 8], [3, 101, 10]), which is a cost matrix leading to the solution.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Network Flow and Integer Linear programming\r\n                \r\nWe all know that the problem of network flow can be reduced to linear programming. However, when we solve network flow problem, we need the flow to be integer all the time. So I think network flow should be reduced to integer linear programming. Because of ILP which is NP-complete, the network flow problem should be NP-complete problem too. But this contradicts what we learned since the running time of network flow is O(Cm)! Where am I wrong? Is it because network flow problem’s running time is pseudo-polynomial time like knapsack problem(Wn)? I am so confused now! \n    ", "Answer": "\r\nYou still technically have to show that the reduction takes polynomial time, but that is a more minor issue here. The main issue is that your reduction is the wrong way around. \n\nTo show that something is NP-complete, you need to do two things:\n\n\nShow that it is in NP\nShow that it is also NP-hard.\n\n\nTo do the latter using reductions, you need to reduce ILP to network flow, not reduce network flow to ILP. The point of the reduction is to show that you could solve ILP (and by extension, every NP problem) in polynomial time if you could solve your given problem (in this case, network flow). By reducing the wrong way, you've actually shown that you can solve network flow in polynomial time if you could solve ILP in polynomial time (which is true but useless since network flow is in P).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Algorithms for subgraph isomorphism detection [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs to be more focused. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nSubgraph isomorphism is an NP Complete problem.  The most widely used algorithm is the one proposed by Ullman.\n\nCan someone please explain the algorithm to me in layman's language? I read the above paper by him, but couldn't understand much.\n\nWhat other algorithms exist for this problem?\n\nI am working on an image processing project.\n    ", "Answer": "\r\nVFLib2 is a C++ library for graph isomorphism finding. It also includes an Ullman implementation: http://mivia.unisa.it/datasets/graph-database/vflib/\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity of an old Top Coder riddle: Making a number by inserting +\r\n                \r\nThis is a follow up to my previous question (about an old top coder riddle).\n\nGiven a string of digits, find the minimum number of additions required for the string to equal some target number. Each addition is the equivalent of inserting a plus sign somewhere into the string of digits. After all plus signs are inserted, evaluate the sum as usual.\nFor example, consider \"303\" and a target sum of 6. The best strategy is \"3+03\".\n\nI guess (not proved it though) the problem is NP-complete.\nWhat do you think? How would you reduce a well-known NP-complete problem to this problem?\n    ", "Answer": "\r\nIf the base is made a parameter, then there is a reduction from subset sum. Let x1, …, xn, s > 0 be the instance of subset sum and let S = x1 + … + xn. In base S + 1, let the Top Coder input be\n\nx1 0 x2 0 … xn 0\n\nsumming to (S - s) (S + 1) + s.\n\nMuch more interesting of course is the hardness of the base 10 case.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reduce Subset Sum to Polyomino Packing\r\n                \r\nThis is a homework assignment, so any help is appreciated.\nI should prove that the following problem is NP-complete. The hint says that you should reduce the subset sum problem to this problem.\n\nGiven a set of shapes, like the below, and an m-by-n board, decide whether is it possible to cover the board fully with all the shapes. Note that the shapes may not rotate.\nFor example, for a 3-by-5 board and the following pieces, the board can be covered like this:\n\n\n\nNow the important thing to note is that the subset sum problem we are trying to reduce should be given input length polynomial in terms of m and n.\nAny ideas for using another NP-complete problem are appreciated.\n    ", "Answer": "\r\nThe easiest reduction is from the partition problem.\nSuppose that we have a set of positive numbers that sum to ```\n2n```\n and we want to know a subset of them sums to ```\nn```\n.\nWe create a set of blocks of length the numbers and width 1, then try to fit them into a rectangle of width 2 and length ```\nn```\n.  We can succeed if and only if the partition problem was solvable for those numbers, and the rows are the partition.  So any partition problem can be reduced to a polyomino packing problem in linear time.  Since the partition problem is NP-complete, we are done.\nBut they said subset sum.  If they mean subset sum on positive numbers, then we can just use another trick.  Suppose that our numbers sum to ```\nn```\n and we want to know if a subset sums to ```\nk```\n.  Then we just add 2 numbers to the problem of size ```\nk+1```\n and size ```\nn-k+1```\n and aim to solve the partition problem.  If we succeed, our additional 2 numbers couldn't have been in the same partition and so the rest are a solution to the partition problem.  Since we've already reduced the partition problem to polyomino packing problem, we are done.\nIf they intended subset sum from numbers that can be both positive and negative, then I don't see the reduction that they suggested.  But since I've managed to reduce 2 well-known NP-complete problems to this one, I think we're good.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Need help to understand the Prove that the longest path problem is NP complete by reduction from Hamiltonian path\r\n                \r\nHamiltonian Path: If there is a path to visit each vertex of a graph exactly once.\nLongest Path: Given a graph G=(V,E) and an integer k, decide if there is a simple path of length k.\nIn my class, the solution is to set k = V-1, and then it is trivial that the two problems are equivalent.\nI can understand the direction from Hamiltonian Path to the longest path. But I cannot understand the direction from the longest path to the Hamiltonian path since the given number k does not need to be the number of vertices - 1.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Prove NP-Completeness of generating 2 shortest routes over given edge grouping constraints?\r\n                \r\nI've been trying unsuccessfully to the following problem is NP-Complete or NP-Hard.\n\nThe problem is as follows:\n\nYou are given a graph G(V,E) and asked to generate two routes from starting node S to node T.  The edges E are split into K disjoint sets.  Let us refer two the routes as R1 and R2.  There can be no edges E1 and E2 in the same set such that E1 is in the path R1 and E2 is in R2 (in simpler terms each set must be used by no more than one of the routes).  Additionally there can be no nodes shared between R1 and R2.  We are seeking the shortest combined path length of R1 and R2 (Minimize (len(R1) + len(R2)) ).\n\nI have tried reducing Subset Sum and Independent Set to this with no success.\n    ", "Answer": "\r\nFor starters, thanks for posting a seriously interesting problem. This was a lot of fun to work through!\n\nThe reduction I've come up with is from 3SAT to your problem. Intuitively, the reduction works as follows: we build a graph consisting of two parallel, cascading series of nodes (let's call them the left and the right branches). The left branch edges correspond to the variables in the formula and the right branch corresponds to the clauses in the formula. We'll build the graph such that the two paths correspond to choosing a variable assignment for the formula that satisfies all the clauses.\n\nThe left branch, which forces variables to take on values, is build as follows. For each variable x, build a gadget that looks like this:\n\n```\n              *\n  true -->   / \\  <-- false\n            *   *\n             \\ /\n              *\n```\n\n\nStarting at the top node, we'll have \"left\" mean \"x is true\" and \"right\" mean \"x is false.\" We'll build one copy of this gadget for each variable and link them from top to bottom. Therefore, a path from the top of the chain down to the bottom corresponds to choosing a variable assignment for the propositional formula.\n\nThe right branch is built similarly. Suppose we have a clause x &lor; y &lor; z. We then build this gadget:\n\n```\n              *\n             /|\\\n            * * *\n             \\|/\n              *\n```\n\n\nHere, the left branch corresponds to \"x is true,\" the middle branch corresponds to \"y is true\", and the right branch corresponds to \"z is true.\" The idea is that we need to have at least one true literal per clause, and we'll choose which literal that is by choosing which path to go down.\n\nNow, we build the constrain sets. For each variable x, we want to ensure that if in the left branch we say that x is true, we don't follow an edge in the right branch where x is supposed to be false. Therefore, we'll create a constraint set containing the edge \"x is true\" from the left branch and all copies of \"x is false\" from the right branch. We'll similarly create a second constrain set containing the edge \"x is false\" from the left branch and all edges marked \"x is true\" from the right branch. These constraint sets collectively ensure that if we take a path through the left branch and through the right branch, we chose a value for every variable (the path through the left branch) and picked at least one true literal per clause (the path through the right branch).\n\nTo finish everything, we'll create a new start node S and a new terminal node T, linking S to the first node in the left branch and the first node in the right branch and linking the last node in the left and right branches to T. Now, there's a satisfying assignment to the formula if and only if there are two node-disjoint paths from S to T respecting all the constraints. Doing some quick math shows that if the formula has n variables and m clauses, then the length of the path through the left branch will be 2n + 2 and the length of the path through the right branch will be 2m + 2, so the formula is satisfiable if and only if there's a pair of node-disjoint paths from S to T of combined length 2n + 2m + 4. Note that there isn't a legal path at all if the formula isn't satisfiable.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What problem type the Power Set belong to?\r\n                \r\nI don't seem to find any much resource about \"Power Set\" problem.\nIs Power Set a NP-Complete or NP-Hard problem? And why? Can someone advise me?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Computational complexity of a longest path algorithm witn a recursive method\r\n                \r\nI wrote a code segment to determine the longest path in a graph. Following is the code. But I don't know how to get the computational complexity in it because of the recursive method in the middle. Since finding the longest path is an NP complete problem I assume it's something like ```\nO(n!)```\n or ```\nO(2^n)```\n, but how can I actually determine it?\n\n```\npublic static int longestPath(int A) {\n    int k;\n    int dist2=0;\n    int max=0;\n\n    visited[A] = true;\n\n    for (k = 1; k <= V; ++k) {\n        if(!visited[k]){\n            dist2= length[A][k]+longestPath(k);\n            if(dist2>max){\n                max=dist2;\n            }\n        }\n    }\n    visited[A]=false;\n    return(max);\n}\n```\n\n    ", "Answer": "\r\nYour recurrence relation is ```\nT(n, m) = mT(n, m-1) + O(n)```\n, where ```\nn```\n denotes number of nodes and ```\nm```\n denotes number of unvisited nodes (because you call ```\nlongestPath```\n ```\nm```\n times, and there is a loop which executes the visited test ```\nn```\n times). The base case is ```\nT(n, 0) = O(n)```\n (just the visited test).\n\nSolve this and I believe you get T(n, n) is O(n * n!).\n\nEDIT\n\nWorking:\n\n```\nT(n, n) = nT(n, n-1) + O(n) \n        = n((n-1)T(n, n-2) + O(n)) + O(n) = ...\n        = n(n-1)...1T(n, 0) + O(n)(1 + n + n(n-1) + ... + n(n-1)...2)\n        = O(n)(1 + n + n(n-1) + ... + n!)\n        = O(n)O(n!) (see http://oeis.org/A000522)\n        = O(n*n!)\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is finding zeros of a function a NP-pb?\r\n                \r\nI would like to find the zeros of a real function of multiple variables.\nMany algorithms are known to solve this problem (such as the Newton-Rhapson method), but in the general case, do these problems belong to the NP-complete class of problems ?\nIn other words do we know a method to solve this in reasonable time if the number of variables becomes high ?\n\nThanks in advance !\n\nPS: I haven't found this question asked on the forum but some topics seem closely related, if my question is redundant please tell me.\n    ", "Answer": "\r\nWhat is your input definition? Remember, for questions of complexity, you need to compare run times to the encoding length of the input.\n\nAnd what do you understand as a \"solution\" in computer terms? One finite definition would be a box with rational corners containing exactly one solution. Or a similar box inside the domain of quadratic convergence of Newtons method. See the standard book of Blum/Shucker/Smale/?? on the complexity of the real numbers.\n\nEven for polynomial problems the situation is complicated, it is not known if the solution of polynomial systems is in P or in NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "A 2-approximation algorithm for Vertex-Cover problem using \"Spanning Tree\"\r\n                \r\nI have seen a question on 2-approximation algorithm for Vertex-Cover problem(VC, known Np-Complete problem), and i don't know the answer. The problem is the following : Find a 2-approximation algorithm for Vertex Cover problem using \"Spanning Tree\". \nWell, many greedy approaches are already presented for VC, but special algorithm using \"Spanning Tree\" is challenging.\nAny idea? \n    ", "Answer": "\r\nYou just search for max matching in the given graph and the solution is the set of nodes that create a max matching.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is applying AI ok and/or practical to finding the optimal solution to the algorithmic problem\r\n                \r\nBoth in learning environment and practice, from time to time I had to use different algorithms to solve problems. But the more I use them, the more it seems like the AI could be deployed to try finding the optimal solution, especially to the NP-complete problems, since the AI \"progression\" is easily tracked\n\nIf we, for example, never knew how to solve knapsack problem efficiently; I wonder, is applying AI practical and/or ever OK to finding the optimal solution to the given problem? \n    ", "Answer": "\r\nAI algorithms in general can find an approximation to basically any function. They are so powerful because this is true even for extremely complex functions with many input parameters and/or many output parameters and/or a very complicated internal structure. \n\nOn the other hand, there is no known way to solve NP-complete problems \"quickly\". In practice, you would often have to search through a huge solution space for finding the optimal solution. This is why people use heuristic methods and approximation algorithms to efficiently find a \"sufficiently good\" solution. \n\nSo yes, you can use AI to find a good approximate solution (and possibly even a better one than with traditional heuristics) to a computationally hard problem. \n\nBut no, if the problem is NP-complete, you still cannot know that you have found the optimal solution. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "delete minium weight edges to disconnect a set of nodes\r\n                \r\nThe problem says that given a weighted edge bidirectional graph, find the set of edges, by deleting which a given set of nodes becomes disconnected with each other. And also the sum of these edge weights should be minimum. Does this problem has any name? Any particular algorithm to solve them? I know that this must be the NP complete problem.   \n    ", "Answer": "\r\nIf you just want to find a minimum weight cut which departs your graph into two part, this simply can be done by running max flow/min cut algorithm (e.g Edmonds algorithm). You just should fix one vertex and then find its min cut with all other |V|-1 vertices, finally out put minimum cut among all cuts. Note that your fixed vertex should be in one of a components. For running max-flow/min cut algorithm on undirected graphs just draw each edge into two direction. This algorithm causes to running max-flow algorithm * O(|V|).\n\nBut if your problem is how to divide the graph into k connected component with minimum weight cut, this is NP-Hard problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Finding a loopless path passing through a series of nodes?\r\n                \r\nGiven a directed graph, which has n points, there are k \"must pass\" points, where k < n-2.\n\nHow do I find a path from a start node to an end node that passes through all the \"must pass\" points without revisiting any nodes? Maybe this is a NP-complete problem... seems like TSP is very similar to this problem.\n    ", "Answer": "\r\nThis problem is indeed NP-hard. To see this, you can reduce the Hamiltonian path problem to this one by starting with the original graph, adding in two new nodes not connected to anything, then asking for a path that passes through every node in the graph except for those two new ones.\n\nYou may be able to use some techniques designed for finding long paths in graphs, like color coding or dynamic programming techniques, to avoid a brute-force search, but given the nature of this problem I doubt you'll be able to do much better than brute-force.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Sub Exponential compleixty\r\n                \r\nI saw in the below link that 2nO(1)\nis sub exponential complexity. I do not understand the difference between 2n and 2nO(1). Aren't they the same as O(1) evaluates to 1? \n\nhttps://cs.stackexchange.com/questions/9813/are-there-subexponential-time-algorithms-for-np-complete-problems\n\nI have algorithms of subset sum problem that have been solved in 2n -1 runtime steps thus having O(2n) complexity. Is that sub polynomial time? If it is then it violates the exponential time hypothesis(ETH) and proves P not equal to NP!\n\nI also know that brute force for such problems runs in O(2n). So what is the difference in this complexity and sub exponential one?\n\nPlease help.\nThanks!\n    ", "Answer": "\r\nO(1) is definitely not the same as 1.\n\nIf f(x) is in O(1), then so is g(x)=c×f(x). For example, f(x)=(x−1)⁄x is clearly in O(1) since its asymptotic to 1, and so is g(x)=(x−1) ⁄ 2 x, whose asymptote is 0.5.\n\nBut 2n1 (=2n) is quite different from 2n1⁄2 (=2√n). The latter certainly could be described as subexponential. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What is an algorithm to find the circuit with max weight in a directed graph?\r\n                \r\nFirst problem was that i couldn't find an algorithm that,given an directed graph as input, gives as output a list of all cycles present in the graph. (This problem should be NP-complete).\n\nAfter thinking about the problem for a while I realized that what probably I really needed was to find the circuit (it can have duplicate vertex but not duplicate edges) with max weight (sum of the weights of the edges). \n\nIt should be a NP-complete problem too, and a way to proceed could be to list  all circuits present in the graph and then to sort them by sum of edge weights. \n\nDo you know some algorithm that gives as output a list of all circuits present in a directed graph? Or one that find the circuit with max weight ?\n\nI have found this, but it's not exactly what i need.\n\nhttp://epubs.siam.org/doi/abs/10.1137/0205007\n\nHowever do you confirm the computational complexity of these problems ?\n    ", "Answer": "\r\nYou could do sth. like here: Finding all cycles in a directed graph.\n\nYou do this search for every node and parallelize that so as to reduce runtime. Afterwards you apply an efficient sort-algorithm to your list of cycle where each cycle is a list of nodes. Sorting algorithms may me Mergesort or Quicksort for instance, but choose which ever u prefer..\n\nI hope that brings u forward.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Ideas for student parallel programming project\r\n                \r\nI'm looking to do a parallel programming project in C (probably using pthreads or maybe OpenMP) for a class. It will done by a group of about four students, and should take about 4 weeks. I was thinking it would be interesting to attack some NP-complete problem with a more complex algorithm like a genetic algo with simulated annealing, but I'm not sure if it would be a big enough project.\n\nAnyone knew of any cool problems that could benefit from a parallel approach?\n    ", "Answer": "\r\nI remember a 'learning' project at our university about parallelizing alpha-beta pruning algorithms. Alpha-beta pruning itself isn't too complicated and has quite large complexity. If you parallelize it you'll need to install some signaling/data sharing to really benefit from the parallelization. Otherwise some threads would go too often or too deep into branches that already were considered too bad by other threads. I think that can be a good use case.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to determine if a NxN matrix with non-negative integer entries is a product of k square 0/1 matrices?\r\n                \r\nSo I'm suspecting this problem could be NP-complete or NP-hard at least in certain circumstances, but still, often for NP-complete problems there is a nice solution that runs much faster than naïve brute force. \n\nMy problem is, given an NxN matrix A, with non-negative integer entries, and an integer k > 1, how can we determine if A can be written as a product of k NxN matrices whose entries are all either 0 or 1?\n\nLike I said, I think this problem may be \n\n\nNP-complete even for k = 2 but I maybe wrong, \nmaybe it's polynomial time for k=2 or even for any fixed k or even for k not fixed. \nAlso it may help to bound the non-negative entries in the target matrix A, to come up with good running times. \n\n\nI would just like to find out good algorithms that run asymptotically faster (hopefully much faster) than brute force over all choices of 0/1 matrices to multiply. \n\nAlso, I apologize if this question is better suited on CS.stackexchange, if so, please let me know and I'll migrate the question. However we do have an ```\nalgorithm\"```\n tag here, and since I suspect this problem is NP-hard, at least in one of its variants about whether k=2 or k is fixed or unbounded k, it's of more interest to me to just get whatever good algorithms may be available, e.g. that may work in polynomial time for fixed k or run in pseudo-polynomial time for arbitrary k but not polynomial time in general.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "List of problems that are in general NP-hard but have polynomial-time solution in planar graphs?\r\n                \r\nI encountered many problems that can be formulated as graph problem.\nIt is in general NP-hard but sometimes the graph can be proved to be planar.\nHence, I am interested in learning these problems and the algorithms.\n\nSo far as I know:\n\n\nMax cut in planar graphs\nFour-coloring in planar graphs\nMax Independent Set in cubic planar graphs\n\n\nHope someone can complete this list.\n    ", "Answer": "\r\nIn this compendium of NP-complete problems, under planar in the index there are a good number (~25) of entries.  These entries typically link to problems where planar input admits a PTAS.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "ILP in poly-time?\r\n                \r\nInteger programming is said to be NP-complete. However, I think formulating a problem into ILP can't prove the problem to be NP-hard. Is there any example of problem that can be modeled into ILP but has a polynomial time?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Subset-sum prob. (congruence variation)\r\n                \r\nI'm wondering about the NP-completeness of a variation of the Subset-sub problem:\n\nSubset-sum problem:\nGiven a set of integers and an integer s, does any non-empty subset sum to s?\n\nThis problem is known to be in NP and be NP-complete. Now consider the variation:\n\nSubset-sum problem (congruence variation):\nGiven two integers s and m and a set of integers modulo m, does any non-empty subset sum to s mod m?\n\n(i.e., all the numbers in the set are modulo m and the expected sum s is also in mod m). \n\nI'm wondering if this problem has been studied before? (Would like to know if it is NP-complete or not). Does anyone know if there is any paper or similar variation of the Subset-sum problem? Thank you!\n    ", "Answer": "\r\nYes, this problem is also NP-complete.  Since normal subset sum is NP complete, there is a reduction of some other NP-complete problem to subset sum.\n\nThe same reduction will also work to prove that modular subset sum is NP complete, if you can additionally generate a sufficiently large modulus with a size that is polynomial in the input size.  The modulus just has to be bigger than the largest number used in the subset sum solution, and then the difference between subset sum and modular subset sum is irrelevant.\n\nFor any reduction I can think of, it is easy to generate such a modulus.  Remember that it is only the size of the modulus that has to be polynomial in the input size, so, say 100^(N^2) works fine -- it's only 2*(N^2) digits long.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity of subset sum with multiple targets\r\n                \r\nIs the following problem in NP-Complete or P? \nInput: A set S of positive integers {a1, a2, ..., an) and a positive integer M \nQuestion: Is there a subset S' of S such that all the elements in S' sum to either M-1, M or M+1.\n\n\nMy guess is that it is in NP-Complete and related to subset sum. However I'm having a hard time reducing Subset sum to this problem.\n    ", "Answer": "\r\nThis is NP-complete. Given an instance of subset sum\n\n\n  Find a subset of {x1, ... xn} with sum X\n\n\nConsider the following instance of your problem\n\n\n  Find a subset of {4 * x1, 4 * x2, ..., 4 * xn} with sum 4*X, 4*X-1 or 4*X + 1\n\n\nBy considering divisibility-by-4, it's clear that any subset which sums to 4*X, 4*X-1 or 4*X + 1 will actually have to sum to 4X. But that then trivially gives a solution to the original subset-sum problem, by dividing through by 4.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this an NP problem?\r\n                \r\nfirst off I'm going to say I don't know a whole lot about theory and such. But I was wondering if this was an NP or NP-complete problem. It specifically sounds like a special case of the subset sum problem.\n\nAnyway, there's this game I've been playing recently called Alchemy which prompted this thought. Basically you start off with 4 basic elements and combine them to make other elements. \n\nSo, for instance, this is a short \"recipe\" if you will for making elements\n\n\nfire=basic element\nwater=basic element\nair=basic element\nearth=basic element\nsand=earth+earth\nglass=sand+fire\nenergy=fire+air\nlightbulb=energy+glass\n\n\nSo let's say a computer could create only the 4 basic elements, but it could create multiple sets of the elements. So you write a program to make any element by combining other elements. How would this program process the list the create a lightbulb? \n\nIt's clearly fire+air=energy, earth+earth=sand, sand+fire=glass, energy+glass=lightbulb. \n\nBut I can't think of any way to write a program to process a list and figure that out without doing a brute force type method and going over every element and checking its recipe. \n\nIs this an NP problem? Or am I just not able to figure this out? \n    ", "Answer": "\r\n\n  How would this program process the list the create a lightbulb?\n\n\nSurely you just run the definitions backwards; e.g. \n\n\nCreating a lightbulb requires 1 energy + 1 glass\nCreating an energy requires 1 fire + 1 air\n\n\nand so on.  This is effectively a simple tree walk.\n\nOTOH, if you want the computer to figure out that energy + glass means lightbulb (rather than \"blob of molten glass\"), you've got no chance of solving the problem.  You probably couldn't get 2 gamers to agree that energy + glass = lightbulb!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "show the problem of find two subsets such that the difference of them of two sets is smaller than a value, is NP-Hard\r\n                \r\nAs input, given two finite sets of integers X = {x1,...,xm},Y = {y1,...,yn} ⊆ Z, and a non-negative integer v ≥ 0. The goal is to decide if there are non-empty subsets S ⊆ [m] and T ⊆ [n] such that\n|\nHow to show this problem is NP-Complete? I'm quite confused\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Maximum non-overlapping intervals in a interval tree\r\n                \r\nGiven a list of intervals of time, I need to find the set of maximum non-overlapping intervals.\n\nFor example,\n\nif we have the following intervals:\n\n```\n[0600, 0830], [0800, 0900], [0900, 1100], [0900, 1130], \n[1030, 1400], [1230, 1400]\n```\n\n\nAlso it is given that time have to be in the range ```\n[0000, 2400]```\n.\n\nThe maximum non-overlapping set of intervals is ```\n[0600, 0830], [0900, 1130], [1230, 1400]```\n.\n\nI understand that maximum set packing is NP-Complete. I want to confirm if my problem (with intervals containing only start and end time) is also NP-Complete. \n\nAnd if so, is there a way to find an optimal solution in exponential time, but with smarter preprocessing and pruning data. Or if there is a relatively easy to implement fixed parameter tractable algorithm. I don't want to go for an approximation algorithm.\n    ", "Answer": "\r\nThis is not a NP-Complete problem. I can think of an ```\nO(n * log(n))```\n algorithm using dynamic programming to solve this problem.\n\nSuppose we have n intervals. Suppose the given range is ```\nS```\n (in your case, ```\nS = [0000, 2400]```\n). Either suppose all intervals are within ```\nS```\n, or eliminate all intervals not within ```\nS```\n in linear time.\n\n\nPre-process:\n\n\nSort all intervals by their begin points. Suppose we get an array ```\nA[n]```\n of n intervals.\n\n\nThis step takes ```\nO(n * log(n))```\n time\n\nFor all end points of intervals, find the index of the smallest begin point that follows after it. Suppose we get an array ```\nNext[n]```\n of ```\nn```\n integers.\n\n\nIf such begin point does not exist for the end point of interval ```\ni,```\n we may assign ```\nn```\n to ```\nNext[i]```\n.\nWe can do this in ```\nO(n * log(n))```\n time by enumerating n end points of all intervals, and use a binary search to find the answer. Maybe there exists linear approach to solve this, but it doesn't matter, because the previous step already take ```\nO(n * log(n))```\n time.\n\n\nDP:\n\n\nSuppose the maximum non-overlapping intervals in range ```\n[A[i].begin, S.end]```\n is ```\nf[i]```\n. Then ```\nf[0]```\n is the answer we want.\nAlso suppose ```\nf[n] = 0```\n;\nState transition equation:\n\n\n```\nf[i] = max{f[i+1], 1 + f[Next[i]]}```\n\n\nIt is quite obvious that the DP step take linear time.\n\n\n\nThe above solution is the one I come up with at the first glance of the problem. After that, I also think out a greedy approach which is simpler (but not faster in the sense of big O notation):\n\n(With the same notation and assumptions as the DP approach above)\n\n\nPre-process: Sort all intervals by their end points. Suppose we get an array ```\nB[n]```\n of n intervals.\nGreedy:\n\n```\nint ans = 0, cursor = S.begin;\nfor(int i = 0; i < n; i++){\n    if(B[i].begin >= cursor){\n        ans++;\n        cursor = B[i].end;\n    }\n}\n```\n\n\n\nThe above two solutions come out from my mind, but your problem is also referred as the activity selection problem, which can be found on Wikipedia http://en.wikipedia.org/wiki/Activity_selection_problem.\n\nAlso, Introduction to Algorithms discusses this problem in depth in 16.1.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Gurobi: Optimize a quadratic non PSD\r\n                \r\nWill Gurobi optimize a quadratic problem where the objective function\nis NOT positive definite?  Our constraints are linear--in fact, they are\nbox constraints.  This is a known NP-complete problem, as per Vavasis,\nNonlinear Complexity: Optimization Issues, Oxford University Press.\n\nWe know that Gurobi will not optimize a quadratic programming problem\nwith quadratic constraints, except under special conditions.  However, we\nhave not seen a specific statement that it can or cannot handle\na quadratic objective function.\n    ", "Answer": "\r\nGurobi is designed to handle problems with objective functions that are linear or\n\n\nconvex quadratic functions for minimization problems\nconcave quadratic functions for maximization problems\n\n\nIn addition, it can handle quadratic constraints where the feasible region is convex or a second order cone\n\nYou haven't mentioned the type of problem that you are tackling, but if you want to use Gurobi to solve it, the best approach is probably to use its mixed-integer linear optimizer, or use a decomposition method.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "I have found on the Internet polynomial time algorithm for graph coloring, possibly proving P=NP\r\n                \r\nI was searching for graph coloring algorithms, and I have found algorithm, which, how author states, runs in polynomial time.\nAuthor gives also C++ program source code and demonstration program.\n\nThe suspicious thing is that decision problem whether graph is k-colorable, is NP-complete, so no polynomial time algorithm should exist until P=NP.\n\nHowever, author doesn't claims, that algorithm works for all graphs, he only says, that he haven't found any graph, for which algorithm doesn't work.\n\nSo, the question: does that algorithm really works for every graph and that means actually P=NP, or there exist certain graphs/graph classes for which it doesn't work? Or maybe there is simply a mistake in complexity calculation?\n    ", "Answer": "\r\nI think you haven't read the abstract very carefully.\n\nThe author presents an algorithm which finds ```\nm```\n-colorings of a graph, for some ```\nm```\n less than the limit imposed by Brooks' theorem: https://en.wikipedia.org/wiki/Brooks'_theorem\n\n(which is old and states that ```\nchi < delta + 1```\n as the author states in second sentence.)\n\nThe author is aware of the P vs NP question. The paper does not claim to resolve the question, he merely states:\n\n\n  For all known examples of graphs, the algorithm finds a proper m-coloring of the vertices of the graph G for m equal to the chromatic number χ(G)\n\n\nThen he asks,\n\n\n  In view of the importance of the P versus NP question, we ask: does there exist a graph G for which this algorithm cannot find a proper m-coloring of the vertices of G with m equal to the chromatic number χ(G)?\n\n\nEmphasis in original (!)\n\nSo it doesn't claim to resolve P vs NP, its just, as a matter of academic research, they ask \"can anyone produce an example on which this algorithm fails to reach the chromatic number\", which might be instructive to them for mathematical purposes. It is highly unlikely that the algorithm actually achieves the chromatic number for all graphs. (Although it is, scientifically speaking, unknown whether it does or doesn't.)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Gurobi: Optimize a quadratic non PSD\r\n                \r\nWill Gurobi optimize a quadratic problem where the objective function\nis NOT positive definite?  Our constraints are linear--in fact, they are\nbox constraints.  This is a known NP-complete problem, as per Vavasis,\nNonlinear Complexity: Optimization Issues, Oxford University Press.\n\nWe know that Gurobi will not optimize a quadratic programming problem\nwith quadratic constraints, except under special conditions.  However, we\nhave not seen a specific statement that it can or cannot handle\na quadratic objective function.\n    ", "Answer": "\r\nGurobi is designed to handle problems with objective functions that are linear or\n\n\nconvex quadratic functions for minimization problems\nconcave quadratic functions for maximization problems\n\n\nIn addition, it can handle quadratic constraints where the feasible region is convex or a second order cone\n\nYou haven't mentioned the type of problem that you are tackling, but if you want to use Gurobi to solve it, the best approach is probably to use its mixed-integer linear optimizer, or use a decomposition method.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Heuristic to find the maximum weight independent set in an arbritary graph\r\n                \r\nThe MWIS (Maximum weight independent set) is a NP-complete problem, so if P!=NP we cannot find a solution in a good enough time complexity.\n\nI am looking for an algorithm that can find an approximation of the MWIS in an arbitrary graph within a good time complexity. I am currently working on a connected graph with 128 nodes and 3051 edges.\n\nI have found this paper, but it seems that it is only working for bipartite graph with an unique MWIS.\n\nI will be glad if anyone can help me with some references or even better with a pseudo-code of a working algorithm.\n    ", "Answer": "\r\nIt's possible to formulate this as the following problem. Suppose each vertex v in the graph has weight w(v). You define a variable x(v), and use some out-of-the-box linear programming solver to solve\n\nmax \\sum_v w(v) x(v) (maximize the weight of chosen vertices)\n\nsubject to \n\nx(u) + x(v) <= 1, (u, v) \\in E (don't take neighbors)\n\nand\n\nx(v) \\in {0, 1} (can only choose to take or not take a vertex)\n\n\n\nThis is a combinatorical problem (the last constraint is exponential in the number of vertices). There are two ways to continue from here:\n\n\nSwitch the last constraint to \n\nx(v) \\in [0, 1] (extent to which you choose a vertex)\n\nsolve it with an LP solver, and continue along this paper, 4.3.\nIn the comment below, David Eisenstat claims that for the sizes of your graph, an integer solver will do just fine (and yield better results)\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why cant we use algorithm to find all cycles to find an hamiltonian cycle?\r\n                \r\nI recently came across algorithms to find all cycles in an undirected graph, and was confused when i saw that they are running linear time (example), It seem easy to use one of these to find hamilton cycle (for each cycle we find just check if it is of n nodes, e.g contains all nodes) in polynomial time, but hamilton problem is a known NP complete problem so i gotta be missing something... what am i missing here?\nThanks!\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Polygon packing 2D\r\n                \r\nI have problem of packing 2 arbitrary polygons. I.e. we have 2 arbitrary polygons. We are to find such placement of this polygons (we could make rotations and movements), when rectangle, which circumscribes this polygons has minimal area.\n\nI know, that this is a NP-complete problem. I want to choose an efficient algorithm for solving this problem. I' looking for No-Fit-Polygon approach. But I could't find anywhere the simple and clear algorithm for finding the NFP of two arbitrary polygons.\n    ", "Answer": "\r\nThe parameter space does not seem too big and testing it is not too bad either. If you fix one polygon, the other ploygon can be shifted along x-axis by X, and shifted along y-axis by Y and rotated by r.\n\nThe interesting region for X and Y can be determined by finding some bounding box for for the polygons. r of course is between  and 360 degrees.\n\nSo how about you tried a set of a set of equally spaced intervals in the interesting range for X,Y and r. Perhaps, once you found the interesting points in these dimensions, you can do more finer grained search.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to assign N numbers into M pack that minimize some target function?\r\n                \r\nI have N(for example 30) integer numbers ```\nV[i]```\n, and M(for example 8) packs, each pack\nhave an expected value ```\nP[j]```\n.\n\nI want to assign each integer number to one pack, the following expression calculate the difference\nbetween the sum of ```\nV[k]```\n that in pack ```\nj```\n and the expected value of pack ```\nj```\n.\n\n```\ndiff[j] = abs(P[j] - sum(V[k] that in pack j))\n```\n\n\nThe target is to find the best solution that minimize ```\nsum(diff[j])```\n.\n\nI don't know what's the type of this kind of problem. Can this be solved by Linear programming, or is it a NP-Complete problem?\n    ", "Answer": "\r\nRegardless of whether this is NP-hard or not, you may be able to efficiently solve your problem for the problem instances you need using easily accessible integer programming software. For your problem, you could define x_{ij} to define if X[i] is assigned to group j. You would then also define variables d_j, which are the diff[j] in your formulation. Then your model is:\n\n```\nmin_{x, d} \\sum_{j=1}^M d_j\ns.t.       d_j >= P[j] - \\sum_{i=1}^N X[i]x_{ij} \\forall j\n           d_j >= \\sum_{i=1}^N X[i]x_{ij} - P[j] \\forall j\n           \\sum_{j=1}^M x_ij = 1 \\forall i\n           x_{ij}\\in \\{0, 1\\}\n```\n\n\nThis is a mixed integer optimization model, which can be solved, for instance, using the ```\nlpsolve```\n or ```\nlpSolveAPI```\n packages in R or the ```\nintlinprog```\n function in MATLAB.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Problem for which proof of NP is non-trivial\r\n                \r\nI'm looking for a problem that (provably) lies in NP, but for which the proof that it lies in NP is \"not completely trivial/obvious\". Anyone know of such a problem (ideally a \"natural\" problem)?\n    ", "Answer": "\r\nI think primality is a good candidate for this:\n\nWitnessing that a number is composite is easy (give a factorization), and it can be checked efficiently.\n\nWitnessing that a number is prime is not so obvious. But it has been known since the 80s that this can be done. So for a long time, PRIMES was a natural language in \"NP intersect coNP\".\n\nIt is known since like 2004 that PRIMES is actually in P\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are there exact methods to solve the Path cover in bipartite graphs?\r\n                \r\nWe consider a simple graph G =(V; E). The well known Path Cover problem  (https://en.wikipedia.org/wiki/Path_cover) is NP-complete on all graph classes on which the Hamiltonian path problem is NP-complete, including planar graphs, bipartite graphs and chordal graphs.  Many polynomial algorithms have been proposed in the literature for special graph classes on which this problem is polynomial, but I did not find any exact methods to find the minimum vertex-disjoint path cover for bipartite graphs (or even for planar graphs and chordal graphs), especially Branch and Bound Algorithms.\n\nDo you know any exact methods, in particular Branch and Bound algorithms, for the path cover problem on graph classes on which this problem is NP-hard  (bipartite graphs, planar graphs and chordal graphs)?\n\nThank you in advance.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is finding a simple path in a weighted undirected graph with maximum cost in polynomial time? Is it NP?\r\n                \r\nI need to know if it is possible to find a simple path with maximum cost in any weighted undirected graph. \n\nI mean to find THE MOST expensive path of all for any pair of vertex.\n\nInput: Graph G = (V,E)\n\nOutput: The cost of the most expensive path in the graph G.\n\nIs this problem NP-Complete?, I think it is. Could you provide any reference to an article where I can review this.\n    ", "Answer": "\r\nYou're not the first to think of this problem. In fact, it was the first link in the google search results.\n\nedit\nGuys, un-weighted graph is a special case of weighted graph: all edges have weight 1 :)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Edge bi-partitioning, no triangles: complexity?\r\n                \r\nI've got to find an algorithm to solve a problem for faculty.\nI'm not requesting solutions (and please don't post any), just read further.\n\nThe problem's sentence:\n\n```\n** Given a graph G = (V, E) find 2 sets S1 and S2 of edges of G such that:\n   1. S1 ∪ S2 = E\n   2. S1 ∩ S2 = ∅\n   3. The 2 subgraphs of G formed by S1 and S2 do not contain triangles (triangle = 3 nodes such that they link together 2 by 2)\n```\n\n\nI've been trying to find an algorithm to solve this in the last 2 days and I think I'm on the right way. For any of you that stumbled upon it before: do you know if this problem has been solved in polynomial time? (and if not, is it NP-complete/NP-hard/NP?)\n\nThanks in advance,\nJohn\n    ", "Answer": "\r\nGoogled a bit more and found it. It's called monochromatic triangle and it's NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How hard is this graph problem?\r\n                \r\nI have a problem to solve for a social-networks application, and it sounds hard: I'm not sure if its NP-complete or not. It smells like it might be NP-complete, but I don't have a good sense for these things. In any case, an algorithm would be much better news for me. \n\nAnyhow, the input is some graph, and what I want to do is partition the nodes into two sets so that neither set contains a triangle. If it helps, I know this particular graph is 3-colorable, though I don't actually know a coloring.\n\nHeuristically, a \"greedy\" algorithm seems to converge quickly: I just look for triangles in either side of the partition, and break them when I find them. \n    ", "Answer": "\r\nThe decision version of problem is NP-Complete for general graphs: http://users.soe.ucsc.edu/~optas/papers/G-free-complex.pdf and is applicable not just for triangles.\n\nOf course, that still does not help resolve the question for the search version of 3-colourable graphs and triangle freeness (the decision version is trivially in P).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is there a graph coloring algorithm where limits can be placed on number of vertices per color\r\n                \r\nI understand that graph coloring is a NP-complete problem. I was wondering if adding a restriction on the number of vertices that can have a given color makes the problem simpler? I can't seem to find any algorithm which does this. For example if I have a graph, I'd like to say \"what is the smallest coloring of this graph such that each color has at most 3 vertices\", or if it simplifies the problem \"is there a way to color this graph with 4 colors such that each color has at most 3 vertices\"?\n\nThanks!\n    ", "Answer": "\r\nThis problem is still NP-complete by a simple reduction from the original graph coloring problem: a graph with n nodes is k-colorable if and only if the graph can be colored with k colors and no color is assigned to more than n nodes.  In other words, the general version of the problem you're phrasing has graph coloring as a special case, and so it will still be NP-hard.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Shortest weight constrained path to Partition reduction\r\n                \r\nI am trying to prove NP-completness of a shortest weight constrained path problem. I have read multiple papers, but for love of god, cannot figure out how to show a reduction of this to partition problem. \n\nThe question is given for each edge, a weight w and length l, show that for an undirected graph, the problem of finding a path such that sum of weights on the path < W and sum of lenghths of the path < L where, L and W are constants given to us in the problem. \n\nI looked at Garey and Johnson which just states that problem is NP complete and doesn't provide a way to prove, or a reduction. \n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Graph Coloring with CLP(FD)\r\n                \r\nI am trying to solve the map/graph coloring problem using CLP(FD) in Prolog. I took the predicates from the paper\n\"A comparison of CLP(FD) and ASP solutions to NP-complete problems\" and I'm trying with the following example:\n```\ncoloring(K, Output) :- graph(Nodes, Edges),\n    create_output(Nodes, Colors, Output), domain(Colors, 1, K),\n    different(Output, Edges), labeling([ff], Colors).\ncreate_output([],[],[]).\ncreate_output([N | Nodes], [C|Colors], [N-C|Output]) :-\n    create_output(Nodes, Colors, Output).\ndifferent(_, []).\ndifferent(Output, [[A,B]|R]) :- member(A-CA, Output),\n    member(B-CB, Output), CA #\\= CB, different(Output, R).\ngraph([1,2,3,4,5],[(1,2),(1,3),(2,4),(2,5),(3,4),(3,5)]).\n```\n\nbut when I run the query\n```\ncreate_output([1,2,3,4,5],[a,b,c,d],A).```\n\nit gives me false even that for this graph it is possible to use only 4 colors (a,b,c,d). When I add another color it works fine, it seems that set of nodes should be same size as set of colors. But this is  not what map coloring should do.\nAnyone is able to help me understand what's the problem with the predicates above?\n    ", "Answer": "\r\nI think ```\ncreate_output/3```\n should be called with only Nodes instantiated. It will create the other 2 lists with domain variables (that is, color indexes) and associations between nodes and colors.\nAnyway, from the code below, you can see that the real problem is in the head of different/2, where a list has been used instead of a 'tuple' to match an edge...\n```\n\n:- module(mapcolor,\n          [coloring/2]).\n\n:- use_module(library(clpfd)).\n\ncoloring(K, Output) :-\n    graph(Nodes, Edges),\n    create_output(Nodes, Colors, Output),\n    domain(Colors, 1, K),\n    different(Output, Edges),\n    labeling([ff], Colors).\n\ndomain(Colors, Low, High) :- Colors ins Low .. High.\n\ncreate_output([],[],[]).\ncreate_output([N | Nodes], [C|Colors], [N-C|Output]) :-\n    create_output(Nodes, Colors, Output).\n\ndifferent(_, []).\ndifferent(Output, [(A,B)|R]) :-  % note: was [[A,B]|R]\n    member(A-CA, Output),\n    member(B-CB, Output),\n    CA #\\= CB,\n    different(Output, R).\n\ngraph([1,2,3,4,5],[(1,2),(1,3),(2,4),(2,5),(3,4),(3,5)]).\n\n```\n\nNote that the graph can be colored with just 2 colors:\n```\n?- coloring(2,C).\nC = [1-1, 2-2, 3-2, 4-1, 5-1] ;\nC = [1-2, 2-1, 3-1, 4-2, 5-2] ;\nfalse.\n```\n\nWith 4 colors, there are a lot of solutions...\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Sum-subset with a fixed subset size\r\n                \r\nThe sum-subset problem states:\n\n\n  Given a set of integers, is there a non-empty subset whose sum is zero? \n\n\nThis problem is NP-complete in general. I'm curious if the complexity of this slight variant is known:\n\n\n  Given a set of integers, is there a subset of size ```\nk```\n whose sum is zero? \n\n\nFor example, if ```\nk = 1```\n, you can do a binary search to find the answer in ```\nO(log n)```\n. If ```\nk = 2```\n, then you can get it down to ```\nO(n log n)```\n (e.g. see Find a pair of elements from an array whose sum equals a given number). If ```\nk = 3```\n, then you can do ```\nO(n^2)```\n (e.g. see Finding three elements in an array whose sum is closest to a given number).\n\n\n  Is there a known bound that can be placed on this problem as a function of ```\nk```\n?\n\n\nAs motivation, I was thinking about this question How do you partition an array into 2 parts such that the two parts have equal average? and trying to determine if it is actually NP-complete. The answer lies in whether or not there is a formula as described above.\n\nBarring a general solution, I'd be very interested in knowing an optimal bound for ```\nk=4```\n.\n    ", "Answer": "\r\nFor k=4, space complexity O(n), time complexity O(n2 * log(n))\n\nSort the array. Starting from 2 smallest and 2 largest elements, calculate all ```\nlesser```\n sums of 2 elements ```\n(a[i] + a[j])```\n in the non-decreasing order and  all ```\ngreater```\n sums of 2 elements ```\n(a[k] + a[l])```\n in the non-increasing order. Increase ```\nlesser```\n sum if total sum is less than zero, decrease ```\ngreater```\n one if total sum is greater than zero, stop when total sum is zero (success) or ```\na[i] + a[j] > a[k] + a[l]```\n (failure).\n\nThe trick is to iterate through all the indexes ```\ni```\n and ```\nj```\n in such a way, that ```\n(a[i] + a[j])```\n will never decrease. And for ```\nk```\n and ```\nl```\n, ```\n(a[k] + a[l])```\n should never increase. A priority queue helps to do this:\n\n\nPut ```\nkey=(a[i] + a[j]), value=(i = 0, j = 1)```\n to priority queue.\nPop ```\n(sum, i, j)```\n from priority queue.\nUse ```\nsum```\n in the above algorithm.\nPut ```\n(a[i+1] + a[j]), i+1, j```\n and ```\n(a[i] + a[j+1]), i, j+1```\n to priority queue only if these elements were not already used. To keep track of used elements, maintain an array of maximal used 'j' for each 'i'. It is enough to use only values for 'j', that are greater, than 'i'.\nContinue from step 2.\n\n\nFor k>4\n\nIf space complexity is limited to O(n), I cannot find anything better, than use brute force for ```\nk-4```\n values and the above algorithm for the remaining ```\n4```\n values. Time complexity O(n(k-2) * log(n)).\n\nFor very large ```\nk```\n integer linear programming may give some improvement.\n\nUpdate\n\nIf ```\nn```\n is very large (on the same order as maximum integer value), it is possible to implement O(1) priority queue, improving complexities to O(n2) and O(n(k-2)).\n\nIf ```\nn >= k * INT_MAX```\n, different algorithm with O(n) space complexity is possible. Precalculate a bitset for all possible sums of ```\nk/2```\n values. And use it to check sums of other ```\nk/2```\n values. Time complexity is O(n(ceil(k/2))).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Divide a given set of numbers N in two groups such that their difference of their sum is minimum?\r\n                \r\nYou can exempt atmost one element from the set to acheive the goal.\nexample:-\n\nN=3\n\nthe numbers given are = 1,2,5\n\nSo,\n\nSet 1 should be :- [1]\n\nSet 2 should be :- [2]\n\nWe have excluded 5 as we can acheive a lesser difference without it being in either groups.\n\nN=4\n\nnumbers = 1,2,2,5\n\nSet1 = [1,2,2]\n\nSet2 = [5]\n\nWhat is best algorithm for this?\nI know that this a NP-complete problem.\nAnd I think that brute force would give me the correct solution but I need an algorithm if available.\n    ", "Answer": "\r\n\n  I know that this a NP-complete problem.\n\n\nNot exactly, the partition optimisation problem is even known to be NP-hard.\n\n\n  And I think that brute force would give me the correct solution but I need an algorithm if available.\n\n\nNP-hard means just that there is no known algorithm (to determine the solution) performing better than the brute force method.\n\nSo you'll probably need an approximation, but which one fits your needs only you can know.\n\n\n  What is best algorithm for this?\n\n\nDefine \"best\".\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Finding the maximum sum that can be formed from a set, by partitioning it into two subset\r\n                \r\nDecription\n\nGiven a set of numbers S.\n\nFind maximum sum such that\n\nSum(A1) = Sum(A2)\n\nWhere, A1⊂S and A2⊂S and A1⋂A2=∅\n\nAnd Sum(X), is the sum of all elements within the set X.\n\nApproach\n\nBrute Force\n\nThe easiest approach is:\n\n```\nprint maximumSum(0,0,0)\ndef maximumSum(index,sum1,sum2):\n  ans=0\n  if sum1 == sum2:\n    ans=sum1\n  if index >= len(S):\n    return ans\n  m1=maximumSum(index+1,sum1+S[index],sum2)\n  m2=maximumSum(index+1,sum1,sum2+S[index])\n  m3=maximumSum(index+1,sum1,sum2)\n  return max(m,m1,m2,m3)\n```\n\n\nTime Complexity:O(2N)Space Complexity:O(1)\n\nIs there a better approach than this?\nOptional:\nI would like to know whether the given problem is an NP-Complete problem or not.\n\nEdit:\n\nLimits\n\n1 <= Sum(S) <= 1000000\n2 <= len(S) <= 100\nTime Limit: 60sec(can vary depending upon language used)\n    ", "Answer": "\r\nYes It is NPC problem\nPartition Problem\n\nYou can see the pseudo polynomial algorithm part if the sum of the set is small\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reducing Planning to Quantified Boolean Formulae\r\n                \r\nWhy don't we reduce the  Planning Problem in AI   to the \n TQBF Version of SAT  in practical solvers.\n\nMany planning problems are in practice \"compiled down\" or reduced to the SAT problem, which is in turn solved by SAT Solvers. The problem is that , since planning is PSPACE Complete, and SAT is NP Complete, an exponential number of literals may be required. \n\nWhy, then, do practical planners use this approach? Why don't we all solve TQBF SAT and then \"compile\" Planning down to TQBF, which should only take Polynomial time anyway?\n    ", "Answer": "\r\nThis has already been done.\n\nGenerally TQBF is used to model conformant planning, but there do exist encodings of purely propositional logic planning problems to (polynomially-sized) TQBF formulae.\n\nThe main drawback is that, although we have a much smaller formula, it's not neccessarily easier to solve.  TQBF solving is no way near as mature as the research into solving SAT, and Planning as TQBF is still some way behind in performance.\n\nHere is one publication detailing such a transformation (mine):\n\nhttp://users.cecs.anu.edu.au/~ssanner/ICAPS_2010_DC/Abstracts/cashmore.pdf\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Unit Testing Approximation Algorithms\r\n                \r\nI'm working on an open-source approximation algorithms library for graphs and networks using some popular python packages as a base. The main goal is to encompass up-to-date approximation algorithms for NP-Complete problems over graphs and networks. The reason for this is 1) I haven't seen a nice (modern) consolidated package that covers this and 2) it would be a nice pedagogical tool for learning about approximation algorithms on NP-Hard optimization problems.\n\nIn building this library I am using unit-tests to sanity check (as any proper developer would). I am somewhat cautious about my unit tests in that by their very nature, approximation algorithms may not return the correct solution. Currently I am solving some small instances by hand and then assuring that the returned result matches that, but this is not desirable, nor scalable in an implementation sense.\n\nWhat would be the best way to unit test approximation algorithms? Generate random instances and ensure that the returned results are less than the bound guaranteed by the algorithm? That would seem to have false positives (the test just got lucky that time, not guaranteed for all instances to be below bound).\n    ", "Answer": "\r\nYou need to separate two concerns here. The quality of your approximation algorithms and the correctness of implementation of those algorithms. \n\nTesting the quality of an approximation algorithm usually will not lend itself to unit testing methods used in software development. For example you would need to generate random problems that is representative of the real sizes of problems. You might need to do mathematical work to get some upper/lower bound to judge the quality of your algorithms for unsolvable large instances. Or use problem test sets that have known or best known solutions and compare your results. But in any case unit testing would not help you much in improving the quality of the approximation algorithms. This is where your domain knowledge in optimization and math will help.\n\nThe correctness of your implementation is where unit tests will be really useful. You can use toy sized problems here and compare known results (solving by hand, or verified through careful step by step debugging in code) with what your code generates. Having small problems is not only enough but also desirable here so that tests run fast and can be run many times during development cycle. These types of tests makes sure that overall algorithm is arriving at the correct result. It is somewhere between a unit test and an integration tests since you are testing a large portion of the code as a black box. But I have found these types of tests to be extremely useful in optimization domain. One thing I recommend doing for this type of testing is removing all randomness in your algorithms through fixed seeds for random number generators. These tests should always run in a deterministic way and give exactly the same result 100% of the time. \nI also recommend unit testing at the lower level modules of your algorithms. Isolate that method that assigns weights to arcs on the graph and check if the correct weights are assigned. Isolate your objective function value calculation function and unit test that. You get my point. \n\nOne other concern that cuts both of these slices is performance. You cannot reliably test performance with small toy problems. Also realizing a change that degrades performance significantly for a working algorithm quickly is very desirable. Once you have a running version of your algorithms you can create larger test problems where you measure the performance and automate it to be your performance/integration tests. You can run these less frequently as they will take more time but at least will notify you early of newly introduced performance bottlenecks during refactoring or new feature additions to algorithms \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Find best scoring assignment of customers to products\r\n                \r\nI got this programming question in an difficult interview's last round. \n\nSo the question has two lists of same size.\n\n```\nList<Customer>, List<Products>\n```\n\n\nThere is a function which is like follows\n\n```\nint score(Customer, Product)```\n and returns a score.\n\nI have to the find an assignment of all the customer to products where score should be maximum.\n\nIt seems like an NP-complete problem and unlikely to be solved by me in the interview especially when I still couldn't a few days after the interview. Now I am just curious to know the solution.\nCan anyone please help?\n    ", "Answer": "\r\nYou could model this as a weighted bipartite graph that you want to find a maximal match.\n\nWikipedia on Matching has this answer that may be useful:\n\n\n  In a weighted bipartite graph, each edge has an associated value. A\n  maximum weighted bipartite matching is defined as a matching where the\n  sum of the values of the edges in the matching have a maximal value.\n  If the graph is not complete bipartite, missing edges are inserted\n  with value zero. Finding such a matching is known as the assignment\n  problem. It can be solved by using a modified shortest path search in\n  the augmenting path algorithm. If the Bellman–Ford algorithm is used,\n  the running time becomes O(V^2 E), or the edge cost can be shifted\n  with a potential to achieve O(V^2 log(V) + V E) running time with the\n  Dijkstra algorithm and Fibonacci heap. The remarkable Hungarian\n  algorithm solves the assignment problem and it was one of the\n  beginnings of combinatorial optimization algorithms. The original\n  approach of this algorithm needs O(V^2E) running time, but it could be\n  improved to O(V^2 log(V) + V E) time with extensive use of priority\n  queues.\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Subgraph isomorphism to SAT\r\n                \r\nThe Subgraph Isomorphism (SI) problem is a computational task in which two graphs G and H are given as input, and one must determine whether G contains a subgraph that is isomorphic to H. \n\nThis is a NP-Complete problem .\n\nI want to know its relation with the SAT problem.\n In particular, I want  instances of this problem can be solved throughout SAT Solver(like miniSAT).I need an alorithm  which can do a mapping from SI to SAT problem in polynomial time and then SAT assignment can be used to find a mapping from nodes of G to nodes of H .  \n\nAny idea ??? \n    ", "Answer": "\r\nA ```\nSAT```\n encoding for the Graph Isomorphism problem is described in the SAT 2013 paper \"On the Resolution Complexity of Graph non-Isomorphism\".\n\nMinisat is one of the best-known SAT solvers, but it has several successors which are probably faster and have a higher success rate. Try Cryptominisat (version 2.9.5 seems to be faster than version 3; it supports parallel threads), Riss3g or Clasp.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is it possible to write a program to print all pairs that add to k from an input array of size n [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and  cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened,  visit the help center.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 12 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nIs it possible to write a program to print all pairs that add to k from an input array of size n. If so how? I heard this problem is NP-Complete. I was wondering if we can provide a solution to this problem in typical programming languages like C/C++\n    ", "Answer": "\r\nIt can't be NP-Complete as there is an obvious O(n^2) solution with two nested loops over the array and checking if the sum is k.\n\nThere is however an O(n) solution using hashtable. Here is the solution in C#:\n\n```\n        int[] ar = new int[] { 1, 4, 6, 8 };\n        int k = 7;\n\n        HashSet<int> set = new HashSet<int>();\n        foreach (int n in ar)\n        {\n            if (set.Contains(n))\n                Console.WriteLine(\"({0}, {1})\", k - n, n);\n\n            set.Add(k - n);\n        }\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Generate a minesweeper board which doesn't need guessing [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs to be more focused. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\r\n                \r\n                    \r\n                        Closed last year.\r\n                    \r\n                \r\n            The community reviewed whether to reopen this question last year and left it closed:\r\n            \r\n                    Original close reason(s) were not resolved\r\n            \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI am designing a Minesweeper-like game (with modified rules), and I want to prevent player from guessing. My goal is: The generated board is with few revealed squares, and player can solve the entire puzzle without any guessing.\n\nWikipedia mentioned:\n\n\n  Some implementations of Minesweeper will set up the board by never placing a mine on the first square revealed, or by arranging the board so that the solution does not require guessing. \n\n\nHowever, I cannot figure out the algorithm. \n\nBesides, in another StackOverflow question: Minesweeper solving algorithm\n\n\n  Improvement: Run the solver alongside the generator, making sure that the puzzle has a unique solution. This takes some cleverness, and isn't done in most variants.\n\n\nI doubt if this really works. It's well-known solving minesweeper is NP-complete. \n\nIn summary, my questions are:\n\n\nHow to generate a Minesweeper board which doesn't need any guessing?\nIf we can, what's the concrete algorithm?\nCould we solve this problem in polynomial time deterministically? Is this problem NP-complete? How to prove it?\n\n    ", "Answer": "\r\nThe implementation of Minesweeper in Simon Tatham's Portable Puzzle Collection is guessing-free. (It's also MIT licensed, so you're free to copy his implementation if you so desire.)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to find what numbers in a set add up to another given number?\r\n                \r\nHere's a problem that I seem to be running into working with an accounting system.\n\nI have a set of transactions, but their sum does not equal the amount that the accounting department thinks that it should. They are not questioning the math, just the transactions being included :p\n\nIs there an algorithm that would help me determine which transactions in the set should not be included in order for the sum to match a given amount.\n\n```\nGiven Set:  \n2  \n4  \n5  \n7\n\nGiven Sum Amount:\n13\n\nResult Set:\n2\n4\n7\n```\n\n\nEdit:\nThere's less than 100 transactions in the set. Does anyone have a C# example as there is not one on the Solving the NP-complete problem in XKCD question? \n\nMan, I should have gotten a CS degree.\n    ", "Answer": "\r\nThis is the Subset Sum problem, which is NP-Complete.  But that doesn't mean there isn't an algorithm for finding a subset sum.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "when a given graph is 3-colorable?\r\n                \r\nI want to use graph 3-colorability to prove a problem is NP-complete But I'm not sure when a given graph is 3-colorable. I think if it doesn't have any node to be connected to all 3 vertices of a triangle in the graph.But i'm not sure. is it correct?\n    ", "Answer": "\r\nNo. Having a node connected to all three nodes in a triangle (which is just a more complicated way of saying \"it has a clique of size 4\") is sufficient but not necessary for the graph to not be 3-colorable. Graphs may be not 3-colorable for different reasons than having a clique of size 4.\n\nFor example:\n\n\n\nIt's not 3-colorable. Proof: the 5-cycle around the outside is not 2-colorable, and then you need an extra color for the middle vertex.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Minimizing space usage by moving sets on a graph\r\n                \r\nI have a complete directional graph. On each edge there is a set of numbers. The set is saved on the source node by default. Note that each number is saved only ONCE. For example, if a node has two edges with sets {1,2,3} and {2,3,4} it takes only 4 spaces.\nNow, we can select an edge to move the set from the source to the destination with one space penalty. The question is which sets to move to the other side to get minimum space usage.\n\nFor example if I have the following graph\n\n```\n1->2: {123}\n1->3: {456}\n2->1: {}\n2->3: {456}\n3->1: {}\n3->2: {123}\n```\n\n\nThe original space usage is 12. But if I move all the sets to the destinations the used space is 3+3=6 which with 4 space penalty the result will be 10 which is better than the original setting.\n\nDoes anyone have any hint for this problem? Is this similar to an NP-complete problems?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Dividing objects into two piles of equal weight\r\n                \r\nI am sure you have already heard about this problem. Given a list of natural numbers, is it possible to divide them into two piles of equal sums? If yes, write two lines with objects in each pile.\n\nIs this some well-known problem? Does it have a name? Is it NP-Complete? If not, what is the fastest solution?\n    ", "Answer": "\r\nThis is the Partition problem, which is NP-Complete. It is a variant of Subset SUM.\n\nWhich is the fastest, really depends on the data you have. For instance, if they were bounded, you could use dynamic programming etc.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Finding minimum distance in graph for path passing minimum three nodes and finishing with start node?\r\n                \r\nI came across a problem to find optimal algorithm solving the issue: Finding minimum path in a graph from starting point to starting point(make a cycle) and visiting minimum three different nodes in the graph. For example if we have a graph ```\nG(V,E)```\n with ```\nV={a,b,c,d,e}```\n and edges ```\nE={(a,b,16),(a,c,300),(a,d,1),(b,c,100),(b,e,15),(c,a,10),(e,c,20)}```\n the shortest distance will be 61 and it will visit ```\na->c->e->b->a```\n.\n\nI think of using Dijkstra's algorithm for weighted graph, however I do not know how to implement the part for the constraint to visit minimum 3 nodes? It looks like the Hamiltonian cycle's problem but not using all the nodes but only part of them. Is this NP-complete problem?\n\nAny help would be appreciated.\n    ", "Answer": "\r\nOne easy way to implement this is the following:\n\n\nprecompute all-pair shortest paths (e.g. using Floyd–Warshall or running Dijkstra for each possible start node)\nfor each tuple (a, b, c) of distinct nodes in the graph, consider the concatenation of shortest paths from a to b, b to c and c to a.\nReport the minimum of all examined paths.\n\n\nThe runtime will be dominated by the second step, which has runtime O(n3). So no, the problem is not NP-hard, because the number of different nodes we have to visit is fixed (in this case, 3).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Checking if A is a part of binary tree B\r\n                \r\nLet's say I have binary trees A and B and I want to know if A is a \"part\" of B. I am not only talking about subtrees. What I want to know is if B has all the nodes and edges that A does.\n\nMy thoughts were that since tree is essentially a graph, and I could view this question as a subgraph isomorphism problem (i.e. checking to see if A is a subgraph of B). But according to wikipedia this is an NP-complete problem.\n\nhttp://en.wikipedia.org/wiki/Subgraph_isomorphism_problem\n\nI know that you can check if A is a subtree of B or not with O(n) algorithms (e.g. using preorder and inorder traversals to flatten the trees to strings and checking for substrings). I was trying to modify this a little to see if I can also test for just \"parts\" as well, but to no avail. This is where I'm stuck. \n\nAre there any other ways to view this problem other than using subgraph isomorphism? I'm thinking there must be faster methods since binary trees are much more restricted and simpler versions of graphs.\n\nThanks in advance! \n\nEDIT: I realized that the worst case for even a brute force method for my question would only take O(m * n), which is polynomial. So I guess this isn't a NP-complete problem after all. Then my next question is, is there an algorithm that is faster than O(m*n)?\n    ", "Answer": "\r\nI would approach this problem in two steps:\n\n\nFind the root of ```\nA```\n in ```\nB```\n (either BFS of DFS)\nVerify that ```\nA```\n is contained in ```\nB```\n (giving that starting node), using a recursive algorithm, as below (I concocted same crazy pseudo-language, because you didn't specify the language. I think this should be understandable, no matter your background). Note that ```\na```\n is a node from ```\nA```\n (initially the root) and ```\nb```\n is a node from ```\nB```\n (initially the node found in step 1)\n\n\n\n\n```\nfunction checkTrees(node a, node b) returns boolean\n    if a does not exist or b does not exist then\n        // base of the recursion\n        return false\n    else if a is different from b then\n        // compare the current nodes\n        return false\n    else\n        // check the children of a\n        boolean leftFound = true\n        boolean rightFound = true\n\n        if a.left exists then\n            // try to match the left child of a with\n            // every possible neighbor of b\n            leftFound = checkTrees(a.left, b.left)\n                       or checkTrees(a.left, b.right)\n                       or checkTrees(a.left, b.parent)\n\n        if a.right exists then\n            // try to match the right child of a with\n            // every possible neighbor of b\n            leftFound = checkTrees(a.right, b.left)\n                       or checkTrees(a.right, b.right)\n                       or checkTrees(a.right, b.parent)\n\n        return leftFound and rightFound\n```\n\n\nAbout the running time: let ```\nm```\n be the number of nodes in ```\nA```\n and ```\nn```\n be the number of nodes in ```\nB```\n. The search in the first step takes ```\nO(n)```\n time. The running time of the second step depends on one crucial assumption I made, but that might be wrong: I assumed that every node of ```\nA```\n is equal to at most one node of ```\nB```\n. If that is the case, the running time of the second step is ```\nO(m)```\n (because you can never search too far in the wrong direction). So the total running time would be ```\nO(m + n)```\n.\n\nWhile writing down my assumption, I start to wonder whether that's not oversimplifying your case...\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to construct a Hamilton path from a complete directed graph\r\n                \r\nGiven a directed graph.\n\nAny 2 vertices are adjacent. The edge connecting a pair of vertices may be uni-directional or bi-directional.\n\nHow do I find a Hamilton path?\n\nSide notes:\n\n\nWikipedia says \"A strongly connected simple directed graph with n vertices is Hamiltonian if every vertex has a full degree greater than or equal to n.\" Therefore, a solution must exist in my problem.\nI understand that the general Hamilton path problem is NP-Complete. But it feels like this specific version should have a polynomial solution.\n\n    ", "Answer": "\r\nUse a variant of insertion sort to construct a path in quadratic time. Given a path\n\n```\nv1 v2 ... vn-1\n```\n\n\non a subset of vertices, consider how to insert ```\nvn```\n. If ```\nvn```\n has an arc to ```\nv1```\n, then prepend ```\nvn```\n. If ```\nvn-1```\n has an arc to ```\nvn```\n, then append ```\nvn```\n. Otherwise, there exists by Sperner's lemma an index ```\ni```\n such that ```\nvn```\n has an arc from ```\nvi```\n and an arc to ```\nvi+1```\n. Insert it there.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Sub-graph Selection Algorithm Problem (Dynamic Programming or NP)\r\n                \r\nWe have an algorithm problem in hand, can you please write your ideas about this, thank you!\nThere are N many nodes with K different colors. Some of the nodes have direct connection between each other and some do not.\nWe want to select M nodes from these N total nodes, but these M nodes must be connected. Also, our selected group of M nodes must have minimum number of distinct colored neighbors. There might be more than one best combinations, finding any of them is the goal.\nFor example, we selected M nodes and in total, these M nodes have the following neighbors: 5 red, 3 blue, 1 green. In this case, we count the unique colors, so the number of distinct colored neighbors, in this case, is 3. We want to minimize this number by selecting the best possible combination of M nodes.\nExample graph visualization :\n\nIn this example, let's assume M = 4, then the best possible combination of nodes would be {9, 10, 11, 12} since this group has only one neighbor which is yellow.\nIf we choose {0, 1, 3, 5}, the neighbors of this combination would be {2, 4, 6}, which consists of 2 red neighbors and 1 green neighbor; which results with score of 2 since we look for distinct number of colored neighbors.\nIs this algorithm question NP-complete? How should we proceed? If this is not NP-complete, what is the best algorithm we can use to solve this problem?\nCan we combine graph algorithms such as Prim’s, Kruskal's, Floyd Warshall or traversal algorithms?\n    ", "Answer": "\r\nIf this is an NP problem, you could use ASP to solve it.\nGiven ```\ninstance.lp```\n\n```\ncolor(0,yellow).\ncolor(3,yellow).\ncolor(8,yellow).\ncolor(10,yellow).\ncolor(2,green).\ncolor(5,green).\ncolor(12,green).\ncolor(7,blue).\ncolor(1,red).\ncolor(4,red).\ncolor(6,red).\ncolor(9,red).\ncolor(11,red).\n\nedge(0,5).\nedge(0,1).\nedge(0,2).\nedge(0,6).\nedge(5,3).\nedge(5,4).\nedge(6,4).\nedge(3,4).\nedge(2,7).\nedge(7,8).\nedge(8,9).\nedge(5,3).\nedge(9,10).\nedge(9,11).\nedge(9,12).\nedge(11,12).\n\nedge(B,A) :- edge(A,B).\n```\n\nand ```\nencoding.lp```\n\n```\nnode(X) :- color(X,_).\n\n%select exactly one start node\n1 {start(X) : node(X)} 1.\n\n% start node is in sub graph\nsub(X) :- start(X).\n% for any node in the sub graph you can add any connected node\n{sub(Y) : edge(X,Y)} :- sub(X).\n\n% it is wrong if we do not have exactly m nodes in the sub graph\n:- not m = #sum {1,X: sub(X)}.\n\n#minimize {1,C : sub(X), edge(X,Y), not sub(Y), color(Y,C)}.\n\n#show sub/1.\n```\n\nThe call\n```\nclingo encoding.lp instance.lp --const m=4```\n gives you an optimal solution:\n```\nsub(3) sub(5) sub(4) sub(6)\n```\n\nThe call\n```\nclingo encoding.lp instance.lp --const m=4 --opt-mode=optN --project```\n\ngives you all optimal solutions.\nThe tools can be found at https://potassco.org/\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Can You Reduce K-Independent Set to 2-SAT\r\n                \r\nThis is a homework question to start out. I just have some questions before I begin.\n\nOur problem is:\n\n\"Reduce from k-Independent Set to 2−SAT as follows. Given a graph G with n vertices form n propositions, one per vertex. Each proposition xi for vertex i is set to true iff the vertex i belongs to an indepdenent set. Now for every edge (u,v) write a clause that says both u and v cannot belong to the independent set.\"\n\nMy question is that everything I read says 2-SAT is not an NP-Complete problem. How can we be reducing from the Independent Set problem then?\n    ", "Answer": "\r\nThere is an important difference between finding any independent set and finding a maximum independent set (independent set of maximum size).\n\nFinding any independent set nicely reduces to 2-SAT, using the reduction you described in your question. Neither problem is NP-complete. Note that the reduction you described in your question does not constrain the number of nodes in the independent set in any way. Even the empty set will satisfy the 2-SAT problem that is produced by this reduction, because the empty set also is an independent set!\n\nFinding a maximum independent set (or k-independent set) however is an NP-complete problem. It does not reduce to 2-SAT.\n\nOr in other words: The k in \"k-Independent Set\" is an additional constraint that is not part of this 2-SAT reduction (that's why the k is not even mentioned in the description of the reduction). You could add additional clauses to the SAT problem to count the number of included nodes and enforce that this number is at least k, but you can't do that by adding only 2-clauses. So adding the k is the step where your 2-SAT problem becomes an NP-complete general SAT problem.\n\nMAX-2-SAT is an NP-complete extension of 2-SAT that can also be used to solve the maximum independent set problem using the reduction you posted. (You'd need two trivial modifications to the reduction: (1) Add 1-clauses for each proposition and (2) duplicate the 2-clauses for weighting.)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Select k numbers from each category without duplicates and maximize the selection\r\n                \r\nThere are ```\nN```\n lists of numbers.  Select ```\nk```\n numbers from each list and return the largest set (no duplicates) that can be formed in this way.  If multiple sets of the same size are possible, returning any one of them is acceptable.  \n\nFor example, if N = 3, k = 2,\n\n```\nl1: [1, 2, 3]\nl2: [2, 7]\nl3: [3]\n```\n\n\nThen the optimal result is ```\n[1, 3, 2, 7]```\n. Pick ```\n[1, 3]```\n from ```\nl1```\n, pick ```\n[2, 7]```\n from ```\nl2```\n, pick ```\n[3]```\n from ```\nl3```\n. (Though there are other selections but the number of the elements in result set is less than this one, so this one is the best selection.)\n\nI think this is a NP-complete problem and the only approach is enumeration.\n\nPlease shed some light on. Thanks in advance!\n    ", "Answer": "\r\nThis problem may be solved with maximum bipartite matching. It is a classic algorithm and its description can be easily find on the internet, so I won't include it here.\n\nNote that this algorithm is polynomial-time, so the problem is not NP-hard.\n\nThe bipartite matching problem is: given a bipartite graph, select a set of edges such that each vertex is adjacent to at most one selected edge, and among possible sets find one with maximum cardinality.\n\nLet's build a bipartite graph. In the left part there will be a vertex for all distinct numbers which appear in the input. In the right part there will be ```\nk```\n vertices per each list. Now, the \"number\" vertex is connected with all \"list\" vertices such that the list contains the number.\n\nNow note that the cardinality of the maximum matching in this graph is exactly the answer for your problem: we've taken as many distinct numbers as possible without taking more than ```\nk```\n from any single list. Here we allow taking less than ```\nk```\n items from a list because it cannot increase the answer. You can take any extra (useless) items if necessary.\n\nIf you know something about maximum flows, you may consider adding only one vertex per each list, having ```\nk```\n-capacity edge to sink. This is essentially the same but yields faster asymptotic running time.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "2D Bin Packing with Multiple Size Bins\r\n                \r\nLets say we have multiple sizes of bins defined by Length x Width , those could be called \"raw material\" sizes. \n\nI need to cut certain amount of tables (rectangles, in guillotine form) out of that raw material so that the amount of raw material is minimized.\n\nAs the bins do not have the same size they should be somehow factored or prioritize to reflect their value - so a bigger bin is obviously \"more expensive\". \n\nI know this is a NP-Complete problem and I don't expect a deterministic algorithm in a polynomial time.\n\nI need an algorithm that solves the problem.\n\nAny suggestions would be helpful!\n\nThanks\n    ", "Answer": "\r\nWell, the basics are: You first need to define well a goodness function. Only after that your problem can be considered clearly stated. Let us call any layout of rectangles on your material plate an \"Arrangement\". The goodnes function should map from the domain of Arrangements to the domain of real numbers, the bigger the better, let's say. The function should be decreasing with the amount of material \"wasted\" in the given Arrangement, and increasing with the amount and value of the rectangles satisfied by the Arranegement. I repeat, you are the one who has to define that goodness function, that is, relative value of material and the value of the individual rectangles, which, as you say, fulfill the saying \"the bigger the better\". You have to quantify it.\n\nOnce you do this, a plethora of algorithms opens for you, the first being the random algorithm: You distribute a non-overlapping Arrangement or rectangles randomly on your sheet of material, evaluate its goodness and store it in the memory. After you do this sufficiently many times, you pick the best one. The improvement of this algorithm would be to try to pick already good arrangements and \"nudge around\" the rectangles a bit to gain space for one more small rectangle. That's what Dylan might mean by using simulated annealing. And btw. don't read that Wikipedia page on Simulated annealing, it will only mess up your head.\n\n\n\nResponse to the comment:\n\nNick, obviously, you have to use all kinds of bins from the very beginning. Let's say you have the starting sheet of material defined (either as a bitmap, or by vectors). You'll do the following:\n1. Randomly pick a point\n2. Randomly pick a rectangle type\n3. Randomly pick rotation\n4. If the rectangle doesn't fit, go back to point 1.\n5. If the rectangle fits, place it on the material sheet and\n   try placing a second rectangle by the same method.\n6. Then third, fourth etc., until you encounter too many failures and conclude that\n   you hit a dead end.\n7. Calculate the goodness of the Resulting arrangement\n8. Go on to the next arrangment\n\nNow it occurs to me, that maybe your cutting machine only allows one orientation (2 axis\nwith no tool rotation), so rotation of the rectangles does not have to be taken into account.\nIn that case, you will randomly pick the point not just anywhere, but on the side of the material\nsheet or on the side of another rectangle already on the sheet and you will place the\nnext rectangle to this point so that it has adjacent side with the side of the sheet\nor with another rectangle. In this case (no rotation) you can randomly pick a direction\nand shift the new rectangle in the chosen direction until it hits any perpendicular\nwall. That way, you'll save computing work and create better arrangements from the get\ngo. The last step is still computing the goodness function and picking the best.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why Eulerian path can be implemented in linear time, but not Hamiltonian path?\r\n                \r\nI learned that even though seemingly similar, Eulerian path can be solved in linear time while Hamiltonian path problem is NP-complete. I wonder what is the reason that underlies this difference? I don't know too much graph theory so probably won't understand well a rigorous proof, but some jargons should be fine.\n    ", "Answer": "\r\nBasically, the Euler problem can be solved with dynamic programming, and the Hamilton problem can't. \n\nThis means that if you have a subset of your graph and find a valid circular path through it, you can combined this partial solution with other partial solutions and find a globally valid path. That isn't so for the optimal path: even after you have found the optimal path through a small part of a graph, this may very well not be a part of the globally optimal path (and in fact, it usually isn't). Informally, the optimal path through a large graph depends on the exact values in all other parts of the graph, and therefore no one has ever found a way to use \"divide and conquer\" correctly on the problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Verification algorithm for minimum vertex cover?\r\n                \r\nWe know that the minimum vertex cover is NP complete, which means that it is in the set of problems that can be verified in polynomial time. \n\nAs I understand it, the verification process would require the following:\n\n\nVerify that the solution is a vertex cover at all\nVerify that the solution is the smallest possible subset of the source graph that satisfies condition #1\n\n\nI'm finding it hard to establish that step #2 can be done in polynomial time.  Can anyone explain how it is?\n    ", "Answer": "\r\nThe minimum vertex cover is NP-hard. It is only NP-complete if it is restated as a decision problem which can be verified in polynomial time.\n\n\n  The minimum vertex cover problem is the optimization problem of finding a smallest vertex cover in a given graph.\n  \n  \n  INSTANCE: Graph G\n  OUTPUT: Smallest number k such that G has a vertex cover of size k.\n  \n  \n  If the problem is stated as a decision problem, it is called the vertex cover problem:\n  \n  \n  INSTANCE: Graph G and positive integer k.\n  QUESTION: Does G have a vertex cover of size at most k?\n  \n\n\nRestating a problem as a decision problem is a common way to make problems NP-complete. Basically you turn an open-ended problem of the form \"find the smallest solution k\" into a yes/no question, \"for a given k, does a solution exist?\"\n\nFor example, for the travelling salesman problem, verifying that a proposed solution the shortest path between all cities is NP-hard. But if the problem is restated as only having to find a solution shorter than k total distance for some k, then verifying a solution is easy. You just find the length of the proposed solution and check that it's less than k.\n\nThe decision problem formulation can be easily used to solve the general formulation. To find the shortest path all you have to do is ratchet down the value of k until there are no solutions found.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Explore every node in a graph\r\n                \r\nI am given a connected graph with N nodes (numbered from 1..N) and M bidirectional edges consisting in a couple (A,B). Edges are unweighted.\n\nI have K people starting at node 1 and I want to explore every node of the graph. I takes one unit of time to a person to travel from one node to one of its neighbor. \n\nHow long will it take to explore every node? I am searching for an efficient algorithm to compute the minimum traversal time, but I am afraid it is an NP-complete problem. (The constraints on the number of edges and number of people are small though).\n    ", "Answer": "\r\nSuppose K were 1. Then the minimisation problem reduces to finding a minimum length path that touches every node at least once.\n\nIf we construct a new weighted graph G' with the same nodes and with edges between every two nodes whose weight is the minimum distance between those nodes in the original graph, then the minimum length path through all the nodes in G is the minimum length Hamiltonian path through G', the travelling salesperson problem, which is well-known to be NP-complete.\n\nSo for at least one value of K, the problem is NP-complete. However, for large values of K (say, ≥ N), we can produce a minimum solution in much less time, since we can just construt the minimum spanning tree and find the distance of the furthest element. I doubt whether there is any such simplified solution for small values of K, but I'd definitely use the MST as a heuristic for finding a reasonable solution.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Time complexity analysis of minimum set cover solution\r\n                \r\nFor the question \n\n\n  There are n persons and k different type of dishes. Each person has\n  some preference for each dish. Either he likes it or not. We need to\n  feed all people. Every person should get atleast one dish of his\n  chioce. What is the minimum number of different type of dishes we can\n  order?\n\n\nOne of the solution is,\n\n```\n  public class OptimumDish {\n\n  private Set<Integer> result = new HashSet<Integer>();\n\n  public void print(){\n    for(int r:result)\n      System.out.print(r + \" \");\n  }\n\n  // Find the optimum dish by navigating all available options\n  public void find(int[][] m, int r, int c, int mr, int mc, Stack<Integer> dishes) {\n\n    dishes.push(c);\n\n    if (r == mr) {\n      // Reached last person. Get the unique dishes\n      Set<Integer> d = new HashSet<>(dishes);\n      if(result.size() == 0 || result.size() > d.size())\n        result = d;\n    }\n    else if (r < mr) {\n      // Check next person's preferred dish\n      for (int i = 0; i <= mc; i++) {\n        if (m[r + 1][i] == 1) {\n          find(m, r+1, i, mr, mc, dishes);\n          break;\n        }\n      }\n    }\n\n    dishes.pop();\n\n    // Current dish may not be the optimum.\n    // Check other dish for the same person\n    for (int i = c + 1; i <= mc; i++) {\n      if (m[r][i] == 1) {\n        find(m, r, i, mr, mc, dishes);\n      }\n    }\n  }\n\n  public static void main(String[] args) {\n\n    int[][] m = { \n        { 0, 1, 1, 0, 0, 0, 0 },\n        { 0, 1, 0, 1, 0, 0, 0 },\n        { 0, 1, 1, 0, 0, 1, 0 },\n        { 1, 0, 0, 1, 0, 0, 0 },\n        { 0, 0, 1, 0, 1, 0, 0 },\n        { 0, 0, 0, 1, 0, 0, 1 }\n        };\n\n    int mr = m.length - 1;\n    int mc = m[0].length - 1;\n    int c = 0;\n\n    for (int i = 0; i <= mr; i++) {\n      if (m[0][i] == 1) {\n        c = i;\n        break;\n      }\n    }\n\n    OptimumDish od = new OptimumDish();\n    Stack<Integer> dishes = new Stack<>();\n    od.find(m, 0, c, mr, mc, dishes);\n    od.print();\n  }\n}\n```\n\n\nThis problem is of type 'Minimum Set Cover'. Since it is a NP-Complete problem, it can't be solved in polynomial time. As per the solution it can be solved in polynomial time?\n\nPlease let me know what is the time complexity of this solution? O(n^4)?. Thanks.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Easy way to determine whether a given graph is subgraph of some other graph?\r\n                \r\nI'm looking for an algorithm to check whether a given graph is subgraph of another given graph.\n\nI have few conditions to make this NP complete problem bit more feasible..\n\n\nThe graphs have approx <20 vertices.\nThe graphs are DAG.\nAll vertices are non-uniquely labeled, and the corresponding vertices in the main graph and the subgraph should have same label. I don't know if I'm using the correct terminologies (because I haven't taken a graph theory course...). It will be something like:\n\n\nThe line graph A--B is subgraph of A--B--A but A--A is not a subgraph of A--B--A.\n\nAny suggestions are fine. This is not a homework question btw. :D\n    ", "Answer": "\r\nIf the labels are unique, for a graph of size ```\nN```\n, there are ```\nO(N^2)```\n edges, assuming there are no self loops or multiple edges between each pair of vertices.  Let's use ```\nE```\n for the number of edges.\n\nIf you hash the set edges in the parent graph, you can go through the subgraph's edges, checking if each one is in the hash table (and in the correct amount, if desired).  You're doing this once for each edge, therefore, ```\nO(E)```\n.\n\nLet's call the graph ```\nG```\n (with ```\nN```\n vertices) and the possible subgraph ```\nG_1```\n (with ```\nM```\n vertices), and you want to find ```\nG_1 is in G```\n.\n\nSince the labels are not unique, you can, with Dynamic Programming, build the subproblems as such instead - instead of having ```\nO(2^N)```\n subproblems, one for each subgraph, you have ```\nO(M 2^N)```\n subproblems - one for each vertex in ```\nG_1```\n (with ```\nM```\n vertices) with each of the possible subgraphs.\n\n```\nG_1 is in G = isSubgraph( 0, empty bitmask)```\n\n\nand the states are set up as such:\n\n```\nisSubgraph( index, bitmask ) =\n   for all vertex in G\n       if G[vertex] is not used (check bitmask)\n          and G[vertex]'s label is equal to G_1[index]'s label\n          and isSubgraph( index + 1, (add vertex to bitmask) )\n               return true\n   return false\n```\n\n\nwith the base case being ```\nindex = M```\n, and you can check for the edges equality, given the bitmask (and an implicit label-mapping).  Alternatively, you can also do the checking within the if statement - just check that given current ```\nindex```\n, the current subgraph ```\nG_1[0..index]```\n is equal to ```\nG[bitmask]```\n (with the same implicit label mapping) before recursing.\n\nFor ```\nN = 20```\n, this should be fast enough.\n\n(add your memo, or you can rewrite this using bottoms up DP).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to find the size of maximal clique or clique number?\r\n                \r\nGiven an undirected graph G = G(V, E), how can I find the size of the largest clique in it in polynomial time? Knowing the number of edges, I could put an upper limit on the maximal clique size with\n\nhttps://cs.stackexchange.com/questions/11360/size-of-maximum-clique-given-a-fixed-amount-of-edges\n\n, and then I could iterate downwards from that upper limit to 1. Since this upper cap is O(sqrt(|E|)), I think I can check for the maximal clique size in O(sqrt(|E|) * sqrt(|E|) * sqrt(|E|)) time. \n\nIs there a more efficient way to solve this NP-complete problem?\n    ", "Answer": "\r\nFinding the largest clique in a graph is the clique number of the graph and is also known as the maximum clique problem (MCP). This is one of the most deeply studied problems in the graph domain and is known to be NP-Hard so no polynomial time algorithm is expected to be found to solve it in the general case (there are particular graph configurations which do have polynomial time algorithms). Maximum clique is even hard to approximate (i.e. find a number close to the clique number).\n\nIf you are interested in exact MCP algorithms there have been a number of important improvements in the past decade, which have increased performance in around two orders of magnitude. The current leading family of algorithms are branch and bound and use approximate coloring to compute bounds. I name the most important ones and the improvement:\n\n\nBranching on color (MCQ)\nStatic initial ordering in every subproblem (MCS and BBMC)\nRecoloring: MCS\nUse of bit strings to encode the graph and the main operations (BBMC)\nReduction to maximum satisfiability to improve bounds (MaxSAT)\nSelective coloring (BBMCL)\n\n\nand others.\nIt is actually a very active line of research in the scientific community.\nThe top algorithms are currently BBMC, MCS and I would say MaxSAT. Of these probably BBMC and its variants (which use a bit string encoding) are the current leading general purpose solvers. The library of bitstrings used for BBMC is publicly available. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to remove duplicates elements in nested list in c++\r\n                \r\nI'm trying to solve one np-complete problem in C++. I can solve this problem in Python but running time is relatively slow, so that's why I switch to C++. In one part of the problem I need to clean duplicate elements from my list.\nI have a list the type is list<list<int> > in c++. My list contains duplicate elements for example:\nIf I send list below as an input:\n```\n[ [1,2,3] , [2,3,4] , [2,3,4] , [4,5,6] ]\n```\n\nI should get ```\n[ [1,2,3] , [2,3,4] , [4,5,6] ]```\n as a result from the method.\nSo, how can I make my nested list contains only unique elements? Are there any efficient way or built-int function in c++ instead of using nested loop?\n    ", "Answer": "\r\n```\nstd::unique```\n works just fine: (where ```\ninput```\n is your nested list)\n```\nauto it = std::unique(begin(input), end(input));\ninput.erase(it, end(input));\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this NP-Complete? If so, knapsack, MIS, set-filling or scheduling?\r\n                \r\nI've got a \"gut-feeling\" that the problem I'm facing in my application is NP-complete, but I'm after help classifying it.\n\nThe problem\n\n\nWe have a bag with n heterogeneous slots \nWe can either put an item (with an associated value) in each slot, or leave it empty. A slot may contain at most one item.\nSince the slots are heterogeneous, an item for slot #2 cannot go in slot #3 \nWe have a finite set of slot-filling actions\nEach action may be invoked at most once\nInvoking a given action will fill some (1-n) of the slots with a fixed value (specific to the action), but only if all requested slots are available (otherwise the action cannot be invoked) i.e. all requested slots or none.\n\n\nHow do we determine the set of actions to invoke to maximise the total value in the bag?\n\nAn example:\n\n\nWe have 5 slots, numbered #1-#5\nWe have three actions, A1, A2 and A3\nA1 wants to put value $30 in slots #1 through #5\nA2 wants to put $50 in slots #1 & #2\nA3 wants to put $50 in slots #4 & #5\n\n\nThe optimal solution for this example is to invoke actions A2 & A3 (for a total value of $200, leaving slot #3 empty) - rather than invoking A1 (which would fill all slots, but only give a total of $150).\n\nFollow-up question - how should I brute-force this?\n\nSome thoughts:\n\n\nWe will want to prune off any action A[y] which covers the exact same slots as another action A[x] if the slot value ($) associated with A[y] is less than or equal to that of A[x].\nOther than that, I think evaluating the solution space boils down to iterating through the powerset of all remaining actions\nOf the sets {S1, S2...} in the powerset of all actions, if S2 is a subset of S1 AND all the actions applied successfully for S1 then we can disregard S2 (and all it's subsets!) without evaluating them, since they can never give a better result. In other words, if we can find a set that applies successfully early on, we can disregard all the subsets of it (significantly reducing what we have to test)\n\n\nInterested to hear of any other optimisations you can think of.\n    ", "Answer": "\r\nNP-completeness is about decision problems, and yours is an optimization problem. If we change it to feasibility (\"does a solution ≥ m exist?\") then we can trivially reduce set packing to your problem, and your problem to 0-1 integer linear programming, both of which are known to be NP-complete. Congratulations, you're NP-complete!\n\nI'm not sure which NPO-complete class your problem falls into, though.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What is an NP-complete in computer science? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is not about programming or software development. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about a specific programming problem, a software algorithm, or software tools primarily used by programmers. If you believe the question would be on-topic on another Stack Exchange site, you can leave a comment to explain where the question may be able to be answered.\r\n                \r\n                    \r\n                        Closed 7 months ago.\r\n                    \r\n                \r\n            The community reviewed whether to reopen this question 2 months ago and left it closed:\r\n            \r\n                    Original close reason(s) were not resolved\r\n            \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nWhat is an NP-complete problem? Why is it such an important topic in computer science?\n    ", "Answer": "\r\nWhat is NP?\nNP is the set of all decision problems (questions with a yes-or-no answer) for which the 'yes'-answers can be verified in polynomial time (O(nk) where n is the problem size, and k is a constant) by a deterministic Turing machine. Polynomial time is sometimes used as the definition of fast or quickly.\nWhat is P?\nP is the set of all decision problems which can be solved in polynomial time by a deterministic Turing machine. Since they can be solved in polynomial time, they can also be verified in polynomial time. Therefore P is a subset of NP.\nWhat is NP-Complete?\nA problem x that is in NP is also in NP-Complete if and only if every other problem in NP can be quickly (ie. in polynomial time) transformed into x.\nIn other words:\n\nx is in NP, and\nEvery problem in NP is reducible to x\n\nSo, what makes NP-Complete so interesting is that if any one of the NP-Complete problems was to be solved quickly, then all NP problems can be solved quickly.\nSee also the post What's \"P=NP?\", and why is it such a famous question?\nWhat is NP-Hard?\nNP-Hard are problems that are at least as hard as the hardest problems in NP. Note that NP-Complete problems are also NP-hard. However not all NP-hard problems are NP (or even a decision problem), despite having ```\nNP```\n as a prefix. That is the NP in NP-hard does not mean non-deterministic polynomial time. Yes, this is confusing, but its usage is entrenched and unlikely to change.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "how were the first NP-complete problems shown to be NP-complete?\r\n                \r\nFrom the wikipedia entry on NP-Complete:\n\n\"The easiest way to prove that some new problem is NP-complete is first to prove that it is in NP, and then to reduce some known NP-complete problem to it\"\n\nI'm pretty sure that I understand this:  If I have a problem, I can show that it is NP-Complete if I: \n\n\nshow that it is in NP (a solution to\nthe problem can be verified in\npolynomial time on a\nnon-deterministic Turing machine)\nShow that a problem already known to be NP-Complete can be\n'reduced' to the new problem\n\n\nSo, my question is, how were the first NP-complete problems 'proven' to be NP-complete?  At one time, the set of known NP-complete problems must have been zero, and this would have made it impossible to resort to step 2 in the above process.  \n\nThis makes me think that there is a different method for proof which I'm not aware of.  Either that, or maybe the whole NP-complete property is 'assumed' for certain problems due to lack of a known polynomial time solution. (actually, having written this, I wouldn't be surprised if this is the case, but I'd like some guru-feedback either way). \n    ", "Answer": "\r\nCook's Theorem\n\nThe class NP can be defined as the class of problems decidable by a nondeterministic Turing machine in polynomial time. This theorem shows that SAT is NP-complete by encoding the operation of any nondeterministic Turing machine by a boolean formula, in such a way that the machine accepts if and only if that formula is SATisfiable.\n\nHistorically speaking, the notion of NP-completeness was introduced in Richard Karp's seminal paper (Reducibility Among Combinatorial Problems), where he defined NP-completeness, used Cook's theorem, and in one big shot, proved 21 problems NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to prove that a problem is NP complete?\r\n                \r\nI have problem with scheduling. I need to prove that the problem is NP complete. What can be the methods to prove it NP complete?\n    ", "Answer": "\r\nTo show a problem is NP complete, you need to:\nShow it is in NP\nIn other words, given some information ```\nC```\n, you can create a polynomial time algorithm ```\nV```\n that will verify for every possible input ```\nX```\n whether ```\nX```\n is in your domain or not.\nExample\nProve that the problem of vertex covers (that is, for some graph ```\nG```\n, does it have a vertex cover set of size ```\nk```\n such that every edge in ```\nG```\n has at least one vertex in the cover set?) is in NP:\n\nour input ```\nX```\n is some graph ```\nG```\n and some number ```\nk```\n (this is from the problem definition)\n\nTake our information ```\nC```\n to be \"any possible subset of vertices in graph ```\nG```\n of size ```\nk```\n\"\n\nThen we can write an algorithm ```\nV```\n that, given ```\nG```\n, ```\nk```\n and ```\nC```\n, will return whether that set of vertices is a vertex cover for ```\nG```\n or not, in polynomial time.\n\n\nThen for every graph ```\nG```\n, if there exists some \"possible subset of vertices in ```\nG```\n of size ```\nk```\n\" which is a vertex cover, then ```\nG```\n is in ```\nNP```\n.\nNote that we do not need to find ```\nC```\n in polynomial time. If we could, the problem would be in `P.\nNote that algorithm ```\nV```\n should work for every ```\nG```\n, for some ```\nC```\n. For every input there should exist information that could help us verify whether the input is in the problem domain or not. That is, there should not be an input where the information doesn't exist.\nProve it is NP Hard\nThis involves getting a known NP-complete problem like SAT, the set of boolean expressions in the form:\n\n(A or B or C) and (D or E or F) and ...\n\nwhere the expression is satisfiable, that is there exists some setting for these booleans, which makes the expression true.\nThen reduce the NP-complete problem to your problem in polynomial time.\nThat is, given some input ```\nX```\n for ```\nSAT```\n (or whatever NP-complete problem you are using), create some input ```\nY```\n for your problem, such that ```\nX```\n is in SAT if and only if ```\nY```\n is in your problem. The function ```\nf : X -> Y```\n must run in polynomial time.\nIn the example above, the input ```\nY```\n would be the graph ```\nG```\n and the size of the vertex cover ```\nk```\n.\nFor a full proof, you'd have to prove both:\n\nthat ```\nX```\n is in ```\nSAT```\n => ```\nY```\n in your problem\n\nand ```\nY```\n in your problem => ```\nX```\n in ```\nSAT```\n.\n\n\nmarcog's answer has a link with several other NP-complete problems you could reduce to your problem.\nFootnote: In step 2 (Prove it is NP-hard), reducing another NP-hard (not necessarily NP-complete) problem to the current problem will do, since NP-complete problems are a subset of NP-hard problems (that are also in NP).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-hard problems that are not NP-complete are harder?\r\n                \r\nFrom my understanding, all NP-complete problems are NP-hard but some NP-hard problems are known not to be NP-complete, and NP-hard problems are at least as hard as NP-complete problems.\n\nIs that mean NP-hard problems that are not NP-complete are harder? And how it is harder?\n    ", "Answer": "\r\nTo answer this question, you first need to understand which NP-hard problems are also NP-complete. If an NP-hard problem belongs to set NP, then it is NP-complete. To belong to set NP, a problem needs to be\n\n(i) a decision problem, \n(ii) the number of solutions to the problem should be finite and each solution should be of polynomial length, and \n(iii) given a polynomial length solution, we should be able to say whether the answer to the problem is yes/no\n\nNow, it is easy to see that there could be many NP-hard problems that do not belong to set NP and are harder to solve. As an intuitive example, the optimization-version of traveling salesman where we need to find an actual schedule is harder than the decision-version of traveling salesman where we just need to determine whether a schedule with length <= k exists or not.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If np-complete problems are the hardest problems in np, why are there multiple np-complete problems?\r\n                \r\nIf np-complete problems are the hardest problems in np, why are there multiple np-complete problems?\nHow can there be multiple hardest problems?\nIs it like the top 10 hardest problems hard np-complete?\nAre np-complete problems the hardest types of problems?\n    ", "Answer": "\r\n\nIf np-complete problems are the hardest problems in np.\n\nThe definition of an np-complete problem is: If a problem is NP and all other NP problems are polynomial-time reducible to it, the problem is NP-complete.\n\nWhy are there multiple np-complete problems?\n\nThere are multiple np-complete problems because people have found multiple problems comply with the definition of NP-complete problems.\n\nHow can there be multiple hardest problems?\n\nThere are more problems that are polynomial-time reducible to each other and are NP.\n\nIs it like the top 10 hardest problems hard np-complete?\n\nThe criterium isn't the top 10 hardest, but they should be NP, and all other NP problems have to be polynomial-time reducible to them.\n\nAre np-complete problems the hardest types of problems?\n\nI think that minimally unsolvable problems are harder.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-complete problems\r\n                \r\nI have come into NP-complete problems and I can't tell when the problem is NP-complete.\nIs there a shortcut to know whether a given problem is NP-complete or not so that I don't waste time thinking about a fast algorithm?\n    ", "Answer": "\r\nThe only easy way to show that a problem is NP-Hard is to convert an already known NP-complete problem into this problem in polynomial time. Meaning the conversion should be calculated in polynomial time with respect to the size of the input. In this case, you know that the problem you have is NP-Hard, which means it is at least as hard as NP-Complete but may be more difficult.\nAt this point, you could stop trying to find a solution for it.\nBut if you also need to show that it is NP-complete, then you need to show that a solution could be check in polynomial time.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What are NP and NP-complete problems? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and  cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened,  visit the help center.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 11 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI am struggling to understand what are nondeterministic polynomial-time problems and NP-complete problems. I understand what polynomial-time solvable problems are, and saw in Wikipedia about NP problems.  After reading about this I tried to think about some example problems.  As I understand it, depth-first search in an undirected is NP-complete, since each decisions can be made nondeterministically (i.e if I made the wrong decision, I could instead try some other choice) if the graph is large (cit an be polynomial if graph size is small.)\n\nCan anyone briefly explain all these NP terms with simple examples without using much maths?\n    ", "Answer": "\r\nThere are many ways of thinking about NP and NP-completeness.  I'll start with a definition of NP, then will talk about NP-hardness, and finally NP-completeness.\n\nAt a high level, P and NP are classes of problems. A problem is in P if is a yes-or-no question (a decision problem) and there is some algorithm that solves the problem in polynomial time. For example, the question of \"can you get from node u to node v in this graph?\" belongs to P because you can solve it with depth-first search. (Note that DFS itself is not in P, since DFS is an algorithm rather than a problem). Another example of a problem in P would be checking whether a sequence is in sorted order.\n\nA problem is in NP if it is a yes-or-no question (a decision problem) where a correct answer can be verified in polynomial time.  For example, a classic NP problem is seeing whether, given a set of weights of known weight, you can pick a set of weights that weighs exactly some amount k (this is called the subset sum problem).  It might be tricky to figure out whether a set of weights with that property exists, but if I were to give you a set of weights that I said I knew was correct, you could very easily check whether or not I had given you the correct set of weights by just adding them up and seeing if they totaled k.\n\nThe reason that NP is called \"nondeterministic polynomial\" is that a different way of thinking about NP is to think about a magic algorithm that can somehow guess the correct answer to a problem in polynomial time.  That is, if you can write an algorithm that is allowed to make guesses about the answer to a problem and runs in polynomial time, then the problem you are solving is in NP.  To go back to our weights example, we could write such a guessing algorithm for the problem as follows.  Start off by, in linear time, guessing which set of weights is the correct set of weights, then add them all up and see if they total k.  If so, report that the answer is \"yes.\" Otherwise, say \"no.\" If this program is always guaranteed to make correct guesses, then given any input to the problem that has a solution it will always find one and report \"yes,\" and if there is no solution it will always guess wrong and report \"no.\"\n\nOne of the most fundamental and important questions in computer science right now is whether any problem that is known to be in NP is also in P.  That is, if we can easily verify the answer to a problem efficiently (in polynomial time), can we always solve that problem efficiently (in polynomial time)?  It is known that any problem in P is also a problem in NP, since you can use the polynomial time algorithm to produce an answer and then check whether it's correct, but no one has ever found a way to solve arbitrary problems in NP in polynomial time.\n\nThe reason for this is that some problems in NP are known as NP-complete, meaning that (informally) they are at least as hard as every other problem in NP.  If we could solve these problems efficiently (polynomial time), then we could solve every problem in NP in polynomial time.  This would be a huge deal, since there are a lot of problems in NP that are extremely important that we currently have no good, fast algorithms for.  This is also the allure of the P = NP question, since all it would take would be one algorithm to show that an enormous class of problems presumed to be impractically hard to solve would actually be solvable efficiently.\n\nMore formally, a problem in NP is called NP-complete if, in polynomial time, you can transform any instance of any other NP problem into an instance of that problem.  The above problem with weights is such a problem, as is the problem of determining whether a boolean formula has a satisfying assignment, solving certain optimization problems over the integers (integer programming), determining the fastest route to visit a set of locations (traveling salesman), or determining how to assign cell towers in a city using the smallest number of frequencies (graph coloring).  Even determining whether it's possible to solve a game like Sudoku and minesweeper are known to be NP-complete for arbitrary board sizes.\n\n(Some problems have this latter property - that any problem in NP can be converted efficiently into that problem - but aren't themselves in NP. Those problems are called NP-hard.)\n\nFrom a practical perspective, if you are ever asked to solve a problem that is known to be NP-complete or NP-hard, don't expect to find an exact solution in any reasonable time.  In some cases, it's not even possible to approximate solutions to within any precision efficiently.  You are best off looking for an alternative problem to try to solve or to resign yourself to a heuristic solution that does well in most but not all cases.\n\nAs to your original thoughts about DFS being NP-complete, only problems can be in NP or be NP-complete; algorithms cannot. DFS is an algorithm for solving the graph reachability problem - given two nodes in a graph, is there a path from the first to the second? That problem is in NP because if there is a path it's easy to check, but it's (probably) not NP-complete because we know we can solve it in polynomial time using DFS.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are all NP problems also NP-complete?\r\n                \r\nThe definition of NP-complete is\n\nA problem is NP-complete if\n\n\nit belongs to class NP  \nall the other problems in NP polynomially transform to it\n\n\nSo, if all other problems in NP transform to an NP-complete problem, then does that not also mean that all NP problems are also NP-complete?  What is the point of classifying the two if they are the same?\n\nIn other words, if we have an NP problem then through (2) this problem can transform into an NP-complete problem. Therefore, the NP problem is now NP-complete, and NP = NP-complete. Both classes are equivalent.\n\nJust trying to clarify this up for myself.\n    ", "Answer": "\r\n\n  Are all NP problems also NP-complete?\n\n\nOnly if P = NP.\n\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What's \"P=NP?\", and why is it such a famous question? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is off-topic. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.\r\n                \r\n                    \r\n                        Closed 10 years ago.\r\n                    \r\n                \r\n            The community reviewed whether to reopen this question last year and left it closed:\r\n            \r\n                    Original close reason(s) were not resolved\r\n            \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nThe question of whether P=NP is perhaps the most famous in all of Computer Science. What does it mean? And why is it so interesting?\n\nOh, and for extra credit, please post a proof of the statement's truth or falsehood. :)\n    ", "Answer": "\r\nP stands for polynomial time.  NP stands for non-deterministic polynomial time.  \n\nDefinitions:\n\n\nPolynomial time means that the complexity of the algorithm is O(n^k), where n is the size of your data (e. g. number of elements in a list to be sorted), and k is a constant.\nComplexity is time measured in the number of operations it would take, as a function of the number of data items.\nOperation is whatever makes sense as a basic operation for a particular task.  For sorting, the basic operation is a comparison.  For matrix multiplication, the basic operation is multiplication of two numbers.\n\n\nNow the question is, what does deterministic vs. non-deterministic mean?  There is an abstract computational model, an imaginary computer called a Turing machine (TM).  This machine has a finite number of states, and an infinite tape, which has discrete cells into which a finite set of symbols can be written and read.  At any given time, the TM is in one of its states, and it is looking at a particular cell on the tape.  Depending on what it reads from that cell, it can write a new symbol into that cell, move the tape one cell forward or backward, and go into a different state.  This is called a state transition.  Amazingly enough, by carefully constructing states and transitions, you can design a TM, which is equivalent to any computer program that can be written.  This is why it is used as a theoretical model for proving things about what computers can and cannot do.\n\nThere are two kinds of TM's that concern us here: deterministic and non-deterministic.  A deterministic TM only has one transition from each state for each symbol that it is reading off the tape.  A non-deterministic TM may have several such transition, i. e. it is able to check several possibilities simultaneously.  This is sort of like spawning multiple threads.  The difference is that a non-deterministic TM can spawn as many such \"threads\" as it wants, while on a real computer only a specific number of threads can be executed at a time (equal to the number of CPUs).  In reality, computers are basically deterministic TMs with finite tapes.  On the other hand, a non-deterministic TM cannot be physically realized, except maybe with a quantum computer.  \n\nIt has been proven that any problem that can be solved by a non-deterministic TM can be solved by a deterministic TM.  However, it is not clear how much time it will take. The statement P=NP means that if a problem takes polynomial time on a non-deterministic TM, then one can build a deterministic TM which would solve the same problem also in polynomial time.  So far nobody has been able to show that it can be done, but nobody has been able to prove that it cannot be done, either.\n\nNP-complete problem means an NP problem X, such that any NP problem Y can be reduced to X by a polynomial reduction.  That implies that if anyone ever comes up with a polynomial-time solution to an NP-complete problem, that will also give a polynomial-time solution to any NP problem. Thus that would prove that P=NP. Conversely, if anyone were to prove that P!=NP, then we would be certain that there is no way to solve an NP problem in polynomial time on a conventional computer. \n\nAn example of an NP-complete problem is the problem of finding a truth assignment that would make a boolean expression containing n variables true.\nFor the moment in practice any problem that takes polynomial time on the non-deterministic TM can only be done in exponential time on a deterministic TM or on a conventional computer.\nFor example, the only way to solve the truth assignment problem is to try 2^n possibilities.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why do we say that NP complete problems are NP?\r\n                \r\nI have gone through all the links regarding this topic but still confused that why do we consider NP Complete to be NP. Is it only that we can verify it in polynomial time that we say that NP complete problems are NP, but we have some NP problems which can be solved in polynomial time as well but NP complete problems can't be solved in polynomial time so then doesn't this contradict the property of calling NP complete problems to be NP?\n    ", "Answer": "\r\nThere's the set P of decision problems that can be solved by a deterministic Turing machine in polynomial time.\n\nThen there's the set NP of decision problems that can be solved by a non-deterministic Turing machine in polynomial time, i.e. those whose solution can be verified in polynomial time given some witness string.\n\nA deterministic Turing machine can simulate a non-deterministic one, so we know that there is an exponential-time algorithm to solve NP problems. We don't know however whether we don't in fact have P = NP.\n\nAn NP-complete problem is an NP problem that is at least as hard as any other NP problem. For example, SAT is NP-complete because it can effectively encode a non-deterministic Turing machine and solving SAT means simulating that machine. You can show NP-completeness of a problem decision problem A by demonstrating that a previously known to be NP-complete problem B can be reduced to A in polynomial time. This means that if A can be solved in polynomial time, B can be solved in polynomial time too, thus in a sense A is at least as hard as B.\n\n\n  but we have some NP problems which can be solved in polynomial time as well\n\n\nExactly, because P is a subset of NP.\n\n\n  NP complete problems can't be solved in polynomial time\n\n\nWe don't know that for sure.\n\n\n  doesn't this contradict the property of calling NP complete problems to be NP\n\n\nNot at all. Yes there are problems in NP that we know to be also in P. That doesn't mean that there are no problems in NP that are not in P. But of course we don't know the latter. It could even be the case that every NP-complete problem is in P, in the case P = NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Relating NP-Complete problems to real world problems\r\n                \r\nI have a decent grasp of NP Complete problems; that's not the issue.  What I don't have is a good sense of where they turn up in \"real\" programming.  Some (like knapsack and traveling salesman) are obvious, but others don't seem obviously connected to \"real\" problems.\n\nI've had the experience several times of struggling with a difficult problem only to realize it is a well known NP Complete problem that has been researched extensively.  If I had recognized the connection more quickly I could have saved quite a bit of time researching existing solutions to my specific problem.\n\nAre there any resources (online or print) that specifically connect NP Complete to real world instances?\n\nEdit:\nFor example, I was working on a program that tried to divide students into groups based on age, grade, and school of origin, which is essentially a graph partitioning problem. It took me a while to realize the connection.\n    ", "Answer": "\r\nI have found that Computers and Intractability is the definitive reference on this topic.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What makes an NP-hard problem not to be an NP-complete problem?\r\n                \r\nI am having confusion about NP-hard problems.\nSome NP-hard problems are in NP which are called NP-Complete and some are not in NP.\nFor ex : Halting problem is only NP-hard, not NP-complete.\nBut why it is not NP-complete ? I mean what property should a problem have to qualify as\n\"NP-hard but not NP-complete problem\" ?\n    ", "Answer": "\r\nI think the shortest answer is: NP-complete = NP-hard AND in NP.\n\nThus, to show that a problem is NP-complete you must show that it is both NP-hard and in NP.  Typically, showing that a problem is in NP is pretty easy (just give a non-deterministic polynomial time algorithm).  Showing that a problem is NP-hard is, well, hard.  Thus, even in a proof of NP-completeness, most of the proof is dedicated to the NP-hardness.\n\nAs for the halting problem, it fails to be in NP, and thus is not NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Example problems not in P nor in NP-complete but in NP\r\n                \r\nI have a course called Algorithm Analysis at college, where we're currently studying the different complexity classes -- P, NP, NP-hard etc.\n\nWe've already discussed NP-complete problems as the intersection between NP and NP-hard, and P problems, contained in NP. We've also talked about some examples, mainly of NP-complete problems (k-coloring, k-clique, SAT).\n\nMost of the time, we prove a problem is NP-complete by:\n\na. Finding a nondeterministic algorithm to solve it (that uses choice, success, fail);\n\nb. Reducing a known NP-complete problem to it.\n\nThe thing is that these problems, when run on a deterministic machine (sequentially, instead of simultaneously branching when encountering a choice) have exponential-time solutions.\n\nMy question is this -- I've never encountered problems that were solvable neither in polynomial time neither in exponential time; polynomial time problems are in P and exponential-time problems are usually in NP-complete.\n\nThere's a helpful Venn diagram here:\nhttp://en.wikipedia.org/wiki/Np_complete\n\n\nI'd like to know an example of a problem that is neither in P, neither in NP-complete, but in NP.\nAlso, are intrinsically exponential problems, like generating the power set of a set NP-complete? Or does that name only apply for problems for which an exponential time algorithm is used only because there's no other obvious method for solving it?\n\n\nOk, so I gave the answer to Rosh Oxymoron because he actually listed some examples of problems suspected to be between P and NPC. Thanks for your help guys, and I actually noticed that I put this question in the wrong place.\nThere's also:\nhttps://cstheory.stackexchange.com/\n\nwhere I found the following very useful answers to my question:\nhttps://cstheory.stackexchange.com/questions/79/problems-between-p-and-npc\nwhich is specifically about what I asked, and:\nhttps://cstheory.stackexchange.com/questions/52/hierarchies-in-np-under-the-assumption-that-p-np\nwhich is generally interesting, if not exactly related to the initial question.\n\nThanks a lot,\n\nDan\n    ", "Answer": "\r\n\nI'd like to know an example of a problem that is neither in P, neither in NP-complete, but in NP.\n\nMe too; if you find one go ahead and visit this web page to claim your $1M prize:  https://www.claymath.org/millennium-problems/p-vs-np-problem\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How can some NP-Complete problems be also NP-Hard?\r\n                \r\nI'm trying wrap my heard around P, NP, NP-Complete and NP-Hard in an intuitive way so that I don't have to remember their definitions.\n\nIn the following image (the left hand scenario, P != NP), there's an overlapping area between NP-Complete and NP-Hard. Does it mean that some problems are both NP-Complete and NP-Hard? I find that contradictory, according to this particular answer: What are the differences between NP, NP-Complete and NP-Hard?.\n\nThe table in the above link says an NP-Complete problem is verifiable in polynomial time and an NP-Hard problem is not. So how can there be an overlap?\n\n\n    ", "Answer": "\r\nPart of the definition of NP-completeness is being NP hard. Therefore, every NP-complete problem is NP-hard. This is also reflected by both of your graphs.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are all problems in NP which are not P NP-complete?\r\n                \r\n\nAre all problems in NP which are not P NP-complete?\nTo make myself more clear, is NP-P=NPC? If not, can you give an example of an NP problem that is neither P nor NP-complete?\nAre all NP-complete problems NP-hard?\n\n\nThank you very much in advance. \n    ", "Answer": "\r\nFirst, a picture\n\n \n\n\nProblems in NP not known to be in P or NP-complete \n\n\n\n  It was shown by Ladner that if ```\nP ≠ NP```\n then there exist problems in ```\nNP```\n\n  that are neither in ```\nP```\n nor ```\nNP-complete```\n. Such problems are called\n  ```\nNP-intermediate```\n problems. The graph isomorphism problem, the discrete\n  logarithm problem and the integer factorization problem are examples\n  of problems believed to be ```\nNP-intermediate```\n. They are some of the very\n  few ```\nNP```\n problems not known to be in ```\nP```\n or to be ```\nNP-complete```\n.\n\n\n\n```\nNP-hard```\n is a class of problems which are at least as hard as the hardest problems in ```\nNP```\n. Thus, yes, every ```\nNP-complete```\n problem is ```\nNP-hard```\n. \n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why all NP-complete problems can be reducible to 3-SAT?\r\n                \r\nWhen I tried to figure out why halting-problem is NP-hard, I found this.\nHowever, there is a statement confuse me\n\n\n  We begin by noting that all NP-complete problems are reducible to 3SAT.\n\n\nWhy all NP-Complete problems can be reducible to 3-SAT?\n\nHope for your answer :-)\n    ", "Answer": "\r\nBy definition, an NP-complete problem X has the property that every problem Y &in; NP reduces to X. (This is what NP-hardness means.) Similarly, by definition every NP-complete problem is in NP. Putting these two together, every NP-complete problem reduces to every other, so all NP-complete problems reduce to 3SAT.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Numberlink/Flow Game: How to spot NP-Complete problems?\r\n                \r\nI was trying to find a way to solve the problem in the famous game Flow. http://moh97.us/flow/\n\nAfter googling I find out that this is a NP-complete problem. A good solution would make use of heuristics and cuts. How can I spot a NP-complete problem easily? Sometimes when I block, I can't see the obvious solution. When this happens with an NP-complete, it's better to recognise it quickly and move on to the next problem.\n    ", "Answer": "\r\nWhen you have an explosion of objects (say objects whose count grows\nexponentially based on some parameter or parameters), this should point \nyou in the direction that it's an NP-complete problem. When you\nhave to inspect, check too many objects (combinatorial or others).\nUsually these objects are subsets or sub-spaces of some initial\nobject space. You should build some intuition for this. But as usual, \nthe intuition lies sometimes (I've been lied like this by my intuition\non 2-3 occasions).\n\nThen once you suspect some problem is NP-complete, just\nGoogle for it and try finding more information about\nthe same or about a similar problem.\n\nThis is what I do at least and I've been\nsolving quite a few algorithmic problems\nsome time ago.\n\nHere is a nice problem which I am pretty sure\nis NP-complete but which can be solved through\na genetic algorithm for example.\n\nhttp://uva.onlinejudge.org/index.php?option=com_onlinejudge&Itemid=8&page=show_problem&problem=973\n\nAnd as Dukeling said, there's no generic way of doing this.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How do we know NP-complete problems are the hardest in NP?\r\n                \r\nI get that if you can do a polynomial time reduction from \"every\" problem then it proves that the problem is at least as hard as every problem in NP. Except, how do we know that we've discovered every problem in NP? Can't there exist problems that we may not have discovered or proven exist in NP but CANNOT be reduced to any np-complete problem? Or is this still an open question?\n    ", "Answer": "\r\nAs others have correctly stated, the existence of the problem that is NP, but is not NP-complete would imply that P != NP, so finding one would bring you a million dollar and eternal glory. One famous problem that is believed to belong in this class is integer factorization. However, your original question was\n\n\n  Can't there exist problems that we may not have discovered or proven\n  exist in NP but CANNOT be reduced to any np-complete problem?\n\n\nThe answer is no. By definition of NP-completeness, one of two \nnecessary conditions for a problem A to be NP-complete is that every NP problem needs to be reducible in polynomial time to A. If you want to find out how to prove that every single NP problem can be reducible in polynomial time to some NP-complete problem, have a look at the proof of Cook-Levin theorem that states that 3-SAT problem is NP-complete. It was the first proven NP-complete problem and many other NP-complete problems are later proven to be NP-complete by finding the appropriate reduction from 3-SAT to these problems.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "The subsets-sum problem and the solvability of NP-complete problems\r\n                \r\nI was reading about the subset-sums problem when I came up with what appears to be a general-purpose algorithm for solving it:\n\n```\n(defun subset-contains-sum (set sum)\n    (let ((subsets) (new-subset) (new-sum))\n        (dolist (element set)\n            (dolist (subset-sum subsets)\n                (setf new-subset (cons element (car subset-sum)))\n                (setf new-sum (+ element (cdr subset-sum)))\n                (if (= new-sum sum)\n                    (return-from subset-contains-sum new-subset))\n                (setf subsets (cons (cons new-subset new-sum) subsets)))\n            (setf subsets (cons (cons element element) subsets)))))\n```\n\n\n\"set\" is a list not containing duplicates and \"sum\" is the sum to search subsets for. \"subsets\" is a list of cons cells where the \"car\" is a subset list and the \"cdr\" is the sum of that subset. New subsets are created from old ones in O(1) time by just cons'ing the element to the front.\n\nI am not sure what the runtime complexity of it is, but appears that with each element \"sum\" grows by, the size of \"subsets\" doubles, plus one, so it appears to me to at least be quadratic.\n\nI am posting this because my impression before was that NP-complete problems tend to be intractable and that the best one can usually hope for is a heuristic, but this appears to be a general-purpose solution that will, assuming you have the CPU cycles, always give you the correct answer. How many other NP-complete problems can be solved like this one?\n    ", "Answer": "\r\nNP-complete problems are solvable, just not in polynomial time (as far as we know). That is, an NP-complete problem may have an ```\nO(n*2^n)```\n algorithm that could solve it, but it won't have, for example, an ```\nO(n^3)```\n algorithm to solve it.\n\nInterestingly, if a quick (polynomial) algorithm was found for any NP-complete problem, then every problem in NP could be solved in polynomial time. This is what P=NP is about.\n\nIf I understand your algorithm correctly (and this is based more on your comments than on the code), then it is equivalent to the ```\nO(n*2^n)```\n algorithm here. There are ```\n2^n```\n subsets, and since you also need to sum each subset, the algorithm is ```\nO(n*2^n)```\n.\n\nOne more thing about complexity - the ```\nO(whatever)```\n only indicates how well a particular algorithm scales. You cannot compare two algorithms and say that one is faster than the other based on this. Big-O notation doesn't care about implementation details and optimisations - it is possible to write two implementations of the same algorithm with one being much faster than the other, even though they might both be ```\nO(n^2)```\n. One woman making babies is an ```\nO(n)```\n operation, but the chances are that this is going to take a lot longer than most ```\nO(n*log(n))```\n sorts you perform. All you can say based on this is that sorting will be slower for very large values on n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Best-case Running-time to solve an NP-Complete problem?\r\n                \r\nWhat is the fastest algorithm that exists up with to solve a particular NP-Complete problem? For example, a naive implementation of travelling salesman is O(n!), but with dynamic programming it can be done in O(n^2 * 2^n). Is there any perhaps \"easier\" NP-Complete problem that has a better running time?\n\nI'm curious about exact solutions, not approximations.\n    ", "Answer": "\r\n\n  [...] with dynamic programming it can be done in O(n^2 * 2^n). Is there any perhaps \"easier\" NP-Complete problem that has a better running time?\n\n\nSort of. You can get rid of any polynomial factor by creating an artificial problem that encodes the same solution in a polynomially larger input. As long as the input is only polynomially larger, the resulting problem is still NP-complete. Since the complexity is by definition the function that maps input size to running time, if the input size grows the function gets into lower O classes.\n\nSo, the same algorithm running on TSP with the input padded with n^2 useless bits, will have complexity O(1 * 2^sqrt(n)).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proving PATH problem is not a NP-complete problem\r\n                \r\nPATH refers to the question of whether a directed path exists from s to t in a graph G. I know that PATH∈P but I find it hard to prove that it's not an \nNP-complete problem. If this was proven somehow, would that mean P≠NP?\n    ", "Answer": "\r\nFor a problem to be NP-complete: \n\n\nit needs to be NP-hard\nit needs to be in NP\n\n\nFor a problem to be NP-hard, it must be at least as hard as the hardest problems in NP.\nThat means it must be possible to use an NP-hard problem to solve any other problem in NP in polynomial time.\n\nWe want to prove that PATH isn't NP-complete, but we already know it's in P, so it is definitely in NP too (trivially, every deterministic Turing Machine can be simulated by a non-deterministic Turing Machine).\n\n\n\nHence, the only way to prove that PATH is not NP-complete is proving that there is at least one NP problem that cannot be reduced to PATH in polynomial time.\nUnfortunately, you will find that this depends on the P vs NP open problem.\n\nProof by contradiction\n\nLet us use the The Traveling salesman problem (TSP), which is an NP-complete problem that seems to be quite relevant to PATH.\nAssume that TSP reduces to PATH, i.e. there exists a polynomial time modification for instances of the TSP problem so that they could then be correctly solved by a PATH Turing Machine.\n\nWe know all P problems are reducible to each other in polynomial time. \nAlso, we know all NP problems are reducible to TSP in polynomial time.\n\nSo by transitivity, all NP problems reduce to TSP, TSP would reduce to PATH, and PATH reduces to all other P problems. \nThis yields P = NP = NP-complete.\n\nPATH is an NP-complete problem if and only if P = NP = NP-complete.\n\nSimilarly, proving that PATH isn't an NP-complete problem would be equivalent to proving P ≠ NP ≠ NP-complete. If PATH isn't an NP-complete problem, then no problem in P is, because all P problems are reducible to each other in polynomial time. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is it correct to ask to solve an NP-complete problem on a job interview? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is off-topic. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.\r\n                \r\n                    \r\n                        Closed 11 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nToday there was a question on SO, where the author was given an NP-complete problem during an interview and he obviously hadn't been told that it was one.\n\nWhat is the purpose of asking such questions?  What behavior does the interviewer expect when asking such things?  Proof?  Useful heuristics?  And is it even legitimate to ask one if it's not a well-known NP-complete problem everyone should know about?  (there's a plenty of them)\n    ", "Answer": "\r\nCompletely legitimate to me. If you are Computer Science professional there are good chances that you can either argument informally why the problem seems to be hard, or (even better) provide a sketch of reduction from a known NP-hard problem.\n\nMany real world problems eventually turn out to be NP-hard, and stackoverflow also has now and then questions about the complexity of a problem which turns out to be a difficult one (NP-hard, for instance). It is an important part of a CS professionals toolbox to be able to recognize and to argue for problems which are known to be difficult to solve.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Prove a problem that is NP-hard and not NP-complete in not in P\r\n                \r\nIf A is not NP-hard, but not NP-complete, then prove that A in not in P.  \n\nA is NP-hard if there is an NP-complete problem B such that B is reducible to A in polynomial time.  A is NP-complete if A is in NP and all NP problems are reducible to A in polynomial time. But A is not NP-complete, so one one or both of those conditions must be false.  If A is not in NP, then A is not in P.  The other case is that there exists at least one NP problem that is not reducible to A in polynomial time.  This is where I am stuck. How do I get from knowing that there is an NP-complete problem that is reducible and an NP problem that is not reducible to A is not in P?\n    ", "Answer": "\r\nIf a problem A is NP-hard, then all NP problems are reducible to A in polynomial time.\n\nProof:\nSince the problem A is not NP-Complete, then there exists problem B as defined above.  All problems C in NP can be reduced to B in polynomial time, then B can be reduced to A in polynomial time.  Composition of polynomial time algorithms is polynomial, so C can be reduced to A in polynomial time.\n\n--\n\nSince A is NP-Hard but not NP-Complete, A must not be in NP, therefore A is not in P either.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete VS NP-Hard\r\n                \r\nI am trying to understand the difference between NP-Complete and NP-Hard. \n\nBelow is my understanding \n\n\n  An NP-Hard problem is one that is not solvable in polynomial time but can be verified in polynomial time.\n  An NP-Complete problem is one that is in NP and is also NP-Hard. \n\n\nIs the above definition correct? If so, What about problems not In NP but NP-Hard. Wouldn't they be harder than NP-Complete problem, say they can only be solved and verified in exponential time? \n    ", "Answer": "\r\nA ```\nNP```\n problem (not ```\nNP-Hard```\n problem) is a decision problem which can be verified in polynomial time. Maybe they are solvable in polynomial time, since all problems in ```\nP```\n are also in ```\nNP```\n. \n\nA ```\nNP-complete```\n problem is a decision problem, which all ```\nNP```\n problems can reduced to in polynomial time. They are the hardest problems in the class ```\nNP```\n.\n\nThe ```\nNP-hard```\n class is the class  of the problems which are at least as hard as the ```\nNP-complete```\n problem. They are not necessarily a decision problem. Given that we don't know whether ```\nNP = P```\n or not, it would be hard to say whether we can verify a ```\nNP-hard```\n problem in polynomial time.\n\nFor example, the decision problem of maximum clique (Give a graph ```\nG```\n an integer ```\nK```\n, to tell whether there is a complete graph with at least ```\nK```\n vertices ) is ```\nNP```\n problem. It is also ```\nNP-complete```\n and ```\nNP-hard```\n. However, maximum clique problem (Find the maximum clique in the given Graph) is not ```\nNP```\n or ```\nNP-complete```\n, since it is not decision problem. We can say it is ```\nNP-hard```\n, since it is at least as hard as the decision version of maximum clique problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this problem np-complete?\r\n                \r\nSay there is a line of x bins filled with trinkets (random amount), in plain-sight (you can see how many trinkets there are in each bin). Now there are two players who can when it's their turn pick a bin from either end. They cannot forgo a turn. Come up with a strategy for a player to get the maximum amount of trinkets.\n\nx is even.\n\nIs this a np-complete problem? Is it similar to boolean SAT?\n    ", "Answer": "\r\nIt is very simple problem, and it is not NP complete.\nHere is short description of algorithm, it is based on dynamic programming.\n\nCan[i] - array which stores number of trinkets.\nF[i,j] - array determining what is best move if only cans from i to j are avaible. 0 means take from the left side, 1 means take from the right side.\nG[i,j] - array where 'goodness'  of move is stored.  \n\n```\nfor (i=1 to n) F[i,i] = 0\nfor (i=1 to n) G[i,i] = Can[i]\n\nfor (i=1 to n-1)\n   for (j=1 to n-i)\n       tmp1 = Can[j] - G[j+1,j+i]\n       tmp2 = Can[j+i] - G[j,j+i-1]\n       if (tmp1>tmp2)\n       {\n             F[j,j+i] = 0;\n             G[j,j+i] = tmp1;\n       }\n       else\n       {\n             F[j,j+1] = 1;\n             G[j,j+i] = tmp2;\n       }\n```\n\n\nSorry for lack of comments, but if you read some articles about dynamic programming You will get it without any problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP complete or NP hard, in a equivalences problems?\r\n                \r\nI ran into a question.\n\n\n  Finding of all cycle in a graph is NP-Complete.\n\n\nI see this note on Google search.\n\n\n  counting all cycle in a graph is NP-Complete.\n\n\n```\nare these two sentence equivalences ? can we say these two is NP-Hard?\n```\n\n\nThanks for every useful note. \n    ", "Answer": "\r\n```\nare these two sentence equivalences ?```\n\n\nYes but it's not phrased properly. None of those questions are decision problems. Decision problems return either true or false. NP-Complete is a categorization of decision problems so it'll be \"improper\" to say the above are NP-Complete. But if we say, \"Are there X number of cycles in a graph?\" that would be a NP-Complete question.\n\n```\ncan we say these two is NP-Hard?```\n\nYes NP-Hard means it's as hard as NP at least so because these two problems are NP-Complete then this is true.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Every np-complete problem reduces to the Halting problem. Is this true?\r\n                \r\nI guess that every np-complete problem reduces to the np-hard problem, so the given statement is true. But don't know how to prove it.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete problems to Partition Problem reductions\r\n                \r\nAccording to Wikipedia, Partition Problem (PP) is NP-Complete (NPC) problem with existing pseudo-polynomial time dynamic programming (DP) solution. If a problem is NPC any NP problem can be reduced to instance of such problem in polynomial-time, i.e. Traveling salesman problem (TSP) instance to PP instance. Now there is no algorithm, DP or otherwise, for TSP to have better bound than ```\nO(2^n)```\n.\nNow, why is that if I can take TSP instance, create PP instance out of it, solve PP instance in pseudo-polynomial time and reduce it back? The reductions only costing me something polynomial.\n    ", "Answer": "\r\nThe question here is “pseudopolynomial in what quantity?” For the knapsack problem, the pseudopolynomial-time algorithm runs in time O(nW), where W is the maximum weight of any of the items. If you actually try running through the details of reducing TSP (or most other NP-complete problems) to knapsack using the “standard” reductions known today, you’ll find that the weights on the items are enormous and typically exponential in the size of the inputs to those problems. For example, the typical reduction from set packing to knapsack works by building items whose weights are on the order of 2n, where n is the number of distinct items across all sets. That makes the runtime of first using this reduction and then applying knapsack O(n · 2n), which isn’t pseudopolynomial time.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are these two definitions of an NP-Complete problem equivalent?\r\n                \r\nDefinition 1 (usual definition)\nA problem B is NP-Complete if\n\nB is in NP\nFor C in NP, C is polynomal-time reducible to B\n\nDefinition 2 (in a few documents)\nA problem B is NP-Complete if\n\nB is in NP\nif B  admits a polynomial-time algorithm, then all problems in NP  also admit a polynomial-time algorithm\n\n(as in \"On the Inherent Intractability of Certain Coding Problems,..., Berlekamp, McEliece and Tilborg\" and other documents\n    ", "Answer": "\r\nDefinition 1 is the definition of NP-completeness you get if you define reducibility to be polynomial-time mapping reducibility (sometimes called polynomial-time many-one reducibility). That is, you’re allowed to reduce one problem to another by doing polynomial work to transform the input, then make a single call to the target problem. This is the standard definition of NP-completeness.\nDefinition 2 is the (nonstandard) definition of NP-completeness you get if you use polynomial-time Turing reducibility (called Cook reductions), in which you are allowed to spend polynomial time including an arbitrary number of calls to an oracle (solver) for the problem you’re reducing to.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Can a problem be in NP but not NP-Complete or P?\r\n                \r\nI am looking at the graphs in:\nhttps://en.wikipedia.org/wiki/P_versus_NP_problem\n\nIt seems like, there is gap between P and NP-complete. So are there a class of problems that are in NP but neither in P or NP-Complete.\n\nIn other words, do the classes P, NP-complete completely cover NP?\n\nAnd if so, an example is appreciated.\n    ", "Answer": "\r\nIf P = NP, the answer to your question is that all problems in NP are both in P and in NP-Complete.\n\nIf P != NP, the answer to your question is that there are problems known to be in NP, which are known not to be NP-complete but for which no polynomial-time algorithm is yet known. I say there is none yet known because if you knew (1) the problem is in NP and (2) the problem is not in P, well then you'd know P != NP, which we don't.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What are the examples of NP problems that is reducible to a NP-complete but not the other way round?\r\n                \r\nWhat are the examples of NP problems that is reducible to NP-complete problem but not the other way round? When I read about NP and NP-complete, I thought the mapping will be one-one such that it is stupid to categorize them. However, surely there are problems where it can only be reducible in one direction. I am interested to know them.\n    ", "Answer": "\r\nAll NP problems can be reduced to NP-complete problems. NP-complete problems are a special type of NP problems. Therefore, NP-complete problems don't need to be reduced to be considered to be in NP; they're already in NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "polynomial time reduction from a problem to a NP-complete problem\r\n                \r\nI have problems to solve the following question:\nIf there are two problems p1 and p2, p2 is NP-complete and there is a polynomial reduction from p1 to p2, then p1 ...\na) is NP-hard but not necessarily NP-complete\nb) could be in P, even if P!=NP\nc) is NP-complete\nd) none of the above\nI think c) is correct, but I am not sure and how can I justify ist?\n    ", "Answer": "\r\nIf there is a polynomial-time reduction from p1 to p2 it means that if you get an instance of problem p1, then you can transform it (in polynomial time) to an instance of problem p2. What does that tell us about problem p1?\nWell, not very much. It means it's decidable, but it doesn't tell us a lot about its time complexity. For all we know, it might be the problem \"What is 1+1?\".\nHad it been the other way around, then it would imply that p1 is NP-hard because otherwise we could solve p2 in polynomial time by reducing it to p1 and solving that in polynomial time.\nSo, since we don't know anything else about p1, the answer should be b).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is there an optimization problem that is NP-Complete?\r\n                \r\nIs there such a thing as an NP-complete optimization (not decision) problem?\nWhat is an example of an NP-complete optimization problem?\nThe decision versions of optimization problems are the ones in NP-complete.\nI can't think of any NP-hard optimizations that can be confirmed in polynomial time. I need verification/correction on this.\nThank you.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is it possible to find the probability to a solution of NP-complete problems?\r\n                \r\nThe title covers the entirety of the question. Is it possible to derive a function to say with certainty that a proposed solution to a NP-complete problem has a m percent chance of being correct?\n    ", "Answer": "\r\nI doubt it. For example a random function's probability to be optimal is ```\nnumberOfOptimalSolutions / searchSpace```\n. So if you know the answer to that, you can deduce the numberOfOptimalSolutions (which is IIRC always harder to know than finding 1 optimal solution to an NP complete problem).\n\nThe book \"In pursuit of the traveling salesman\" lists for each construction heuristic in TSP how close (or far) it is in the worst case scenario from the optimal solution. It also mentions the average percentage of being correct for (some of) those algo's, but IIRC it's probably based on sampling and it gets worse as the problem scales out. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why are NP problems called that way (and NP-hard and NP-complete)?\r\n                \r\nReally.. I'm having the last test for graduation this Tuesday, and that's one of the things I just never could understand.\nI realize that a solution for NP problem can be verfied in polynomial time. But what does determinism has to do with that?\nAnd if you could explain me where NP-complete and NP-hard got their names, that would be great (I'm pretty sure I get the meaning of them, I just don't see what their names have to do with what they are).\nSorry if that's trivial, I just can't seem to get it (-:\nThanks all!\n    ", "Answer": "\r\nP\n\nClass of all problems which can be solved by a deterministic Turing machine in polynomial time.\n\nNP\n\nClass of all problems which can be solved by a non-deterministic Turing machine in polynomial time (they can also be verified by a deterministic Turing machine in polynomial time.)\n\nNP-Hard\n\nA class of problems which are \"at least as hard as the hardest problems in NP\". Formally, a problem is in NP-Hard iff there is an NP-complete problem that is polynomial time Turing-reducible to it; (also: iff it can be solved in polynomial time by an oracle machine with an oracle for the problem). It is pretty obvious where the name comes from.\n\nNPC\n\nThe class of problems which are both NP as well as NP-Hard. Regarding the naming, even wikipedia is not sure why it's named as it is.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Solving the NP-complete problem in XKCD\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                Locked. This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n\r\n\r\n    \r\n\r\nThe problem/comic in question: http://xkcd.com/287/\n\n\n\nI'm not sure this is the best way to do it, but here's what I've come up with so far. I'm using CFML, but it should be readable by anyone.\n\n```\n<cffunction name=\"testCombo\" returntype=\"boolean\">\n    <cfargument name=\"currentCombo\" type=\"string\" required=\"true\" />\n    <cfargument name=\"currentTotal\" type=\"numeric\" required=\"true\" />\n    <cfargument name=\"apps\" type=\"array\" required=\"true\" />\n\n    <cfset var a = 0 />\n    <cfset var found = false />\n\n    <cfloop from=\"1\" to=\"#arrayLen(arguments.apps)#\" index=\"a\">\n        <cfset arguments.currentCombo = listAppend(arguments.currentCombo, arguments.apps[a].name) />\n        <cfset arguments.currentTotal = arguments.currentTotal + arguments.apps[a].cost />\n        <cfif arguments.currentTotal eq 15.05>\n            <!--- print current combo --->\n            <cfoutput><strong>#arguments.currentCombo# = 15.05</strong></cfoutput><br />\n            <cfreturn true />\n        <cfelseif arguments.currentTotal gt 15.05>\n            <cfoutput>#arguments.currentCombo# > 15.05 (aborting)</cfoutput><br />\n            <cfreturn false />\n        <cfelse>\n            <!--- less than 15.05 --->\n            <cfoutput>#arguments.currentCombo# < 15.05 (traversing)</cfoutput><br />\n            <cfset found = testCombo(arguments.currentCombo, arguments.currentTotal, arguments.apps) />\n        </cfif>\n    </cfloop>\n</cffunction>\n\n<cfset mf = {name=\"Mixed Fruit\", cost=2.15} />\n<cfset ff = {name=\"French Fries\", cost=2.75} />\n<cfset ss = {name=\"side salad\", cost=3.35} />\n<cfset hw = {name=\"hot wings\", cost=3.55} />\n<cfset ms = {name=\"moz sticks\", cost=4.20} />\n<cfset sp = {name=\"sampler plate\", cost=5.80} />\n<cfset apps = [ mf, ff, ss, hw, ms, sp ] />\n\n<cfloop from=\"1\" to=\"6\" index=\"b\">\n    <cfoutput>#testCombo(apps[b].name, apps[b].cost, apps)#</cfoutput>\n</cfloop>\n```\n\n\nThe above code tells me that the only combination that adds up to $15.05 is 7 orders of Mixed Fruit, and it takes 232 executions of my testCombo function to complete.\n\nIs there a better algorithm to come to the correct solution? Did I come to the correct solution?\n    ", "Answer": "\r\nIt gives all the permutations of the solutions, but I think I'm beating everyone else for code size.\n\n```\nitem(X) :- member(X,[215, 275, 335, 355, 420, 580]).\nsolution([X|Y], Z) :- item(X), plus(S, X, Z), Z >= 0, solution(Y, S).\nsolution([], 0).\n```\n\n\nSolution with swiprolog:\n\n```\n?- solution(X, 1505).\n\nX = [215, 215, 215, 215, 215, 215, 215] ;\n\nX = [215, 355, 355, 580] ;\n\nX = [215, 355, 580, 355] ;\n\nX = [215, 580, 355, 355] ;\n\nX = [355, 215, 355, 580] ;\n\nX = [355, 215, 580, 355] ;\n\nX = [355, 355, 215, 580] ;\n\nX = [355, 355, 580, 215] ;\n\nX = [355, 580, 215, 355] ;\n\nX = [355, 580, 355, 215] ;\n\nX = [580, 215, 355, 355] ;\n\nX = [580, 355, 215, 355] ;\n\nX = [580, 355, 355, 215] ;\n\nNo\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete and some decision problems on graph?\r\n                \r\nWe know about NP-Complete and NP-Hard, and NP Class. I want to conclude some tips on following problem, that take from 2008 Mid exam on MIT. \n\nDecision Version of which of the following problem for a connected undirected weighted graph G is NP-Complete?\n\n\n  a) finding maximal matching.\n  \n  b) finding maximum Hamiltonian cycle\n  \n  c) finding maximum Eulelrian cycle\n  \n  d) finding maximum cut\n\n\nHow can categorized these problem in a simple manner for me? i.e. NP or NP-Complete or NP-Hard. \n    ", "Answer": "\r\nThere are poly-time algorithms for computing maximal matchings (e.g., greedy; Edmonds's Blossom algorithm computes a maximum matching in poly-time) and Eulerian cycles. The decision versions trivially belong to NP (P, in fact).\n\nHamilton cycle and max cut are well-known NP-hard problems. The decision versions are in NP so thus are NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is the integer-factorization problem (used for many cryptographic applications) NP-Complete?\r\n                \r\nAs the question states, does the integer-factorization problem fall into the class of NP-Complete problems?\n    ", "Answer": "\r\nFactoring:\n\n\nIt is not known to be NP-complete. (No reduction from an NP-complete problem has been found.)\nIt is not known not to be NP-complete either (if we knew the latter about some nontrivial problem in NP, it would mean P≠NP, so the latter is not surprising). \nNo polynomial factoring algorithm is known (or believed to exist), so it is believed not to be in P either.\n\n\nThe informal consensus/belief is that this is one of the \"in-between\" problems that are not in P and are not NP-complete. Of course, this belief is less strong and widely held than P≠NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is there an NP problem that is not NP-complete or P?\r\n                \r\nI am trying to understand the relationships between P, NP, NP-Complete and NP-Hard.  \n\nI believe I am starting to understand the general idea but, I am hung up on this question(see title).\n\nWhat is an example of a problem that is not solvable in P time, is verifiable in P time but is not NP-Complete?\n\nIf there is some piece of understanding I am missing please fill me in.\n\nThanks in advance\n    ", "Answer": "\r\nAs noted in the comments, this is the wrong site for this question. However, it can be answered briefly:\n\n\n  What is an example of a problem that is not solvable in P time, is verifiable in P time but is not NP-Complete?\n\n\nIf I understand you, what you want are problems that are (1) not in P, (2) in NP, and (3) not in NPC. Such problems are the NP-intermediate (NPI) problems.\n\nIt is not known if there is any such problem, because it is not known if P=NP.\n\nIf P=NP then clearly there are no such problems; if P=NP then also P=NPC, and therefore every problem which can be verified in P time is in all of P, NP and NPC because they are equal.\n\nIf P!=NP then it is known that there are such problems; at least one exists.  Unfortunately we do not know if any real-world problems we face are in NPI provided that P!=NP. A list of likely candidates can be found here: \n\nhttps://en.wikipedia.org/wiki/NP-intermediate \n\nIn short: knowing whether NPI is empty or not is equivalent to solving proving P!=NP, so get cracking! If you can find a problem that is definitely in NP but definitely not in P or NPC, then there's a big money prize awaiting you.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If a polynomial time algorithm for an NP-Complete problem is found, does this imply that it is the same time complexity for all NP problems?\r\n                \r\nIf a polynomial time algorithm for an NP-Complete problem is found, lets say its O(n^2) hypothetically, does this imply that there is an O(n^2) solution for all NP problem? I know this would imply that there is a polynomial solution for all NP-problems, but would it necessarily be O(n^2)? \n    ", "Answer": "\r\nNot necessarily \n\n\n  A problem x that is in NP is also in NP-Complete if and only if every\n  other problem in NP can be quickly (ie. in polynomial time)\n  transformed into x.\n\n\nTherefore an algorithm that solves one NP-Complete problem means we can solve any other problem in NP by transforming it to an instance of that problem and solving it. But the transformation could be any complexity as long as its polynomial we satisfy the condition. \n\nSo the answer to your question in no, an O(N^2) algorithm to solve an NP-Complete problem does not imply all NP problems can be solved in O(N^2) time, it only guarantees there exists a polynomial time algorithm to solve it. \n\nie O(N^2) + T(N) where T(N) is the complexity to transform the problem instance \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete vs. NP-hard [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is off-topic. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.\r\n                \r\n                    \r\n                        Closed 11 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nIf a problem A known to be NP-Complete can be reduced to another problem B in polynomial time then B is\n(A) NP-Complete\n(B) NP-hard\n\nNothing is given about problem B whether it is in NP or not. I'm confused because in Hopcraft and Ullman book there is theorem given if a NP-complete problem P1 can be reduced to problem P2 in polynomial time then P2 is NP-complete. But it also required for a problem to be NP-Complete that it should belong to NP class. Guys help in understanding this concept.\n    ", "Answer": "\r\nIf A can be reduced to B in polynomial time all you know is that B is harder than A. In your case, if A is NP-complete, B is NP-hard.\nIf B also happens to be in NP then B will be NP-complete (since NP-complete means being both in NP and being NP-hard at the same time).\nHowever, nothing stops you from reducing A to a problem that is not in NP. For example, it is trivial to reduce any problem in NP to the halting problem - a problem that is undecideable in addition to being NP-hard:\n```\nConstruct the following program:\n    Test all possible solutions for A.\n    If one of them is successful halt and otherwise enter an infinite loop.\nA has a solution if-and-only if that program halts\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why is the NP-complete set restricted to only decision problems?\r\n                \r\nAmong P, NP, NP hard and NP-complete, only the NP-complete set is restricted to decision problems (those that have a binary solution). What is the reason for this? Why not define it simply as the intersection of NP and NP-hard? And this leads to another question - there must be problems that are not necessarily decision problems and also have the property that any problem in NP can be reduced to them in polynomial time. Is this then a set encompassing NP-complete? Is there already a name for this set?\n\nEDIT: Per the comment by Matt and also the post: What are the differences between NP, NP-Complete and NP-Hard?, its seems P and NP are defined only for decision problems. That would resolve this question apart from why they would be defined this way. But, this seems to be in contradiction to the book Introduction to Algorithms by Cormen et.al. In chapter 34, the section titled \"NP-completeness and the classes P and NP\", they simply say: \"P consists of those problems that are solvable in polynomial time\". They even say later, \"NP-completeness applies directly not to optimization problems, but to decision problems\" but say no such thing about P and NP.\n    ", "Answer": "\r\nThe classes P and NP are indeed classes of decision problems. I don’t have my copy of CLRS handy, but if they’re claiming that P and NP are all problems solvable in polynomial time or nondeterministic polynomial time, respectively, they are incorrect.\nThere are some good theoretical reasons why it’s helpful to define P and NP as sets of decision problems. Working with decision problems makes reducibility much easier (reducing one problem to another doesn’t require transforming output), simplifies the model by eliminating issues of how big the answer to a question must be, makes it easier to define nondeterministic computation, etc.\nBut none of those are “dealbreakers” in the sense that you can define analogous complexity classes that involve computing functions rather than just coming up with yes or no answers. For example, the classes FP and FNP are the function problem versions of P and NP, and the question of whether FP = FNP is similarly open.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is an NP-complete pr0blem also an NP-hard?\r\n                \r\nWe can say that an NP-complete problem is one which is in NP and in NP-hard, but can we argue exclusively that a problem is NP-hard solely due to the fact that it is NP-complete.\n\nExample: I reduce an NP-complete problem ```\na```\n to a problem ```\nb```\n. Therefore, problem ```\nb```\n is now proven to be NP-complete. Can I actually say that it is also NP-hard?\n    ", "Answer": "\r\nThe definition of NP completeness is:\n\n\n  A problem Q is NP-complete if and only if Q is in NP and Q is NP-hard.\n\n\nTherefore, yes, we can most definitely say that any NP-complete problem is NP-hard, by definition.\n\nNote that you have a slight misstatement in your question:\n\n\n  Example: I reduce an NP-complete problem ```\na```\n to a problem ```\nb```\n. Therefore, problem ```\nb```\n is now proven to be NP-complete.\n\n\nThe above conclusion only holds if you've shown ```\nb```\n to be in NP. If ```\nb```\n is \"harder\" than NP, then it is not NP-complete. Note, however, that the reduction is enough to prove that ```\nb```\n is NP-hard.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete reduction (in theory)\r\n                \r\nI want to embed 3 NP-Complete problems(2 of them are known to be NP-Complete, 1 of them is my own idea). I saw \"this question\" and got idea about reinterpreting embedding problems in theory:\n\n\nThe Waiter is The Thief.\nTables are store.\nFoods are valued items which has different weight.\nThief know all the items' price and weight before the robbery.\nHis target is most efficient robbery(max capacity of knapsack used, most valued items got) with robbing(getting at least 1 item) all stores(shortest way to completing robbery tour, also visit each store 1 time).\n\n\nThis part is embedding 2 NP-Complete problems.\n\nMy idea is, that more items mean more bag weight. More bag weight slow downs the thief exponentially. So another target of the thief should be finishing the robbery as quickly as he/she can.\n\nAt this time, I'm not sure that my idea is actually NP-Complete. Maybe, \"gravity\" is not a NP-Complete Problem alone. But maybe it is in this context of the travelling salesman and knapsack problem.\n\nSo my questions are:\n\n\nIs the slowing down of the thief NP-complete, too?\nIs it possible to reduce those three embedded problems to a simple NP-complete problem?\n\n    ", "Answer": "\r\nOkay, that was just a bit tough to follow, but I think I'm getting the gist.\n\nThe XKCD cartoon is showing you how easy it is to make a real-life problem NP-complete.  (Of course, since most menus have a small number of items and a uniform set of prices, it's also easy to show that there is a trivial answer.)  \n\nThe idea of \"embedding\" an NP-complete problem I think you're referring to is finding a poly-time reduction; I've written that up pretty completely elsewhere on SO.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Classifying NP Completeness and Hardness\r\n                \r\nChoose the correct statement(s):\n\n(A) If ```\nX```\n is an NP-complete problem, then ```\nX```\n is an NP problem\n(B) If ```\nX```\n is an NP-complete problem, then ```\nX```\n is an NP-hard\n(C) Let ```\nX```\n be an NP-complete problem. If ```\nX```\n can polynomial reduce to a problem ```\nY```\n, then ```\nY```\n is an NP-complete.\n(D) Let ```\nX```\n be an NP-complete problem. If ```\nY```\n can polynomial reduce to a problem ```\nX```\n, then ```\nY```\n is an NP-complete.\n(E) Let ```\nX```\n be an NP-complete problem. If ```\nX```\n can polynomial reduce to a problem ```\nY```\n, then ```\nY```\n is an NP-hard.\n\nMy answer is (A)(B)(C)(E):\n\n(A)(B) : X belongs to NP-complete, means X belongs to NP and NP-hard\n(C) true\n(D) Y may be P, NP-hard or NP-complete\n(E) Y is an NP-complete, and it also is an NP-hard\n\n\nIs answer true?\n    ", "Answer": "\r\nHere are some corrections:\n(C) False. Y is NP-hard, but not necessarily in NP.\n(D) False. Y is in NP, not necessarily NP-complete.\n(E) True, but Y is no necessarily NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If these problems are NP-Complete, how are there polynomial time algorithms for solving them?\r\n                \r\nI'm studying P, NP, and NP-Complete problems and I've encountered some questions.\n\nI understand that a problem is P if you can solve it in polynomial time, and a problem is NP if it is verifiable in polynomial time. I also understand that a problem is NP-Complete if it is NP and can be reduced from an existing NP-Complete problem.\n\nI know that SAT, 3-SAT, Independent Set, Vertex Cover, Hamiltonian Cycle, Subset Sum, and Traveling Salesman are all NPC. But I encountered a problem where I was told that deciding whether an independent set of 5 vertices exists in a graph is actually polynomial time solvable instead of NPC. This then confused me because I thought independent set problems were NPC.\n\nSo then it made me wonder, in what scenarios are these \"NPC\" problems not NPC and are in fact P? When given a problem, how do I determine whether a problem is P or NPC? What if the problem does have a poly time solvable solution I just wasn't able to come up with it and therefore went down the NPC path. How do I know that I've made a mistake?\n    ", "Answer": "\r\nThe problem of finding a maximal independent set of a graph is NP-hard, just like the travelling salesman problem. They are both optimisation problems, and they both involve enumerating a number of cases which is greater than polynomial in the input size.\n\nGiven a number ```\nk```\n, and a graph of ```\nn```\n vertices, the problem of finding an independent set of ```\nk```\n vertices is a separate problem, for which there is a polynomial-time solution. This is not an optimisation problem.\n\nThe solution is bounded by the fact that there are at most ```\nC(n, k)```\n subsets of five vertices, and for each subset, you need to check at most ```\nC(k, 2)```\n edges. Each of these is polynomial in ```\nn```\n for constant ```\nk```\n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Possible NP-complete problem?\r\n                \r\nI'd just like someone to verify whether the following problem is NP-complete or if there is actually a better/easier solution to it than simple brute-force combination checking.\n\nWe have a sort-of resource allocation problem in our software, and I'll explain it with an example.\n\nLet's say we need 4 people to be at work during the day-shift. This number, and the fact that it is a \"day-shift\" is recorded in our database.\n\nHowever, we don't require just anyone to fill those spots, there's some requirements that needs to be filled in order to fit the bill.\n\nOf those 4, let's say 2 of them has to be a nurse, and 1 of them has to be doctors.\n\nOne of the doctors also has to work as part of a particular team.\n\nSo we have this set of information:\n\n\n  Day-shift: 4\n     1 doctor\n     1 doctor, need to work in team A\n     1 nurse  \n\n\nThe above is not the problem. The problem comes when we start picking people to work the day-shift and trying to figure out if the people we've picked so far can actually fill the criteria.\n\nFor instance, let's say we pick James, John, Ursula and Mary to work, where James and Ursula are doctors, John and Mary are nurses.\n\nUrsula also works in team A.\n\nNow, depending on the order we try to fit the bill, we might end up deducing that we have the right people, or not, unless we start trying different combinations.\n\nFor instance, if go down the list and pick Ursula first, we could match her with the \"1 doctor\" criteria. Then we get to James, and we notice that since he doesn't work in team A, the other criteria about \"1 doctor, need to work in team A\", can't be filled with him. Since the other two people are nurses, they won't fit that criteria either.\n\nSo we backtrack and try James first, and he too can fit the first criteria, and then Ursula can fit the criteria that needs that team.\n\nSo the problem looks to us as we need to try different combinations until we've either tried them all, in which case we have some criteria that aren't filled yet, even if the total number of heads working is the same as the total number of heads needed, or we've found a combination that works.\n\nIs this the only solution, can anyone think of a better one?\n\n\n\nEdit: Some clarification.\n\nComments to this question mentions that with this few people, we should go with brute-force, and I agree, that's probably what we could do, and we might even do that, in the same lane that some sort optimizations look at the size of the data and picks different sort algorithms with less initial overhead if the data size is small.\n\nThe problem though is that this is part of a roster planning system, in which you might have quite a few number of people involved, both as \"We need X people on the day shift\" as well as \"We have this pool of Y people that will be doing it\", as well as potential for a large \"We have this list of Z criteria for those X people that will have to somehow match up with these Y people\", and then you add to the fact that we will have a number of days to do the same calculation for, in real-time, as the leader adjusts the roster, and then the need for a speedy solution has come up.\n\nBasically, the leader will see a live sum information on-screen that says how many people are still missing, both on the day-shift as a whole, as well as how many people is fitting the various criteria, and how many people we actually ned in addition to the ones we have. This display will have to update semi-live while the leader adjusts the roster with \"What if James takes the day-shift instead of Ursula, and Ursula takes the night-shift\".\n\nBut huge thanks to the people that has answered this so far, the constraint satisfaction problem sounds like the way we need to go, but we'll definitely look hard at all the links and algorithm names here.\n\nThis is why I love StackOverflow :)\n    ", "Answer": "\r\nWhat you have there is a constraint satisfaction problem; their relationship to NP is interesting, because they're typically NP but often not NP-complete, i.e. they're tractable to polynomial-time solutions.\n\nAs ebo noted in comments, your situation sounds like it can be formulated as an exact cover problem, which you can apply Knuth's Algorithm X to.  If you take this tack, please let us know how it works out for you.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP complete - solvable in non-deterministic polynomial time\r\n                \r\nIt is written in a book that --\"If a problem A is NP-Complete, there exists a non-deterministic polynomial time algorithm to solve A\" . But as far I know 'yes' -answer for NP complete problems can be \"verified\" in polynomial time. I am really confused. Can a NP-complete problem be \"solved\" using non-deterministic polynomial time algorithm?\n    ", "Answer": "\r\nThe two things are basically identical and are based on two different though equivalent definition of NP.\n\nEvery problem (language) in NP must be:\n\n\nVerified in polynomial time by a deterministic turing machine. (given a problem and a 'verification', you can answer if the verification is correct for the problem in a polynomial time).\nExample: Given a graph, and you want to check if there is a hamiltonian path in it - the verifier can be the path. You can easily check if the path is indeed hamiltonian once you have it.\nSolved in polynomial time by a non deterministic turing machine. (there exists non deterministic Turing Machine ```\nM```\n that can solve the problem polynomially)\n\n\nSince by definition of NP-Complete - a problem is NP Complete if it is NP-Hard AND in NP, every NP-Complete problem is also NP - and both are correct.\n\n\n\nNote that those two claims are basically based on the two equivalent definitions for NP:\n\n\nA language ```\nL```\n is in NP if for each ```\nx```\n in ```\nL```\n there is a word ```\nz```\n such that ```\n|z|```\n is polynomial in ```\n|x|```\n, and there exists some deterministic turing machine that runs in polynomial time ```\nM```\n - such that for each ```\nx```\n and its matching ```\nz```\n,: ```\nM(x,z) = true if and only if x is in L```\n\nA problem is in NP if there is a non deterministic turing machine that can solve the problem in polynomia time. Formally, a language ```\nL```\n is in NP if there is a non deterministic turing machine such that ```\nM(x) = true if and only if x is in L```\n\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is it compulsory that the 'reduction of p‌r‌o‌b‌l‌e‌m be done in polynomial time' for it to be NP complete?\r\n                \r\nFor a problem to be NP complete, it must belong to the class NP and there must be a polynomial time algorithm to reduce it to an NP complete problem . \n\nNow what if we only have an exponential time algorithm for reduction . Will this problem still be called NP-complete ? Or are there no such existing problems? \n\nEDIT : Also please tell me whether there is any such problem and if it exists then to which class does it belong ? \n    ", "Answer": "\r\nIt can only be consider NP-complete if other NP problems can be reduced to it in polynomial time.  The reason this is a useful definition is that if we find a polynomial time algorithm for one, it automatically gives one for all NP problems.  If we allowed an exponential time reduction, but found a polynomial time solution to the reduced problem, that wouldn't actually help us solve the one we reduced it to.\n\nHope this helps.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Confusion about NP-hard and NP-Complete in Traveling Salesman problems\r\n                \r\nTraveling Salesman Optimization(TSP-OPT) is a NP-hard problem and Traveling Salesman Search(TSP) is NP-complete. However, TSP-OPT can be reduced to TSP since if TSP can be solved in polynomial time, then so can TSP-OPT(1). I thought for A to be reduced to B, B has to be as hard if not harder than A. As I can see in the below references, TSP-OPT can be reduced to TSP. TSP-OPT is supposed to be harder than TSP. I am confused...\n\nReferences: (1)Algorithm, Dasgupta, Papadimitriou, Vazirani Exercise 8.1 http://algorithmics.lsi.upc.edu/docs/Dasgupta-Papadimitriou-Vazirani.pdf https://cseweb.ucsd.edu/classes/sp08/cse101/hw/hw6soln.pdf\n\nhttp://cs170.org/assets/disc/dis10-sol.pdf\n    ", "Answer": "\r\nI took a quick look at the references you gave, and I must admit there's one thing I really dislike in your textbook (1st pdf) : they address NP-completeness while barely mentioning decision problems. The provided definition of an NP-complete problem also somewhat deviates from what I'd expect from a textbook. I assume that was a conscious decision to make the introduction more appealing...\n\nI'll provide a short answer, followed by a more detailed explanation about related notions.\n\n\n\nShort version\n\nIntuitively (and informally), a problem is in NP if it is easy to verify its solutions.\n\nOn the other hand, a problem is NP-hard if it is difficult to solve, or find a solution.\n\nNow, a problem is NP-complete if it is both in NP, and NP-hard. Therefore you have two key, intuitive properties to NP-completeness. Easy to verify, but hard to find solutions.\n\nAlthough they may seem similar, verifying and finding solutions are two different things. When you use reduction arguments, you're looking at whether you can find a solution. In that regard, both TSP and TSP-OPT are NP-hard, and it is difficult to find their solutions. In fact, the third pdf provides a solution to excercise 8.1 of your textbook, which directly shows that TSP and TSP-OPT are equivalently hard to solve.\n\nNow, one major distinction between TSP and TSP-OPT is that the former is (what your textbook call) a search problem, whereas the latter is an optimization problem. The notion of verifying the solution of a search problem makes sense, and in the case of TSP, it is easy to do, therefore it is NP-complete. For optimization problems, the notion of verifying a solution becomes weird, because I can't think of any way to do that without first computing the size of an optimal solution, which is roughly equivalent to solving the problem itself. Since we do not know an efficient way to verify a solution for TSP-OPT, we cannot say that it is in NP, thus we cannot say that it is NP-complete. (More on this topic in the detailed explanation.)\n\n\n\nThe tl;dr is that for TSP-OPT, it is both hard to verify and hard to find solutions, while for TSP it is easy to verify and hard to find solutions.\nReductions arguments only help when it comes to finding solutions, so you need other arguments to distinguish them when it comes to verifying solutions.\n\n\n\nMore details\n\nOne thing your textbook is very brief about is what a decision problem is.\nFormally, the notion of NP-completeness, NP-hardness, NP, P, etc, were developed in the context of decision problems, and not optimization or search problems.\n\nHere's a quick example of the differences between these different types of problems.\n\nA decision problem is a problem whose answer is either YES or NO.\n\n\n  TSP decision problem\n  \n  Input: a graph G, a budget b\n  \n  Output: Does G admit a tour of weight at most b ? (YES/NO)\n\n\nHere is the search version\n\n\n  TSP search problem\n  \n  Input: a graph G, a budget b\n  \n  Output: Find a tour of G of weight at most b, if it exists.\n\n\nAnd now the optimization version\n\n\n  TSP optimization problem\n  \n  Input: a graph G\n  \n  Output: Find a tour of G with minimum weight.\n\n\nOut of context, the TSP problem could refer to any of these. What I personally refer to as the TSP is the decision version. Here your textbook use TSP for the search version, and TSP-OPT for the optimization version.\n\nThe problem here is that those various problems are strictly distinct. The decision version only ask for existence, while the search version asks for more, it needs one example of such a solution. In practice, we often want to have the actual solution, so more practical approaches may omit to mention decision problems.\n\nNow what about it? The definition of an NP-complete problem was meant for decision problems, so it technically does not apply directly to search or optimization problems. But because the theory behind it is well defined and useful, it is handy to still apply the term NP-complete/NP-hard to search/optimization problem, so that you have an idea of how hard these problems are to solve. So when someone says the travelling salesman problem is NP-complete, formally it should be the decision problem version of the problem.\n\nObviously, many notions can be extended so that they also cover search problems, and that is how it is presented in your textbook. The differences between decision, search, and optimization, are precisely what the exercises 8.1 and 8.2 try to cover in your textbook. Those exercises are probably meant to get you interested in the relationship between these different types of problems, and how they relate to one another.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Polynomial time reduction from NP Complete to other problems\r\n                \r\nCan any one clear my doubt please?\n\nsuppose I have a problem A which is known to be in NP-complete. and I have a another problem B for which we don't know the complexity class.\n\nif I reduce A to B in polynomial time . we can say B also is in NP-Complete.\n\nbut..\nif I reduce B to A in polynomial time . why can't I say B also in NP-Complete?\n    ", "Answer": "\r\n\n  if I reduce A to B in polynomial time . we can say B also is in NP-Complete.\n\n\nNo, we can say that B is NP-hard. Completeness requires membership in NP as well, which does not follow from the assumptions.\n\nFor example, we can reduce 3SAT to the Halting Problem. The Halting Problem is not in NP (it's not even decidable).\n\n\n  if I reduce B to A in polynomial time . why can't I say B also in NP-Complete?\n\n\nWe can say that B is in NP. One algorithm for B is to use the reduction and then solve A. B might be an easy problem like \"length of the input is odd\".\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Which of these languages is NP-complete?\r\n                \r\nI was searching the difference between NP and NP-complete problems. I came upon this great answer in  StackOverflow by Jason. About NP-complete problems, he said\n\n\n  An NP problem X for which it is possible to reduce any other NP problem Y to X in polynomial time. Intuitively this means that we can solve Y quickly if we know how to solve X quickly. Precisely, Y is reducible to X if there is a polynomial time algorithm f to transform instances x of X to instances y = f(x) of Y in polynomial time with the property that the answer to x is yes if and only if the answer to f(x) is yes.\n\n\nMy question is: which one is the NP-complete problem, X or Y?\n    ", "Answer": "\r\nThe NP-complete language is X.  The idea is that you can start with an arbitrary NP language Y and, in polynomial time, reduce it to X.\n\nFormally, the definition of NP-completeness is as follows: A language X is called NP-complete iff\n\n\nX &in; NP.  That is, X can't be \"harder\" than the \"hardest NP problem,\" since X is itself a member of NP.\nFor any Y &in; NP, there is a polynomial-time mapping reduction from Y to X.  That is, X is \"at least as hard\" as any problem in NP, since a polynomial-time algorithm for X gives a polynomial-time algorithm for Y.  The fact that Y is polynomial-time reducible to X is sometimes denoted Y ≤p X, by the way.\n\n\nThat said, it is possible to reduce any NP-complete language to any other NP-complete language, so if Y polynomial-time reduces to X and X is NP-complete, it is possible (but not necessary) for Y to be NP-complete.  However, it is known that if Y reduces in polynomial time to X, that Y has to be an element of NP.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Definition of NP Complete\r\n                \r\nI'm trying to understand the formal definition of NP Complete and had some questions. I was wondering if someone can provide more insight.\n\nThe Jon Kleinberg algorithms book says that if every NP problem can be reduced to a problem X, then problem X is in the set NP Complete.\n\nNow since P is a subset of NP, it follows that we can reduce any problem in P to an NP Complete problem in polynomial time. This leads to a contradiction that since the reduction is in polynomial time, we can solve this NP Complete problem in polynomial time. This cannot be true. So I'm not sure where this reasoning is wrong.\n\nAlso if we are able to reduce any NP problem in polynomial time to NP Complete, then why do we say that NP Complete is harder. Since the reduction is in polynomial time, asymptotically speaking, it should not make a difference. \n    ", "Answer": "\r\n\n  Now since P is a subset of NP, it follows that we can reduce any\n  problem in P to an NP Complete problem in polynomial time. This leads\n  to a contradiction that since the reduction is in polynomial time, we\n  can solve this NP Complete problem in polynomial time.\n\n\nYou get the direction of the reduction wrong.  If you can reduce any NP-complete problem to a given P problem, then P = NP, because that means this P problem is harder than or equivalent to any NP-Complete problem. The fact that a P problem can be reduced to NP problems doesn't show that it is harder than NP -- it shows that it's easier than NP, which is not surprising or contradictory. \n\nPretend that we can reduce shortest path to 1 run of TSP, and pretend that TSP can only be solved by by enumeration (exponential complexity). Then, shortest path is polynomial, the reduction is polynomial (O(1)), but the TSP is not polynomial. This is a hypothetical example. But hopefully, it shows that the fact TSP can solve SP in one run doesn't mean TSP is easy by any measure. The complexity of TSP is not constrained by the fact that it can easily solve SP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "what is the class of the combination of two problems which one of them is NP-Complete problem?\r\n                \r\nI have an optimization problem with a minimization cost function and two constraints to meet. Without considering one of the constraints, I can reduce the optimization problem to an NP-Complete problem. But with both constraints, I don't have any idea to reduce the problem to a known NP-Complete or NP-hard problem.\nSuppose in a graph, I want to select the minimum number of nodes that address two different conditions. These conditions are independent. For example one of them is addressing the minimum dominating set problem and another is ensuring that nodes with some structural features are selected. So, I should find the minimum number of nodes that both dominant all nodes of the network, and also ensure nodes with specific structural features are selected. Without the second constraint, I can prove that the optimization model is an NP-hard problem. But with both of them, I can't find any known problem to reduce.\nTherefore, I want to know that, is it possible to say that as the optimization problem with one of the constraints is NP-hard or NP-Complete, so with both constraints has also the same complexity class?\n    ", "Answer": "\r\nIf you are asking if this is true in general, the answer is no.\nExample 1: Satisfiability problem (3-SAT) is NP-Complete. Add a constraint that the clauses have atmost one positive literal (Horn clause), we get Horn-satisfiability (HORN-SAT) problem which is solvable in polynomial time. Here, adding a constraint made the problem less complex and easier to solve.\nExample 2: Minimum Spanning Tree (MSP) is of complexity O(E log(V)). If we add the constraints that there can be no branches in the tree, we get the Traveling Salesman Problem (TSP) which is NP-Complete. Here, adding a constraint made the problem more complex and difficult to solve.\nSo, adding a constraint can either increase or decrease complexity. Therefore, the answer to your question is - No.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Does solving a NP-hard problem in polynomial time make it NP-complete?\r\n                \r\nI am trying to understand the process so that P = NP. Consider a problem L which is reducible to a problem that is NP-Complete, meaning L is NP-hard. Now, if we solve L in polynomial time, will it be NP-complete? Making P = NP to be true. Am I missing something?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "example of reduction a polynomial decision to an NP-complete\r\n                \r\nI know if I reduce an NP-complete problem to a unknown problem P then I'm sure that P is itself NP-complete. And I know if I reduce a Problem P to an NP-complete problem there is no conclusion. So I want to give an example to show that we can reduce a Polynomial solvable problem P to an NP-complete one.\n    ", "Answer": "\r\n\n  If I reduce an NP-complete problem to a unknown problem P then I'm\n  sure that P is itself NP-complete\n\n\nNo, this is not well formulated. If an NP-complete problem A is reducible to a problem P all we can say is that any problem in NP is reducible to P. To say that P is NP-complete we need to know additionally that P is itself in NP.\n\nWhat you probably intended to say was\n\n\n  If I reduce an NP-complete problem to some a unknown  problem P in NP then I'm\n  sure that P is itself NP-complete\n\n\nNow to your original question. \n\n\n  give an example to show that we can reduce a Polynomial solvable\n  problem P to an NP-complete one\n\n\nConsider the problem known as 2-SAT: Given a boolean formula in conjunctive normal form such that each disjunction contains at most two variables tell it if is satisfiable.\n\nSolving this problem following an algorithm by Aspvall, Plass & Tarjan (1979) involves building an implication graph and finding all its strongly connected components. The paper proves that the formula is satisfiable if and only if the implication graph does not contain a strongly connected component that include some variable together with its negation. It also shows that this algorithm is linear in the size of the formula encoding.\n\nSo \n\n\nthere exists a linear algorithm for 2-SAT.\n2-SAT is reducible to unrestricted boolean satisfiability problem known as SAT.\n\n\nThis gives an example of a polynomially solvable problem (2-SAT) that is reducible to an NP-complete problem (SAT).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If a problem X (decision problem) is known to be NP-Complete, and proven to be reduced to problem Y, can you then say problem Y is NP-Complete?\r\n                \r\nIf a problem X (decision problem) is known to be NP-Complete, and proven to be reduced to problem Y in polynomialtime, can you then say problem Y is NP-Complete?\n\nMy first thought was, no, problem Y needs to be shown that it is in NP. But after further thought, if X is reduced to Y, Y is already considered to be NP-Complete. Now I'm just confused...any help would be appreciated.\n    ", "Answer": "\r\nArgumentum per contrarium:\n\nIf X ∈ NP and X ⇔ Y and Y ∉ NP then X ∉ NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "how is sudoku np-complete?\r\n                \r\nhow is Sudoku an np-complete problem? according to wiki, to be classed as an np-complete problem it must satisfy 2 conditions\n\n\nproblem must be in np\nevery other problem in np must be reducible to given problem in polynomial time\n\n\nhow is the second condition satisfied? can you give an example? for instance, I don't see any correlation between Sudoku problem and the travelling salesman problem or knapsack problem\n\n(kindly forgive poor formatting as I'm typing this question on my mobile device)\n    ", "Answer": "\r\nNP-completeness of SUDOKU notes in part:\n\n\n  This result was first shown in this master’s thesis by reduction from\n  the NP-complete problem LATIN SQUARE COMPLETION. Sudoku wikipedia\n  page. \n  \n  Here is how it works (simplified, without reference to\n  ASP-completeness, which I don’t cover in this course).\n  \n  Suppose we have a n×n instance of LATIN SQUARE COMPLETION. We\n  construct a n2×n2 instance of SUDOKU, that encodes the instance of\n  LATIN SQUARE COMPLETION. Moreover, the encoding is very direct.\n\n\nhttp://www-imai.is.s.u-tokyo.ac.jp/~yato/data2/MasterThesis.pdf being a link to the thesis in PDF.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Cook's theorem and NP complete reductions\r\n                \r\nBased on Cook's theorem, \n\n\n  Any NP problem can be converted to SAT in polynomial time\n\n\nI know that SAT is a NP-complete problem. Therefore, is it accurate to say:\nIf we can reduce a search problem A (which is in NP) to problem B in a polynomial number of steps, then problem B must be NP-complete? \n    ", "Answer": "\r\nYou are on the right track, but there is a little bit more that must be done to show that problem A is in fact NP hard. If you have already proven that problem A is in NP (reword as a decision problem, describe a yes certificate, and show that it can be verified in polynomial time), then what you must do is show that if you were to hypothetically find an algorithm that solves problem A in polynomial time, then that algorithm could be used to solve any SAT problem in polynomial time as well. \n\nThis shows that your problem requires you to solve SAT (as well as other possible inputs for problem A) in polynomial time, and since SAT has yet to be solved in polynomial time, you can explain to whoever is asking you to solve the problem that this is an unreasonable request. To show this, find a way to convert SAT into input for your problem A (think how to transform the edges and vertices into the input of problem A). \n\nNow, show that this transformation from SAT to problem A is done in polynomial time, and then show that the answer from problem A can be transformed back into an answer for SAT (again, in polynomial time). Lastly, make sure to explain that an answer to problem A is equivalent to an answer to SAT (the answer to SAT is correct IFF the answer to problem A is correct).\n\nFor all of these steps, treat the hypothetical algorithm for problem A as a black box that magically solves the problem in polynomial time. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is there any well-known NP-complete problem that I can reduce a 'node placement' problem to?\r\n                \r\nI have the following NP-complete problem:\n\nGiven:\n\n\na set of locations in a N × N field,\na set of m nodes, and \na connectivity graph of the nodes (i.e. an undirected graph whose edges represent every pair of nodes in contact with each other), and\ncontact range R (in the same length unit as the N × N field),\n\n\nfind a placement of the nodes in the field respecting the connectivity graph (i.e. place nodes such that any pair in contact is nearer than R and any pair not in contact is farther than R), or show that such placement does not exist.\n\nIs the a well-known NP-complete problem that this problem can be reduced to?\n\n(Also an optimization version of the problem can be considered, i.e. to find the most optimal placement)\n    ", "Answer": "\r\nSet cover sounds alot like this problem. In fact, it may be almost precisely this problem. Even better: it has an approximation algorithm guaranteed to be within O(log n) of the optimal solution.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What is a \"Natural\" NP-Complete prob?\r\n                \r\nI think I have a pretty decent understanding of NP-Complete, NP-Hard, etc. in general, but all of a sudden, stumbling upon some literature, I found someone saying a \"natural\" NP-complete problem -- explicitly with those quotes. I didn't understand what they meant, so I tried to google it -- it popped up several more times, but no one ever bothered explaining what they meant by \"natural\".\n\nCan someone explain to me what the context is for putting quotes around \"natural\" -- what does one mean when they say a \"natural\" NP-complete problem?\n    ", "Answer": "\r\nIn the context of CS theory, you often see someone prove that there are problems with certain properties by defining highly contrived problems that no one would likely actually encounter in practice. For example, Ladner's theorem shows that if P ≠ NP, then there is a problem in NP that isn't in P but also isn't NP-complete, but the specific problem devised is highly contrived and, essentially, was constructed for the sole purpose of having the indicated property. These problems, subjectively, are referred to as \"unnatural\" problems because the problem was invented to have some property.\n\nA \"natural\" problem is a problem that, subjectively, is interesting in its own right - usually, something that's been studied before - that is later shown to have some interesting theoretical property. In that context, a \"natural\" NP-complete problem would be an NP-complete problem that actually arises in practice - say, something like 3-colorability, the Hamiltonian cycle problem, or boolean satisfiability.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP COMPLETE and NP HARD\r\n                \r\nI have to check out whether my logic is on the right path.\n\nNP-HARD: these are the hardest problems which may/may not be in NP class. If you have an efficient algorithm for these problems you have one for every problem in class NP.\n\nNP COMPLETE: these are the hardest problems in class NP and also if you solve one of these you could solve any problem in class NP. So, NP COMPLETE problem is an NP-HARD problem.\n\nCOOK'S THEOREM: If SAT(NP-HARD) has a polynomial time algorithm then so does every problem in class NP.\n\nNow, suppose we have to prove that CDP(clique decision problem) is NP COMPLETE.\n\n->Step 1: Prove that CDP is in the class NP.\n  It is in class NP because the prover can generate a proof for yes inputs which would enable the verifier to check that it is a CDP (has a clique of size k).\n\n->Step 2: Prove that CDP is NP HARD.\n For that, we can convert the SAT to CDP by constructing a graph from clauses and supplying k.\n We supply(G,k) to the clique subroutine which would verify is there a clique of size k or not. If it can figure this out in polynomial time then SAT has a polynomial time algorithm as CDP had a polynomial time algorithm and we converted SAT to CDP. So, now we proved that if there is a polynomial time algorithm for CDP then there is for the SAT. Now if we can find a polynomial time algorithm for CDP then it would imply that there is a polynomial time algorithm for SAT. This would imply that there is a polynomial time algorithm for every problem in  NP by COOK'S THEOREM.\n\nSo we proved that CDP is NP COMPLETE. Once we have added CDP to NP COMPLETE class and now we come up with a new problem which we have again to prove that it is NP COMPLETE we can prove that problem to be in NP and then we could prove that if there is an efficient algorithm for given problem then that implies that there is an efficient algorithm for SAT/CDP(as we have added this to NP COMPLETE). Then as said above we can convert this problem to CDP/SAT and then prove that if there is an efficient algorithm for our problem then there is one for CDP/SAT and then by COOK'S THEOREM again we have that if there is a solution to NP-HARD problem (in this case CDP/SAT) then there is one for every problem in NP. So we again proved our problem as NP-HARD and as now it also belongs to NP as said above it is NP COMPLETE.\n\nSo we can add as many problems to the NP COMPLETE class as long as we can convert some problem which is already in NP-HARD class(in this case SAT/CDP) into our problem and we should find an efficient algorithm to our problem  which would indirectly find an efficient algorithm to the NP-HARD problem and by COOK's theorem we can say that as some NP-HARD problem has an efficient algorithm we have an efficient algorithm to solve all problems in NP.\n    ", "Answer": "\r\nYou're on the right path, but there your logic is a little incomplete.\n\nThe general structure of your proof is correct: First prove a problem is in NP, then prove the problem is NP-Hard. Those two bits of information together prove that a problem is NP-Complete. \n\nYour proof for proving a problem is in NP is incomplete. Here are the key components to proving a problem is in NP:\n\n\nReword the problem as a decision problem that can be answered with a yes or a no.\nDescribe what a \"certificate\" would be. NOTE: a certificate is an output that can be checked to verify the answer to the decision problem. For CDP it could be a list of vertices and edges that make up the clique of size k.\nProve that this certificate can be verified in polynomial time.\n\n\nYour proof for proving NP-Hard is incomplete. Here are the key components to proving a problem is NP-Hard:\n\n\nTransform the input of the known NP-Hard problem into the input for the problem you are trying to prove.\nProve that this transformation can be done in polynomial time.\nTransform the output of the problem your trying to prove into the output of the known NP-Hard problem.\nDemonstrate how this can be done in polynomial time.\nProve that if you get an answer for the problem you are trying to prove, then you have an answer for the known problem.\nProve that if you get an answer for the known problem you have an answer for the problem you are trying to prove.\n\n\nOnly by meeting those 6 criterion can you say you have completely proven that a problem is NP-Hard. \n\nBesides the specifics on that your logic is sound. Be careful when saying \"efficient\" if you really mean \"can be solved in polynomial time\".\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to prove this josephus problem variation is a np-complete problem?\r\n                \r\nI have a problem that is a Josephus problem variation. It is described below:\nThere are m cards with number from 1 to m，and each of them has a unique number. The cards are dispatched to n person who sit in a circle. Note that m >= n.\nThen we choose the person \"A\" who sits at the position \"p\" to out of the circle, just like the Josephus problem does. Next step we skip \"k\" person at the right of p while k is the number of the card toked by the person \"A\", and we do the same thing until only one person left in the circle.\nQuestion is given n person and m cards, can we choose n cards and allocate them to the n person, to make that whether start at which position(exclude the first position), the person survival at the end is always the first person in the circle.\nFor example, m = n = 5, the only solution is (4, 1, 5, 3, 2).\nI think this problem is a np-complete problem, but I can't prove it. Anybody has a good idea to find a polynomial time solution or prove it's np-hard?\n--- example solutions ---\n```\n 2: [ 1,  2]\n 2: [ 2,  1]\n 3: [ 1,  3,  2]\n 3: [ 3,  1,  2]\n 4: [ 4,  1,  3,  2]\n 5: [ 4,  1,  5,  3,  2]\n 7: [ 5,  7,  3,  1,  6,  4,  2]\n 9: [ 2,  7,  3,  9,  1,  6,  8,  5,  4]\n 9: [ 3,  1,  2,  7,  6,  5,  9,  4,  8]\n 9: [ 3,  5,  1,  8,  9,  6,  7,  4,  2]\n 9: [ 3,  9,  2,  7,  6,  1,  5,  4,  8]\n 9: [ 6,  1,  8,  3,  7,  9,  4,  5,  2]\n10: [ 3,  5,  6, 10,  1,  9,  8,  7,  4,  2]\n10: [ 4,  5,  2,  8,  7, 10,  6,  1,  9,  3]\n10: [ 5,  1,  9,  2, 10,  3,  7,  6,  8,  4]\n10: [ 6,  3,  1, 10,  9,  8,  7,  4,  5,  2]\n10: [ 8,  5,  9, 10,  1,  7,  2,  6,  4,  3]\n10: [10,  5,  2,  1,  8,  7,  6,  9,  3,  4]\n11: [ 2,  1, 10, 11,  9,  3,  7,  5,  6,  8,  4]\n11: [ 3,  7, 11, 10,  9,  8,  1,  6,  5,  4,  2]\n11: [ 3, 11, 10,  9,  8,  1,  7,  2,  4,  5,  6]\n11: [ 4,  1, 10,  2,  9,  8,  7,  5, 11,  3,  6]\n11: [ 4,  2,  7, 11,  5,  1, 10,  9,  6,  3,  8]\n11: [ 4,  7,  2,  3,  1, 10,  9,  6, 11,  5,  8]\n11: [ 4,  7,  3,  9, 11, 10,  1,  8,  6,  5,  2]\n11: [ 4, 11,  7,  2,  1, 10,  9,  6,  5,  3,  8]\n11: [ 5, 11,  3,  9,  8,  7,  6,  1, 10,  4,  2]\n11: [ 6,  1, 10,  2,  9,  8,  7,  5, 11,  3,  4]\n11: [ 6,  2,  7, 11,  5,  1, 10,  9,  4,  3,  8]\n11: [ 6, 11,  1,  3, 10,  2,  7,  5,  4,  9,  8]\n11: [ 9,  5,  3,  1, 10,  2,  8,  7, 11,  6,  4]\n12: [ 1,  7, 11, 10,  4,  9,  2, 12,  6,  5,  8,  3]\n12: [ 3,  7, 12,  2, 11, 10,  9,  1,  6,  5,  4,  8]\n12: [ 3,  8, 11,  2, 12,  9,  1,  7,  5, 10,  4,  6]\n12: [ 4,  2,  5,  1, 11, 10,  9,  8, 12,  7,  3,  6]\n12: [ 4,  3,  7,  6,  1, 11, 10,  9,  8, 12,  5,  2]\n12: [ 5,  1,  6, 11,  9,  2, 10,  7, 12,  8,  3,  4]\n12: [ 5,  2,  3, 12,  9, 10,  7,  6,  1, 11,  4,  8]\n12: [ 5,  7, 12,  2, 10,  9,  8, 11,  1,  4,  6,  3]\n12: [ 7,  1,  2,  3,  5,  9, 10,  8, 11,  6, 12,  4]\n12: [ 8,  7,  1, 11,  9,  3,  5, 10,  6,  4, 12,  2]\n12: [ 8,  7, 11, 10, 12,  3,  1,  9,  6,  5,  4,  2]\n12: [12,  3, 11,  5,  1, 10,  8,  7,  6,  4,  9,  2]\n12: [12,  7, 11,  1,  9,  3,  2, 10,  6,  5,  4,  8]\n13: [ 2,  1,  4,  7, 11,  6,  3, 10, 13,  5,  8, 12,  9]\n13: [ 2,  5, 13, 12,  4, 11,  3,  1,  9,  7,  8,  6, 10]\n13: [ 2, 13, 12, 11,  3,  1,  9,  4,  8,  7, 10,  5,  6]\n13: [ 3,  5,  2,  1, 12,  9, 11, 10,  7,  6, 13,  4,  8]\n13: [ 3,  5, 13,  1, 11,  2,  9,  8,  7, 12,  6,  4, 10]\n13: [ 4, 13,  3,  1, 12, 11, 10,  9,  7,  2,  5,  6,  8]\n13: [ 6,  4,  3,  1, 10, 11, 13,  5,  9, 12,  7,  8,  2]\n13: [ 6,  4, 13,  7,  5,  1, 12, 11, 10,  9,  8,  3,  2]\n13: [ 6,  7,  3, 13, 12, 11, 10,  2,  1,  9,  5,  4,  8]\n13: [ 6,  7, 13, 11,  2, 10,  9,  1,  8, 12,  5,  3,  4]\n13: [ 6, 11,  7, 13,  1, 10,  2, 12,  9,  8,  5,  4,  3]\n13: [ 7,  3,  2,  1, 11, 10,  9,  8, 13,  5, 12,  4,  6]\n13: [ 7,  5, 13,  3, 10, 11,  2,  9,  1,  6,  8,  4, 12]\n13: [ 7,  5, 13,  3, 11,  2,  9,  8,  1,  6, 12,  4, 10]\n13: [ 7,  5, 13,  3, 11, 12,  2,  1,  9,  8,  6,  4, 10]\n13: [ 7,  9,  1, 11,  3, 13,  2, 10, 12,  6,  5,  4,  8]\n13: [ 8,  3,  5, 11, 13,  9, 10,  7,  1,  6,  4, 12,  2]\n13: [ 8,  3, 13,  1,  5, 11, 10,  9, 12,  7,  6,  4,  2]\n13: [ 9,  3, 13,  2, 10,  4,  1,  7,  6,  5, 12, 11,  8]\n13: [ 9,  4,  7,  5,  1, 11, 13, 10, 12,  8,  6,  3,  2]\n13: [ 9,  5,  4, 13,  2, 11,  8, 10,  1,  7, 12,  3,  6]\n13: [ 9,  5, 13,  4, 11,  1,  8,  3,  7, 12,  6, 10,  2]\n13: [10,  4,  3,  5, 13,  1,  9, 11,  7,  6,  8, 12,  2]\n13: [11,  2,  7,  3, 12,  1, 10,  9,  6,  5, 13,  4,  8]\n13: [11, 13,  5,  2, 10,  9,  8,  7,  1,  6,  4,  3, 12]\n13: [11, 13,  7,  1, 12,  9,  2,  3, 10,  5,  4,  6,  8]\n13: [12,  1,  3,  5, 11, 13,  4, 10,  9,  8,  7,  6,  2]\n13: [12,  7, 13,  3, 11,  1,  9,  8,  6,  5, 10,  4,  2]\n13: [12, 13,  7, 11,  2,  5,  1,  9, 10,  6,  4,  3,  8]\n13: [13,  3,  1, 12, 11,  2,  9, 10,  7,  6,  4,  5,  8]\n13: [13,  3,  7,  1,  5, 12,  4, 10,  9,  8, 11,  6,  2]\n14: [ 3,  5, 13, 14,  1, 12, 11, 10,  9,  8,  7,  6,  4,  2]\n14: [ 3,  9,  1, 13, 11, 10,  2,  4,  7, 14,  6,  8,  5, 12]\n14: [ 3, 14,  4, 12, 11,  1,  9,  8,  2, 13,  7,  5, 10,  6]\n14: [ 4, 11,  1, 13,  7, 10, 12,  2, 14,  9,  8,  5,  6,  3]\n14: [ 4, 14,  2,  5, 13,  1, 12, 11,  7,  6, 10,  9,  3,  8]\n14: [ 5,  7,  1, 13, 12, 11, 10,  2,  9,  8, 14,  6,  4,  3]\n14: [ 6,  3, 14,  5, 11, 13,  2, 12,  9,  1,  7,  4,  8, 10]\n14: [ 6, 14,  1, 12,  5, 13,  2, 11,  9,  7,  8,  4,  3, 10]\n14: [ 7,  5, 13, 12,  1, 11,  4, 10,  2, 14,  9,  8,  6,  3]\n14: [ 7, 11,  5, 13,  1,  3,  2,  4, 10,  9, 14,  6,  8, 12]\n14: [ 7, 14,  1, 13,  2,  5, 11, 12, 10,  9,  8,  4,  3,  6]\n14: [ 8,  7,  5, 13,  2, 11,  3,  9, 10, 12,  1, 14,  4,  6]\n14: [11,  2, 10,  5,  8,  7,  9,  1, 13, 14, 12,  4,  3,  6]\n14: [11,  3, 14,  2, 13,  1, 10,  8,  9,  7,  5, 12,  4,  6]\n14: [11,  5,  3, 14,  2,  1, 13, 10,  8,  7,  6, 12,  4,  9]\n14: [11, 14,  5,  3, 13,  1, 10,  2,  9,  4,  7,  8, 12,  6]\n14: [12,  1, 14,  3, 13,  4, 10,  9,  2,  7,  6,  5, 11,  8]\n14: [12, 11,  7,  5, 13,  3,  2, 14,  1,  9,  8,  4,  6, 10]\n14: [12, 14,  7, 13,  6,  5, 11,  1, 10,  9,  8,  4,  3,  2]\n14: [13,  1,  7,  2, 11,  3,  9, 14,  8,  6,  5, 10,  4, 12]\n14: [13, 11,  3,  1,  4,  2,  7, 10,  9,  6, 14, 12,  5,  8]\n14: [14,  1, 13,  3, 11,  5, 10,  9,  2,  6,  8,  7,  4, 12]\n14: [14, 5, 1, 13, 12, 2, 11, 3, 7, 9, 6, 8, 4, 10]\n```\n\n--- possibly helpful for a mathematical solution ---\nI noticed that starting with length 9, at least one solution for every length has a longish sequence of integers that decrement by 1.\n```\n 9: [3,  1,  2,                               7, 6, 5,    9, 4, 8]  \n10: [6,  3,  1,                     10, 9, 8, 7,          4, 5, 2] \n11: [3,  7,                     11, 10, 9, 8,             1, 6, 5, 4, 2]\n11: [3,                         11, 10, 9, 8,             1, 7, 2, 4, 5, 6]\n11: [5, 11,  3,                         9, 8, 7, 6,       1, 10, 4, 2]\n12: [4,  2,  5,  1,             11, 10, 9, 8,            12, 7, 3, 6] \n12: [4,  3,  7,  6, 1,          11, 10, 9, 8,            12, 5, 2] \n13: [6,  4, 13,  7, 5, 1,   12, 11, 10, 9, 8,             3, 2]\n14: [3,  5, 13, 14, 1,      12, 11, 10, 9, 8, 7, 6,       4, 2] \n```\n\n    ", "Answer": "\r\nI noticed that for every length I tested except the very small, at least one solution contains a relatively long run of descending\nnumbers. So far this answer only considers m = n. Here are a few examples; note that excess is n - run_len:\n```\nn = 3, run_len = 2, excess = 1: [1] + [3-2] + []\nn = 4, run_len = 2, excess = 2: [4, 1] + [3-2] + []\nn = 5, run_len = 2, excess = 3: [4, 1, 5] + [3-2] + []\nn = 6, no solution\nn = 7, run_len = 1, excess = 6: [5] + [7-7] + [3, 1, 6, 4, 2]\nn = 8, no solution\nn = 9, run_len = 3, excess = 6: [3, 1, 2] + [7-5] + [9, 4, 8]\nn = 10, run_len = 4, excess = 6: [6, 3, 1] + [10-7] + [4, 5, 2]\nn = 11, run_len = 4, excess = 7: [3, 7] + [11-8] + [1, 6, 5, 4, 2]\nn = 12, run_len = 4, excess = 8: [4, 2, 5, 1] + [11-8] + [12, 7, 3, 6]\nn = 13, run_len = 5, excess = 8: [6, 4, 13, 7, 5, 1] + [12-8] + [3, 2]\nn = 14, run_len = 7, excess = 7: [3, 5, 13, 14, 1] + [12-6] + [4, 2]\nn = 15, run_len = 8, excess = 7: [3, 15, 2] + [13-6] + [1, 5, 4, 14]\nn = 16, run_len = 6, excess = 10: [6, 3, 1, 10] + [16-11] + [2, 9, 7, 4, 5, 8]\nn = 17, run_len = 8, excess = 9: [2, 5, 17, 15, 14, 1] + [13-6] + [4, 3, 16]\nn = 18, run_len = 10, excess = 8: [6, 3, 17, 18, 1] + [16-7] + [5, 4, 2]\nn = 19, run_len = 10, excess = 9: [4, 19, 3, 17, 18, 1] + [16-7] + [5, 6, 2]\nn = 20, no solution found with run_length >= 10\nn = 21, run_len = 14, excess = 7: [3, 21, 2] + [19-6] + [1, 5, 4, 20]\nn = 22, run_len = 14, excess = 8: [22, 3, 2, 1] + [20-7] + [5, 21, 4, 6]\nn = 23, run_len = 14, excess = 9: [7, 1, 23, 3] + [21-8] + [6, 5, 22, 4, 2]\nn = 24, run_len = 16, excess = 8: [6, 5, 24, 2] + [22-7] + [3, 1, 23, 4]\nn = 25, run_len = 17, excess = 8: [25, 3, 2, 1] + [23-7] + [5, 24, 4, 6]\nn = 26, run_len = 17, excess = 9: [26, 3, 25, 2, 1] + [23-7] + [5, 24, 4, 6]\nn = 27, run_len = 20, excess = 7: [3, 27, 2] + [25-6] + [1, 5, 4, 26]\nn = 28, run_len = 18, excess = 10: [28, 1, 27, 2, 3] + [25-8] + [6, 5, 7, 4, 26]\nn = 29, run_len = 20, excess = 9: [2, 5, 29, 27, 26, 1] + [25-6] + [4, 3, 28]\nn = 30, run_len = 23, excess = 7: [30, 5, 2, 1] + [28-6] + [29, 3, 4]\nn = 31, run_len = 24, excess = 7: [5, 31, 3] + [29-6] + [1, 30, 4, 2]\nn = 32, run_len = 23, excess = 9: [7, 32, 31, 2, 1] + [30-8] + [5, 4, 3, 6]\nn = 33, run_len = 26, excess = 7: [3, 33, 2] + [31-6] + [1, 5, 4, 32]\nn = 34, run_len = 27, excess = 7: [3, 5, 33, 34, 1] + [32-6] + [4, 2]\nn = 35, run_len = 27, excess = 8: [5, 35, 3, 33, 34, 1] + [32-6] + [4, 2]\nn = 36, run_len = 26, excess = 10: [35, 7, 3, 1, 36, 2] + [34-9] + [6, 5, 4, 8]\nn = 37, run_len = 29, excess = 8: [6, 5, 2, 1] + [35-7] + [36, 37, 3, 4]\nn = 38, run_len = 29, excess = 9: [3, 7, 37, 38, 1] + [36-8] + [6, 4, 5, 2]\nn = 39, run_len = 32, excess = 7: [3, 39, 2] + [37-6] + [1, 5, 4, 38]\nn = 40, run_len = 31, excess = 9: [5, 2, 1] + [38-8] + [3, 7, 40, 4, 6, 39]\nn = 41, run_len = 33, excess = 8: [3, 5, 1, 40, 2] + [38-6] + [41, 39, 4]\nn = 42, run_len = 33, excess = 9: [42, 3, 41, 2, 1] + [39-7] + [5, 4, 40, 6]\nn = 43, run_len = 34, excess = 9: [6, 5, 7, 43, 1] + [41-8] + [42, 4, 3, 2]\nn = 44, run_len = 35, excess = 9: [5, 3, 2, 1] + [42-8] + [43, 7, 4, 44, 6]\nn = 45, run_len = 38, excess = 7: [3, 45, 2] + [43-6] + [1, 5, 4, 44]\nn = 50, run_len = 43, excess = 7: [50, 5, 2, 1] + [48-6] + [49, 3, 4]\nn = 100, run_len = 91, excess = 9: [5, 2, 1] + [98-8] + [3, 7, 100, 4, 6, 99]\nn = 201, run_len = 194, excess = 7: [3, 201, 2] + [199-6] + [1, 5, 4, 200]\n```\n\n20 is missing from the above table because the run length is at most 10, and is taking a long time to compute. No larger value that I've tested has such a small max run length relative to n.\nI found these by checking run lengths from n-1 descending, with all possible starting values and permutations of the run & surrounding elements. This reduces the search space immensely.\nFor a given n, if the max run in any solution to n is length n-k, then this will find it in O(k! * n). While this looks grim, if k has a constant upper bound (e.g. k <= some threshold for all sufficiently large n) then this is effectively O(n). 'Excess' is what I'm calling k in the examples above. I haven't found any greater than 10, but I don't have a solution yet to n = 20. If it has a solution then its excess will exceed 10.\nUPDATE: There are a lot of patterns here.\nIf n mod 6 is 3 and n >= 9, then [3, n, 2, [n-2, n-3, ..., 6], 1, 5, 4, n-1] is valid.\nIf n mod 12 is 5 and n >= 17 then [2, 5, n, n-2, n-3, 1, [n-4, n-5, ..., 6], 4, 3, n-1] is valid.\nIf n mod 20 is 10, then [n, 5, 2, 1, [n-2, n-3, ..., 6], n-1, 3, 4] is valid.\nIf n mod 60 is 7, 11, 31, or 47, then [5, n, 3, [n-2, n-3, ..., 6], 1, n-1, 4, 2] is valid.\nIf n mod 60 is 6 or 18 and n >= 18 then [6, 3, n-1, n, 1, [n-2, n-3, ..., 7], 5, 4, 2] is valid.\nIf n mod 60 is 1, 22, 25 or 52 and n >= 22 then [n, 3, 2, 1], [n-2, n-3, ..., 7], 5, n-1, 4, 6] is valid.\nIf n mod 60 is 23 then [7, 1, n, 3, [n-2, n-3, ..., 8], 6, 5, n-1, 4, 2] is valid.\nIf n mod 60 is 14 or 34 then [3, 5, n-1, n, 1, [n-2, n-3, ..., 6], 4, 2] is valid.\nIf n mod 60 is 24 then [6, 5, n, 2, [n-2, n-1, ..., 7], 3, 1, n-1, 4] is valid\nIf n mod 60 is 2, 6, 26, 42 and n >= 26 then [n, 3, n-1, 2, 1, [n-3, n-4, ..., 7], 5, n-2, 4, 6] is valid.\nIf n mod 60 is 16 or 28 then [n, 1, n-1, 2, 3, [n-3, n-4, ..., 8], 6, 5, 7, 4, n-2] is valid.\nIf n mod 60 is 32 then [7, n, n-1, 2, 1, [n-2, n-3, ..., 8], 5, 4, 3, 6] is valid.\nIf n mod 60 is 35 or 47 then [5, n, 3, n-2, n-1, 1, [n-3, n-4, ..., 6], 4, 2] is valid.\nIf n mod 60 is 37 then [6, 5, 2, 1, [n-2, n-1, ..., 7], n-1, n, 3, 4]\nIf n mod 60 is 38 then [3, 7, n-1, n, 1] + [n-2, n-3, ..., 8] + [6, 4, 5, 2]\nIf n mod 60 is 40 then [5, 2, 1, [n-2, n-3, ..., 8], 3, 7, n, 4, 6, n-1] is valid\nIf n mod 60 is 0 and n >= 60 then [3, 5, n, 2, [n-2, n-3, ..., 7], 1, 6, n-1, 4] is valid\nIf n mod 60 is 7, 19, or 31 and n >= 19 then [4, n, 3, n-2, n-1, 1, [n-3, n-4, ..., 7], 5, 6, 2] is valid\nIf n mod 60 is 23, 38, or 43 then [7, 3, n, 1, [n-2, n-3, ..., 8], 6, 5, n-1, 4, 2] is a valid solution\nIf n mod 60 is 14 or 44 and n >= 74 then [3, 5, n-1, n, 1, [n-3, n-4, ..., 6], n-2, 4, 2] is valid.\nIf n mod 60 is 1 or 49 and n >= 49 then [3, 5, n, 1, [n-2, n-3, ..., 7], 2, n-1, 4, 6] is valid.\nIf n mod 60 is 6, 18, 30, 42, or 54 and n >= 18 then [n, 3, n-1, 2, 1, [n-3, n-4, ..., 7], 5, 4, n-2, 6] is valid.\nIf n mod 60 is 10, 18, 38 or 58 and n >= 18 then [n-1, 7, 5, n, 1, [n-2, n-3, ..., 8], 2, 6, 4, 3] is valid.\nCurrently solved for n mod 60 is any of the following values:\n```\n 0,  1,  2,  3,      5,  6,  7,      9, \n10, 11,         14, 15, 16, 17, 18, 19,\n    21, 22, 23, 24, 25, 26, 27, 28, 29, \n30, 31, 32, 33, 34, 35,     37, 38, 39, \n40, 41, 42, 43, 44, 45,     47,     49,\n50, 51, 52, 53, 54,         57, 58\n```\n\nAlso,\nIf n mod 42 is 31 then [n, 3, 2, 1, [n-2, n-3, ..., 8], n-1, 5, 4, 7, 6] is valid.\nIf n mod 420 is 36 or 396 then [n-1, 7, 3, 1, n, 2, [n-2, n-3, ..., 9], 6, 5, 4, 8] is valid.\n--- Example for n=21, using the first pattern listed above, and all starting indices.\n```\n1:  [21,  2, 18, 19, 16, 17, 14, 15, 12, 13, 10, 11,  8, 9, 6, 7, 5,  4, 20,  1]\n2:  [ 2, 18, 21, 16, 19, 14, 17, 12, 15, 10, 13,  8, 11, 6, 9, 5, 1,  4, 20,  7]\n3:  [19, 21, 18,  2, 16, 17, 14, 15, 12, 13, 10, 11,  8, 9, 6, 7, 5,  4, 20,  1]\n4:  [18, 21, 19, 17,  2, 15, 16, 13, 14, 11, 12,  9, 10, 7, 8, 1, 5,  4, 20,  6]\n5:  [17, 21, 19, 18, 16,  2, 14, 15, 12, 13, 10, 11,  8, 9, 6, 7, 5,  4, 20,  1]\n6:  [16, 21, 19, 18, 17, 15,  2, 13, 14, 11, 12,  9, 10, 7, 8, 1, 5,  4, 20,  6]\n7:  [15, 21, 19, 18, 17, 16, 14,  2, 12, 13, 10, 11,  8, 9, 6, 7, 5,  4, 20,  1]\n8:  [14, 21, 19, 18, 17, 16, 15, 13,  2, 11, 12,  9, 10, 7, 8, 1, 5,  4, 20,  6]\n9:  [13, 21, 19, 18, 17, 16, 15, 14, 12,  2, 10, 11,  8, 9, 6, 7, 5,  4, 20,  1]\n10: [12, 21, 19, 18, 17, 16, 15, 14, 13, 11,  2,  9, 10, 7, 8, 1, 5,  4, 20,  6]\n11: [11, 21, 19, 18, 17, 16, 15, 14, 13, 12, 10,  2,  8, 9, 6, 7, 5,  4, 20,  1]\n12: [10, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11,  9,  2, 7, 8, 1, 5,  4, 20,  6]\n13: [ 9, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  8, 2, 6, 7, 5,  4, 20,  1]\n14: [ 8, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9, 7, 2, 1, 5,  4, 20,  6]\n15: [ 7, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9, 8, 6, 2, 5,  4, 20,  1]\n16: [ 6, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9, 8, 7, 1, 5,  4, 20,  2]\n17: [ 1,  5,  2, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9, 8, 7, 6, 4, 19, 20, 21]\n18: [ 5,  2, 18, 19, 16, 17, 14, 15, 12, 13, 10, 11,  8, 9, 6, 7, 4,  1, 20, 21]\n19: [ 4,  2, 18, 19, 16, 17, 14, 15, 12, 13, 10, 11,  8, 9, 6, 7, 5, 20, 21,  1]\n20: [20,  4, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9, 8, 7, 6, 1,  5, 21,  2]\n```\n\nYou can observe the same relationship between elements from the decrementing run and other elements for all values of n that the pattern applies to. This isn't a proof, but you can turn this into a proof, though I think the work would need to be done for each pattern separately and it's beyond the scope of what I'm going to spend time on for an S/O question.\n--- We can fill in the blanks by using m > n. ---\nThe pattern [n-1, n, 1, [n-2, n-3, ..., 3], n+5] is valid for n mod 4 is 1 and n >= 9.\nThe pattern [n, 2, 1, [n-2, n-3, ..., 3], n+4] is valid for n mod 2 is 0 and n >= 6.\nWith these two, plus what we already found, we get nearly everything. I found these by checking a single replacement value in a limited range.\n```\n 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, \n10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \n30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n50, 51, 52, 53, 54,     56, 57, 58\n```\n\nIf n mod 30 is 29, then [3, n, 2, [n-2, n-3, ..., 4], n-1, n+15) is valid, giving us n mod 60 is 59. We're left with just one unknown: n mod 60 is 55.\n...And finally! If n mod 12 is 7 (i.e. n mod 60 is 7, 19, 31, 43, or 55) then [n-1, n, 1, [n-2, n-3, ..., 6], 2, 5, 3, n+4] is valid for all n >= 19.\nWe now have solutions for all n mod 60, using m=n in most cases, and m=n+15 in the worst case.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is the resolution problem in OSGi NP-Complete?\r\n                \r\nThe resolution problem is described in the modularity chapter of the OSGi R4 core specification. It's a constraint satisfaction problem and certainly a challenging  problem to solve efficiently, i.e. not by brute force. The main complications are the uses constraint, which has non-local effects, and the freedom to drop optional imports to obtain a successful resolution.\n\nNP-Completeness is dealt with elsewhere on StackOverflow.\n\nThere has already been plenty of speculation about the answer to this question, so please avoid speculation. Good answers will include a proof or, failing that, a compelling informal argument.\n\nThe answer to this question will be valuable to those projects building resolvers for OSGi, including the Eclipse Equinox and Apache Felix open source projects, as well as to the wider OSGi community.\n    ", "Answer": "\r\nYes.\n\nThe approach taken by the edos paper Pascal quoted can be made to work with OSGi. Below I’ll show how to reduce any 3-SAT instance to an OSGi bundle resolution problem. This site doesn’t seem to support mathematical notation, so I’ll use the kind of notation that’s familiar to programmers instead.\n\nHere’s a definition of the 3-SAT problem we’re trying to reduce:\n\nFirst define A to be a set of propositional atoms and their negations A = {a(1), … ,a(k),na(1), … ,na(k)}. In simpler language, each a(i) is a boolean and we define na(i)=!a(i)\n\nThen 3-SAT instances S have the form:  S = C(1) & … & C(n)\n\nwhere C(i) = L(i,1) | L(i,2) | L(i,3) and each L(i,j) is a member of A\n\nSolving a particular 3-SAT instance involves finding a set of values, true or false for each a(i) in A, such that S evaluates to true.\n\nNow let’s define the bundles we’ll be use to construct an equivalent resolution problem. In the following all bundle and package versions are 0 and import version ranges unrestricted except where specified. \n\n\nThe whole expression S will be represented by Bundle BS \nEach clause C(i) will be represented by a bundle BC(i) \nEach atom a(j) will be represented by a bundle BA(j) version 1 \nEach negated atom na(j) will be represented by a bundle BA(j) version 2\n\n\nNow for the constraints, starting with the atoms:\n\nBA(j) version 1\n-export package PA(j) version 1\n-for each clause C(i) containing atom a(j) export PM(i) and add PA(j) to PM(i)’s uses directive  \n\nBA(j) version 2\n-export package PA(j) version 2\n-for each clause C(i) containing negated atom na(j) export PM(i) and add PA(j) to PM(i)’s uses directive  \n\nBC(i)\n-export PC(i)\n-import PM(i) and add it to the uses directive of PC(i)\n-for each atom a(j) in clause C(i) optionally import PA(j) version [1,1] and add PA(j) to the uses directive of the PC(i) export\n-for each atom na(j) in clause C(i) optionally import PA(j) version [2,2] and add PA(j) to the uses directive of the PC(i) export  \n\nBS\n-no exports\n-for each clause C(i) import PC(i)\n-for each atom a(j) in A import PA(j) [1,2]  \n\nA few words of explanation:\n\nThe AND relationships between the clauses is implemented by having BS import from each BC(i) a package PC(i) that is only exported by this bundle.\n\nThe OR relationship works because BC(i) imports package PM(i) which is only exported by the bundles representing its members, so at least one of them must be present, and because it optionally imports some PA(j) version x from each bundle representing a member, a package unique to that bundle.\n\nThe NOT relationship between BA(j) version 1 and BA(j) version 2 is enforced by uses constraints. BS imports each package PA(j) without version constraints, so it must import either PA(j) version 1 or PA(j) version 2 for each j. Also, the uses constraints ensure that any PA(j) imported by a clause bundle BC(i) acts as an implied constraint on the class space of BS, so BS cannot be resolved if both versions of PA(j) appear in its implied constraints. So only one version of BA(j) can be in the solution.\n\nIncidentally, there is a much easier way to implement the NOT relationship - just add the singleton:=true directive to each BA(j). I haven’t done it this way because the singleton directive is rarely used, so this seems like cheating. I’m only mentioning it because in practice, no OSGi framework I know of implements uses based package constraints properly in the face of optional imports, so if you were to actually create bundles using this method then testing them could be a frustrating experience.\n\nOther remarks:\n\nA reduction of 3-SAT that doesn't use optional imports in also possible, although this is longer. It basically involves an extra layer of bundles to simulate the optionality using versions. A reduction of 1-in-3 SAT is equivalent to a reduction to 3-SAT and looks simpler, although I haven't stepped through it.\n\nApart from proofs that use singleton:=true, all of the proofs I know about depend on the transitivity of uses constraints. Note that both singleton:=true and transitive uses are non-local constraints.\n\nThe proof above actually shows that the OSGi resolution problem is NP-Complete or worse. To demonstrate that it’s not worse we need to show that any solution to the problem can be verified in polynomial time. Most of the things that need to be checked are local, e.g. looking at each non-optional import and checking that it is wired to a compatible export. Verifying these is O(num-local-constraints). Constraints based on singleton:=true need to look at all singleton bundles and check that no two have the same bundle symbolic name. The number of checks is less than num-bundlesnum-bundles. The most complicated part is checking that the uses constraints are satisfied. For each bundle this involves walking the uses graph to gather all of the constraints and then checking that none of these conflict with the bundle’s imports. Any reasonable walking algorithm would turn back whenever it encountered a wire or uses relationship it had seen before, so the maximum number of steps in the walk is (num-wires-in-framework + num-uses-in framework). The maximum cost of checking that a wire or uses relationship hasn't been walked before is less than the log of this. Once the constrained packages have been gathered the cost of the consistency check for each bundle is less than num-imports-in-bundlenum-exports-in-framework. Everything here is a polynomial or better.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why we cant have FPTAS for Strong NP complete problems [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI understood that we can apply FPTAS to the weak NP problems like 0-1 knapsack.\n\nBut why we cant apply the same principal to the strong NP problems like bin packing.I also checked wiki page about the same but understood very less.\n    ", "Answer": "\r\nIf a stongly NP complete problem had an FPTAS, you could \"trick\" the approximation algorithm into giving an optimal solution.  Details are here: http://www.idi.ntnu.no/~mlh/algkon/complexity.pdf\n\nThe existence of this FPTAS would give a polynomial time algorithm for NP-complete problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-complete or NP-hard?\r\n                \r\nGiven a list of n positive integers (n even), divide the list into two sublists such that the difference between  the sums of the integers in the two sublists is minimized. Would this be a NP-complete problem or a NP-hard problem?\n    ", "Answer": "\r\nTL;DR - it's np hard.\n\nthis is the optimization version of the partition problem.\nthe partition problem is deciding if a given list of positive integers can be divided into 2 subsets so that the sums of the subsets are equal.\nthe optimization version asks for the minimized difference (like you asked).\n\nthe partition problem is np-complete but the optimization is np hard.\n\nyou can read more on these problems in wiki:\nhttps://en.wikipedia.org/wiki/Partition_problem\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What would a P=NP proof be like, hypothetically?\r\n                \r\nWould it be an polynomial time algorithm to a specific NP-complete problem, or just abstract reasonings that demonstrate solutions to NP-complete problems exist?\n\nIt seems that the a specific algoithm is much more helpful. With it, all we'll have to do   to polynomially solve an NP problem is to convert it into the specific NP-complete problem for which the proof has a solution, and we are done.\n    ", "Answer": "\r\nP = NP: \"The 3SAT problem is a classic NP complete problem. In this proof, we demonstrate an algorithm to solve it that has an asymptotic bound of (n^99 log log n). First we ...\"\n\nP != NP: \"Assume there was a polynomial algorithm for the 3SAT problem. This would imply that .... which by ..... implies we can do .... and then ... and then ... which is impossible. This was all predicated on a polynomial time algorithm for 3SAT. Thus P != NP.\"\n\nUPDATE: Perhaps something like this paper (for P != NP).\n\nUPDATE 2: Here's a video of Michael Sipser sketching out a proof for P != NP\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "When asked if two graphs are the same, is the problem P, NP, NP-hard, NP-complete? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs details or clarity. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Add details and clarify the problem by editing this post.\r\n                \r\n                    \r\n                        Closed 2 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI was given a question where two graphs are given and the questions asks if the two graphs are the same and whether the problem was a P, NP, NP-hard or NP-complete. By looking at the two graph, the graphs are not the same. However, I don't know what type of problem it is.\n    ", "Answer": "\r\nFirst of all, you have to define what you mean by \"the same\". There are several ways of defining equality, but the most likely one in this context is graph isomorphism, where two graphs are equal if there is an edge-preserving bijection between them.\nNext, if the problem is just to decide if your two given graphs are the same or not (and this is how you stated it), the problem is trivially in O(1) (and therefore in P and NP).\nIf, however, the problem is to decide whether any two graphs are isomorphic, the problem is in NP. It is currently neither known whether it is in P nor whether it is NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How does NP-Complete compare to NP-Hard?\r\n                \r\nSo from what I understand:\n\nNP are problems that can be easy to solve and verify (ie: multiplication)\n\nNP-Hard are problems that are hard to solve but easy to verify (factoring)\n\nWhat is NP-Complete? The answers I find online say it's almost like NP-hard but I'm having trouble distinguishing the two.\n\nRelated: NP-Complete VS NP-Hard\n    ", "Answer": "\r\nNP-complete problems are decision problems and belong to NP (and every problem in NP can be reduced in polynomial time to them, but these details I guess you already saw online).\n\nNP-hard are problems to which any problem in NP can be reduced, but not necessarily belong to NP or are decision problems.\n\nObviously, every NP-complete problem is also NP-hard (by definition of NP-hard). The opposite is not true, there are problems that are NP-hard but do not belong to NP. \n\nFor example, finding count of all solutions to a SAT instance (#SAT) is NP-hard but does not belong to NP-complete class, at least because it is not a decision problem and hence does not belong to NP. \n\nOn the other hand, SAT, the problem of deciding if count of satisfying solutions is greater than zero, belongs to NP and every problem in NP can be reduced to it, hence it is NP-complete.\n\nNote, every problem in NP can be reduced to (#SAT) (because SAT can be reduced to #SAT, just find a count and output true if it is non-zero). It is \"hard\" at least as SAT; this is the intuition behind the name NP-hard. \n\nI would also like to point to an excellent and detailed answer covering more details.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Have you ever had a business requirement that turned out to be an NP-Complete problem?\r\n                \r\nNP-completeness seems to me like one of those things that's mostly just theoretical and not really something you'd run into in a normal work environment.  \n\nSo I'm kind of curious if anyone's ever run into a problem at their job that turned out to be NP-complete, and that the design needed to be changed to accommodate for it?\n    ", "Answer": "\r\nAs the others have stated, the knapsack (for packing cargo) and traveling salesmen problem are probably the most common \"real world\" NP-complete problems.\n\nI tend to run into problems at work that can't be proven to be NP complete or incomplete because they're not very well defined.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Have you ever had a business requirement that turned out to be an NP-Complete problem?\r\n                \r\nNP-completeness seems to me like one of those things that's mostly just theoretical and not really something you'd run into in a normal work environment.  \n\nSo I'm kind of curious if anyone's ever run into a problem at their job that turned out to be NP-complete, and that the design needed to be changed to accommodate for it?\n    ", "Answer": "\r\nAs the others have stated, the knapsack (for packing cargo) and traveling salesmen problem are probably the most common \"real world\" NP-complete problems.\n\nI tend to run into problems at work that can't be proven to be NP complete or incomplete because they're not very well defined.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proving NP-Completeness of a problem\r\n                \r\nWe are given a set A = {a1,a2,...,an}\n\nGiven subsets of A named B1,B2, ..., Bm. If a subset of A named H has intersection with all given B's, we call H \"Covering subset\". Is there any \"covering subset\" of size K (cardinality of H is K) for given A and Bs?  Prove that this problem is NP-Complete. \n\nWe should reduce some known problem to \"covering subset\" problem.\n    ", "Answer": "\r\nupdate  This is called a hitting set. You can read the same answer in wikipedia article.  \n\nThis problem is, in a way, dual to set cover problem.  \n\nWe'll change some terminology. Let ```\n{B1, B2, ...}```\n be elements and ```\n{a1, a2, ...}```\n be sets. 'Set' ```\nai```\n contains 'element' ```\nBj```\n in a new problem if set ```\nBj```\n contains ```\nai```\n in original problem.  \n\nNow, you just need to select minimum number of 'sets' ```\nai```\n covering all 'elements' ```\nBj```\n. And that problem is NP-complete, as shown in the link above.\n\nTo clarify the transformation, one problem definition can be produced from another just by replacing set/element and contains/contained. Compare following  \n\nEvery set ```\nBj```\n contains some selected element ```\nai```\n\nEvery 'element' ```\nBj```\n is contained by some selected 'set' ```\nai```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If X is NP-complete and Y is in NP, why Y must also be NP-complete\r\n                \r\nSuppose X and Y are decision problems for which X≤ P ​ Y, i.e., X is polynomial-time reducible to Y . If X is NP-complete and Y is in NP, why Y must also be NP-complete.\n    ", "Answer": "\r\nIf X is NP complete, in particular it is NP hard, that is, every NP problem Z is polynomial-time reducible to X, which in turn is polynomial-time reducible to Y, thus Y is also NP hard. Being both NP and NP hard means you're NP complete, therefore Y is NP complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-complete vs NP-hard (why are they unequal?)\r\n                \r\nWhy is NP-hard unequal to NP-complete?\n\nMy informal understanding of definitions being used:\n\nNP - all problems that can be verified in polynomial time\n\nNP-complete - all problems that are NP and NP-hard\n\nNP-hard - at least as hard as the hardest problem in NP\n\nDecision Problem - A problem that asks a question with regards to an input and outputs a bool value\n\nConfusion:\n\nThe problem with unknown solution of P vs NP arises from the fact that we cannot prove or disprove all problems in NP can be solved in polynomial time. It feels like a similar question arises from NP-complete vs NP-hard. How do we know all problems in NP-hard cannot be verified in polynomial time and thus result in NP-hard=NP-complete?\n\nHere is my line of reasoning \n\nFrom online research the distinction seems that this has something to do with decision problems (a concept I'm entirely new to but seem simple enough). I think this means that problems in NP have complementary decision problems that ask if an input is the solution to the problem. Let's say the problem is to find an optimal solution. I believe the complementary decision problem to be \"is the given input the optimal solution?\"and I believe that if this decision problem is verifiable in polynomial time then the problem is NP-complete (or in NP). So this means that NP-hard problems that aren't NP-complete problems are those that either have no decision problem (which I believe is never true since any brute force solution can answer this) or a problem is NP-hard and not NP-complete if it has a decision problem that's not verifiable in polynomial time. If it is the latter then it feels like we have the same problem from P vs NP. That is, how do we confirm all decision problems in NP-hard do not have polynomial time solutions?\n\nSorry if the above phrasing is weird. I will try and clarify any confusion in my question.\n\nnotes\n\nI am interested in both an intuitive explanation and a formal explanation (a proof if it's a complicated answer). The formal explanation can certainly be a link to an academic paper. I don't want anyone to invest a significant amount of time into an overly complicated proof that may be beyond the scope of my understanding (I've found complexity theory to become very quickly... complex).\n\nIf it helps for the sake of explanation I have done work on the traveling salesman problem and I am currently working on a paper for the nurse scheduling problem (I believe these are NP-hard problems).\n    ", "Answer": "\r\nNP-Hard includes all problems whose solutions can be used to derive solutions to problems in NP with polynomial overhead.\n\nThis includes lots of problems that aren't in NP. For instance, the halting problem - an undecidable problem - is NP-Hard, because any problem in NP can be reduced to it in polynomial time:\n\n\nReduce any problem in NP to an instance of the NP-Complete problem 3-SAT\nConstruct in polynomial time a TM which checks all assignments and halts iff a satisfying assignment is found.\nUse a solution to the halting problem to tell whether the TM halts.\nIf it halts, accept; otherwise, reject.\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Prove specific decision problem is NP-complete\r\n                \r\n\nGiven: graph G\nInput: k\nReturn: \"YES\" if there exists a set of k nodes, such that no two nodes are connected and no two nodes are connected to the same node. For example if (A,B) and (B,C) then A and C are not allowed in the set of k nodes.\nHow would we prove this problem is NP-complete?\n\n\nEDIT: I imagine we could use Independent Set/Vertex Cover?\n    ", "Answer": "\r\nI'm assuming (?) this is a homework problem.\n\nAs a hint, start with the dominating set problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Would an exponential lower bound on an NP-complete language prove P does not equal NP?\r\n                \r\nIf someone were able to prove an exponential lower bound for a NP-complete problem, would that prove that P ≠ NP?\n    ", "Answer": "\r\nYes, that would prove that P is not equal to NP. All polynomials are bounded from above by any exponential function, so an exponential lower bound on any NP problem would prove that the problem is not in P, and thus would prove that P cannot equal NP.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is MAX 3 SAT NP-complete or co-NP-complete? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 8 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI'm seeing a lot conflicting info about this problem. With some saying sites it is NP-complete and others saying that it is co-NP-complete. The only real consistent info I can find is that is definitely NP-hard. Which is it? And why?\n    ", "Answer": "\r\nI think this depends on how you define MAX-3SAT.\n\nIf you define MAX-3SAT as the function problem \"given a 3CNF formula, produce a variable assignment maximizing the number of satisfied clauses,\" then it's neither NP-complete nor co-NP-complete. NP and co-NP are classes of decision problems and therefore no function problem can belong to them. Therefore, MAX-3SAT can't belong to NP or co-NP, so it can't be a complete problem for either class. This function problem is NP-hard via a reduction from vanilla 3SAT - if you could find the maximally satisfying assignment, you could check if the original formula was satisfiable by seeing if all clauses were satisfied.\n\nYou could also define MAX-3SAT as the decision problem \"given a 3CNF formula and a number n, determine whether there's a variable assignment to the formula that makes at least n clauses true.\" This is definitely in NP and also NP-complete via a reduction from 3SAT.\n\nOn the other hand, if you define MAX-3SAT as the decision problem \"given a 3CNF formula and a variable assignment to that formula, is that assignment the one that maximizes the number of satisfied clauses?,\" then it would belong to co-NP (if the answer is no, you could confirm this by exhibiting a better satisfying assignment). I'm not sure if it would be NP-hard, though, and I'm also not sure whether it's co-NP-hard either.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If P = NP, why does P = NP = NP-Complete? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 8 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nIf ```\nP = NP```\n, why does ```\nP = NP```\n also then equal ```\nNP-Complete```\n?\n\nI.e. Why would it then be the case that ```\nP = NP = NP-Complete```\n?\n\nAssuming ```\nP != NP```\n , there were problems in NP not in NP - Complete.\nWhen ```\nP = NP```\n, all NP problems are actually now P.\n\nShouldn't there still be ```\nP = NP```\n problems not in ```\nNP - Complete```\n?\n\n\n    ", "Answer": "\r\nfor future reference, no code = does not belong in stackoverflow...\n\nas for your answer, http://en.wikipedia.org/wiki/NP-complete provides a full explanation. In 'layman' terms, all NP problems can be converted to an NP-C problem with a polynomial converter. that means that if P=NP, all of NP can be converted to NP-C which by definition can be converted to another NP-C etc. so P=NP=NP-C.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If A is NP-complete and if there is a reduction from A to B, does it imply that B is also NP-complete? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nSuppose that A, B, and C are decision problems. Suppose also that A is polynomial-time reducible to B and that B is polynomial-time reducible to C. If both A and C are NP-complete, then does it imply that B is also NP-complete? \n\nI know that, if A is NP-complete and it is polynomial-time reducible to B, then B is NP-hard. However, in order for a problem to be NP-complete, it must meet (1) it's in NP, and (2) it's NP-hard.\n\nI have no idea how to prove the first requirement of NP-complete.\n    ", "Answer": "\r\nIf A is NP-complete and it is polynomial time reducible to B, then B is NP-hard.\n\nIf B is polynomial time reducible to C and C is NP-complete, then B is in NP.\n\nA problem in NP which is in NP-hard is NP-complete.\n\nAnother way to show B is NP-complete is to notice that any two NP-complete problems (e.g A and C) are polynomially reducible to each other, and thus B is equivalent (two-way polynomially reducible) to any NP-complete problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why do we get to pick the source in an NP-completeness reduction?\r\n                \r\nWe know that to prove that problem A is NP-complete, we have to \nfind a polynomial time reduction from NP-complete problem B to this problem A.\n\nFor example, we can do these reductions:\n\n```\n SAT ---> clique\n SAT ---> independent set\n Independent set ---> Vertex Cover\n```\n\n\nWhy is it that we get to choose which NP-complete problem we use as the source of the reduction? Are all NP-complete problems reducible to each other, and we just need to choose the one that is easier to show the reduction?\n\nI mean it was easy to show the reduction from SAT to clique. However, I don't know how to show the reduction from SAT to Vertex Cover, but I know how to reduce from Independent Set to Vertex Cover. Is it in principle possible reduce each NP-Complete to every other NP-Complete, but we just use the easiest one?\n    ", "Answer": "\r\nA problem is NP-complete if\n\n\nit's in NP, and\nevery problem in NP is polynomial-time reducible to it.\n\n\nThis means that if you take any two NP-complete problems, you're guaranteed that they're polynomial-time reducible to one another, even if you don't know precisely what that reduction is going to look like.\n\nYou asked why you get to pick which NP-complete problem to use as the source of a reduction when proving NP-completeness. The reason is that once you've shown that some NP-complete problem A reduces to an NP problem B, you can conclude that every NP-complete problem C reduces to B, since C reduces to A and A reduces to B. In other words, if you prove that a problem is NP-complete by reducing any known NP-complete problem to it, you could have in principle reduced every NP-complete problem to it. You're just keeping things easy by reducing from a problem that makes the reduction easiest to do.\n\nIt can be pretty tough in practice to do a reduction if you pick the wrong NP-complete language as your source. To get a sense of why this is, think about how the proof of Cook-Levin theorem (that SAT is NP-complete) works. To show that you can reduce any NP problem to SAT, you start with a polynomial-time, nondeterministic Turing machine for that problem, then use that to construct a massive propositional formula that basically says \"there is some computation of this TM that accepts its input string.\" This is great in theory, but in practice this is a horrid reduction that would be almost utterly incomprehensible to anyone who looked at it. Any time you're proving NP-completeness of a problem by doing a reduction from a known NP-complete problem, think of it as finding a shortcut to skip a really tough proof - if you can find something nice and simple, you're skipping a behemoth of a reduction.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Can it be proven no polynomial algorithm exists for an NP-Complete prob.?\r\n                \r\nI can't really seem to grasp what it really means to say a problem is NP-Complete. Could anyone help me with the following question?\n\nAn NP-complete problem is a problem for which one can prove that an algorithm for solving it in polynomial time does not exist. Is the statement true?\n\nI would want to say this statement isn't true, because can anyone actually prove that such an algorithm doesn't exist for any NP-Complete problem? From looking around on various sources, I understand that no polynomial time algorithm is known for any NP-Complete problem; however, it can't be proven.\n\nAny help would be greatly appreciated. Thanks.\n    ", "Answer": "\r\nIt is possible in some situations to prove that no algorithm exists that is better than a certain limit.\n\nFor example the ```\nO(n log n)```\n bound for a comparison sort has been proven. No matter how clever we become in the future, we can be sure that no-one will ever invent an ```\nO(n)```\n comparison sort.\n\nIn this case though, no-one has found a proof. But that doesn't mean it can't be proven. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is GAP (graph accessibility) NP-Complete?\r\n                \r\nIs the GAP (graph accessibility problem) NP-Complete ?\nIt has polynomial and non-deterministic polynomial algorithms that solve it, but I don't think this is a criteria that overrides the basic way of showing it's NP-Complete, by showing it is NP and NP-Hard => NP-Complete.\nI heard both versions from older students than me.\nSo in the end, is it or not NP-Complete?\n    ", "Answer": "\r\nWikipedia says that the problem is ```\nNL-Complete```\n, which means that it’s also in ```\nP```\n. This makes it extremely unlikely that it is ```\nNP-Complete```\n. If it was, that would prove that P=NP, which is a very old and unsolved question. And it is widely assumed that ```\nP≠NP```\n.\n\nYou won’t be able to prove that it is not ```\nNP-Complete```\n either, because that would prove ```\nP≠NP```\n. \n\nIf you can prove that it is ```\nNP-Complete```\n or that it is not ```\nNP-Complete```\n, you will recieve an award of one million dollars.\n\nSo in summary the answer is: It seems very unlikely, but it is just as unlikely that you can prove anything in that direction :).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-complete to determine vertex cover\r\n                \r\nIs it right that \"it is NP-complete to determine if a graph contains a vertex cover of size 99\"???\n\nand\n\nis it right that \" it takes linear time to determine if a graph contains a vertex cover of size 99\"???\n\nOne more, is it right to say that \" No NP-complete problem can be solved in polynomial time unless the VERTEX COVER problem admits a polynomial-time algorithm.\"???\n    ", "Answer": "\r\n\"is it NP-complete to determine if a graph contains a vertex cover of size 99\"\n\nPedantically: no.\n\nThis problem can be solved in polynomial time.  However, the following algorithm is completely useless in practice.\n\nThe approach for a graph with n vertices is simply to test all C(n,99) possible choices of vertex cover.  For each choice, we test all edges (at most n*(n-1) edges in the graph) to see if either of their vertices are included.\n\nThere are fewer than ```\nn^99```\n ways of choosing the vertex cover, so overall this algorithm has polynomial complexity of ```\nn^101```\n. \n\nAs noted by j_random_hacker, this answer assumes that the vertex size of 99 is a known constant.  If the 99 is meant to be a variable and is part of the input, then the problem become the standard NP-complete vertex cover problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-complete, no efficient algorithm?\r\n                \r\nI don't know much about NP-complete but read about it here and there. The book Introduction to Algorithm, I'm studying(by myself) states \"Although no efficient algorithm for an NP-complete problem has ever been found, nobody has ever proven that an efficient algorithm for one cannot exist.\" I'm just wondering, how does one know that the algorithm they have is not the most efficient...if that's the efficient one out of all set of algorithms?\n\nThanks,\n\nSam\n    ", "Answer": "\r\nGreat question. I'm curious what the answers will be to this question, but here's my try.\n\nIt's surprisingly difficult to know if a better algorithm exists then the one you come up with (if you did know that, then your algorithm would be the better one). The question then becomes when should you stop trying to look for a better algorithm. The primary approaches involve coming up with lower bounds for the problem, and then successively making them stronger and stronger.\n\nImagine you're a researcher\n\nA good start to further investigating this problem is to think about the standard comparison based sorting problem. We are given a list of n elements and want to sort it. So the worst algorithm, is come up with all n! lists, and check which is sorted. Then a more intuitive approach is to use something like bubble sort, which is O(n^2). We wonder if we can still do better though. Well say we use divide and conquer and we come up with merge sort which is O(n log n). Now we are interested in knowing if merge sort is NOT the most efficient. So we spend more time thinking of an even better algorithm, but cannot come up with one. So we get frustrated, and switch our approach and think about proving that there cannot be a comparison sort better than O(n log n).\n\nNow intuitively, a naive lower bound is O(n), simply because in order to sort the list, we at least need O(n) time to read it. But, let us try to improve this lower bound. See if you can come up with the lower bound improvement to O(n log n) if you haven't seen it before. If you can't get it check out this great article that proves that n log n is a lower bound for comparison sorts: http://www.cs.uiuc.edu/~jeffe/teaching/algorithms/notes/19-lowerbounds.pdf\n\nNow let us start thinking about NP Complete problems. Consider vertex cover problem (does there exist a set of k vertices in a graph s.t. each edge is incident to at least one vertex) which is NP Complete. We come up with the most intuitive brute force method for solving it (making all (n choose k) vertex choices and test each possible solution). Now the question is, does something more efficient exist? Well, after much effort, suppose we cannot come up with anything faster. So we take the same approach as before of trying to find good lower bounds and successively improving them. clearly O(n) is one lower bound, but we cannot prove a O(n choose k) time lower bound (if we did prove such a lower bound, then that brute force is the best way to solve vertex cover). So we take a break, and work on other problems.\n\nThen one day we are working on the max independent set problem on graphs (does there exist a set S of k vertices such that no two vertices in S are adjacent). We come up with a brute force solution, but we want to know if this is NOT the most efficient algorithm. However we cannot come up with something better and we can't come up with a tight lower bound, so we cannot say if something faster exists.\n\nThen many days later we see that these problems are actually equivalent, in the sense that an efficient algorithm for one gives an efficient algorithm for the other: http://www.cs.cmu.edu/~ckingsf/bioinfo-lectures/npcomplete.pdf\n\nSo although we don't know if the algorithm we have for vertex cover or independent set is the most efficient, we can compare relative degrees of hardness by reducing problems to one another, so that if we find a good algorithm for one we can apply that to the other problem.\n\nTL;DR\n\nEssentially it boils down to the Feynmann approach:\n\n\n\nIn all seriousness, in order to show that our algorithm is or is not the best one:\n\n\nFind a better algorithm or prove its existence (possibly by reduction to another problem you have seen)\nProve that a better algorithm cannot exist. Possibly by finding Lower Bounds that our algorithm realizes.\n\n\nIf the above two fail, rather then answering definitively, try to come up with a notion of how difficult the problem you are working on is by looking at problems which you can reduce to and thinking about their hardness.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is a reduction enough for proving NP-complete or do I need a transformation?\r\n                \r\nIf I have a decision problem A, and wish to show that it is NP-complete.  Is it enough to prove that another NP-complete problem polynomially reduces to A, or must I show that another NP-complete problem polynomially transforms to A? \n\nThat is, can I show that\n\n```\nprocedure solve_SAT\n...\ncall solve_A\ncall solve_A\ncall solve_A\n...\nend\n```\n\n\nor am I only limited to a single use of solve_A, as shown\n\n```\nprocedure solve_SAT\ninput  = ...\nresult = call solve_A(input)\nreturn result\nend\n```\n\n\nI find some sources say the former while other sources say the latter, and it is a bit confusing to me.\n    ", "Answer": "\r\nSuppose you have a decision problem A and you wish to prove that it is NP-Complete then the way to do it is, take an existing NP-Complete problem and reduce it to A.\nWhat I mean by reduction here is a polynomial time reduction.\n\nSo suppose you wanted to show that 3-SAT is NP-Complete then you can show a reduction from the SAT problem.\n\nThe important thing to note here is that the reduction must be poly-time. It doesn't matter whether you call solve_A() multiple times. You can choose to call solve_A() multiple times as long as you make a polynomial number of calls to solve_A().\n\nWhy does it work? You can prove it by contradiction.\nSuppose you had a poly-time algorithm for 3SAT. Then you could solve SAT also in poly-time. Since a polynomial number of calls to a polynomial function is still polynomial. \nSo unless P=NP, this would imply that SAT can also be solved in polynomial time using the newly discovered poly-time algorithm for 3SAT. But we know that SAT is NP-Complete, hence 3SAT must also be NP-Complete.\n\nIn short, to show NP-Completeness two things are required.\n\nExistence of a certificate.\nA reduction from an existing NP-Complete problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "To prove something is NP-hard, why do you need to reduce to it from an NP-complete?\r\n                \r\nFrom wikipedia: \n\n\n  A problem H is NP-hard if and only if there is an NP-complete problem L that is polynomial time Turing-reducible to H (i.e., L ≤ TH).\n\n\nWhy does the problem(call it W) being reduced from need to be NP-complete? Why can't it just also be NP-hard? It seems like what you care about W being \"hard\" not that its in NP.\n\nThoughts? \n    ", "Answer": "\r\nIt can. In fact, your second paragraph implies the first paragraph.\n\nAssume NP-hard problem H is polynomially reducible to problem X. By definition, there exists an NP-complete problem C that is polynomially reducible to H.  Since both reductions are polynomial, you can reduce C to X in polynomial time.  Therefore, NP-complete problem C is reducible to X in polynomial time. Therefore problem X is NP-hard.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "np-completeness in the bounded degree spanning tree\r\n                \r\nI understand why the Bounded Degree Spanning Tree is considered NP Complete with a degree or 2 (it is an instance of the Hamiltonian Path Problem), but I do not understand why this applies to degrees > 2. If someone could please explain why this is an NP Complete problem for degree > 2, It would be most helpful\n    ", "Answer": "\r\nWell, I think that you can make a simple reduction from the instance of bounded by 2, to the instance of General k.\n\nIntuitivly, we will connect to each node of the original graph new k-2 nodes. Therefore every spanning tree will have to contain the k-2 edges from the original node to the new nodes that we connected to him, and a spanning tree from degree at most k exists if there is a spanning tree of degree at most 2 for the original graph.\n\nThe formal reduction will be:\n\nF(V,E)=(V',E'), when : V'={(v,i)|v is in the original graph, 0 < i < k+1), E' = E U {((v,0),(v,i))}, and I don't write a formal proof for the correctness because after all we are not in a math forum.\n\nGood luck and hope that it helped :)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proof that the halting problem is NP-hard?\r\n                \r\nIn this answer to a question about the definitions of NP, NP-hard, and NP-complete, Jason makes the claim that\n\n\n  The halting problem is the classic NP-hard problem. This is the problem that given a program P and input I, will it halt? This is a decision problem but it is not in NP. It is clear that any NP-complete problem can be reduced to this one.\n\n\nWhile I agree that the halting problem is intuitively a much \"harder\" problem than anything in NP, I honestly cannot come up with a formal, mathematical proof that the halting problem is NP-hard.  In particular, I cannot seem to find a polynomial-time many-to-one mapping from instances of every problem in NP (or at least, any known NP-complete problem) onto the halting problem.\n\nIs there a straightforward proof that the halting problem is NP-hard?\n    ", "Answer": "\r\nWe begin by noting that all NP-complete problems are reducible to 3SAT. Now we have a Turing machine that iterates over all possible assignments, and if a satisfying assignment is not found then it runs forever. This machine halts if and only if the 3SAT instance is satisfiable.\n\nCompleting the proof - we can, in polynomial time, reduce any instance of an NP-complete problem to 3SAT.  From there, we can reduce this problem to an instance of the halting problem by pairing the input with a description of the Turing machine described above (which has constant size).  This pairing can be done in polynomial time, because the Turing machine has only constant size.  Then, the original NP-complete problem has answer \"yes\" iff 3SAT instance is satisfiable iff the Turing machine halts on the given input.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Obtaining all possible states of an object for a NP-Complete(?) problem in Python\r\n                \r\nNot sure that the example (nor the actual usecase) qualifies as NP-Complete, but I'm wondering about the most Pythonic way to do the below assuming that this was the algorithm available.\n\nSay you have :\n\n```\nclass Person:\n  def __init__(self):\n    self.status='unknown'\n  def set(self,value):\n    if value:\n      self.status='happy'\n    else :\n      self.status='sad'\n  ... blah . Maybe it's got their names or where they live or whatev.\n```\n\n\nand some operation that requires a group of Persons. (The key value is here whether the Person is happy or sad.)\n\nHence, given PersonA, PersonB, PersonC, PersonD - I'd like to end up a list of the possible 2**4 combinations of sad and happy Persons. i.e.\n\n```\n[\n[ PersonA.set(true), PersonB.set(true), PersonC.set(true), PersonD.set(true)], \n[ PersonA.set(true), PersonB.set(true), PersonC.set(true), PersonD.set(false)], \n[ PersonA.set(true), PersonB.set(true), PersonC.set(false), PersonD.set(true)], \n[ PersonA.set(true), PersonB.set(true), PersonC.set(false), PersonD.set(false)], \netc..\n```\n\n\nIs there a good Pythonic way of doing this? I was thinking about list comprehensions (and modifying the object so that you could call it and get returned two objects, true and false), but the comprehension formats I've seen would require me to know the number of Persons in advance. I'd like to do this independent of the number of persons.\n\nEDIT : Assume that whatever that operation that I was going to run on this is part of a larger problem set - we need to test out all values of Person for a given set in order to solve our problem. (i.e. I know this doesn't look NP-complete right now =) ) \nany ideas?\n\nThanks!\n    ", "Answer": "\r\nI think this could do it:\n\n```\nl = list()\nfor i in xrange(2 ** n):\n    # create the list of n people\n    sublist = [None] * n\n    for j in xrange(n):\n        sublist[j] = Person()\n        sublist[j].set(i & (1 << j))\n    l.append(sublist)\n```\n\n\nNote that if you wrote ```\nPerson```\n so that its constructor accepted the value, or such that the ```\nset```\n method returned the person itself (but that's a little weird in Python), you could use a list comprehension. With the constructor way:\n\n```\nl = [ [Person(i & (1 << j)) for j in xrange(n)] for i in xrange(2 ** n)]\n```\n\n\nThe runtime of the solution is ```\nO(n 2**n)```\n as you can tell by looking at the loops, but it's not really a \"problem\" (i.e. a question with a yes/no answer) so you can't really call it NP-complete. See What is an NP-complete in computer science? for more information on that front.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why is TSP NP-hard while the Hamiltonian path NP-complete?\r\n                \r\nWhy aren't these 2 problems, namely TSP and Hamiltonian path problem, both NP-complete?\n\nThey seem identical.\n    ", "Answer": "\r\nFor a problem X to be NP-complete, it has to satisfy:\n\n\nX is in NP, given a solution to X, the solution can be verified in polynomial time.\nX is in NP-hard, that is, every NP problem is reduceable to it in polynomial time (you can do this through a reduction from a known NP-hard problem (e.g. Hamiltonian Path)).\n\n\nThere are two versions of the The Travelling Salesman Problem (TSP):\n\n\nThe optimization version (probably the one you are looking at), namely, find the optimum solution to the TSP. This is not a decision problem, and hence cannot be in NP, but it is however in NP-hard which can be proven via a Hamiltonian Path reduction. Therefore this isn't an NP complete problem.\nThe decision version - given an integer K is there a path through every vertex in the graph of length < K? This is a decision (yes/no) problem, and a solution can be verified in polynomial time (just traverse the path and see if it touches every vertex) and so it is in NP, but it is also in NP-hard (by an identical proof as above). Since it satisfies both requirements for NP-completeness, it is an NP-complete problem.\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are there public key cryptography algorithms that are provably NP-hard to defeat? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is off-topic. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.\r\n                \r\n                    \r\n                        Closed 10 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nShould practical quantum computing become a reality, I am wondering if there are any public key cryptographic algorithms that are based on NP-complete problems, rather than integer factorization or discrete logarithms.\n\nEdit:\n\nPlease check out the \"Quantum computing in computational complexity theory\" section of\nthe wiki article on quantum computers.  It points out that the class of problems quantum computers can answer (BQP) is believed to be strictly easier than NP-complete. \n\nEdit 2:\n\n'Based on NP-complete' is a bad way of expressing what I'm interested in.\n\nWhat I intended to ask is for a Public Key encryption algorithm with the property that any method for breaking the encryption can also be used to break the underlying NP-complete problem.  This means breaking the encryption proves P=NP.\n    ", "Answer": "\r\nI am responding to this old thread because it is a very common and important question, and all of the answers here are inaccurate.\n\nThe short answer to the original question is an unequivocal \"NO\".  There are no known encryption schemes (let alone public-key ones) that are based on an NP-complete problem (and hence all of them, under polynomial-time reductions).  Some are \"closer\" that others, though, so let me elaborate.\n\nThere is a lot to clarify here, so let's start with the meaning of \"based on an NP-complete problem.\"  The generally agreed upon interpretation of this is: \"can be proven secure in a particular formal model, assuming that no polynomial-time algorithms exist for NP-complete problems\".  To be even more precise, we assume that no algorithm exists that always solves an NP-complete problem.  This is a very safe assumption, because that's a really hard thing for an algorithm to do - it's seemingly a lot easier to come up with an algorithm that solves random instances of the problem with good probability.\n\nNo encryption schemes have such a proof, though.  If you look at the literature, with very few exceptions (see below), the security theorems read like the following:\n\n\n  Theorem: This encryption scheme is provably secure, assuming that no\n  polynomial-time algorithm exists for\n  solving random instances of some problem X.\n\n\nNote the \"random instances\" part.  For a concrete example, we might assume that no polynomial-time algorithm exists for factoring the product of two random n-bit primes with some good probability.  This is very different (less safe) from assuming that no polynomial-time algorithm exists for always factoring all products of two random n-bit primes.\n\nThe \"random instances\" versus \"worst case instances\" issue is what is tripped up several responders above.  The McEliece-type encryption schemes are based on a very special random version of decoding linear codes - and not on the actual worst-case version which is NP-complete.\n\nPushing beyond this \"random instances\" issue has required some deep and beautiful research in theoretical computer science.  Starting with the work of Miklós Ajtai, we have found cryptographic algorithms where the security assumption is a \"worst case\" (safer) assumption instead of a random case one.  Unfortunately, the worst case assumptions are for problems that are not known to be NP complete, and some theoretical evidence suggests that we can't adapt them to use NP-complete problems.  For the interested, look up \"lattice based cryptography\".\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is there an algorithm to solve this problem efficiently? Is it NP-Complete?\r\n                \r\nI have two arrays.  One array represents items.  The other array represents customers with money.  I need to find if all items can be purchased.  An item can only be purchased by one person.  But multiple items can be purchased by a single customer.\nExample,\n```\nItems: [10, 20, 30]\nCustomers: [40, 20]\nYes. Customer 1 can purchase items 1 and 3.  Customer 2 can purchase item 2.\n\nItems: [10, 20]\nCustomers: [15, 15]\nNo. Customer 1 can purchase item 1, but Customer 2 cannot purchase item 2.\n```\n\nEdit: I think this may be np-complete since it seems like a variation of the bin packing problem.\n    ", "Answer": "\r\nYou can solve it by use of iteration over Knapsack problem with same value and weight  for each element.\n```\nLet E as elements\nLet V as item values for all elements\nLet M the number of Customers\nfor i = 0 to M\n   W = Customers[i]\n   Knapsack(E,V,W)\n   E = E - {funded elements for this W}  \n   i= i +1\nend for\n\nIf E is empty print YES\nelse print NO\n```\n\nIf Items has N element and Customers has M elements the time complexity for recursive method is M * O(2N). But you can use dynamic programming to solve it roughly in O(M * N * WM) Which WM is the average of customer budgets (in you first example 30). So you can solve it in polynomial time complexity.\nI provide you a dynamic programming sample to solve your problem in Java. This code may have bug and you can improve this code as well.\n```\nimport java.util.*;\n\nclass Main {\n\n    // A utility function that returns\n    // maximum of two integers\n    static int max(int a, int b)\n    {\n        return (a > b) ? a : b;\n    }\n  \n    static void knapSack(int W, ArrayList<Integer> wtArr, int n)\n    {\n        int i, w;\n        int K[][] = new int[n + 1][W + 1];\n        \n        int wt[] = wtArr.stream().mapToInt(ix -> ix).toArray();\n        int[] val = new int[n];\n        System.arraycopy(wt, 0, val, 0, n);\n\n\n        // Build table K[][] in bottom up manner\n        for (i = 0; i <= n; i++) {\n            for (w = 0; w <= W; w++) {\n                if (i == 0 || w == 0)\n                    K[i][w] = 0;\n                else if (wt[i - 1] <= w)\n                    K[i][w] = Math.max(val[i - 1] +\n                              K[i - 1][w - wt[i - 1]], K[i - 1][w]);\n                else\n                    K[i][w] = K[i - 1][w];\n            }\n        }\n \n        // stores the result of Knapsack\n        int res = K[n][W];\n        //System.out.println(\"\\nres = \"+res);\n \n        int j=0;\n        w = W;\n        for (i = n; i > 0 && res > 0; i--) {\n \n            // either the result comes from the top\n            // (K[i-1][w]) or from (val[i-1] + K[i-1]\n            // [w-wt[i-1]]) as in Knapsack table. If\n            // it comes from the latter one/ it means\n            // the item is included.\n            if (res == K[i - 1][w]) {\n                //System.out.print(wt[i - 1] + \"<< \");\n                continue;\n            }\n            else {\n \n                // This item is included.\n                System.out.print(wt[i - 1] + \" \");\n                wtArr.remove(i-1);\n                // Since this weight is included its\n                // value is deducted\n                res = res - val[i - 1];\n                w = w - wt[i - 1];\n            }\n        }\n        System.out.println(wtArr);\n    }\n    \n\n    // Driver code\n    public static void main(String args[])\n    {\n        ArrayList<Integer> wt = new ArrayList<Integer>();\n        wt.addAll(Arrays.asList(10, 20 , 30));\n        int cu[] = new int[] {40 , 20};\n        for (int i=0; i<cu.length; i++) {\n            int n = wt.size();\n            int W = cu[i];\n            \n            knapSack(W, wt, n);\n        }\n        \n        if(wt.size() > 0)\n            System.out.println(\"NO\");\n        else \n            System.out.println(\"YES\");\n        \n    }\n}\n```\n\nSee Java Online Demo for test by yourself.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity measurement of NP-complete\r\n                \r\nFor example, the set-cover decision problem is known to be a NP-complete problem. The input of this problems is a universe U, a family S of subsets of U, and an integer k (). \n\nOne thing that I'm confused with is that if we let k=1, then obviously the problem can be solved in time |S|, by simply checking each element in S. More generally, when k is a constant, the problem can be solved in polynomial time of |S|. In such a way, the time complexity becomes exponentially high only when k also increases with |S|, like |S|/2, |S|/3...\n\nSo here're my questions:\n\n\nMy current understanding is that the time complexity measurement of a NP-complete problem is measured in terms of the WORST case. Can anybody please tell me if the understanding is right?\nI saw somebody proved that another problem is NP-hard by showing that a set-covering desicion problem with input ```\n<U,S,|U|/3>```\n can be reduced to that problem. I'm just wondering why did he only prove for ```\n<U,S,|U|/3>```\n, instead of ```\n<U,S,ARBITRARY k>```\n?? Is such a proof reliable?\n\n\nMany thanks!\n    ", "Answer": "\r\nTime complexity is measured as a function of the input instance size. The input instance size can be measured in bits. The input instance size increases as any of the inputs ```\nU```\n, ```\nS```\n, and ```\nk```\n increase. So the question that one is trying to answer is how much more time does it take to solve the problem of instance size for example ```\n2n```\n bits vs the problem of instance size ```\nn```\n. \n\nSo simply the size of the whole input instance has to increase and in this particular case it means increasing the size of ```\nU```\n and/or ```\nS```\n and/or ```\nk```\n. \n\nTo answer your two questions:\n\n\nYes, the worst case time complexity is used: you are looking for the hardest problem of input size ```\nn```\n and you correctly noticed that the problem (of the same size) probably becomes harder as you increase more parameters than just one.\nIt would be better to see the proof you are referring to but the thinking probably goes like: \n\n\n  I give a polynomial reduction of the set-covering decision problem instance of size ```\nn```\n to my problem's instance of size ```\nm```\n. If the size of the set-covering decision problem's input instance increases to ```\n2n```\n then the result of the reduction will be my problem's instance of size ```\n2m```\n because there is a direct correspondence between the input size of ```\nU```\n, ```\nS```\n, and ```\nk```\n and the input size of my problem.\n\n\nSo all set-covering decision problem instances of size ```\nn```\n map to my problem instances of size ```\nm```\n. Thus if I am looking for the hardest instance of the set-covering decision problem using this reduction I will find the hardest instance of my problem of size ```\nm```\n. \n\n\nEDIT\n\nFrom the proof in your linked paper:\n\n\n  Proof. We reduce an arbitrary 3-cover problem instance—in which we are\n  given a universe U, a family S of subsets of U, such that each subset\n  contains 3 elements, and we are asked whether we can (exactly) cover\n  all of U using |U|/3 elements of S—to a game with homogeneous\n  resources and schedules of size 3.\n\n\nAs you correctly say, they need to convert all instances of the set-cover problem to their problem. But they are using a reduction from a different problem: the Exact 3-cover problem that is proven to be NP-complete in \"Computers and intractability - MR Garey, DS Johnson, 1979\".\n\nThe Exact 3-Cover problem is like the set cover decision problem but with ```\n|U| = 3t```\n and ```\nS```\n is a set of 3-element subsets of ```\nU```\n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proof of NP Completeness of set-partition problem\r\n                \r\nI have reduced subset sum problem to set partition problem but do not know whether it is correct and so I need your help.\nMY METHOD:\nIn subset sum problem we have to find a subset S1 of set S so that it sums to a number t and in set partition problem we need to find a subset X1 of set X such that summation of numbers in set X1 is half of that in X.\nSo let us take instance of subset sum problem where t = sum of numbers in X / 2. If we can solve the set partition problem than we solved the subset sum problem too. But we know that subset sum id NP Complete so subset sum problem is also NP Complete( I know how to prove it is NP).\nI am having doubt whether we can make a choice of t like that or not. Please help.\n    ", "Answer": "\r\nYour logic is sound, that is a valid reduction. \n\nWe know this is valid because the proof is for the known problem to the unknown problem. You need to prove that EVERY instance of the known problem can be reduced into SOME instance of the unknown problem. So putting restrictions on your unknown problem is perfectly acceptable. \n\nSome notes: Your description is not sufficient for a proper proof. You noted that you knew this but for any readers here: to prove a problem is NP-Complete, you first prove it is in NP, and then you prove it is NP-Hard. This question only addresses a small portion of what an NP-Hard proof should contain.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete Reduction for Subset Sum\r\n                \r\nI'm studying for a final exam and one of the practice problems given to us from a past exam is as follows:\n\n\n\nMy instinct says to reduce this problem to the Subset Sum problem. \n\nMy initial solution is:\n\nLet 'A' be the Subset Sum NP-Complete problem.\n\nLet 'B' be the Partition Problem that we are trying to prove is NP-Complete\n\n'A' takes an instance alpha that is: a set S and a value 'b'\n\n'B' takes an instance beta that is: a set S' and a k value for the decision\n\nWe want to polynomially reduce alpha to an instance beta\n\nI would take b from alpha, put it into the set S to make S', then set k = 0 making\nbeta equal to: S'=S union 'b', K = 0\n\nLet's assume 'B' can solve for this instance. Since it can, it produces an output using beta which was formed from alpha.\n\nSince 'B' can solve that instance, it means that 'A' is solvable in polynomial time, however we know this not to be true since 'A' is NP-Complete. We have a contradiction. Because of this contradiction, we know that 'B' is at least as 'hard' as 'A', therefore it too is NP complete. \n\nPlease let me know what's wrong with my solution or if it is valid.\n\nThanks\n    ", "Answer": "\r\nActually this problem is (minimizing difference) is NP-hard. The decision version (not to be confused with decision problem, which you are) is whether there exists a solution that partitions so that the difference is zero, which is a NP-complete problem.\n\nSee http://en.wikipedia.org/wiki/Partition_problem\n\nExcerpt from wiki page:\nThere is an optimization version of the partition problem, which is to partition the multiset S into two subsets S1, S2 such that the difference between the sum of elements in S1 and the sum of elements in S2 is minimized. The optimization version is NP-hard.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Relationship between NP-hard and undecidable problems\r\n                \r\nAm a bit confused about the relationship between undecidable problems and NP hard problems. Whether NP hard problems are a subset of undecidable problems, or are they just the same and equal, or is it that they are not comparable?\n\nFor me, I have been arguing with my friends that undecidable problems are a superset to the NP hard problems. There would exist some problems that are not in NP hard but are undecidable. But i am finding this argument to be weak and am confused a bit. Are there NP-complete problems that are undecidable.? is there any problem in NP hard which is decidable.??\n\nSome discussion would be of great help! Thanks!\n    ", "Answer": "\r\nUndecidable = unsolvable for some inputs.  No matter how much (finite) time you give your algorithm, it will always be wrong on some input.\n\nNP-hard ~= super-polynomial running time (assuming P != NP).  That's hand-wavy, but basically NP-hard means it is at least as hard as the hardest problem in NP.\n\nThere are certainly problems that are NP-hard which are not undecidable (= are decidable).  Any NP-complete problem would be one of them, say SAT.\n\nAre there undecidable problems which are not NP-hard?  I don't think so, but it isn't easy to rule it out - I don't see an obvious argument that there must be a reduction from SAT to all possible undecidable problems.  There could be some weird undecidable problems which aren't very useful.  But the standard undecidable problems (the halting problem, say) are NP-hard.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Simple reduction (NP completeness)\r\n                \r\nI'm looking for a means to prove that the bicriteria shortest path problem is np complete.\nThat is, given a graph with lengths and weights, I need to know if a there exists a path in the graph from s to t with total length <= L and weight <= W.\n\nI know that i must take an NP complete problem and reduce it to this one. We have at our disposal the following problems to choose from: 3-SAT, independent set, vertex cover, hamiltonian cycle, and 3-dimensional matching.\n\nAny ideas on which may be viable?\n\nthanks\n    ", "Answer": "\r\nDid you try Google?  3rd hit is:\n\nhttp://www.jstage.jst.go.jp/article/ieejeiss/128/3/128_416/_article\n\nThe article is pay-per-view, but the Google cache supplies the important bit upfront:\n\n\"Unfortunately, the multiobjective case ( including the bicriteria case) is NP-complete(3).\n\nand the reference points to:\n\n(3) M. Garey and D. Johnson : Computers, and Intractability : A Guide to the theory of NP-Completeness, New York: Freeman (1979)\n\nwhich is the standard reference for questions of this form.\n\nSo ... have you looked at Garey and Johnson?  I don't have a copy here to check, but it was my go-to when I did comps.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Question about NP-Completeness of the Independent Set Problem\r\n                \r\nI thought that, when proving that a problem P is NP-Complete, we were supposed to reduce a known NPC problem to P. But, looking at the solution to the Independent Set problem, it seems to not go this way.\n\nTo prove that Independent Set is NP-Complete, you take a graph G, find its inverse G', and then compute CLIQUE(G'). But, this is doing the other way around: it's taking a problem P I DON'T know if it's NPC and then reduces it to a know NPC problem.\n\nHere's an example of the solution.\n\nWhat am I missing here? Isn't this wrong, since it's doing it the other way around?\n    ", "Answer": "\r\nTo prove that P is NP-complete, we need to show two things:\n\n\nThat P exists in NP.\nThat there's a polytime reduction algorithm to reduce some NP-complete problem Q to P.\n\n\nIf we know that CLIQUE is in NPC, then we can easily prove that IS is in NPC.\n\n\nWe can verify IS trivially in polytime. Iterate vertices, ensure that each has an edge not in the candidate solution.\nWe now need to reduce CLIQUE to IS. Given a graph ```\nG```\n and an integer ```\nn```\n, for CLIQUE we want to check if there's a CLIQUE of size ```\nn```\n. Let ```\nH```\n be the inverse of ```\nG```\n. If you find an IS in ```\nH```\n of size ```\nn```\n, you have a CLIQUE of size ```\nn```\n in ```\nG```\n with the same vertices. We've reduced CLIQUE to IS.\n\n\nIf you were to reduce IS to CLIQUE, you wouldn't prove that either is in NPC unless you could reduce some other problem in NPC to IS. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Deterministic solutions to Minimal Vertex cover problems - NP complete is fine\r\n                \r\nA vertex cover problem is to find a set ψ for an undirected graph G = (V, E) for ψ ∈ V such that if {u, v} ∈ E then either u ∈ ψ or v ∈ ψ or both. This Problem is defined and proved to be NP complete.\n\nAre there Deterministic Algorithms that can solve this problem? An exponential running time is acceptable but are there any better deterministic algorithms? I found a similar question and only one approach Using Binary search. I am not looking for approximate solutions which can be run in lesser time - as I understand the one listed in Chapter 35 of Cormen, Leiserson, Rivest, and Stein (CLRS) text is an Approximation Algorithm.\n    ", "Answer": "\r\nYou can use a search-tree for this problem. For every edge {v, w}, there are 3 options.\n\nv is included\nw is included\nboth are included.\n\nYou can also apply some pruning rules, like the following:\n\nIf a vertex v has degree 1, include the neighbour of v in the VC.\nIf for two neighbours v and w the neighbour-set of v is a subset of the neighbours of w, include w in the VC.\n\nBoth of these rules can be proven in the sense that the choice you make by these rules are at least as good as any other choice you could make for the considered edge.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Effect of number base when proving NP completeness of numerical problems\r\n                \r\nI am reading about NP completeness from the algorithm design book of tardos, In the section of proving subset sum is NP complete, it is written that -\nThe algorithm developed for subset sum has running time of O(nW). If an instance of 100 numbers is given, each of which is 100 bits long then the input is only 100 * 100 = 10000 digits, but W is roughly 2^100.\nI dont understand this claim, why is W 2^100 ? what is the effect of base on this problem, I mean if we change it to some other base x, would W be x^100 ? what if we change it into unary base ?\nthanks.\n    ", "Answer": "\r\nTo understand this you need to think about how the running time of the algorithm changes as the size of the numbers in the problem set grows.  I'm assuming that your textbook describes the usual dynamic programming attack on subset sum.  That algorithm's run time grows linearly with the width of the problem set.  (The problem set width is the sum of the positive numbers in the set minus the sum of the negative numbers.)  This width grows exponentially as you increase the size of the numbers in the set.  For example, if you use 101 bit numbers instead of 100 bit numbers, the width of the problem set doubles.  Move to 102 bit numbers and the problem set width doubles again.  And since the algorithm's run time grows linearly with the problem set width, that run time doubles each time as well.  This doubling is exponential growth in run time as the input size grows linearly, so this is not a polynomial-time algorithm.\n\nIf the numbers were written in a different base > 1, then yes, you would see exponential growth of the problem width in that base.  For example, in base 10 adding another digit makes the problem width ten times larger.  If you switch to unary, you lose the exponential growth in the problem set size, but instead the input size for any given problem is exponentially larger than it would be in bases > 1, so you gain nothing.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Whats the difference between NP and co-NP\r\n                \r\nI know their complete counterparts mean that\nNP - complete is the hardest in the NP problems and co-NP-complete means the hardest in co-NP problems but whats the difference between the two? My textbook said \"The yes and no are reversed\" which doesn't leave that much of a clue to me. \n    ", "Answer": "\r\nWhen you want to prove the difficulty of a problem, you have to turn it into something called a decision problem, which means a \"yes/no\" answer type problem. For example, in Set Cover, we may ask \"can we cover all elements using only X subsets?\" where X is some arbitrary number. We can show that this problem exists in NP because a solution to it is easily verifiable; you provide the X subsets, and I check to see if all elements are covered in polynomial time. If we can answer efficiently answer \"yes\" to the decision problem, then we can minimize X and thus solve the entire Set Cover problem efficiently (thereby proving P=NP). \n\nCo-* (Co-NP, Co-NP-complete) focuses on answering \"no\" to the complemented decision problem. For example, the complemented decision problem of Set Cover would be \"For every combination of X subsets, is it impossible to cover all elements?\" Answering \"no\" to this question requires you to provide a counter-example.\n\nIn summary: NP is concerned with a \"yes\" answer to some decision problem. Co-NP is concerned with a \"no\" answer to the same, but complemented, decision problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Authentic List of NP, NP Complete and NP Hard problems\r\n                \r\nAfter wading through multiple sources, fol list has been prepared by me. But this seems confusing and overlapping. Pl validate or share a resource with authentic list:-\n```\n    NP Problems:\n1.  Hamiltonian Path Problem\n2.  Subset Sum Problem\n3.  Graph Isomorphism Problem\n4.  Boolean Satisfiability Problem (SAT)\n5.  Vertex Cover Problem\n6.  Knapsack Problem\n7.  3-SAT Problem\n8.  Clique Problem\n9.  Traveling Salesman Problem (TSP)\n10. Maximum Independent Set Problem\n\nNP-Complete Problems:\n1.  Boolean Satisfiability Problem (SAT)\n2.  Traveling Salesman Problem (TSP)\n3.  Knapsack Problem\n4.  Graph Coloring Problem\n5.  Hamiltonian Cycle Problem\n6.  Subset Sum Problem\n7.  3-SAT Problem\n8.  Steiner Tree Problem\n9.  Bin Packing Problem\n10. Vehicle Routing Problem\n\n NP-Hard Problems:\n1.  Halting Problem\n2.  Post Correspondence Problem\n3.  Knapsack Problem\n4.  Graph Coloring Problem\n5.  Hamiltonian Cycle Problem\n6.  Steiner Tree Problem\n7.  Bin Packing Problem\n8.  Vertex Cover Problem\n9.  Independent Set Problem\n10. Partition Problem\n```\n\n    ", "Answer": "\r\nBy definition, every NP-complete problem is also NP, and NP-hard. And many problems (but not all) in NP are NP-hard. So overlap is not only allowed, but also expected.\nFor example, the clique (decision) problem is NP-complete, meaning it is also NP and NP-hard, so it should be in all of your lists.\nHowever, that doesn't make your list of examples incorrect, unless you claim it to be a complete and exhaustive list of all problems in these categories. This would be impossible because there exists an infinite number of problems so you cannot list them.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Judge:Some N P -complete problems have polynomial time algorithms, but some others do not\r\n                \r\nHere is the context of the question:\nFor each of the following statements, indicate whether it is true, false, or unknown, where 'unknown' indicates that scientists have not conclusively determined whether the statement is true or false. For example, the correct answer for the statement P=NP is unknown. But the correct answer for the best algorithm for the maximum flow problem in n-vertex graphs takes time at least 2^n'' is ``false''.\nGive a short justification for your answer (i.e. explain why the\nstatement is true, or false, or not known to be either true or false).\nAnd here is the statement I am unsure:\nSome N P -complete problems have polynomial time algorithms, but some others do not..\nI came up with two solutions which I think both make sense to me:\nUnknown:If\nany NP-complete problem can be solved by a polynomial time algorithm, then all of them can\nbe by the reduction. So NP = P OR\nFalse: if some NP-complete algorithms have polynomial time\nalgorithms, we can reduce them to the NP-complete problems which don’t have polynomial\ntime algorithms, which means they have polynomial time algorithms as well.\nI wonder which is true.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is the board game \"Go\" NP complete?\r\n                \r\nThere are plenty of Chess AI's around, and evidently some are good enough to beat some of the world's greatest players.\n\nI've heard that many attempts have been made to write successful AI's for the board game Go, but so far nothing has been conceived beyond average amateur level.\n\nCould it be that the task of mathematically calculating the optimal move at any given time in Go is an NP-complete problem?\n    ", "Answer": "\r\nChess and Go are both EXPTIME complete.  IIRC, Go has more possible moves, so I think it a higher multiple of that complexity class than chess.  Wikipedia has a good article on the complexity of Go.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How do I prove a class-room scheduling issue to be NP complete correctly?\r\n                \r\nI am given a problem, that is about scheduling n classes in k rooms at a school, and it is a decision problem, because we want to ask if we can arrange these n classes in those k rooms so that a given timelimit t is not exceeded (the total time of classes in a certain scheduled way should not exceed t).\n\nI am aware about to firstly show that every solution to the problem can be verified in polynomial time, but when it comes to reducing some known NP complete problem to the class-room scheduling problem then I do not know which NP-complete problem I should take.\n\nI was thinking about using Traveling Salesman Problem to reduce, but I am not sure about how to interpret my class-room scheduling problem into a graph considering the symbolics. My first attempt to interpret my problem as a graph is to consider the classes as vertices, rooms as colours and the time for a class denoted by a weighted edge between two classes (the latter two interpretations completely unsure). But I don't know if this follows a standard pattern for some scheduling problem or I don't even know if Traveling Salesman Problem is a good NP-complete problem to reduce to the class-room scheduling problem. In the latter case, then I would like to know examples of more suitable NP-complete problems to reduce in my case.\n\nThanks in advance!\n    ", "Answer": "\r\nYou can use map-coloring (graph-coloring) for it. You just need to define rules for edges and nodes. Nodes will be classes, rooms will be colors and you connect classes that can't be in same time. This is actually k-coloring problem, where you need to color specific graph with k colors in order to minimize number of classes per color. However in this special case, you just need to have less or equal to t per color. You can achieve this by going by standard rule of coloring, and switch to new color as soon as it has t number of classes. \n\nThis is still a NP-complete problem. Only exception is when you have 1 or 2 classes, then its in polynomial time. When you have 1 room, you just need to check if ```\nn<=t```\n. When you have 2 rooms, you just need to check if it can be colored by 2 colors. You can achieve this by DFS (but first check if n <= 2t) and color odd steps with first color and even steps with second color. If it is possible to color all nodes with this tactic, you have a positive solution. When ```\nk>=3```\n, its NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What is the Big-O worst case running time for constraint satisfaction problems in general?\r\n                \r\nSince intractable constraint satisfaction problems in general are considered NP-complete problems, what is the Big-O worst case running time of NP-complete constraint satisfaction problems?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Does Reducing P or NP instance to NP-Complete make that instance also NP-Hard?\r\n                \r\nIf a Problem X lying in P or NP can be reduced to NP-Complete, is that problem X automatically an NP-Hard problem?\n    ", "Answer": "\r\nQuick reply: No, it does not.\n\nRecall the definition of NP-hard problems. \n\n\n  A problem X is NP-Hard if every problem in NP can be polynomially\n  reduced to X.\n\n\nIf on the other hand a problem X can be polynomially reduced to some NP-complete problem Y, it means that Y is at least as hard as X, not the other way around.\n\nFinally, if an NP-complete problem Z can be polynomially reduced to X, then indeed X is NP-hard as every problem W in NP can be reduced to Z and by combining the two reductions we can reduce W to X, so the definition is satisfied.\n\nQ: If a Problem X lying in P or NP can be reduced to NP-Complete, is that problem X automatically an NP-Hard problem?\n\nA: No\n\nQ: If a Problem X lying in P or NP is such that an NP-Complete problem can be reduced to it, is that problem X automatically an NP-Hard problem?\n\nA: Yes\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Confusion about why NP is contained in PSPACE, EXPTIME etc\r\n                \r\nHere's something that has puzzled me lately, and perhaps someone can explain what I'm missing. \n\nProblems in NP are those that can be solved on a NDTM in polynomial time. Now assuming P /= NP, PSPACE /= NP etc. this means that there are NP-complete problems that cannot be solved in polynomial time on a DTM. Which means that either they have some complexity that lies between polynomial and exponential (which I am not sure what that might be) or they must take exponential time on a DTM (and no more than polynomial space). If its the latter, then consider the PSPACE-complete problems. A problem is in PSPACE if it can be solved using a polynomial amount of space. Since NP \\subseteq PSPACE \\subseteq EXPTIME, PSPACE-complete problems must also take exponential time on a DTM. Then what is the practical difference between NP-complete and PSPACE-complete problems?\n    ", "Answer": "\r\nWell as far as I see it. The practical difference is the functionality of time.\nThe closer to the halting problem the longer the run....even if they equate.\nUnless provided with infinite time and space which wouldn't even be feasible let alone practical.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is the problem of finding the chromatic number of this modified interval graph NP-Complete?\r\n                \r\nFew days ago I was working on interval graphs to solve the known problem of resource allocation, as we know there is a greedy approach that solves this problem (chromatic number) in polynomial time and gives us the colors of each vertex in the interval graph (the problem of finding the chromatic number in general graphs is NP-Complete (3-satisfiability reduction by Karp)).\n\nI was wondering: if had a graph that is not an interval graph but it is because it has one and only one chordless cycle of length > 3 (there is an edge that, when you remove it, the graph becomes an interval graph), does it makes the problem of finding the chromatic number on this kind of graph NP-Complete?\n    ", "Answer": "\r\nKind of hand-wavey, if there's just a single edge which prevents the interval graph coloring algorithm from working, then remove it.  Run the interval graph algorithm.  If the two endpoints of the removed edge have different colors, you're done.  Otherwise, Let C be the number of colors that the algorithm used.  Try all (C choose 2) fixed colors for the two endpoints, and try the interval graph algorithm again.  If it succeeds with C colors, you're done.  Otherwise, you'll need C+1 colors so just pick one of the endpoints and give it a unique color.\n\nI'm assuming you can find the removable edge in poly time.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Please explain how the logic behind defining a new problem as NP-Complete is correct\r\n                \r\nThe logic used goes like this - we have an existing class of problems that are NP-Complete. Now a new problem \"Q\" comes up.\n\nStep 1 - We prove Q is in NP, well and good.\n\nStep 2 - We show that a problem in NP-C(say O) is reducible to Q. (O - > Q)\n\nNow we say that because O is NP-Hard, and because it is reducible to Q, Q must also be NP-hard since there is no simpler solution for O, and were Q a simpler solution, then we could just reduce O -> Q and solve Q.\n\nHowever, we don't know for sure yet that P!=NP. Maybe this new problem Q was the problem that could actually be solved in polynomial time, and that to solve each of the problems in NPC we only need to convert them to Q and then Q needs to be solved. If so, how is step 2 a valid proof for Q being NP-Hard?\n    ", "Answer": "\r\n```\nNP-hard```\n is a definition involving certain complexity classes, namely ```\nNP```\n and ```\nNP-complete```\n. The definitions do not refer to the complexity class ```\nP```\n. Poly-time reduction in itself does not refer to ```\nP```\n. Think of using a vocabulary from which the notion ```\nP```\n has been stripped.\n\nThe definitions and theorems thus remain valid when notion ```\nP```\n is introduced to the vocabulary. It may be the case that the notion ```\nP```\n is actually mathematically equivalent to the notion ```\nNP```\n. That still does not invalidate definitions and theorems phrased in terms of ```\nN```\n-notions, it would just open up a richer theory to discuss them.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "String to string correction problem np-completeness proof\r\n                \r\nI have this assignment to prove that this problem:\n\n\n  Finite alphabet £, two strings x,y €\n  £*, and a positive integer K.  Is\n  there a way to derive the string y\n  from the string x by a sequence  of K\n  or fewer operations of single symbol\n  deletion or adjacent symbol\n  interchange?\n\n\nis np-complete. I already figured out I have to make transformation from decision version of set covering problem, but I have no clue how to do this. Any help would be appreciated.\n    ", "Answer": "\r\nIt looks like modified Levenshtein distance. Problem can be solved with DP in quadratic time.\n\nTransformation from minimum set cover (MSC) to this string correction problem is described in:\n\n```\nRobert A. Wagner\nOn the complexity of the Extended String-to-String Correction Problem\n1975, Proceedings of seventh annual ACM symposium on Theory of computing \n```\n\n\nIn short with MSC problem:\n\nGiven finite sets x_1, ..., x_n, and integer L, does there exists a subset J of {1,...,n} such that |J| <= L, and\n\nunion_{j in J} x_j = union all x_i ?\n\nLet w = union all x_i, let t = |w| and r = t^2, and choose symbols Q, R, S not in w.\n\nTake strings:\n\n```\nA = Q^r R x_1 Q^r S^(r+1) ... Q^r R x_n Q^r S^(r+1)\nB = R Q^r ... R Q^r w S^(r+1) ... S^(r+1)   <- each ... is n times\nand\nk = (l+1)r - 1 + 2t(r+1)(n-1) + n(n-1)(r+1)^2/2 + (r*n + |x_1 ... x_n| - t)*W_d\n[W_d is delete operation weight, can be 1.]\n```\n\n\nIt is shown that string-string correction problems (A,B,k) is satisfiable iff source MSC problem is.\n\nFrom strings construction it is clear that proof is not trivial :-) But it isn't too complex to manage.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How is TSP NP-Hard?\r\n                \r\nI read the following in one of the answer on SO :\n\nThe Traveling Salesman Problem, as normally posed, is to find the cheapest route connecting all cities. That isn't a decision problem, and we can't verify any proposed solution directly. We can restate it as a decision problem: given a cost C, is there a route that's cheaper than C? This problem is NP-complete, and with a little work we can solve the original TSP about as easily as the modified, NP-complete, form. Therefore, the TSP is NP-hard, since it's at least as hard as an NP-complete problem.\n\nI understand that a TSP is NP-Complete but  how the problem is NP-Hard ? I read that problems that are in NP but not in P are NP-Hard. I cannot relate this thing to the TSP . Please explain this. \n    ", "Answer": "\r\nNP-Hard problems are those problems for which every problem in NP has a polynomial time (Cook or Karp, multiple definitions) reduction to. These could contain problems which are not in NP and in fact need not even contain decideable problems (like the Halting problem).\n\nNP-Complete problems are those problems in NP which are also NP-Hard.\n\nIf P is not equal to NP, then there are infinitely many problems in NP which are neither in P, nor NP-Complete (Ladner's theorem).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why does the formal procedure prove NP-Completeness? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI know how to show that a problem X is NP-Complete.\n\n\nShow that X ∈ NP.\nShow Y ≤p X: show a problem Y known to be NP-Complete can be reduced to X in polynomial time. \n\n\nHowever, I'm stuck on why this procedure proves that X is NP-Complete. Could someone explain this  in a relatively simple way?\n    ", "Answer": "\r\nNP Complete problem is defined to be a problem that is both NP-Hard and in NP (definition), so you basically need to show 2 things:\n\n\nThe problem is in NP (same as your 1)\nThe problem is NP-Hard\n\n\nYou can show (2) by 2 ways:\n\n\nProve directly that there is a reduction from every problem in NP to it (hard to do)\nShow a reduction from any known NP-Hard problem to your problem.\n\n\nThe thing is, reduction is transitive, so if you prove there is a reduction from some NP-Hard problem (let it be ```\nL1```\n) to your problem (Let it be ```\nL2```\n), you basically showed that there is a reduction from EVERY ```\nL```\n in NP to ```\nL1```\n (definition of NP-Hard), and from ```\nL1```\n to ```\nL2```\n (your reduction), thus the chain of these reductions (which is itself polynomial, neat things about polynoms), is a reduction by itself from every ```\nL```\n in NP to ```\nL2```\n (your problem).\n\nIn other words, since ```\nL <=p L1 <=p L2```\n for every ```\nL```\n, it follows that ```\nL <=p L2```\n for every ```\nL```\n as well, and this is the exact definition of NP-Hardness.\n\nThis way, you showed there is a reduction from every problem in NP to your problem, and this is the definition of NP-Hardness.\n\n\n\nSince showing directly that there is a reduction from EVERY ```\nL```\n in NP to a language, it was done once on SAT (Cook-Levin theorem) [twice actually...], and now you can use reductions to increase the number of known NP-Hard Problems.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Understanding Poly-time Reduction/NP-complete\r\n                \r\n\n\nHi there, I am having trouble understanding the relation of X and Y when problem X is reducible to Y. \n\nIn the question in the picture, I especially don't understand why a and b are not correct, if X is no harder than Y, then Y is at least as hard as X (?), then if X is NP-complete, wouldn't Y be at least NP-complete too?\n\nThank you\n\n(question source: https://introcs.cs.princeton.edu/java/55intractability/) \n    ", "Answer": "\r\nIt might help to reason by analogy here. Rather than thinking about problems and reducibility, let’s talk about people and how fast they run.\n\nLet’s define SO to be all the people who use Stack Overflow, and then define someone to be SO-fast if they can run at least as fast as anyone who uses Stack Overflow. We can then say that someone is SO-complete if they use Stack Overflow (they’re in SO) and also can run at least as fast as anyone on Stack Overflow (they’re SO-fast).\n\nNow, suppose that X can run no faster than Y and that Y is SO-complete. Does that mean that X is definitely SO-fast? Probably not. All we know that X can’t outrun someone who can run as fast as everyone on Stack Overflow. Maybe that means X can run just as fast as Y and is therefore also SO-fast, but it’s more likely that X isn’t nearly that fast. So, reasoning by analogy, do you see why option (a) is incorrect?\n\nNext, suppose X can run no faster than Y and that X is SO-complete. Does that mean that Y is SO-complete? The answer is no. I’m going to assume that Usain Bolt is not a Stack Overflow user, but I can guarantee you that Usain Bolt can outrun anyone on Stack Overflow. That means that Usain Bolt is SO-fast, but not SO-complete. Remember that SO-completeness has two components: you have to be fast, but you also have to be a Stack Overflow user. Knowing you can outrun the fastest Stack Overflow users says nothing about whether you yourself are on Stack Overflow. Does that account for why option (b) is incorrect?\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reduction from / to clique problem to prove problem is NP Complete\r\n                \r\nI've the following problem:\nGiven a set of males and a set of females, with rank between any two people equal to 0 or 1. Pick a subset of people such that:\n\n\nI want to maximize the number of liked people (total sum of all the ranks between any two people in the subset) over the total number people in the subset.\nIn the picked subset of people there must be an equal number of males and females.\n\n\nMy questions are: in order to show np-completeness of this problem I know clique problem reduction can be used... Does anyone can provide an example on how to carry out this reduction? Do I need a reduction FROM or TO clique problem? \nMany thanks \n    ", "Answer": "\r\nTo answer your question, you need a reduction FROM clique problem to the problem you are currently dealing with since clique is a known NP-complete problem.\n\nAs for your hints with your transformation process (from known Clique problem to your Ranking problem), a good way to think of this is how would you reduce the scenario of clique to your problem. I am assuming 1 means \"linked people\" and 0 means \"unliked people\" in your problem.\n\nTake each person as our vertex in graph G(assumed given graph in clique problem). To distinguish between male and female, we would mark male group as A1,A2,A3...Am, female group as B1,B2,B3...Bf. Now we can draw edges to each pair of people whose rank is 1 between them(liked people). Suppose N(N>=1) cliques formed after the graph is done. \n\nNow, we remove the vertices in each clique that makes the clique has unequal number of As and Bs(to provide equal number of vertices in both genders). Now the largest clique with number K is the one you will be looking for.\n\nThis transformation is supposed to be done in polynomial time since what we are doing is sheerly reconstructing our clique graph and labelling them(and removing them). It would be of O(V+E) to perform such transformation.\n\nLater, you will be required to prove the answers works both way between your problem's answer and the clique problem answer if you want to prove that your problem is NP-complete. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Question about nSudoku if we assume that it is NP-complete\r\n                \r\nExplain why each of the following statements is correct. You may assume that nSudoku is NP-complete.\nIf nSudoku can be reduced in polynomial time to factorization, then factorization is NP-complete.\nIf nSudoku can be reduced in polynomial time to the problem of sorting an integer array, then P = NP.\nAny ideas how to explain? Thank you!!!\n    ", "Answer": "\r\nIn order to determine if a problem (A) is NP-Complete, we must take four steps:\n\n\nProve that A is in NP\nTransform a known NP Complete problem (B) into A in polynomial time\nProve that an answer to A is an answer to B\nProve that an answer to B is an answer to A\n\n\nIn your problem, you start with the known NP-Complete problem nSudoku, with the goal to first show that factorization is also NP-Complete. To do this, we would first show that factorization is in NP. You then provide the information that nSudoku can be transformed to factorization in polynomial time. If we then show that an answer to nSudoku is an answer to factorization and vice versa, then we have proven that factorization is NP-Complete.\n\nWe will then follow this same pattern for factorization and the problem of sorting an integer array to prove that the problem of sorting an integer array is NP Complete (starting with the fact that factorization is in NP). This, however, complicates things, because the problem of sorting an integer array is actually in P, as you can sort an integer array in O(nlogn), which is polynomial time.\n\nAt the core of this question is the \"P versus NP problem\", which is an unsolved problem that asks whether every problem in NP is really in P (in other words if every problem that has a decision problem that can be verified in polynomial time can ALSO be solved in polynomial time). To this date, there is no answer to the problem.\n\nHowever, in your problem we prove that a problem that is known to be P is also NP complete, which then results in the conclusion stated in your problem that P=NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Np class of problems\r\n                \r\nAre All problems in NP are known to be reducible to one another.\nI know if a problem X is in NP and any NP problem Y in NP is reducible to X then X is NP-complete. So by this assumption can we state that all NP problems are reducible to one another?\n    ", "Answer": "\r\n```\nA decision problem C is NP-complete if:\n\nC is in NP, and\nEvery problem in NP is reducible to C in polynomial time. \n```\n\n\nSource: https://en.wikipedia.org/wiki/NP-completeness\n\nIf all NP problems are reducible to one another, it would mean that all NP problems are NP complete, which we can not say since we still can't prove whether ```\nP = NP```\n\nRefer to the image below for a better understanding.\n\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "proof NP-complete\r\n                \r\nHi guys I have a question. I am wondering if anyone know how to proof it.\nHere is the question:\nThe Subset Sum problem is shown to be NP-complete. The input is a sequence of positive numbers w1, ... ,wn, W, where W is the target weight. The problem is to decide whether there is a set of weights F ⊆ {1, ... ,n} such that the the sum of some weights equal to the target weight (i.e. w1 + ... + wi = W)\nLet the Restricted Subset Sum problem be defined like Subset Sum, but with the extra requirement that the target weight is less than half the sum of all weights. (If this fails then the input must be rejected right away.) Show that Restricted Subset Sum is NP-complete.\nThank you.  \n    ", "Answer": "\r\nYou have to show (a) your problem is in NP and (b) your problem is NP hard. For (a), show that a solution to some problem in NP would make solving your problem easy (if you think about it, showing this is trivial). For (b), you need to show that a solution to your problem would make solving any problem in NP easy (in other words, find another NP-complete problem whose solution can be rephrased in terms of a solution to your problem).\n\nThis is already practically half the proof - (a) is trivial now - I'd prefer not to do the rest.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Heuristics for this (probably) NP-complete puzzle game\r\n                \r\nI asked whether this problem was NP-complete on the Computer Science forum, but asking for programming heuristics seems better suited for this site. So here it goes.\n\nYou are given an NxN grid of unit squares and 2N binary strings of length N. The goal is to fill the grid with 0's and 1's so that each string appears once and only once in the grid, either horizontally (left to right) or vertically (top down). Or determine that no such solution exists. If N is not fixed I suspect this is an NP-complete problem. However are there any heuristics that can hopefully speed up the search to faster than brute force trying all ways to fill in the grid with N vertical strings?\n    ", "Answer": "\r\nI remember programming this for my friend that had the 5x5 physical version of this game, but I used brute force back then. I can only think of this heuristic:\n\nConsider a 4x4 map with these 8 strings (read each from left to right):\n\n```\n1 1 0 1\n1 0 0 1\n1 0 1 1\n1 0 1 0\n\n1 1 1 1\n1 0 0 0\n0 0 1 1\n1 1 1 0\n```\n\n\n(Note that this is already solved, since the second 4 is the first 4 transposed)\n\nFirst attempt:\n\nWe will choose columns from left to right. Since 7 of 8 strings start with ```\n1```\n, we will try to put the one with most ```\n1```\ns to the first column (so that we can lay rows more easily when columns are done).\n\nIn the second column, most string have 0, so you can also try putting a string with most zeros to the second row, and so on.\n\nThis i would call a wide-1 prediction, since it only looks at one column at a time\n\n(Possible) Improvement:\n\nYou can look at 2 columns at a time (a ```\nwide-2```\n prediction, if i may call it like that). In this case, from the 8 strings, the most common combination of first two bits is ```\n10```\n (5/8), so you would like to choose first two columns so the the combination ```\n10```\n occurring as much as possible (in this case, ```\n1111```\n followed by ```\n1000```\n has 3 of 4 ```\n10```\n at start).\n\n(Of course you don't have to stop at 2)\n\nWeaknesses:\n\n\nI don't know if this would work. I just made it up and thought it might work.\nIf you choose to he ```\nwide-X```\n prediction, the number of possibilities is exponential with ```\nX```\n\nThis can absolutely fail if the distribution of combinations if even.\n\n\nWhat you can do:\n\nAs i said, this game has physical 5x5 adaptation, only there you can also lay the string from right-to-left and bottom-to-top, if you found that name, you could google further. I unfortunately don't remember it.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Example of longest path problem having a NP complexity?\r\n                \r\nI saw on the internet that finding the longest path problem is NP-Complete problem.\n\nFor some reason, my teacher tells me that it isn't an NP-complete problem.\nSo now I am looking for an example that shows the amount of computation needed for getting the longest path is bigger then polynomial time.\n\nfor now, I saw only examples of it having a polynomial complexity time.\n\nanyone can bring me a proof for this problem being NP-complete?\n    ", "Answer": "\r\nFor starters, depending on how you phrase the longest path problem, it may actually be the case that the problem is NP-hard but not NP-complete. The NP-complete version of this problem is the following:\n\n\n  Given a graph G and a length k, does G have a simple path of length k or more?\n\n\nThis problem is known to be NP-complete for reasons I'll detail later on. However, this closely-related problem is not actually NP complete:\n\n\n  Given a graph G, what is the longest simple path in G?\n\n\nThis second problem is NP-hard but not NP-complete. For a problem to be NP-complete, the problem has to be a decision problem, a problem whose answer is a boolean \"yes\" or \"no.\" This second version of the problem, however, isn't a decision problem, and so it can't be in NP, and so it can't be NP-complete. It's entirely possible that your teacher was thinking about this when saying that the longest path problem isn't NP-complete, though I can't say for certain.\n\nAs for why the longest path problem is NP-complete, we need to argue two points:\n\n\nThis problem is in NP. Intuitively, there's an efficient way to check yes answers to the problem.\nThis problem is NP-hard. That is, there's an NP-hard problem that reduces to it.\n\n\nFor point (1), the intuition is that if the answer to the question \"does this graph have a simple path of length 137 or more?\" is \"yes,\" there's some easy way to demonstrate this to someone. Just give them that simple path. Once they have the path, it's easy for them to check that, indeed, it meets the requirements. (Now, finding that path might be really hard. But once we've somehow isolated it, it's not hard to convince people that it works.)\n\nFor point (2), the general way to do this is to start with an existing NP-hard problem and to reduce it to our problem. Here, we'll start with the Hamiltonian path problem, which is the following:\n\n\n  Given a graph G, is there a simple path that passes through every node in G once and exactly once?\n\n\nHere's how we reduce that problem to the longest path problem. Start with the graph G. Now, ask the question: does G have a simple path of length at least n - 1, where n is the number of nodes in G? If so, then that simple path has to visit every node once and exactly once, since otherwise there aren't enough nodes in the path to make its length at least n - 1. And conversely, if not, then there's no Hamiltonian path, since any Hamiltonian path would fit the bill. Therefore, if we can solve the longest path problem efficiently, we can solve the Hamiltonian path problem efficiently. Since the Hamiltonian path problem is NP-hard, so is the longest path problem.\n\nNow, the fact that this problem is NP-complete doesn't mean that there is no polynomial-time solution for it. The P versus NP problem still hasn't been resolved, and without knowing whether P = NP or P ≠ NP we can't say whether there's a polynomial-time algorithm for the longest path problem. What we can say is that no known algorithms for it run in polynomial time (you mentioned some sites claim they have polynomial-time algorithms for this problem, but that doesn't sound right; if so, whoever found that algorithm would be a millionaire).\n\nNow, there's a follow-up question you can ask: why is the Hamiltonian path problem NP-hard? The usual way to prove this is to start with 3SAT and to do a clever, gadget-based reduction. That's way too long to explore here, but most intro theory textbooks (including Sipser's famous one) do a great job of explaining this.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Bounded PCP NP-Complete Proof\r\n                \r\nI'm looking for a simple proof that shows that the Bounded-PCP problem belongs to NP-Complete as many text books say so. It is clear to me that the problem is decidable but I cannot find any reduction from an NP-Hard problem to this one.\n\nMoreover, the verifying algorithm might go through a series of N indexes which is exponential in comparison to the input size (N) which is logN, so how can this problem be in NP?\n\nThanks.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If Y is reducible to X in polynomial time, then how is it true that X is at least as hard as Y?\r\n                \r\nI am having difficulty understanding the relationship between the complexity of two classes of problems, say NP-hard and NP-complete problems.\nThe answer at https://stackoverflow.com/a/1857342/ states:\n\nNP Hard\nIntuitively, these are the problems that are at least as hard as the NP-complete problems. Note that NP-hard problems do not have to be in NP, and they do not have to be decision problems.\nThe precise definition here is that a problem ```\nX```\n is NP-hard, if there is an NP-complete problem ```\nY```\n, such that ```\nY```\n is reducible to ```\nX```\n in polynomial time.\n\nIf a problem ```\nY```\n can be reduced to ```\nX```\n in polynomial time, should we not say that ```\nY```\n is at least as hard as ```\nX```\n? If a problem ```\nY```\n is reducible to ```\nX```\n in polynomial time, then the time required to solve ```\nY```\n is polynomial time + the time required to solve ```\nX```\n. So it appears to me that problem ```\nY```\n is at least as hard as ```\nX```\n.\nBut the quoted text above says just the opposite. It says, if an NP-complete problem ```\nY```\n is reducible to an NP-hard problem ```\nX```\n, then the NP-hard problem is at least as hard as the NP-complete problem.\nHow does this make sense? Where am I making an error in thinking?\n    ", "Answer": "\r\nYour error is in supposing that you have to solve X in order to solve Y. Y might be actually much easier, but one way to solve it is to change it to an instance of X problem. And since we are in big O notation and in NP class we are way past linear algorithms, you can always safely discard any linear parts of an algorithm. Heck you can almost safely discard any polynomial parts until P=NP problem is solved. That means ```\nO(f(n) + n) = O(f(n))```\n where ```\nn=O(f(n))```\n.\n\nExample (which is obviously with neither NP-hard or NP-complete problems but just a mere illustration): You are to find the lowest number in an unsorted array of n numbers. There is obvious solution to iterate over the whole list and remember the lowest number you found, pretty straight-forward and solid O(n).\n\nSomeone else comes and says, ok, let's change it to sorting the array, then we can just take the first number and it will be the lowest. Note here, that this conversion of the problem was O(1), but we can for example pretend there had to be some preprocessing done with the array that would make it O(n). The overall solution is O(n + n*log(n)) = O(n * log(n)).\n\nHere you too changed easy problem to a hard problem, thus proving that the hard problem is indeed the same or harder as the easy one.\n\nBasically what the NP-hard problem difinition means is, that X is at least as hard as an NP-complete Y problem. If you find an NP-complete Y problem that you can solve by solving X problem, it means either that X is as hard or harder than Y and then it is indeed NP-hard, or if it is simpler, it means you found an algorithm to solve Y faster than any algorithm before, potentially even moving it out of NP-complete class.\n\nAnother example: let's pretend convolution is in my set of \"complete\", and normally takes O(n²). Then you come up with Fast Fourier Transformation with O(n * log(n)) and you find out you can solve convolution by transforming it to FFT problem. Now you came up with a solution for convolution, which is o(n²), more specifically O(n * log(n)).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What are NP-Intermediate problems?\r\n                \r\nAssuming P != NP\n\nThe euler diagram shows a part not part of P and NP-complete. I read on wikipedia that this set is called NP-Intermediate.\n\nEuler Diagram\n\nI have some doubts as to how are NPI problems defined?\n    ", "Answer": "\r\nAn NP-intermediate problem is a decision problem that\n\n\nis in NP (that is, \"yes\" answers can be verified in polynomial time),\nis not in P (that is, there is no polynomial-time algorithm for solving the problem), and\nis not NP-complete.\n\n\nThat last criterion can be stated in a number of different ways. One way to say this is that there is no polynomial-time mapping reduction from SAT to that particular problem.\n\nThese problems are primarily of theoretical interest right now because we don't know if any NP-intermediate problems exist - if we could find one, we'd have a problem in NP that's not in P, meaning that P ≠ NP! However, they're interesting because if we can prove that P ≠ NP, then we know that there are some problems in NP that are too hard to be solved in polynomial time, but which aren't among the \"hardest\" of the hard problems in NP (the problems that are NP-complete).\n\nIn the event that P = NP, then there would not be any NP-intermediate problems because you couldn't have a problem in NP but not in P. If P ≠ NP, then Ladner's theorem guarantees at least one NP-intermediate problem exists, but does so by specifically constructing a problem that is highly artificial and designed solely to be NP-intermediate in that case. Right now, with a few exceptions (notably the graph isomorphism problem), all the problems we know of in NP are either squarely in P or known to be NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity of Some problems in NP?\r\n                \r\nI want to summarize some problem on Complexity. Which of them can be solved in poly-time? \n\n\n  I) finding maximal sub complete graph of given graph = Clique Problem\n  \n  II) select some elements among ```\nn```\n objects in which value and weights\n  are given, such that sum of weights of selected elements is not bigger\n  than an specific bound and sum of value being maximum\n  \n  III) finding all cycles of a graph\n  \n  IV) Finding a path that visit each vertex exactly once = Determine a graph is Hamiltonian \n\n\nI think IV is Hamiltonian path that is NP-Complete, III is NP-Hard and NP-Complete, II is NP-Complete, and I is NP-Complete. so 0 of these solved in poly-time. \n\nWho can more clearer me about NP-Hard and NP-Complete of these problem in a nice way? Am I right?\n    ", "Answer": "\r\nAs you've noted, parts (1), (2), and (4) are all famous NP-hard problems (max clique, knapsack, and Hamiltonian path). These problems are not in NP, though, because NP consists of decision problems (questions for which the answer is either \"yes\" or \"no\") and these are not decision problems.\n\nPart (3) is more nuanced. This problem is a counting problem - the goal is to determine how many objects of some type exist - rather than a decision problem, so it can't be in NP. To the best of my knowledge, it's not really known how hard this problem is. It's known that if it can be solved in polynomial time, then P = NP (see this link for details), and the specific proof shows that it's NP-hard as well.\n\nIf P ≠ NP, then none of these can be solved in polynomial time. If any of these can be solved in polynomial time, then P = NP. They are all NP-hard.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "what is the Non-cyclical definition of NP-hard?\r\n                \r\nI am trying to comprehend the concepts NP, NP complete and NP hard according to Wikipedia. \n\nIf I inderstand the given text correctly:\n\nEDIT: corrected according to David\n\nNP == decision problem whose answer can be verified in polynomial time (given the solution)\n\nNP complete == NP and NP hard simultaneously\n\nNP hard == there is a NP complete problem which is polynomial time Turing reducible to it.\n\nSo in order to understand the concept of NP completeness, I need to understand the NP hardness first. So I try to analyze what is NP hard according to the above statements. So I get:\n\nNP hard == there is a problem which is NP hard  and NP simultaneously, which is reducible to it. But there is a cycle in the definition. What is the noncyclical definition?\n    ", "Answer": "\r\nYou can also define NP-complete as a problem such that any NP-problem can be reduced to it in polynomial time. That definition should remove your cycle.\n\nYour definition of NP-hard seems backwards. It should be that a problem is NP hard if some NP-complete problem (thus any NP problem) can be reduced to it in polynomial time.\n\nYou can see more detail here: http://en.wikipedia.org/wiki/P_versus_NP_problem\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this bipartite graph optimization task NP-complete?\r\n                \r\nI have been trying to find out a polynomial-time algorithm to solve this problem, but in vain. I'm not familiar with the NP-complete thing. Just wondering whether this problem is actually NP-complete, and I should not waste any further effort trying to come up with a polynomial-time algorithm.\n\nThe problem is easy to describe and understand. Given a bipartite graph, what is the minimum number of vertices you have to select from one vertex set, say A, so that each vertex in B is adjacent to at least one selected vertex.\n    ", "Answer": "\r\nUnfortunately, this is NP-hard; there's an easy reduction from Set Cover (in fact it's arguably just a different way of expressing the same problem).  In Set Cover we're given a ground set F, a collection C of subsets of F, and a number k, and we want to know if we can cover all n ground set elements of F by choosing at most k of the sets in C.  To reduce this to your problem: Make a vertex in B for each ground element, and a vertex in A for each set in C, and add an edge uv whenever ground element v is in set u.  If there was some algorithm to efficiently solve the problem you describe, it could solve the instance I just described, which would immediately give a solution to the original Set Cover problem (which is known to be NP-hard).\n\nInterestingly, if we are allowed to choose vertices from the entire graph (rather than just from A), the problem is solvable in polynomial time using bipartite maximum matching algorithms, due to Kőnig's Theorem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Can a genetic algorithm optimize my NP-complete problem?\r\n                \r\nI have an array that stores a large collection of elements.\nAny two elements can be compared in some function with the result being true or false.\nThe problem is to find the largest or at least a relatively large subgroup, where every element with all the others in that subgroup is in a true relationship.\nFinding the largest subgroup from an array of size N requires N! operations, so the iterative way is out.\nRandomly adding successive matching elements works, but the resulting subgroups are too small.\nCan this problem be significantly optimised using a genetic algorithm and thus find much larger subgroups in a reasonable time?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Showing NP, NP-Completeness, or NP-Hardness\r\n                \r\nIs my understanding of the three categories correct?\n\nTo show a problem X is NP:\n\n\nShow that X can be verified deterministically in polynomial time (Or\nX is solvable using a NTM)\n\n\nTo show a problem X is NP-Complete:\n\n\nShow that X can be verified deterministically in polynomial time(Or\nX is solvable using a NTM) \nShow that given a known NP-C problem L, L ≤p X \nShow that given a known NP-C problem L, X ≤p L (Is this step\nnecessary? If so, is this what differentiates a purely NP-Hard\nproblem from a NP-C problem?)\n\n\nTo show a problem X is NP-Hard:\n\n\nShow that given a known NP-C problem L, L ≤p X\n\n    ", "Answer": "\r\nYou almost got it.\n\nGiven a problem ```\nX```\n, to show it is NPC, you don't need to show ```\nX ≤p L```\n, for some NPC problem ```\nL```\n.\n\nIn fact, this is guaranteed, since you already showed that ```\nX```\n is in NP (in 1), and you know ```\nL```\n is NP-Complete. By definition of NP-Complete, this means there is a polynomial time reduction from ALL problems in NP to ```\nL```\n, including from ```\nX```\n, so basically your step (3) in proving NPC is redundant.\n\n\n\nA more elegant way to show the statements of what needs to be done to prove each property:\n\nTo show ```\nX```\n is NP:\n\n\nShow that X can be verified deterministically in polynomial time (Or X is solvable using a NTM)\n\n\nTo show ```\nX```\n is NP-Hard:\n\n\nShow that given a known NP-Hard problem L, L ≤p X\n\n\nOR\n\n\nShow that for any problem ```\nL```\n in NP, L ≤p X (this is done only once actually, for SAT, and is the definition of NP-Hard).\n\n\nTo show a problem X is NP-Complete:\n\n\nShow X is NP-Hard\nShow X is in NP\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "3-OCC-MAX SAT np-complete?\r\n                \r\nAssuming 3-OCC-MAX SAT is the language of all CNF formulas in which every variable appears in at most 3 clauses.\nIs this problem NP-Complete? I'm trying to find a karp reduction between SAT and this problem, but I couldn't find it.\n    ", "Answer": "\r\nThis problem is NP-complete. It is easy to see that it is in NP (guessing a model; check it in polynomial time).\nFirst Attempt (Failure)\nTo show NP-hardness, I propose the following construction:\nConsider a 3-SAT instance F over n variables.\nConsider a clause ```\n[L1, L2, L3]```\n.\nDefine fresh variables p1, p2, p3.\nDefine Li equivalent to pi.\nAfterwards, replace the original clause using the fresh variables.\nThis results in clauses of the form:\n```\n[p1, p2, p3]\n[-p1, L1]\n[-L1, p1]\n[-p2, L2]\n[-L2, p2]\n[-p3, L3]\n[-L3, p3]\n```\n\nDo this for all clauses and always use fresh variables.\nNote that the variables p1 to p3 are used exactly three times, whereas L1 till L3 are used twice.\nThis construction is polynomial.\nEDIT: I currently see that this is not a valid solution yet: The original literals may exceed the maximum occurence of 3.\nSecond Attempt\nThe idea is to use fresh variables for every apperance of a literal.\nLet M be the number of appearences of variables in the 3SAT formula (this can be improved).\nFor every atom A in the 3SAT CNF, add the following to the resulting the 3-OCC-MAX SAT formula:\n```\nq0 <- A\nq1 <- q0\nq2 <- q1\nq3 <- q2     \nq4 <- q3\n...\nq_M <- q_M-1\nq_M+1 <- q_M\nq0 <- q_M+1\n```\n\nDo the same for the occurences of -A.\n```\np0 <- -A\np1 <- p0\np2 <- p1\np3 <- p2     \np4 <- p3\n...\np_M <- p_M-1\np_M+1 <- p_M\np0 <- p_M+1\n```\n\nFurthermore, add the following to ensure that either the q-row or the p-row is true.\n```\n-p0 <- qM+1\n-q0 <- pM+1\n```\n\nNow, add the clauses of the original 3SAT CNF, in which the n-th occurence of the literal L is replaced by qn.\nThere is no \"0-th occurence\", i.e. we start counting by 1; therefore q0 and p0 as well as qM and pM are not used in this context.\nNote that A and -A appears 2x, the variable p0, q0, p_M+1, q_M+1 three times and the variables p_i, q_i, where i is between 1 and M at most three times.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Looking for a model to represent this problem, which I suspect may be NP-complete\r\n                \r\n(I've changed the details of this question to avoid NDA issues. I'm aware that if taken literally, there are better ways to run this theoretical company.)\n\nThere is a group of warehouses, each of which are capable of storing and distributing 200 different products, out of a possible 1000 total products that Company A manufactures. Each warehouse is stocked with 200 products, and assigned orders which they are then to fill from their stock on hand.\n\nThe challenge is that each warehouse needs to be self-sufficient. There will be an order for an arbitrary number of products (5-10 usually), which is assigned to a warehouse. The warehouse then packs the required products for the order, and ships them together. For any item which isn't available in the warehouse, the item must be delivered individually to the warehouse before the order can be shipped.\n\nSo, the problem lies in determining the best warehouse/product configurations so that the largest possible number of orders can be packed without having to order and wait for individual items.\n\nFor example (using products each represented by a letter, and warehouses capable of stocking 5 product lines):\n\n```\nWarehouse 1: [A, B, C, D, E]\nWarehouse 2: [A, D, F, G, H]\n\nOrder: [A, C, D] -> Warehouse 1\nOrder: [A, D, H] -> Warehouse 2\nOrder: [A, B, E, F] -> Warehouse 1 (+1 separately ordered)\nOrder: [A, D, E, F] -> Warehouse 2 (+1 separately ordered)\n```\n\n\nThe goal is to use historical data to minimize the number of individually ordered products in future. Once the warehouses had been set up a certain way, the software would just determine which warehouse could handle an order with minimal overhead.\n\nThis immediately strikes me as a machine learning style problem. It also seems like a combination of certain well known NP-Complete problems, though none of them seem to fit properly.\n\nIs there a model which represents this type of problem?\n    ", "Answer": "\r\nIf I understand correctly, you have to separate problems :\n\n\nPredict what should each warehouse pre-buy\nGet the best warehouse for an order\n\n\nFor the first problem, I point you to the netflix prize : this was almost the same problem, and great solutions have been proposed. (My datamining handbook is at home and I can't remember for precise keyword to google, sorry.Try \"data mining time series\" )\n\nFor the second one, this is a problem for Prolog.\n\n\nSet a cost for separately ordering an item\nSet a cost, for, idk, proximity to the customer\nSet the cost for already owning the product to 0\nMake the rule to get a product : buy it if you don't have it, get it if you do\nMake the rule to get all products : foreach product, rule above\nget the cost of this rule\nGently ask Prolog to get a solution. If it's not good enough, ask more.\n\n\nIf you don't want to use Prolog, there are several constraints libraries out there. Just google \"constraint library ```\n<insert your programming language here```\n>\"\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Steiner Minimal Trees and NP-completeness\r\n                \r\nWhat is the difference between the following Steiner trees: (Non-)Metric Steiner Minimal Tree, Euclidean Steiner Minimal Tree, Graph Steiner Minimal Tree, etc? Which of these are NP-complete and which are NP-hard? Some of the online resources I found suggest that Steiner trees are NP-hard, and others suggest it's NP-complete, but I believe they are referring to different versions/variants of the problem.\n\nUpdate: nevermind, I've figured it out. The decision problem of SMT is NP-complete because, given a Steiner tree and an integer k, it is easy to verify in polynomial time whether the cost of the tree is less than or equal to k. But the optimization problem of SMT does not have a polynomial time verifier (we can still find the cost of the tree, but we cannot verify that it is the optimal solution), so it's NP-hard.\n    ", "Answer": "\r\nI was confused by NP-completeness and NP-hardnesses of problems a lot, especially since it sometimes looks like they are used interchangeably. \n\nThe catch is very simple. NP-complete is a subclass of NP which is the class of polynomial time verifiable decision problems. So only decision problems can be NP-complete, and an optimization problem is never NP-complete. \n\nNP-Hard means just any problem that's at least as hard as NP-complete, including both decision and optimization problems. Therefore all NP-Complete decision problems are also NP-Hard. If a decision problem is NP-Complete the optimization version is NP-Hard because if you have a solution to the optimization, you can also use it to answer the decision problem. However the converse is not necessarily true. \n\nSo technically per definition, even if the optimization problem had a polynomial time verifier it would still not be NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is Shortest Hamiltonian path NP-hard?\r\n                \r\nHamiltonian Path is a path that connects all nodes without repeat and it is an NP-complete problem.\n\n\nIs the Shortest Hamiltonian Path (SHP) NP-hard?\nWhat is the difference between travelling salesman problem with SHP?\n\n    ", "Answer": "\r\nI assume the SHP problem is the Hamiltonian problem on the edge weighted graph. It is NP-hard because it is at least as hard as the Hamiltonian problem. Assume you have an algorithm to solve the SHP problem, then you apply the algorithm on a weighted graph with all edge weights are 1, it will solve the Hamiltonian problem with the same time complexity. \n\nTSP requires to return to the original vertex and you can visit each vertex more one once. SHP asks for the path which visits every vertex exactly once.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "np-completeness in the bounded degree spanning tree\r\n                \r\nI understand why the Bounded Degree Spanning Tree is considered NP Complete with a degree or 2 (it is an instance of the Hamiltonian Path Problem), but I do not understand why this applies to degrees > 2. If someone could please explain why this is an NP Complete problem for degree > 2, It would be most helpful\n    ", "Answer": "\r\nWell, I think that you can make a simple reduction from the instance of bounded by 2, to the instance of General k.\n\nIntuitivly, we will connect to each node of the original graph new k-2 nodes. Therefore every spanning tree will have to contain the k-2 edges from the original node to the new nodes that we connected to him, and a spanning tree from degree at most k exists if there is a spanning tree of degree at most 2 for the original graph.\n\nThe formal reduction will be:\n\nF(V,E)=(V',E'), when : V'={(v,i)|v is in the original graph, 0 < i < k+1), E' = E U {((v,0),(v,i))}, and I don't write a formal proof for the correctness because after all we are not in a math forum.\n\nGood luck and hope that it helped :)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reduction between problems in NP\r\n                \r\nBy definition, any problem in NP can be reduced to a problem in NP-Complete. However, let's say we have two arbitrary problems X and Y in NP. Is it necessarily true that X is reducible to Y?\n\nI'm unclear on the aspect of reduction between two arbitrary problems of a particular complexity class, so any guidance would be appreciated.\n    ", "Answer": "\r\nIn principle there is no reason why an arbitrary problem should be reducible to another.\n\nFor a concrete example, it is known that factorization of an arbitrary integer with ```\nn```\n bits is in ```\nNP```\n, but it is is believed to both not be in ```\nP```\n and not to be ```\nNP```\n-complete.  Therefore traveling salesman is not reducible to integer factorization.\n\nhttps://en.wikipedia.org/wiki/NP-intermediate has a list of other problems that are in the same category, and there is no reason to believe that, for example, graph isomorphism is reducible to factoring or vice versa.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this a correct understanding of proving something is NP Complete?\r\n                \r\nAs I understand it there are two steps to proving that a problem is NP complete:\n\n\nGive an algorithm that can verify a solution to the problem in polynomial time. That is, an algorithm whose input is a proposed solution to the problem and whose output is either \"yes\" or \"no\" based on whether the input is a valid solution to the problem.\nProve the problem is NP hard - eg, assume you have an oracle that can compute another known NP complete problem in one step.  Using that, write an algorithm that solves this problem in polynomial time.\n\n\nFor example, suppose we want to prove that the following problem is NP Complete:\n\nGiven a set of integers, ```\nS```\n, is it possible to isolate a subset of elements, ```\nS'```\n, such that the sum of the elements in ```\nS'```\n is exactly equal to the sum of the remaining elements in ```\nS```\n that are not included in ```\nS'```\n?\n\nStep 1: Verification algorithm\n\n```\nVerify_HalfSubset(Set S, Solution sol):\n    accum = 0\n    for each element i in sol:\n        accum+=i\n        linear search for an element with the same value as i in S.\n        if found, delete it from s, if not found, return false\n    end for\n    accum2 = 0\n    for each element i in S:\n        accum2+=i\n    end for\n    if accum==accum2 return true, else return false\n```\n\n\nClearly this runs in polynomial time: The first for loop runs in ```\nO(nm)```\n and the second runs in ```\nO(n)```\n.\n\nStep 2: Reduction\n\nAssume we have an oracle ```\nO(Set S, int I)```\n that computes the subset sum problem in a single step (that is, is there a subset of elements in S that sum up to I)?\n\nThen, we can write a polynomial time algorithm that computes our half-subset problem:\n\n```\nHalfSubset(Set S):\n    accum = 0\n    for each s in S:\n        accum+=S\n    end for\n    if(accum%2==1) \n    // this question forbids \"splitting\" values to non-integral parts\n        return NO_ANSWER\n    end if\n    half1 = O(S, accum/2)\n    if(half1 == NO_ANSWER)\n        return NO_ANSWER\n    end if\n    for each i in half1:\n        linear search for an element with the same value as half1[i] in S\n        delete it from S.\n    end for\n    half2 = S\n    return (half1 and half2)\n```\n\n\nCan someone please tell me if I've made any mistakes in this process? This is the one question on my final exam review that I'm not entirely sure I understand completely.\n    ", "Answer": "\r\nThe second portion of your answer is a bit off. What you are saying in step two is that you can reduce this problem to a known NP-complete problem in polynomial time. That is, you are saying that this problem is at most as hard as the NP-complete problem. \n\nWhat you want to say is that the NP-complete problem can be reduced to your example problem in polynomial time. This would show that, if you could solve this problem in polynomial time, then you could also solve the NP-complete problem in polynomial time, proving that your example problem is NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "proof of SAT np completeness\r\n                \r\nI know if we want to prove the np completeness of some problem we must show these :\n\nthere is a nondeterministic polynomial solution for the problem\nall other np problems are reducible to the problem\nin the case of sat problem it's easy to show \"there is a nondeterministic polynomial solution for the SAT problem\" but I don't know how to prove \"all other np problems are reducible to the SAT problem\"\n\n    ", "Answer": "\r\n\nbut I don't know how to prove \"all other np problems are reducible to the SAT problem\"\n\nThis is known as the Cook Levin Theorem: https://en.wikipedia.org/wiki/Cook%E2%80%93Levin_theorem .\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are all scheduling problems NP-Hard?\r\n                \r\nI know there are some scheduling problems out there that are NP-hard/NP-complete ... however, none of them are stated in such a way to show this situation is also NP.\n\nIf you have a set of tasks constrained to a startAfter, startBy, and duration all trying to use a single resource ... can you resolve a schedule or identify that it cannot be resolved without an exhaustive search?\n\nIf the answer is \"sorry pal, but this is NP-complete\" what would be the best heuristic(s?) to use and are there ways to decrease the time it takes to a) resolve a schedule and b) to identify an unresolvable schedule.\n\nI've implemented (in prolog) a basic conflict resolution goal through recursion that implements a \"smallest window first\" heuristic. This actually finds solutions rather quickly, but is exceptionally slow at finding invalid schedules. Is there a way to overcome this?\n\nYay for compound questions!\n    ", "Answer": "\r\nThe hardest part of most scheduling problems in real life is getting hold of a reliability and complete set of constraints. If we take the example of creating a university timetable:\n\n\nProfessor A will not get up in the morning, he is on a lot of committees, but  no-one will tell the timetable office about this sort of constraint\nDepartment 1 needs the timetable by the start of term, however, Department 2 that uses the same rooms is unwilling to decide on the courses that will be run until after all the students have arrived\nEtc\n\n\nThen you need a schedule system that can cope with changes, so when one constraint is changed at the last minute you don’t have to change the complete timetable.\n\nAll of the above is normally ignored in research papers about scheduling systems.  As to NP completeness of a given scheduling problem, in real life you don’t care as even if it is not NP complete you are unlikely to even be able to define what the “best solution” is, so good enough is good enough.\n\nSee http://www.asap.cs.nott.ac.uk/watt/resources/university.html for a list of papers that may help get you started; there are still many PHDs to be had in scheduling software.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is generating all strings permutation NP Complete?\r\n                \r\nCalculating all string permutations of a given string can be solved in O(n!) by trying all possibilities.\n\nNow, looking at the Travel Salesman Problem, we can solve it by trying all permutations of cities. Lets say we have cities A, B and C.\nLets say we start at city A. By calculating all permutations of BC string we get ABC ACB, then we just sum (in polynomial time the distance between AB, CB and CA for the first case...)\n\nSo isnt this a reduction of the all strings permutation to the travel salesman problem and isnt it a NP Complete problem?\n    ", "Answer": "\r\nI think you're confusing some concepts:\n\nWhat you describe is not \"reducing the all permutations problem to TSP\", but the opposite: reducing TSP to the all permutations problem.\nWhat that proves is that generating all permutations is NP-Hard (at least as hard as the hardest NP problem).\n\nTo prove something is NP-Complete, you would also have to prove that it's in NP. But this is not true, right out of the gate: NP is a set of decision problems, and the problem you described isn't a decision problem.\n\nSee also: What are the differences between NP, NP-Complete and NP-Hard?\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "what are examples of exact cover problems in real world applications?\r\n                \r\nIn computer science, the exact cover problem is a decision problem to determine if an exact cover exists. The exact cover problem is NP-complete[1] and is one of Karp's 21 NP-complete problems.[2] The exact cover problem is a kind of constraint satisfaction problem.\n\nI have been reading examples of exact cover problems such as the n-queens, sudoku, etc but cant seem to understand how a problem can be exact.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Showing that the decison version of an NP-complete language is NP-complete\r\n                \r\nSay you are given a combinatorial optimization problem A. Let us assume WLOG that the problem is the clique problem.\n\nHow can I show that if clique is NP-complete, then the decision version of clique is NP-complete, where the decision version is of course the following problem B: is there a clique of size equal to k?\n\nI think I have the intuition in mind but not sure if it suffices as a proof:\n\nStep I: \n\nif I am given a set of vertices C of size k, I can verify in polynomial time that there is a clique of size k (assuming that the answer to B is yes i.e. there exists a clique of size k). Hence, B is in NP.\n\nStep II: reduce A to B.\n\n-Since A asks for the clique of maximum size, we can break the problem down into pieces, B1: is there a clique of size 1?, ..., BN: is there a clique of size N? \n\n-If A is solvable, say there is a clique of size k*, then every Bk, k=1,...,N can be easily answered by comparing k to k*\n\n-If all of the Bks are solvable, we can tell what is the maximum clique size.\n\nI'm really not sure that this is a reduction although it's in polynomial time. Maybe because one problem is broken down into many problems. Moreover, I'm not sure I should be using the the word \"all\" above.\n\nThanks for the help! :)\n    ", "Answer": "\r\nA combinatorial optimization problem cannot be NP-complete. Only decision problems can be NP-complete (see, e.g, http://en.wikipedia.org/wiki/NP-complete).\n\nThe Clique optimization problem (given a graph, find a maximal set of vertices that form a clique) is NP-hard, because its decision version (given a graph and a k, is there a clique of size >= k?) is NP-complete. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Does every NP-complete prob. admit a polynomial-time restriction?\r\n                \r\nI have to answer this question as a homework assignment but I am finding very little material to work with. I understand what is a NP-complete problem and what is a restriction. In my opinion, this statement is true, because you can always restrict the problem in order to \"make the problem easier\". But I'm looking at it with a bird's eye view... Can anyone help me make some progress finding the answer to this question?\nAny help will be much appreciated. \n    ", "Answer": "\r\nConverting my comment into an answer - consider the \"empty problem,\" a problem whose instance set is empty. Since the empty set is a subset of every set, this problem technically counts as a restriction of any language (including languages not in NP). It's also a problem in P; you can build a polynomial-time TM that always rejects its input. Therefore, every problem in NP has a polynomial-time restriction.\n\nWhat I'm still curious about, though, is whether every NP problem whose instance set is infinite has a polynomial-time restriction whose instance set is also infinite. That's a more interesting question, IMHO, and I don't currently have an answer.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this prob on weighted bipartite graph solvable in polynomial time or it is NP-Complete\r\n                \r\nI encounter this problem recently and I want to know whether it is NP-Complete or solvable in polynomial time:\n\nGiven a weighted bipartite graph G=(V,E) where V can be partitioned into two sets A and B and E is a set of edges connecting A and B. The weight of an edge (v,u) is denoted as w(v,u).\n\nDo the following sequentially:\n\n\nPick a node v∈A,\nremove all node u∈B for every (v,u)∈E and,\nadd the weight w(v,u) to the total score for every edges deleted.\n\n\nThe goal is to find the sequence of nodes v1,…,vn∈A that maximizes the total score.\n\nI have searched for the bank of NP-Complete problems to find something possible can reduce to this problem but I haven't found anything useful yet. Any suggestions would be extremely helpful!\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Problems formerly in NP but now in P\r\n                \r\nAre there any problems that used to be in NP (not NP-complete and not P) but since then have been proven to be in P? I saw this video which states that people sometimes find ways of doing NP problems as quickly as P, thus proving that the problem is actually in P. Does anyone know of any examples?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proving NP completeness of optimal path cover\r\n                \r\nThis paper solves the optimal path cover problem for block graphs or bipartite permutation graph. In the third line of its introduction it's written that optimal path cover problem is NP-Complete and has given reference to \"Computer and intractability: a guide to the theory of NP-completeness by David S. Johnson, Michael R. Garey\". But I couldn't find its proof in the book. If anyone knows how to prove NP-Completeness of this problem then share your solution.\n\n\n  Optimal path cover problem:\n  Given a graph G, find a minimum number of\n  vertex disjoint paths which together cover all the vertices of the\n  graph.\n\n    ", "Answer": "\r\nConsidering the obvious decision variant (ie given k, is there a cover with k paths)\n\nOPC(k=1) detects Hamiltonian paths, so clearly it's NP-hard.\n\nIt's also in NP because given the paths, checking whether they're disjoint and covering is easy.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Prove NP-Completeness clique + independent set graph\r\n                \r\n\"Prove that it is NP-Complete to determine given input G and k whether G has both a clique of size k and an independent set of size k. Note that this is 1 problem, not 2; the answer is yes if and only if G has both of these subsets.\"\n\nWe were given this problem in my algorithms course and a large group of students could not figure it out. Here is what we have so far...\n\nWe know that both the clique and independent set problems are NP-Complete in of themselves. We also know that the verification of this problem, given some \"certificate\" is in NP.\n\nThe problem is somehow performing a reduction on the above problem (which contains both independent sets and cliques) to either a problem consisting entirely of cliques or independent sets (at least that's what we think we need to do). We don't know how to perform this reduction without losing information needed to reduce the reduction back to its original form.\n    ", "Answer": "\r\nHint: Reduce CLIQUE to this problem, by adding some vertices.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proving NP hard by polynomial reduction to 3SAT\r\n                \r\nI know the correct way of proving NP hard of a problem X is to reduce a known NP-Hard problem to X i.e. the direction is from the known, harder problem to the problem we want to prove is NP-Hard. But all NP-Complete problems are polynomially related (one can be transformed into the other in polynomial time), so I would like to ask if it's correct to assert that a problem is NP-Hard when it can be polynomially reduced to 3SAT? \n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Show np-completeness of Disjoint Hamiltonian Path\r\n                \r\nConsider the problem of Disjoint Hamiltonian Path: \n\nInput: A graph which may be directed or undirected\n\nOutput: Does this graph exist at least 2 Hamiltonian Paths that are edge-disjoint? \nEdge-disjoint means that no single edge is shared by two paths. \n\nShow that Disjoint Hamiltonian Path is np-complete.\n\nI have been told that this problem is np-complete, but I couldn't prove it is np-hard. I tried reducing the original Hamiltonian Path and Hamiltonian Cycle to this problem but I couldn't think of a solution.\n    ", "Answer": "\r\nI came up with the following reduction, not sure if it's the simplest but it is simple.\n\nSuppose G is an undirected graph corresponding to an instance of HP.\nNow construct a new graph G' in the following way:\n\n\nKeep every vertex from G.\nFor every edge (u,v) in G, create 4 additional vertices and connect them in the following way : \n\n\n\nNow it is easy to see that if G has a Hamiltonian path, G' will have two edge-disjoint Hamiltonian paths, because every edge was replaced by some subgraph which itself has two edge-disjoint Hamiltonian paths (go straight or take the curvy edges). And if G' has a HP, then so does G because once you enter the subgraph corresponding to one of the original edges you have no choice but to get out of it on the other end, which corresponds to taking the original edge in G. The only \"problem\" that could occur is if the path were to start or end inside one of these subgraphs, but then we can just ignore the small part of the path which is inside and still get a HP for G.\n\nAnd notice that G' has a HP => G has a HP => G' has two edge-disjoint HPs. Thus, G has a HP <=> G' has two edge-disjoint HPs.\n\nThe transformation can obviously be done in poly-time, thus your problem is NP-Hard.\n\nThe directed case is similar, just direct the edges in the transformed graph accordingly.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is mapping array elements to perfect hash indexes NP Complete?\r\n                \r\nAssuming I have a set of integers that can range from 0 to INT64MAX, but I know the set in its entirety so I can generate a perfect hash.\n\nIf I want to use these hashes as array indices, I need to modulus with the size of the array I want to store this in.\n\nThis brings a problem where I want to find a non-colliding set for my hashes that map to integers such that minimal array size is needed and I still have no collisions.\n\nIs this NP complete? It \"feels\" NP Complete.\n    ", "Answer": "\r\nNo.\n\nThere exist algorithms that construct perfect hashes (even minimal perfect hashes) in linear time. See for example the CMPH docs which list a couple of them.\n\nLinear time means deterministic polynomial problem, thus the problem lies in ```\nP```\n. P is contained in ```\nNP```\n, but the problem certainly is not at least as hard as the hardest problems in ```\nNP```\n, thus it is not in ```\nNP-hard```\n.\n\n```\nNP-complete```\n is defined as being in both ```\nNP```\n and ```\nNP-hard```\n. Therefore, it is not NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to show that a prob is in NP and that it is NP-complete\r\n                \r\nLongest Path\n\nWe have a graph G=(V,E), lengths l(e) in Z^(+) for each e in E, a positive integer K and two nodes s,t in V.\n\nThe question is if  there is a simple path in G from s to t of length at least K ?\n\n\nShow that the problem Longest Path belongs to NP.\nShow that the problem Longest Path is NP-complete, reducing Hamiltonian Path to it.\nShow that if the graph is directed and acyclic then the problem can be solved in time O(|V|+|E|).\n\n\nCould you give me a hint how we could show that the problem belongs to NP?\nAlso, how can we reduce a problem to an other, in order to show that the latter is NP-complete?\n\nEDIT:\n\nSo in order to show that the problem belongs to NP, do we have to draw a simple and count the sum of the lengths of the edges?\n\nDo we say for example the following?\n\n\n\nWe see that the length of the path from the node s to the node t is equal to l((s,w))+l((w,t))=3+12=15, so there is no simple path in G from s to t of length at least K.\n\nOr does it suffice the following?\n\n\"Given a a simple path , we can easily check if its length is at least K(by simply computing the sum of lengths of all edges in it). Thus, it is in NP.\"\n\nEDIT 2: Also could you explain me further why  we reduce the Hamiltonian path problem to this one in polynomial time by  setting all edges' lengths equal to one and set K = |V| - 1 ?\n\nEDIT 3: Suppose that we have a problem A and a problem B and it is known that B is NP-complete. If we want to show that A is also NP-complete, do we change the data of A in that way so that we have the same problem as the problem B and so we deduce that A is also NP-complete? Or have I understood it wrong? \n\nEDIT 4: Also how can we show that if the graph is directed and acyclic then the problem can be solved in time O(|V|+|E|)?\n\nEDIT 5: All edges'lengths of a Hamiltonian path are equal to 1, right? And if we have V vertices, the length of the longest path is at V-1, yes? But in our problems, the lengths of the edges aren't specific and K is also not a fixed number. So if we set all edges' lengths equal to one and set K = |V| - 1, don't we reduce our problem to the Hamiltonian path problem? Or have I understood it wrong?\n    ", "Answer": "\r\n\nTo show that a problem is in NP, we need to show that it can be verified in polynomial time. Given a certificate(a simple path in this case), we can easily check that it length is at least K(by simply computing the sum of lengths of all edges in it). Thus, it is in NP.\nReduction from A to B means: given an instance of A, create an instance of B(to be more precise, we are interested in polynomial time reduction here) and solve it in order to solve the original problem. So how can we reduce the Hamiltonian path problem to this one in polynomial time? It is pretty straightforward: we can set all edges' lengths equal to one and set ```\nK = |V| - 1```\n. Then we should try all pairs of vertices in the graph ```\n(s, t), s != t```\n and if the solution for this problem returns true for at least one pair, return true. Otherwise, we should return false(checking that we have a path of length ```\n|V| - 1```\n in a graph where all edges have unit length is exactly the same thing as checking that a Hamiltonian path exists by its definition). \n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Array search NP complete [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 8 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nGiven an unsorted array of size n, it's obvious that finding whether an element exists in the array takes O(n) time.\n\nIf we let m = log n then it takes O(2^m) time. \n\nNotice that if the array is sorted, a binary search actually takes O(m) time (which is polynomial) but the binary search cannot apply to an unsorted array.\n\nIs it possible to prove that the problem to find an element in an array (yes or no) is NP complete in terms of m. What problem should I reduce from and how to reduce?\n\nAny idea would be appreciated.\n\nEDIT:\n\nMy description above probably did not express clearly what I was trying to say.\n\nLet's reword the problem in the following way.\n\n\nWe have an oracle, which is a binary tree of height h with each node having random values. I.E. a tree that DOES NOT have the property that all values in the left subtree of a node must be smaller than the value in the node or all values in the right subtree of a node must be greater than the value in the node. However all nodes in the oracle tree are guaranteed to have value between 0 and 2^h-1.\nThe input is a number to be searched. The input is guaranteed to have value between 0 and 2^h-1. (The input has h bits)\n\n\n(Let's say we are searching through the same array every time and hence we have the same oracle every time so the tree is not a part of input.)\n\n\nThe output is YES or NO, indicating whether the input is in a node of the tree or not.\n\n\nQuestion: whether this problem is NP complete or not in terms of h.\nThis problem is NP because if a path to the YES node in the tree is given it can be verified in O(h) time.\n\n(Note that if the oracle tree has the property that left subtree of a node is less than the node and right subtree of a node is greater than the node then the problem is NOT NP complete because binary search can be applied.)\n    ", "Answer": "\r\n\n  Finding an element in an array is NOT NP-complete as it can be done in linear time. (Assuming P ≠ NP)\n\n\nIn fact, the naive brute-force search algorithm you mentioned in your question is a linear time algorithm!\n\nWhen we are talking about the complexity of a computational problem, we always measure the time with respect to the size of the input. You claimed the input size of our algorithm is ```\nm = log(n)```\n, but in our case, the size of our input is determined by the number of elements in the array, which is ```\nn```\n.\n\nFor your reference, testing whether a given number ```\nn```\n is a prime number is an example computational problem that takes input of size ```\nlog(n)```\n. The input of the problem is ```\nn```\n, and it is of size ```\nlog(n)```\n because we need to use ```\nlog(n)```\n bits to represent ```\nn```\n in binary form.\n\nUpdate\n\n\n  Deterministic search algorithm requires Ω(n) time for unsorted array.\n\n\nAny search algorithm must read through the entire input (i.e. the n entries of the array). We are going to prove this by contradiction.\n\nSuppose there is a search algorithm that does not read all n input entries, then there is an entry that is not read by this algorithm. you can then construct a case that the search item is at the entry that is not read by this hypothetical algorithm, this violates the correctness of the algorithm. Hence such algorithm does not exist.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "np-complete and turing reductions\r\n                \r\nI have some difficulties with a complexity proof : \nI work with 3 problems : A, B and C\nI know :\n\n\nA-> B \nA-> C\nC -> B \n\n\nA-> B meaning : if I have a \"yes answer \" for A , then I have a \"yes answer\" for B.\nI know that A belongs to NP,\nB and C are NP-complete. Moreover I can write an algorithm for A with a quadratic number of calls to C.\ncan I deduce something about the complexity of A? \n\nTo be more precise : I have a set P of k objects.\nThe problem A answer yes if all these objects are removed, no otherwise.\nThe problem C answer yes if one of these objects can be removed, no otherwise.\nWe have the constraint that at least one objects has to be removed at each step. In worst we make P steps.\nSo algorithm for A : \n\n```\n    for( i = 0 ; i < k){\n    for each object p of P \n    { \n    if C(p,P)=true then \n      remove p of P}\n    }\n    return P = emptyset\n```\n\n    ", "Answer": "\r\nAs you don't state that B -> A, it could be the case that A only requires yes answers in trivial cases or cases that can be determined in polynomial time while determining answers for B requires more time as more complex cases might require a Yes answer.\nShorter answer to your question: no.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Subset Inference NP-complete?\r\n                \r\nConsider the following problem:\n\nThere are N coins numbered 1 to N.\n\nYou can't see them, but are given M facts about them of the form:\n\n```\nstruct Fact\n{\n    set<int> positions\n    int num_heads\n}\n```\n\n\n```\npositions```\n identifies a subset of the coins, and ```\nnum_heads```\n is the number of coins in that subset that are heads.\n\nGiven these M facts you need to work out the maximum number of heads there could possibly be.\n\nIs this problem NP-complete?  If yes, what is the reduction?  If no, what is a polynomial time solution?\n\nFor example:\n\n```\nN = 5\nM = 3\nfact1 = { {1, 2}, 1 } // Either coin 1 or coin 2 is a head\nfact2 = { {4}, 0 } // Coin 4 is a tail\nfact3 = { {2, 4, 5}, 2 } // Out of coins 2, 4 and 5, two are heads\n```\n\n\nA configuration with the most heads that matches the facts is:\n\n```\nT H H T H\n```\n\n\nSo the answer is 3 heads.\n    ", "Answer": "\r\nLet's say you have a 3-SAT problem. You can map every boolean variable v in that problem to two coins. Call them 'true(v)' and 'false(v)'. The idea is that if v in a solution to the 3-SAT problem is true, then 'true(v)' is heads; otherwise 'false(v)' is heads. For every v you add the coin constraint\n\n```\n{true(v), false(v)} has 1 heads, and has 1 tails\n```\n\n\nAfter this, you can translate a 3-SAT clause with literals l1, l2, l3\n\n```\nl1 or l2 or l3\n```\n\n\nto the coin constraint\n\n```\n{t/f(l1), t/f(l2), t/f(l3)} has at least 1 heads\n```\n\n\nwhere t/f(l1) is either 'true(l1)' or 'false(l1)' depending on if l1 is positive (not negated) or negative (negated) in the clause. We just need to show that 'at least 1 heads' can be implemented in the coin problem as 'at least 1 heads' is not expressible directly. This can be done with the following device. Let C1, C2, C3 be three coins for which we want to state the constraint 'at least one of them is heads'. Create three other coins X1, X2, X3 and put in constraint\n\n```\n{X1, X2, X3, C1, C2, C3} has 4 heads\n```\n\n\nbut no other constraints for X1, X2, X3. This constraint is satisfied only if at least one of C1, C2, C3 is heads; the coins X1..3 can be used to provide the remaining needed heads.\n\nNote that this reduction does not use the \"maximum number of heads\" aspect of the problem at all; it is plainly impossible to choose heads/tails status for the coins that represent boolean variables at all if the 3-SAT formula is unsatisfiable.\n\nThis is a polynomial reduction FROM 3-SAT TO your coin problem, showing it is NP-hard. To show it is NP-complete, just observe that a solution to your coin problem can be checked in polynomial time, QED.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "With all the available problems that have been categorized and their time complexities deduced, so why haven't anyone solved NP vs P yet?\r\n                \r\nWe have problems proved to be in classes P, NP, co-NP, NP-Complete, and NP-Hard. These problems have their time complexities deduced too. I am wondering if I am missing any key information on the topic.\n    ", "Answer": "\r\nOne of the standard tricks for solving this sort of problem is what's called using an \"oracle\".  Suppose we could ask the oracle a question about a specific class of problems, and in one step it would answer \"yes\" or \"no\".  It becomes reasonable to ask \"What sort of problems are in P for a machine with this oracle\"?  \"What sort of problems are in NP for a machine with this Oracle.\nIt has been shown that there are oracles for which P=NP.  It has been shown that there are oracles for which P≠NP.  Most of the techniques we know for proving hardness should give the same result, no. matter what oracle is used.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to prove a prob is np complete and is in np?\r\n                \r\nGiven a department needs a committee to select the department’s head. The committee cannot include people who have conflicts of interest with each other. The input consists of:\n\n\nthe desired committee size\na list of all people\na list of all pairs of people that are conflicted. \n\n\nThe goal is to determine whether there’s a conflict-free committee of that size.\n\nHow can I show that this problem is NP-complete and is in NP?\n    ", "Answer": "\r\nAs this is 99.99% homework, so I only give you a very brief \"answer\":\nTry to reduce\nIndepedent Set Decision Problem to your problem.\nAlso a useful note is that if you prove the problem is NPC, then it is NP\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "If a NP solved in polynomial time, can Satisfiability solved in polynomial time\r\n                \r\nBased on the below link , I can know that solving of Satisfiability(NP Complete) in polynomial time means any other NP problem can be solved in polynomial time.\nBut is Vice - Versa true?\n\nAlso, If there is a polynimial for any other NP-Complete problemt does it mean , all the other NP-Complete can be solved in polynomial time?\n\nWhat are the differences between NP, NP-Complete and NP-Hard?\n    ", "Answer": "\r\nThe 'complete' in NP-complete means that if a problem is in NP-complete, a solution for that problem gives a solution to any problem in NP with a polynomial amount of conversion processing.\n\nIn layman's terms - if you solve a single NP-complete problem in polynomial time you have proven that NP = P.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is k -rainbow coloring of a hypergraph NP-complete or not?\r\n                \r\n**A hypergraph is k-rainbow colorable if there exists a vertex coloring using k colors such that each hyperedge has all the k colors. Is k-rainbow coloring of a hypergraph is NP-complete or not? The problem is also called \"polychromatic coloring\" **\n\nI looked at some reference papers such as \"Hardness of Rainbow Coloring Hypergraphs by Venkatesan Guruswami and Rishi Sakety\" and \"Strong Inapproximability Results on Balanced Rainbow-Colorable Hypergraphs by Venkatesan Guruswami and Euiwoong Lee\". But these are the only reference I found discuss the problem but the authors foucs on generating balance rainbow coloring for K-uniform hypergraph where each color has to appear the same number of times in the hypergraph. It has been proved that K-rainbow coloring for planer graph is P for K= 2 and NP complete for K=3,4 according to this reference \"Polychromatic Colorings of Plane Graphs\".\n\nMy question \" Is k-rainbow coloring of a hypergraph NP-complete or not?\" in general for any hypergraph. I think this problem is related to vertex cover problem.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete reduction\r\n                \r\nThe problem states that we want to show that Independent Set poly-time reduces to Relative Prime Sets, more formally ```\nIndependent Set <p Relative Prime Sets```\n.\n\nI need to provide a reduction f from ind.set to rel. prime sets, where\n\n- input of f must be a Graph G and an integer k, where k denotes the size of an independent set.\n\n- output of f must be a set S of integers and an integer t, where t denotes the number of pairwise relative prime numbers in the set S.\n\nDefinition of relative prime sets (decision version):\n\n\n  it takes a set P of n-integers and an integer t from 1 to n.\n  \n  returns yes if there's a subset A of P, with t-many pairwise relative\n  primes. That is, for all a, b in A, it must be true that gcd(a, b) =\n  1.\n  \n  returns no otherwise\n\n\nSo far I have come-up with what I believe is a reduction, but I am not sure if it is valid and I want to double check it with someone who knows how to do this. \n\nReduction:\n\n\n  Let G be a graph.Let k indicate the size of an independent set. Then we\n  want to find-out if there exists an independent set of size k in G.\n  Since this problem is NP-Complete, if we can solve another NP-Complete\n  problem in poly-time, we know that we can also solve Independent Set\n  in poly-time. So we chose to reduce independent set to Relative Prime\n  Sets.\n  \n  We take the graph G and label its vertices from 1 to n as pr the\n  definition of the input for relative prime sets. Then we find the gcd\n  of each node to every other node in G. We draw an edge between the\n  nodes that have gcd(a, b) = 1. When the graph is complete, we look at\n  the nodes and determine which nodes are not connected to each other\n  via an edge. We create sets for those nodes. We return the set\n  containing the most nodes along with an integer t denoting the number\n  of integers in the set. This is the set of the most relative prime\n  numbers in the graph G and also the greatest independent set of G.\n\n    ", "Answer": "\r\nSuppose two graphs, each of four nodes. On graph one, the nodes are connected in a line so that the max-independent set is 2. Graph two is a complete graph each node is connected to each other node, so the max-independent set is 1. \n\nIt sounds like your reduction would result in the same set for each graph, leading to an incorrect result for independent set. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Factorial-time algorithms and P/NP\r\n                \r\nIt's quite easy to see that n! grows slower than almost anything to the N power (say, 100^N) and so, if a problems is considered NP complete and one happened upon a n! algorithm that approximates the solution, one would do the Snoopy dance.\n\nI have 2 questions about this situation:\n\n\nWould the n! algorithm be considered a solution in polynomial time? A factorial certainly doesn't appear to be a term raised to a power.\nIf finding a n! solution means we have a decently fast algorithm and since n! grows faster than 2^N, then does this mean that some NP-complete problems do not need heuristic/approximation algorithms (except for obscure cases)?\n\n\nOf course, these two questions rely on the first paragraph being true; if I've erred, please let me know.\n    ", "Answer": "\r\n\nNo. factorial time is not polynomial time. Polynomial time normally means an equation of the form O(Nk), where N = number of items being processed, and k = some constant. The important part is that the exponent is a constant -- you're multiplying N by itself some number of that's fixed -- not dependent on N itself. A factorial-complexity algorithm means the number of multiplications is not fixed -- the number of multiplications itself grows with N.\nYou seem to have the same problem here. N2 would be polynomial complexity. 2N would not be. Your basic precept is mistaken as well -- a factorial-complexity algorithm does not mean \"we have a decently fast algorithm\", at least as a general rule. If anything, the conclusion is rather the opposite: a factorial algorithm may be practical in a few special cases (i.e., where N is extremely small) but becomes impractical very quickly as N grows.\n\n\nLet's try to put this in perspective. A binary search is O(log N). A linear search is O(N). In sorting, the \"slow\" algorithms are O(N2), and the \"advanced\" algorithms O(N lg N). A factorial-complexity is (obviously enough) O(N!).\n\nLet's try to put some numbers to that, considering (for the moment) only 10 items. Each of these will be roughly how many times longer processing should take for 10 items instead of 1 item:\n\nO(log N): 2\nO(N):10\nO(N log N): 23\nO(N2): 100\nO(N!): 3,628,800\n\nFor the moment I've cheated a bit, and use a natural logarithm instead of a base 2 logarithm, but we're only trying for ballpark estimates here (and the difference is a fairly small constant factor in any case).\n\nAs you can see, the growth rate for the factorial-complexity algorithm is much faster than for any of the others. If we extend it to 20 items, the difference becomes even more dramatic:\n\nO(log N): 3\nO(n): 20\nO(N log N): 60\nO(N2): 400\nO(N!): 2,432,902,008,176,640,000\n\nThe growth rate for N! is so fast that they're pretty much guaranteed to be impractical except when the number of items involves is known to be quite small. For grins, let's assume that the basic operations for the processes above can each run in a single machine clock cycle. Just for the sake of argument (and to keep the calculations simple) let's assume a 10 GHz CPU. So, the base is that processing one item takes .1 ns. In that case, with 20 items:\n\nO(log N) = .3 ns\nO(N) = 2 ns\nO(N log N) = 6 ns\nO(N2) = 40 ns\nO(N!) = 7.7 years.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Algorithm to maximize profit: ways to solve/approach? (Advanced NP-Complete)\r\n                \r\nThis one's hard, so all help really appreciated!\n\nI know it is NP-Complete and thus cannot be solved in polynomial time, but looking for help in analysis, what type of NP-Complete problem it reduces to, similar problems it reminds you of, etc.\n\nThe story goes as follows. I own an ice cream truck business with n trucks. There are m stops where I make deliveries. Each location mi has pi people waiting for me. After buying their ice cream, everyone leaves. pi increases over time as more people line up to get ice cream.\n\nHow can I figure out where to send the trucks next in order to maximize my profit in any given day?\n\nThings to keep in mind:\n\n\nTwo trucks that stop in the same spot at similar times will only get the profit once, i.e. the people leave after one truck arrives\nThe trucks take time to get from one location to another\npi increases over time at each stop, but some stops increase faster than others, i.e. some locations are near malls (location, location, location)\n\n\nI've tried reducing this to a multimachine scheduling problem, traveling sales person problem, ILP etc., but the main issue is that the pi at every location (i.e. the distance in the TSP or the job length in the scheduling problem) is constantly increasing.\n\nThanks in advance!\n    ", "Answer": "\r\nSounds like a variant of the Assignment Problem. So one approach you may not have considered is an Auction Algorithm (which has the advantage it can be parallelized easily) or Hungarian algorithm. \n\nI realize there are complications in your problem (there always are!) but the Auction algorithm is pretty flexible. You can have quite a complicated cost function between your trucks and customers. You can also tweak the algorithm to have multiple trucks service multiple customers subject to capacity constraints. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How a shortest path problem with negative cost cycles can be polynomially reduced to the Hamiltonian cycle problem to demonstrate NP-completeness\r\n                \r\nI know that if there are negative cost cycles in a graph, the relative shortest path problem belongs to the np-complete class. I need to prove this by performing a polynomial reduction using the Hamiltonian cycle problem. Could anyone explain it? It would be very helpful.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity for converting any propositional formula to CNF format\r\n                \r\nWhat is the complexity for converting any propositional formula to CNF format? Is it an NP-complete problem?\n    ", "Answer": "\r\nThe standard algorithm to transform a general Well-Formed Formula to an equivalent CNF has an exponential run time, since in the worst case a n-clauses WFF is equivalento to a 2^n-clauses CNF. \n\nHowever, you can transform in polynomial time an arbitrary boolean formula into a CNF that is not stricty equivalent, but satisfable only if the boolean formula is satisfable. This is the standard reduction used to prove that 3CNF is NP-complete, givent that the more general SAT is NP-complete. See here.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Non deterministic Polynomial(NP) vs Polynomial(P)?\r\n                \r\nI am actually looking for description what NP alogrithm actually means and what kind of algo/problem can be classified as NP problem\n\nI have read many resources on net . I liked\n\n\nhttps://www.quora.com/What-are-P-NP-NP-complete-and-NP-hard\nWhat are the differences between NP, NP-Complete and NP-Hard?\nNon deterministic Turing machine\nWhat are NP problems?\nWhat are NP and NP-complete problems?\n\n\nPolynomial problem :-\nIf the running time is some polynomial function of the size of the input**, for instance if the algorithm runs in linear time or quadratic time or cubic time, then we say the algorithm runs in polynomial time . Example can be binary search\n\nNow I do understand Polynomial problem . But not able to contrast it with NP.\n\nNP(nondeterministic polynomial Problem):-\n\nNow there are a lot of programs that don't (necessarily) run in polynomial time on a regular computer, but do run in polynomial time on a nondeterministic Turing machine.  These programs solve problems in NP, which stands for nondeterministic polynomial time.  \n\nI am not able to to understand/think of example that does not run in polynomial time on a regular computer. Per mine current understanding, Every problem/algo can be solved\nin some polynomial function of time which can or can't be proportional to time. I know i am missing something here but really could not grasp this concept. Could someone\ngive example of problem which can not be  solved in polynomial time on regular computer but can be verified in polynomial time ?\n\nOne of the example given at second link mentioned above is ```\nInteger factorization is in NP. This is the problem that given integers n and m, is there an integer f with 1 < f < m, such that f divides n (f is a small factor of n)?```\n why  this can't be solved in some polynomial time on regular computer ? we can check for all number from 1 to n if they divide n or not. Right ?\nAlso where verification part come here(i mean if it can be solved in polynomial time but then how the problem solution can be verified in polynomial time)?\n    ", "Answer": "\r\nIt's probably worth noting how the idea of \"checking a solution in polynomial time\" relates to a nondeterministic Turing Machine solving a problem: in a normal (deterministic) Turing Machine, there is a well-defined set of instructions telling the machine exactly what to do in any situation (\"if you're in state 3 and see an 'a', move left, if you're in state 7 and see a 'c', overwrite it with a 'b', etc.\") whereas in a nondeterministic Turing Machine there is more than one option for what to do in some situations (\"if you're in state 3 and see an 'a', either move right or overwrite it with a 'b'\"). In terms of algorithms, this lets us \"guess\" solutions in the sense that if we can encode a problem into a language on an alphabet* then we can use a nondeterministic Turing Machine to generate strings on this alphabet, and then use a standard (deterministic) Turing Machine to ensure that it is correct. If we assume that we always make the right guess, then the runtime of our algorithm is simply the runtime of the deterministic checking part, which for NP problems runs in polynomial time. This is what it means for a problem to be 'decidable in polynomial time on a nondeterministic Turing Machine', and why it is often simply phrased as 'checking a solution/ certificate in polynomial time'. \n\n*\nExample: The Hamiltonian Path problem could be encoded as follows:\n\nLabel the vertices of the graph 1 through n, where n is the number of vertices. Our alphabet is then the numbers 1 through n, and our language consists of all words such that \n\na) every integer from 1 to n appears exactly once\n\nand\n\nb) for every consecutive pair of integers in a word, the vertices with those labels are connected\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "theory about p, np problems\r\n                \r\nI am reading about P , NP and NP-Complete problems theory. Here is text snippet.\n\n\n  The class NP includes all problems that have polynomial-time\n  solutions, since obviously the solution provides a check. One would\n  expect that since  it is so much easier to check an answer than to\n  come up with one from scratch,  there would be problems in NP that do\n  not have polynomial-time solutions. To date no such problem has been\n  found, so it is entirely possible, though  not considered likely by\n  experts, that nondeterminism is not such an important improvement. The\n  problem is that proving exponential lower bounds  is an extremely\n  difficult task. The information theory bound technique, which we used\n  to show that sorting requires (n log n) comparisons,  does not seem to\n  be adequate for the task, because the decision trees are not nearly\n  large enough.\n\n\nMy question is what does author mean by\n\n\nby statement \"To date no such problem has been found, so it is entirely possible, though\nnot considered likely by experts, that nondeterminism is not such an important improvement.\" ?\nAnother question what does author mean by in last statement by \"because the decision trees are not nearly large enough.\" ?\n\n\nThanks!\n    ", "Answer": "\r\n(1) I think the author means that no NP problem has been found, for which it is proven that it is not in P. Certainly there are problems in NP for which no polynomial solution is known, but that's not the same as knowing that none exists.\n\nIf in fact ```\nP = NP```\n (that is to say, if in fact there are no NP problems that don't have a polynomial solution), then in some sense a nondeterministic machine is no \"more powerful\" than a deterministic machine, since they solve the same problems in polynomial time. Then we'd say \"nondeterminism is not such an important improvement\".\n\n(2) The way that the ```\nn log n```\n proof works is that there are ```\nn!```\n possible outputs from a sorting function, any one of which might be the correct one according to what order the input was in. Each comparison adds a two-legged branch to the tree of all possible states that a given comparison sort algorithm can get into. In order to sort any input, this \"decision tree\" must have enough branches to produce any of the ```\nn!```\n possible re-orderings of the input, and hence there must be at least ```\nlog(n!)```\n comparisons. So, the lower bound on runtime comes from the size of the tree.\n\nThe author is saying that there are no known NP problems for which we've proved they require a tree so large that it implies a lower bound that is super-polynomial. Any such proof would prove ```\nP != NP```\n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why using linear integer programming (ILP) though it is NP-Complete?\r\n                \r\nThe question may be stupid but it really confuses me for a long time.\n\nI read a lot of papers in wireless sensor network. Many researchers model their problems into the form of ILP. However, ILP is NP-Complete so it is not efficient for solving a problem.\n\nSo why people write their problems into the form of ILP? Do they do that to make their problem clear to see and easy to understand? Or do I make some mistakes understanding the relations between ILP and NPC?\n\nI am really appreciated that you can help me to solve this question.\n    ", "Answer": "\r\nAlthough the question might be considered off-topic, there are basically a few points to address.\n\n\nYou are right that general integer linear programming is ```\nNP```\n-hard.\nIf a specific problem needs to be solved and general integer linear programming is the most specific way to formulate it, then nothing can be done about it; some problems are just hard to solve.\nIn some cases, it is possible to use the LP relaxation instead, either as a heuristic or some approximation ratio can be proven.\n\n\nThe key point here is that integer linear programming is a widespread formalism for expressing problems. Basically I understand your question as the follwing one.\n\n\n  \"Why do people use a model that is algorithmically hard to solve to\n  describe practical problems?\"\n\n\nWell, if that shortcoming could be circumvented in general, it would be a good idea to express every problem there is in terms of sorting, which is algorithmically easy.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this geometric cover NP-Complete and how can I prove it?\r\n                \r\nI have the following problem which I believe to be NP-Complete but I would like to prove it to be so:\n\nGiven a set of M points on a plane where circles can be centered and a set of N points which need to be covered by the circles, find the minimum area circle cover for the points. That is, find the radii of the circles and the centers (chosen from the M points) such that all the N points are covered and the total area of the circles is minimized. A given point is covered if it is inside at least one circle in cover.\n\nI have been looking through various geometric cover NP-Complete results but they all involve using polygons for cover.\n\nAny ideas of a suitable problem that this can be reduced to? \n\nThanks in advance for any clues. \n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Prove for every i includes exactly 3 vertices in the path from subset Ti is NP-Complete\r\n                \r\nThe directed graph G is given. Several subsets of vertices are specified – T1, . . . , Tk (these subsets could intersect). Does there exist a path in G which\n• does not contain cycles\n• and for every i includes exactly 3 vertices from Ti?\nProve that this problem is NP-complete.\nI am considering from 3SAT reducing to this problem to prove it is NP-Hard, but I don't know how...\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reducing from Vertex Cover to prove NP-complete\r\n                \r\nWe define ROMAN-SUBSET as the following problem:\n\n\n  INPUT: Directed graph  G = ( V , E )  and a positive integer  k\n  \n  OUTPUT: If there is a subset  R  of  V  such that  | R | <= k  , and\n  such that every directed circuit in G includes at least one vertex\n  from  R , then the output should be \"TRUE\", otherwise, it should be\n  \"FALSE\".\n\n\nAssuming that the Vertex Cover (VC) problem is NP-complete, I must prove that ROMAN-SUBSET is also NP-complete. From what I understand, that means taking the VC input, modifying it, and then showing that plugging it into the ROMAN-SUBSET algorithm will yield the result of the VC problem.\n\nI'm having a really tough time coming up with the transformation. I know that the VC input is a graph G and an integer k, and the problem is whether or not there exists a subset R of V that covers every edge in G, such that |R| <= k. So clearly, the R and k are similar from ROM to VC, but my difficulty is identifying how to transform the graph so that 1 vertex in every directed cycle (for ROM) corresponds to every edge (for VC). How can I go about modifying the graph to prove that VC can be reduced to ROM?\n\nThanks!\n    ", "Answer": "\r\nHere is the construction.\n\nTake undirected graph ```\nG = (V, E)```\n as in VC.\nNow define the directed graph ```\nG1 = (V, E1)```\n, where for every edge ```\n(u,v)```\n in ```\nE```\n there are two edges ```\n(u,v)```\n and ```\n(v,u)```\n in ```\nE1```\n.\n\nIn other words the new graph is the same as the old one, but every undirected edge is replaced with two directed edges that form a 2-cycle.\n\nThe claim is that from ROM on ```\nG1```\n follows VC on ```\nG```\n.\n\nIndeed, suppose that the answer for ROM on ```\nG1```\n is FALSE. Then for every choice of a set of less than ```\nk```\n vertices there exists a cycle not in this set. So there exists an edge whose endpoints are not in the set. But this means that for the same choice of the set of less than ```\nk```\n vertices in ```\nG```\n there exists an edge whose endpoints are not in the set, so VC's answer is FALSE.\n\nConversely, suppose that the answer for ROM on ```\nG1```\n is TRUE. Then there exists a subset of ```\nV```\n containing less than ```\nk```\n vertices, so that given any cycle there exists at least one vertex in the cycle, which is in the set. But this means that for any edge in ```\nE```\n one of its endpoints in in the set, because an edge in ```\nE```\n corresponds to a 2-cycle in ```\nE1```\n. Thus the answer for VC is TRUE.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to prove that the language $E_{tm}$ is $NP-Hard$\r\n                \r\nConsider the language $E_{tm}={ \\langle M \\rangle: M\\text{is a Turing Machine that accepts nothing}$ \n\nI am not sure how to even start.\nMy idea is to provide poly time reduction from some NP - Complete problem.\nE_tm\n\nWhat I don't understand is that, knowing that E_tm is not decidable, but NP-Hard class is decidable. \n    ", "Answer": "\r\nsolution:\n\nDF:  A problem is NP-hard if all problems in NP are polynomial time reducible to it, even thoughit may not be in NP itself ( p326 Sipser) (the only definition our book has  ).\nFor any language L' that is in NP if we show that we can poly-time reduce to Etm.\nThis will prove that that Etm is NP - hard.\nSince L' is in NP by definition there exist a TM ( NTM but since they are equivalent in power I write TM ) M' such that decides L'.\n\n```\nTM M'' that takes as an input <M,w> constructs\nTM M' such that\n on arbitrary x\nif w = x\n  run M on w if accept => reject\n                     if reject => accept\nelse reject.\n```\n\n\nTherefore M accepts w iff M'' rejects all the input.\nLet's confirm that. First assume that M accepts w, then M'' reject on any input therefore L(M'') = empty.\nNow assume that M rejects w, then M'' accept, therefore L(M'') is not empty.\nNote that to construct the M'' takes polynomial time.\nThat completes the proof.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is the problem of finding the simple path with maximum cost in a weighted undirected graph with the same number of vertex and edges NP-Complete?\r\n                \r\nHello and thanks again for reading this.\n\nI need to know now if the problem of finding the simple path with maximum cost in a weighted undirected graph with the same number of vertex and edges is NP-Complete or not?\n\nInput: Graph G = (V,E) with V (vertex) = E (edges)\n\nOutput: The cost of the most expensive path in the graph G.\n\nCould you provide any reference to an article where I can review this.\n\nThank you very much for your time.\n\nSincerely,\n\nAlex.\n    ", "Answer": "\r\nIf the graph is not necessarily connected,  then any instance of the longest path problem can be reduced to this problem by adding extra isolated vertices to the input graph to make the number of nodes and edges the same.  If this isn't thyroid case, and the graph must be connected, then the input graph must have exactly one cycle, since a graph with n-1 edges is a tree.  IF you find this cycle with a DFS and contract it to a single node, you then have a tree.  It's easy to do longest path computations here; just consider all pairs of edges and get the cost of the unique path between them.  If you take this path ans then expand it in the original graph by walking around the cycle where you originally went through the contracted node, I think you get the longest path in polynomial time.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP hard but not NPC\r\n                \r\nI have seen couple of scheduling problem which says that the problem is NP hard. My question is that \n1)when we say a problem is NP hard does it mean that it is not in NP?because if it is NP we say the problem is NP complete.\nI know that a problem is in NPC if\na)it is in NP\nb)it is NP hard.\n    ", "Answer": "\r\nIf a problem is NP Hard, it may be in NP(then it's a NP complete), but it could also be not in NP. The following is a Venn diagram of these classes:\n\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this a special case of the NP-complete set packing?\r\n                \r\nI'm almost certain that my problem is equivalent to set packing, and thus, NP-complete, but I would like someone to verify.\n\nI have the following situation:\nThere is a set of pens (i.e. universe).\nA store sells bundles of these pens, which are subsets of that universe.\nI know a guy who has certain pens (also a subset of the universe) from the store, but I have no idea which bundles he bought.\nHe might have lost some pens and gotten others from other bundles that his friends gave him.\n\nWhat I want to do is map the bundles sold by the store into the subset of pens that my friend has so that I cover the highest amount of pens and the chosen bundles must not contain any pen which my friend doesn't have.\nFor example:\n\n```\nPossible Pens: {0, 1, 2, 3, 4, 5}\nBundles sold by store: {0, 1} | {0, 1, 2} | {2, 3} | {3} | {3, 4, 5} | {4, 5}\nMy friend has: {0, 1, 2, 3}\nHere, there are perfect matches: {{0, 1, 2}, {3}} and {{0, 1}, {2, 3}}. \nThese would be equivalent\n\nFriend 2 has: {0, 2, 3}\nIn this case, there is no perfect match.\nPossible matches are {{3}} and {{2, 3}}.\nThe best match is {{2, 3}}.\n```\n\n\nI this problem NP-complete given a number ```\nm```\n of pens, a number ```\nn```\n of bundles and a number ```\nl```\n of my friend's pens ?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Cook's Theorem (in plain English)\r\n                \r\nI read the book Computers and Intractability - A Guide to the Theory of NP-Completeness by Garey and Johnson for my algorithms course; however, upon reviewing the material a year later, I realized that I never really understood Cook's Theorem.  \n\nIn regards to the proof, I understand why SAT is first shown to be in NP first (first requirement of NP-complete), but am struggling through the technicalities of showing that the \"other\" NP-complete problems under a \"genetic\" polynomial transform to SAT.  \n\nI was wondering if someone could explain this in a more watered down manner, that would perhaps clarify an additional reading of this section.  \n    ", "Answer": "\r\nThe proof that SAT is NP-hard (that is, that there's a polynomial-time reduction from every NP problem to SAT) is nontrivial. I'm going to try to give an intuition for how it works, but I'm not going to attempt to go over all the details. For that, you probably want to consult a textbook.\n\nLet's start off by taking any NP language L. By definition, the fact that L is an NP language means that there is a nondeterministic, polynomial-time Turing machine M for the language L. This means that the machine M accepts a string w if and only if w belongs to L, and on top of this the runtime of M is some polynomial p(n). The reduction from L to SAT will work by showing that you can build a propositional formula that essentially simulates the operation of M on some particular string w. That formula has the property that M accepts w (that is, w belongs to L) if and only if the resulting propositional formula is satisfiable.\n\nIt's not at all clear that it's possible to do this at all. To see how it works, we'll use a standard technique for reducing problems involving TMs to one another. Think about the operation of M on the string w. Since M is a Turing machine, when we start up M with w, it begins with w written on the tape (surrounded by infinitely many blanks), in some state q0, and with the tape head over the first character of w. Each step of the Turing machine causes the machine to move the tape head left or right, to replace the symbol under the tape head, and to move the tape head left or right.\n\nRight before each step of the TM, we can take a \"snapshot\" of the state of the machine. That snapshot will include the tape after trimming off the infinitely many blanks from both sides, the position of the tape head, and the current state of the TM. This \"snapshot\" is more properly called an instantaneous description or ID of the machine. You can think of it as a tuple of (tape contents, state, position).\n\nBecause M is a polynomial-time NTM, we know that it can't run for more than p(|w|) steps when run on the input string w, where p is some polynomial. Therefore, when M runs, the computation will have at most p(|w|) + 1 instantaneous descriptions, one for each step. Consequently, you can think of any execution of M as a series of this ID's, written out one after the other, as (tape0, state0, position0), (tape1, state1, position1), ..., (tapeK, stateK, positionK).\n\nTwo observations are in order about these IDs. First, these IDs can't be totally arbitrary. We know what the first ID is going to be - it's going to be an ID where the tape holds w, the state is q0, and the tape head is over the start of string w. As a result, there are only a few possible choices for what the second ID will be, based on each of the nondeterministic choices that the TM can make for its first step. Similarly, the number of choices for the third ID is finite, since that ID has to be formed by starting with some legal second ID and applying one move of the TM. More generally, each ID has to follow from a legal TM move starting with the previous ID.\n\nSecond, notice that if M accepts w, then there is some possible chain of IDs such that the last ID in the chain will be on in which the state is the machine's accepting state. Conversely, if M doesn't accept w, then no possible chain of IDs will legally end with the machine in accepting state.\n\nThe reduction from L to SAT therefore works by, essentially, building up a gigantic propositional formula. Each variable corresponds to some piece of one of the IDs in the chain (either the contents of some specific tape cell, or what state the machine would be in, or where the tape head would be). The formula then encodes the rules about the IDs: the first ID has to be one where the machine starts up state q0 with the tape head scanning the first character of the input string w, each ID has to follow from the previous one, etc. There's one last part to the formula - the machine has to end in an accepting state. Actually building up all of these pieces of the formula is pretty tricky (that's why you should look at a textbook). However, the net result is that if the formula is satisfiable, there's a series of IDs that show that M accepts w (so w is in L(M)), and if it's unsatisfiable then there is no way for M to accept w.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Np completeness - Need some clarification in reduction\r\n                \r\nI wanted some clarification in a concept.\nFor proving that a problem is NP complete, we use reductions. \n\nNow suppose I have L<=L'. has the reduction to be from L to L' or can I do it it the reverse way also? i.e Can I show that if L can be solved using L', then L' is NP-complete??\n\nI am pretty confused regarding this.\n\nFor example. for a reduction from ham cycle to ham path, we so it the backward way.\n\nAlso, I am not able to solve the problem that I have to show that \"is there a path from s to t in a graph with at least k edges\" by reduction from ham cycle. \n\nPlease give me a clarification and guide me with the above problem. Thanks\n    ", "Answer": "\r\nTo show that a language L is NP-complete you actually need to prove two things, L is in NP and L is NP-hard. Usually, proving L is in NP is easy, but don't forget to do it.\n\nThe normal way of showing L is NP-hard is to show, in effect, that a polynomial-time decider for L could be used to build a polynomial-time decider for a language L' that has been proved to be NP-complete.\n\nIt has to be that way round. There are many cases of a polynomial-time decidable language L for which a polynomial time decider could be built from a polynomial time decider for an NP-complete language. For example, consider the polynomial time decidable problem of coloring a graph with two colors, vs. the NP-complete general graph coloring problem.\n\nI gave you a hint in a comment on your question about Hamiltonian Cycle. Have you read the hint and thought about it? If so, please respond in that question.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Booking System is NP Complete\r\n                \r\nI have to show that the following problem is NP-Complete and need some helpful hints on how to proceed. \n\nThe problem:\n\nWe're looking at a meeting booking system. The input is a list n of possible times as well as m lists (where m <= n), one list per person containing their choice of possible meeting times. For each possible time, a priority number is also given. For each reservation time in the list of n, a cost is also given. (Cost of booking the room). The algorithm should assign times so that the combined priority for those who have booked should be as small as possible while the total cost of booking should not be higher than M. \n\nNP\n\nSo first to show that it's in NP we should show that given a correct solution it can be verified that it is indeed correct. I guess it should verify that that the cost is below the threshold of K and that the priority of the correct solution is indeed the minimum - both of which can be done in Polynomial time I assume. We traverse through the lists of people, assert that each one has a time granted to them, add up the cost in a variable and at the end of this list assert that the cost is below K. The priority can be dealt with in similar fashion I suppose? \n\nNP Hard\n\nThen to show it's NP Hard I can use the Knapsack Problem since they're rather similar. With input S, size of bag, a list of items with weight w and value v as well as the goal W which is the goal-value. I guess it's clear that S can correlate to cost and that W correlate to the priority? So we want S, the size, to be below S i.e we have the similar condition for the problem above where the cost has to be below K. Then W, the total value should generally exceed W, but in our case we want it to be as low as possible which seems doable.\n\nI'm afraid I might've gone the wrong way when it comes to verifying the problem. Also the reduction to show it's NP Hard is perhaps not thought out all the way. Some pointers would be very helpful! Thanks\n    ", "Answer": "\r\nNP\n\nWhen you are proving the problem is in NP, you must first turn your problem into a decision problem. Then you can verify your certificate in polynomial time as you started to describe.\n\nNP Hard\n\nYou need to transform the Knapsack problem into your meeting problem. You are going the right way because you are transforming size and weight from Knapsack into the meeting problem. Once you figure out the transformation, you must verify that it can be done in polynomial time. Finally, you can show that the solution to Knapsack is a solution to meeting problem and vice versa.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "3 partition np completeness\r\n                \r\nI want to know how 3 partition problem is NP complete ? We have to find triplets in set which sums to target. So isn't time complexity will be O(n^3) which is polynomial ?\nsolution: https://www.geeksforgeeks.org/find-a-triplet-that-sum-to-a-given-value\noriginal question: https://en.wikipedia.org/wiki/3-partition_problem\nAlso, can someone explain the reduction from partition to 3 partition by example.\n    ", "Answer": "\r\nThe problem is not to find a triplet (which would be O(n^3)) but a way to split the set into triplets which all have the same sum; the brute-force approach would be to test all such partitions, which would not be polynomial.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Proof of np-completeness\r\n                \r\nShow that the following problem is NP-complete.\n\n\n  The tv problem is to select tv shows for a weekly tv night so that\n  everyone in a group of people sees something that they like. You are\n  given a list of people (P1, . . . , Pn) in the group and a list of\n  possible shows (S1, . . . , Sk). For each show Si, there is a subset\n  of the people who would like that show choice. You also get w, the\n  number of weeks for which you can select shows. The question is\n  whether there are these many movies so that every person likes at\n  least one of them.\n\n\nI can't figure out which np problem can be reduced to this and how to establish the certificate. \n    ", "Answer": "\r\nYou can model this as the Set cover problem. You have elements {P1, ..., Pn}, and k subsets of these, T1, ..., Tk, defined as Ti = {Pj : Pj likes Si}. You then want to find the smallest collection of subsets such that their union is the whole set of people. Deciding whether the number of necessary subsets is less than or equal to a number is NP-complete. Finding the actual optimal collection of subsets is NP-hard.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Some inference about NP [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 8 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nthis is my first question on this site. \n\nI‌ recently, study on NP. I have some confusion about this Topic, and want to propose my inference and some one verify me.\n\n\n  I) each NP problem can be solved in Exponential Time. \n  \n  II) if P=NP then NP=NP-Complete.\n  \n  III) Problem of factorization into 2-prime factor, is NP.\n  \n  IV) if problem X can reduce to a known NP-Hard problem, then X must be\n  NP-HARD.\n\n\nanyone can verify my inference and learn me?‌ \n    ", "Answer": "\r\n\n  I) each NP problem can be solved in Exponential Time.\n\n\nYes, this because it can be solved in polynomial time on Non Determinisitc Machine (definition of NP), and thus can be solved on a Deterministic Machine in exponential time.\n\n\n  II) if P=NP then NP=NP-Complete.\n\n\nYes, because if P=NP, \"yes\" and \"no\" answers for all NP problems are equivalently easy to achieve, run the polynomial time algorithm for the \"yes\" problem, and answer like it. Result is always correct and runs in polynomial time, assuming such a polynomial time machine exists.\n\n\n  III) Problem of factorization into 2-prime factor, is NP.\n\n\nYes. Given an number and its prime factorization - it is easy to verify if this is the correct answer (this is equivalent definition of problem being in NP).\n\n\n  IV) if problem X can reduce to a known NP-Hard problem, then X must be\n  NP-HARD.\n\n\nNo, it should be the other way around. You need to reduce a known NP-Hard Problem to X, and then you can tag X as NP-Hard.\nRememeber that every problem in NP has a reduction to SAT (Cook Levin theorem), and yet P != NP-Complete (or so we think at least)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Polynomial time algorithm for a NP-hard [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 11 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\n\n  Possible Duplicate:\n  NP vs NP-Complete vs NP-Hard — what does it all mean?  \n\n\n\n\nEuler circuit problem can be easily solved in polynomial time\nHamilton circuit problem is proved to be NP-hard\nnobody in the world can give a polynomial time algorithm for a NP-hard problem\n\nWhat is meant by polynomial time and NP-hard? I know what is O(n).\n    ", "Answer": "\r\nPolynomial time means that there exist a constant ```\na```\n, such that the complexity of your algorithm is ```\nO(n^a)```\n.\n\nHere is an explanation about ```\nNP-hard```\n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Coin distribution exercise - is it NP-Complete?\r\n                \r\nI want to know if the following problem is NP-Complete or if there's a specific algorithm that solves it:\n\nImagine you have a certain amount of money, 30€ for example, in coins and bills of specific values (0.01€, 0.05€, 5.00€...). \n\nThe quantity of the coins and bills we have is given and you have to distribute it amongst some people A, B, C, etc.\n\nYou want A to have a certain amount of money (10€, for example), B to have a different or equal amount, and so on. \n\nThe sum of the \"demanded\" money is not greater than the money we have.\n\nSo, the question is: ```\nis there a distribution of coins and bills such that every person has the quantity of money that belongs to him?```\n\n\nThanks in advance!\n    ", "Answer": "\r\nOne can reduce instances of this problem to Bin Packing (by having A=B=C=...) or to Knapsack (by having only A and B, with B=total-A). Both Bin Packing and Knapsack are known to be NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this \"Valid mathematical expression\" problem P, or NP?\r\n                \r\nThis question is purely out of curiosity. I am off school for the summer, and was going to implement an algorithm to solve this just for fun. That led to the above question, how hard is this problem?\n\nThe problem: you are given a list of positive integers, a set of mathematical operators and the equal sign(=). can you create a valid mathematical expression using the integers (in the same order) and the operators (any number of times)? \n\nAn example will should clarify any questions:\n\ngiven: {2, 3, 5, 25} , {+, -, *, /} , {=}\n   output: YES\n\nthe expression (only one i think) is (2 + 3) * 5 = 25. you only need to output YES/NO.\n\nI believe the problem is in NP. I say this because it is a decision problem (YES/NO answer) and I can find a non-deterministic poly time algorithm that decides it. \n\na. non-deterministically select a sequence of operators to place between the integers.\n   b. verify you answer is a valid mathematical expression (this can be done in constant\n      time). \n\nIn this case, the big question is this: Is the problem in P? (i.e. Is there a deterministic poly time algorithm that decides it?) OR Is the problem NP complete? (i.e. Can a known NP Complete problem be reduced to this? or equivalently Is every NP language poly time reducable to this problem?) OR neither? (i.e. problem in NP but not NP Complete)\n\nNote: This problem statement assumes P not equal to NP. Also, although I am new to Stack Overflow, I am familiar with the homework tag. This is indeed just curiosity, not homework :)\n    ", "Answer": "\r\nAn straightforward reduction from the Partition problem (which is NP-Complete) - given a set of N integers S, the input to the \"Valid Math\" problem would be - the elements of S, N-2 '+' operators and an '=' sign.  \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Trying to proof NP-completeness\r\n                \r\nImagine I have an equation like\n\nA + B + C + D + E + F + G + H + … = Some Value\n\nAnd every summand has an upper limit\n\nA ≤ 500,\nB ≤ 200,\nC ≤ 300,\nD ≤ 600,\n…\n\nIf i want a program to determine every possible combination of the summands, would the problem be NP-complete?\nHow would the mathematical proof look like?\n\nIf not, how would an efficient algorithm for this problem look like?\n    ", "Answer": "\r\nTo determine whether the problem is NP complete, you must first figure out if it is in NP. We need to create a decision question from the problem. \n\nIf you wanted to set a limit on the sum without actually having to determine all the combinations of the summands, the decision question could be: Are there limits for A, B, C... such that the sum is ≤ k? Then your certificate could be a set of limits on the summands.\n\nHere, the decision question is unclear and a certificate cannot be verified. This problem, as it is phrased, is not in NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "understanding this NP-complete optimization?\r\n                \r\nHas anyone seen this problem before? It's supposed to be NP-complete.\n\n\n  We are given vertices V_1,...,V_n and possible parent sets for each vertex. Each parent set has an associated cost. Let O be an ordering (a permutation) of the vertices. We say that a parent set of a vertex V_i is consistent with an ordering O if all of the parents come before the vertex in the ordering. Let mcc(V_i, O) be minimum cost of the parent sets of vertex V_i that are consistent with ordering O. I need to find an ordering O that minimizes the total cost: mcc(V_1, O), ... ,mcc(V_n, O).\n\n\nI don't quite understand the part \"...if all of the parents come before the vertex in the ordering.\" What does it mean?\n    ", "Answer": "\r\nNo, I haven't seen that problem before. \n\nAs for the bit you're not sure about - an ordering is just an order of all the vertices, so I think \"if all the parents come before the vertex in the ordering\" just means exactly what it says. For instance, say (A, B) is one parent set of D: that parent set is consistent with the ordering [A,B,C,D], since A and B are before D, and not consistent with the ordering [A,D,B,C], since B is after D; however, say (A) is another parent set of D - that one is consistent with both those orderings.  Does that make sense?\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "understanding this NP-complete optimization?\r\n                \r\nHas anyone seen this problem before? It's supposed to be NP-complete.\n\n\n  We are given vertices V_1,...,V_n and possible parent sets for each vertex. Each parent set has an associated cost. Let O be an ordering (a permutation) of the vertices. We say that a parent set of a vertex V_i is consistent with an ordering O if all of the parents come before the vertex in the ordering. Let mcc(V_i, O) be minimum cost of the parent sets of vertex V_i that are consistent with ordering O. I need to find an ordering O that minimizes the total cost: mcc(V_1, O), ... ,mcc(V_n, O).\n\n\nI don't quite understand the part \"...if all of the parents come before the vertex in the ordering.\" What does it mean?\n    ", "Answer": "\r\nNo, I haven't seen that problem before. \n\nAs for the bit you're not sure about - an ordering is just an order of all the vertices, so I think \"if all the parents come before the vertex in the ordering\" just means exactly what it says. For instance, say (A, B) is one parent set of D: that parent set is consistent with the ordering [A,B,C,D], since A and B are before D, and not consistent with the ordering [A,D,B,C], since B is after D; however, say (A) is another parent set of D - that one is consistent with both those orderings.  Does that make sense?\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity class of problems solvable in polynomial-time which are not decision problems\r\n                \r\nComplexity class P ~ set of all decision problems that can be solved by a deterministic Turing machine in polynomial time.\nA decision problem is a problem which can be stated as a yes/no question.\n\nSo how would you formally classify problems such as:\n\n\nfind the maximum number in an unsorted list of length n?\nwhat is the shortest path in a weighted, undirected graph?\n\n\nClearly these problems can be solved in polynomial time, but they are not decision problems. \n\nThis however is different for NP-complete versus NP-hard problems. Example (TSP):\n\n\nTSP (decision version): does there exist a tour that visits all cities, and costs less than L? (NP-complete)\nTSP (optimization version): what is the shortest tour that visits all cities? (NP-hard).\n\n\nIn other words, the class of NP-hard problems is not restricted to decision problems; it can also contain search or optimization problems. So why do most (all?) definitions of complexity class P limit the definition to decision problems?\n    ", "Answer": "\r\nBecause any optimization problem can be converted into multiple decision problems in P. If your question is what is the shortest tour that visits all cities, you can convert this into n decision problems. \n\nDoes there exist a tour that visits all cities, and costs less than n?\n\nDoes there exist a tour that visits all cities, and costs less than n-1?  \n\nDoes there exist a tour that visits all cities, and costs less than n-2? \n\nBecause there are at most n different options, converting an optimization problem into a decision problem can take place in polynomial time. Therefore, if a decision problem is in P, the corresponding optimization problem is also in P.\n\nAlso, an NP-complete problem is just an NP-hard problem that is also in NP. It has nothing to do with whether or not the problem is a decision problem or an optimization problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Radix Sort is an example of complexity algorithm P or NP?\r\n                \r\nThe problem of ordering a vector by Radix Sort is an example of a complexity algorithm P?\n\nI do not know if it can be NP-Complete or just NP.\n\n```\nvoid radixsort(int vector[], int size) {\n    int i;\n    int *b;\n    int bigger= vector[0];\n    int exp = 1;\n\n    b = (int *)calloc(size, sizeof(int));\n\n    for (i = 0; i < size; i++) {\n        if (vetor[i] > bigger)\n            size= vector[i];\n    }\n\n    while (bigger/exp > 0) {\n        int bucket[10] = { 0 };\n        for (i = 0; i < size; i++)\n            bucket[(vetor[i] / exp) % 10]++;\n        for (i = 1; i < 10; i++)\n            bucket[i] += bucket[i - 1];\n        for (i = size- 1; i >= 0; i--)\n            b[--bucket[(vector[i] / exp) % 10]] = vector[i];\n        for (i = 0; i < size; i++)\n            vector[i] = b[i];\n        exp *= 10;\n    }\n\n    free(b);\n}\n```\n\n    ", "Answer": "\r\nOf course, it is in P! as its complexity is polynomial. Answer the other questions is related to the relation of these class of complexities. P is in NP. Hence, radix sort is in NP. As we do not know any polynomial agorithm for NP-Complete problems, hence, we do not know it is in NP-Complete or not and it is related to the known problem that is P = NP?\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is it NP-complete to find a sub-maximal clique which is at least max clique size - 1?\r\n                \r\nIt is well-known that it is a NP-complete problem to find a maximal clique in a graph. But I wonder know if it possible to find a sub-maximal clique in a graph in polynomial time. That is, given that we don't know whether ```\nP=NP```\n or not, is there a polynomial algorithm that would give me a clique whose size is at least the maximal clique size minus 1?\nI guess the answer is \"no\", because I know that there isn't a polynomial-time algorithm that gives me a clique whose size is exactly maximal clique size minus 1 - otherwise I would know the size of max clique by this algorithm in polynomial time, which is impossible if ```\nP!=NP```\n.\nBut I just don't know how to prove it when we expect the algorithm to return a clique with size at least maximal clique size minus 1 - say, it may randomly return a clique, whose size may be maximal, or may be maximal-1.\nIs there any approach to prove its NP-completeness? Or such an algorithm really exists?\n    ", "Answer": "\r\nI just got the answer by myself. The maximal clique problem can be reduced to this problem.\nGiven a maximal clique problem with graph ```\nG```\n, we can duplicate the graph ```\nG```\n to a new graph ```\nG'```\n. Then combine the two graphs in the following manner: if there is an edge between two vertices in graph ```\nG```\n, connect each pair of the two vertices in ```\nG```\n and ```\nG'```\n; and for each vertex in ```\nG```\n, connect it and its duplication in ```\nG'```\n.\nThen, each clique in ```\nG```\n of size ```\nm```\n with its duplication in ```\nG'```\n consist of a larger clique of size ```\n2m```\n. So, there is a clique of size ```\nm```\n if and only if there is a clique of size ```\n2m```\n in ```\nG'```\n.\nSo, to find the maximum clique in ```\nG```\n, we just find the sub-maximum clique in ```\nG'```\n and the clique must contains all vertices in the maximum clique of ```\nG```\n. Thus, we know the maximum clique in ```\nG```\n in polynomial time, which is only possible when ```\nP=NP```\n.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete Graph optimization: minimal node selection?\r\n                \r\nSuppose you have a graph ```\nG = (V, E)```\n that represents the floor plan of a one-story shopping mall.  The individual stores are represented by vertices, and the edges between vertices represent some arbitrary definition of stores being close to each other.\n\nRecently, there has been an increase in the amount of shoplifting that occurs in this mall, so management decides to make it so that every store either:\n\n\nHas a security guard stationed in it\nOr is close to a store that has a security guard stationed in it\n\n\nWhile hiring as few security guards as possible.\n\nHow would you prove this optimization problem is NP-complete?  I feel like it's a simple reduction from the independent set problem, but I want to make sure.\n    ", "Answer": "\r\nThis is exactly the minimum vertex cover problem which is known to be NP-complete. The key insight in seeing that computing the size of a minimum vertex cover is equivalent to computing the size of a maximum independent set is the following:\n\n```\nA set of vertices is a vertex cover, if and only if its complement is an independent set.```\n\n\nIn particular, this means that the total number of vertices is equal to the size of a minimum vertex cover plus the size of a maximum independent set. This illustrates nicely how computing one number reduces to computing the other.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reducing 3-Coloring to 10-Coloring (NP-completeness)\r\n                \r\nI am trying to show that the NP-Complete problem of 3-coloring a graph reduces to the problem of 10-coloring a graph.I have already shown how 10-coloring can be verified in polynomial time, and is thus in NP. Now I just need to show it indeed can be reduced to 3-coloring.\n\nMy thinking was to essentially prove a bi-conditional: given a graph G, we have that G has a 3-coloring iff G has a 10-coloring. Now, I am not sure how to go about showing this since, fairly obviously, G could have a 10-coloring and not a 3-coloring. So this leads me to believe that there must be some reduction that alters G in some way that lets me see that, yes, 3-coloring does reduce to 10-coloring. Problem is, I am having a difficult time visualizing this.\n\nCan anyone help me out?\n    ", "Answer": "\r\nTake your given Graph ```\nG```\n and complement it with an instance of ```\nK_7```\n such that for each vertex pair ```\n(u, v) \\in G x K_7```\n an edge be added to form a new Graph ```\nG'```\n. This enhancement can obviously be done in polynomial time.\n\n\nIf ```\nG```\n is 3-colorable, ```\nG'```\n is 10-colorable:\nTake a 3-coloring of ```\nG```\n, use 7 other colors to color the ```\nK_7```\n instance.\nIf ```\nG```\n is not 3-colorable, ```\nG'```\n is not 10-colorable:\nThe instance of ```\nK_7```\n in ```\nG'```\n consumes 7 colors. None of these colors may occur in ```\nG```\n, as there is an edge between each pair of vertices from ```\nG```\n and the ```\nK_7```\n instance, respectively. \nConsider an arbitrary 3-color assignment on ```\nG```\n. Since ```\nG```\n is not 3-colorable, there must be edges ```\n((x_i, y_i)_i=1..m```\n whose vertices are given the same color under this assignment.\nAssume that we re-color all vertices ```\n{x_i, y_i}_i=1..m```\n simultaneously. However, no vertex' new color may be among the colors used for the ```\nK_7```\n instance nor among the 3 colors used for vertices of ```\nG```\n ( in the latter case the assignment restricted to ```\nG```\n still would not be admissible after the recoloring). Therefore we would need an 11th color.\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reduction of A to B : True or False\r\n                \r\nThere are two statements:\nIf a decision problem A is polynomial-time reducible to a decision problem B (i.e., ```\nA≤ pB```\n ), and B is NP-complete, then A must be NP-complete.\n\nAnd: \n\nIf a decision problem B is polynomial-time reducible to a decision problem A (i.e., ```\nB≤ pA```\n ), and B is NP-complete, then A must be NP-complete.\n\nWhich of the above statements are true?\n\nCan you also give explanation?\n    ", "Answer": "\r\nthe first statement is false because it means that by solving B and then applying some polynomial time algorithm you can solve A but maybe there is another way to solve A that doesn't require solving B and maybe it's only polynomial.\n\nthe second statement is true because it means that you can solve B by first solving A then apply some polynomial time algorithm to solve B but B is NP-complete so A has to be NP-complete \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP problems can be solved in deterministically EXPONENTIAL time?\r\n                \r\nany problem in NP can be solved in deterministically exponential time,\nor we can say that \nany language in NP can be decided by an algorithm running in time 2^O(n^k)\ni.e., NP  ⊆ EXP\n\ninformally speaking, we just try each one of the possible solutions and then decide it\n\nHowever, there is a simple example that I can not figure out what's wrong with the idea i made\n\nHere it is..\n\nThe Traveling Salesman problem : given a undirected graph G=(V,E)  V=|n|\n\nThis is a well-known NP-complete problem, therefore, indeed belongs to NP\n\nAnd I try to analyse the running time..like this:\n\nI simply list out all the possible solutions, and there are (n-1)! possible tours in total\n\nThen I check each one of them, it takes O(n) for each possible tour\n\nThe total running time will be O(n!)\n\nIt doesn't look like can be bounded above by 2^O(n^k), i.e., exponential time\n\nwhere is the pitfall of this analysis?\n\nor in the other word, how can we explain traveling salesman problem indeed can be decided by an algorithm running in time 2^O(n^k)\n    ", "Answer": "\r\nNote that\n\n\n  n! ≤ nn = (2log n)n = 2n log n ≤ 2n2\n\n\nSo n! = 2O(n2), so n! &in; EXP.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Implementation of Graph Coloring Algorithms [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is seeking recommendations for books, tools, software libraries, and more. It does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     We don’t allow questions seeking recommendations for books, tools, software libraries, and more. You can edit the question so it can be answered with facts and citations.\r\n                \r\n                    \r\n                        Closed 6 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI came to know that graph colouring algorithms are NP-Complete problems. Still, I want to know whether any implementation is possible using heuristic approach or not, especially the distinguishing graph colouring? If possible then is there any suitable resource to learn about that ?\n    ", "Answer": "\r\nAs discussed in a somewhat related post:\n\nConstraint solvers like MiniZinc are able to solve a broad range of graph colouring problems.\n\nThis MiniZinc example demonstrates colouring of the Petersen graph:\n\n```\n%  Petersen Graph\nset of int: Colors = 1..3;\nset of int: Nodes = 1..10;\nset of int: Edges = 1..15;\narray[Edges] of Nodes: aFrom = [ 1, 2, 3, 4, 1, 1, 2, 3, 4,  5, 6,  7, 7,  8, 6 ];\narray[Edges] of Nodes: aTo   = [ 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 8, 10, 9, 10, 9 ];\n\narray[int] of string: colorName = [ \"red\", \"green\", \"blue\", \"purple\", \"yellow\", \"brown\", \"black\" ];\n\narray[Nodes] of var Colors: nodeColor;\n\nconstraint\n  forall(e in Edges) (\n      nodeColor[aFrom[e]] != nodeColor[aTo[e]]\n  );\n\nsolve satisfy;\n\noutput [ show(colorName[nodeColor[n]]) ++ \"\\n\" | n in Nodes ];    \n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "how do I construct np-reduction for this matching problem?\r\n                \r\nI have a matching problem, which I think is np-hard:\n```\nWe need to arrange a dinner for a group of n people, some of the people are friends with eachother, some are not. We need to sit everyone at a table, but they should never sit with someone that they are not friends with. There are *k* tables K = r1+r2+···+rk=n.\n\n**Input**\ninput is formatted as one first line k, then follow one line of k numbers, where each number represents a table and it's capacity. Then comes n lines of people, where we can see friendships of person i. All friendships are mutual.\n\n**Output**\n\nOutput the formations of people that can be seated together, without having to sit with someone that they are not friends with\n\n example: \n Input:\n 2\n 3, 3\n Alice:  Bob, Claire, Eric, Juliet, Romeo\n Bob:  Alice, Claire, Juliet, Romeo\n Claire:  Alice, Bob, Juliet\n Eric:  Alice, Romeo\n Juliet:  Alice, Bob, Claire\n Romeo:  Alice, Bob, Eric\n\n Output:\n Romeo, Eric, Alice \n Bob, Claire, Juliet\n```\n\nIm fairly certain that this problem is np-complete, but I am having some problems finding a proper reduction.\nThe example corresponds to the following (badly drawn)graph:\n\nI have a loose idea around using a complimentary graph to reduce to independent set. but i would be very gratefull for any ideas for solutions\n    ", "Answer": "\r\nClique problem reduction\nFirst off, note that NP is a class for decision problems, so we'll adjust the question to \"is there a table arrangement?\" instead of \"output the table arrangement\". In practice there is of course no real difference.\nNow, given a graph, let's say we want to know if there is a clique of at least size ```\nk```\n. This is the (decision) clique problem, which is one of the famous NP-complete problems.\nThis graph will have at least one clique of size ```\nk```\n if and only if your matching problem has a solution for the same graph, with a table of size ```\nk```\n. The seating for all the others should be unconstrained, so we have ```\nn-k```\n one-seat tables.\nThus, we can create an instance of the matching problem that is equivalent to any instance of a known NP-complete problem. This instance is roughly the same size (no exponential blow-up), so this constitutes a reduction, proving that the matching is NP-hard. As it is also (clearly?) in NP, it is also NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Performance difference between \"int a, b;\" and \"int a; int b;\"?\r\n                \r\nIt's an easily described in question as the title says.\n\nThis question came to my mind every time I can put two separate statements together in a block. Especially when I code for CPU cost problems like NP-complete problems.\n\nIs there any, necessary to combine two separate statements together?.\n    ", "Answer": "\r\n\n  Performance difference between “int a, b;” and “int a; int b;”?\n\n\nThose declarations are semantically equivalent, and there is no reason why either would generate different program from the other, and therefore no reason why there would be difference in performance.\n\nHowever, the first declaration is shorter by a few characters, so the compilation process might be a few micro-seconds faster for the time that's needed to load the source file from the disk.\n\n\n  Is there any necessary to combine two separate statements together?\n\n\nIn general, no.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Venn Diagram Drawing Algorithms\r\n                \r\nSomeone asked about overlapping subclusters in GraphViz and got the following response:\n\n\n  Sorry, no. General subgraphs can share nodes without implying subset\n  containment but not clusters. The problem is in the drawing.\n  If clusters can overlap arbitrarily, drawing them becomes the problem\n  of drawing Venn diagrams, for which there are no good algorithms.\n\n\nWhat is a formal definition or example of the \"problem of drawing Venn diagrams\"?, and why is it (I assume NP-complete/hard) hard ?  (Extra points: Sketch a reduction to a well-known NP-complete problem)\n    ", "Answer": "\r\nYou have N points and a binary relation R on them, and you need to represent the relation graphically so that every node is represented by a circle on Euclidean plane so that two circles overlap if and only if for the corresponding nodes n and n' it holds that n R n'.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Pick one item of each type with highest value without exceeding budget\r\n                \r\nGiven the list of items below, a budget B and a list of item types (T1, T2, T3...TN), pick 1 item of each type that provides the most value (most expensive) without exceeding the budget.\n\n```\n[\n  {\n    \"id\": \"1\",\n    \"types\": \"T1\",\n    \"price\": 1000,\n  },\n  {\n    \"id\": \"2\",\n    \"types\": \"T2\",\n    \"price\": 109292,\n  },\n  {\n    \"id\": \"3\",\n    \"types\": \"T3\",\n    \"price\": 7228,\n  },\n  {\n    \"id\": \"4\",\n    \"types\": \"T4\",\n    \"price\": 1000,\n  },\n]\n```\n\n\nExplored knapsack problems and not sure if this is a NP-complete problem.\n    ", "Answer": "\r\nJust use ```\nfilter```\n to find all items that do not exceed budget, then ```\nsort```\n it in descending order and take the first element:\n\n\r\n\r\n```\nconst array = [{\r\n    \"id\": \"1\",\r\n    \"types\": \"T1\",\r\n    \"price\": 1000,\r\n  },\r\n  {\r\n    \"id\": \"2\",\r\n    \"types\": \"T2\",\r\n    \"price\": 109292,\r\n  },\r\n  {\r\n    \"id\": \"3\",\r\n    \"types\": \"T3\",\r\n    \"price\": 7228,\r\n  },\r\n  {\r\n    \"id\": \"4\",\r\n    \"types\": \"T4\",\r\n    \"price\": 1000,\r\n  },\r\n];\r\n\r\nconst budget = 9000;\r\n\r\nvar budgetMatch = array.filter(({ price }) => price <= budget);\r\nbudgetMatch.sort(({ price: a}, { price: b}) => b - a);\r\n\r\nvar highestPrice = budgetMatch[0];\r\n\r\nconsole.log(highestPrice);```\n\r\n\r\n\r\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "List of O(n^2) and O(n^3) algorithms that aren't linear algebra? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and  cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened,  visit the help center.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 10 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI've been reading a lot of papers on performance optimizations for matrix-vector multiplication (BLAS2) and matrix-matrix multiplication (BLAS3). I'd like to think about if/how these optimizations would apply to O(n^2) and O(n^3) algorithms that don't cleanly reduce to dense or sparse linear algebra.  \n\nIt's easy to find lists of NP-complete or NP-hard algorithms, but I haven't found a good breakdown of common (and not-so-common) polynomial time algorithms. Can anyone suggest a list of polynomial-time problems for which the best known algorithm is O(n^2) or O(n^3)?\n\nEdit: To make this more concrete, I'm looking for something like this list of NP-complete problems, but for polynomial problems with n^2 or n^3 algorithms instead. \n    ", "Answer": "\r\nFirst: It's worth noting that the complexity of level-two and level-three BLAS operations are actually formally O(n) and O(n^3/2); the input matrices are themselves quadratic in what people usually think of as \"n\".\n\nThe techniques commonly used for dense linear algebra do not really apply directly to other problem domains, because they tend to make heavy use of linearity of the problem.\n\nNext: some of the most common examples of O(n^2) algorithms are the naive algorithms for sorting, integer multiplication, and computing discrete Fourier transforms.  In all of these cases, better algorithms with lower complexity exist.  Similarly, there is a large number of naive O(n^3) algorithms.\n\nOne can apply dense linear algebra techniques to computing the DFT (since it is also linear), but you can do much better still by using one of the FFT algorithms, so in practice no one does this.\n\nAs far as non-naive algorithms go, it's been far too long since I had to teach a complexity course; IIRC, the best known algorithm for deciding if a string is in a context-free language is O(n^3).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Which of the following problems can be reduced to the Hamiltonian path problem?\r\n                \r\nI'm taking the Algorithms: Design and Analysis II class, one of the questions asks:\n\n\n  Assume that P ≠ NP. Consider undirected graphs with nonnegative edge\n  lengths. Which of the following problems can be solved in polynomial\n  time?\n  \n  Hint: The Hamiltonian path problem is: given an undirected graph with\n  n vertices, decide whether or not there is a (cycle-free) path with n\n  - 1 edges that visits every vertex exactly once. You can use the fact that the Hamiltonian path problem is NP-complete. There are relatively\n  simple reductions from the Hamiltonian path problem to 3 of the 4\n  problems below.\n  \n  \n  For a given source s and destination t, compute the length of a shortest s-t path that has exactly n - 1 edges (or +∞, if no such path\n  exists). The path is allowed to contain cycles.\n  Amongst all spanning trees of the graph, compute one with the smallest-possible number of leaves.\n  Amongst all spanning trees of the graph, compute one with the minimum-possible maximum degree. (Recall the degree of a vertex is the\n  number of incident edges.)\n  For a given source s and destination t, compute the length of a shortest s-t path that has exactly n - 1 edges (or +∞, if no such path\n  exists). The path is not allowed to contain cycles.\n  \n\n\nNotice that a Hamiltonian path is a spanning tree of a graph and only has two leaf nodes, and that any spanning tree of a graph with exactly two leaf nodes must be a Hamiltonian path. That means that the NP-Complete problem of determining whether a Hamiltonian path exists in a graph can be solved by finding the minimum-leaf spanning tree of the graph: the path exists if and only if the minimum-leaf spanning tree has exactly two leaves. Thus, problem 2 is NP-Complete.\n\nProblem 3 is NP-Hard; here is a paper that proves that.\n\nThat means, between 1 and 4, one is NP-Complete, another is in P. It seems like problem 4 reduces trivially to the the Hamiltonian path problem, but I'm not able to understand how having a cycle makes it solvable? Or is it the other way?\n    ", "Answer": "\r\nFor the first one you can use Dijkstra to get shortest even and odd distances possible. To this end for every vertex you need to store not a single minimum number, but two of them. One is minimum weight of an odd path, another one is for minimum weight of an even path. After you have these two lengths you can easily increase path length by even number of edges if cycles are allowed. So, the first problem is from P. Step-be-step algorithm would be:\n\n\nFind shortest even and odd length paths.\nIncrease length of one of these paths which has the same parity as ```\nn-1```\n to ```\nn-1```\n by adding cycle of length 2 required number of times.\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Complete? Optimal graph embedding for a graph with specific constraints\r\n                \r\nI have a grid based graph, where nodes and edges occupy cells. Edges can cross, but cannot travel on top of each other in the same direction. \n\nLets say I want to optimize the graph so that the distance covered by edges is minimized.\nI am currently using A* search for each connection, but the algorithm is greedy and does not plan ahead. Consider the diagram below, where the order in which connections are made is changed (note also that there can be multiple shortest paths for any given edge, see green and \npurple connections). \n\n\n\nMy intuition says this is NP-Complete and that an exhaustive search is necessary, which will be extremely expensive as the size of the graph grows. However, I have no way of showing this, and it is not quite the same as other graph embedding problems which usually concern minimization of crossing.\n    ", "Answer": "\r\nYou didn't really describe your problem and your image is gone, but your problem sounds like the minimum T-join problem.\n\nThe minimum T-join problem is defined on a graph G.  You're given a set T of even size, and you're trying to find a subgraph of the graph where the vertices of T have odd degree and the other vertices have even degree.  You've got weights on the edges and you're trying to minimise the sum of the weights of edges in the subgraph.\n\nSurprisingly, the minimum T-join problem can be solved in polynomial time thanks to a very close connection with the nonbipartite matching problem.  Namely, if you find all-pairs shortest paths between vertices of T, the minimum T-join is attained by the minimum-weight perfect matching of vertices in T, where there's an edge between two vertices whose length is the length of the shortest path in G.\n\nThe minimum T-join will be a collection of paths.  If two distinct paths, say a->b and c->d, use the same edge uv, then they can be replaced by a->u->c and b->v->d and reduce the cost of the T-join.  So it won't use the same edge twice.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "class NP, polynomial-time verification CLIQUE\r\n                \r\nThe CLIQUE problem-- problem of finding the \nmaximum clique in a graph is NP-complete. \nThat is, CLIQUE is \n\na.) in NP and \nb.) there is an NP complete problem, 3-SAT for one, \nthat reduces to CLIQUE in polynomial time. \n\nPart (b) above is fine-- all over in every resource and very well explained. \nFor Part (a), from what i know, we need to have the following:\nGiven a specific solution instance, we need to show that \nit can be verified, in polynomial time, that that solution is an answer to this problem. \nSo for instance, given a specific graph and a subgraph of it, we should be \nable to check whether that subgraph is a clique of maximum size in that graph. \n\nThe resources I've read so far are phrasing this \nPart (a) here as \"easy, straightforward, etc\" or \n\"it can be shown in O(n^2) time that the given subgraph is a clique/not\". \nHowever, the verification here is not just whether it's a clique, but also is whether it is a maximum clique in the graph. \nHow can this be decided in polynomial time?\n\nWhat am i missing here?\n    ", "Answer": "\r\nYou are confusing the optimization version of the problem with the decision version of the problem.   \n\nThe decision version of clique asks if the graph has a clique of size k.  Given a candidate solution, you can test its feasibility in polynomial time. Focus on the decision versions for NP-completeness proofs.\n\nCertificates of optimality for the optimization problems are indeed harder to come by.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-hardness. Is it average case or worst-case?\r\n                \r\nDo we measure the NP-hardness in terms of average-case hardness or worst-case hardness?\nI've found this here:\n\"However, NP-completeness is defined in terms of worst-case complexity\".\nDoes it remain true to NP-hardness?\nI don't know what the term \"worst-case complexity\" means. What is the difference between worst-case complexity and worst-case problems?\n    ", "Answer": "\r\nAn interesting nuance here is that NP-hardness, by itself, doesn’t speak about worst-case or average case complexity. Rather, the formal definition of NP-hardness purely says that there’s a polynomial-time reduction from every problem in NP to any NP-hard problem. That reduction means that any instance of any problem in NP could be solved by applying the reduction and then solving the NP-hard problem. But because this applies to “any instance” and the specific transform done by the reduction isn’t specified, that definition by itself doesn’t say anything about average-case complexity.\nWe can artificially construct NP-hard problems that are extremely easy to solve on average. Here’s an example. Take an NP-hard problem - say, the problem of checking whether a graph is 3-colorable. We can solve this in time (roughly) O(3n) by simply trying all possible colorings. (The actual time complexity is a bit higher because we need to check edges in each step, but let’s ignore that for now). Now, we’ll invent a contrived problem of the following form:\n\nGiven a string of 0s, 1s, and 2s, determine whether\n\nThe first half of the string contains a 1 or a 2, or\nWhether it doesn’t and the back half of the string is a base-3 encoding of a graph that’s 3-colorable.\n\n\nThis problem is NP-hard because we can reduce graph 3-colorability to it by just prepending a bunch of 0s to any input instance of 3-colorability. But on average it’s very easy to solve this problem. The probability that a string’s first half is all 0s is 1 / 3n/2, where n is the length of the string. This means that even if it takes O(3n/2) time to check the coloring of the graph encoded in the back half of a suitable string, mathematically the average amount of work required to solve this problem is O(1). (I’m aware I’m conflating the meaning of n as “the number of nodes in a graph” and “how long the string is,” but the math still checks out here.)\nWhat’s worrisome is that we still don’t have a very well-developed theory of average-case complexity for NP-hard problems. Some NP-hard problems, like the one above, are very easy on average. But others like SAT, graph coloring, etc. are mysteries to us, where we legitimately don’t know how hard they are for random instances. It’s entirely possible, for example, that P ≠ NP and yet the average-case hardness of individual NP-hard problems are not known.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Constructing a permutation graph\r\n                \r\nI have read about how permutation graphs make many NP-complete problems a lot easier to solve. For example, the maximal clique problem, tree width problem etc. However, I am unable to understand the process of creating a permutation graph from a given graph G(V,E). How would one go about doing this?\n    ", "Answer": "\r\nYou do not create a permutation graph from a graph, but from a permutation. The process is quite simple: \n\n\nwrite numbers 1 to n on a line, then \nwrite them again on a separate, parallel line according to the order in which they appear in your permutation;\nconnect each element from the first line to the same element on the second line (1 to 1, 2 to 2, ..., n to n), \nlabel each such connection with the numbers that it connects (e.g. connection 2 to 2 receives label 2);\nthe resulting permutation graph is obtained by treating each connection as a vertex and connecting two vertices whenever the corresponding connections intersect.\n\n\nIf that's still unclear, see the nice example on Wikipedia.\n\nIt is clear from the process that such a graph can always be constructed from any permutation; however, having a permutation graph may lead you to deduce several permutations that correspond to it.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this NP-Complete\r\n                \r\nMy problem is similar to the problem here https://cs.stackexchange.com/questions/2244/need-a-np-complete-proof-on-an-example , but it is a little different.\n\nHere is my problem:\n\nThere are three islands, A, B and C, and a lot of fan-shaped rafts. We must build a bridge from A-->B-->C, and the number of rafts required for each part is already known, say, four rafts are required for connecting AB and three rafts are required for connecting BC. \n\nThese rafts are at different positions originally and they can rotate without cost. An interesting thing is that they can overlap with each other if necessary. The distance of moving one raft can be calculated as the distance between the center of mass's original position and its deployed position.\n\nThe objective is to find the solution having the minimum total distance of moving rafts in order to have bridge A-->B-->C and using the exact number of rafts for each part of bridge.\n\nI used to the following figure to show my question.\n\n\n\nWe can see from this figure that the arrangement might not be a straight line, and the rafts can overlap with another one.\n\nThere are too many candidates locations for these rafts. It seems the problem is NPC. I do not know whether I am right and how to prove it to be NPC. Anyone know how to solve it? Thanks!\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Difference between C-SAT and SAT?\r\n                \r\nWhat exactly is the difference between these two NP-complete problems? It seems to me that they are both asking if a boolean formula can be satisfied (i.e. output 1) but one is in the context of a circuit and the other just a formula. However couldnt one write a boolean formula from a boolean circuit? \n    ", "Answer": "\r\nYou are right, they are very close to each other. Any C-SAT problem could be represented as SAT, any SAT problem could be represented as C-SAT. There is a question how to translate C-SAT <-> SAT in the most efficient way. Some tasks are better to represent as SAT, some of them 'looks' better as C-SAT.\n\nIn addition, there are SAT solvers that use circuit representation internally, instead of more popular clausal form.\n\nFurther, you can read this great survey: M. Bjork, 2009, Successful SAT encoding techniques\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "complexity of printing all possible paths on a graph\r\n                \r\nIn an undirected, unweighted graph, and I'm trying to print (store in file) all possible connecting paths between given 2 vertices on the graph, not including cycles. \n\nwhen you consider a complete graph this problem is a NP-complete. because there are ```\n\"(V-2)!\"```\n different paths between 2 vertices. \n\nHowever,seems it is possible to do it with one of graph traversal (DFS-BFS) algorithm with time complexity of ```\nO(|V|+|E|)```\n which is pretty polynomial.\n\nI got confuse about solving a NP-Complete problem in polynomial time?\nany idea about what is missing here ?\n    ", "Answer": "\r\nIf you want all possible paths, and the graph has V vertices, and E edges, then the number of paths will be dependent upon the number of connects.  Consider a fully connected graph, where every point connects to every other point.  Then there are ```\n(v-2)!```\n possible paths, right?  Well ```\n(v-2)! > V+E```\n (much greater).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What is nondeterministic in NP exactly?\r\n                \r\nI am studying NP-Completeness and I have a question about the definition of the NP problems.\n\nMaterial says  \n\n\n  nondeterministic refers to the fact that a solution can be guessed out\n  of polynomially many options in O(1) time\n\n\nHere, what does it mean by ```\npolynomially many options in O(1) time```\n?\n\nFor example, in the case of famous ```\n3SAT```\n problem, isn't there a exponentially many options?\n(b.c. each literal can be ```\ntrue```\n or ```\nfalse```\n and if there are are n literals, total number of options are ```\n2*2*2* ... * 2 = 2^n```\n)\n\nHowever, it says ```\n3SAT```\n problem is NP problem. How can it be NP problem even though there are exponentionally many certificates?\n\nThanks\n    ", "Answer": "\r\nThat quote seems to be a weird way of phrasing it, but it might refer to something similar to being able to pick a random number between 1 and n in O(1) - there are n possibilities, but only picking one of them takes O(1).\n\nSee also: nondeterministic algorithms.\n\n\"Nondeterministic polynomial time\" is the full definition of NP - \"polynomial time\" is important - each decision you make might take O(1), but there are polynomially many such decisions, leading to something that can theoretically be solved in polynomial time, if you can make the right choice at every step or execute all options at the same time.\n\nPicture a k-ary tree with height p(n). You can get to the correct leaf in O(p(n)) if you (randomly) pick the correct child at each step from the root, or if you can somehow visit all paths concurrently.\n\nOf course, in practice, you can't rely on making correct random choices, nor do you have infinitely many processors - if you were to visit all nodes sequentially, that will take O(kp(n)).\n\n\n\nFor 3SAT, we can randomly pick true or false for every literal, which leads us to a polynomial time algorithm which would produce the correct result if all our random choices were correct.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Advantage of Using backtracking and branch and bound\r\n                \r\nI understand that DP gives a better performance for many NP complete problems like TSP. Though the space needed is large, it reduces the complexity well.\n\nBut I couldn't understand the efficiency of branch and bound and backtracking as compared to an brute force search.\n\nIn worst case whether brute force equals b&b or backtracking ?\n    ", "Answer": "\r\nWith exhaustive search, you would compute all N! possible routes between the nodes. With backtracking, you might compute a route visiting half the nodes, notice that it is already more expensive than the best route found so far, and stop investigating that partial route at that point. By doing so, you have skipped computing all of the routes that are produced by completing that partial route, thus saving time over exhaustive search, which would have continued to check them all.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "P=NP in Exponential Space?\r\n                \r\nSuppose that we find that, for any NP-complete problem, there is an algorithm that can solve it in P time. However, the algorithm takes exponential space. For example, the algorithm to revert SHA256 would only take 256 steps. But you would need 2^256 bits to write the algorithm. Is the time complexity of this algorithm P? Would P equal NP?\nThe Clay Math Institute says that \"Informally the class P is the class of decision problems solvable by some algorithm within a number of steps bounded by some fixed polynomial in the length of the input.\"\nIt makes no limitations to the space taken by this algorithm.\nWe also commonly say that a binary decision tree with depth d can be executed in time-complexity O(d), even if the tree's length might be 2^d.\nOn the other hand, we know that P is contained within PSPACE.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Can abstract models for solving NP-hard problems be built in reality?\r\n                \r\nThis paper proofs, that NP-hard problems can be solved efficiently through abstract geometrical computations. These computations are based on signals, which are dimensionless and can move uniformly on a hypothetical real axis in time and space.\n\nThe authors claim the model to be only abstract and \n\n\n  ...with no apriori ambition to be physically realizable.\n\n\nIn fact, this paper shows, that the practical limitation is due to the need for a black hole to absorb emerging limit points within calculations.\n\nActually, there exist several black hole analogues and the first one was created in 2009, based on a rubidium Bose–Einstein condensate using a technique called density inversion (1). A further method by lasing the phonons also detected self-amplifying Hawking radiation in 2014 (2).\n\nCan such analogues of black holes be used to build the signal machines described above? In effect, such a machine could be able to solve NP-complete problems efficiently.\n\nIf not, what exactly are the physically limitations for building such signal machines. If it could be possible to built them, what would be the implications for complex theory and the N versus NP Problem?\n\n\n\n(1) Lahav, et. al. \"Realization of a sonic black hole analogue in a Bose-Einstein condensate\", 2009 (see doi: 10.1103/PhysRevLett.105.240401)\n\n(2) J. Steinhauer, \"Observation of self-amplifying Hawking radiation in an analogue black-hole laser\", 2014 (see doi:10.1038/nphys3104)\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Problem related to Completeness : Is P = PC?\r\n                \r\nI am learning computational complexity. So, i took some practise problems from internet. I came across 1 problem which I am not sure whether my solution is correct or not. The question is : \n\nLet us define a complexity class PC as follows : A decision problem A belongs to PC if and only if the following 2 conditions hold :\n\n1) A belongs to P\n2) For every problem B belongs to P, B is polynomial time reducible to A. Now we need to prove that PC = P.\n\nMy argument is that, PC is not equal to P. Because, this conditions are similar to NP-Complete conditions right. So, there are some problems in NP which are not NP-Complete right. So, NP is not equal to NP-Complete. Similarly, we can argue here that assuming C in PC is for completeness, P is not equal to PC.\n\nIs my argument correct ? Please clarify me on this.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Algorithm for checking if a string was built from a list of substrings\r\n                \r\nYou are given a string and an array of strings. How to quickly check, if this string can be built by concatenating some of the strings in the array?\n\nThis is a theoretical question, I don't need it for practical reasons. But I would like to know, if there is some good algorithm for this.\n\nEDIT\nReading some answer I have noticed, that this is probably NP-Complete problem. Even finding a subset of strings, that will together have same length, as a given string is a classic subset sum problem.\n\nSo I guess there is no easy answer to this.\n\nEDIT\n\nNow it seems, that it is not a NP-Complete problem after all. That's way cooler :-)\n\nEDIT\n\nI have came up with a solution that passes some tests:\n\n```\ndef can_build_from_substrings(string, substrings):\n    prefixes = [True] + [False] * (len(string) - 1)\n    while True:\n        old = list(prefixes)\n        for s in substrings:\n            for index, is_set in enumerate(prefixes):\n                if is_set and string[index:].startswith(s):\n                    if string[index:] == s:\n                        return True\n                    prefixes[index + len(s)] = True\n        if old == prefixes: # nothing has changed in this iteration\n            return False\n```\n\n\nI believe the time is ```\nO(n * m^3)```\n, where ```\nn```\n is length of ```\nsubstrings```\n and ```\nm```\n is length of ```\nstring```\n. What do you think?\n    ", "Answer": "\r\nNote: I assume here that you can use each substring more than once. You can generalize the solution to include this restriction by changing how we define subproblems. That will have a negative impact on space as well as expected runtime, but the problem remains polynomial.\n\nThis is a dynamic programming problem. (And a great question!)\n\nLet's define ```\ncomposable(S, W)```\n to be true if the string ```\nS```\n can be written using the list of substrings ```\nW```\n.\n\n```\nS```\n is composable if and only if:\n\n\n```\nS```\n starts with a substring ```\nw```\n in ```\nW```\n.\nThe remainder of ```\nS```\n after ```\nw```\n is also composable.\n\n\nLet's write some pseudocode:\n\n```\nCOMPOSABLE(S, W):\n  return TRUE if S = \"\" # Base case\n  return memo[S] if memo[S]\n\n  memo[S] = false\n\n  for w in W:\n    length <- LENGTH(w)\n    start  <- S[1..length]\n    rest   <- S[length+1..-1]\n    if start = w AND COMPOSABLE(rest, W) :\n      memo[S] = true # Memoize\n\n  return memo[S]\n```\n\n\nThis algorithm has O(m*n) runtime, assuming the length of the substrings is not linear w/r/t to the string itself, in which case runtime would be O(m*n^2) (where m is the size of the substring list and n is the length of the string in question).  It uses O(n) space for memoization.\n\n(N.B. as written the pseudocode uses O(n^2) space, but hashing the memoization keys would alleviate this.)\n\nEDIT\n\nHere is a working Ruby implementation:\n\n\n\n```\ndef composable(str, words)\n  composable_aux(str, words, {})\nend\n\ndef composable_aux(str, words, memo)\n  return true if str == \"\"                # The base case\n  return memo[str] unless memo[str].nil?  # Return the answer if we already know it\n\n  memo[str] = false              # Assume the answer is `false`\n\n  words.each do |word|           # For each word in the list:\n    length = word.length\n    start  = str[0..length-1]\n    rest   = str[length..-1]\n\n    # If the test string starts with this word,\n    # and the remaining part of the test string\n    # is also composable, the answer is true.\n    if start == word and composable_aux(rest, words, memo)\n      memo[str] = true           # Mark the answer as true\n    end\n  end\n\n  memo[str]                      # Return the answer\nend\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Minimal addition-chain exponentiation\r\n                \r\nI know it has been proven NP-complete, and that's ok. I'm currently solving it with branch and bound where I set the initial upper limit at the number of multiplications it would take the normal binary square/multiply algorithm, and it does give the right answers, but I'm not satisfied with the running time (it can take several seconds for numbers around 200). This being an NP-complete problem, I'm not expecting anything spectacular; but there are often tricks to get the Actual Time under control somewhat. \n\nAre there faster ways to do this in practice? If so, what are they?\n    ", "Answer": "\r\nThis looks like section 4.6.3 \"Evaluation of Powers\" in Knuth Vol 2 Seminumerical Algorithms. This goes into considerable detail to give various approaches, which look much quicker than branch and bound but do not all provide the absolutely best solution.\n\nKnuth states in the discussion after Theorem F that he uses backtrack search to prove that l(191) = 11, so I doubt if you will find a short-cut answer for this. He defers explanation of the backtrack search to section 7.2.2, which is I think still unpublished, although there are traces of work on this at http://www-cs-faculty.stanford.edu/~uno/programs.html.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "NP-Completeness in Task Scheduling\r\n                \r\nSo this is a bit of a thought provoking question to get across the idea of NP-Completeness by my professor. I get WHY there should be a solution, due to the rules of NP-Completeness, but I don't know how to find it. So here is the problem:\n\nThe problem is a simple task scheduling problem with two processors. Each processor can handle one of the ```\nn```\n tasks, and any two tasks can be done simultaneously. Each task has an end time ```\ne```\n, it must be completed by this time. Each task also has a duration ```\nd```\n. All time values, such as end time, duration, and the current time in the system (the time will start at 0), are all integers. So we are given a list of ```\nn```\n tasks and we need to use these two processors to schedule them ALL. If any one can not be scheduled, the algorithm has to return no solution. Keep in mind that the order does not matter and it doesn't matter which processor gets which task, as long as there is no overlap and each task finishes before its deadline. \n\nSo here is where the problem gets conceptual/abstract, say we have access to a special little function, we have no idea how it works, all we know is this: given a list of ```\nn```\n tasks and the current schedule, it will return ```\ntrue```\n or ```\nfalse```\n based on whether or not the algorithm is solvable from this point. This function assumes that the already scheduled tasks are set in stone, and it will only change the times of the unscheduled tasks. However, all this function does is return true or false, it will not give you the proper schedule if it does find a solution. The point is that you can use the special function in the implementation of the scheduling problem. The goal is to solve the scheduling problem, and return a working schedule with every job scheduled properly, using a polynomial number of calls to the special function. \n\nEDIT: To clarify, the question is this: Create a solution to schedule all ```\nn```\n tasks without any going over deadline, using a polynomial number of calls to the \"special function.\"\n\nI think this problem is to show that verifying a solution is polynomial, but finding it is nonpolynomial. But my professor is insistent that there is a way to solve this using a polynomial number of calls to the special function. Since the problem as a whole is NP-Complete, this would prove that the nonpolynomial aspect of the runtime comes in during the \"decision portion of the algorithm. \n\nIf you would like me to clear up anything just leave a comment, I know this wasn't a perfect explanation of the problem. \n    ", "Answer": "\r\nGiven an oracle ```\nM```\n that returns ```\ntrue```\n or ```\nfalse```\n only:\n\ninput:\ntasks - list of tasks\noutput:\nschedule: a triplet(task,processor,start) for each task\nalgorithm:\n\n```\nWhile there is some unscheduled task:\n   let p be the processor that currently finished up his scheduled tasks first\n   let x be the first available time on x\n   for each unscheduled task t:\n      assign t with the triplet: (t,p,x)\n      run M on current tasks\n      if M answers true:\n            break the for loop, continue to next iteration of while loop\n      else:\n            unassign t, and continue to next iteration of for loop\n    if no triplet was assigned, return NO_SOLUTION\nreturn all assigned triplets\n```\n\n\n\nThe above runs in polynomial time - it needs ```\nO(N^2)```\n calls to ```\nM```\n.\nCorrectness of the above algorithm can be proved by induction, where the induction hypothesis is After round ```\nk```\n of the while loop, if there was a solution before it, there is still a solution after it (and after the assignment of some task). After proving this claim, correctness of the algorithm is achieved trivially for ```\nk=#tasks```\n\n\n\nFormally proving the above claim:\n\n\nBase of induction is trivial for k=0.\nHypothesis: for any k < i, the claim \"if there was a solution before round k, there is still one after round k\", is correct\nProof:\n\n\nAssume there is some solution ```\n{ (tj,pj,xj)  | j=1,...,n}```\n, ordered by ```\nj<u <-> xj<xu```\n, and also assume that t1,t2,...,ti-1 is assigned same as the algorithm yielded (induction hypothesis).\nNow, we are going to assign ```\nti```\n, and we'll be able to do it, since we are going to find the smallest available time stamp (```\nxi```\n), and place some task on it. We are going to find some task, and since ```\nti```\n is a possibility - it will not \"fail\" and yield \"NO_SOLUTION\".\nAlso, since the algorithm does not yields \"NO_SOLUTION\" in iteration ```\ni```\n, from correctness of ```\nM```\n, it will yield some task ```\nt```\n, that by assigning ```\n(t,p,x)```\n - there will still be a solution, and the claim for step ```\ni```\n is proven.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Cuda optimization techniques\r\n                \r\nI have written a CUDA code to solve an NP-Complete problem, but the performance was not as I suspected.    \n\nI know about \"some\" optimization techniques (using shared memroy, textures, zerocopy...)  \n\nWhat are the most important optimization techniques CUDA programmers should know about?\n    ", "Answer": "\r\nYou should read NVIDIA's CUDA Programming Best Practices guide: http://developer.download.nvidia.com/compute/cuda/3_0/toolkit/docs/NVIDIA_CUDA_BestPracticesGuide.pdf \n\nThis has multiple different performance tips with associated \"priorities\". Here are some of the top priority tips:\n\n\nUse the effective bandwidth of your device to work out what the upper bound on performance ought to be for your kernel\nMinimize memory transfers between host and device - even if that means doing calculations on the device which are not efficient there\nCoalesce all memory accesses\nPrefer shared memory access to global memory access\nAvoid code execution branching within a single warp as this serializes the threads\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reduction from Maximum independent set to Dominating set to prove the Dominating set is NP-complete\r\n                \r\nI know of the reduction from the Vertex cover to Dominating set. \n\nHowever, I was seeing if I could get a reduction from the maximum independent set problem straight to the Dominating set problem in order to prove the latter NP-complete.\n\nDoes anyone know if this has been done? I can't find anything online.\n\nI was hoping to find something along the lines of a proof like:\n\nIf there is a dominating set of size k -> there is a maximum independent set of size k.\n\nAND\n\nIf there is a maximum independent set of size k -> then there is a dominating set of size k.\n    ", "Answer": "\r\nYes you can get a reduction from the maximum independent set problem straight to the Dominating set problem -- but not that straight, you need to construct another graph in the following manner. We then can prove that if the original graph has an independent set of size ```\nk```\n iff the new graph has a dominating set of some size related to k. The construction is polynomial. \n\nGiven a graph ```\nG = (V, E)```\n  we can construct another graph ```\nG' = (V', E')```\n where for each edge ```\ne_k = (v_i, v_j)```\n in ```\nE```\n, we add a vertex ```\nv_{e_k}```\n and two edges ```\n(v_i, v_{e_k})```\n and ```\n(v_{e_k}, v_j)```\n. \n\nWe can prove ```\nG```\n has an independent set of size ```\nk```\n iff ```\nG'```\n has a dominating set of size ```\n|V|-k```\n.\n\n(=>) Suppose I is a size-```\nk```\n independent set of ```\nG```\n, then ```\nV-I```\n must be a size-```\n(|V|-k)```\n dominating set of ```\nG'```\n. Since there is no pair of connected vertex in ```\nI```\n, then each vertex in ```\nI```\n is connected to some vertex in ```\nV-I```\n. Moreover, every new added vertex are also connected to some vertices in ```\nV-I```\n. \n\n(<=) Suppose ```\nD```\n is a size-```\n(|V|-k)```\n independent set of ```\nG'```\n, then we can safely assume that all vertices in ```\nD```\n is in ```\nV```\n (since if ```\nD```\n contains an added vertex we can replace it by one of its adjacent vertex in ```\nV```\n and still have a dominating set of the same size). \n\nWe claim ```\nV-D```\n is a size-```\nk```\n independent set in ```\nG```\n and prove it by contradiction: suppose ```\nV-D```\n is not independent and contains a pair of vertices ```\nv_i```\n and ```\nv_j```\n and the edge ```\ne_k = (v_i, v_j)```\n is in ```\nE```\n. Then in ```\nG'```\n the added vertex ```\nv_{e_k}```\n need to be dominated by either ```\nv_i```\n or ```\nv_j```\n, that is at least one of ```\nv_i```\n and ```\nv_j```\n is in ```\nD```\n. Contradiction. Therefore ```\nV-D```\n is a size-```\nk```\n independent set in ```\nG```\n.\n\nCombining the two directions you get what you want. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Network Flow and Integer Linear programming\r\n                \r\nWe all know that the problem of network flow can be reduced to linear programming. However, when we solve network flow problem, we need the flow to be integer all the time. So I think network flow should be reduced to integer linear programming. Because of ILP which is NP-complete, the network flow problem should be NP-complete problem too. But this contradicts what we learned since the running time of network flow is O(Cm)! Where am I wrong? Is it because network flow problem’s running time is pseudo-polynomial time like knapsack problem(Wn)? I am so confused now! \n    ", "Answer": "\r\nYou still technically have to show that the reduction takes polynomial time, but that is a more minor issue here. The main issue is that your reduction is the wrong way around. \n\nTo show that something is NP-complete, you need to do two things:\n\n\nShow that it is in NP\nShow that it is also NP-hard.\n\n\nTo do the latter using reductions, you need to reduce ILP to network flow, not reduce network flow to ILP. The point of the reduction is to show that you could solve ILP (and by extension, every NP problem) in polynomial time if you could solve your given problem (in this case, network flow). By reducing the wrong way, you've actually shown that you can solve network flow in polynomial time if you could solve ILP in polynomial time (which is true but useless since network flow is in P).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is \"house coloring with three colors\" NP?\r\n                \r\nConsider the problem described here (reproduced below.)  Can some better known NP-complete problem be reduced to it? \n\nThe problem:\n\nThere are a row of houses.  Each house can be painted with three colors: red, blue and green. The cost of painting each house with a certain color is different.  You have to paint all the houses such that no two adjacent houses have the same color. You have to paint the houses with minimum cost. How would you do it?\n\nNote: The cost of painting house 1 red is different from that of painting house 2 red. Each combination of house and color has its own cost.\n    ", "Answer": "\r\nNo, it is not NP-hard (technically, \"NP-complete\" is the wrong term for this, as this is not a decision problem).\n\nDynamic programming works, and gives you an O(n) time algorithm. (n is the number of houses).\n\nYou maintain three arrays ```\nR[1..n], B[1..n], G[1..n]```\n, where ```\nR[i]```\n is the minimum cost of painting houses 1, 2, 3 ... ```\ni```\n such that ```\ni```\n is colored Red. Similarly ```\nB[i]```\n is min cost of painting 1, 2 ... ```\ni```\n with ```\ni```\n being colored Blue, and ```\nG[i]```\n is with ```\ni```\n being colored Green.\n\nYou can compute ```\nR[i+1]```\n:\n```\nR[i+1]= (Cost of painting house i+1 Red) + minimum {G[i], B[i]}```\n. \n\nSimilarly ```\nB[i+1]```\n and ```\nG[i+1]```\n can be computed.\n\nUltimately you take the minimum of ```\nR[n], B[n] and G[n]```\n.\n\nThis is O(n) time and O(n) space.\n\nFor example consider the following cost matrix for the houses:\n\n\nHouse #: 1   2   3\nR      : 1   4   6\nG      : 2  100  2\nB      : 3  100  4\n\n\nThe algorithm is building the following matrix to get the answer:\n\n\nHouses : 0  1   2    3\nR      : 0  1   6   107\nG      : 0  2  101   8\nB      : 0  3  101  10\n\n\nFrom the last column, where all 3 houses are painted, we can find the minimum cost, which is equal to 8 and corresponds to the combination [Green (2), Red (4), Green (2)].\n\nQuick Python:\n\n```\n# rc = costs of painting red, bc of blue and gc of green.\ndef min_paint(rc, bc, gc):\n    n, i = len(rc), 1\n    r, b, g = [0]*n, [0]*n, [0]*n\n    r[0], b[0], g[0] = rc[0], bc[0], gc[0]\n    while i < n:\n        r[i] = rc[i] + min(b[i-1], g[i-1])\n        b[i] = bc[i] + min(r[i-1], g[i-1])\n        g[i] = gc[i] + min(b[i-1], r[i-1])\n        i += 1\n\n    return min(r, b, g)\n\ndef main():\n    print min_paint([1, 4, 6], [2, 100, 2], [3, 100, 4])\n\nif __name__ == \"__main__\":\n    main()\n```\n\n\nThe output will be ([1, 6, 107], [2, 101, 8], [3, 101, 10]), which is a cost matrix leading to the solution.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Algorithms for subgraph isomorphism detection [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs to be more focused. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nSubgraph isomorphism is an NP Complete problem.  The most widely used algorithm is the one proposed by Ullman.\n\nCan someone please explain the algorithm to me in layman's language? I read the above paper by him, but couldn't understand much.\n\nWhat other algorithms exist for this problem?\n\nI am working on an image processing project.\n    ", "Answer": "\r\nVFLib2 is a C++ library for graph isomorphism finding. It also includes an Ullman implementation: http://mivia.unisa.it/datasets/graph-database/vflib/\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity of an old Top Coder riddle: Making a number by inserting +\r\n                \r\nThis is a follow up to my previous question (about an old top coder riddle).\n\nGiven a string of digits, find the minimum number of additions required for the string to equal some target number. Each addition is the equivalent of inserting a plus sign somewhere into the string of digits. After all plus signs are inserted, evaluate the sum as usual.\nFor example, consider \"303\" and a target sum of 6. The best strategy is \"3+03\".\n\nI guess (not proved it though) the problem is NP-complete.\nWhat do you think? How would you reduce a well-known NP-complete problem to this problem?\n    ", "Answer": "\r\nIf the base is made a parameter, then there is a reduction from subset sum. Let x1, …, xn, s > 0 be the instance of subset sum and let S = x1 + … + xn. In base S + 1, let the Top Coder input be\n\nx1 0 x2 0 … xn 0\n\nsumming to (S - s) (S + 1) + s.\n\nMuch more interesting of course is the hardness of the base 10 case.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reduce Subset Sum to Polyomino Packing\r\n                \r\nThis is a homework assignment, so any help is appreciated.\nI should prove that the following problem is NP-complete. The hint says that you should reduce the subset sum problem to this problem.\n\nGiven a set of shapes, like the below, and an m-by-n board, decide whether is it possible to cover the board fully with all the shapes. Note that the shapes may not rotate.\nFor example, for a 3-by-5 board and the following pieces, the board can be covered like this:\n\n\n\nNow the important thing to note is that the subset sum problem we are trying to reduce should be given input length polynomial in terms of m and n.\nAny ideas for using another NP-complete problem are appreciated.\n    ", "Answer": "\r\nThe easiest reduction is from the partition problem.\nSuppose that we have a set of positive numbers that sum to ```\n2n```\n and we want to know a subset of them sums to ```\nn```\n.\nWe create a set of blocks of length the numbers and width 1, then try to fit them into a rectangle of width 2 and length ```\nn```\n.  We can succeed if and only if the partition problem was solvable for those numbers, and the rows are the partition.  So any partition problem can be reduced to a polyomino packing problem in linear time.  Since the partition problem is NP-complete, we are done.\nBut they said subset sum.  If they mean subset sum on positive numbers, then we can just use another trick.  Suppose that our numbers sum to ```\nn```\n and we want to know if a subset sums to ```\nk```\n.  Then we just add 2 numbers to the problem of size ```\nk+1```\n and size ```\nn-k+1```\n and aim to solve the partition problem.  If we succeed, our additional 2 numbers couldn't have been in the same partition and so the rest are a solution to the partition problem.  Since we've already reduced the partition problem to polyomino packing problem, we are done.\nIf they intended subset sum from numbers that can be both positive and negative, then I don't see the reduction that they suggested.  But since I've managed to reduce 2 well-known NP-complete problems to this one, I think we're good.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Need help to understand the Prove that the longest path problem is NP complete by reduction from Hamiltonian path\r\n                \r\nHamiltonian Path: If there is a path to visit each vertex of a graph exactly once.\nLongest Path: Given a graph G=(V,E) and an integer k, decide if there is a simple path of length k.\nIn my class, the solution is to set k = V-1, and then it is trivial that the two problems are equivalent.\nI can understand the direction from Hamiltonian Path to the longest path. But I cannot understand the direction from the longest path to the Hamiltonian path since the given number k does not need to be the number of vertices - 1.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Prove NP-Completeness of generating 2 shortest routes over given edge grouping constraints?\r\n                \r\nI've been trying unsuccessfully to the following problem is NP-Complete or NP-Hard.\n\nThe problem is as follows:\n\nYou are given a graph G(V,E) and asked to generate two routes from starting node S to node T.  The edges E are split into K disjoint sets.  Let us refer two the routes as R1 and R2.  There can be no edges E1 and E2 in the same set such that E1 is in the path R1 and E2 is in R2 (in simpler terms each set must be used by no more than one of the routes).  Additionally there can be no nodes shared between R1 and R2.  We are seeking the shortest combined path length of R1 and R2 (Minimize (len(R1) + len(R2)) ).\n\nI have tried reducing Subset Sum and Independent Set to this with no success.\n    ", "Answer": "\r\nFor starters, thanks for posting a seriously interesting problem. This was a lot of fun to work through!\n\nThe reduction I've come up with is from 3SAT to your problem. Intuitively, the reduction works as follows: we build a graph consisting of two parallel, cascading series of nodes (let's call them the left and the right branches). The left branch edges correspond to the variables in the formula and the right branch corresponds to the clauses in the formula. We'll build the graph such that the two paths correspond to choosing a variable assignment for the formula that satisfies all the clauses.\n\nThe left branch, which forces variables to take on values, is build as follows. For each variable x, build a gadget that looks like this:\n\n```\n              *\n  true -->   / \\  <-- false\n            *   *\n             \\ /\n              *\n```\n\n\nStarting at the top node, we'll have \"left\" mean \"x is true\" and \"right\" mean \"x is false.\" We'll build one copy of this gadget for each variable and link them from top to bottom. Therefore, a path from the top of the chain down to the bottom corresponds to choosing a variable assignment for the propositional formula.\n\nThe right branch is built similarly. Suppose we have a clause x &lor; y &lor; z. We then build this gadget:\n\n```\n              *\n             /|\\\n            * * *\n             \\|/\n              *\n```\n\n\nHere, the left branch corresponds to \"x is true,\" the middle branch corresponds to \"y is true\", and the right branch corresponds to \"z is true.\" The idea is that we need to have at least one true literal per clause, and we'll choose which literal that is by choosing which path to go down.\n\nNow, we build the constrain sets. For each variable x, we want to ensure that if in the left branch we say that x is true, we don't follow an edge in the right branch where x is supposed to be false. Therefore, we'll create a constraint set containing the edge \"x is true\" from the left branch and all copies of \"x is false\" from the right branch. We'll similarly create a second constrain set containing the edge \"x is false\" from the left branch and all edges marked \"x is true\" from the right branch. These constraint sets collectively ensure that if we take a path through the left branch and through the right branch, we chose a value for every variable (the path through the left branch) and picked at least one true literal per clause (the path through the right branch).\n\nTo finish everything, we'll create a new start node S and a new terminal node T, linking S to the first node in the left branch and the first node in the right branch and linking the last node in the left and right branches to T. Now, there's a satisfying assignment to the formula if and only if there are two node-disjoint paths from S to T respecting all the constraints. Doing some quick math shows that if the formula has n variables and m clauses, then the length of the path through the left branch will be 2n + 2 and the length of the path through the right branch will be 2m + 2, so the formula is satisfiable if and only if there's a pair of node-disjoint paths from S to T of combined length 2n + 2m + 4. Note that there isn't a legal path at all if the formula isn't satisfiable.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What problem type the Power Set belong to?\r\n                \r\nI don't seem to find any much resource about \"Power Set\" problem.\nIs Power Set a NP-Complete or NP-Hard problem? And why? Can someone advise me?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Computational complexity of a longest path algorithm witn a recursive method\r\n                \r\nI wrote a code segment to determine the longest path in a graph. Following is the code. But I don't know how to get the computational complexity in it because of the recursive method in the middle. Since finding the longest path is an NP complete problem I assume it's something like ```\nO(n!)```\n or ```\nO(2^n)```\n, but how can I actually determine it?\n\n```\npublic static int longestPath(int A) {\n    int k;\n    int dist2=0;\n    int max=0;\n\n    visited[A] = true;\n\n    for (k = 1; k <= V; ++k) {\n        if(!visited[k]){\n            dist2= length[A][k]+longestPath(k);\n            if(dist2>max){\n                max=dist2;\n            }\n        }\n    }\n    visited[A]=false;\n    return(max);\n}\n```\n\n    ", "Answer": "\r\nYour recurrence relation is ```\nT(n, m) = mT(n, m-1) + O(n)```\n, where ```\nn```\n denotes number of nodes and ```\nm```\n denotes number of unvisited nodes (because you call ```\nlongestPath```\n ```\nm```\n times, and there is a loop which executes the visited test ```\nn```\n times). The base case is ```\nT(n, 0) = O(n)```\n (just the visited test).\n\nSolve this and I believe you get T(n, n) is O(n * n!).\n\nEDIT\n\nWorking:\n\n```\nT(n, n) = nT(n, n-1) + O(n) \n        = n((n-1)T(n, n-2) + O(n)) + O(n) = ...\n        = n(n-1)...1T(n, 0) + O(n)(1 + n + n(n-1) + ... + n(n-1)...2)\n        = O(n)(1 + n + n(n-1) + ... + n!)\n        = O(n)O(n!) (see http://oeis.org/A000522)\n        = O(n*n!)\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is finding zeros of a function a NP-pb?\r\n                \r\nI would like to find the zeros of a real function of multiple variables.\nMany algorithms are known to solve this problem (such as the Newton-Rhapson method), but in the general case, do these problems belong to the NP-complete class of problems ?\nIn other words do we know a method to solve this in reasonable time if the number of variables becomes high ?\n\nThanks in advance !\n\nPS: I haven't found this question asked on the forum but some topics seem closely related, if my question is redundant please tell me.\n    ", "Answer": "\r\nWhat is your input definition? Remember, for questions of complexity, you need to compare run times to the encoding length of the input.\n\nAnd what do you understand as a \"solution\" in computer terms? One finite definition would be a box with rational corners containing exactly one solution. Or a similar box inside the domain of quadratic convergence of Newtons method. See the standard book of Blum/Shucker/Smale/?? on the complexity of the real numbers.\n\nEven for polynomial problems the situation is complicated, it is not known if the solution of polynomial systems is in P or in NP.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "A 2-approximation algorithm for Vertex-Cover problem using \"Spanning Tree\"\r\n                \r\nI have seen a question on 2-approximation algorithm for Vertex-Cover problem(VC, known Np-Complete problem), and i don't know the answer. The problem is the following : Find a 2-approximation algorithm for Vertex Cover problem using \"Spanning Tree\". \nWell, many greedy approaches are already presented for VC, but special algorithm using \"Spanning Tree\" is challenging.\nAny idea? \n    ", "Answer": "\r\nYou just search for max matching in the given graph and the solution is the set of nodes that create a max matching.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is applying AI ok and/or practical to finding the optimal solution to the algorithmic problem\r\n                \r\nBoth in learning environment and practice, from time to time I had to use different algorithms to solve problems. But the more I use them, the more it seems like the AI could be deployed to try finding the optimal solution, especially to the NP-complete problems, since the AI \"progression\" is easily tracked\n\nIf we, for example, never knew how to solve knapsack problem efficiently; I wonder, is applying AI practical and/or ever OK to finding the optimal solution to the given problem? \n    ", "Answer": "\r\nAI algorithms in general can find an approximation to basically any function. They are so powerful because this is true even for extremely complex functions with many input parameters and/or many output parameters and/or a very complicated internal structure. \n\nOn the other hand, there is no known way to solve NP-complete problems \"quickly\". In practice, you would often have to search through a huge solution space for finding the optimal solution. This is why people use heuristic methods and approximation algorithms to efficiently find a \"sufficiently good\" solution. \n\nSo yes, you can use AI to find a good approximate solution (and possibly even a better one than with traditional heuristics) to a computationally hard problem. \n\nBut no, if the problem is NP-complete, you still cannot know that you have found the optimal solution. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "delete minium weight edges to disconnect a set of nodes\r\n                \r\nThe problem says that given a weighted edge bidirectional graph, find the set of edges, by deleting which a given set of nodes becomes disconnected with each other. And also the sum of these edge weights should be minimum. Does this problem has any name? Any particular algorithm to solve them? I know that this must be the NP complete problem.   \n    ", "Answer": "\r\nIf you just want to find a minimum weight cut which departs your graph into two part, this simply can be done by running max flow/min cut algorithm (e.g Edmonds algorithm). You just should fix one vertex and then find its min cut with all other |V|-1 vertices, finally out put minimum cut among all cuts. Note that your fixed vertex should be in one of a components. For running max-flow/min cut algorithm on undirected graphs just draw each edge into two direction. This algorithm causes to running max-flow algorithm * O(|V|).\n\nBut if your problem is how to divide the graph into k connected component with minimum weight cut, this is NP-Hard problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Finding a loopless path passing through a series of nodes?\r\n                \r\nGiven a directed graph, which has n points, there are k \"must pass\" points, where k < n-2.\n\nHow do I find a path from a start node to an end node that passes through all the \"must pass\" points without revisiting any nodes? Maybe this is a NP-complete problem... seems like TSP is very similar to this problem.\n    ", "Answer": "\r\nThis problem is indeed NP-hard. To see this, you can reduce the Hamiltonian path problem to this one by starting with the original graph, adding in two new nodes not connected to anything, then asking for a path that passes through every node in the graph except for those two new ones.\n\nYou may be able to use some techniques designed for finding long paths in graphs, like color coding or dynamic programming techniques, to avoid a brute-force search, but given the nature of this problem I doubt you'll be able to do much better than brute-force.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Sub Exponential compleixty\r\n                \r\nI saw in the below link that 2nO(1)\nis sub exponential complexity. I do not understand the difference between 2n and 2nO(1). Aren't they the same as O(1) evaluates to 1? \n\nhttps://cs.stackexchange.com/questions/9813/are-there-subexponential-time-algorithms-for-np-complete-problems\n\nI have algorithms of subset sum problem that have been solved in 2n -1 runtime steps thus having O(2n) complexity. Is that sub polynomial time? If it is then it violates the exponential time hypothesis(ETH) and proves P not equal to NP!\n\nI also know that brute force for such problems runs in O(2n). So what is the difference in this complexity and sub exponential one?\n\nPlease help.\nThanks!\n    ", "Answer": "\r\nO(1) is definitely not the same as 1.\n\nIf f(x) is in O(1), then so is g(x)=c×f(x). For example, f(x)=(x−1)⁄x is clearly in O(1) since its asymptotic to 1, and so is g(x)=(x−1) ⁄ 2 x, whose asymptote is 0.5.\n\nBut 2n1 (=2n) is quite different from 2n1⁄2 (=2√n). The latter certainly could be described as subexponential. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What is an algorithm to find the circuit with max weight in a directed graph?\r\n                \r\nFirst problem was that i couldn't find an algorithm that,given an directed graph as input, gives as output a list of all cycles present in the graph. (This problem should be NP-complete).\n\nAfter thinking about the problem for a while I realized that what probably I really needed was to find the circuit (it can have duplicate vertex but not duplicate edges) with max weight (sum of the weights of the edges). \n\nIt should be a NP-complete problem too, and a way to proceed could be to list  all circuits present in the graph and then to sort them by sum of edge weights. \n\nDo you know some algorithm that gives as output a list of all circuits present in a directed graph? Or one that find the circuit with max weight ?\n\nI have found this, but it's not exactly what i need.\n\nhttp://epubs.siam.org/doi/abs/10.1137/0205007\n\nHowever do you confirm the computational complexity of these problems ?\n    ", "Answer": "\r\nYou could do sth. like here: Finding all cycles in a directed graph.\n\nYou do this search for every node and parallelize that so as to reduce runtime. Afterwards you apply an efficient sort-algorithm to your list of cycle where each cycle is a list of nodes. Sorting algorithms may me Mergesort or Quicksort for instance, but choose which ever u prefer..\n\nI hope that brings u forward.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Ideas for student parallel programming project\r\n                \r\nI'm looking to do a parallel programming project in C (probably using pthreads or maybe OpenMP) for a class. It will done by a group of about four students, and should take about 4 weeks. I was thinking it would be interesting to attack some NP-complete problem with a more complex algorithm like a genetic algo with simulated annealing, but I'm not sure if it would be a big enough project.\n\nAnyone knew of any cool problems that could benefit from a parallel approach?\n    ", "Answer": "\r\nI remember a 'learning' project at our university about parallelizing alpha-beta pruning algorithms. Alpha-beta pruning itself isn't too complicated and has quite large complexity. If you parallelize it you'll need to install some signaling/data sharing to really benefit from the parallelization. Otherwise some threads would go too often or too deep into branches that already were considered too bad by other threads. I think that can be a good use case.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "ILP in poly-time?\r\n                \r\nInteger programming is said to be NP-complete. However, I think formulating a problem into ILP can't prove the problem to be NP-hard. Is there any example of problem that can be modeled into ILP but has a polynomial time?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "List of problems that are in general NP-hard but have polynomial-time solution in planar graphs?\r\n                \r\nI encountered many problems that can be formulated as graph problem.\nIt is in general NP-hard but sometimes the graph can be proved to be planar.\nHence, I am interested in learning these problems and the algorithms.\n\nSo far as I know:\n\n\nMax cut in planar graphs\nFour-coloring in planar graphs\nMax Independent Set in cubic planar graphs\n\n\nHope someone can complete this list.\n    ", "Answer": "\r\nIn this compendium of NP-complete problems, under planar in the index there are a good number (~25) of entries.  These entries typically link to problems where planar input admits a PTAS.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to determine if a NxN matrix with non-negative integer entries is a product of k square 0/1 matrices?\r\n                \r\nSo I'm suspecting this problem could be NP-complete or NP-hard at least in certain circumstances, but still, often for NP-complete problems there is a nice solution that runs much faster than naïve brute force. \n\nMy problem is, given an NxN matrix A, with non-negative integer entries, and an integer k > 1, how can we determine if A can be written as a product of k NxN matrices whose entries are all either 0 or 1?\n\nLike I said, I think this problem may be \n\n\nNP-complete even for k = 2 but I maybe wrong, \nmaybe it's polynomial time for k=2 or even for any fixed k or even for k not fixed. \nAlso it may help to bound the non-negative entries in the target matrix A, to come up with good running times. \n\n\nI would just like to find out good algorithms that run asymptotically faster (hopefully much faster) than brute force over all choices of 0/1 matrices to multiply. \n\nAlso, I apologize if this question is better suited on CS.stackexchange, if so, please let me know and I'll migrate the question. However we do have an ```\nalgorithm\"```\n tag here, and since I suspect this problem is NP-hard, at least in one of its variants about whether k=2 or k is fixed or unbounded k, it's of more interest to me to just get whatever good algorithms may be available, e.g. that may work in polynomial time for fixed k or run in pseudo-polynomial time for arbitrary k but not polynomial time in general.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Subset-sum prob. (congruence variation)\r\n                \r\nI'm wondering about the NP-completeness of a variation of the Subset-sub problem:\n\nSubset-sum problem:\nGiven a set of integers and an integer s, does any non-empty subset sum to s?\n\nThis problem is known to be in NP and be NP-complete. Now consider the variation:\n\nSubset-sum problem (congruence variation):\nGiven two integers s and m and a set of integers modulo m, does any non-empty subset sum to s mod m?\n\n(i.e., all the numbers in the set are modulo m and the expected sum s is also in mod m). \n\nI'm wondering if this problem has been studied before? (Would like to know if it is NP-complete or not). Does anyone know if there is any paper or similar variation of the Subset-sum problem? Thank you!\n    ", "Answer": "\r\nYes, this problem is also NP-complete.  Since normal subset sum is NP complete, there is a reduction of some other NP-complete problem to subset sum.\n\nThe same reduction will also work to prove that modular subset sum is NP complete, if you can additionally generate a sufficiently large modulus with a size that is polynomial in the input size.  The modulus just has to be bigger than the largest number used in the subset sum solution, and then the difference between subset sum and modular subset sum is irrelevant.\n\nFor any reduction I can think of, it is easy to generate such a modulus.  Remember that it is only the size of the modulus that has to be polynomial in the input size, so, say 100^(N^2) works fine -- it's only 2*(N^2) digits long.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Complexity of subset sum with multiple targets\r\n                \r\nIs the following problem in NP-Complete or P? \nInput: A set S of positive integers {a1, a2, ..., an) and a positive integer M \nQuestion: Is there a subset S' of S such that all the elements in S' sum to either M-1, M or M+1.\n\n\nMy guess is that it is in NP-Complete and related to subset sum. However I'm having a hard time reducing Subset sum to this problem.\n    ", "Answer": "\r\nThis is NP-complete. Given an instance of subset sum\n\n\n  Find a subset of {x1, ... xn} with sum X\n\n\nConsider the following instance of your problem\n\n\n  Find a subset of {4 * x1, 4 * x2, ..., 4 * xn} with sum 4*X, 4*X-1 or 4*X + 1\n\n\nBy considering divisibility-by-4, it's clear that any subset which sums to 4*X, 4*X-1 or 4*X + 1 will actually have to sum to 4X. But that then trivially gives a solution to the original subset-sum problem, by dividing through by 4.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this an NP problem?\r\n                \r\nfirst off I'm going to say I don't know a whole lot about theory and such. But I was wondering if this was an NP or NP-complete problem. It specifically sounds like a special case of the subset sum problem.\n\nAnyway, there's this game I've been playing recently called Alchemy which prompted this thought. Basically you start off with 4 basic elements and combine them to make other elements. \n\nSo, for instance, this is a short \"recipe\" if you will for making elements\n\n\nfire=basic element\nwater=basic element\nair=basic element\nearth=basic element\nsand=earth+earth\nglass=sand+fire\nenergy=fire+air\nlightbulb=energy+glass\n\n\nSo let's say a computer could create only the 4 basic elements, but it could create multiple sets of the elements. So you write a program to make any element by combining other elements. How would this program process the list the create a lightbulb? \n\nIt's clearly fire+air=energy, earth+earth=sand, sand+fire=glass, energy+glass=lightbulb. \n\nBut I can't think of any way to write a program to process a list and figure that out without doing a brute force type method and going over every element and checking its recipe. \n\nIs this an NP problem? Or am I just not able to figure this out? \n    ", "Answer": "\r\n\n  How would this program process the list the create a lightbulb?\n\n\nSurely you just run the definitions backwards; e.g. \n\n\nCreating a lightbulb requires 1 energy + 1 glass\nCreating an energy requires 1 fire + 1 air\n\n\nand so on.  This is effectively a simple tree walk.\n\nOTOH, if you want the computer to figure out that energy + glass means lightbulb (rather than \"blob of molten glass\"), you've got no chance of solving the problem.  You probably couldn't get 2 gamers to agree that energy + glass = lightbulb!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "show the problem of find two subsets such that the difference of them of two sets is smaller than a value, is NP-Hard\r\n                \r\nAs input, given two finite sets of integers X = {x1,...,xm},Y = {y1,...,yn} ⊆ Z, and a non-negative integer v ≥ 0. The goal is to decide if there are non-empty subsets S ⊆ [m] and T ⊆ [n] such that\n|\nHow to show this problem is NP-Complete? I'm quite confused\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Maximum non-overlapping intervals in a interval tree\r\n                \r\nGiven a list of intervals of time, I need to find the set of maximum non-overlapping intervals.\n\nFor example,\n\nif we have the following intervals:\n\n```\n[0600, 0830], [0800, 0900], [0900, 1100], [0900, 1130], \n[1030, 1400], [1230, 1400]\n```\n\n\nAlso it is given that time have to be in the range ```\n[0000, 2400]```\n.\n\nThe maximum non-overlapping set of intervals is ```\n[0600, 0830], [0900, 1130], [1230, 1400]```\n.\n\nI understand that maximum set packing is NP-Complete. I want to confirm if my problem (with intervals containing only start and end time) is also NP-Complete. \n\nAnd if so, is there a way to find an optimal solution in exponential time, but with smarter preprocessing and pruning data. Or if there is a relatively easy to implement fixed parameter tractable algorithm. I don't want to go for an approximation algorithm.\n    ", "Answer": "\r\nThis is not a NP-Complete problem. I can think of an ```\nO(n * log(n))```\n algorithm using dynamic programming to solve this problem.\n\nSuppose we have n intervals. Suppose the given range is ```\nS```\n (in your case, ```\nS = [0000, 2400]```\n). Either suppose all intervals are within ```\nS```\n, or eliminate all intervals not within ```\nS```\n in linear time.\n\n\nPre-process:\n\n\nSort all intervals by their begin points. Suppose we get an array ```\nA[n]```\n of n intervals.\n\n\nThis step takes ```\nO(n * log(n))```\n time\n\nFor all end points of intervals, find the index of the smallest begin point that follows after it. Suppose we get an array ```\nNext[n]```\n of ```\nn```\n integers.\n\n\nIf such begin point does not exist for the end point of interval ```\ni,```\n we may assign ```\nn```\n to ```\nNext[i]```\n.\nWe can do this in ```\nO(n * log(n))```\n time by enumerating n end points of all intervals, and use a binary search to find the answer. Maybe there exists linear approach to solve this, but it doesn't matter, because the previous step already take ```\nO(n * log(n))```\n time.\n\n\nDP:\n\n\nSuppose the maximum non-overlapping intervals in range ```\n[A[i].begin, S.end]```\n is ```\nf[i]```\n. Then ```\nf[0]```\n is the answer we want.\nAlso suppose ```\nf[n] = 0```\n;\nState transition equation:\n\n\n```\nf[i] = max{f[i+1], 1 + f[Next[i]]}```\n\n\nIt is quite obvious that the DP step take linear time.\n\n\n\nThe above solution is the one I come up with at the first glance of the problem. After that, I also think out a greedy approach which is simpler (but not faster in the sense of big O notation):\n\n(With the same notation and assumptions as the DP approach above)\n\n\nPre-process: Sort all intervals by their end points. Suppose we get an array ```\nB[n]```\n of n intervals.\nGreedy:\n\n```\nint ans = 0, cursor = S.begin;\nfor(int i = 0; i < n; i++){\n    if(B[i].begin >= cursor){\n        ans++;\n        cursor = B[i].end;\n    }\n}\n```\n\n\n\nThe above two solutions come out from my mind, but your problem is also referred as the activity selection problem, which can be found on Wikipedia http://en.wikipedia.org/wiki/Activity_selection_problem.\n\nAlso, Introduction to Algorithms discusses this problem in depth in 16.1.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Gurobi: Optimize a quadratic non PSD\r\n                \r\nWill Gurobi optimize a quadratic problem where the objective function\nis NOT positive definite?  Our constraints are linear--in fact, they are\nbox constraints.  This is a known NP-complete problem, as per Vavasis,\nNonlinear Complexity: Optimization Issues, Oxford University Press.\n\nWe know that Gurobi will not optimize a quadratic programming problem\nwith quadratic constraints, except under special conditions.  However, we\nhave not seen a specific statement that it can or cannot handle\na quadratic objective function.\n    ", "Answer": "\r\nGurobi is designed to handle problems with objective functions that are linear or\n\n\nconvex quadratic functions for minimization problems\nconcave quadratic functions for maximization problems\n\n\nIn addition, it can handle quadratic constraints where the feasible region is convex or a second order cone\n\nYou haven't mentioned the type of problem that you are tackling, but if you want to use Gurobi to solve it, the best approach is probably to use its mixed-integer linear optimizer, or use a decomposition method.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "I have found on the Internet polynomial time algorithm for graph coloring, possibly proving P=NP\r\n                \r\nI was searching for graph coloring algorithms, and I have found algorithm, which, how author states, runs in polynomial time.\nAuthor gives also C++ program source code and demonstration program.\n\nThe suspicious thing is that decision problem whether graph is k-colorable, is NP-complete, so no polynomial time algorithm should exist until P=NP.\n\nHowever, author doesn't claims, that algorithm works for all graphs, he only says, that he haven't found any graph, for which algorithm doesn't work.\n\nSo, the question: does that algorithm really works for every graph and that means actually P=NP, or there exist certain graphs/graph classes for which it doesn't work? Or maybe there is simply a mistake in complexity calculation?\n    ", "Answer": "\r\nI think you haven't read the abstract very carefully.\n\nThe author presents an algorithm which finds ```\nm```\n-colorings of a graph, for some ```\nm```\n less than the limit imposed by Brooks' theorem: https://en.wikipedia.org/wiki/Brooks'_theorem\n\n(which is old and states that ```\nchi < delta + 1```\n as the author states in second sentence.)\n\nThe author is aware of the P vs NP question. The paper does not claim to resolve the question, he merely states:\n\n\n  For all known examples of graphs, the algorithm finds a proper m-coloring of the vertices of the graph G for m equal to the chromatic number χ(G)\n\n\nThen he asks,\n\n\n  In view of the importance of the P versus NP question, we ask: does there exist a graph G for which this algorithm cannot find a proper m-coloring of the vertices of G with m equal to the chromatic number χ(G)?\n\n\nEmphasis in original (!)\n\nSo it doesn't claim to resolve P vs NP, its just, as a matter of academic research, they ask \"can anyone produce an example on which this algorithm fails to reach the chromatic number\", which might be instructive to them for mathematical purposes. It is highly unlikely that the algorithm actually achieves the chromatic number for all graphs. (Although it is, scientifically speaking, unknown whether it does or doesn't.)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "I have found on the Internet polynomial time algorithm for graph coloring, possibly proving P=NP\r\n                \r\nI was searching for graph coloring algorithms, and I have found algorithm, which, how author states, runs in polynomial time.\nAuthor gives also C++ program source code and demonstration program.\n\nThe suspicious thing is that decision problem whether graph is k-colorable, is NP-complete, so no polynomial time algorithm should exist until P=NP.\n\nHowever, author doesn't claims, that algorithm works for all graphs, he only says, that he haven't found any graph, for which algorithm doesn't work.\n\nSo, the question: does that algorithm really works for every graph and that means actually P=NP, or there exist certain graphs/graph classes for which it doesn't work? Or maybe there is simply a mistake in complexity calculation?\n    ", "Answer": "\r\nI think you haven't read the abstract very carefully.\n\nThe author presents an algorithm which finds ```\nm```\n-colorings of a graph, for some ```\nm```\n less than the limit imposed by Brooks' theorem: https://en.wikipedia.org/wiki/Brooks'_theorem\n\n(which is old and states that ```\nchi < delta + 1```\n as the author states in second sentence.)\n\nThe author is aware of the P vs NP question. The paper does not claim to resolve the question, he merely states:\n\n\n  For all known examples of graphs, the algorithm finds a proper m-coloring of the vertices of the graph G for m equal to the chromatic number χ(G)\n\n\nThen he asks,\n\n\n  In view of the importance of the P versus NP question, we ask: does there exist a graph G for which this algorithm cannot find a proper m-coloring of the vertices of G with m equal to the chromatic number χ(G)?\n\n\nEmphasis in original (!)\n\nSo it doesn't claim to resolve P vs NP, its just, as a matter of academic research, they ask \"can anyone produce an example on which this algorithm fails to reach the chromatic number\", which might be instructive to them for mathematical purposes. It is highly unlikely that the algorithm actually achieves the chromatic number for all graphs. (Although it is, scientifically speaking, unknown whether it does or doesn't.)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Heuristic to find the maximum weight independent set in an arbritary graph\r\n                \r\nThe MWIS (Maximum weight independent set) is a NP-complete problem, so if P!=NP we cannot find a solution in a good enough time complexity.\n\nI am looking for an algorithm that can find an approximation of the MWIS in an arbitrary graph within a good time complexity. I am currently working on a connected graph with 128 nodes and 3051 edges.\n\nI have found this paper, but it seems that it is only working for bipartite graph with an unique MWIS.\n\nI will be glad if anyone can help me with some references or even better with a pseudo-code of a working algorithm.\n    ", "Answer": "\r\nIt's possible to formulate this as the following problem. Suppose each vertex v in the graph has weight w(v). You define a variable x(v), and use some out-of-the-box linear programming solver to solve\n\nmax \\sum_v w(v) x(v) (maximize the weight of chosen vertices)\n\nsubject to \n\nx(u) + x(v) <= 1, (u, v) \\in E (don't take neighbors)\n\nand\n\nx(v) \\in {0, 1} (can only choose to take or not take a vertex)\n\n\n\nThis is a combinatorical problem (the last constraint is exponential in the number of vertices). There are two ways to continue from here:\n\n\nSwitch the last constraint to \n\nx(v) \\in [0, 1] (extent to which you choose a vertex)\n\nsolve it with an LP solver, and continue along this paper, 4.3.\nIn the comment below, David Eisenstat claims that for the sizes of your graph, an integer solver will do just fine (and yield better results)\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why cant we use algorithm to find all cycles to find an hamiltonian cycle?\r\n                \r\nI recently came across algorithms to find all cycles in an undirected graph, and was confused when i saw that they are running linear time (example), It seem easy to use one of these to find hamilton cycle (for each cycle we find just check if it is of n nodes, e.g contains all nodes) in polynomial time, but hamilton problem is a known NP complete problem so i gotta be missing something... what am i missing here?\nThanks!\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Polygon packing 2D\r\n                \r\nI have problem of packing 2 arbitrary polygons. I.e. we have 2 arbitrary polygons. We are to find such placement of this polygons (we could make rotations and movements), when rectangle, which circumscribes this polygons has minimal area.\n\nI know, that this is a NP-complete problem. I want to choose an efficient algorithm for solving this problem. I' looking for No-Fit-Polygon approach. But I could't find anywhere the simple and clear algorithm for finding the NFP of two arbitrary polygons.\n    ", "Answer": "\r\nThe parameter space does not seem too big and testing it is not too bad either. If you fix one polygon, the other ploygon can be shifted along x-axis by X, and shifted along y-axis by Y and rotated by r.\n\nThe interesting region for X and Y can be determined by finding some bounding box for for the polygons. r of course is between  and 360 degrees.\n\nSo how about you tried a set of a set of equally spaced intervals in the interesting range for X,Y and r. Perhaps, once you found the interesting points in these dimensions, you can do more finer grained search.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to assign N numbers into M pack that minimize some target function?\r\n                \r\nI have N(for example 30) integer numbers ```\nV[i]```\n, and M(for example 8) packs, each pack\nhave an expected value ```\nP[j]```\n.\n\nI want to assign each integer number to one pack, the following expression calculate the difference\nbetween the sum of ```\nV[k]```\n that in pack ```\nj```\n and the expected value of pack ```\nj```\n.\n\n```\ndiff[j] = abs(P[j] - sum(V[k] that in pack j))\n```\n\n\nThe target is to find the best solution that minimize ```\nsum(diff[j])```\n.\n\nI don't know what's the type of this kind of problem. Can this be solved by Linear programming, or is it a NP-Complete problem?\n    ", "Answer": "\r\nRegardless of whether this is NP-hard or not, you may be able to efficiently solve your problem for the problem instances you need using easily accessible integer programming software. For your problem, you could define x_{ij} to define if X[i] is assigned to group j. You would then also define variables d_j, which are the diff[j] in your formulation. Then your model is:\n\n```\nmin_{x, d} \\sum_{j=1}^M d_j\ns.t.       d_j >= P[j] - \\sum_{i=1}^N X[i]x_{ij} \\forall j\n           d_j >= \\sum_{i=1}^N X[i]x_{ij} - P[j] \\forall j\n           \\sum_{j=1}^M x_ij = 1 \\forall i\n           x_{ij}\\in \\{0, 1\\}\n```\n\n\nThis is a mixed integer optimization model, which can be solved, for instance, using the ```\nlpsolve```\n or ```\nlpSolveAPI```\n packages in R or the ```\nintlinprog```\n function in MATLAB.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Problem for which proof of NP is non-trivial\r\n                \r\nI'm looking for a problem that (provably) lies in NP, but for which the proof that it lies in NP is \"not completely trivial/obvious\". Anyone know of such a problem (ideally a \"natural\" problem)?\n    ", "Answer": "\r\nI think primality is a good candidate for this:\n\nWitnessing that a number is composite is easy (give a factorization), and it can be checked efficiently.\n\nWitnessing that a number is prime is not so obvious. But it has been known since the 80s that this can be done. So for a long time, PRIMES was a natural language in \"NP intersect coNP\".\n\nIt is known since like 2004 that PRIMES is actually in P\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Are there exact methods to solve the Path cover in bipartite graphs?\r\n                \r\nWe consider a simple graph G =(V; E). The well known Path Cover problem  (https://en.wikipedia.org/wiki/Path_cover) is NP-complete on all graph classes on which the Hamiltonian path problem is NP-complete, including planar graphs, bipartite graphs and chordal graphs.  Many polynomial algorithms have been proposed in the literature for special graph classes on which this problem is polynomial, but I did not find any exact methods to find the minimum vertex-disjoint path cover for bipartite graphs (or even for planar graphs and chordal graphs), especially Branch and Bound Algorithms.\n\nDo you know any exact methods, in particular Branch and Bound algorithms, for the path cover problem on graph classes on which this problem is NP-hard  (bipartite graphs, planar graphs and chordal graphs)?\n\nThank you in advance.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "What's the complexity of 3-SAT algorithm on a quantum machine?\r\n                \r\nI know that 3-SAT problem is NP-Complete but 'they say' it can be run quit faster on a quantum machine.\nCould you explain what kind of performance is possible to gain using quantum computers?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is finding a simple path in a weighted undirected graph with maximum cost in polynomial time? Is it NP?\r\n                \r\nI need to know if it is possible to find a simple path with maximum cost in any weighted undirected graph. \n\nI mean to find THE MOST expensive path of all for any pair of vertex.\n\nInput: Graph G = (V,E)\n\nOutput: The cost of the most expensive path in the graph G.\n\nIs this problem NP-Complete?, I think it is. Could you provide any reference to an article where I can review this.\n    ", "Answer": "\r\nYou're not the first to think of this problem. In fact, it was the first link in the google search results.\n\nedit\nGuys, un-weighted graph is a special case of weighted graph: all edges have weight 1 :)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Edge bi-partitioning, no triangles: complexity?\r\n                \r\nI've got to find an algorithm to solve a problem for faculty.\nI'm not requesting solutions (and please don't post any), just read further.\n\nThe problem's sentence:\n\n```\n** Given a graph G = (V, E) find 2 sets S1 and S2 of edges of G such that:\n   1. S1 ∪ S2 = E\n   2. S1 ∩ S2 = ∅\n   3. The 2 subgraphs of G formed by S1 and S2 do not contain triangles (triangle = 3 nodes such that they link together 2 by 2)\n```\n\n\nI've been trying to find an algorithm to solve this in the last 2 days and I think I'm on the right way. For any of you that stumbled upon it before: do you know if this problem has been solved in polynomial time? (and if not, is it NP-complete/NP-hard/NP?)\n\nThanks in advance,\nJohn\n    ", "Answer": "\r\nGoogled a bit more and found it. It's called monochromatic triangle and it's NP-complete.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How hard is this graph problem?\r\n                \r\nI have a problem to solve for a social-networks application, and it sounds hard: I'm not sure if its NP-complete or not. It smells like it might be NP-complete, but I don't have a good sense for these things. In any case, an algorithm would be much better news for me. \n\nAnyhow, the input is some graph, and what I want to do is partition the nodes into two sets so that neither set contains a triangle. If it helps, I know this particular graph is 3-colorable, though I don't actually know a coloring.\n\nHeuristically, a \"greedy\" algorithm seems to converge quickly: I just look for triangles in either side of the partition, and break them when I find them. \n    ", "Answer": "\r\nThe decision version of problem is NP-Complete for general graphs: http://users.soe.ucsc.edu/~optas/papers/G-free-complex.pdf and is applicable not just for triangles.\n\nOf course, that still does not help resolve the question for the search version of 3-colourable graphs and triangle freeness (the decision version is trivially in P).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is there a graph coloring algorithm where limits can be placed on number of vertices per color\r\n                \r\nI understand that graph coloring is a NP-complete problem. I was wondering if adding a restriction on the number of vertices that can have a given color makes the problem simpler? I can't seem to find any algorithm which does this. For example if I have a graph, I'd like to say \"what is the smallest coloring of this graph such that each color has at most 3 vertices\", or if it simplifies the problem \"is there a way to color this graph with 4 colors such that each color has at most 3 vertices\"?\n\nThanks!\n    ", "Answer": "\r\nThis problem is still NP-complete by a simple reduction from the original graph coloring problem: a graph with n nodes is k-colorable if and only if the graph can be colored with k colors and no color is assigned to more than n nodes.  In other words, the general version of the problem you're phrasing has graph coloring as a special case, and so it will still be NP-hard.\n\nHope this helps!\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Shortest weight constrained path to Partition reduction\r\n                \r\nI am trying to prove NP-completness of a shortest weight constrained path problem. I have read multiple papers, but for love of god, cannot figure out how to show a reduction of this to partition problem. \n\nThe question is given for each edge, a weight w and length l, show that for an undirected graph, the problem of finding a path such that sum of weights on the path < W and sum of lenghths of the path < L where, L and W are constants given to us in the problem. \n\nI looked at Garey and Johnson which just states that problem is NP complete and doesn't provide a way to prove, or a reduction. \n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Graph Coloring with CLP(FD)\r\n                \r\nI am trying to solve the map/graph coloring problem using CLP(FD) in Prolog. I took the predicates from the paper\n\"A comparison of CLP(FD) and ASP solutions to NP-complete problems\" and I'm trying with the following example:\n```\ncoloring(K, Output) :- graph(Nodes, Edges),\n    create_output(Nodes, Colors, Output), domain(Colors, 1, K),\n    different(Output, Edges), labeling([ff], Colors).\ncreate_output([],[],[]).\ncreate_output([N | Nodes], [C|Colors], [N-C|Output]) :-\n    create_output(Nodes, Colors, Output).\ndifferent(_, []).\ndifferent(Output, [[A,B]|R]) :- member(A-CA, Output),\n    member(B-CB, Output), CA #\\= CB, different(Output, R).\ngraph([1,2,3,4,5],[(1,2),(1,3),(2,4),(2,5),(3,4),(3,5)]).\n```\n\nbut when I run the query\n```\ncreate_output([1,2,3,4,5],[a,b,c,d],A).```\n\nit gives me false even that for this graph it is possible to use only 4 colors (a,b,c,d). When I add another color it works fine, it seems that set of nodes should be same size as set of colors. But this is  not what map coloring should do.\nAnyone is able to help me understand what's the problem with the predicates above?\n    ", "Answer": "\r\nI think ```\ncreate_output/3```\n should be called with only Nodes instantiated. It will create the other 2 lists with domain variables (that is, color indexes) and associations between nodes and colors.\nAnyway, from the code below, you can see that the real problem is in the head of different/2, where a list has been used instead of a 'tuple' to match an edge...\n```\n\n:- module(mapcolor,\n          [coloring/2]).\n\n:- use_module(library(clpfd)).\n\ncoloring(K, Output) :-\n    graph(Nodes, Edges),\n    create_output(Nodes, Colors, Output),\n    domain(Colors, 1, K),\n    different(Output, Edges),\n    labeling([ff], Colors).\n\ndomain(Colors, Low, High) :- Colors ins Low .. High.\n\ncreate_output([],[],[]).\ncreate_output([N | Nodes], [C|Colors], [N-C|Output]) :-\n    create_output(Nodes, Colors, Output).\n\ndifferent(_, []).\ndifferent(Output, [(A,B)|R]) :-  % note: was [[A,B]|R]\n    member(A-CA, Output),\n    member(B-CB, Output),\n    CA #\\= CB,\n    different(Output, R).\n\ngraph([1,2,3,4,5],[(1,2),(1,3),(2,4),(2,5),(3,4),(3,5)]).\n\n```\n\nNote that the graph can be colored with just 2 colors:\n```\n?- coloring(2,C).\nC = [1-1, 2-2, 3-2, 4-1, 5-1] ;\nC = [1-2, 2-1, 3-1, 4-2, 5-2] ;\nfalse.\n```\n\nWith 4 colors, there are a lot of solutions...\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Graph Coloring with CLP(FD)\r\n                \r\nI am trying to solve the map/graph coloring problem using CLP(FD) in Prolog. I took the predicates from the paper\n\"A comparison of CLP(FD) and ASP solutions to NP-complete problems\" and I'm trying with the following example:\n```\ncoloring(K, Output) :- graph(Nodes, Edges),\n    create_output(Nodes, Colors, Output), domain(Colors, 1, K),\n    different(Output, Edges), labeling([ff], Colors).\ncreate_output([],[],[]).\ncreate_output([N | Nodes], [C|Colors], [N-C|Output]) :-\n    create_output(Nodes, Colors, Output).\ndifferent(_, []).\ndifferent(Output, [[A,B]|R]) :- member(A-CA, Output),\n    member(B-CB, Output), CA #\\= CB, different(Output, R).\ngraph([1,2,3,4,5],[(1,2),(1,3),(2,4),(2,5),(3,4),(3,5)]).\n```\n\nbut when I run the query\n```\ncreate_output([1,2,3,4,5],[a,b,c,d],A).```\n\nit gives me false even that for this graph it is possible to use only 4 colors (a,b,c,d). When I add another color it works fine, it seems that set of nodes should be same size as set of colors. But this is  not what map coloring should do.\nAnyone is able to help me understand what's the problem with the predicates above?\n    ", "Answer": "\r\nI think ```\ncreate_output/3```\n should be called with only Nodes instantiated. It will create the other 2 lists with domain variables (that is, color indexes) and associations between nodes and colors.\nAnyway, from the code below, you can see that the real problem is in the head of different/2, where a list has been used instead of a 'tuple' to match an edge...\n```\n\n:- module(mapcolor,\n          [coloring/2]).\n\n:- use_module(library(clpfd)).\n\ncoloring(K, Output) :-\n    graph(Nodes, Edges),\n    create_output(Nodes, Colors, Output),\n    domain(Colors, 1, K),\n    different(Output, Edges),\n    labeling([ff], Colors).\n\ndomain(Colors, Low, High) :- Colors ins Low .. High.\n\ncreate_output([],[],[]).\ncreate_output([N | Nodes], [C|Colors], [N-C|Output]) :-\n    create_output(Nodes, Colors, Output).\n\ndifferent(_, []).\ndifferent(Output, [(A,B)|R]) :-  % note: was [[A,B]|R]\n    member(A-CA, Output),\n    member(B-CB, Output),\n    CA #\\= CB,\n    different(Output, R).\n\ngraph([1,2,3,4,5],[(1,2),(1,3),(2,4),(2,5),(3,4),(3,5)]).\n\n```\n\nNote that the graph can be colored with just 2 colors:\n```\n?- coloring(2,C).\nC = [1-1, 2-2, 3-2, 4-1, 5-1] ;\nC = [1-2, 2-1, 3-1, 4-2, 5-2] ;\nfalse.\n```\n\nWith 4 colors, there are a lot of solutions...\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Divide a given set of numbers N in two groups such that their difference of their sum is minimum?\r\n                \r\nYou can exempt atmost one element from the set to acheive the goal.\nexample:-\n\nN=3\n\nthe numbers given are = 1,2,5\n\nSo,\n\nSet 1 should be :- [1]\n\nSet 2 should be :- [2]\n\nWe have excluded 5 as we can acheive a lesser difference without it being in either groups.\n\nN=4\n\nnumbers = 1,2,2,5\n\nSet1 = [1,2,2]\n\nSet2 = [5]\n\nWhat is best algorithm for this?\nI know that this a NP-complete problem.\nAnd I think that brute force would give me the correct solution but I need an algorithm if available.\n    ", "Answer": "\r\n\n  I know that this a NP-complete problem.\n\n\nNot exactly, the partition optimisation problem is even known to be NP-hard.\n\n\n  And I think that brute force would give me the correct solution but I need an algorithm if available.\n\n\nNP-hard means just that there is no known algorithm (to determine the solution) performing better than the brute force method.\n\nSo you'll probably need an approximation, but which one fits your needs only you can know.\n\n\n  What is best algorithm for this?\n\n\nDefine \"best\".\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Finding the maximum sum that can be formed from a set, by partitioning it into two subset\r\n                \r\nDecription\n\nGiven a set of numbers S.\n\nFind maximum sum such that\n\nSum(A1) = Sum(A2)\n\nWhere, A1⊂S and A2⊂S and A1⋂A2=∅\n\nAnd Sum(X), is the sum of all elements within the set X.\n\nApproach\n\nBrute Force\n\nThe easiest approach is:\n\n```\nprint maximumSum(0,0,0)\ndef maximumSum(index,sum1,sum2):\n  ans=0\n  if sum1 == sum2:\n    ans=sum1\n  if index >= len(S):\n    return ans\n  m1=maximumSum(index+1,sum1+S[index],sum2)\n  m2=maximumSum(index+1,sum1,sum2+S[index])\n  m3=maximumSum(index+1,sum1,sum2)\n  return max(m,m1,m2,m3)\n```\n\n\nTime Complexity:O(2N)Space Complexity:O(1)\n\nIs there a better approach than this?\nOptional:\nI would like to know whether the given problem is an NP-Complete problem or not.\n\nEdit:\n\nLimits\n\n1 <= Sum(S) <= 1000000\n2 <= len(S) <= 100\nTime Limit: 60sec(can vary depending upon language used)\n    ", "Answer": "\r\nYes It is NPC problem\nPartition Problem\n\nYou can see the pseudo polynomial algorithm part if the sum of the set is small\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Reducing Planning to Quantified Boolean Formulae\r\n                \r\nWhy don't we reduce the  Planning Problem in AI   to the \n TQBF Version of SAT  in practical solvers.\n\nMany planning problems are in practice \"compiled down\" or reduced to the SAT problem, which is in turn solved by SAT Solvers. The problem is that , since planning is PSPACE Complete, and SAT is NP Complete, an exponential number of literals may be required. \n\nWhy, then, do practical planners use this approach? Why don't we all solve TQBF SAT and then \"compile\" Planning down to TQBF, which should only take Polynomial time anyway?\n    ", "Answer": "\r\nThis has already been done.\n\nGenerally TQBF is used to model conformant planning, but there do exist encodings of purely propositional logic planning problems to (polynomially-sized) TQBF formulae.\n\nThe main drawback is that, although we have a much smaller formula, it's not neccessarily easier to solve.  TQBF solving is no way near as mature as the research into solving SAT, and Planning as TQBF is still some way behind in performance.\n\nHere is one publication detailing such a transformation (mine):\n\nhttp://users.cecs.anu.edu.au/~ssanner/ICAPS_2010_DC/Abstracts/cashmore.pdf\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Unit Testing Approximation Algorithms\r\n                \r\nI'm working on an open-source approximation algorithms library for graphs and networks using some popular python packages as a base. The main goal is to encompass up-to-date approximation algorithms for NP-Complete problems over graphs and networks. The reason for this is 1) I haven't seen a nice (modern) consolidated package that covers this and 2) it would be a nice pedagogical tool for learning about approximation algorithms on NP-Hard optimization problems.\n\nIn building this library I am using unit-tests to sanity check (as any proper developer would). I am somewhat cautious about my unit tests in that by their very nature, approximation algorithms may not return the correct solution. Currently I am solving some small instances by hand and then assuring that the returned result matches that, but this is not desirable, nor scalable in an implementation sense.\n\nWhat would be the best way to unit test approximation algorithms? Generate random instances and ensure that the returned results are less than the bound guaranteed by the algorithm? That would seem to have false positives (the test just got lucky that time, not guaranteed for all instances to be below bound).\n    ", "Answer": "\r\nYou need to separate two concerns here. The quality of your approximation algorithms and the correctness of implementation of those algorithms. \n\nTesting the quality of an approximation algorithm usually will not lend itself to unit testing methods used in software development. For example you would need to generate random problems that is representative of the real sizes of problems. You might need to do mathematical work to get some upper/lower bound to judge the quality of your algorithms for unsolvable large instances. Or use problem test sets that have known or best known solutions and compare your results. But in any case unit testing would not help you much in improving the quality of the approximation algorithms. This is where your domain knowledge in optimization and math will help.\n\nThe correctness of your implementation is where unit tests will be really useful. You can use toy sized problems here and compare known results (solving by hand, or verified through careful step by step debugging in code) with what your code generates. Having small problems is not only enough but also desirable here so that tests run fast and can be run many times during development cycle. These types of tests makes sure that overall algorithm is arriving at the correct result. It is somewhere between a unit test and an integration tests since you are testing a large portion of the code as a black box. But I have found these types of tests to be extremely useful in optimization domain. One thing I recommend doing for this type of testing is removing all randomness in your algorithms through fixed seeds for random number generators. These tests should always run in a deterministic way and give exactly the same result 100% of the time. \nI also recommend unit testing at the lower level modules of your algorithms. Isolate that method that assigns weights to arcs on the graph and check if the correct weights are assigned. Isolate your objective function value calculation function and unit test that. You get my point. \n\nOne other concern that cuts both of these slices is performance. You cannot reliably test performance with small toy problems. Also realizing a change that degrades performance significantly for a working algorithm quickly is very desirable. Once you have a running version of your algorithms you can create larger test problems where you measure the performance and automate it to be your performance/integration tests. You can run these less frequently as they will take more time but at least will notify you early of newly introduced performance bottlenecks during refactoring or new feature additions to algorithms \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Find best scoring assignment of customers to products\r\n                \r\nI got this programming question in an difficult interview's last round. \n\nSo the question has two lists of same size.\n\n```\nList<Customer>, List<Products>\n```\n\n\nThere is a function which is like follows\n\n```\nint score(Customer, Product)```\n and returns a score.\n\nI have to the find an assignment of all the customer to products where score should be maximum.\n\nIt seems like an NP-complete problem and unlikely to be solved by me in the interview especially when I still couldn't a few days after the interview. Now I am just curious to know the solution.\nCan anyone please help?\n    ", "Answer": "\r\nYou could model this as a weighted bipartite graph that you want to find a maximal match.\n\nWikipedia on Matching has this answer that may be useful:\n\n\n  In a weighted bipartite graph, each edge has an associated value. A\n  maximum weighted bipartite matching is defined as a matching where the\n  sum of the values of the edges in the matching have a maximal value.\n  If the graph is not complete bipartite, missing edges are inserted\n  with value zero. Finding such a matching is known as the assignment\n  problem. It can be solved by using a modified shortest path search in\n  the augmenting path algorithm. If the Bellman–Ford algorithm is used,\n  the running time becomes O(V^2 E), or the edge cost can be shifted\n  with a potential to achieve O(V^2 log(V) + V E) running time with the\n  Dijkstra algorithm and Fibonacci heap. The remarkable Hungarian\n  algorithm solves the assignment problem and it was one of the\n  beginnings of combinatorial optimization algorithms. The original\n  approach of this algorithm needs O(V^2E) running time, but it could be\n  improved to O(V^2 log(V) + V E) time with extensive use of priority\n  queues.\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Subgraph isomorphism to SAT\r\n                \r\nThe Subgraph Isomorphism (SI) problem is a computational task in which two graphs G and H are given as input, and one must determine whether G contains a subgraph that is isomorphic to H. \n\nThis is a NP-Complete problem .\n\nI want to know its relation with the SAT problem.\n In particular, I want  instances of this problem can be solved throughout SAT Solver(like miniSAT).I need an alorithm  which can do a mapping from SI to SAT problem in polynomial time and then SAT assignment can be used to find a mapping from nodes of G to nodes of H .  \n\nAny idea ??? \n    ", "Answer": "\r\nA ```\nSAT```\n encoding for the Graph Isomorphism problem is described in the SAT 2013 paper \"On the Resolution Complexity of Graph non-Isomorphism\".\n\nMinisat is one of the best-known SAT solvers, but it has several successors which are probably faster and have a higher success rate. Try Cryptominisat (version 2.9.5 seems to be faster than version 3; it supports parallel threads), Riss3g or Clasp.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is it possible to write a program to print all pairs that add to k from an input array of size n [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and  cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened,  visit the help center.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 12 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nIs it possible to write a program to print all pairs that add to k from an input array of size n. If so how? I heard this problem is NP-Complete. I was wondering if we can provide a solution to this problem in typical programming languages like C/C++\n    ", "Answer": "\r\nIt can't be NP-Complete as there is an obvious O(n^2) solution with two nested loops over the array and checking if the sum is k.\n\nThere is however an O(n) solution using hashtable. Here is the solution in C#:\n\n```\n        int[] ar = new int[] { 1, 4, 6, 8 };\n        int k = 7;\n\n        HashSet<int> set = new HashSet<int>();\n        foreach (int n in ar)\n        {\n            if (set.Contains(n))\n                Console.WriteLine(\"({0}, {1})\", k - n, n);\n\n            set.Add(k - n);\n        }\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Generate a minesweeper board which doesn't need guessing [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs to be more focused. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\r\n                \r\n                    \r\n                        Closed last year.\r\n                    \r\n                \r\n            The community reviewed whether to reopen this question last year and left it closed:\r\n            \r\n                    Original close reason(s) were not resolved\r\n            \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI am designing a Minesweeper-like game (with modified rules), and I want to prevent player from guessing. My goal is: The generated board is with few revealed squares, and player can solve the entire puzzle without any guessing.\n\nWikipedia mentioned:\n\n\n  Some implementations of Minesweeper will set up the board by never placing a mine on the first square revealed, or by arranging the board so that the solution does not require guessing. \n\n\nHowever, I cannot figure out the algorithm. \n\nBesides, in another StackOverflow question: Minesweeper solving algorithm\n\n\n  Improvement: Run the solver alongside the generator, making sure that the puzzle has a unique solution. This takes some cleverness, and isn't done in most variants.\n\n\nI doubt if this really works. It's well-known solving minesweeper is NP-complete. \n\nIn summary, my questions are:\n\n\nHow to generate a Minesweeper board which doesn't need any guessing?\nIf we can, what's the concrete algorithm?\nCould we solve this problem in polynomial time deterministically? Is this problem NP-complete? How to prove it?\n\n    ", "Answer": "\r\nThe implementation of Minesweeper in Simon Tatham's Portable Puzzle Collection is guessing-free. (It's also MIT licensed, so you're free to copy his implementation if you so desire.)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "when a given graph is 3-colorable?\r\n                \r\nI want to use graph 3-colorability to prove a problem is NP-complete But I'm not sure when a given graph is 3-colorable. I think if it doesn't have any node to be connected to all 3 vertices of a triangle in the graph.But i'm not sure. is it correct?\n    ", "Answer": "\r\nNo. Having a node connected to all three nodes in a triangle (which is just a more complicated way of saying \"it has a clique of size 4\") is sufficient but not necessary for the graph to not be 3-colorable. Graphs may be not 3-colorable for different reasons than having a clique of size 4.\n\nFor example:\n\n\n\nIt's not 3-colorable. Proof: the 5-cycle around the outside is not 2-colorable, and then you need an extra color for the middle vertex.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to find what numbers in a set add up to another given number?\r\n                \r\nHere's a problem that I seem to be running into working with an accounting system.\n\nI have a set of transactions, but their sum does not equal the amount that the accounting department thinks that it should. They are not questioning the math, just the transactions being included :p\n\nIs there an algorithm that would help me determine which transactions in the set should not be included in order for the sum to match a given amount.\n\n```\nGiven Set:  \n2  \n4  \n5  \n7\n\nGiven Sum Amount:\n13\n\nResult Set:\n2\n4\n7\n```\n\n\nEdit:\nThere's less than 100 transactions in the set. Does anyone have a C# example as there is not one on the Solving the NP-complete problem in XKCD question? \n\nMan, I should have gotten a CS degree.\n    ", "Answer": "\r\nThis is the Subset Sum problem, which is NP-Complete.  But that doesn't mean there isn't an algorithm for finding a subset sum.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Minimizing space usage by moving sets on a graph\r\n                \r\nI have a complete directional graph. On each edge there is a set of numbers. The set is saved on the source node by default. Note that each number is saved only ONCE. For example, if a node has two edges with sets {1,2,3} and {2,3,4} it takes only 4 spaces.\nNow, we can select an edge to move the set from the source to the destination with one space penalty. The question is which sets to move to the other side to get minimum space usage.\n\nFor example if I have the following graph\n\n```\n1->2: {123}\n1->3: {456}\n2->1: {}\n2->3: {456}\n3->1: {}\n3->2: {123}\n```\n\n\nThe original space usage is 12. But if I move all the sets to the destinations the used space is 3+3=6 which with 4 space penalty the result will be 10 which is better than the original setting.\n\nDoes anyone have any hint for this problem? Is this similar to an NP-complete problems?\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Dividing objects into two piles of equal weight\r\n                \r\nI am sure you have already heard about this problem. Given a list of natural numbers, is it possible to divide them into two piles of equal sums? If yes, write two lines with objects in each pile.\n\nIs this some well-known problem? Does it have a name? Is it NP-Complete? If not, what is the fastest solution?\n    ", "Answer": "\r\nThis is the Partition problem, which is NP-Complete. It is a variant of Subset SUM.\n\nWhich is the fastest, really depends on the data you have. For instance, if they were bounded, you could use dynamic programming etc.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Finding minimum distance in graph for path passing minimum three nodes and finishing with start node?\r\n                \r\nI came across a problem to find optimal algorithm solving the issue: Finding minimum path in a graph from starting point to starting point(make a cycle) and visiting minimum three different nodes in the graph. For example if we have a graph ```\nG(V,E)```\n with ```\nV={a,b,c,d,e}```\n and edges ```\nE={(a,b,16),(a,c,300),(a,d,1),(b,c,100),(b,e,15),(c,a,10),(e,c,20)}```\n the shortest distance will be 61 and it will visit ```\na->c->e->b->a```\n.\n\nI think of using Dijkstra's algorithm for weighted graph, however I do not know how to implement the part for the constraint to visit minimum 3 nodes? It looks like the Hamiltonian cycle's problem but not using all the nodes but only part of them. Is this NP-complete problem?\n\nAny help would be appreciated.\n    ", "Answer": "\r\nOne easy way to implement this is the following:\n\n\nprecompute all-pair shortest paths (e.g. using Floyd–Warshall or running Dijkstra for each possible start node)\nfor each tuple (a, b, c) of distinct nodes in the graph, consider the concatenation of shortest paths from a to b, b to c and c to a.\nReport the minimum of all examined paths.\n\n\nThe runtime will be dominated by the second step, which has runtime O(n3). So no, the problem is not NP-hard, because the number of different nodes we have to visit is fixed (in this case, 3).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Checking if A is a part of binary tree B\r\n                \r\nLet's say I have binary trees A and B and I want to know if A is a \"part\" of B. I am not only talking about subtrees. What I want to know is if B has all the nodes and edges that A does.\n\nMy thoughts were that since tree is essentially a graph, and I could view this question as a subgraph isomorphism problem (i.e. checking to see if A is a subgraph of B). But according to wikipedia this is an NP-complete problem.\n\nhttp://en.wikipedia.org/wiki/Subgraph_isomorphism_problem\n\nI know that you can check if A is a subtree of B or not with O(n) algorithms (e.g. using preorder and inorder traversals to flatten the trees to strings and checking for substrings). I was trying to modify this a little to see if I can also test for just \"parts\" as well, but to no avail. This is where I'm stuck. \n\nAre there any other ways to view this problem other than using subgraph isomorphism? I'm thinking there must be faster methods since binary trees are much more restricted and simpler versions of graphs.\n\nThanks in advance! \n\nEDIT: I realized that the worst case for even a brute force method for my question would only take O(m * n), which is polynomial. So I guess this isn't a NP-complete problem after all. Then my next question is, is there an algorithm that is faster than O(m*n)?\n    ", "Answer": "\r\nI would approach this problem in two steps:\n\n\nFind the root of ```\nA```\n in ```\nB```\n (either BFS of DFS)\nVerify that ```\nA```\n is contained in ```\nB```\n (giving that starting node), using a recursive algorithm, as below (I concocted same crazy pseudo-language, because you didn't specify the language. I think this should be understandable, no matter your background). Note that ```\na```\n is a node from ```\nA```\n (initially the root) and ```\nb```\n is a node from ```\nB```\n (initially the node found in step 1)\n\n\n\n\n```\nfunction checkTrees(node a, node b) returns boolean\n    if a does not exist or b does not exist then\n        // base of the recursion\n        return false\n    else if a is different from b then\n        // compare the current nodes\n        return false\n    else\n        // check the children of a\n        boolean leftFound = true\n        boolean rightFound = true\n\n        if a.left exists then\n            // try to match the left child of a with\n            // every possible neighbor of b\n            leftFound = checkTrees(a.left, b.left)\n                       or checkTrees(a.left, b.right)\n                       or checkTrees(a.left, b.parent)\n\n        if a.right exists then\n            // try to match the right child of a with\n            // every possible neighbor of b\n            leftFound = checkTrees(a.right, b.left)\n                       or checkTrees(a.right, b.right)\n                       or checkTrees(a.right, b.parent)\n\n        return leftFound and rightFound\n```\n\n\nAbout the running time: let ```\nm```\n be the number of nodes in ```\nA```\n and ```\nn```\n be the number of nodes in ```\nB```\n. The search in the first step takes ```\nO(n)```\n time. The running time of the second step depends on one crucial assumption I made, but that might be wrong: I assumed that every node of ```\nA```\n is equal to at most one node of ```\nB```\n. If that is the case, the running time of the second step is ```\nO(m)```\n (because you can never search too far in the wrong direction). So the total running time would be ```\nO(m + n)```\n.\n\nWhile writing down my assumption, I start to wonder whether that's not oversimplifying your case...\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to construct a Hamilton path from a complete directed graph\r\n                \r\nGiven a directed graph.\n\nAny 2 vertices are adjacent. The edge connecting a pair of vertices may be uni-directional or bi-directional.\n\nHow do I find a Hamilton path?\n\nSide notes:\n\n\nWikipedia says \"A strongly connected simple directed graph with n vertices is Hamiltonian if every vertex has a full degree greater than or equal to n.\" Therefore, a solution must exist in my problem.\nI understand that the general Hamilton path problem is NP-Complete. But it feels like this specific version should have a polynomial solution.\n\n    ", "Answer": "\r\nUse a variant of insertion sort to construct a path in quadratic time. Given a path\n\n```\nv1 v2 ... vn-1\n```\n\n\non a subset of vertices, consider how to insert ```\nvn```\n. If ```\nvn```\n has an arc to ```\nv1```\n, then prepend ```\nvn```\n. If ```\nvn-1```\n has an arc to ```\nvn```\n, then append ```\nvn```\n. Otherwise, there exists by Sperner's lemma an index ```\ni```\n such that ```\nvn```\n has an arc from ```\nvi```\n and an arc to ```\nvi+1```\n. Insert it there.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Sub-graph Selection Algorithm Problem (Dynamic Programming or NP)\r\n                \r\nWe have an algorithm problem in hand, can you please write your ideas about this, thank you!\nThere are N many nodes with K different colors. Some of the nodes have direct connection between each other and some do not.\nWe want to select M nodes from these N total nodes, but these M nodes must be connected. Also, our selected group of M nodes must have minimum number of distinct colored neighbors. There might be more than one best combinations, finding any of them is the goal.\nFor example, we selected M nodes and in total, these M nodes have the following neighbors: 5 red, 3 blue, 1 green. In this case, we count the unique colors, so the number of distinct colored neighbors, in this case, is 3. We want to minimize this number by selecting the best possible combination of M nodes.\nExample graph visualization :\n\nIn this example, let's assume M = 4, then the best possible combination of nodes would be {9, 10, 11, 12} since this group has only one neighbor which is yellow.\nIf we choose {0, 1, 3, 5}, the neighbors of this combination would be {2, 4, 6}, which consists of 2 red neighbors and 1 green neighbor; which results with score of 2 since we look for distinct number of colored neighbors.\nIs this algorithm question NP-complete? How should we proceed? If this is not NP-complete, what is the best algorithm we can use to solve this problem?\nCan we combine graph algorithms such as Prim’s, Kruskal's, Floyd Warshall or traversal algorithms?\n    ", "Answer": "\r\nIf this is an NP problem, you could use ASP to solve it.\nGiven ```\ninstance.lp```\n\n```\ncolor(0,yellow).\ncolor(3,yellow).\ncolor(8,yellow).\ncolor(10,yellow).\ncolor(2,green).\ncolor(5,green).\ncolor(12,green).\ncolor(7,blue).\ncolor(1,red).\ncolor(4,red).\ncolor(6,red).\ncolor(9,red).\ncolor(11,red).\n\nedge(0,5).\nedge(0,1).\nedge(0,2).\nedge(0,6).\nedge(5,3).\nedge(5,4).\nedge(6,4).\nedge(3,4).\nedge(2,7).\nedge(7,8).\nedge(8,9).\nedge(5,3).\nedge(9,10).\nedge(9,11).\nedge(9,12).\nedge(11,12).\n\nedge(B,A) :- edge(A,B).\n```\n\nand ```\nencoding.lp```\n\n```\nnode(X) :- color(X,_).\n\n%select exactly one start node\n1 {start(X) : node(X)} 1.\n\n% start node is in sub graph\nsub(X) :- start(X).\n% for any node in the sub graph you can add any connected node\n{sub(Y) : edge(X,Y)} :- sub(X).\n\n% it is wrong if we do not have exactly m nodes in the sub graph\n:- not m = #sum {1,X: sub(X)}.\n\n#minimize {1,C : sub(X), edge(X,Y), not sub(Y), color(Y,C)}.\n\n#show sub/1.\n```\n\nThe call\n```\nclingo encoding.lp instance.lp --const m=4```\n gives you an optimal solution:\n```\nsub(3) sub(5) sub(4) sub(6)\n```\n\nThe call\n```\nclingo encoding.lp instance.lp --const m=4 --opt-mode=optN --project```\n\ngives you all optimal solutions.\nThe tools can be found at https://potassco.org/\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Can You Reduce K-Independent Set to 2-SAT\r\n                \r\nThis is a homework question to start out. I just have some questions before I begin.\n\nOur problem is:\n\n\"Reduce from k-Independent Set to 2−SAT as follows. Given a graph G with n vertices form n propositions, one per vertex. Each proposition xi for vertex i is set to true iff the vertex i belongs to an indepdenent set. Now for every edge (u,v) write a clause that says both u and v cannot belong to the independent set.\"\n\nMy question is that everything I read says 2-SAT is not an NP-Complete problem. How can we be reducing from the Independent Set problem then?\n    ", "Answer": "\r\nThere is an important difference between finding any independent set and finding a maximum independent set (independent set of maximum size).\n\nFinding any independent set nicely reduces to 2-SAT, using the reduction you described in your question. Neither problem is NP-complete. Note that the reduction you described in your question does not constrain the number of nodes in the independent set in any way. Even the empty set will satisfy the 2-SAT problem that is produced by this reduction, because the empty set also is an independent set!\n\nFinding a maximum independent set (or k-independent set) however is an NP-complete problem. It does not reduce to 2-SAT.\n\nOr in other words: The k in \"k-Independent Set\" is an additional constraint that is not part of this 2-SAT reduction (that's why the k is not even mentioned in the description of the reduction). You could add additional clauses to the SAT problem to count the number of included nodes and enforce that this number is at least k, but you can't do that by adding only 2-clauses. So adding the k is the step where your 2-SAT problem becomes an NP-complete general SAT problem.\n\nMAX-2-SAT is an NP-complete extension of 2-SAT that can also be used to solve the maximum independent set problem using the reduction you posted. (You'd need two trivial modifications to the reduction: (1) Add 1-clauses for each proposition and (2) duplicate the 2-clauses for weighting.)\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Select k numbers from each category without duplicates and maximize the selection\r\n                \r\nThere are ```\nN```\n lists of numbers.  Select ```\nk```\n numbers from each list and return the largest set (no duplicates) that can be formed in this way.  If multiple sets of the same size are possible, returning any one of them is acceptable.  \n\nFor example, if N = 3, k = 2,\n\n```\nl1: [1, 2, 3]\nl2: [2, 7]\nl3: [3]\n```\n\n\nThen the optimal result is ```\n[1, 3, 2, 7]```\n. Pick ```\n[1, 3]```\n from ```\nl1```\n, pick ```\n[2, 7]```\n from ```\nl2```\n, pick ```\n[3]```\n from ```\nl3```\n. (Though there are other selections but the number of the elements in result set is less than this one, so this one is the best selection.)\n\nI think this is a NP-complete problem and the only approach is enumeration.\n\nPlease shed some light on. Thanks in advance!\n    ", "Answer": "\r\nThis problem may be solved with maximum bipartite matching. It is a classic algorithm and its description can be easily find on the internet, so I won't include it here.\n\nNote that this algorithm is polynomial-time, so the problem is not NP-hard.\n\nThe bipartite matching problem is: given a bipartite graph, select a set of edges such that each vertex is adjacent to at most one selected edge, and among possible sets find one with maximum cardinality.\n\nLet's build a bipartite graph. In the left part there will be a vertex for all distinct numbers which appear in the input. In the right part there will be ```\nk```\n vertices per each list. Now, the \"number\" vertex is connected with all \"list\" vertices such that the list contains the number.\n\nNow note that the cardinality of the maximum matching in this graph is exactly the answer for your problem: we've taken as many distinct numbers as possible without taking more than ```\nk```\n from any single list. Here we allow taking less than ```\nk```\n items from a list because it cannot increase the answer. You can take any extra (useless) items if necessary.\n\nIf you know something about maximum flows, you may consider adding only one vertex per each list, having ```\nk```\n-capacity edge to sink. This is essentially the same but yields faster asymptotic running time.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "2D Bin Packing with Multiple Size Bins\r\n                \r\nLets say we have multiple sizes of bins defined by Length x Width , those could be called \"raw material\" sizes. \n\nI need to cut certain amount of tables (rectangles, in guillotine form) out of that raw material so that the amount of raw material is minimized.\n\nAs the bins do not have the same size they should be somehow factored or prioritize to reflect their value - so a bigger bin is obviously \"more expensive\". \n\nI know this is a NP-Complete problem and I don't expect a deterministic algorithm in a polynomial time.\n\nI need an algorithm that solves the problem.\n\nAny suggestions would be helpful!\n\nThanks\n    ", "Answer": "\r\nWell, the basics are: You first need to define well a goodness function. Only after that your problem can be considered clearly stated. Let us call any layout of rectangles on your material plate an \"Arrangement\". The goodnes function should map from the domain of Arrangements to the domain of real numbers, the bigger the better, let's say. The function should be decreasing with the amount of material \"wasted\" in the given Arrangement, and increasing with the amount and value of the rectangles satisfied by the Arranegement. I repeat, you are the one who has to define that goodness function, that is, relative value of material and the value of the individual rectangles, which, as you say, fulfill the saying \"the bigger the better\". You have to quantify it.\n\nOnce you do this, a plethora of algorithms opens for you, the first being the random algorithm: You distribute a non-overlapping Arrangement or rectangles randomly on your sheet of material, evaluate its goodness and store it in the memory. After you do this sufficiently many times, you pick the best one. The improvement of this algorithm would be to try to pick already good arrangements and \"nudge around\" the rectangles a bit to gain space for one more small rectangle. That's what Dylan might mean by using simulated annealing. And btw. don't read that Wikipedia page on Simulated annealing, it will only mess up your head.\n\n\n\nResponse to the comment:\n\nNick, obviously, you have to use all kinds of bins from the very beginning. Let's say you have the starting sheet of material defined (either as a bitmap, or by vectors). You'll do the following:\n1. Randomly pick a point\n2. Randomly pick a rectangle type\n3. Randomly pick rotation\n4. If the rectangle doesn't fit, go back to point 1.\n5. If the rectangle fits, place it on the material sheet and\n   try placing a second rectangle by the same method.\n6. Then third, fourth etc., until you encounter too many failures and conclude that\n   you hit a dead end.\n7. Calculate the goodness of the Resulting arrangement\n8. Go on to the next arrangment\n\nNow it occurs to me, that maybe your cutting machine only allows one orientation (2 axis\nwith no tool rotation), so rotation of the rectangles does not have to be taken into account.\nIn that case, you will randomly pick the point not just anywhere, but on the side of the material\nsheet or on the side of another rectangle already on the sheet and you will place the\nnext rectangle to this point so that it has adjacent side with the side of the sheet\nor with another rectangle. In this case (no rotation) you can randomly pick a direction\nand shift the new rectangle in the chosen direction until it hits any perpendicular\nwall. That way, you'll save computing work and create better arrangements from the get\ngo. The last step is still computing the goodness function and picking the best.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Why Eulerian path can be implemented in linear time, but not Hamiltonian path?\r\n                \r\nI learned that even though seemingly similar, Eulerian path can be solved in linear time while Hamiltonian path problem is NP-complete. I wonder what is the reason that underlies this difference? I don't know too much graph theory so probably won't understand well a rigorous proof, but some jargons should be fine.\n    ", "Answer": "\r\nBasically, the Euler problem can be solved with dynamic programming, and the Hamilton problem can't. \n\nThis means that if you have a subset of your graph and find a valid circular path through it, you can combined this partial solution with other partial solutions and find a globally valid path. That isn't so for the optimal path: even after you have found the optimal path through a small part of a graph, this may very well not be a part of the globally optimal path (and in fact, it usually isn't). Informally, the optimal path through a large graph depends on the exact values in all other parts of the graph, and therefore no one has ever found a way to use \"divide and conquer\" correctly on the problem.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Explore every node in a graph\r\n                \r\nI am given a connected graph with N nodes (numbered from 1..N) and M bidirectional edges consisting in a couple (A,B). Edges are unweighted.\n\nI have K people starting at node 1 and I want to explore every node of the graph. I takes one unit of time to a person to travel from one node to one of its neighbor. \n\nHow long will it take to explore every node? I am searching for an efficient algorithm to compute the minimum traversal time, but I am afraid it is an NP-complete problem. (The constraints on the number of edges and number of people are small though).\n    ", "Answer": "\r\nSuppose K were 1. Then the minimisation problem reduces to finding a minimum length path that touches every node at least once.\n\nIf we construct a new weighted graph G' with the same nodes and with edges between every two nodes whose weight is the minimum distance between those nodes in the original graph, then the minimum length path through all the nodes in G is the minimum length Hamiltonian path through G', the travelling salesperson problem, which is well-known to be NP-complete.\n\nSo for at least one value of K, the problem is NP-complete. However, for large values of K (say, ≥ N), we can produce a minimum solution in much less time, since we can just construt the minimum spanning tree and find the distance of the furthest element. I doubt whether there is any such simplified solution for small values of K, but I'd definitely use the MST as a heuristic for finding a reasonable solution.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Verification algorithm for minimum vertex cover?\r\n                \r\nWe know that the minimum vertex cover is NP complete, which means that it is in the set of problems that can be verified in polynomial time. \n\nAs I understand it, the verification process would require the following:\n\n\nVerify that the solution is a vertex cover at all\nVerify that the solution is the smallest possible subset of the source graph that satisfies condition #1\n\n\nI'm finding it hard to establish that step #2 can be done in polynomial time.  Can anyone explain how it is?\n    ", "Answer": "\r\nThe minimum vertex cover is NP-hard. It is only NP-complete if it is restated as a decision problem which can be verified in polynomial time.\n\n\n  The minimum vertex cover problem is the optimization problem of finding a smallest vertex cover in a given graph.\n  \n  \n  INSTANCE: Graph G\n  OUTPUT: Smallest number k such that G has a vertex cover of size k.\n  \n  \n  If the problem is stated as a decision problem, it is called the vertex cover problem:\n  \n  \n  INSTANCE: Graph G and positive integer k.\n  QUESTION: Does G have a vertex cover of size at most k?\n  \n\n\nRestating a problem as a decision problem is a common way to make problems NP-complete. Basically you turn an open-ended problem of the form \"find the smallest solution k\" into a yes/no question, \"for a given k, does a solution exist?\"\n\nFor example, for the travelling salesman problem, verifying that a proposed solution the shortest path between all cities is NP-hard. But if the problem is restated as only having to find a solution shorter than k total distance for some k, then verifying a solution is easy. You just find the length of the proposed solution and check that it's less than k.\n\nThe decision problem formulation can be easily used to solve the general formulation. To find the shortest path all you have to do is ratchet down the value of k until there are no solutions found.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Time complexity analysis of minimum set cover solution\r\n                \r\nFor the question \n\n\n  There are n persons and k different type of dishes. Each person has\n  some preference for each dish. Either he likes it or not. We need to\n  feed all people. Every person should get atleast one dish of his\n  chioce. What is the minimum number of different type of dishes we can\n  order?\n\n\nOne of the solution is,\n\n```\n  public class OptimumDish {\n\n  private Set<Integer> result = new HashSet<Integer>();\n\n  public void print(){\n    for(int r:result)\n      System.out.print(r + \" \");\n  }\n\n  // Find the optimum dish by navigating all available options\n  public void find(int[][] m, int r, int c, int mr, int mc, Stack<Integer> dishes) {\n\n    dishes.push(c);\n\n    if (r == mr) {\n      // Reached last person. Get the unique dishes\n      Set<Integer> d = new HashSet<>(dishes);\n      if(result.size() == 0 || result.size() > d.size())\n        result = d;\n    }\n    else if (r < mr) {\n      // Check next person's preferred dish\n      for (int i = 0; i <= mc; i++) {\n        if (m[r + 1][i] == 1) {\n          find(m, r+1, i, mr, mc, dishes);\n          break;\n        }\n      }\n    }\n\n    dishes.pop();\n\n    // Current dish may not be the optimum.\n    // Check other dish for the same person\n    for (int i = c + 1; i <= mc; i++) {\n      if (m[r][i] == 1) {\n        find(m, r, i, mr, mc, dishes);\n      }\n    }\n  }\n\n  public static void main(String[] args) {\n\n    int[][] m = { \n        { 0, 1, 1, 0, 0, 0, 0 },\n        { 0, 1, 0, 1, 0, 0, 0 },\n        { 0, 1, 1, 0, 0, 1, 0 },\n        { 1, 0, 0, 1, 0, 0, 0 },\n        { 0, 0, 1, 0, 1, 0, 0 },\n        { 0, 0, 0, 1, 0, 0, 1 }\n        };\n\n    int mr = m.length - 1;\n    int mc = m[0].length - 1;\n    int c = 0;\n\n    for (int i = 0; i <= mr; i++) {\n      if (m[0][i] == 1) {\n        c = i;\n        break;\n      }\n    }\n\n    OptimumDish od = new OptimumDish();\n    Stack<Integer> dishes = new Stack<>();\n    od.find(m, 0, c, mr, mc, dishes);\n    od.print();\n  }\n}\n```\n\n\nThis problem is of type 'Minimum Set Cover'. Since it is a NP-Complete problem, it can't be solved in polynomial time. As per the solution it can be solved in polynomial time?\n\nPlease let me know what is the time complexity of this solution? O(n^4)?. Thanks.\n    ", "Answer": "", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Easy way to determine whether a given graph is subgraph of some other graph?\r\n                \r\nI'm looking for an algorithm to check whether a given graph is subgraph of another given graph.\n\nI have few conditions to make this NP complete problem bit more feasible..\n\n\nThe graphs have approx <20 vertices.\nThe graphs are DAG.\nAll vertices are non-uniquely labeled, and the corresponding vertices in the main graph and the subgraph should have same label. I don't know if I'm using the correct terminologies (because I haven't taken a graph theory course...). It will be something like:\n\n\nThe line graph A--B is subgraph of A--B--A but A--A is not a subgraph of A--B--A.\n\nAny suggestions are fine. This is not a homework question btw. :D\n    ", "Answer": "\r\nIf the labels are unique, for a graph of size ```\nN```\n, there are ```\nO(N^2)```\n edges, assuming there are no self loops or multiple edges between each pair of vertices.  Let's use ```\nE```\n for the number of edges.\n\nIf you hash the set edges in the parent graph, you can go through the subgraph's edges, checking if each one is in the hash table (and in the correct amount, if desired).  You're doing this once for each edge, therefore, ```\nO(E)```\n.\n\nLet's call the graph ```\nG```\n (with ```\nN```\n vertices) and the possible subgraph ```\nG_1```\n (with ```\nM```\n vertices), and you want to find ```\nG_1 is in G```\n.\n\nSince the labels are not unique, you can, with Dynamic Programming, build the subproblems as such instead - instead of having ```\nO(2^N)```\n subproblems, one for each subgraph, you have ```\nO(M 2^N)```\n subproblems - one for each vertex in ```\nG_1```\n (with ```\nM```\n vertices) with each of the possible subgraphs.\n\n```\nG_1 is in G = isSubgraph( 0, empty bitmask)```\n\n\nand the states are set up as such:\n\n```\nisSubgraph( index, bitmask ) =\n   for all vertex in G\n       if G[vertex] is not used (check bitmask)\n          and G[vertex]'s label is equal to G_1[index]'s label\n          and isSubgraph( index + 1, (add vertex to bitmask) )\n               return true\n   return false\n```\n\n\nwith the base case being ```\nindex = M```\n, and you can check for the edges equality, given the bitmask (and an implicit label-mapping).  Alternatively, you can also do the checking within the if statement - just check that given current ```\nindex```\n, the current subgraph ```\nG_1[0..index]```\n is equal to ```\nG[bitmask]```\n (with the same implicit label mapping) before recursing.\n\nFor ```\nN = 20```\n, this should be fast enough.\n\n(add your memo, or you can rewrite this using bottoms up DP).\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to find the size of maximal clique or clique number?\r\n                \r\nGiven an undirected graph G = G(V, E), how can I find the size of the largest clique in it in polynomial time? Knowing the number of edges, I could put an upper limit on the maximal clique size with\n\nhttps://cs.stackexchange.com/questions/11360/size-of-maximum-clique-given-a-fixed-amount-of-edges\n\n, and then I could iterate downwards from that upper limit to 1. Since this upper cap is O(sqrt(|E|)), I think I can check for the maximal clique size in O(sqrt(|E|) * sqrt(|E|) * sqrt(|E|)) time. \n\nIs there a more efficient way to solve this NP-complete problem?\n    ", "Answer": "\r\nFinding the largest clique in a graph is the clique number of the graph and is also known as the maximum clique problem (MCP). This is one of the most deeply studied problems in the graph domain and is known to be NP-Hard so no polynomial time algorithm is expected to be found to solve it in the general case (there are particular graph configurations which do have polynomial time algorithms). Maximum clique is even hard to approximate (i.e. find a number close to the clique number).\n\nIf you are interested in exact MCP algorithms there have been a number of important improvements in the past decade, which have increased performance in around two orders of magnitude. The current leading family of algorithms are branch and bound and use approximate coloring to compute bounds. I name the most important ones and the improvement:\n\n\nBranching on color (MCQ)\nStatic initial ordering in every subproblem (MCS and BBMC)\nRecoloring: MCS\nUse of bit strings to encode the graph and the main operations (BBMC)\nReduction to maximum satisfiability to improve bounds (MaxSAT)\nSelective coloring (BBMCL)\n\n\nand others.\nIt is actually a very active line of research in the scientific community.\nThe top algorithms are currently BBMC, MCS and I would say MaxSAT. Of these probably BBMC and its variants (which use a bit string encoding) are the current leading general purpose solvers. The library of bitstrings used for BBMC is publicly available. \n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "How to remove duplicates elements in nested list in c++\r\n                \r\nI'm trying to solve one np-complete problem in C++. I can solve this problem in Python but running time is relatively slow, so that's why I switch to C++. In one part of the problem I need to clean duplicate elements from my list.\nI have a list the type is list<list<int> > in c++. My list contains duplicate elements for example:\nIf I send list below as an input:\n```\n[ [1,2,3] , [2,3,4] , [2,3,4] , [4,5,6] ]\n```\n\nI should get ```\n[ [1,2,3] , [2,3,4] , [4,5,6] ]```\n as a result from the method.\nSo, how can I make my nested list contains only unique elements? Are there any efficient way or built-int function in c++ instead of using nested loop?\n    ", "Answer": "\r\n```\nstd::unique```\n works just fine: (where ```\ninput```\n is your nested list)\n```\nauto it = std::unique(begin(input), end(input));\ninput.erase(it, end(input));\n```\n\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
{"Question": "Is this NP-Complete? If so, knapsack, MIS, set-filling or scheduling?\r\n                \r\nI've got a \"gut-feeling\" that the problem I'm facing in my application is NP-complete, but I'm after help classifying it.\n\nThe problem\n\n\nWe have a bag with n heterogeneous slots \nWe can either put an item (with an associated value) in each slot, or leave it empty. A slot may contain at most one item.\nSince the slots are heterogeneous, an item for slot #2 cannot go in slot #3 \nWe have a finite set of slot-filling actions\nEach action may be invoked at most once\nInvoking a given action will fill some (1-n) of the slots with a fixed value (specific to the action), but only if all requested slots are available (otherwise the action cannot be invoked) i.e. all requested slots or none.\n\n\nHow do we determine the set of actions to invoke to maximise the total value in the bag?\n\nAn example:\n\n\nWe have 5 slots, numbered #1-#5\nWe have three actions, A1, A2 and A3\nA1 wants to put value $30 in slots #1 through #5\nA2 wants to put $50 in slots #1 & #2\nA3 wants to put $50 in slots #4 & #5\n\n\nThe optimal solution for this example is to invoke actions A2 & A3 (for a total value of $200, leaving slot #3 empty) - rather than invoking A1 (which would fill all slots, but only give a total of $150).\n\nFollow-up question - how should I brute-force this?\n\nSome thoughts:\n\n\nWe will want to prune off any action A[y] which covers the exact same slots as another action A[x] if the slot value ($) associated with A[y] is less than or equal to that of A[x].\nOther than that, I think evaluating the solution space boils down to iterating through the powerset of all remaining actions\nOf the sets {S1, S2...} in the powerset of all actions, if S2 is a subset of S1 AND all the actions applied successfully for S1 then we can disregard S2 (and all it's subsets!) without evaluating them, since they can never give a better result. In other words, if we can find a set that applies successfully early on, we can disregard all the subsets of it (significantly reducing what we have to test)\n\n\nInterested to hear of any other optimisations you can think of.\n    ", "Answer": "\r\nNP-completeness is about decision problems, and yours is an optimization problem. If we change it to feasibility (\"does a solution ≥ m exist?\") then we can trivially reduce set packing to your problem, and your problem to 0-1 integer linear programming, both of which are known to be NP-complete. Congratulations, you're NP-complete!\n\nI'm not sure which NPO-complete class your problem falls into, though.\n    ", "Knowledge_point": "NP-Complete Problems", "Tag": "算法分析"}
