{"Question": "Duality approaches in functional programming\r\n                \r\nI'd like to know what kind of real life problems can be tackled by \"duality methods\" in functional programming. More precisely, I'd like to know whether someone did actually use a duality method like the ones I present below, or whether there are other interesting examples. I'd be particularly interested in existing implementations, probably in Haskell.\n\n[Since the majority of people which will be interested in this question likely know Haskell, let me please add the Haskell tag, even if the question is quite language independent]\n\nLet me explain what I mean by duality (by lack of a better name) through a few examples. The first one is the real numbers. Assume the existence of a ```\nInteger```\n and a ```\nRational```\n type, and define a real number as a function (pardon my Haskell, I'm no hardcore haskeller)\n\n```\ntype Real = Integer -> Rational\n```\n\n\nsuch that whenever ```\nx :: Real```\n denotes the real number x, ```\nx n```\n yields a rational number which is within ```\n2^(-n)```\n of x.\n\nNow one can do\n\n```\n(+) :: Real -> Real -> Real\n(+) x y n = (x $ n + 1) + (y $ n + 1)\n```\n\n\nor likewise for other arithmetic operations. Given a continuous real function f, one can also compute ```\nf x```\n as soon as one can compute a modulus of continuity for ```\nf```\n.\n\nThis has the advantage that one can write natural looking code, and at the end, get a result at the desired level of precision automatically. However, it is no longer possible to compare real numbers for equality. The only kind of comparison possible between ```\nx```\n and ```\ny```\n  is ```\nx < y + eps```\n.\n\nAnother example of duality is this question on probability measures, which triggered the present question in my head. Let us write\n\n```\ntype Measure a = (a -> Double) -> Double\n```\n\n\nand define measures as integration procedures against functions. In the linked question, I show how natural it is in this framework to express concepts like convolution or pushforward which are much more difficult (computationally, but also theoretically) to define at the level of probability densities.\n\nIt allows one to compose building blocks from probability theory, and in principle allows one to build complex Monte Carlo procedures, and even allows one to work with explicit probability densities (at the expense of numerical integration). I'd be especially interested in any attempt at a real world library on this topic.\n\nAnother example that I have in mind, but did not quite formalize yet is the notion of vector fields (from differential geometry), that one can express as differentiation operators. For this, one needs a suitable type of \"smooth real valued functions\", and then a vector field is like this:\n\n```\ntype VectorField = SmoothFunction -> SmoothFunction\n```\n\n\nsuch that ```\nv (f * g) = f * (v g) + g * (v f)```\n.\n\nOf course, describing a sheaf of regular functions in say Haskell should not be easy. But by doing that, we could express all the stuff from differential geometry in a totally coordinate independant way, and plug coordinates at the very end.\n\nThere are other examples, eg. Taylor series have been discussed in Sigfpe's blog (I can't find this particular post though), where an analytic function is the following type:\n\n```\ntype AnalyticFunction = Double -> Integer -> [Double]\n```\n\n\nand where ```\nf x n```\n returns the ```\nn```\n first partial sums of the Taylor expansion of ```\nf```\n around ```\nx```\n. This allows us to seamlessly write all kind of arithmetic on analytic functions, including stuff like ```\nf / g```\n where ```\nf```\n and ```\ng```\n both can vanish at a point (along with some of their derivatives), or even ```\nf^(-1)```\n (provided ```\nf'```\n does not vanish). At the end, only the necessary terms of the intermediate series are computed to yield the value of a given expression.\n    ", "Answer": "\r\nThe common feature of your example is the representation of some (mathematical) object by functions. This is common in functional languages, but not as practical as in mathematics because functions in programs are used extensionally (you cannot inspect their definitions, only observe their actions on arguments), and only with computable operations (you can only observe a finite number of arguments).\n\nIn mathematics, you don't bother with such stuff, for example you very often say \"if f is analytic, then let's (a_n) be its sequence of coefficients, and...\". In a computer language, if you start with a function of type ```\nDouble -> Integer -> [Double]```\n, it will be painful to convert it to a representation where you can easily recover the coefficients. In programming languages, function really are black boxes.\n\nFor this reason, programmers often try to use explicit data representations instead of function black boxes. You can easily obtain a function from a data representation (its a kind of evaluation or interpretation), while the other way around can be more difficult, less efficient, etc. See Conal Elliott's “Everything is a function” in Haskell?.\n\nFunctions are however still used in cases where we really want extensional objects, that can only be observed instead of inspected. For each possible observation on the object you want to define, you give a function that realize this observation. In your example, you only have one function because you only have one observation. This is the core idea of Object Oriented Programming as defined by William Cook in his On Understanding Data Abstraction, Revisited paper.\n\nI think the reason why you relate this to the term \"duality\" (a term that is, in the Haskell intelligentsia, rather related to category-theoretic concepts) is that the shift from an object to some particular form of observation of it is sometimes called duality in maths, and has the effect of adding functions everywhere. For example, there is the classical example of the dual of a vector space, and in particular the bidual construction which is really a conversion from a vector to its observations by linear functions : you switch from ```\nV```\n to ```\n(V -> K) -> K```\n, for ```\nK```\n the field underlying your vector space.\n\n(Would one think of continuations reading my last example ? Of course those are related, as this representation of continuations is really an \"observation\" of concrete evaluation contexts, represented by their action on values.)\n\nYour representation of probability measures is actually used to define probability measure monads in functional languages. There are different ways to define probability monads. See for example http://www.cs.tufts.edu/~nr/pubs/pmonad-abstract.html by Norman Ramsey and Avi Pfeffer. Most real-world implementation of probability DSL however use a more concrete representation such as a ```\n[(prob,event)]```\n list of pair (Haskell probability library and OCaml HANSEI).\n\nFinally, for an example of representation of real number as functions, see Russel O'Connor's A Monadic, Functional Implementation of Real Numbers. Numerous representation of \"computable\" numbers exist and have different merits, and most of them are based on sequences and may therefore be represented as ```\nInteger -> ...```\n functions.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Principle of duality\r\n                \r\nThe following is given in my textbook-\n\nWhen we start with a boolean relation, another boolean relation can be derived by:\n\nchanging OR to AND\nchanging AND to OR\nreplacing 0 to 1 and 1 to 0\n\nThis derived expression is known as the dual of the initial expression.\n\nSo dual of  1 AND 0 is 0 OR 1. Isn't?\nWhat about the dual of X OR X' ? Is it X' AND X?  (Note that ' stands for complement.)\nPS -\n\nOne change we did not need to make as part of this interchange was to\ncomplement. We say that complement is a self-dual operation. The\nidentity or do-nothing operation x (copy the input to the output) is\nalso self-dual.\n\nWhat does the above line mean?\nSource : Duality principle in wikipedia\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Rigorous Formalization of the Data/Computation Duality?\r\n                \r\nIt seems to be a matter of computer science lore that data and computation (or data and process, whatever you want to call it) are in some vague sense duals of each other: data is generated by computation but also guides future computation, and so the two are, vaguely, two sides of the same coin. This duality is more apparent in programming languages like Lisp which purposefully blur the line between the two.\n\nI'm wondering whether this notion of duality has been studied in complexity theory in a rigorous setting. For instance, are there any computational models in which this duality arises naturally out of some deeper duality intrinsic to the model? For instance--and this is wishful thinking bordering on the nonsensical--if, say, we equated data with the states of a DFA and process with the DFA's transition function, and then the graph-dual of the DFA would yield another DFA related to the original in some meaningful way, then the data/computation duality would emerge naturally from the underlying model.\n\nThat sort of thing. Any pointers to research in the area (or even just keywords) are appreciated.\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Find the longest string duality\r\n                \r\n```\nT1```\n:\nFind the length of longest substring T that contains at most k distinct characters.\n\n```\nT2```\n: \nFind the length of shortest substring T contains at least k distinct characters. \n\nIs ```\nT1```\n a strong or weak duality of ```\nT2```\n? Essentially, are ```\nT1```\n and ```\nT2```\n asking the same thing?\n    ", "Answer": "\r\nI would answer both questions with a no. Consider the example string:\n\n```\n\"This is an example. Don't ask me about the example string.\"\n```\n\n\nFor k=15 gives ```\n\"'t ask me about the example st\"```\n for T1 and ```\n\"xample. Don't ask\"```\n for T2.\n\nThese were computed using the following Python program:\n\n```\n1 'T' 'T'\n2 't t' 'Th'\n3 'is is ' 'Thi'\n4 'his is ' 'This'\n5 'is is an ' 'This '\n6 'his is an ' 'n exam'\n7 'is is an exa' 'n examp'\n8 'his is an exa' 'n exampl'\n9 ' me about the e' 'xample. D'\n10 ' me about the exam' 'xample. Do'\n11 't ask me about the e' 'xample. Don'\n12 't ask me about the exam' \"xample. Don'\"\n13 \"'t ask me about the exam\" \"xample. Don't\"\n14 't ask me about the example st' 'xample string.'\n15 \"'t ask me about the example st\" \"xample. Don't ask\"\n16 \"is is an example. Don't ask me a\" \"ple. Don't ask me abou\"\n17 \"is is an example. Don't ask me abo\" 'bout the example string'\n18 \"s an example. Don't ask me about the example st\" 'bout the example string.'\n19 \"his is an example. Don't ask me about the example st\" 'k me about the example string.'\nx = \"This is an example. Don't ask me about the example string.\"\n\ndef factors(s):\n    return [s[i:j] for i in range(len(s)+1) for j in range(i, len(s)+1)]\n\nfor k in range(20):\n    t1 = max([f for f in factors(x) if len(set(f)) <= k], key=len)\n    t2 = min([f for f in factors(x) if len(set(f)) >= k], key=len)\n\n    print k, repr(t1), repr(t2)\n```\n\n\nWhich prints:\n\n```\n0 '' ''\n1 'T' 'T'\n2 't t' 'Th'\n3 'is is ' 'Thi'\n4 'his is ' 'This'\n5 'is is an ' 'This '\n6 'his is an ' 'n exam'\n7 'is is an exa' 'n examp'\n8 'his is an exa' 'n exampl'\n9 ' me about the e' 'xample. D'\n10 ' me about the exam' 'xample. Do'\n11 't ask me about the e' 'xample. Don'\n12 't ask me about the exam' \"xample. Don'\"\n13 \"'t ask me about the exam\" \"xample. Don't\"\n14 't ask me about the example st' 'xample string.'\n15 \"'t ask me about the example st\" \"xample. Don't ask\"\n16 \"is is an example. Don't ask me a\" \"ple. Don't ask me abou\"\n17 \"is is an example. Don't ask me abo\" 'bout the example string'\n18 \"s an example. Don't ask me about the example st\" 'bout the example string.'\n19 \"his is an example. Don't ask me about the example st\" 'k me about the example string.'\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Related to Principle of Duality (Boolean Algebra)\r\n                \r\nWhen we write:\n\nA(B+C) = AB + AC \n\ndoesn't the principle of duality tells us that all 0s and 1s should be complement of each other and the dot and + operator is interchanged?\n\nThen: won't \n\nA' + (B'C') = (A'+B') (A'+C') \n\nbe the correct way of writing its duality? \nMy textbook writes the same instead without the complement signs. Why is it so?\n\nEDIT:\nIt could be that A and B were referring to general binary variables.However, judging by the way that they said 0 . 0 = 0 has its dual as 1+1=1. \n    ", "Answer": "\r\nBecause every single term is complemented, it’s equivalent (up to isomorphism) to the expression where none of the terms is complemented. They’ve all flipped identically relative to each other, so the truth table doesn’t change for that expression.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Applying the dual/duality principle to Boolean expressions\r\n                \r\nFirst off, my textbook says the Dual Principle is switching ORs with ANDs and ANDs with ORs, but leaving the variables themselves in their complemented or uncomplemented form. This differs from what I've read online about the Duality Principle, which states that you must interchange the ORs and ANDs as well as complement each individual variable. Regardless, these are just two different definitions. My question lies in how to apply the Dual and/or Duality Principle to the following situation:\n\n```\n(xy)'\n```\n\n\nWould the dual (according to the Duality Principle) be \n\n```\n(x' + y')'? \n```\n\n\nIn other words, does the outside NOT stay there? Or, are all NOTs themselves, even if they are \"outer NOTs\" complemented? This would lead to: \n\n```\n(x' + y'). \n```\n\n\nI'm pretty sure it is the latter.\n    ", "Answer": "\r\nIt is like this:\n\n```\n (x' + y')' = (x')'(y')' = xy \n```\n\n\nThe rules applied here are:\n\n```\n (x + y)' = x'y', and\n (x')' = x\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Duality to find Maximum number of collinear points in given plane\r\n                \r\nGiven set of N points on a 2-D plane, find maximum number of collinear points from this set.\n                                                                          Is there a O(n*2) solution for this using Duality algorithm ? Can someone explain if it is possible to use Duality here.\n    ", "Answer": "\r\nI don't think you need to use duality for this.  Map each pair of points to a line equation in some canonical form.  Find the line equation that shows up most often using an appropriate hash table.\n\n(If you insist on using duality, note that three collinear points correspond to a point being hit by three lines in the dual to your point set.  This doesn't actually give you a speedup, though.)\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Details of duality of Streams and Tables in Kafka Streams\r\n                \r\nThe confluent document here states\n\nAnd Kafka exploits this duality in many ways: for example, to make your applications elastic, to support fault-tolerant stateful processing, or to run Kafka Streams Interactive Queries against your application’s latest processing results.\n\nWonder if there are more details for how is the duality of streams/tables used in these scenarios. Looking for some simple explanation rather than some long design docs\n    ", "Answer": "\r\nA stream can be considered as log and table can be a snapshot of logs at a given instant of time.\nA stream is a flow of data, new data can keep on coming and we process it as it comes, store the processed results in a table for querying.\nA table's data, changes over time. At any given instant of time, we get a snapshot of that data at that instant. A table, therefore, can be used for performing queries and retreiving results on demand, which is not the case with 'just' streams\n\nFor example,\nUser comments on a video can be a stream of events, new comments keep on coming and they simply get displayed on the UI. Nothing to query here (typically).\nBut there also some other use cases, like..\nCricket updates: For every new ball, we get no. of runs for that ball, now we need to add them to the score. We certainly, need to store the previous score and update it with every new ball. We also need to query the score at any given instant of time (on demand). For performing queries or updating the score, we can use a table.\n\nIn the Kafka context, event is a log message and every message is immutable.\nConsider an example, of an user information getting updated.\n```\n{user_id: 101, name: X}\n{user_id: 101, name: Y}\n```\n\nThe ```\nname```\n of the ```\nuser_id=101```\n is updated from ```\nX```\n to ```\nY```\n. When you perform the update on a database directly and do a query, you see only ```\nname: Y```\n, you may not have the previous name of the user with you, because it is overridden with the new value.\nIn Kafka, we have two messages, ```\n'X'```\n and ```\n'Y'```\n.\nAt times, this may be useful and even critical. A hacker could have changed all the user information, and the legit user has no way of proving his identity to re-claim his account. But if there is previous info about his account which he can tell as a proof, he can re-claim it.\nSo for those who use Kafka, there could be use-cases to store data as a table (or) a map and then retrieve it using queries.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Meaning of strong duality between max flow and min cut\r\n                \r\nMy question is about the max-flow and min-cut algorithm. I would like to know why there is strong duality between a max flow and a min cut?\n    ", "Answer": "\r\nAs explained in this Wikipedia article, the Max-Flow problem and the Min-Cut problem can be formulated as dual linear programs. As both linear programs are feasible, the duality can be seen as a special case of the duality of linear programs.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Lisp Code-Data Duality, Lambda Expressions Are Constants?\r\n                \r\nI'm following Paul Graham's book On Lisp, where Section 5.7 says \"A sharp-quoted lambda-expression is a constant, but a call to a constructor function will be evaluated at run time.\"\nThis reminds me of Lisp's general principle of code-data duality.\nCan someone please help explain how a function is a constant when represented in computer memory? Sure it's just a set of instructions, but the functions still take inputs, so doesn't that mean the actual execution during run-time isn't constant?\n    ", "Answer": "\r\nWhat is meant is that a function is a constant object which cannot be modified. Like a shovel: you cannot change the shovel, but you can dig many different ditches with it. Similarly, you cannot change the function, but you can apply it to different arguments and get different values.\nIncidentally, this is not necessarily always the case for all implementations.\nE.g., in CLISP:\n```\n(defun f(x) (+ x 10))\n(compile 'f)\n(f 5)\n==> 15\n(disassemble #'f)\n\nDisassembly of function F\n(CONST 0) = 10\n1 required argument\n0 optional arguments\nNo rest parameter\nNo keyword parameters\n4 byte-code instructions:\n0     (CONST&PUSH 0)                      ; 10\n1     (LOAD&PUSH 2)\n2     (CALLSR 2 55)                       ; +\n5     (SKIP&RET 2)\n```\n\nPretty straightforward, huh?\nnow, if you use internal functionality of CLISP to modify its vector of constants and replace ```\n10```\n with something else, you will change the function's behavior:\n```\n(setf (sys::closure-const #'f 0) 42)\n(f 7)\n==> 49\n```\n\nThis is similar to running a C program under a debugger and modifying local variables.\nSee also Why does an elisp local variable keep its value in this case? and Why does this function return a different value every time?\nPS. Please note that doing this may lead to hard crashes (segfaults). Beware.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Strong Duality constraint using Pyomo library in Python\r\n                \r\nI am implementing an Inverse Optimization Problem which instead of using KKT conditions applies the strong duality theorem (primal optimal objective and the dual optimal objective are equal). For this purpose, it is required to formulate the primal and the dual problem. I have 4 generators with 8 energy blocks (b) each and a fixed demand. This is a market clearing per hour. \nThe primal problem is an easy Market Clearing and it is as follows using the library ```\nPyomo```\n:\n\n```\nmodel = ConcreteModel()\nmodel.g1=Var(b, within=NonNegativeReals)\nmodel.g2=Var(b, within=NonNegativeReals)\nmodel.g3=Var(b, within=NonNegativeReals)\nmodel.g4=Var(b, within=NonNegativeReals)\n\nmodel.obj = Objective(expr=\n                      (sum(g1price[i]*model.g1[i] for i in b)+\n                       sum(g2price[i]*model.g2[i] for i in b)+\n                       sum(g3price[i]*model.g3[i] for i in b)+\n                       sum(g4price[i]*model.g4[i] for i in b)))\nmodel.con_power_balance=Constraint(\n                      expr=\n                      (sum(model.g1[i] for i in b)+\n                       sum(model.g2[i] for i in b)+\n                       sum(model.g3[i] for i in b)+\n                       sum(model.g4[i] for i in b)- demand) == 0)\n\n\nmodel.con_g1max=ConstraintList()\nfor i in b:\n    model.con_g1max.add(model.g1[i] <= gsize[i])\nmodel.con_g2max=ConstraintList()\nfor i in b:\n    model.con_g2max.add(model.g2[i] <= gsize[i])\nmodel.con_g3max=ConstraintList()\nfor i in b:\n    model.con_g3max.add(model.g3[i]< = gsize[i])\nmodel.con_g4max=ConstraintList()\nfor i in b:\n    model.con_g4max.add(model.g4[i] <= gsize[i])\n```\n\n\nLet's say that the previous equations are named (1a-1f). When no stated, is set as default to minimize the objective function. As the primal problem is a minimization problem, its dual must be a maximization one. But it is equivalent max[F(x)] == min[-F(x)], and it is what I have applied. Here is the dual problem (equations 2a-2e): \n\n```\nmodel = ConcreteModel()\nmodel.mu_g1max=Var(b, within=NonNegativeReals)\nmodel.mu_g2max=Var(b, within=NonNegativeReals)\nmodel.mu_g3max=Var(b, within=NonNegativeReals)\nmodel.mu_g4max=Var(b, within=NonNegativeReals)\nmodel.mu_g1min=Var(b, within=NonNegativeReals)\nmodel.mu_g2min=Var(b, within=NonNegativeReals)\nmodel.mu_g3min=Var(b, within=NonNegativeReals)\nmodel.mu_g4min=Var(b, within=NonNegativeReals)\nmodel.lambda=Var(b, within=NonNegativeReals)\n\nmodel.obj = Objective(expr=\n                      (sum(gsize[i]*model.mu_g1max[i] for i in b)+\n                       sum(gsize[i]*model.mu_g2max[i] for i in b)+\n                       sum(gsize[i]*model.mu_g3max[i] for i in b)+\n                       sum(gsize[i]*model.mu_g4max[i] for i in b))\n\nmodel.con_g1_dual=ConstraintList()\nfor i in b:\n    model.con_g1_dual.add(model.lambda[i]+model.mu_g1min[i]-model.mu_g1max <= gsize[i])\nmodel.con_g2_dual=ConstraintList()\nfor i in b:\n    model.con_g2_dual.add(model.lambda[i]+model.mu_g2min[i]-model.mu_g2max <= gsize[i])\nmodel.con_g3_dual=ConstraintList()\nfor i in b:\n    model.con_g3_dual.add(model.lambda[i]+model.mu_g3min[i]-model.mu_g3max <= gsize[i])\nmodel.con_g4_dual=ConstraintList()\nfor i in b:\n    model.con_g4_dual.add(model.lambda[i]+model.mu_g4min[i]-model.mu_g4max <= gsize[i])\n```\n\n\nOnce the primal and the dual problem are presented, the real problem that I have to solve is the following one: \n\n```\nmodel = ConcreteModel()\nmodel.lambda=Var(b, within=NonNegativeReals)\nmodel.obj = Objective(expr=\n                      np.absolute(sum(model.lambda[i]-lambda_ini[i] for i in b*4)))\n```\n\n\nHere I have to put as constraints the ones from the dual problem (2b-2e) written before and moreover apply the strong duality constraint which would be:\n\nmin (objective function primal problem) = max (objective function dual problem)\n\nHere is my problem: How would be this last constraint written??\n    ", "Answer": "\r\nWell, I did not really understand your question, and I cannot comment yet, so I am posting an answer, hoping that it would help you.\n\nFirst of all in pyomo, like @Qi Chen mentioned, you can access the dual values which generated by solver itself. For that you need to add following in your model:\n\n```\nmodel.dual = Suffix(direction=Suffix.IMPORT)\n```\n\n\nThen you may call the instance of your model elsewhere, and you can get the dual values of the constraints, which are inside your model via:\n\n```\ndual_value = inst.dual[inst.constraint_name]\n```\n\n\ne.g.:\n\n```\ndual_con_g1max = inst.dual[inst.con_g1max]\n```\n\n\nbut, ofc since ```\ncon_g1max```\n is a ```\nConstraint_List```\n, you need to give its index to the dual getting algo. like:\n\n```\ninst.dual[inst.con_g1max[1]]\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Integer and int duality?\r\n                \r\nCan someone explain me this \n\n```\n List<Integer> list = new LinkedList<Integer>();\n list.add(2);\n list.add(1);\n list.add(3);\n```\n\n\nwhen I used\n\n```\n list.remove(1);\n```\n\n\nthen 1st element got removed\n\n```\n list.remove(new Integer(\"1\"));\n```\n\n\nthen 2nd element got removed.\n\nso, can you explain behavior of auto boxing and unboxing in above senario\n\nwhen ```\nnew A().a(new Integer(\"1\"));```\n\n\nexecuted on, \n\n```\npublic class A {\n    public void test(Integer i) {} //1\n    public void test(int i) {} //2\n    public void test(Object o) {}//3\n} \n```\n\n\nmethod 1 go executed\n\n```\npublic class A {\n    public void test(int i) {} //2\n    public void test(Object o) {}//3\n} \n```\n\n\nmethod 3 got executed\n    ", "Answer": "\r\nBasically overload resolution will prefer an ```\nObject```\n parameter over an ```\nint```\n parameter when presented with an ```\nInteger```\n argument. (It will prefer an overload with an ```\nint```\n parameter over ```\nObject```\n or ```\nInteger```\n when presented with an ```\nint```\n argument, of course.)\n\nFrom JLS section 15.12.2 (with discussion snipped):\n\nThe process of determining applicability begins by determining the potentially applicable methods (§15.12.2.1). The remainder of the process is split into three phases.\n\nDiscussion\n\nThe purpose of the division into phases is to ensure compatibility with older versions of the Java programming language.\n\n\n  The first phase (§15.12.2.2) performs overload resolution without permitting boxing or unboxing conversion, or the use of variable arity method invocation. If no applicable method is found during this phase then processing continues to the second phase.\n  \n  The second phase (§15.12.2.3) performs overload resolution while allowing boxing and unboxing, but still precludes the use of variable arity method invocation. If no applicable method is found during this phase then processing continues to the third phase.\n  \n  The third phase (§15.12.2.4) allows overloading to be combined with variable arity methods, boxing and unboxing.\n\n\nAs ```\nInteger```\n is implicitly convertible to ```\nObject```\n, overload resolution succeeds in the first phase, so never gets as far as considering an unboxing conversion.\n\nIf that doesn't explain everything to your satisfaction, please comment on which bit remains puzzling for you.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "C Duality Expression\r\n                \r\nI have created a program in C which takes values of a,b and c from keyboard and show the \"+value\" and \"-value\" . But after when I give inputs it shows outputs such like \"-1.#IND0\" . Why this happens ? There are no compile errors...\n\nHeres my code :\n\n```\n#include<stdio.h>\n#include<math.h>\nint main(void)\n{\nint a,b,c;\ndouble x1,x2;\nprintf(\"Enter a \");\nscanf(\"%d\",&a);\n\nprintf(\"Enter b \");\nscanf(\"%d\",&b);\n\nprintf(\"Enter c \");\nscanf(\"%d\",&c);\n\nx1 = ( (-1 * b) + sqrt(pow(b,2) - (4 * a * c)) ) /  2 * (float)a ;\nx2 = ( (-1 * b) - sqrt(pow(b,2) - (4 * a * c)) ) /  2 * (float)a ;\n\nprintf(\"Plus Value %.5f\\n\",x1);\nprintf(\"Minus Value %.5f\\n\",x2);\n}\n```\n\n    ", "Answer": "\r\nYou need to check if ```\npow(b,2) - (4 * a * c)```\n is non-negative, otherwise you can't take the square root. \n\nAlso check ```\na```\n is not 0, since you are dividing by it. \n\nSanity checks are important to avoid unexpected behavior. Hope this helps!\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Duality of max-flow and min-cut: when infinite capacity exists\r\n                \r\nI am wondering if the celebrated duality between max-flow and min-cut actually tolerates infinite valued capacities.  Here is a simple example where it seems not:\n\nsource s, sink t, five other nodes a, b, c, d, e\n\ns -> a: capacity 3\n\ns -> b: 3\n\na -> c: \\infty\n\na -> d: \\infty\n\nb -> d: \\infty\n\nb -> e: \\infty\n\nc -> t: 1\n\nd -> t: 1\n\ne -> t: 4\n\nThe max flow is 5.  However, there is no cut whose capacity is 5.  This is because the infinite capacities force all a, b, c, d, e to belong to the same set/half of a cut (otherwise there would be an \\infty weight in the cut-set).\n    ", "Answer": "\r\noh, I forgot that when the graph is directed, for an edge (u, v) to be counted into the cut weight, not only should u and v belong to different halves of the cut, but also u should be in the same half as the source s, and v in the same half as the sink t.\n\nSo now there is a trivial cut with capacity 5:\nS = {s, a, c, d}\nT = {b, e, t}\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "r wordcloud external ttf vfont not recognized\r\n                \r\nI've installed the 'extrafont' package in order to install an external font library Duality via the ttf_import() method. However, when specifying the font via the wordcloud method, I receive the following error:\n\nInstallation command:\n\n```\n# Assuming the font file, DUALITY_.ttf, is in the working directory (see link to font above)\nfont_import(\".\",FALSE,pattern=\"DUALITY\")\n```\n\n\nWordcloud command:\n\n```\nwordcloud(ap.d$word, ap.d$freq, scale=c(8,2), min.freq=10, vfont=c(\"Duality\",\"plain\"),\n      random.order=FALSE, rot.per=0, use.r.layout=FALSE, colors=pal2, fixed.asp=FALSE)\n```\n\n\nOutput:\n\n```\nError in strwidth(words[i], cex = size[i], ...) : \n  invalid 'vfont' value [typeface -2147483648]\n```\n\n\nIn order to verify that the font is indeed installed, I issued the following commands\n\n```\n> choose_font(\"Duality\")\n[1] \"Duality\"\n> fonts()\n....[49] \"Waree\"                    \"Duality\"    \n```\n\n\nHow come the Duality font is not visible to the vfont parameter of wordcloud? And how do I make it visible to Cairo (the default renderer). TIA!\n    ", "Answer": "\r\nI've been able to overcome the same problem using the parameters passed to text ```\nfamily```\n and ```\nfont```\n and described in ```\n?par```\n instead of ```\nvfont```\n. Also I needed to load the font first. So the thing goes:\n\nImport the font (sorry, the link to Duality provided in OP is no longer available, I use Lucida Handwriting instead, available in windows):\n\n```\nlibrary(extrafont)\nfont_import(pattern=\"LHANDW\")\n```\n\n\nLoad (see this blog for details):\n\n```\nloadfonts() # loadfonts(device = \"win\") if you are working in windows\n```\n\n\nWordcloud:\n\n```\nwordcloud(ap.d$word, ap.d$freq, scale=c(8,2), min.freq=10, family=\"Lucida Handwriting\", font=1,\n  random.order=FALSE, rot.per=0, use.r.layout=FALSE, colors=pal2, fixed.asp=FALSE)\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Clarification Around \"Duality\" of Service Accounts\r\n                \r\nI have two Cloud Run services. ```\nService U```\n has Unauthenticated access open to all users. ```\nService R```\n I want the access Restricted so that only ```\nService A```\n can invoke it.\nThis gist has a pretty succinct implementation using the CLI. My services are configured with Terraform and I'm trying to translate, but also understand:\nBased on this I thought I could allow Service R access by Service U by adding U's service account (I added ```\nservice_account: service-u-sa@abcdefg.iam.gserviceaccount.com```\n to Service U's ```\ngoogle_cloud_run_service.spec.service_account_name```\n) in the same way I open up access to all users. Here is allUsers:\n```\nresource \"google_cloud_run_service\" \"service_r\" {\n  name                       = local.service_name\n  # ... rest of the service definition\n}\n\nresource \"google_cloud_run_service_iam_member\" \"run_all_users\" {\n  service  = google_cloud_run_service.service_r.name\n  location = google_cloud_run_service.service_r.location\n  role     = \"roles/run.invoker\"\n  member   = \"allUsers\"\n  depends_on = [\n    google_cloud_run_service.service_r,\n  ]\n}\n```\n\nAnd I amended it to be for just one service account with:\n```\nresource \"google_cloud_run_service_iam_member\" \"run_all_users\" {\n  service  = google_cloud_run_service.service_r.name\n  location = google_cloud_run_service.service_r.location\n  role     = \"roles/run.invoker\"\n  member = \"serviceAccount:service-u-sa@abcdefg.iam.gserviceaccount.com\n  depends_on = [\n    google_cloud_run_service.service_b,\n  ]\n}\n\n```\n\nThis does not seem to work.\nHowever, adding a data source that creates a policy does seem to work:\n```\n\ndata \"google_iam_policy\" \"access_policy\" {\n  binding {\n    role = \"roles/run.invoker\"\n    members = [\n      \"serviceAccount:service-u-sa@abcdefg.iam.gserviceaccount.com\",\n    ]\n  }\n}\n\nresource \"google_cloud_run_service_iam_policy\" \"cloud_run_policy\" {\n  location    = google_cloud_run_service.service_r.location\n  project     = google_cloud_run_service.service_r.project\n  service     = google_cloud_run_service.service_r.name\n\n  policy_data = data.google_iam_policy.access_policy.policy_data\n}\n```\n\nI've read on this SO answer (and elsewhere) that service accounts are identities as well as resources. Is that what is happening here? That is, rather than using the service account ```\nservice-b-sa@abcdefg.iam.gserviceaccount.com```\n as an identity, I am attaching it to Service R as a \"resource\"? Is that what a \"policy\" is in this context? And is there anywhere in the GCR UI where I can see these relationships?\n    ", "Answer": "\r\n                \r\nOk, I will try to clarify the wording and the situation, even if I didn't catch what changed between your 2 latest piece of code.\nDuality\nYes, Service Account have duality: they are identity AND resources. And because they are a resource, you can grant on identity on it (especially to perform impersonation).\nAccess Policy\nIt's simply a binding between an identity and a role. Then you have to apply that binding to a resource to grant the identity the role on the resource. This trio is an IAM authorization policy, or policy in short.\nService and Service Account\nYour question is hard to understand because you mix the Cloud Run service, and the service account.\nA Cloud Run service has an identity: the runtime service account.\nA Cloud Run service CAN'T have access to another Cloud Run service. But the identity of a Cloud Run service can access another Cloud Run service.\n\nThat being said, there is no difference between your 2 latest piece of code. In fact yes, there is a difference but the second definition is much more restrictive than the first one.\nIn the latest one, you use ```\n....._iam_policy```\n. It means you REPLACE all the policies. In other word, the \"access_policy\" override all the existing permissions.\nIn the case before, you use ```\n....._iam_member```\n. It means you simply add a policy to the current resource, without changing the existing ones.\nThat's why, the result is the same: ```\nservice-u```\n has the role Invoker on the service_r.\nCan you try again? the issue is somewhere else.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to find a nearest point to a given query line from a set of points in O(log n) time with out using duality concept?\r\n                \r\nAssume that we have been given a set S of n points and an arbitrary query line l. Do some preprocessing (other than duality) so that we can answer the nearest (closest) point (of S) to l in O(log n) time (no restriction on space).\n    ", "Answer": "\r\nYou say \"no restriction on space\", which implies no restriction on preprocessing time.\n\nConsider the sorted abscissas of the sites after rotation by an arbitrary angle: the site closest to a vertical line is found by dichotomy after ```\nLg(N)```\n comparisons.\n\nNow consider the continuous set of rotations: you can partition it in angle ranges such that the order of the sorted abscissas does not change.\n\nSo you will find all limiting angles by taking the sites in pairs, and store the angle value as well as the corresponding ordering of the rotated abscissas.\n\nFor a query, find the enclosing angle interval by a first binary search (among O(N²) angles), then the closest site by a search on the rotated abscissas (binary search among O(N) abscissas).\n\nDone the straightforward way, this will require O(N³) storage.\n\nGiven that the ordering permutations for two consecutive angles just differ by a single swap, it is not unthinkable that O(N²) storage can be achieved by a suitable data structure.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "SVM duality: set of hyperparameters not supported\r\n                \r\nI am trying to train a SVM model on the Iris dataset. The aim is to classify Iris virginica flowers from other types of flowers. Here is the code:\n\n```\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\n\niris = datasets.load_iris()\nX = iris[\"data\"][:, (2,3)] # petal length, petal width\ny = (iris[\"target\"]==2).astype(np.float64) # Iris virginica\n\nsvm_clf = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\", dual=False))\n])\n\nsvm_clf.fit(X,y)\n```\n\n\nMy book, which is Aurelien Geron's \"Hands-On Machine Learning with Scikit-Learn , Keras and TensorFlow\", 2nd edition, at page 156 says:\n\n\n  For better performance, you should set the ```\ndual```\n hyperparameter to\n  ```\nFalse```\n, unless there are more features than training instances\n\n\nBut If I set the ```\ndual```\n hyperparameter to False, I get the following error:\n\n```\nValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n```\n\n\nIt instead works if I set the ```\ndual```\n hyperparameter to True.\n\nWhy is this set of hyperparameters not supported?\n    ", "Answer": "\r\nL2 SVM with L1 loss (hinge) cannot be solving in the primal form. Only its dual form can be solved effectively. This is due to the limitation of the LIBLINEAR library used by sklearn. If you want to solve the primal form of the L2 SVM you will have to use L2 loss (squared hinge) instead. \n\n```\nLinearSVC(C=1, loss='squared_hinge', dual=False).fit(X,y)\n```\n\n\nFor mode details: Link 1\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Integer constant / callable duality of variable in R\r\n                \r\nI've come across this snippet of code in an R package:\n\n```\nif (msLevel != 2 || (msLevel == 2 & !any(msLevel(x) == 2))) {\n    ...\n}\n```\n\n\nHow can ```\nmsLevel```\n be both an integer constant equal to 2, and a function that can be applied to a variable ```\nx```\n? (Here ```\nmsLevel```\n is a function parameter with the default assignment ```\n2L```\n.)\n\n(Related question: should R be considered an esoteric programming language? )\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to call method from separate package : Android\r\n                \r\nI am trying to get a method from the file Duality.java to be run in Min.Java when a button is clicked. Below are the two files and what I am currently trying to do, which is not working. How do I get the method duality() to run when the button is clicked within Min.java?\n\nDuality.java\n\n```\npackage com.android.control;\n\nimport android.util.Log;\nimport com.map.AppName.R;\n\npublic class duality {\n\n    public void duality(){\n       Log.e(\"Did It Run\",\"Yes it ran\");\n    }\n}\n```\n\n\nMin.java\n\n```\npackage com.android.control;\n\nimport android.view.View;\nimport android.widget.Button;\nimport android.widget.LinearLayout;\n\nimport com.map.AppName.R;\n\npublic class Min extends LinearLayout {\n\n    Button but;\n    private final int ELEMENT_HEIGHT = 60;\n    private final int ELEMENT_WIDTH = 80;;\n    private final int TEXT_SIZE = 30; \n\n    public Min( Context context, AttributeSet attributeSet ) {\n        super(context, attributeSet);   \n\n        this.setLayoutParams( new LinearLayout.LayoutParams( LayoutParams.WRAP_CONTENT, LayoutParams.WRAP_CONTENT ) );\n        LayoutParams elementParams = new LinearLayout.LayoutParams( ELEMENT_WIDTH, ELEMENT_HEIGHT );\n\n        createBut( context );\n\n        addView( but, elementParams );\n    }\n\nprivate void createButton( Context context){\n        but = new Button( context );\n        but.setTextSize( TEXT_SIZE );\n        but.setText( \"Go\" );\n\n        but.setOnClickListener(new View.OnClickListener() {\n            public void onClick(View v) {\n\n                 Duality duality = new duality();\n\n            }\n        });\n}\n}\n```\n\n    ", "Answer": "\r\nYou're only constructing an instance of the ```\nduality```\n class - you're not calling the ```\nduality()```\n method on it.\n\nThis might be because you wanted that method to be a constructor - but it's not, because you specified a ```\nvoid```\n return type, so it's just a conventional method.\n\n(By the way, it's conventional in Java to give classes names that start with uppercase characters.  If you called your class ```\nDuality```\n, there may be less chance that you'd get the two confused; though the problem with accidental non-constructors would still stand.)\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Quantum duality: variable is null and undefined at the same time?\r\n                \r\nConsider following JavaScript code (tested in Firefox):\n\n```\nfunction f(a) {\n\n  if (a == undefined) {\n    alert('undefined');\n  }\n\n  if (a == null) {\n    alert('null');\n  }\n}\n\nf();\n```\n\n\nBoth alerts are shown, suggesting that both statements are true.\n\nCould you provide a reasonable explanation?\n    ", "Answer": "\r\n```\n==```\n is a \"soft\" equality operator.\nIt uses type coercion to compare two equivalent objects as equal.\n\nAll of the following are true:\n\n```\n42 == \"42\"\n0 == false\n0 == \"\"\n[] == \"\"\n{} == \"[object Object]\"\n'/(?:)/' == new RegExp\n```\n\n\nInstead, you should use the  ```\n===```\n operator, which checks for strict equality.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "duality of vector-numpy array operation between C++ and Python\r\n                \r\nI am relatively new to the binding between python and C++, so I am sorry if my pratique is not perfect or not good enough.\nI am trying to write an extension of a python code in C++. To bind the codes I use pybind11. In the meanwhile I want to use the vector structure from the std library, passing a ```\nnumpy```\n vector from the python side.\nMy piece of code in C++ is the following:\n```\ntemplate<typename OffsetT> void unique_nodes(\n                const std::vector<OffsetT> &PC, const std::vector<OffsetT> &PCO,\n                std::vector<OffsetT> &PointConnectivity_singular, std::vector<OffsetT> &PointConnectivity_singular_O){\n    OffsetT ivert = 0;\n    const auto nc = PCO.size()-1;\n    auto begin_PC = PC.begin();\n    auto end_PC = PC.end();\n    for (auto icell = 0; icell < nc; icell++) {\n        PointConnectivity_singular_O[icell]=ivert;\n        std::vector<OffsetT> Cell (begin_PC+PCO[icell],begin_PC+PCO[icell+1]);\n        auto size = RemoveDuplicatesKeepOrder(Cell);\n        for (auto &elem:Cell){\n                *(PointConnectivity_singular.begin()+ivert) = elem;\n                ivert++;\n        }\n    }\n    PointConnectivity_singular.shrink_to_fit();\n    PointConnectivity_singular_O[nc]=ivert;\n}\n\n\n```\n\nThe ```\nRemoveDuplicatesKeepOrder```\n function is taken from this question and here reported:\n```\ntemplate<typename T>\nsize_t RemoveDuplicatesKeepOrder(std::vector<T>& vec)\n{\n    std::unordered_set<T> seen;\n\n    auto newEnd = std::remove_if(vec.begin(), vec.end(), [&seen](const T& value)\n    {\n        if (seen.find(value) != std::end(seen))\n            return true;\n\n        seen.insert(value);\n        return false;\n    });\n\n    vec.erase(newEnd, vec.end());\n\n    return vec.size();\n}\n\n```\n\nI do the binding in a \"classical\" way, as reported in the pybind11 documentation:\n```\n#include <pybind11/pybind11.h>\n#include <pybind11/stl.h>\n#include <pybind11/numpy.h>\n\n#include \"parsing_nodes.h\"\n#include \"node_to_cells_Types.h\"\n\nnamespace py = pybind11;\n\nPYBIND11_MODULE(parsing_nodes, m) {\n  m.doc() = \"Parsing nodes from the NGon and NFaces\";\n  m.def(\n      \"RemoveDuplicatesKeepOrder\",\n      [](std::vector<n2c_OffsetT> &vec) {\n        RemoveDuplicatesKeepOrder<n2c_OffsetT>(vec);\n        return std::make_tuple(vec);\n      });\n  m.def(\"unique_nodes\",\n      []( const std::vector<n2c_OffsetT> &PC, const std::vector<n2c_OffsetT> &PCO,\n                std::vector<n2c_OffsetT> &PointConnectivity_singular, std::vector<n2c_OffsetT> &PointConnectivity_singular_O\n              ) {unique_nodes<n2c_OffsetT>(PC,PCO,PointConnectivity_singular,PointConnectivity_singular_O);\n        return std::make_tuple(PointConnectivity_singular,PointConnectivity_singular_O);\n      });\n}\n```\n\nThe compilation pass smoothly (using CMake and gcc). When I try to call the method from python side like this (oversizing my numpy array, seen thah I apply a ```\nshrink_to_fit```\n):\n```\nnvert=5000\nncells=10000\nPointConnectivity = np.zeros((nvert*12, ),dtype = np.int64)\nPointConnectivityO = np.zeros((nb_cells+1, ),dtype = np.int64)\nPointConnectivity_singular = np.zeros((4*nvert, ),dtype = np.int64)\nPointConnectivity_singular_O = np.zeros((nb_cells+1, ),dtype = np.int64)\nPCU,PCOU =unique_nodes(PC,PCO,PointConnectivity_singular,PointConnectivity_singular_O)\n```\n\nI obtain a ```\nsegfault```\n at a certain point. In particular a segfault related to the dimension of the vectors:\n```\n Error in `python': corrupted size vs. prev_size: 0x0000000003631960 \n```\n\nSo my questions are:\n\nAm I doing correctly the binding (in the sense of the data structure ```\nnumpy```\n and ```\nstd```\n)?\nIs there a way to avoid the copy in memory (so to have an opaque way to modify the numpy array). I have seen the buffer protocol in the documentation, but I have not understood how to apply it to my case where I want to use standard library methods on my vectors (that is a different data structure from numpy array).\nIs it the ```\nshrink_to_fit```\n possible or it invalidate in some way the pointer and hence it should be avoided?\n\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "What mathematical duals are there in OO programming?\r\n                \r\nIf you have watched Going Deep shows of the Channel9 lately, one very frequently mentioned topic is mathematical duality in programming. TomasP has a good blog post about duality in object oriented programming.\n\nThis has been since Microsoft Research found that the observer design pattern is actually a mathematical dual of the iterator pattern. Since then they have used the duality concept in various ways.\n\nMy question is:\n\nWhat mathematical dualities are there in programming?\n\nObject oriented programming is a good start. The major GoF design patterns are: Decorator, State, Iterator, Facade, Strategy, Proxy, Factory Method, Adapter, Observer, Template Method, Composite, Singleton, Abstract Factory and Command. Here is a good object-graph-poster.\n    ", "Answer": "\r\nI'd say the primary duality in programming is the code-data duality, most clearly exposed in Lisp, but also clear in most contemporary languages which provide introspection functionality.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Are there contravariant monads?\r\n                \r\nFunctors can be covariant and contravariant. Can this covariant/contravariant duality also be applied to monads?\n\nSomething like:\n\n```\nclass Monad m where\n  return :: a -> m a\n  (>>=) :: m a -> (a -> m b) -> m b    \n\nclass ContraMonad m where\n  return :: a -> m a\n  contrabind :: m a -> (b -> m a) -> m b\n```\n\n\nDoes ```\nContraMonad```\n class make sense? Any examples?\n    ", "Answer": "\r\nWell, of course, it's possible to define it, but I doubt it would be of any use.\n\nThere is a popular saying that \"monad is just a monoid in a category of endofunctors\". What it means is, first of all, that we have a category of endofunctors (meaning, (covariant) functors from some category to itself), and what's more, we have some multiplication on this endofunctors (in this case — composition). And then monad fits into some general framework that we don't have to worry about right now. The point is, there is no \"multiplication\" of contravariant functors. Composition of two covariant functors is again a covariant functor; but composition of two contravariant functors is not a contravariant functor (rather it's a covariant functor, so, a totally different beast).\n\nSo, \"contravariant monads\" do not really make sense.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Why variable profile_id is displaying duality in controller and view template in codeigniter?\r\n                \r\nI have a function in my controller which is trying to fetch the value from view template and print the same through post method but something else is printing on there.\n\n```\npublic function editProfile(){\n    $profile = $this->input->post('profile');\n    echo (\"PROFILE:\" . $profile);\n}\n```\n\n\nThis is my view template which is taking profile id from the application_info array stored in the database and matching it with the other profiles id so that the value of the particular id can be fetched and display out to the user-side using form. \n\n```\n$profile_id = $application_info[0]->profile_id;\n\n<form role=\"form\" action=\"<?php echo base_url() ?>Job_profiles/editProfile\" method=\"post\" id=\"editApplication\" role=\"form\">\n<div class=\"form-group\">\n    <label for=\"profile\">Profile</label>\n    <select class=\"form-control\" id=\"profile\" name=\"profile\">\n        <option value=\"0\">Select profile</option>\n        <?php\n        if(!empty($profiles))\n        {\n            foreach ($profiles as $p)\n            {\n                ?>\n                <option value=\"<?php echo $p->profile; ?>\" <?php if($p->profile_id == $profile_id) {echo \"selected=selected\";} ?>><?php echo $p->profile ?></option>\n                <?php\n            }\n        }\n        ?>\n    </select>\n</div>\n```\n\n\n\n\nWhile printing the value of the variable inside the view template, everything is going fine. But when displaying the value through the controller, it prints nothing.\n\nThanks.\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "MySQL select into outfile \"file already exists\" and \"file does not exist\" duality (?) case\r\n                \r\nI ran this command successfully on my CentOS machine's MariaDB:\n\n```\nMariaDB> select * from foobar into outfile '/tmp/schrodinger_cat.csv'\nfields terminated by ',' enclosed by '\"' lines terminated by '\\n';\n\nQuery OK, 900 rows affected (0.06 sec)\n```\n\n\nCat is alive? No.\n\nYou'd expect to find '/tmp/schrodinger_cat.csv'. Me too. I ```\nls```\n it:\n\n```\n# ls /tmp/schrodinger_cat.csv\n\nls: cannot access /tmp/schrodinger_cat.csv: No such file or directory\n```\n\n\nCat is dead? No.\n\nWhat? So I went back to the MariaDB command line client and run the same SQL again:\n\n```\nMariaDB> select * from foobar into outfile '/tmp/schrodinger_cat.csv'\nfields terminated by ',' enclosed by '\"' lines terminated by '\\n';\n\nERROR 1086 (HY000): File '/tmp/schrodinger_cat.csv' already exists\n```\n\n\nCat is alive exclusively for MariaDB? No.\n\nI thought maybe the MariaDB is accessing another file system? So I tried this:\n\n```\nMariaDB> \\! ls /tmp/schrodinger_cat.csv;\n\nls: cannot access /tmp/schrodinger_cat.csv: No such file or directory\n```\n\n\nSo, no.\n\nAny idea what happened? How do I get the file '/tmp/schrodinger_cat.csv'?\n    ", "Answer": "\r\nTurns out it is exclusive for MariaDB.\n\n```\n# ls /tmp/systemd-private-*-mariadb.service-*/tmp\n\n/tmp/systemd-private-xxxxxxxxxxxxxxxxxxxxx-mariadb.service-xxx/tmp:\nschrodinger_cat.csv\n```\n\n\nThe reason is that the CentOS systemd service file set ```\nPrivateTmp```\n to ```\ntrue```\n:\n\n```\n[Unit]\nDescription=MariaDB database server\nAfter=syslog.target\nAfter=network.target\n\n[Service]\nType=simple\nUser=mysql\nGroup=mysql\n\nExecStartPre=/usr/libexec/mariadb-prepare-db-dir %n\n# Note: we set --basedir to prevent probes that might trigger SELinux alarms,\n# per bug #547485\nExecStart=/usr/bin/mysqld_safe --basedir=/usr\nExecStartPost=/usr/libexec/mariadb-wait-ready $MAINPID\n\n# Give a reasonable amount of time for the server to start up/shut down\nTimeoutSec=300\n\n# Place temp files in a secure directory, not /tmp\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\n```\n\n\nYou may find more information from this RedHat blog post. If ```\nPrivateTmp=true```\n the process will have a, well, private ```\n/tmp```\n folder.\n\nTurn out the cat is alive and well in a private castle :-)\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "max min in linear programming\r\n                \r\nI need to solve\n\n```\n\\max_x \\min_y x^T M y\n```\n\n\nwhere ```\nM \\in \\mathbb{R}^{m\\times n}```\n, ```\nx \\in \\mathbb{R}^m```\n and ```\ny \\in \\mathbb{R}^n```\n.\n\nContrains are\n\n```\n \\sum_{i=1}^n y_i = 1\n \\sum_{j=1}^m x_j = 1\n```\n\n\nI know, the way to get a around this, is to make use of the duality theorem.\n\nMy question is: What is the reason that ```\n\\min_y x^T M y```\n which says to be the reason, why duality is needed here?\n\na. Is it, because ```\n\\min_y x^T M y```\n is not linear? I don't why this is the case.\nb. Is it, because ```\n\\min_y x^T M y```\n is not solvable using lin prog?\nc. Is it, becaus of another reason?\n    ", "Answer": "\r\nFor a fixed value of your variable ```\nx```\n, then the problem ```\nP(x)```\n:\n\n```\n\\min_y x^T M y```\n subject to: ```\n\\sum y_i = 1```\n \n\nis indeed a linear problem (in the variable ```\ny```\n only), and therefore can be solved by classical linear programming method.\n\nThe problem is that the solution function of this problem, that is the function (I denote it ```\nf```\n) that associates ```\nx```\n with the value of the problem ```\nP(x)```\n is not linear; and you can see that the original (min-max) problem you want to solve is equivalent to:\n\n```\n\\max_x f(x)```\n subject to: ```\n\\sum x_i = 1```\n,\n\nwhich is therefore not a linear problem.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Avoiding circular includes with shared_ptrs\r\n                \r\nI have a pair of classes for which I can't seem to avoid the circular include problem:\n\npoint.h\n\n```\n#include group.h // Needed for GroupOfPoints::weak_ptr\n\nclass Point\n{\n    private:\n        double _x;\n        double _y;\n\n        // Groups of points that this point belongs too\n        std::vector<GroupOfPoints::weak_ptr> _groups;\n\n    public:\n        typedef std::shared_ptr<Point> shared_ptr;\n        typedef std::weak_ptr<Point> weak_ptr;\n\n        Point(); // Constructor\n        // etc...\n}\n```\n\n\ngroup.h\n\n```\n#include point.h // Needed for Point::shared_ptr\n\nclass GroupOfPoints\n{\n\n    private:\n        // Collection of points that fall in this group\n        std::vector<Point::shared_ptr> _points;\n\n    public:\n        typedef std::shared_ptr<GroupOfPoints> shared_ptr;\n        typedef std::weak_ptr<GroupOfPoints> weak_ptr;\n\n        GroupOfPoints(); // Constructor\n        // etc...\n\n}\n```\n\n\nI understand that shared and weak pointers exist in duality to prevent circular ownership, but how can I utilize that duality without circular includes in the case where the pointers are member variables (i.e. must defined in a header rather than an implementation file)?\n    ", "Answer": "\r\nFirst get rid of this:\n\n```\ntypedef std::shared_ptr<Point> shared_ptr;\ntypedef std::weak_ptr<Point> weak_ptr;\n```\n\n\nI do not see the point.\n\n```\nstd::shared_ptr<Foo>```\n is clearer than ```\nFoo::shared_ptr```\n.\n\nNow, forward declare ```\nclass Point;```\n and ```\nclass Group;```\n.  This can be in place of ```\n#include <point.h>```\n, or before including the other header file.\n\nNext ensure your constructor are defined where they can see the entire declaration of the other class; whereever you call ```\nmake_shared<Foo>```\n or ```\nnew Foo```\n or ```\ndelete Foo```\n or ```\nshared_ptr<Foo>(pFoo)```\n.  Shared pointers type erase destruction at construction time.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Why does property 'find' not exist on my array using // @ts-check on Javascript in VS Code? (2018, typescript 2.7x)\r\n                \r\n** update\n\n```\nconsole.log(Array.isArray(primaryNumberFemales)); // true\n```\n\n\nand I export it with:\n\n```\nexport {\n  primaryNumberFemales,\n};\n```\n\n\n** end update\n\nI have an array (which is of course type object) that looks like this:\n\n```\nconst primaryNumberFemales = [{\n  name: 'Sky',\n  number: 6,\n  duality: 'Yang',\n  complexity: 'Complex',\n  year: [1910,\n    1919,\n    1928,\n    1937,\n    1946,\n    1955,\n    1964,\n    1973,\n    1982,\n    1991,\n    2000,\n    2009,\n    2018,\n  ],\n},\n{\n  name: 'Lake',\n  number: 7,\n  duality: 'Yin',\n  complexity: 'Simple',\n  year: [1911,\n    1920,\n    1929,\n    1938,\n    1947,\n    1956,\n    1965,\n    1974,\n    1983,\n    1992,\n    2001,\n    2010,\n    2019,\n  ],\n},\n];\n```\n\n\nWhich I import with:\n\n```\nimport {\n  primaryNumberFemales,\n} from './data';\n```\n\n\nand confirm it is an object after importing (so nothing funny has gone on somehow) with:\n\n```\nconsole.log(typeof primaryNumberFemales); // object\n```\n\n\ni want to type check my JS in VS Code 1.20.1 so add:\n\n// @ts-check\n\nnow with the code below i get an error in the linter for every instance of ```\nfind```\n, the program works fine!:\n\n```\n  return (gender === 'F') ? {\n    primaryNumber: (primaryNumberFemales.find(includesYearOfBirth) || {}).number,\n    typeOfExpression: (primaryNumberFemales.find(includesYearOfBirth) || {}).name,\n  } : {\n    primaryNumber: (primaryNumberMales.find(includesYearOfBirth) || {}).number,\n    typeOfExpression: (primaryNumberMales.find(includesYearOfBirth) || {}).name,\n  };\n```\n\n\nProperty 'find' does not exist on type '{ [x: string]: any; name: string; number: number; duality: string; complexity: string; year: numb...'.\n\nI know Array.prototype.find() is es6, and it was not supported in the past (plenty of posts on that here before), but it should definitely be supported now. Is there something wrong with my code, or is this some kind of bug? THANKS! \n    ", "Answer": "\r\nIf I parse the code in my head, when I'm looking at this expression:\n\n```\nimport { primaryNumberFemales } from './data';\n```\n\n\nI'm wondering how the error isn't here, as your module doesn't export this constant. To fix this, I would use the ```\nexport```\n keyword:\n\n```\nexport const primaryNumberFemales = [{\n    name: 'Sky',\n    number: 6,\n    duality: 'Yang',\n    complexity: 'Complex',\n    year: [1910,\n      1919,\n      1928,\n      1937,\n      1946,\n      1955,\n      1964,\n      1973,\n      1982,\n      1991,\n      2000,\n      2009,\n      2018,\n    ],\n  },\n  {\n    name: 'Lake',\n    number: 7,\n    duality: 'Yin',\n    complexity: 'Simple',\n    year: [1911,\n      1920,\n      1929,\n      1938,\n      1947,\n      1956,\n      1965,\n      1974,\n      1983,\n      1992,\n      2001,\n      2010,\n      2019,\n    ],\n  },\n  ];\n```\n\n\nIf I run this example through the compiler it seems happy enough, I can use the ```\nArray.find```\n method too. I have set my compiler to target ```\nES6```\n.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Why does support vectors in SVM have alpha (Lagrangian multiplier) greater than zero?\r\n                \r\nI understood the overall SVM algorithm consisting of Lagrangian Duality and all, but I am not able to understand why particularly the Lagrangian multiplier is greater than zero for support vectors. \n\nThank you.\n    ", "Answer": "\r\nThis might be a late answer but I am putting my understanding here for other visitors.\n\nLagrangian multiplier, usually denoted by α is a vector of the weights of all the training points as support vectors. \n\nSuppose there are m training examples. Then α is a vector of size m. Now focus on any ith element of α: αi. It is clear that αi captures the weight of the ith training example as a support vector. Higher value of αi means that ith training example holds more importance as a support vector; something like if a prediction is to be made, then that ith training example will be more important in deriving the decision.\n\nNow coming to the OP's concern:\n\n\n  I am not able to understand why particularly the Lagrangian multiplier\n  is greater than zero for support vectors.\n\n\nIt is just a construct. When you say αi=0, it is just that ith training example has zero weight as a support vector. You can instead also say that that ith example is not a support vector.\n\nSide note: One of the KKT's conditions is the complementary slackness: αigi(w)=0 for all i. For a support vector, it must lie on the margin which implies that gi(w)=0. Now αi can or cannot be zero; anyway it is satisfying the complementary slackness condition. \nFor αi=0, you can choose whether you want to call such points a support vector or not based on the discussion given above. But for a non-support vector, αi must be zero for satisfying the complementary slackness as gi(w) is not zero.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Is there a protocol buffer compiler that outputs pure TypeScript files?\r\n                \r\nhttps://github.com/improbable-eng/ts-protoc-gen seeems to output type definitions in ```\nd.ts```\n files. \nIs it possible somehow to convert ```\n.proto```\n files into ```\n.ts```\n files (instead of separate ```\n.js```\n and ```\n.d.ts```\n)?\n\nI have a fully TypeScript frontend, so no need for the ```\n.js```\n + ```\n.d.ts```\n duality.\n    ", "Answer": "\r\nI know that your question is old, but maybe this helps someone looking for answers today:\nYes, there are plugins for protoc that generate plain TypeScript.\n\nThe first one I learned about is ts-proto.\n\nI needed support for for bigint and proto3 optionals, so I wrote another one: protobuf-ts\nIt passes googles conformance tests (the official JS generator doesn't), comes with grpc-web and twirp support and has no external dependencies.\n\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "What are the similarities / differences between Control.Observable and Control.Event modules in F#?\r\n                \r\nF# (at least in Visual Studio 2012) has both ```\nControl.Observable```\n and ```\nControl.Event```\n.\n\n\nHow are they related?\nWhich one should be used when?\nAre there performance differences between the two?\n\n\n\n\nI would also love to know what Haskell modules / packages / features the .NET ```\nIEnumerable```\n / ```\nIObservable```\n duality achieved with reactive extensions to .NET correspond to.\n    ", "Answer": "\r\nTo answer the first part of your question, there is a number of differences between ```\nIEvent```\n and ```\nIObservable```\n. The reason why there are two similar types is that ```\nIEvent```\n has been designed for F# (earlier and it is left there mostly for compatibility reasons) and the ```\nIObservable```\n type was added later on to the .NET (and so F# added support for it too). Here are some differences:\n\n\n```\nIEvent```\n does not support removing of event handlers, so when you create a processing pipeline (combining ```\nmap```\n, ```\nfilter```\n and others) and then call ```\nRemoveHandler```\n on the resulting event, it leaves some handlers attached (yes, that's a leak and we wrote a more detailed paper about it)\nOn the other hand ```\nIObservable```\n is able to remove handlers.\nAs a result of the previous point, ```\nIObservable```\n behaves differently with respect to stateful combinators. For example, when you use ```\nEvent.scan```\n, you can attach multiple handlers to the resulting event and they will see the same state. ```\nIObservable```\n creates a \"new state\" for every attached handler (unless you use subject explicitly).\n\n\nIn practical F# programming, this means:\n\n\nYou should generally prefer ```\nIObservable```\n if you want to be able to remove event handlers (using ```\nRemoveHandler```\n or when using ```\nAwaitObservable```\n in F# async workflows).\nIf you want to declare events (usable from C#) then you need to create properties of type ```\nIEvent```\n and so you need to use ```\nEvent```\n combinators.\n\n\nAs mentioned in comments, the F# model is heavily influenced by functional reactive programming (FRP) which is an idea that was first developed in Haskell, so you should find a plenty of similar libraries. The F# version is \"less pure\" in order to be more practical for .NET programming.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Getting a dual of a boolean expression\r\n                \r\nI am brushing up on my boolean algebra and I am confused which one is actually the correct method?\n\nWhat's the difference between the dual and the complement of a boolean expression?\n\nduality principle in boolean algebra\n\n```\nF(X,Y) = X + Y\n\nDUAL: XY\n```\n\n\nor is it ```\nDUAL: X'Y'```\n ?\n    ", "Answer": "\r\nIn one word it is : ```\nX'Y'```\n . simply duality principle is : \n\n\n  Let (S,∨,∧) be a Boolean algebra.\n  Then any theorem in (S,∨,∧) remains valid if both ∨ and ∧ are interchanged, and also ⊥ and ⊤ are interchanged throughout the whole theorem.\n\n\nSo you have to interchange ```\n+```\n with ```\n.```\n and ```\nTrue```\n with ```\nFalse```\n. So whether ```\nX```\n and ```\nY```\n are true of false they must be replace with ```\nX'```\n and ```\nY'```\n.\n\nIf you want to understand better to read this. And also you can see some good examples in this forum.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Why UIViewController and UIView subclass UIResponder?\r\n                \r\nLooking at Apple GLPaint sample code.\n\nI see that both PaintingViewController and PaintingView implement \n\n```\n- (BOOL)canBecomeFirstResponder {\n    return YES;\n}\n```\n\n\nWhy is duality? Generally speaking, shouldn't only the UIView be responsible for handling the touch events generated by the hardware? as explained in The Runtime Interaction Model for Views \n    ", "Answer": "\r\nNope, there is one simple example:\n\nImagine you have a ```\npresentedController```\n. Then you don't want the ```\npresentingController```\n to handle touch events even if it's still visible.\n\nView controller hierarchy is VERY important in event delivery.\n\nSee the note in ```\nUIViewController```\n documentation:\n\n\n  A view controller is tightly bound to the views it manages and takes part in the responder chain used to handle events. View controllers are also UIResponder objects and are inserted into the responder chain between the view controller’s root view and that view’s superview, which typically belongs to a different view controller. If none of the view controller’s views handle an event, the view controller has the option of handling the event or passing it along to the superview.\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Time of Arrival estimation of a signal in Matlab\r\n                \r\nI want to estimate the time of arrival of ```\nGPR echo```\n signals using Music algorithm in matlab, I am using the duality property of Fourier transform.\n\nI am first applying FFT on the obtained signal and then passing these as parameters to ```\npmusic```\n function, i am still getting the result in frequency domain.?\n    ", "Answer": "\r\nShort Answer: You're using the wrong function here.\n\nAs far as I can tell Matlab's ```\npmusic```\n function returns the pseudospectrum of an input signal.\n\nIf you click on the pseudospectrum link, you'll see that the pseudospectrum of a signal lives in the frequency domain.  In particular, look at the plot:\n\n(from Matlab's documentation: Plotting Pseudospectrum Data)\n\nNotice that the result is in the frequency domain.\n\n\n\nAssuming that by GPR you mean Ground Penetrating Radar, then try radar or sonar echo detection approach to estimate the two way transit time.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Optimal solution for linear program given that both primal slack forms are feasible\r\n                \r\nI'm given a linear program ```\nP```\n in a standard form.\n\nI need to prove that if both the primal slack form of ```\nP```\n and primal slack form of the dual problem are feasible, then the optimal solution for ```\nP```\n is ```\n0```\n.\n\nI've trie to work with Weak Duality theorem, but can't get the math together.\n\nAny help would be appericiated.\n    ", "Answer": "\r\nAccording to the Duality Theorem if a primal problem admits an optimal solution (x*1,….x*n) then the dual problem admits an optimal solution (y*1, ….y*m) such that all feasible solutions of the program in primal form are bounded from above by that of the dual program, and we can say the opposite holds true as well, that feasible solutions of the dual are bounded from below by those of the primal, meaning that if the two have the same solution then it is the optimal solution of the linear program. \n\nPut simply, the optimal solution is bound from below by feasible solutions of the primal program and from above by feasible solutions of the dual program.\n\nIn this case it is given that both primal and dual basic slack forms of the program are feasible, meaning that the basic solution to the slack form is a feasible solution. The basic slack form’s feasible solution is 0 (remember we set all non-basic variables to zero when solving for basic solution). Thus we know that for both the dual and primal program 0 is a feasible solution and so from the duality we know that 0 is the optimal solution of the linear program. \n\nWe can prove this by negation. Take some non-zero number k and some non-zero number j such that k is a feasible solution for the linear program’s primal form and j is a feasible solution for the linear program’s dual form. The optimal solution of the linear program occurs when j=k. Let us show that this cannot happen for any number other than 0.\n\nFor any feasible solution k of the primal program we know that it is bound from above by all feasible solutions of the dual program. Since we know that one such solution is 0, since the basic slack form of the dual program is feasible, then we know that k must be a non-positive number. \nFor any feasible solution j of the dual program we know that it is bound from below by all feasible solutions of the primal program. Since we know that one such solution is 0, since the basic slack form of the primal program is feasible, then we know that j must be a non-negative number. \n\nHaving shown that any feasible solution of the dual, j,  is non-negative, and any feasible solution of the primal, k,  is non-positive, we see that the j=k for a non zero number is a contradiction.\nThe only number that can possibly obtain j=k is 0, and thus is the optimal solution.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Swagger parameters in query and/or body\r\n                \r\nOur API has such endpoints that support parameters both from the ```\nquery```\n and from the ```\nbody```\n at the same time, by merging those two sets of parameters.\n\nFor example:\n\n```\n/foo?param1=value1\nbody: {\n    param2=value2\n}\n```\n\n\nThe resulting set of parameters would contain two, ```\nparam1```\n and ```\nparam2```\n.\n\nThis endpoint could be used as:\n\n```\n/foo?param1=value1&param2=value2\n```\n\n\nOR\n\n```\n/foo\nbody: {\n    param1=value1,\n    param2=value2\n}\n```\n\n\nIs there a way how to specify this 'duality' in Swagger?\n\nUPD\nI suppose I should define parameter as both: ```\nbody```\n and ```\nquery```\n\n\n```\nin:\n  - body\n  - query\n```\n\n    ", "Answer": "\r\nYou'll need to define both query parameters and body parameters but mark all of them as optional. Use the operation ```\ndescription```\n to explain that the client can send the parameters in either query string or body.\n\n```\nswagger: '2.0'\n...\npaths:\n  /foo:\n    post:\n      consumes:\n        - application/json\n      parameters:\n        - in: query\n          name: param1\n          type: string\n          required: false\n        - in: query\n          name: param2\n          type: string\n          required: false\n        - in: body\n          name: body\n          required: false\n          schema:\n            type: object\n            properties:\n              param1:\n                type: string\n              param2:\n                type: string\n```\n\n\nUsing OpenAPI 3.0, it's a bit more elegant in that you can reuse the same ```\nschema```\n for the query string and the request body:\n\n```\nopenapi: 3.0.0\n...\npaths:\n  /foo:\n    post:\n      parameters:\n        # This expands into ?param1=value1&param2=value2&...\n        - in: query\n          name: parameters\n          required: false\n          schema:\n            $ref: '#/components/schemas/Parameters'\n          style: form\n          explode: true\n      requestBody:\n        required: false\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/Parameters'\n      responses:\n        '200':\n          description: OK\n\ncomponents:\n  schemas:\n    Parameters:\n      type: object\n      properties:\n        param1:\n          type: string\n        param2:\n          type: string\n```\n\n\nNote for Swagger UI users: Serialization of objects into query string seems to be not supported yet as of UI v. 3.11.0.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Can we think of immutable lists as a dual to trees?\r\n                \r\nI might draw a list of words like:\n\n```\nthis -> is -> a -> test\n```\n\n\nand then through sharing, I might draw two lists as:\n\n```\nthis -> is -> a -> test\n                     ^\n                     |\nthat -> was -> a -> hard\n```\n\n\nNow, if I reverse the arrows, I get a tree, with test as the root.  This is the same notion as duality in graph/category theory.  Therefore, I can think of trees and lists as dual concepts.\n\nIs this correct/useful?\n    ", "Answer": "\r\nSharing and laziness allow you to have arbitrary cyclic structures. For example, in Haskell the definition\n\n```\nones = 1 : ones\n```\n\n\nproduces a graph consisting of a single vertex (corresponding to 1) and a loop (in graph-theoretic, not programming sense). By reversing the arrows, you'd get the same structure, and it's not a tree (as it's got loops).\n\nSo, it's not true in a lazy language.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Double Parameters in youtube embedding\r\n                \r\ni'm trying to embed this video for a project i'm doing on a NTB IPTV and I would like the controls to be hidden and the video to autoplay. Please consider the following:\n\n```\n<iframe width=\"853\" height=\"480\"\nsrc=\"http://youtube.com/embed/3kSSpNpa4q0?autoplay=1?&autohide=2\" \nframeborder=\"0\" \nallowfullscreen>\n</iframe>\n```\n\n\nOh my bad, basically i cannot get these parameters to work in duality as soon as i used autohide autoplay stopped working.\n    ", "Answer": "\r\nUsing Autoplay= 1 together with Autohide=2 is not possible.\n\nBut you could do \n\n\n  https://www.youtube.com/embed/3kSSpNpa4q0?autohide=1&enablejsapi=1&autoplay=1\n\n\nWhich will trigger Autohide after 3 seconds\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to set a button if clicked, ignore the mouseout on vanilla JS?\r\n                \r\nI'm trying to make a ToDoList and I'm using the 'mouseover'/'mouseout' duality to make an effect like hover. But, after a click, it was supposed to maintain the same layout as the 'mouseover' and ignore the 'mouseout', but the 'mouseout' effect prevails and the layout returns. How can I set the click to ignore the 'mouseout'?\n```\n  check.addEventListener('mouseover', function(event){\n        check.style.cssText =  'cursor: pointer; color: #eaeaea; border: 1px solid #08a59d; margin-left: -40vw; padding: 4px; border-radius: 5px; background-color: #08a59d;'\n    });\n    check.addEventListener('mouseout', function(event){\n        check.style.cssText = 'cursor: pointer; color: #08a59d; border: 1px solid #08a59d; margin-left: -40vw; padding: 4px; border-radius: 5px;'\n    });\n    check.addEventListener('click', function(event){\n        task.style.cssText = 'width: 30vw; height: 30px; background-color:#5B8581; color: #eaeaea; text-align: center; margin-top: -4.3vh; border-radius: 10px; font-weight: 500; font-size: 18px; padding-top: 4px; text-decoration: line-through;';\n        check.style.cssText =  'cursor: pointer; color: #eaeaea; border: 1px solid #08a59d; margin-left: -40vw; padding: 4px; border-radius: 5px; background-color: #08a59d;'\n    });\n        closebutton.addEventListener('mouseover', function(event){\n        closebutton.style.cssText =  'width: 25px; cursor: pointer; color: #eaeaea; border: 1px solid #C70039; margin-left: 40vw; padding: 4px; padding-left: 6.2px; border-radius: 5px; margin-top: -3.7vh; background-color: #C70039;'\n    });\n    closebutton.addEventListener('mouseout', function(event){\n        closebutton.style.cssText =  'width: 25px; cursor: pointer; color: #C70039; border: 1px solid #C70039; margin-left: 40vw; padding: 4px; padding-left: 6.2px; border-radius: 5px; margin-top: -3.7vh;'\n    })\n\n```\n\n    ", "Answer": "\r\nYou can use the ```\nevent.stopImmediatePropagation()```\n method.\nWhat this method basically does is stop all the other events' execution while an event happens so you could add it to your onclick event and it should solve the problem...\nFor more info Check MDN here\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Printing command line arguments char by char in C\r\n                \r\nHere's what I have:\n\n```\n#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n\nint main(int argc, char **argv)\n{\n\n    while(*argv++ != 0)\n    {\n            printf(\"Argument!\\n\");\n            printf(\"%s %d\\n\",*argv,(int)strlen(*argv));\n            int i = 0;\n\n            while(*argv[i])\n            {\n                    printf(\"char!\\n\");\n                    printf(\"%c\\n\",*argv[i]);\n                    i++;\n            }\n\n            printf(\"End of for loop\\n\");\n    }\n\n    return 0;\n}\n```\n\n\nWhen I run ./a.out test, the output is:\n\n```\nArgument!\ntest 4\nchar!\nt\nSegmentation Fault\n```\n\n\nI've been staring at this for a few hours. Why won't my program print each command line argument character by character? \n\nI'm new to C, and the array-pointer duality, so I wouldn't be surprised if that were the problem. Any help is appreciated!\n    ", "Answer": "\r\nFirst version\n\nWhat you want is use argc:\n\n```\n#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n\nint main(int argc, char **argv)\n{\n    int i = 0;\n    int j = 0;\n    for (i = 0; i < argc; i ++)\n    {\n    j = 0;      \n    while(argv[i][j] != '\\0')\n       printf(\"Argument %d letter %d : %c\\n\", i,j,argv[i][j++]);   \n    }\n    return 0;\n}\n```\n\n\nThe output is actually letter by letter as you needed:\n\n```\n$./a.out hello world\nArgument 0 letter 1 : .\nArgument 0 letter 2 : /\nArgument 0 letter 3 : a\nArgument 0 letter 4 : .\nArgument 0 letter 5 : o\nArgument 0 letter 6 : u\nArgument 0 letter 7 : t\nArgument 1 letter 1 : h\nArgument 1 letter 2 : e\nArgument 1 letter 3 : l\nArgument 1 letter 4 : l\nArgument 1 letter 5 : o\nArgument 2 letter 1 : w\nArgument 2 letter 2 : o\nArgument 2 letter 3 : r\nArgument 2 letter 4 : l\nArgument 2 letter 5 : d\n```\n\n\nSecond version:\n\nYou can use the pointer notation for ```\nj```\n but not for ```\ni```\n since you don't know the letter count of each argument. It could of course be achieved by using ```\nstrlen```\n which would lead under the hood to an iteration through the string to count the letter, which is not what you want to do. If you can do it in one iteration through the argument why do it in two? \n\n```\n#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n\nint main(int argc, char **argv)\n{\n    int i = 0;int j = 0;\n    while(i < argc)\n    {\n    j=0;\n    while(*(argv[i]+j) != '\\0')\n    {\n            printf(\"Argument %d letter %d : %c\\n\", i,j,*(argv[i]+(j)));\n            j++;\n    } \n     i++;\n    }\n    return 0;\n\n}\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Pressurized vessel in modelica [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs to be more focused. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\r\n                \r\n                    \r\n                        Closed 1 year ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI've been trying to create a pressurized vessel in openmodelica but i'm stuck.\nThe block i'm trying to build is a simple vessel for liquid pressurized by gas.\nSo two input ports (liquid input, gas input) and an output port for pressurized liquid outlet. The total volume of the vessel is constant. Looks simple but stuck with the duality gaz/liquid.\n    ", "Answer": "\r\nIt's hard to provide any advice without your code. However, pressure vessels have been modelled in Modelica before and you could take inspiration from the following free libraries:\n\nTRANSFORM: e.g. models in ```\nTRANSFORM.Fluid.Volumes```\n\nThermoPower: e.g. ```\nThermoPower.Water.Accumulator.mo```\n\nBuildings: e.g. ```\nmodel Buildings.Fluid.Storage.ExpansionVessel.mo```\n\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How do I add KKT conditions, dual feasibility constraints into the primal model using Pyomo or Julia?\r\n                \r\nI've to model certain bilevel problems. The approach is to delete the second level problems by replacing them with their KKT conditions or replacing them with their optimality conditions, such as strong duality ...\nI wish to do this automatically without calculating these conditions myself and hardcoding them back to the primal. I have two main issues I would like to have your assistance about:\n\nHow do I add the dual of certain constraints to the objective function?\nAre there any ways for me to do what I want, and if not, where can I start to write them so that eventually they get the primal model and return a model with primal, dual constraints, and strong duality or KKT conditions? I guess getting the constraints and manually form the dual problem could be the right approach.\n\nI really appreciate any help you can provide, no matter whether this would be in Julia or Pyomo.\n    ", "Answer": "\r\nFor Pyomo consult the packages ```\npyomo.bilevel```\n (link) and ```\npyomo.mpec```\n (link). I usually prefer to reformulate by hand just so I know what is happening (and use a tool to confirm I did it correctly).\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Npm; is package-lock.json redundant if package.json only specifies exact versions?\r\n                \r\nI struggle with npm's ```\npackage.json```\n and ```\npackage-lock.json```\n duality. I believe this question may provide insight regarding how these files relate to each other:\nIf we define a ```\npackage.json```\n file which only specifies exact versions for all dependencies, e.g.:\n```\n...\n  \"dependencies\": {\n    \"dep1\": \"1.2.3\",\n    \"dep2\": \"4.5.6\"\n  }\n...\n```\n\nand never any ambiguous versions, such as:\n```\n...\n  \"dependencies\": {\n    \"dep1\": \"^1.2.3\",\n    \"dep2\": \"4.5.*\"\n  }\n...\n```\n\nthen would there ever be a reason to also maintain a ```\npackage-lock.json```\n file? (And if so, what is such a reason?)\n    ", "Answer": "\r\nThe ```\npackage-lock.json```\n is not redundant even if you pin specific version of your dependency.\n```\npackage-lock.json```\n protects you from transitive dependencies - any dependency that is induced by the components that the program references directly.\n\nIt describes the exact tree that was generated, such that subsequent installs are able to generate identical trees, regardless of intermediate dependency updates\n\nFor example:\n\nA → B\nIt is not the case that B → A\nB → C\n\nThen the dependency A → C (which follows from 1 and 3 by the axiom of transitivity) is a transitive dependency.\nNote that B can use any non-exact version constraint on C, such as ```\n>= X```\n. So it might be that when C dependency is resolved, each time it can be any version bigger than X. ```\npackage-lock.json```\n will guarantee that is not the case.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Python - How to handle both int aswell as gmpy / mpz without function overloading?\r\n                \r\nI'm very new to python and I have to implement a few algorithms. To achieve better performance for big numbers (> 1024 bit), I would like to use gmpy2/mpz - but I would still like to support normal python integers aswell.\n\nAs Python lacks function overloading, I'm wondering how this can best be achieved.\n\n```\nif(a.__class__.__name__ == 'mpz'):\n    a = gmpy2.floor(x/8)\nelse:\n    a = floor(x/8)\n```\n\n\nIs there a better way to avoid this duality? \n    ", "Answer": "\r\nIn your example, ```\nx/8```\n will be interpreted first and will result in a standard Python float type. This will cause a loss of precision for large numbers since the float type only has 53 bits of precision.\n\nIf you are working with integers, you should use the floor division operator ```\n//```\n. No conversion to floating point is needed. The approach automatically works with Python integers and the mpz type.\n\n```\n>>> 123456789//256\n482253\n>>> gmpy2.mpz(123456789)//256\nmpz(482253)\n>>> 123456789//gmpy2.mpz(256)\nmpz(482253)\n>>> gmpy2.mpz(123456789)//gmpy2.mpz(256)\nmpz(482253)\n```\n\n\nTo answer the question in the comment...\n\nIf you are working with large integer inputs and want integer results, I would avoid floating point operations and work entirely with integers. The following snippet should work with both Python integers and the mpz type and is not limited by the precision of the Python float type.\n\n```\nq,r = divmod(123456789,256)\nq += bool(r)\n```\n\n\n```\nq```\n will have the desired result. \n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "SignalR remote client\r\n                \r\nI want to connect to signalr with a client thats on a different pc. This means i wont be using localhost. I already made a simple networkdiscovery to get the correct ip address but it seems signalr does not allow remote clients to connect even though I already use CorsOptions.AllowAll.\n\n```\n    class Startup\n{\n    public void Configuration(IAppBuilder app)\n    {\n        var hubConfiguration = new HubConfiguration\n        {\n#if DEBUG\n            EnableDetailedErrors = true\n#else\n        EnableDetailedErrors = false\n#endif\n        };\n        app.UseCors(CorsOptions.AllowAll);\n        app.MapSignalR(hubConfiguration);\n    }\n}\n```\n\n\nIam using duality which is a 2d game engine. Here is the server:\n\n```\n    public class SignalRServer : Component, ICmpInitializable\n{\n    private IDisposable _signalRServer;\n    public int _port { get; set; } = 8080;\n\n    public void StopServer()\n    {\n        if (_signalRServer != null)\n            _signalRServer.Dispose();\n    }\n\n    public void OnInit(InitContext context)\n    {\n        if (context == InitContext.Activate && DualityApp.ExecContext == DualityApp.ExecutionContext.Game)\n        {\n            var networkDiscovery = new NetworkDiscovery(_port, \"TestGame\"); //Network discovery to get the ip adres of the server if one is found\n            IPEndPoint ipEndPoint;\n            if (networkDiscovery.LookForServer(out ipEndPoint))\n            {\n                try\n                {\n                    ConnectToServer(ipEndPoint).Wait();\n                    Debug.WriteLine($\"Connection established to {ipEndPoint}\");\n                }\n                catch (Exception ex)\n                {\n                    Debug.WriteLine(\"Could not find server\");\n                }\n            }\n            else //No server was found so we create one\n            {\n                Debug.WriteLine(\"Starting signalR server\");\n                string url = $\"http://*:{_port}\"; //To test go to http://localhost:8080/signalr/hubs\n                networkDiscovery.Start(); \n                _signalRServer = WebApp.Start<Startup>(url);\n            }\n        }\n    }\n\n    private async Task ConnectToServer(IPEndPoint ipEndPoint)\n    {\n        var hubConnection = new HubConnection($\"http://{ipEndPoint}/\");\n        IHubProxy hubProxy = hubConnection.CreateHubProxy(nameof(MyHub));\n        hubProxy.On<string, string>(nameof(MyHub.Send), (name, message) =>\n        {\n            Debug.WriteLine(\"Incoming data: {0} {1}\", name, message);\n        });\n        ServicePointManager.DefaultConnectionLimit = 10;\n        await hubConnection.Start();\n\n    }\n\n    public void OnShutdown(ShutdownContext context)\n    {\n        StopServer();\n    }\n}\n```\n\n\nAnd the hub:\n\n```\n    public class MyHub : Hub\n{\n    public void Send(string name, string message)\n    {\n        Clients.All.addMessage(name, message);\n    }\n\n    public override Task OnConnected()\n    {\n        Debug.WriteLine(\"Client connected: \" + Context.ConnectionId);\n        Send(\"Server\", $\"Client with id {Context.ConnectionId} has connected\");\n        return base.OnConnected();\n    }\n\n    public override Task OnDisconnected(bool stopCalled)\n    {\n        Debug.WriteLine(\"Client disconnected: \" + Context.ConnectionId);\n        return base.OnDisconnected(stopCalled);\n    }\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "XML & JSON web api : automatic mapping from POJOs?\r\n                \r\nI'm about to start on a small project which goal is to end up with a web xml/json api. I'll be writing it in Java, and I'll be using the restlet library.\n\nHow do I approach the xml/json duality? I know I can use JAXB to \"convert\" pojos to xml (and back), but how do I automate this for json?  Is there any functionality in the restlet library I can leverage?\n    ", "Answer": "\r\nRestlet allows you to directly work with POJOs within your server resources at the level of REST annotated methods, as described below:\n\n```\npublic class MyServerResource extends ServerResource {\n    @Get\n    public List<MyPojo> getList() {\n        List<MyPojo> list = (get list from backend for example)\n        return list;\n    }\n\n    @Post\n    public MyPojo addPojo(Pojo pojo) {\n        addPojoInBackend(pojo\n\n        getResponse().setLocationRef(getUri() + field.getId());\n        getResponse().setStatus(Status.SUCCESS_CREATED);\n\n        return pojo;\n    }\n}\n```\n\n\nYou don't need to specify media type (i.e. content type) within the content of the annotations.\n\nTo handle such code, Restlet provides a generic conversion feature that does the work under the hood. Restlet extensions provide different implementations for this feature. If you want to have both XML and JSON for your RESTful application, I think that you should the Jackson extension for what you want to do. Jackson (http://wiki.fasterxml.com/JacksonHome) is a tool that allows to convert POJO to various formats like XML, JSON and YAML.\n\nTo enable this, simply put the JAR file of the Jackson extension (org.restlet.ext.jackson) in your classpath and use the programming approach described above. Here are the details on how it works:\n\n\nYou will be able to send both JSON and XML content (set the header ```\nContent-Type```\n in the request) and Restlet will automatically convert this content to the bean expected in the annotated method.\n\n```\nPOST /myresource\nContent-type: application/json\n{ \"id\":\"myid\", ... }\n```\n\nTo switch / select the expected content with response, you can leverage to conneg (content negociation of REST) based on the header ```\nAccept```\n. If you specify ```\napplication/json```\n, a JSON content wil be received and ```\napplicaiton/xml```\n, a XML one.\n\n```\nGET /myresource\nAccept: application/json\n{ \"id\":\"myid\", ... }\n\nGET /myresource\nAccept: application/xml\n<elt><id>myid> ... </elt>\n```\n\nYou can notice that Restlet also support a query parameter ```\nmedia```\n (not standard) to select the content to receive. If you specify ```\njson```\n, a JSON content will be received back and ```\nxml```\n an XML one.\n\n```\nGET /myresource?media=json\n{ \"id\":\"myid\", ... }\n\nGET /myresource?media=xml\n<elt><id>myid> ... </elt>\n```\n\n\n\nTo finish, you can notice that this mechanism is also supported on server-side with Restlet. This means that you can work directly with beans. This feature can be used with Restlet annotated interfaces, as described below:\n\n```\npublic interface MyResource {\n    @Get\n    List<MyPojo> getList();\n\n    @Post\n    MyPojo addPojo(Pojo pojo);\n}\n```\n\n\nYou can use this interface as described below:\n\n```\nClientResource cr = new ClientResource(\"http://(...)/myresource\");\nMyResource myResource = cr.wrap(MyResource.class);\n// List\nList<Pojo> list = myResource.getList();\n// Add\nPojo pojo = new Pojo();\npojo.setId(\"myid\"); // for example\n(...)\nPojo returnedPojo = myResource.add(pojo);\n```\n\n\nDon' forget to put in the client classpath application the extension Jackson.\n\nHope it helps,\nThierry\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Minimal rectangle containing all intersections of lines\r\n                \r\nI'm trying to find an algorithm that will find all the intersections of a set of lines and compute the minimal rectangle that contains all the intersections in O(n log n) time. So far I'm guessing it has to do with duality and convex hulls, but I'm kinda stuck on how it would actually help me solve this problem.\n\nIf anyone has an idea on this, please let me know. Thanks :)\n    ", "Answer": "\r\nLet's start from a box B[0] that minimally bounds three intersection points in a triangle.\n\nIf no triangle can be found, then we have a one of the following special cases which can be handled separately:\n\n\nAll lines are parallel.\nAll intersections are along one line.  This could happen if all lines but one are parallel.\nAll lines intersect at a single point.\n\n\nSo let's ignore these cases as details and assume a triangle can be found and that finding it doesn't add too much time to the algorithm.\n\nPhase 1 - Grow the box to include one intersection from each line:\n\n\nTag the three lines forming the initial triangle.\nChoose one untagged line, and find an intersection P with a tagged line.  This is always possible since there are at least three tagged lines that aren't mutually parallel.\nGrow the box to include P.\nRepeat from 2 until all the lines are tagged, i.e. they all have at least one intersection in the box.\n\n\nCall the resulting box B[0].\n\nPhase 2 - Detect if lines have an intersection outside of the box:\n\nHere's the key observation: for two lines A and B that intersect WITHIN the box, walking around the box clockwise we encounter the lines alternating: e.g. A B A B.  For two lines that intersect OUTSIDE the box, a clockwise walk does NOT alternate: e.g. A B B A.  Of course there is the possibility that the lines intersect on the box boundary, or are concurrent, but that will be treated as a detail after describing the main algorithm.\n\n\nChoose an orientation of the lines: Let the lines be directed toward the +y direction if the lines aren't horizontal, and let horizontal lines be oriented in the +x direct.  One things of the lines as arrows, then the arrows are all chosen to point up as much as they can, or to the right if they're horizontal.  With this orientation, each line has a point of entry into the box (where the oriented line points into the box, and a point of exit.  These may be the same point.\nCreate an \"exit sequence\" of the lines by walking the EXITING intersections clockwise around the boundary, starting at, say, the upper right corner.\nCreate an \"enter sequence\" of the lines by walking the ENTERING intersections clockwise starting at the upper right corner of the box as well.\nIf all intersections are interior to the box, the enter and exit sequences will be cyclic with each other, and B[i] is the minimum bounding box of the intersections.\nOtherwise, align the two sequences to an arbitrary element (by cyclic rotation).\nFind the elements in the sequences where they first differ.  Those two lines must have an intersection P outside of the box, so form B[i+1] by growing B[i] to include P.\nRepeat from 2.\n\n\nThis isn't complete because the entering and exiting sequences aren't well defined if a group lines have a common entering or exiting point on the boundary.  For each group of lines L with a common entering or exiting point, use a slightly larger box for ordering L.\n\nNote that this algorithm doesn't emit all the intersections, but it does guarantee (I hope) that the box contains them all.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Optuna ConvergenceWarning on Lasso hyperparameter tuning study\r\n                \r\nWhen fine tuning my Lasso model using Optuna, I get the following ConvergenceWarning..  Is it possible to increase nr. of iterations? I increased n_trials but it didn't help.\nMy code:\n```\ndef objective(trial):\n\n    _alpha = trial.suggest_float(\"alpha\", 0.0001, 0.01)\n    lasso = Lasso(alpha=_alpha, random_state=random_state)\n    score = cross_val_score(lasso, X_train, y_train, cv=kf, scoring=\"neg_root_mean_squared_error\").mean()\n\n    return score\n\n\noptuna.logging.set_verbosity(0)\n\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=300)\n```\n\nThe error/warning:\n\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532:\nConvergenceWarning:\nObjective did not converge. You might want to increase the number of\niterations. Duality gap: 0.02194362081235468, tolerance:\n0.01627441311545211\n\n    ", "Answer": "\r\nAccording to the warning message, I think ```\nLasso```\n in the code is sklearn's ```\nLasso```\n. So ```\nn_trials```\n of optuna does not resolve the warning.\nI think specifying a larger ```\nmax_iter```\n or ```\ntol```\n arguments of ```\nLasso```\n than the default values resolves the warning.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Debugging a vstemplate wizard\r\n                \r\nFor a game engine called duality (https://duality.adamslair.net/) I want to make a solution template that will create the necessary projects and all the files needed for duality to function. This includes files and folders that are not part of a project themselves.\n\nIn order to achieve this iam trying to make a wizard that can generate the files/folder structure I need as I understood that templates alone are quite limited in this aspect. I followed this tutorial: https://msdn.microsoft.com/en-us/library/ms185301.aspx.\n\nHowever when I debug this and try to create the solution it says it failed but not why or how. Breakpoints are not being hit either since the symbols are not loaded.\n\nThis is the error I get when trying to create a project using my template: \n\nWhen I comment out the WizardExtension node in the vstemplate it works fine\n\nSo how do I change my project so that it does load the symbols and I can debug it? Iam using vs2017.\n\nIncluded is my project: \nDualityTemplate\n    ", "Answer": "\r\nTurns out it was because the platform was set to Any Cpu. When I changed this to x86 it worked without problems.\n\nThis is most likely cause by the extension deciding to run in 64 bit while visual studio is only 32 bit.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Deflate length of 258 double encoding\r\n                \r\nIn Deflate algorithm there are two ways to encode a length of 258:\n\n\nCode 284 + 5 extra bits of all 1's\nCode 285 + 0 extra bits;\n\n\nOn first glance, this is not optimal, because the proper use of code 285 would allow a length of 259 be encoded;\n\nIs this duality some specification mistake, not fixed because of compatibility reasons, or there are some arguments about it - for example length of 258 must be encoded with shorter code (0 extra bits) because of some reason?\n    ", "Answer": "\r\nWe may never know.  The developer of the deflate format, Phil Katz, passed away many years ago at a young age.\n\nMy theory is that a match length was limited to 258 so that a match length in the range 3..258 could fit in a byte, encoded as 0..255.  This format was developed around 1990, when this might make a difference in an assembler implementation.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Variance of function types wrt. interfaces\r\n                \r\nI'm trying to understand the variance rules for function types. It seems they don't treat input and output the same (up to duality). Consider this program. \n\n```\nlet mk1 s = s |> Seq.iter (fun _ -> ())\n//  val mk1 : s:seq<'a> -> unit\nlet mk2 = mk1 : list<int> -> unit        // Ok. \n\nlet mk3 () = [1] \n// val mk3 : unit -> int list\nlet mk4 = mk3 : unit -> seq<int>      // Type mismatch. \n```\n\n\nThis is the error:\n\n```\nType mismatch. Expecting a\n    unit -> seq<int>    \nbut given a\n    unit -> int list    \nThe type 'seq<int>' does not match the type 'int list'\n```\n\n\nIt's my understanding that ```\nseq<int>```\n is an interface type, one which ```\nint list```\n implements, so I was expecting this cast to go through(*). \n\nTwo questions:\n\n\nWhy doesn't it?\nWhy is the cast producing ```\nmk2```\n ok?\n\n\n\n\n(*) For theorists: I was expecting the elaborator to exhibit dual behaviour on the input and output positions of the function space type constructor. Is that wrong?\n    ", "Answer": "\r\nYou have this:\n\n```\nlet mk4 = mk3  : unit -> seq<int>\n```\n\n\nWhich will not compile, the up-cast will happen automatically in the input parameter but never in the output of the function. This is in the spec, section 14.4.2 Implicit Insertion of Flexibility for Uses of Functions and Members.\n\nThis means that F# functions whose inferred type includes an unsealed type in argument position may be passed subtypes when called, without the need for explicit upcasts.\n\nThis makes possible to define another version of the function which is restricted to a subtype, which are the other cases you're showing.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "What is the difference between nullable & _Nullable [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        Difference between nullable, __nullable and _Nullable in Objective-C\r\n                            \r\n                                (4 answers)\r\n                            \r\n                    \r\n                Closed 7 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nnullable\n\nI find this syntax rather confusing:\n\n```\n- (void)doSomething:(nullable void (^)(NSArray * _Nullable transactions))successBlock\n            failure:(nullable void (^)(NSError * _Nullable error))failureBlock;\n```\n\n\n...not only because of the duality between ```\nnullable```\n and ```\n_Nullable```\n, but also because, while having the same intent, they are not interchangeable.\n\nAs found in Nullability and Objective-C:\n\n\nuse ```\nnullable```\n like you would use assertions\n```\n__nullable```\n is the old name of ```\nnullable```\n between Xcode 6.3 and 7.0\nuse ```\n_Nullable```\n where you can use ```\nconst```\n\n\n\nThis makes little sense in the example above, since I have yet to see ```\nvoid```\n defined as ```\nconst void```\n. Is there and even better version of nullable that could be used interchangeably? \n\n\n\n_Nonnull, _Null_unspecified\n\nSame puzzle.\n    ", "Answer": "\r\n```\nnullable```\n is Objective C language syntax.  ```\n_Nullable```\n is C language extension, which is inherited by Objective C.\n\nFunctions and blocks are part of the C language, so you must use ```\n_Nullable```\n in those declarations.  Objective C method and property declarations can use either Objective C's ```\nnullable```\n or C's ```\n_Nullable```\n.\n\n\n\nBy the way, C function pointer and block syntax is confusing at the best of times.  It's often a good idea to use typedefs to simplify complex situations.\n\n```\ntypedef void (^SuccessBlock)(NSArray* _Nullable transactions);\n\n- (void)doSomething:(nullable SuccessBlock)successHandler;\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How do I create a table wth both plain and robust standard errors?\r\n                \r\nI often see regression tables in publications where the plain standard errors are reported (in parentheses), together with the robust standard errors (in brackets) below the plain standard errors. The tables also include the accompanying asterisks beside the parentheses/brackets indicating statistical significance.\n\nWhat is the most sensible way to create regression reports like these? \n\nSo far, I have been using the ```\nestout```\n package in Stata. For a given model, I could have one column with the plain standard error and another with the robust one. \n\nFor example, using ```\nestout```\n, I could do the following:\n\n```\neststo: qui reg ROE duality\neststo: qui reg ROE duality, vce(cluster firm)\n\nesttab b(%9.3fc) ///                     \n       se(%9.3fc) ///\n       star (* 0.5 ** 0.25)\n```\n\n\nThe aforementioned code snippet produces:\n\n```\n--------------------------------------------\n                (1)             (2)   \n                ROE             ROE   \n--------------------------------------------\nduality       -8.090**        -8.090*   \n              (6.585)         (7.067)   \n--------------------------------------------\nN               647             647   \n--------------------------------------------\n```\n\n\nHowever, this table wastes column space as the point estimates of the two columns will be identical, with the only difference being the standard errors from the different variance-covariance estimators. \n\nWhat I would much rather have is a table like the one below:\n\n```\n ------------------------\n                (1)      \n                ROE      \n-------------------------\nduality       -8.090     \n              (6.585)** \n              [7.067]*   \n-------------------------\nN               647      \n-------------------------\n```\n\n\nNote that indication of statistical significance at 0.5 and 0.25 is for illustration here only and certainly does not reflect convention.\n    ", "Answer": "\r\nYou just need to manually add the robust standard errors:\n\n```\nsysuse auto, clear\neststo clear\n\nquietly regress price weight mpg, vce(robust)\nmatrix regtab = r(table)\nmatrix regtab = regtab[2,1...]\nmatrix rbse = regtab\n\neststo: quietly regress price weight mpg\n\nestadd matrix rbse = rbse\nesttab, cells(b se rbse)\n\n-------------------------\n                      (1)\n                    price\n                b/se/rbse\n-------------------------\nweight           1.746559\n                 .6413538\n                  .777837\nmpg             -49.51222\n                 86.15604\n                  95.8074\n_cons            1946.069\n                  3597.05\n                 4213.793\n-------------------------\nN                      74\n-------------------------\n```\n\n\nFormatting it to your specifications requires using the relevant options:\n\n```\nesttab , cells(\"b(fmt(a3) star)\" \"se(fmt(a2) par)\" \"rbse(fmt(a2) par([ ]))\") ///\nstar(* 0.5 ** 0.25)  addnote(\"Robust SE in brackets\" \"* p<0.5, ** p<0.25\") ///\nnonumbers\n\n---------------------------\n                    price  \n                b/se/rbse  \n---------------------------\nweight              1.747**\n                   (0.64)  \n                   [0.78]  \nmpg                -49.51  \n                   (86.2)  \n                   [95.8]  \n_cons              1946.1  \n                 (3597.0)  \n                 [4213.8]  \n---------------------------\nN                      74  \n---------------------------\nRobust SE in brackets\n* p<0.5, ** p<0.25\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Gurobi: Objective Value of Primal not equal to dual (transportation problem)\r\n                \r\nUsing the solution here for the transportation problem with the model:\n```\nm = Model(\"transport_problem_2\")\nflow = {}\nfor c in cities:\n    for b in bases:\n        flow[c,b] = m.addVar(obj=distance[c,b], name='flow_%s_%s' %(c,b))\nm.update()\nfor c in cities:\n    m.addConstr(quicksum(flow[c,b] for b in bases) <= supply[c], 'supply_%s' %(c))\nfor b in bases:\n    m.addConstr(quicksum(flow[c,b] for c in cities) >= demand[b], 'demand_%s' %(b))\nm.optimize()\n```\n\nFor practice, I wrote the dual of the above program in Gurobi:\n```\nm_dual = Model(\"transport_problem_2_dual\")\n\n\nalpha = m_dual.addVars(cities,name='alpha')\nbeta = m_dual.addVars(bases,name='beta')\n\nm_dual.setObjective(alpha.prod(supply)+beta.prod(demand), GRB.MAXIMIZE)\nm_dual.addConstrs((alpha[c] + beta[b] <= distance[c,b] for c,b in arcs), 'alpha_beta')\nm_dual.optimize()\n```\n\nUnfortunately, the two optimal objective values are different even though the dual is correct. (I checked it by hand using m_dual.display()). Does someone know why? I thought that the Strong Duality Theorem guarantees this property because both objective values are optimal.\nEdit: To make the dual LP work, I had to bound the variables in the dual correctly (as pointed out by the answer)\n```\nalpha = m_dual.addVars(cities,name='alpha',lb=-GRB.INFINITY) \n```\n\n    ", "Answer": "\r\nI think there may be a sign error in the variables in the dual formulation. This is what I have used:\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Lua: how to block the io library by blacklisting strings? and a sandbox dilemma\r\n                \r\nI want to block the io library so that community created scripts don't have access to it.\n\nI could simply create a Lua state without it, but here's the dilemma: community scripts should still be able to use the io library by calling loadfile() on libraries created by the dev team that have wrapped io functions in them.\n\nI found no way to achieve this duality of blocking functions/libraries from community scripts while still allowing said scripts to run the offending functions/libraries if they are wrapped (for sanitization purposes) in another dev-maintainted library which community scripts can load with loadfile(). I'm resorting to the ugly method of blacklisting certain strings so if the script has them, it doesn't run. BTW, the blacklist is checked from the C++ side where the script to run is a string variable that is fed to the VM if it's clean.\n\nIf I blacklist...\n\n```\n\"_G\", \"io.\", \"io .\", \"io}\", \"io }\", \"io  \", \"=io\", \"= io\", \"{io\", \"{ io\", \",io\", \", io\", \"  io\"\n```\n\n\n...is it still possible to call io library functions, or do I have everything covered? The reason blocking _G is a must is this:\n\n```\na = \"i\"\nb = \"o\"\nboom = _G[a..b]\n```\n\n\nI want to know if another 'hack' is possible. Also, I welcome alternatives on how I can achieve the aforementioned duality without blacklisting strings.\n    ", "Answer": "\r\nWrite your own ```\nloadfile```\n function that will check the location of the loaded files (presumably all dev-maintained libraries have a defined location) and add the ```\nio```\n library to the environment available to the loaded scripts (using ```\nenv```\n parameter in Lua 5.2+). The sandbox itself won't have access to the ```\nio```\n library, but the dev libraries will.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Double opposite histogram in ggplot\r\n                \r\nI would like to know how to do this kind of graphs using ggplot : \n\nhttps://image.noelshack.com/fichiers/2019/21/3/1558514850-plot-example2.png\n\nThis is an excel graph. I already know how to do each of the two histogram (left and right) but I don't know how to plot the two of them on the same graph, separated on the middle of the graph, with this duality.\n\nMaybe using a specific package or geom I don't know yet ? \n\nThanks for help\n    ", "Answer": "\r\nYou need to build your histogram with ```\ngeom_col()```\n, to have positive values for one groupe, négative values for the second groupe, and then use ```\ncoord_split()```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Simplest git workflow for commits signing?\r\n                \r\nWhich would be the simplest git workflow for signing some commits, in order to mark them as having passed a given review, or a set of given reviews?\n\nI suppose tagging them would create too many tags.\nCreating an intermediate repository with a person responsible for committing (effectively using author/committer duality) would be a bit of overkill.\n\nIs there any other way?\nWe generally use the common structure of remote branches for bigger chunks of work, and direct commits in master for simpler ones.\n    ", "Answer": "\r\nYou could consider rebasing those commits on top of a review branch, but that would change the SHA1 of said commit, which is bad if they are already pushed to other repos.\n\n\n  Creating an intermediate repository with a person responsible for committing \n\n\nThis is why a push to a dedicated repo is certainly a valid solution, taking advantage of the publication workflow authorized by a DVCS (Distributed Version Control System).\n\nYou can then consider that repo as the \"one referential\", with the official code (i.e. code having been successfully reviewed).\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "On linux, can I get keys to behave differently if tapped?\r\n                \r\nSo I just read a wonderful article about tricking out the modern keyboard:\n\nhttp://stevelosh.com/blog/2012/10/a-modern-space-cadet/\n\nOn of the most interesting suggestions for me is this vision of a duality for the control key:\n\n\nWhen pressed in conjunction with another key, the control key acts as it normally does.\nWhen briefly tapped, the control key sends escape.\n\n\nThis would be a big deal for me, because it would save me a significant amount of movement as I use vim.\n\nIs there any way I can implement this behavior in linux?\n    ", "Answer": "\r\nhttps://github.com/alols/xcape Xcape seems to be exactly what you're after.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Append to a list defined in a tuple - is it a bug? [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        a mutable type inside an immutable container\r\n                            \r\n                                (3 answers)\r\n                            \r\n                    \r\n                Closed 6 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nSo I have this code:\n\n```\ntup = ([1,2,3],[7,8,9])\ntup[0] += (4,5,6)\n```\n\n\nwhich generates this error:\n\n```\nTypeError: 'tuple' object does not support item assignment\n```\n\n\nWhile this code:\n\n```\ntup = ([1,2,3],[7,8,9])\ntry:\n    tup[0] += (4,5,6)\nexcept TypeError:\n    print tup\n```\n\n\nprints this:\n\n```\n([1, 2, 3, 4, 5, 6], [7, 8, 9])\n```\n\n\nIs this behavior expected?\n\nNote\n\nI realize this is not a very common use case. However, while the error is expected, I did not expect the list change. \n    ", "Answer": "\r\nYes it's expected. \n\nA tuple cannot be changed. A tuple, like a list, is a structure that points to other objects. It doesn't care about what those objects are. They could be strings, numbers, tuples, lists, or other objects.\n\nSo doing anything to one of the objects contained in the tuple, including appending to that object if it's a list, isn't relevant to the semantics of the tuple.\n\n(Imagine if you wrote a class that had methods on it that cause its internal state to change. You wouldn't expect it to be impossible to call those methods on an object based on where it's stored).\n\nOr another example:\n\n```\n>>> l1 = [1, 2, 3]\n>>> l2 = [4, 5, 6]\n>>> t = (l1, l2)\n>>> l3 = [l1, l2]\n>>> l3[1].append(7)\n```\n\n\nTwo mutable lists referenced by a list and by a tuple. Should I be able to do the last line (answer: yes). If you think the answer's no, why not? Should ```\nt```\n change the semantics of ```\nl3```\n (answer: no).\n\nIf you want an immutable object of sequential structures, it should be tuples all the way down.\n\nWhy does it error?\n\nThis example uses the infix operator:\n\n\n  Many operations have an “in-place” version. The following functions\n  provide a more primitive access to in-place operators than the usual\n  syntax does; for example, the statement x += y is equivalent to x =\n  operator.iadd(x, y). Another way to put it is to say that z =\n  operator.iadd(x, y) is equivalent to the compound statement z = x; z\n  += y.\n\n\nhttps://docs.python.org/2/library/operator.html\n\nSo this:\n\n```\nl = [1, 2, 3]\ntup = (l,)\ntup[0] += (4,5,6)\n```\n\n\nis equivalent to this:\n\n```\nl = [1, 2, 3]\ntup = (l,)\nx = tup[0]\nx = x.__iadd__([4, 5, 6]) # like extend, but returns x instead of None\ntup[0] = x\n```\n\n\nThe ```\n__iadd__```\n line succeeds, and modifies the first list. So the list has been changed. The ```\n__iadd__```\n call returns the mutated list. \n\nThe second line tries to assign the list back to the tuple, and this fails.\n\nSo, at the end of the program, the list has been extended but the second part of the ```\n+=```\n operation failed. For the specifics, see this question.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to grab rows which contain a dual id reference\r\n                \r\nI have a messages table:\n\n```\nmessages:\n    id(int)\n    send_id(int)\n    receive_id(int)\n```\n\n\nAnd I want to be able to select rows from this only when a->b and b->a exist, e.g.:\n\n```\n    id     send_id recieve_id\n    0,     15,     16\n    1,     16,     15\n```\n\n\nSo that basically one message has been passed to each person. How would I be able to go about selecting just one of those two rows (either send or receive), and all of those for a specific id. \n\nI want to only return results that have this duality.\n\nMy code currently uses a nested ```\nSELECT```\n and doesn't work at all as needed.\n    ", "Answer": "\r\nYou can achieve the result by taking advantage MySQL's ```\nLEAST```\n and ```\nGREATEST```\n built-in functions.\n\n```\nSELECT  *\nFROM    messages\nWHERE   (LEAST(send_id, recieve_id), GREATEST(send_id, recieve_id), id)       \nIN \n(\n    SELECT  LEAST(send_id, recieve_id) as x, \n            GREATEST(send_id, recieve_id) as y, \n            MAX(id) msg_ID\n    FROM    messages \n    GROUP   BY x, y\n);\n```\n\n\n\nSQLFiddle Demo\nMySQL Comparison Operator (LEAST/GREATEST)\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Reactjs: Key undefined when accessed as a prop\r\n                \r\nTools: Reactjs 0.14.0 Vanilla Flux\nI need unique identifiers for 2 reasons:\n\nChild Reconciliation\nKeeping track of what child was clicked\n\nSo let's say I have a list of messages that looks like this:\n```\n[\n    {\n      id: 1241241234,  // <-----The unique id is kept here\n      authorName: \"Nick\"\n      text: \"Hi!\"\n    },\n    ...\n]\n```\n\nAnd now I use a ```\nArray.prototype.map()```\n to create \"ownee\" component (```\nMessageListItem```\n) inside of the owner component ```\nMessageSection```\n\n```\nfunction getMessageListItem(message) {\n    return (\n        <MessageListItem key={message.id} message={message} />\n    );\n}\n\nvar MessageSection = React.createClass({\n    render: function() {\n        var messageListItems = this.state.messages.map(getMessageListItem);\n        <div>\n            {messageListItems }\n        </div>\n    }\n});\n```\n\nBut the ```\nthis.props.key```\n is undefined in the ```\nMessageListItem```\n even though I know for a fact that is was defined when it was passed down.\n```\nvar ConvoListItem = React.createClass({\n    render: function() {\n        console.log(this.props.key); // Undefined\n    }\n});\n```\n\nI'm guessing there is a reason that React is not letting ```\nkey```\n be used as a prop.\nQuestion:\nIf I can't use ```\nkey```\n as a prop, then what is the proper way to handle the duality need of keying and setting unique identifiers on a dynamic list of child elements that contain state?\n    ", "Answer": "\r\nkey and ref aren't really 'props'. They're used internally by react and not passed to components as props. Consider passing it as a prop such as 'id'.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Boost MinCut from MaxFlow\r\n                \r\nI need to get an st-MinCut of a graph. I recently started using the C++ Boost libraries, which don't seem to have that st-MinCut functionality, but the do have MaxFlow implementations and I can (in theory) make use of the MaxFlow/MinCut duality.\n\nI have gotten the \"push relabel max flow\" function working properly, but I can't figure out how to run a DFS, from the source along edges where the residual capacity are greater than 0, to get the nodes on the source side.\n\nThanks in advance.\n    ", "Answer": "\r\nYou can use filtered_graph to create a (virtual) graph that only has the edges with non-zero residual capacity (or any other criteria)\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "When using universal links, the \"continue\" calls are now only called in the SceneDelegate - can they be called in the AppDelegate?\r\n                \r\nThese days in iOS apps,\n```\nAppDelegate#willContinueUserActivityWithType```\n and\n```\nAppDelegate#continue#restorationHandlers```\n\nare simply it seems not / never? called when you click a universal link.\nInstead,\n```\nSceneDelegate#continue```\n and\n```\nSceneDelegate#willContinueUserActivityWithType```\n\nare called.\nThat's fine but,\n\nis there in fact a way to get the AppDelegate called (\"like in the old days\") rather than the SceneDelegate?  What causes the duality?  Is there a danger of them BOTH being called?\n\nare there perhaps some circumstances where SceneDelegate is NOT called, and it does revert to AppDelegate being called?\n\n\nCan you nowadays reliably rely on SceneDelegate being called with universal links, and forget about AppDelegate?\n    ", "Answer": "\r\niPadOS 13 introduced the concept of multiple windows and the scene delegate. Each window has its own separate scene and scene delegate. Apps on iPad may choose to support multiple windows/scenes. When run on iPhone, there is always only one scene (true up to and including iOS 17, but maybe one day…)\nOnce an app had been converted to use the new scene architecture as part of adding support for iOS 13, or if it was created in a version of Xcode that supported it by default, many old app delegate methods were effectively replaced by similar scene delegate methods. Some app delegate methods are still called because they refer to the entire app rather than specific windows/scenes.\nThe only way in which an app that supports the scene architecture will use the app delegate for the methods that have been superseded by scene delegate versions is if it is executed on a device running iOS/iPadOS 12 or earlier. In the few years that followed iOS 13, apps which still supported older iOS versions needed to implement both the app and scene delegate methods to handle running on pre- or post-iOS 13 devices.\nIt is possible to remove support for the scene architecture for newly-created apps but I recommend against it. We should be looking forward, not backwards.\n\nCan you nowadays reliably rely on SceneDelegate being called with universal links, and forget about AppDelegate?\n\nYes. Any method which has both scene and app delegate versions will only ever use the scene version.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Haskell: How lazy is the lazy `Control.Monad.ST.Lazy` monad?\r\n                \r\nI have been experimenting with the strict and lazy ```\nST```\n monads, and I do not understand clearly the degree of laziness of each.\nFor example, using the lazy ```\nControl.Monad.State.Lazy```\n monad we can write:\n\n```\nmain = print $ (flip evalState) \"a\" $ do\n    forever $ put \"b\"\n    put \"c\"\n    get\n```\n\n\nThis works fine and outputs ```\n\"c\"```\n. Dually, the same code for the strict ```\nControl.Monad.State.Strict```\n variant will run ```\nput \"b\"```\n forever, and hang.\n\nIntuitively, I would expect the same duality to hold for the ```\nST```\n monads. That is, given the code:\n\n```\nmain = print $ S.runST $ do\n        r <- newSTRef \"a\"\n        forever $ writeSTRef r \"b\"\n        writeSTRef r \"c\"\n        readSTRef r\n```\n\n\n```\nControl.Monad.ST.Lazy```\n should output ```\n\"c\"```\n, while ```\nControl.Monad.ST.Strict```\n should hang. However, they both loop indefinitely. I believe that there is a valid reason for this, like: reading backwards, the reference ```\nr```\n is not yet allocated at the time that the last ```\nwriteSTRef```\n is called. But it somehow feels like we could do better.\n    ", "Answer": "\r\n\n  How lazy is the lazy ```\nControl.Monad.ST.Lazy```\n monad?\n\n\nSurprisingly, it is perfectly lazy. But ```\nData.STRef.Lazy```\n isn't.\n\n```\nST.Lazy```\n is lazy\n\nLets focus on another example for a second:\n\n```\nimport qualified Control.Monad.ST as S\nimport qualified Control.Monad.ST.Lazy as L\n\nsquared :: Monad m => m [Integer]\nsquared = mapM (return . (^2)) [1..]\n\nok, oops :: [Integer]\nok   = L.runST squared\noops = S.runST squared\n```\n\n\nEven though ```\nok```\n and ```\noops```\n should do the same, we can get only the elements of ```\nok```\n. If we would try to use ```\nhead oops```\n, we would fail. However, concerning ```\nok```\n, we can take arbitrarily many elements.\n\nOr, to compare them to the non-monadic squared list, they behave like:\n\n```\nok, oops :: [Integer]\nok'   = map (^2) [1..]\noops' = let x = map (^2) [1..] in force x -- Control.DeepSeq.force\n```\n\n\nThat's because the strict version evaluates all state operations, even though they're not required for our result. On the other hand, the lazy version delays the operations:\n\n\n  This module presents an identical interface to Control.Monad.ST, except that the monad delays evaluation of state operations until a value depending on them is required.\n\n\nWhat about ```\nreadSTRef```\n?\n\nNow lets focus again on your example. Note that we can get an infinite loop with even simpler code:\n\n```\nmain = print $ L.runST $ do\n    forever $ return ()\n    r <- newSTRef \"a\"\n    readSTRef r\n```\n\n\nIf we add an additional ```\nreturn```\n at the end …\n\n```\nmain = print $ L.runST $ do\n    forever $ return ()\n    r <- newSTRef \"a\"\n    readSTRef r\n    return \"a\"\n```\n\n\n… everything is fine. So apparently there's something strict in ```\nnewSTRef```\n or ```\nreadSTRef```\n. Lets have a look at their implementation:\n\n```\nimport qualified Data.STRef as ST\n\nnewSTRef        = strictToLazyST . ST.newSTRef\nreadSTRef       = strictToLazyST . ST.readSTRef\nwriteSTRef  r a = strictToLazyST (ST.writeSTRef r a)\n```\n\n\nAnd there's the culprit. ```\nData.STRef.Lazy```\n is actually implemented via ```\nData.STRef```\n, which is meant for ```\nControl.Monad.ST.Strict```\n. ```\nstrictToLazyST```\n only hides this detail:\n\n\n```\nstrictToLazyST :: ST.ST s a -> ST s a\nstrictToLazyST m = ST $ \\s ->\n```\n\n  \n  Convert a strict ST computation into a lazy one. The strict state thread passed to ```\nstrictToLazyST```\n is not performed until the result of the lazy state thread it returns is demanded.\n\n\nNow lets put things together:\n\n\nin ```\nmain```\n, we want to ```\nprint```\n the value given by the lazy ```\nST```\n computation\nthe lazy ```\nST```\n computation's value is given by a lazy ```\nreadSTRef```\n\nthe lazy ```\nreadSTRef```\n is actually implemented as a lazy wrapper around the strict ```\nreadSTRef```\n\nthe strict ```\nreadSTRef```\n evaluates the state as if it was a strict one\nthe strict evaluation of ```\nforever $ return ()```\n bites us\n\n\nSo the current ```\nST.Lazy```\n is lazy enough. It's the ```\nData.STRef.Lazy```\n that's too strict. As long as ```\nData.STRef.Lazy```\n is based on ```\nstrictToLazyST```\n, this behavior will endure.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Why classes implicitly derive from only the Object Class? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is off-topic. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.\r\n                \r\n                    \r\n                        Closed 10 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI do not have any argument opposing why we need only a single universal class. However why not we have two universal classes, say an Object and an AntiObject Class. \nIn nature and in science we find the concept of duality - like Energy & Dark Energy; Male & Female; Plus & Minus; Multiply & Divide; Electrons & Protons; Integration & Derivation; and in set theory. There are so many examples of dualism that it is a philosophy in itself. In programming itself we see Anti-Patterns which helps us to perform work in contrast to how we use Design patterns. \nWe call it object-oriented programming. Is that a limiting factor or is there something fundamental I am missing in understanding the formation of programming languages?\n\nEdit: \nI am not sure, but the usefulness of this duality concept may lie in creating garbage collectors that create AntiObjects that combine with free or loose Objects to destruct themselves, thereby releasing memory. Or may be AntiObjects work along with Objects to create a self-modifying programming language - that allows us to create a safe self modifying code, do evolutionary computing using genetic programming, do hiding of code to prevent reverse engineering.\nI've moved this question to Computer Science Site of Stack Exchange, as this is considered off-topic here. Please use that if you want to comment/answer this question.\n    ", "Answer": "\r\nThe inheritance tree is commonly (as it is in C#) a tree, with a single root, for a number of reasons, which all seem to lead back to one big one:\n\n\nIf there were multiple roots, there wouldn't be a way to specify \"any type of object\" (aside from something like C++'s ```\nvoid *```\n, which would be hideous as it tosses away any notion of \"type\").\nEven the idea of \"any type of object\" loses some usefulness, as you can no longer guarantee anything about the objects you'll be accepting.  How do you say \"all objects have properties a, b, and c\" in such a way as to let programs actually use them?  You'd need an interface that all of them implement...and then, that interface becomes the root type.\nGC'able languages would be useless if they couldn't collect every type of object they manage.  Oops, there goes that \"any type of object\" again!\n\n\nAll-around, it's simpler to have one type be the root of the hierarchy.  It lets you make contracts/guarantees/etc that apply to every object in the system, and makes fewer demands on code that wants to be able to deal with objects in a universal manner.\n\nC++ gets away with having multiple root types because (1) C++ allows multiple inheritance, so objects can bridge the gaps between inheritance trees; (2) it has templates (which are far, far more able than generics to take any type of object); (3) it can discard and sidestep any notion of \"type\" altogether via means like ```\nvoid *```\n; and (4) it doesn't offer to manage and collect your objects for you.\n\nC# didn't want all the complexity of multiple inheritance and templates, and it wanted garbage collection.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Why does Node often us a different module system from browsers?\r\n                \r\nI was considering updating my Node/Express code to use ```\nimport```\n instead of ```\nrequire```\n by adding to my package.json file the line:\n```\n  \"type\": \"module\",\n```\n\nHowever, I did not know why most Node/Express code I see, still uses ```\nrequire```\n while code I see in the browser via webpack uses import.\nIs there a reason for this duality?  Is upgrading to import recommended in general?  Is import because it is newer considered an upgrade and a better technology?\nThis previous Q/A is over 7 years old and has lot of historical information.  I am looking for more current information as the language has evolved.\n    ", "Answer": "\r\nThe reason for having two types of modules is purely historical.\nBack in 2009 when Node.js was created, ES modules (```\nimport```\n syntax) did not exist yet, but there existed other nonstandard alternatives, with the most important being AMD and CommonJS, for which several browser implementations were available. Node.js decided to adopt CommonJS (```\nrequire```\n syntax). For this reason, all packages deployed up until 2015 are CommonJS packages.\nNative ES modules were introduced with the ECMAScript 2015 standard, but they only made it as an experimental technology in Node.js 8.5 in 2017, and it wasn't until Node.js 12 (2019) that their support became good enough to place them as an alternative to CommonJS (although this is subjective).\nFor this reason, a large part of software developed for Node.js still uses CommonJS modules with ```\nrequire```\n statements.\nWhether ES modules are better is a matter of opinion, and not a proper question for StackOverflow. At least, they are standard JavaScript, which makes them fit for use both in browsers and in Node.js, which is imo a big advantage.\nA disadvantage is that ES modules cannot be required in CommonJS code - the opposite is true: CommonJS modules can be imported by ES modules - so if any of your dependencies uses ES modules, that may be a good opportunity to switch your code to ES modules, too.\nSo should we upgrade to use ```\nimport```\n in general? Of course, that's also a matter of opinion. And if that was my opinion, the answer would be \"no\", because there is no reason to change a running system. CommonJS code is not going to rust or worsen simply because a better alternative exists nowadays, although ES modules are a better choice for new code. Node.js, as long as people use it, is not going to drop support for CommonJS either.\nThere is a project called Deno which is designed to provide a more modern and secure alternative to Node.js to run JavaScript code on the server. Deno was originally designed to work with ES modules only, but it soon became clear that not supporting CommonJS modules was a major issue, because so many npm packages were not working, so it introduced a compatibility mode to support CommonJS modules under a flag. The moral of the story is: removing support for ```\nrequire```\n is good idea, but re-adding it is an even better one.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Efficient PairRDD operations on DataFrame with Spark SQL GROUP BY\r\n                \r\nThis question is about the duality between ```\nDataFrame```\n and ```\nRDD```\n when it comes to aggregation operations. In Spark SQL one can use table generating UDFs for custom aggregations but creating one of those is typically noticeably less user-friendly than using the aggregation functions available for RDDs, especially if table output is not required.\n\nIs there an efficient way to apply pair RDD operations such as ```\naggregateByKey```\n to a DataFrame which has been grouped using GROUP BY or ordered using ORDERED BY?\n\nNormally, one would need an explicit ```\nmap```\n step to create key-value tuples, e.g., ```\ndataFrame.rdd.map(row => (row.getString(row.fieldIndex(\"category\")), row).aggregateByKey(...)```\n. Can this be avoided?\n    ", "Answer": "\r\nNot really. While ```\nDataFrames```\n can be converted to ```\nRDDs```\n and vice versa this is relatively complex operation and methods like ```\nDataFrame.groupBy```\n don't have the same semantics as their counterparts on ```\nRDD```\n.\n\nThe closest thing you can get is a new ```\nDataSet```\n API introduced in Spark 1.6.0. It provides a much closer integration with ```\nDataFrames```\n and  ```\nGroupedDataset```\n class with its own set of methods including ```\nreduce```\n, ```\ncogroup```\n or ```\nmapGroups```\n:\n\n```\ncase class Record(id: Long, key: String, value: Double)\n\nval df = sc.parallelize(Seq(\n    (1L, \"foo\", 3.0), (2L, \"bar\", 5.6),\n    (3L, \"foo\", -1.0), (4L, \"bar\", 10.0)\n)).toDF(\"id\", \"key\", \"value\")\n\nval ds = df.as[Record]\nds.groupBy($\"key\").reduce((x, y) => if (x.id < y.id) x else y).show\n\n// +-----+-----------+\n// |   _1|         _2|\n// +-----+-----------+\n// |[bar]|[2,bar,5.6]|\n// |[foo]|[1,foo,3.0]|\n// +-----+-----------+\n```\n\n\nIn some specific cases it is possible to leverage ```\nOrderable```\n semantics to group and process data using ```\nstructs```\n or ```\narrays```\n. You'll find an example in SPARK DataFrame: select the first row of each group\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "LassoCV results depend on the number of inputvariables?\r\n                \r\nI want to perform variable selection using Lasso regression, as I am not sure how many (lagged) variables X still have an effect on my variable y.\nHowever, the resulting model, and also which variables end up being zero, is different for different amounts of inputvariables.\nFor example, I have n=295 observations. If I use LassoCV on 10 lagged input variables, I get that the 5th lag is 0. If I only use 8 lagged input variables, the 4th lag might turn out 0. So my variable selection is dependent on the number of variables I start with, and I therefore think the result can't be trusted. What am I doing wrong?\nSince in my application n>p, I don't think it has to do with multiple minima in the Lasso criterion. I do get ConvergenceWarnings very often, so I increased my number of iterations and tolerance.\nI am not very familiar with the duality gap, it does seem very large. Maybe the error lies here?\nConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31069.631120879843, tolerance: 12362.796494481028\nmodel = cd_fast.enet_coordinate_descent_gram(\nMy code in python:\n```\nimport numpy as np\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.model_selection import TimeSeriesSplit\n\nn_lambs = 50\n    cv = TimeSeriesSplit(\n        n_splits=5,\n        gap=0\n    )\n\nmodel = LassoCV(\n        alphas=np.logspace(-4, 2, n_lambs),\n        fit_intercept=True,\n        cv=cv,\n        n_jobs=-1,\n        max_iter=1000000,\n        tol=0.001\n        )\n\nfit = model.fit(X_train, y_train)\n\n```\n\nIn this code, I vary my X_train variable to have different amounts of lags.\n(By the way, any suggestions on different variable selection methods would be appreciated too.)\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "What are the names used in computer science for some of the following tree data types?\r\n                \r\nSometimes I get myself using different types of trees in Haskell and I don't know what they are called or where to get more information on algorithms using them or class instances for them, or even some pre-existing code or library on hackage. \n\nExamples:\n\nBinary trees where the labels are on the leaves or the branches:\n\n```\ndata BinTree1 a = Leaf | \n                  Branch {label :: a, leftChild :: BinTree1 a, rightChild :: BinTree1 a}\n\ndata BinTree2 a = Leaf {label :: a} | \n                  Branch {leftChild :: BinTree2 a, rightChild :: BinTree2 a}\n```\n\n\nSimilarly trees with the labels for each children node or a general label for all their children:\n\n```\ndata Tree1 a = Branch {label :: a, children :: [Tree1 a]}\n\ndata Tree2 a = Branch {labelledChildren :: [(a, Tree2 a)]}\n```\n\n\nSometimes I start using ```\nTree2```\n and somehow on the course of developing it gets refactored into ```\nTree1```\n, which seems simpler to deal with, but I never gave a lot of thought about it. Is there some kind of duality here?\n\nAlso, if you can post some other different kinds of trees that you think are useful, please do. \n\nIn summary: everything you can tell me about those trees will be useful! :)\n\nThanks.\n\nEDIT: \n\nClarification: this is not homework. It's just that I usually end up using those data types and creating instances (Functor, Monad, etc...) and maybe if I new their names I would find libraries with stuff implemented and more theoretical information on them.\n\nUsually when a library on Hackage have Tree in the name, it implements BinTree2 or some version of a non-binary tree with labels only on the leaves, so it seems to me that maybe Tree2 and BinTree2 have some other name or identifier.\n\nAlso I feel that there may be some kind of duality or isomorphism, or a way of turning code that uses Tree1  into code that uses Tree2 with some transformation. Is there? May be it's just an impression.\n    ", "Answer": "\r\nThe names I've heard:\n\n\n```\nBinTree1```\n is a binary tree\n```\nBinTree2```\n don't know a name but you can use such a tree to represent a prefix-free code like huffman coding for example\n```\nTree1```\n is a Rose tree\n```\nTree2```\n is isomoprhic to ```\n[Tree1]```\n (a forest of ```\nTree1```\n) or another way to view it is a ```\nTree1```\n without a label for the root.\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Git on Windows: \"merging\" 2 directories with the same name but different case\r\n                \r\nThe word \"merge\" does not refer to a git merge, but just moving all the files to the same directory.  \n\nWe somehow came to have two directories with the same name but different cases in our git repository. Windows is case-insensetive in this respect so it works fine just checking out all the files from both directories into one directory on disk.\n\nStill would like to get rid of this \"duality\"\n\nIs there a way to fix this using Windows git clients?\n\nI've tried git mv, but it appears to be case insensetive. I expected it to move only the files that are under the lowercase version of the directory but it moved both directories.\n    ", "Answer": "\r\nThis worked for me:\n\n```\ngit mv myfolder tmp_folder\ngit mv tmp_folder MyFolder\n```\n\n\nEven though it initially removed  ```\nMyFolder```\n and moved all the files under ```\ntmp_folder```\n after issuing the second ```\nmv```\n it worked as expected staging renames for the files in ```\nmyfolder```\n to be moved to ```\nMyFolder```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "ObjectiveC test if int is long or not / CGFloat is float or double\r\n                \r\nApple now requires all iOS code to be 32/64 bit dualistic. That's great - except there's a few of their libraries that don't fully support the duality.\n\ne.g. one project uses NSScanner, which supports \"scanInteger\" (correct) but no \"scanCGFloat\" - instead you have to \"scanFloat\" or \"scanDouble\" (encoded in the method names!).\n\n\n\nUPDATE: NSScanner is a nastier example than I realised; it takes pointers as args.\n\n```\n- (BOOL)scanFloat:(float *)result;\n- (BOOL)scanDouble:(double *)result;\n```\n\n\n...ugh.\n\n\n\nIt affects a whole bunch of stuff - another example is math.h (similarly: float vs double is encoded in function names), although there you can at least switch to tgmath.h and get rid of the \"type-is-in-the-name\" silliness.\n\nWhat's the correct, general, solution to this problem?\n    ", "Answer": "\r\nC11 has introduced a new feature \"Generic selection\" that can be used to \nlet the compiler choose the right method, depending on the type of ```\nCGFloat```\n.\n\nWritten as a ```\nNSScanner```\n category method:\n\n```\n@implementation NSScanner (MyCategory)\n\n-(BOOL) myScanCGFloat:(CGFloat *)cgFloatValue\n{\n    return _Generic(*cgFloatValue,\n                    double: [self scanDouble:(double *)cgFloatValue],\n                    float: [self scanFloat:(float *)cgFloatValue]);\n}\n\n@end\n```\n\n\nRemarks:\n\n\nThe ```\n_Generic```\n keyword is described in \"6.5.1.1 Generic selection\" of the C11 standard (http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf). Another description is here:\nhttp://www.robertgamble.net/2012/01/c11-generic-selections.html. \nSelecting the matching code is done by the compiler, not at runtime.\nThe selection checks if ```\nCGFloat```\n is compatible to ```\nfloat```\n or ```\ndouble```\n,\nnot if the current target architecture is 32-bit or 64-bit.\nThis solution does not depend on any preprocessor macros.\nAs of Xcode 5.0.2, Clang supports the ```\n_Generic```\n keyword, even in the default GNU99 mode. I have not tested earlier Xcode/Clang versions.\n\n\n\n\nPrevious answer: One possible solution would be do mimic the definition of ```\nCGFloat```\n\nand let the preprocessor choose the correct version:\n\n```\nCGFloat f;\n\n#if __LP64__\n    [scanner scanDouble:&f];\n#else\n    [scanner scanFloat:&f];\n#endif\n```\n\n\nOr you define a custom macro:\n\n```\n#if __LP64__\n#define scanCGFloat scanDouble\n#else\n#define scanCGFloat scanFloat\n#endif\n\n// ...\nCFFloat f;\n[scanner scanCGFloat:&f];\n```\n\n\nAlternatively, use a temporary variable:\n\n```\ndouble tmp;\n[scanner scanDouble:&tmp];\nf = tmp;\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Get Ext JS association, inheritance and store to work\r\n                \r\nThis is a simple use case for storing one to many (or even one to one) that has inheritance.  How does Ext JS handle this with it's JSON reader?\n\nThe following code provides few pseudo models and data to illustrate the use case:\n\npseudo code example:\n\n```\nModels:\n\nCar {\n  model,\n  year,\n  color\n}\n\nTruck extends Car {\n  bedLength,\n  duality\n}\n\nVan extends Car {\n  leftSlideDoor,\n  rightSlideDoor,\n  tailGate\n}\n\nCarOwner {\n  name,\n  cars <Car>\n}\n\nData:\n\ncarOwners:\n\n[\n{\n  name: \"Sencha\",\n  cars: [\n   {\n    color: \"Brown\",\n    model: \"Mater\"\n    type: \"truck\",\n    duality: \"false\",\n    bedLength: \"10\"\n    },\n    {\n    color: \"red\",\n    model: \"sienna\",\n    type: \"van\",\n    tailGate: \"true\",\n    leftSlideDoor: \"true\",\n    rightSlideDoor: \"true\"\n    }\n  ]\n}\n]\n```\n\n\nWhen the data is loaded, a \"correct\" type of Cars are instantiated and loaded.\nHow can this be done in Ext JS?\n    ", "Answer": "\r\nFrom an OO perspective what you've described doesn't work. Your car owner has a collection of 'cars' but the types you are trying to use in your data are not cars, they extend cars. In c# your ```\ncarOwner```\n might contain ```\nList<ICar>```\n and whilst that would enable you to store trucks and vans, but you'd only be able to use the properties of the ICar interface (as those are the only shared properties).\n\nI would suggest in that example that if the properties are variable you either setup you car own like this:\n\n```\nCarOwner {\n  name,\n  cars <Car>\n  vans <Van>\n  trucks <Trucks>\n}\n```\n\n\nOr you could describe your data as 'Vehicles' and make that object generic enough to  include all the possible properties.\n\nAs a side note, if you were purely after en example of a 'association' in Ext and the car/van/truck thing was hypothetical, reply to this and I'll drop one over.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "jQuery difference for slider on Chrome, Firefox, and IE\r\n                \r\nThis is a general question on how to debug browser specific quirks. \n\nI have a site:\nhttp://calpolyaias.com/portfolio/scalar-duality#\n\nThis is the code that runs the slider:\n\n```\n<script type=\"text/javascript\">\n    function init_jquery_swipe(){\n        /*If there are no slides, hide slider*/\n        if(!jQuery(\".project-slider\").find(\"li\").length){\n            jQuery(\".project-slider\").hide();\n            return true;\n        }\n        /*If there are no slides, hide slider*/\n\n        jQuery(\".project-slider,.project-slider *\").removeAttr(\"style\");\n\n        var projectWidth = jQuery('.project-content-top').width();\n        jQuery('.project-slider ul li').css('width', projectWidth); /*KV CHANGED*/\n\n        /*var imagesHeight = jQuery('.project-slider ul li').find('img').height();\n        jQuery('.project-slider').css('height', imagesHeight);*/\n        var img_height = [];\n        jQuery('.project-slider ul li').find('img').each(function(el){\n            img_height.push(parseInt(jQuery(this).height()));\n        });\n        img_height = Math.min.apply(null,img_height);\n        //jQuery('.project-slider').css('height', img_height+\"px\");\n\n        var slideWidth = jQuery('.project-slider ul li').width();\n        var currentSlide = 0;\n        var maxSlides =  jQuery('.project-slider ul li').length;\n        var speed = 500;\n\n        var slides;\n        slides = jQuery(\".project-slider ul\");\n        if( /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent) ) {\n            slides.swipe( {\n                triggerOnTouchEnd : true,\n                swipeStatus : swipeStatus,\n                allowPageScroll:\"vertical\",\n                threshold:75\n            } );\n            jQuery(\".slider-arrows\").hide();\n        }\n\n        function swipeStatus(event, phase, direction, distance) {\n            if( phase==\"move\" && (direction==\"left\" || direction==\"right\") )\n            {\n                if(direction==\"left\" || direction==\"right\"){\n                    event.preventDefault();\n                    event.stopPropagation();\n                }\n                var duration=0;\n\n                if (direction == \"left\")\n                    scrollImages((slideWidth * currentSlide) + distance, duration);\n\n                else if (direction == \"right\")\n                    scrollImages((slideWidth * currentSlide) - distance, duration);\n\n            }\n\n            else if ( phase == \"cancel\")\n            {\n                scrollImages(slideWidth * currentSlide, speed);\n            }\n\n            else if ( phase ==\"end\" )\n            {\n                if (direction == \"right\")\n                    previousImage()\n                else if (direction == \"left\")\n                    nextImage()\n            }\n        }\n\n        function previousImage()\n        {\n            currentSlide = Math.max(currentSlide-1, 0);\n            scrollImages( slideWidth * currentSlide, speed);\n            jQuery('.project-slider ul li').eq(currentSlide).find('img').css('opacity', 1);\n            jQuery('.project-slider ul li').eq(currentSlide).next().find('img').css('opacity', 0.3);\n        }\n\n        function nextImage()\n        {\n            currentSlide = Math.min(currentSlide+1, maxSlides-1);\n            scrollImages( slideWidth * currentSlide, speed);\n            //jQuery('.project-slider ul li').eq(currentSlide).next().find('img').css('opacity', 1);\n            jQuery('.project-slider ul li').eq(currentSlide).find('img').css('opacity', 1);\n            jQuery('.project-slider ul li').eq(currentSlide).prev().find('img').css('opacity', 0.3);\n        }\n\n        function scrollImages(distance, duration){\n\n            slides.css(\"-webkit-transition-duration\", (duration/1000).toFixed(1) + \"s\");\n            slides.css(\"-moz-transition-duration\", (duration/1000).toFixed(1) + \"s\");\n            slides.css(\"-o-transition-duration\", (duration/1000).toFixed(1) + \"s\");\n            slides.css(\"-ms-transition-duration\", (duration/1000).toFixed(1) + \"s\");\n\n            var value = (distance<0 ? \"\" : \"-\") + Math.abs(distance).toString();\n            slides.css(\"-webkit-transform\", \"translate3d(\"+value +\"px,0px,0px)\");\n            slides.css(\"-moz-transform\", \"translate3d(\"+value +\"px,0px,0px)\");\n            slides.css(\"-o-transform\", \"translate3d(\"+value +\"px,0px,0px)\");\n            slides.css(\"-ms-transform\", \"translate3d(\"+value +\"px,0px,0px)\");\n            if(!Modernizr.csstransforms3d){\n                jQuery(\".slider-holder\").scrollLeft(Math.abs(value));\n            }\n        }\n\n        /*var projectWidth = jQuery('.project-content-top').width();\n        jQuery('.project-slider ul li').css('width', projectWidth);\n        jQuery('.project-slider ul li').css('height', img_height - 65);\n\n        jQuery('.project-slider').css('height', img_height);\n        jQuery('.slider-holder').css('height', img_height - 65);*/\n\n        var sliderImgHeight = jQuery('.project-slider').height();\n        //jQuery('.project-slider ul').find('li iframe').css('height', sliderImgHeight);\n        //jQuery('.slider-holder .slider-arrows a.next-slide').css('left', 500px); /*KV */ \n        //window.alert(jQuery('.slider-holder .slider-arrows a.next-slide').css('left'));\n\n        jQuery('body').on('click', '.slider-arrows a.next-slide', function(e){\n            e.preventDefault();\n            nextImage();\n        });\n\n        jQuery('.slider-holder').on('click', function(e){\n            e.preventDefault();\n            nextImage();\n        });\n\n\n\n        jQuery('body').on('click', '.slider-arrows a.prev-slide', function(e){\n            e.preventDefault();\n           previousImage();\n        });\n\n        jQuery('.project-slider ul li img').imgscale({\n            scale : 'fit',\n            center : true\n        });\n        center_image();\n        function center_image(){\n            jQuery('.project-slider ul li').find('img').each(function(){\n                var this_img = jQuery(this);\n\n                var parent_width = parseInt(this_img.parent().width() / 2);\n                var this_img_width = parseInt(this_img.width() / 2);\n\n                var parent_height = parseInt(this_img.parent().height() / 2);\n                var this_img_height = parseInt(this_img.height() / 2);\n\n                this_img.css(\"margin-left\",(parent_width - this_img_width) + \"px\");\n                this_img.css(\"margin-top\",(parent_height - this_img_height) + \"px\");\n            });\n        }\n    }\n\n    jQuery('#inner-content').waitForImages( function() {\n        jQuery(\".project-slider ul\").swipe(\"destroy\");\n        init_jquery_swipe();\n        jQuery(\"a[rel='fancybox_gallery']\").fancybox();\n    });\n\n    jQuery(window).resize(function() {\n        jQuery(\".project-slider ul\").swipe(\"destroy\");\n        init_jquery_swipe();\n    });\n\n    jQuery(document).ready(function($){\n        $('.accordion li:first-child').find('a').addClass('active').find('i').removeClass('icon-plus-sign').addClass('icon-minus-sign');\n        $('.accordion li:first-child').find('.section_content').show();\n\n        $('.tabs .tab_buttons > li:first-child').find('a').addClass('active');\n        $('.tabs .tab_content li:first-child').show();\n    });\n\n\n</script>\n```\n\n\nOn Chrome, the images from the slider disappear while the slider works perfectly on IE and Firefox. \n\nWhat are the known difference for chrome and how it treats jQuery-- where do I start looking?\n\nIn general, what is a good procedure for me to follow to nail this one and bugs like it?\n\nSomething interesting is that changing the window size (opening developer tools in chrome) seems to stop the problem however.\n\nThe wordpress theme is called NORDIC if you want to try pinning down the difference between this site and the original template... \n    ", "Answer": "\r\nTry to remove this: \n\n```\ntransition: opacity .5s;\n-webkit-transition: opacity .5s;\n```\n\n\nfrom ```\n.project-slider ul li img```\n. \n\nor Try this:\n\n```\ntransition: all .5s;\n-webkit-transition: all .5s;\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Getting the number of branch and bound nodes explored CPLEX\r\n                \r\nSo I'm curious how to get the number of branch and bounds nodes explored. I was interested in this to gage how hard solving my IP is - if there is a better metric for this please feel free to share.\n\nI tried to use \n\n```\nmy_prob.solution.MIP.get_incumbent_node()\n```\n\n\nwhich from the CPLEX documentation gives the node number which the solution was found - which I would think would be a good gage of number of nodes explored. But it always returns 0, I attached an example where the input (guess) solution and the output are different. I would expect it to be 0 only if the input solution was the global optimimal solution (the root node found strong duality).\n\nHere is a small example:\n\nThank you\n\n```\nimport cplex\nfrom cplex.exceptions import CplexError\n\n# my_prob = cplex.Cplex()\n\n# print(dir(my_prob))\n# print(\"-----------\")\n# print(dir(my_prob.solution))\n# print(my_prob.solution.get_status_string())\n# print(my_prob.solution.get_status())\n# print(my_prob.solution.get_method())\n\n\n\nclass knapsack:\n    def __init__(self,N,g,square_list,density_list,cs,dx,number_squares):\n        self.N = N\n        self.square_list= square_list\n        self.g = g\n        self.nummats= len(density_list)\n        self.numlist=[]\n        self.cs=cs\n        self.number_squares=number_squares\n        self.dx=dx\n        self.density_list=density_list\n    def solve_problem(self):\n        number_squares=self.number_squares\n        square_list=self.square_list\n        nummats=self.nummats\n        density_list=self.density_list\n        dx=self.dx\n        #lol_print([number_squares,square_list,nummats,density_list,dx])\n\n        try:\n            my_prob = cplex.Cplex()\n            prob =my_prob\n            prob.set_log_stream(None)\n            prob.set_error_stream(None)\n            prob.set_warning_stream(None)\n            prob.set_results_stream(None)\n            my_obj = self.g\n            my_ctype = \"B\"\n            number_of_one = self.square_list.count(1.0)\n            my_ctype = my_ctype*len(self.square_list)\n            val = self.N  -number_of_one\n\n            val2=self.cs\n\n            #print(val)\n            #print(len(self.g))\n            #print(len(self.square_list))\n            rhs=[val]\n            my_sense=\"L\"\n            my_rownames = [\"r1\"]\n\n            counter =0\n            variable_list=[]\n            coiff_list=[]\n            coiff_den =[]\n            for k in range(0,number_squares):\n                sub_slice = square_list[k*nummats:k*nummats+nummats]\n                #print(sub_slice)\n                #print(len(sub_slice))\n                temp1=[0]*nummats\n                temp2 = sub_slice\n\n                for j in range(0,len(sub_slice)):\n                    temp1[j] = density_list[j]*dx**2\n\n                    if(temp2[j]==0):\n                        temp2[j] = 1.0\n                    else:\n                        temp2[j]=-1.0\n                    variable_list.append(str(counter))\n                    self.numlist.append(counter)\n                    counter+=1\n\n                coiff_den = coiff_den + temp1\n                coiff_list  = coiff_list + temp2 \n            #print(square_list)\n            #print(coiff_den)\n            #print(coiff_list)\n\n            rhs2 =[val2]\n            #print(\"got here\")\n            rows = [[variable_list, coiff_list]]\n            rows2  =[[variable_list,coiff_den]]\n            prob.objective.set_sense(prob.objective.sense.minimize)\n\n            prob.variables.add(obj=my_obj, types=my_ctype,\n                        names=variable_list)\n            prob.linear_constraints.add(lin_expr=rows, senses=my_sense,\n                                    rhs=rhs)\n            prob.linear_constraints.add(lin_expr=rows2, senses=my_sense,rhs=rhs2)\n\n            for i in range(0,number_squares):\n                sos_var = variable_list[i*nummats:i*nummats+nummats]\n                num_var = self.numlist[i*nummats:i*nummats+nummats]\n                #print((sos_var,num_var))\n                prob.SOS.add(type=\"1\", SOS=[sos_var, num_var])\n\n\n\n            my_prob.solve()\n            x = my_prob.solution.get_values()\n            my_prob.solution.write(\"myanswer\")\n            #print(x)\n            #print(my_prob.solution.get_status_string())\n            #print(my_prob.solution.get_quality_metrics())\n            #print(dir(my_prob.solution.MIP))\n            #print(my_prob.solution.MIP.get_incumbent_node())\n            #print(my_prob.get_stats())\n            print(\"starting\" + str(square_list))\n            print(\"solution :\" + str(x))\n            print(\"what I think returns number of nodes (wrong): \" + str(my_prob.solution.MIP.get_incumbent_node()))\n            #print(my_prob.solution.get_integer_quality())\n            #print(self.cs)\n            mysum=0.0\n            for k in range(0,number_squares):\n                sub_slice = x[k*nummats:k*nummats+nummats]\n\n                for j in range(0,len(sub_slice)):\n                    mysum = mysum+sub_slice[j]*density_list[j]*dx**2\n            #print(mysum)\n            #print(self.cs)\n            #print(coiff_den)\n\n\n            return (x,my_prob.solution.get_status_string())\n        except CplexError as exc:\n            #print(exc)\n            mysum=0.0\n            for k in range(0,number_squares):\n                sub_slice = square_list[k*nummats:k*nummats+nummats]\n\n                for j in range(0,len(sub_slice)):\n                    mysum = mysum+sub_slice[j]*density_list[j]*dx**2\n            #print(mysum)\n            #print(self.cs)\n            return None\n\ndef lol_print(arr):\n    for k in arr:\n        print(k)   \n\n\nlol = knapsack(2,[1,-1,-1,-1,],[0,0,0,0],[1,2],10.0,.1,2)\nlol.solve_problem() \n```\n\n    ", "Answer": "\r\nIf you comment out the following code, the engine log will be shown on stdout:\n\n```\n    prob.set_log_stream(None)\n    prob.set_error_stream(None)\n    prob.set_warning_stream(None)\n    prob.set_results_stream(None)\n```\n\n\nAnd, the engine log, looks like this:\n\n```\nVersion identifier: 12.10.0.0 | 2019-11-26 | 843d4de\nCPXPARAM_Read_DataCheck                          1\nFound incumbent of value 0.000000 after 0.00 sec. (0.00 ticks)\nMIP Presolve eliminated 1 redundant SOS constraints.\nTried aggregator 1 time.\nMIP Presolve eliminated 2 rows and 2 columns.\nReduced MIP has 0 rows, 2 columns, and 0 nonzeros.\nReduced MIP has 2 binaries, 0 generals, 1 SOSs, and 0 indicators.\nPresolve time = 0.00 sec. (0.00 ticks)\nProbing time = 0.00 sec. (0.00 ticks)\nTried aggregator 1 time.\nMIP Presolve eliminated 1 rows and 2 columns.\nAll rows and columns eliminated.\nPresolve time = 0.00 sec. (0.00 ticks)\n\nRoot node processing (before b&c):\n  Real time             =    0.00 sec. (0.01 ticks)\nParallel b&c, 8 threads:\n  Real time             =    0.00 sec. (0.00 ticks)\n  Sync time (average)   =    0.00 sec.\n  Wait time (average)   =    0.00 sec.\n                          ------------\nTotal (root+branch&cut) =    0.00 sec. (0.01 ticks)\n```\n\n\nFrom that we can see that the solution was found in presolve (branch and bound was not needed), so ```\nmy_prob.solution.MIP.get_incumbent_node()```\n is returning the correct result.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Bounding Box of the Line Arrangement in O(n log n) time\r\n                \r\nI want to compute the bounding box of a line arrangement (with no parallel lines). The bounding box should contain all intersections of the line arrangement.\n\nI have done some research and found several times that computing the bounding box should be possible in O(n log n) time. Unfortunately I was not able to find the source of this claim. \n\nI tried to come up with an algorithm that solves this problem in O(n log n) time but was not able so far. I tried to use duality to compute the envelopes but unfortunately the envelopes do not always contain the lowest and highest intersection.\n\nI would appreciate if someone know where to find such an algorithm or how it works.\n    ", "Answer": "\r\nIt is possible to do it in O(n log n) time. We don't have to check every intersection, we just need to find the ones with highest/lowest x and y-coordinate.\n\nHere's what I came up with. I think we are in the same lecture, and this is pretty much exactly what I am going to hand in, so please don't just copy paste it, if you want to use this solution.\n\nAlgorithm for left bound:\n\n1) Make lines into points according to point-line duality l:y = mx + c => l* = (m, -c). O(n)\n\n2) Order them by x-coordinate. O(n log n)\n\n3) Save line of first two points as line with lowest slope. O(1)\n\n4) Go through points and if a line of two points P[i] and P[i+1] has lower slope than previously saved lowest slope, save that line as line with lowest slope. O(n)\n\n5) Make the line into a point, using duality again. O(1)\n\n6) Return x-coordinate of that point as left bound. O(1)\n\nThe line with the lowest slope represents the intersection point with the lowest x-coordinate. Right bound works the same but with highest slope. In order to get an algorithm for upper and lower bound we can change the duality to l:y = mx + c => l* = (-c, m) (basically turning the plane 90 degrees) in order to be able to determine the lowest and highest intersection points by looking at the slopes as well.\n\nWe don't have to look at all intersection points of lines in order to find the steepest slope, looking at lines that are next to each other according to x-coordinate is enough.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "(Yet Another) 'ImportError: No module named my_module'\r\n                \r\nOk, I stripped the code to ultra minimal to illustrate the problem and make it reproducible\ncontext :\n\nPython 3.7\nNo VENV or funny stuff\n\nTalk is cheap. Show you the code :\ncode structure :\n```\n$ tree pymod/\npymod/\n├── modone\n│   ├── __init__.py\n│   └── one.py\n└── modtwo\n    ├── __init__.py\n    └── two.py\n```\n\ninit.py is everywhere where it should be, obviously\none.py :\n```\nfrom modtwo import two\nclass One():\n    @staticmethod\n    def print_one():\n        print(\"this is one\")\n        two.print_two()\n\nif __name__ == \"__main__\":\n    One().print_one()\n```\n\ntwo.py :\n```\nclass Two():\n    @staticmethod\n    def print_two():\n        print(\"this is from two\")\n```\n\nerror thrown\n```\n$ python modone/one.py\n\nTraceback (most recent call last):\n  File \"modone/one.py\", line 1, in <module>\n    from modtwo import two\n  ImportError: No module named modtwo\n```\n\nWhat I tried so far :\n\nAppended every possible directory to PYTHONPATH\nran the command from project root and relative paths\nscratched my head compulsively\n\nEDIT AFTER ANSWERS :\nWhat I've learned so far :\n\nmodules and scripts are two different concepts.\nthey are like the light wave/particle duality \nthey should hence be called/treated as such (either as a module, or a script)\n\na module can be run as a script, but it won't be aware of the directory structures around it\n\n\n    ", "Answer": "\r\nThe problem is how you're calling the print_two method.\nYou called two, which is a module, that's why you got \"module is not callable\"\n```\nfrom modtwo import two\nclass One():\n    @staticmethod\n    def print_one():\n        print(\"this is one\")\n        two().print_two()\n```\n\nYou should access the class first\n```\nfrom modtwo import two\nclass One():\n    @staticmethod\n    def print_one():\n        print(\"this is one\")\n        two.Two.print_two()\n```\n\nAnd run the script like this\n```\npython -m modone.one\n```\n\nThe result is:\n```\nthis is one\nthis is from two\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Merge tables and extract names\r\n                \r\nWill try to make as succinct as possible. I have an excel table on 2 Different Sheets. \n\nOn Sheet1 I have a table with headers:Zodiac Element Duality    Quadraplicity.\n\nOne Sheet2 I have a list of people with the 12 signs of the Zodiac(12 columns with a list of names underneath each Zodiac). \n\nWhat I need to do is select \"Air\" from the Element Column, which will then select the Zodiac(s) on that table, (which is a column to the left). Then go to the second sheet and extract the appropriate columns in a list of names, so i have a list of people who have the \"Air\" attribute. I can then repeat for other attributes. \n\nAll help appreciated!\nDaniel\n    ", "Answer": "\r\nSo this is sheet 1:\n\n\n\nSheet 2 would probably be better structured something like this:\n\n\n\nWith formulas like:\n\n\n\nThis uses a vlookup (https://support.office.com/en-gb/article/VLOOKUP-function-0bbc8083-26fe-4963-8ab8-93a18ad188a1) to get data from sheet 1 abased on the sign. you can then use standard filtering to view people by elements.\n\nBut if yo plan on using filters and you are doing vlookups then \"format as table\" (https://support.office.com/en-us/article/Format-an-Excel-table-6789619F-C889-495C-99C2-2F971C0E2370) is very useful:\n\n\n\nHere i have called the table on sheet 1 \"signs\"\n\nI can then use the table name in my formula on sheet 2 (also formatting it as a table):\n\n\n\nI can then use the table functionality to filter by element (https://support.office.com/en-gb/article/Filter-data-in-a-range-or-table-01832226-31b5-4568-8806-38c37dcc180e):\n\n\n\nFromtehre as teylyn says you could add a pivot table (with or without power pivot depending on how complex the relationship is - https://msdn.microsoft.com/en-us/library/gg413497(v=sql.110).aspx)\n\n\n\nAnd you can add slicers to simply select various properties / dimensions (https://support.office.com/en-gb/article/Use-slicers-to-filter-data-249f966b-a9d5-4b0f-b31a-12651785d29d?ui=en-US&rs=en-GB&ad=GB):\n\n\n\nNote: if you use pivot tables or PowerPivot hen you will need to refresh the pivot table when you add or remove data from your source tables (https://support.office.com/en-ie/article/Refresh-PivotTable-data-6d24cece-a038-468a-8176-8b6568ca9be2). if you have used a \"format as table\" excel will know if you have added or removed columns and rows, if you don't use format as table you will need to change the data source to include new rows or columns in your source data.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Is there ever a valid reason to use C-style arrays in C++?\r\n                \r\nBetween ```\nstd::vector```\n and ```\nstd::array```\n in TR1 and C++11, there are safe alternatives for both dynamic and fixed-size arrays which know their own length and don't exhibit horrible pointer/array duality.\n\nSo my question is, are there any circumstances in C++ when C arrays must be used (other than calling C library code), or is it reasonable to \"ban\" them altogether?\n\nEDIT:\n\nThanks for the responses everybody, but it turns out this question is a duplicate of\n\nNow that we have std::array what uses are left for C-style arrays?\n\nso I'll direct everybody to look there instead.\n\n[I'm not sure how to close my own question, but if a moderator (or a few more people with votes) wander past, please feel free to mark this as a dup and delete this sentence.]\n    ", "Answer": "\r\nI didnt want to answer this at first, but Im already getting worried that this question is going to be swamped with C programmers, or people who write C++ as object oriented C. \n\nThe real answer is that in idiomatic C++ there is almost never ever a reason to use a C style array. Even when using a C style code base, I usually use vectors. How is that possible, you say? Well, if you have a vector v and a C style function requires a pointer to be passed in, you can pass &v[0] (or better yet, v.data() which is the same thing).\n\nEven for performance, its very rare that you can make a case for a C style array. A std::vector does involve a double indirection but I believe this is generally optimized away. If you dont trust the compiler (which is almost always a terrible move), then you can always use the same technique as above with v.data() to grab a pointer for your tight loop. For std::array, I believe the wrapper is even thinner.\n\nYou should only use one if you are an awesome programmer and you know exactly why you are doing it, or if an awesome programmer looks at your problem and tells you to. If you arent awesome and you are using C style arrays, the chances are high (but not 100%) that you are making a mistake,\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to clip some polygons to the boundary of another polygon?\r\n                \r\nI have a Delaunay triangulation in a polygon with a hole (a so-called constrained Delaunay triangulation):\n\nI'm able to construct the Voronoi cells by the duality principle. But some of them go outside the polygon (they go in the hole or outside the big perimeter):\n\nHow could I clip the Voronoi cells to the boundary of the big polygon? Maybe with the sf package, but I never used it.\n(NB: the two pictures do not have the same scale.)\n\nEdit\nNo sorry, that's not correct. Here is the picture with the Voronoi cells to which I added the big polygon:\n\nSo in fact I discarded the cells that go outside the polygon.\nWill see if I can I change that but probably I will delete this question (and perhaps open a new one).\n    ", "Answer": "\r\nWith {sf} you could try along the exemplary lines below. A polygon with hole can be used for clipping, too.\n```\nlibrary(sf)\n\nthe_points <- st_multipoint(cbind(rnorm(10), rnorm(10))) \n\nthe_voronoi <- \n  the_points |> \n  st_voronoi() |>\n  st_geometry() |> \n  lapply(FUN = `[`) |>\n  lapply(FUN = st_multipolygon) |>\n  st_as_sfc() |>\n  st_cast('POLYGON')\n\n## create a polygon with hole(s) by supplying a list of\n## matrices, all after the first matrix defining the holes:\nthe_clip_with_hole <- \n  3 * st_polygon(list(\n    -.5 + cbind(c(0, 1, 1, 0, 0), c(0, 0, 1, 1, 0)),\n    -.25 + .5 * cbind(c(0, 1, 1, 0, 0), c(0, 0, 1, 1, 0))\n  )\n  )\n\n\n\nthe_clipped_voronoi <- the_voronoi |> \n  st_intersection(the_clip_with_hole)\n\nthe_voronoi |> plot()\nthe_points |> plot(add = TRUE)\nthe_clipped_voronoi |> plot(col = 'red', lwd = 3, add = TRUE)\n```\n\nConverting the result of ```\nst_voronoi```\n to a clippable multipolygon turned out some hazzle.\n\nedit\nAlternative with {deldir}:\n```\nlibrary(deldir)\n\nthe_points <- list(x = rnorm(10), y = rnorm(10))\n\n## return Voronoi tesselation object (of class \"deldir\")\nvoronoi_object <- deldir(the_points)\n\ncorners <-  c(-1, 1, 1, -1, -1)\n\nclip_with_hole <- \n  list(\n    poly = list(x = .5 * corners,  y = .5 * rev(corners)),\n    hole = list(x = .25 * corners, y = .25 * rev(corners))\n  )\n\n## return Voronoi polygons (\"tiles\") and plot\n## original:\ntile.list(voronoi_object) |> plot()\n## clipped:\ntile.list(voronoi_object, clipp = clip_with_hole) |>\n  plot(lwd = 3, showpoints = FALSE, fillcol = rainbow(4), add = TRUE)\n```\n\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Sort by a key, but value has more than one element using Scala\r\n                \r\nI'm very new to Scala on Spark and wondering how you might create key value pairs, with the key having more than one element. For example, I have this dataset for baby names:\n\nYear, Name, County, Number\n\n2000, JOHN, KINGS, 50\n\n2000, BOB, KINGS, 40\n\n2000, MARY, NASSAU, 60\n\n2001, JOHN, KINGS, 14\n\n2001, JANE, KINGS, 30\n\n2001, BOB, NASSAU, 45\n\nAnd I want to find the most frequently occurring for each county, regardless of the year. How might I go about doing that?\n\nI did accomplish this using a loop. Refer to below. But I'm wondering if there is shorter way to do this that utilizes Spark and Scala duality. (i.e. can I decrease computation time?)\n\n```\nval names = sc.textFile(\"names.csv\").map(l => l.split(\",\"))\n\nval uniqueCounty = names.map(x => x(2)).distinct.collect\n\nfor (i <- 0 to uniqueCounty.length-1) {\n    val county = uniqueCounty(i).toString;\n    val eachCounty = names.filter(x => x(2) == county).map(l => (l(1),l(4))).reduceByKey((a,b) => a + b).sortBy(-_._2);\n    println(\"County:\" + county + eachCounty.first)\n}\n```\n\n    ", "Answer": "\r\nHere is the solution using RDD. I am assuming you need top occurring name per county.\n\n```\nval data = Array((2000, \"JOHN\", \"KINGS\", 50),(2000, \"BOB\", \"KINGS\", 40),(2000, \"MARY\", \"NASSAU\", 60),(2001, \"JOHN\", \"KINGS\", 14),(2001, \"JANE\", \"KINGS\", 30),(2001, \"BOB\", \"NASSAU\", 45))\nval rdd = sc.parallelize(data)\n//Reduce the uniq values for county/name as combo key\nval uniqNamePerCountyRdd = rdd.map(x => ((x._3,x._2),x._4)).reduceByKey(_+_)\n// Group names per county.\nval countyNameRdd = uniqNamePerCountyRdd.map(x=>(x._1._1,(x._1._2,x._2))).groupByKey()\n// Sort and take the top name alone per county\ncountyNameRdd.mapValues(x => x.toList.sortBy(_._2).take(1)).collect\n```\n\n\nOutput:\n\n```\nres8: Array[(String, List[(String, Int)])] = Array((KINGS,List((JANE,30))), (NASSAU,List((BOB,45))))\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Random effects modeling using mgcv and using lmer. Basically identical fits but VERY different likelihoods and DF. Which to use for testing?\r\n                \r\nI am aware that there is a duality between random effects and smooth curve estimation. At this link, Simon Wood describes how to specify random effects using mgcv. Of particular note is the following passage: \n\n\n  For example if g is a factor then s(g,bs=\"re\") produces a random coefficient for each level of g, with the radndom coefficients all modelled as i.i.d. normal.\n\n\nAfter a quick simulation, I can see this is correct, and that the model fits are almost identical. However, the likelihoods and degrees of freedom are VERY different. Can anyone explain the difference? Which one should be used for testing? \n\n```\nlibrary(mgcv)\nlibrary(lme4)\nset.seed(1)\nx <- rnorm(1000) \nID <- rep(1:200,each=5)\ny <- x \nfor(i in 1:200) y[which(ID==i)] <- y[which(ID==i)] + rnorm(1)\ny <- y + rnorm(1000)\nID <- as.factor(ID)\n\n# gam (mgcv)\nm <- gam(y ~ x + s(ID,bs=\"re\"))\ngam.vcomp(m)\ncoef(m)[1:2]\nlogLik(m)\n\n# lmer\nm2 <- lmer(y ~ x + (1|ID))\nsqrt(VarCorr(m2)$ID[1])\nsummary(m2)$coef[,1]\nlogLik(m2)\n\nmean( abs( fitted(m)-fitted(m2) ) )\n```\n\n\nFull disclosure: I encountered this problem because I want to fit a GAM that also includes random effects (repeated measures), but need to know if I can trust likelihood-based tests under those models. \n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Jackson handling XML arrays with dynamic fields using the hashmap approach\r\n                \r\nI have to write a message handler that will process incoming XML messages and pass them on to another module as JSON representations. There are a relatively high of possible messages and I would rather use a single POJO for my purpose. Here is an example XML message.\n```\n<Message name=\"GenericMsg\">\n    <StartTime>533798131</StartTime> <!-- Unix Timestamp -->\n\n                .\n                .\n    <!-- Some other fields -->\n                .\n    <NumberOfItems>2</NumberOfItems>\n    <List>\n        <ListItem>\n            <Speed>100</Speed>\n            <Location>\n                <lat>38.165748</lat>\n                <lon>37.125363</lon>\n                <alt>800</alt>\n            </Location>\n        </ListItem>\n        <ListItem>\n            <Speed>120</Speed>\n            <Location>\n                <lat>39.123748</lat>\n                <lon>41.312645</lon>\n                <alt>850</alt>\n            </Location>\n        </ListItem>\n    </List>\n</Message>\n```\n\nAnd my POJO\n```\npublic class MsgRepr {\n    private Map<String, Object> details = new LinkedHashMap<>();\n\n    public Object get(String key) {\n        return this.details.get(key);\n    }\n\n    @JsonAnyGetter\n    public Map<String, Object> getDetails() {\n        return this.details;\n    }\n    @JsonAnySetter\n    public void setDetails(String key, Object value) {\n        this.details.put(key,value);\n    }\n}\n```\n\nThis gets converted to the following JSON:\n```\n{\n  \"name\" : \"GenericMsg\",\n  \"NumberOfItems\" : \"2\",\n  \"StartTime\" : \"533798131\"\n  \"List\" : {\n    \"ListItem\" :\n    [\n      {\n        \"Speed\" : \"100\",\n        \"Location\" : {\n          \"lat\" : \"38.165748\",\n          \"lon\" : \"37.125363\",\n          \"alt\" : \"800\"\n        }\n      },\n      {\n        \"Speed\" : \"150\",\n        \"Location\" : {\n          \"lat\" : \"48.564866\",\n          \"lon\" : \"35.18795\",\n          \"alt\" : \"850\"\n        }\n      }\n    ]\n  }\n}\n```\n\nI tried the ```\ndefaultUseWrapper=false```\n option with no avail. Also, omitting the List/ListItem duality results in only the last element being present.\nI know that this can be done by writing a seperate POJO for each message, but I would rather avoid doing that. Is there an alternative XML representation or an alternative approach I can use to correctly convert the json to something similar to the following format?\n```\n{\n  \"name\" : \"GenericMsg\",\n  \"NumberOfItems\" : \"2\",\n  \"StartTime\" : \"533798131\"\n  \"List\" :\n  [\n    {\n      \"Speed\" : \"100\",\n      \"Location\" : {\n        \"lat\" : \"38.165748\",\n        \"lon\" : \"37.125363\",\n        \"alt\" : \"800\"\n      }\n    },\n    {\n      \"Speed\" : \"150\",\n      \"Location\" : {\n        \"lat\" : \"48.564866\",\n        \"lon\" : \"35.18795\",\n        \"alt\" : \"850\"\n      }\n    }\n  ]\n}\n```\n\nJackson version 2.13.0\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "What is the real use of SavedModelBuilder.add_meta_graph in TensorFlow?\r\n                \r\nI've been playing with the saved_model API for a moment until I realise the duality between two ```\nSavedModelBuilder```\n functions: ```\nadd_meta_graph```\n and ```\nadd_meta_graph_and_variables```\n\n\nSince those APIs name seems to means that the first function saves everything and the second one only the graph. I believed wrongly that I could extract a sub graph for the second function to reduce the size of the ```\nsaved_model.pb```\n file.\n\nBut it happens that, even when variables keeps the same names the meta graph can loose its capacity to links the the weights data.\n\nSo far, It looks to me as if it's only useful to add tags to the same graph, which is useless since you can just add a list of them directly.\n\nI'm lost to see any interesting properties to this ```\nadd_meta_graph```\n function, can someone enlighten me on this?\n\nSee the example below:\n\n\n\n```\nimport os, time\n\nimport tensorflow as tf\nimport numpy as np\n\ndir = os.path.dirname(os.path.realpath(__file__))\nexport_dir = dir + '/results/' + str(int(time.time()))\nbuilder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n\n# We build our neural network and its training graph\nwith tf.variable_scope('placeholders'):\n    x_plh = tf.placeholder(tf.float32, shape=[None, nb_features], name=\"x\")\n    y_plh = tf.placeholder(tf.int32, shape=[None, 1], name=\"y\")\n\nwith tf.variable_scope('linear_NN'):\n    W = tf.get_variable('W', dtype=tf.float32, shape=[nb_features, nb_classes], initializer=tf.random_normal_initializer(0.05))\n    y_hat = tf.matmul(x_plh, W)\n\nwith tf.variable_scope('loss'):\n    loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(y_plh, y_hat))\n\nwith tf.variable_scope('predictions'):\n    preds = tf.cast(tf.argmax(tf.nn.softmax(y_hat), 1), tf.int32, name=\"preds\")\n    accuracies = tf.cast(tf.equal(preds, tf.squeeze(y_plh, 1)), tf.float32)\n    accuracy = tf.reduce_mean(accuracies, name=\"accuracy\")\n\nwith tf.variable_scope('optimiser'):\n    global_step_t = tf.Variable(0, dtype=tf.int32, trainable=False, name=\"global_step\")\n    adam = tf.train.AdamOptimizer(1e-2)\n    train_op = adam.minimize(loss, global_step=global_step_t)\n\n# We train our model\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    ...\n\n    # We add the graph and its variables to the saved_model\n    builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.TRAINING])\n\n\n# Let's clean the graph to have only needed inference nodes\nserve_graph_def = tf.graph_util.extract_sub_graph(\n    tf.get_default_graph().as_graph_def(), \n    ['predictions/preds']\n)\ntf.reset_default_graph()\ntf.import_graph_def(serve_graph_def, name=\"\")\n# One of another problem here, is that this function hasn't any useful check to the variable data\n# just because I called the first one, I can now call this one.\nbuilder.add_meta_graph(\n    [tf.saved_model.tag_constants.SERVING]\n    , signature_def_map={\n        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n            tf.saved_model.signature_def_utils.predict_signature_def(\n                inputs={'x': x_plh}\n                , outputs={'out': preds}\n            )       \n    }\n)\nbuilder.save(as_text=True)\n\n# We use a temporary graph to load our saved model\n# Everything is working fine here\nwith tf.Session(graph=tf.Graph()) as sess: \n    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.TRAINING], export_dir)\n    g = tf.get_default_graph()\n    x_plh = g.get_tensor_by_name(\"placeholders/x:0\")\n    y_plh = g.get_tensor_by_name(\"placeholders/y:0\")\n    accuracy = g.get_tensor_by_name(\"predictions/accuracy:0\")\n    acc = sess.run(accuracy, feed_dict={\n        x_plh: val_x,\n        y_plh: val_y\n    })\n    print(\"acc: %f\" % acc)\n\n# Now I want to load the simplified graph for inference, but of course\n# the link to variables is missing (no more trainable_variables and variables collections)\n# So we can't use it like that\n# But then, what is the purpose of this add_meta_graph function??\nwith tf.Session(graph=tf.Graph()) as sess:\n    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n    g = tf.get_default_graph()\n\n    x_plh = g.get_tensor_by_name(\"placeholders/x:0\")\n    preds = g.get_tensor_by_name(\"predictions/preds:0\")\n    p = sess.run(preds, feed_dict={ x_plh: [[.1, .1, .1, .1, .1, .1]] })\n    print(\"p: %f\" % p)\n```\n\n    ", "Answer": "\r\nIn my experiment with your code,when you use the function ```\nextract_sub_graph```\n, the subgraph node names changed, no longer the same as the previously saved ```\ngraph.eg```\n，the node \n```\n'linear_NN/W'```\n would be changed to ```\n'import/linear_NN/W'```\n in the sub graph. So the subgraph can't link the variables, because names changed.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Run OpenTk dependent exe on TeamCity throws AccessViolationException\r\n                \r\nWhat's happening?\n\n\nTC build step via either Command Line (tried custom script as well as Executable with parameters)or .Net process runner\nWhat I am trying to run is an application that uses OpenTk. \nWhen I run the application by calling it con cmd it runs without problems.\nwhen I run from TC I get the error:\n\n\n(removed timestamps to make it more readable)\n\n```\n\n Starting: D:\\TeamCity9\\buildAgent\\temp\\agentTmp\\custom_script3388580896349143851.cmd\n[] out - in directory: D:\\TeamCity9\\buildAgent\\work\\5b9612e40cf3fd7d\\BuildSteam\n[] err - D:\\TeamCity9\\buildAgent\\temp\\agentTmp\\custom_script3388580896349143851.cmd\n[] out -\n[] out - Unhandled Exception: System.AccessViolationException: Attempted to read or write protected memory. This is often an indication that other memory is corrupt.\n[] out - at OpenTK.Graphics.OpenGL.GL.CreateProgram()\n[] out - at Duality.Resources.ShaderProgram.AttachShaders(ContentRef`1 v, ContentRef`1 f, ContentRef`1 g) in d:\\TeamCity9\\buildAgent\\work\\df69930dfe788c6f\\Duality\\Resources\\ShaderProgram.cs:line 208\n[] out - at Duality.Resources.ShaderProgram..ctor(ContentRef`1 v, ContentRef`1 f) in d:\\TeamCity9\\buildAgent\\work\\df69930dfe788c6f\\Duality\\Resources\\ShaderProgram.cs:line 188\n[] out - at Duality.Resources.ShaderProgram.InitDefaultContent() in d:\\TeamCity9\\buildAgent\\work\\df69930dfe788c6f\\Duality\\Resources\\ShaderProgram.cs:line 60\n[2015-03-20 19:30:45,651] out - at Duality.ContentProvider.InitDefaultContent() in d:\\TeamCity9\\buildAgent\\work\\df69930dfe788c6f\\Duality\\ContentProvider.cs:line 52\n[] out - at SceneBaker.Program.Main(String[] args)\n```\n\n\nI am running TC and the agent (in the same machine) as a user with Admin privileges.\n\nWhat I tried\n\nRunning in all possible ways on the command line\nCreated a scriptcs script that checked whether the user is not an admin and if not it elevates this is failing with an Invalid operation exception.. investigating.\n\nTried turning off the firewall to no effect\nTried reinstalling the GC drivers to no effect\n\nEDIT : further investigation shows that that exception was just an error on how I was running the process and I get the same Unhandled Exception: System.AccessViolationException\n\nEDIT II : After adding some logging I can see that TC does somehow make the detected graphics driver the incorrect one:\n\n```\n\nInfo: OpenGL initialized\nInfo: Vendor: Microsoft Corporation\nInfo: Version: 1.1.0\nInfo: Renderer: GDI Generic <--- here it should be Intel HD Graphics 4000 Info: Shading language version:\n```\n\n\nAny ideas what could make this program work from TC? I need this to run in a specific order on the build steps\n\nCheers\n    ", "Answer": "\r\nOk the problem was that teamcity agent was running as a service, and services can't create OpenGl contexts, once the agent was running from command line then it works.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Constructing the 3D Voronoi Diagram from a 3D Delaunay Tessallation\r\n                \r\nI'm trying to convert a 3D Delaunay Tessallation (generated with TetGen) to a Voronoi Diagram. I know TetGen can create Voronoi Diagrams, but I need to perform the conversion myself due to unusual boundary conditions.\n\nI'm totally stumped with the duality here. I have two of the four:\n\n\nEach Delaunay vertex corresponds to one Voronoi cell (the center of the cell is at the vertex).\nEach Delaunay tetrahedron corresponds to one Voronoi vertex (the center of the tetrahedron is at the vertex).\n\n\nI know each Delaunay face corresponds to one Voronoi edge, and I have the face vertices, but how do I get the Voronoi edge out of it?\n\nAlso, each Delaunay edge corresponds to one Voronoi face, but again - how do I find the face corresponding to the edge?\n    ", "Answer": "\r\nLet's consider an edge in the Delaunay triangulation. Assume for now it is not on the convex hull of the input points.\nConsider one tetrahedron incident to that edge. You get the first point of the dual face. Then choose one of the two triangles in the tetrahedron incident to the edge. Cross it and you'll be inside another tetrahedron which gives you the second point of the face. If you keep turning around the edge like this (in the same direction) you'll be back in the first tetrahedron and you'll get the description of the face.\nIf the edge is on the convex hull, you'll need to add rays instead of segments during the description of the face.\n\nNote that if you have more than 3 co-spherical points, some tetrahedra will correspond to the same dual Voronoi vertex.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "In Scala3, if generic type argument(s) is mapped to dependent type, how are covariant & contravariant modifiers mapped?\r\n                \r\nIn this article, it is explained that each generic type argument in Scala 3 code is perceived as a dependent type to be conform with the DOT logic:\nhttps://dotty.epfl.ch/docs/internals/higher-kinded-v2.html\nNamely:\n\nThe duality\nThe core idea: A parameterized class such as\n\n\nclass Map[K, V]\n\n\nis treated as equivalent to a type with type members:\n\n\nclass Map { type Map$K; type Map$V }\n\n(the article may be obsolete but the design philosophy should still hold)\nConsequentially, I would expect any contravariant & covariant modifiers for type arguments are also rewritten, so I did a quick experiment, the compiler should be able to convert the following code:\n```\n  object AsArg {\n\n    trait P[+TT] {\n      val vv: TT\n    }\n\n    trait P1 extends P[Product] {\n      val vv: Product\n    }\n    trait P2 extends P1 with P[Tuple1[Int]] {\n      val vv: Tuple1[Int]\n    }\n  }\n```\n\ninto this:\n```\n  object AsDependentType {\n\n    trait P {\n      type TT\n\n      val vv: TT\n    }\n\n    trait P1 extends P {\n      type TT <: Product\n\n      val vv: Product\n    }\n\n    trait P2 extends P1 with P {\n      type TT <: Tuple1[Int]\n\n      val vv: Tuple1[Int]\n    }\n  }\n```\n\nIronically, after conversion, the compiler throw the following errors:\n```\n[Error] ...CovariantDependentType.scala:30:11: error overriding value vv in trait P of type P1.this.TT;\n  value vv of type Product has incompatible type\n[Error] ...CovariantDependentType.scala:36:11: error overriding value vv in trait P of type P2.this.TT;\n  value vv of type Tuple1[Int] has incompatible type\ntwo errors found\n```\n\nSo what is the correct equivalent code after conversion?\n    ", "Answer": "\r\nIn/co/contra-variance is a property of a type constructor ```\nF[T]```\n.\n```\nF```\n is co-variant if for all ```\nA <: B```\n, ```\nF[A] <: F[B]```\n.\n```\nF```\n is contra-variant if for all ```\nA <: B```\n, ```\nF[B] <: F[A]```\n.\n```\nF```\n is invariant if for all ```\nA <: B```\n, ```\nF[A]```\n and ```\nF[B]```\n are ```\n<:```\n-unrelated.\nType parameters and type members are different things both in Scala 2 and Scala 3.\nFor type parameters, variance can be set up at declaration site\n```\ntrait F[+T] // co-variance\ntrait F[-T] // contra-variance\ntrait F[T] // invariance\n```\n\nor at call site\n```\ntrait F[T]\ntype G[+T] = F[_ <: T] // co-variance\ntype G[-T] = F[_ >: T] // contra-variance\n```\n\nIn Java there is no ```\n+```\n/```\n-```\n, so variance of type parameters has to be always set up with ```\n? extends ...```\n, ```\n? super ...```\n at call site.\nFor type members in Scala, there is no ```\n+```\n/```\n-```\n either, so variance has to be set up at call site\n```\ntrait F { type T }\ntype G[+U] = F { type T <: U } // co-variance \ntype G[-U] = F { type T >: U } // contra-variance\n```\n\nType-parameter code\n```\ntrait P[+TT] {\n  val vv: TT\n}\n\ntrait P1 extends P[Product] {\n  val vv: Product\n}\n\ntrait P2 extends P1 with P[Tuple1[Int]] {\n  val vv: Tuple1[Int]\n}\n```\n\ncan be translated into type-member code in Scala 2 as\n```\ntrait P {\n  type TT\n  val vv: TT1 forSome {type TT1 >: TT} // just val vv: _ >: TT is illegal here: unbound wildcard type\n}\n\ntrait P1 extends P {\n  type TT <: Product\n  val vv: Product\n}\n\ntrait P2 extends P1 with P {\n  type TT <: Tuple1[Int]\n  val vv: Tuple1[Int]\n}\n```\n\nSince ```\nTT1 forSome {type TT1 >: TT} =:= Any```\n, it's the same as\n```\n// (*)\n\ntrait P {\n  type TT\n  val vv: Any\n}\n\ntrait P1 extends P {\n  type TT <: Product\n  val vv: Product\n}\n\ntrait P2 extends P1 with P {\n  type TT <: Tuple1[Int]\n  val vv: Tuple1[Int]\n}\n```\n\nSince existential types are recommended to be translated in Scala 3 as path-dependent types, this can be translated in Scala 3 as (*) or\n```\ntrait P {\n  type TT\n\n  trait Inner {\n    type TT1 >: TT\n    val vv: TT1\n  }\n\n  val i: Inner\n}\n\ntrait P1 extends P {\n  type TT <: Product\n}\n\ntrait P2 extends P1 with P {\n  type TT <: Tuple1[Int]\n}\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Kripke semantics: learning software available?\r\n                \r\nI am stuck on Kripke semantics, and wonder if there is ```\neducational software```\n through which I can test equivalence of statements etc, since Im starting to think its easier to learn by example (even if on abstract variables).\n\nI will use\n\n\n☐A to write necessarily A\n♢A for possibly A\n\n\ndo ☐true, ☐false, ♢true, ♢false evaluate to values, if so what values or kinds of values from what set ({true, false} or perhaps {necessary,possibly})? [1]\n\n\n\nI think I read all ```\nKripke models```\n use the ```\nduality axiom```\n:\n\n(☐A)->(¬♢¬A)\n\ni.e. if its necessary to ```\npaytax```\n then its not allowed to not ```\npaytax```\n\n\n(irrespective of wheither its necessary to pay tax...)\n\ni.e.2. if its necessary to ```\nearnmoney```\n its not allowed to not ```\nearnmoney```\n\n\n(again irrespective of wheither earning money is really necessary, the logic holds, so far)\n\nsince A->B is equivalent to ¬A<-¬B lets test\n\n¬☐A<-♢¬A\n\nits not necessary to ```\nupvote```\n if its allowed to not ```\nupvote```\n\n\nthis axiom works dually:\n\n♢A->¬☐¬A\n\nIf its allowed to ```\nearnmoney```\n then its not necessary to not ```\nearnmoney```\n\n\n\n\nNot all modalities behave the same, and different ```\nKripke model```\n are more suitable to model one modalit than another: not all ```\nKripke models```\n use the same ```\naxioms```\n. (Are classical quantifiers also modalities? if so do ```\nKripke models```\n allow modeling them?)\n\nI will go through the list of common axioms and try to find examples that make it seem counterintuitive or unnecessary to postulate...\n\n\n☐(A->B)->(☐A->☐B):\n\n\nif (its necessary that (earningmoney implies payingtaxes))\nthen ((necessity of earningmoney) implies (necessity of payingtaxes))\n\nnote that earning money does not imply paying taxes, the falsehood of the implication A->B does not affect the truth value of the axiom...\n\nurgh its taking too long to phrase my problems in trying to understand it all... feel free to edit\n    ", "Answer": "\r\nModal logic provers and reasoners:\n\n\nhttp://www.cs.man.ac.uk/~schmidt/tools/\nhttp://www.cs.man.ac.uk/~sattler/reasoners.html\n\n\nEngine tableau in Java:\n\n\nhttp://www.irisa.fr/prive/fschwarz/lotrecscheme/\nhttps://github.com/gertvv/oops/wiki\nhttp://molle.sourceforge.net/\n\n\nModal logic calculators:\n\n\nhttp://staff.science.uva.nl/~jaspars/lvi98/Week3/modal.html\nhttp://www.ffst.hr/~logika/implog/doku.php?id=program:possible_worlds\nhttp://www.personeel.unimaas.nl/roos/EpLogic/start.htm\n\n\nLectures for practical game implementations of epistemic logic:\n\n\nhttp://www.ai.rug.nl/mas/\n\n\nVery good phd thesis:\n\n\nhttp://www.cs.man.ac.uk/~schmidt/mltp/\nhttp://www.harrenstein.nl/Publications.dir/Harrenstein.pdf.gz\n\n\nLectures about modal logic (in action, conflict, games):\n\n\nhttp://www.logicinaction.org/\nhttp://www.masfoundations.org/download.html\nModal Logic for Open Minds, http://logicandgames.pbworks.com/f/mlbook-almostfinal.pdf (the final version is not free)\n\n\nVideo lectures about modal logic and logic in general:\n\n\nhttp://videolectures.net/ssll09_gore_iml/\nhttp://videolectures.net/esslli2011_benthem_logic/\nhttp://videolectures.net/esslli2011_jaspars_logic/\nhttp://www.youtube.com/view_play_list?p=C88812FFE0F526B0\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Getting Warning: \"ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations.\" in ElasticNetCV sklear\r\n                \r\nI am trying to run elasticnet regression on a particular dataset. This is my code:\n```\nelastic= ElasticNetCV(l1_ratio = [0.001,0.005,0.01,0.03,0.07,0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1],\n                          alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, \n                                    0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6], \n                          max_iter = 50000, cv = 10,tol=0.001)\nelastic.fit(x_train,y_train)\nalpha=elastic.alpha_\nratio=elastic.alpha_\nprint('best alpha:',alpha)\nprint('best l1 ratio:',ratio)\n\n```\n\nI am receiving the following warning and unable to finish execution properly.\n```\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1304511543456042, tolerance: 0.16652297337822466\n  tol, rng, random, positive)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3276808651494596, tolerance: 0.17237036604178843\n  tol, rng, random, positive)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1082449562463794, tolerance: 0.17237036604178843\n  tol, rng, random, positive)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1717336811567476, tolerance: 0.16652297337822466\n  tol, rng, random, positive)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.147435308235048, tolerance: 0.17237036604178843\n  tol, rng, random, positive)\n```\n\nI have tried increasing tolerance value. However, the problem does not seem to change\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Array from function to another with dynamic allocating (C)\r\n                \r\nI'm trying to write the following code that calculates the moving average.\nIn \"main.c\" file i call 2 functions of \"movingAVG.h\":\nThe function initAVG() create an array and initialize all element with 0, with this function i choose the number of saples to use for average .\nThe function getAVG() take the array, replace the oldest sample with the newest and return the calculated average.\nI need to pass the array from initAVG to getAVG using the pointer array duality property but i'm not able to do that, i'm new to C. What i'm doing wrong?\nAny help would be really appreciated. Many thanks!\n\n```\n/* ========================================\n *\nMEDIA MOBILE.\n *\n * ========================================\n*/\n\n#include \"project.h\"\n\nuint8 start=0;\nuint8 iy; //sample's vector index\nuint32 sum=0;\nuint32 avg;\nuint32 *ptrSamples;\n\nvoid initAVG(nSample)\n{\n    uint8 i=0;\n    uint32 Samples[nSample];\n    ptrSamples = Samples;\n\n    while (i<=nSample)\n    {\n        Samples[nSample]=0;\n        i++;\n    }\n    start=1;\n}\n\nuint32 getAVG(uint8 nSample,uint32 lastvalue)\n{\n    if (iy<=nSample && start==1)\n    {\n        sum -= ptrSamples[iy];\n        ptrSamples[iy] = lastvalue;\n        sum += ptrSamples[iy];\n        avg = sum / (nSample + 1);\n        if (iy<nSample)\n        {\n            iy++;\n        }else {iy = 0;}\n    }\n    return avg;\n}\n\n/* [] END OF FILE */\n```\n\n\nEDIT:\nI tried to use dynamic memory allocation with malloc() for the array but it doesn't work. What's wrong?\nDoes the allocated memory with malloc() survive exiting from initAVG() function?\n\n```\n#include \"project.h\"\n#include \"malloc.h\"\n\nuint8 start=0;\nuint8 iy; //sample's vector index\nuint32 sum=0;\nuint32 avg;\nuint8 nSample;\nuint32* ptrSamples;\n\nvoid initAVG(numberOfSample)\n{\n    uint8 i=0;\n    nSample=numberOfSample;\n    ptrSamples = malloc((nSample+1)*sizeof(uint32)); \n\n    while (i<=nSample)\n    {\n        ptrSamples[i]=0;\n        i++;\n    }\n    start=1;\n}\n\nuint32 getAVG(uint32 lastvalue)\n{\n    if (iy<=nSample && start==1)\n    {\n        sum -= ptrSamples[iy];\n        ptrSamples[iy] = lastvalue;\n        sum += ptrSamples[iy];\n        avg = sum / (nSample + 1);\n        if (iy<nSample)\n        {\n            iy++;\n        }else {iy = 0;}\n    }\n    return avg;\n}\n```\n\n    ", "Answer": "\r\nYou are creating array Samples inside function initAVG(), And you are storing an address of the first element of the array in the pointer ptrSamples.\n\nBut if you are calling these functions from main(), in the following order as \n\n```\ninitAVG();\ngetAVG();\n```\n\n\nThe lifetime of Samples is only for the time the function initAVG() is executing. After execution of the function, the array will not be there in memory. But the pointer is still pointing to same memory location.\n\nSo please make the array global or assign dynamic memory for the array. \n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Using regex modification only in a selected part of a text\r\n                \r\nLet's say I have the following string:\n```\ns = \"In $ \\mathcal{N}=4$ we fix them completely through the duality to null\"\n```\n\nImagine I am doing some text cleaning with the following command:\n```\nnew_s = s.replace('(', ' ')\nnew_s = re.sub(r'[^\\x00-\\x7F]+',' ', new_s)\n```\n\nIs there a way to modify all the string except what is in the $ $ ?\nThanks\n    ", "Answer": "\r\nUse ```\nre.sub```\n directly with a method as replacement:\n```\nregex = re.compile(r'(\\$[^$]*\\$)|[^\\x00-\\x7F]+|\\(')\nprint(regex.sub(lambda m: m.group(1) or \" \", s))\n```\n\nSee proof online\nWhat does it do\n\n```\n(\\$[^$]*\\$)|[^\\x00-\\x7F]+|\\(```\n captures all between two dollar symbols into capturing group with ID 1 with ```\n(\\$[^$]*\\$)```\n, and matches all non-ASCII or ```\n(```\n characters with ```\n[^\\x00-\\x7F]+|\\(```\n without capturing.\nIf the first alternative matches, nothing is replaced in the string (since ```\nm.group(1)```\n puts back what was matched) and otherwise, the replacement is a space.\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "When does Method.invoke retrieve the vtable method pointer in Java\r\n                \r\nI am reading the book \"The Well Grounded Java Developer 2nd edition\", and in chapter 17 (Modern internals) there is a description of how the reflection internals work. First the duality of the Entry vs Entry.class is discussed (the first picture), which shows how the array of Methods from the Class will match the ordering (indexing) as the ones from the klassOop for the actual type. Following that, in the second screenshot, we are shown a DelegatingMethodAccessorImpl whose role is to delegate the actual invocation to the native or custom method accessor.\nWhen and how is the bytecode for the method to be executed retrieved from the klassOop by the MethodAccessor's invocation.  I guess the Method.slot field used, but from the available code, I don't see exactly how, but I suspect it's some native call which may read it.\n\n\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "What is the Python best practice concerning dicts vs objects for simple key-value storage?\r\n                \r\nAfter some time programming in Javascript I have grown a little fond of the duality there between objects and associative arrays (dictionaries):\n\n\n\n```\n//Javascript\nvar stuff = { a: 17, b: 42 };\n\nstuff.a;    //direct access    (good sugar for basic use)\nstuff['a']; //key based access (good for flexibility and for foreach loops)\n```\n\n\nIn python there are basically two ways to do this kind of thing (as far as I know)\n\n\n\nDictionaries:\n\n```\nstuff = { 'a': 17, 'b':42 };\n\n# no direct access :(\nstuff['a'] #key based access\n```\n\n\nor Objects:\n\n```\n#use a dummy class since instantiating object does not let me set things\nclass O(object):\n    pass\n\nstuff = O()\nstuff.a = 17\nstuff.a = 42\n\nstuff.a #direct access :)\ngetattr(stuff, 'a') #key based access\n```\n\n\nedit: Some responses also mention namedtuples as a buitin way to create lighweight classes for immutable objects.\n\n\n\nSo my questions are:\n\n\nAre there any established best-practices regarding whether I should use dicts or objects for storing simple, method-less key-value pairs?\nI can imagine there are many ways to create little helper classes to make the object approach less ugly (for example, something that receives a dict on the constructor and then overrides ```\n__getattribute__```\n). Is it a good idea or am I over-thinking it?\n\n\nIf this is a good thing to do, what would be the nicest approach? Also, would there be any good Python projects using said approach that I might take inspiration from?\n\n\n    ", "Answer": "\r\nNot sure about \"established best practices\", but what I do is:\n\n\nIf the value types are homogenous – i.e. all values in the mappings are numbers, use a dict.\nIf the values are heterogenous, and if the mapping always has a given more or less constant set of keys, use an object. (Preferrably use an actual class, since this smells a lot like a data type.)\nIf the values are heterogenous, but the keys in the mapping change, flip a coin. I'm not sure how often this pattern comes up with Python, dictionaries like this notably appear in Javascript to \"fake\" functions with keyword arguments. Python already has those, and ```\n**kwargs```\n is a dict, so I'd go with dicts.\n\n\nOr to put it another way, represent instances of data types with objects. Represent ad-hoc or temporary mappings with dicts. Swallow having to use the ```\n['key']```\n syntax – making Python feel like Javascript just feels forced to me.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "typeclass for repetitive actions until fixed point\r\n                \r\ni noticed a common pattern of executing an action until it stops having certain effects, when one knows that this signifies a fixed point (ie, there can be no future effects).  is there a typeclass for this?\n\nis this covered by MonadFix?  looking at the code, it seems it would be, but i was scared off by the wiki page \"It is tempting to see “recursion” and guess it means performing actions recursively or repeatedly. No.\"\n\nit also seems to me that fixed points are something like the dual of identities.  that is, an identity disappears when combined with a non-identity (0 for (+), 1 for (*), [] for append, etc).  whereas a fixed point causes any non-fixed point to disappear under the 'relax' operation below.  is there a way to formalize this duality, and is it useful to do so?  ie, is there a relationship between MonadPlus and/or Monoid and MonadRelax?\n\nlastly, i notice relax is almost an unfold/anamorphism.  would it be better to express it as such?\n\n```\n{-# LANGUAGE MultiParamTypeClasses, FunctionalDependencies #-}\n\nimport Control.Monad.Loops (iterateUntilM) -- cabal install monad-loops\n\n-- states that relax to a fixed point under step\nclass Monad m => MonadRelax m s | s -> m where\nisFixed :: s -> Bool\nstep :: s -> m s -- often (not always): step s = return s iff isFixed s\n\nrelax :: MonadRelax m s => s -> m s\nrelax = iterateUntilM isFixed step\n```\n\n    ", "Answer": "\r\nWhat you are asking for, is actually a plain ```\nfix```\n:\n\n```\ncd :: (Monad m) => Int -> Int -> m Int\ncd = fix (\\f c i -> if i == 0 then return c else f (c+i) (i-1))\n```\n\n\nThis will repeat the computation, until ```\ni```\n becomes 0. (I added ```\nc```\n to have a meaningful computation; but you could assume ```\ns=(Int,Int)```\n with one of them being a rolling sum and the other the counter)\n\n```\n> cd 0 4 :: [Int]\n[10]\n```\n\n\nThis is the same as:\n\n```\nrelax = fix (\\f s -> if isFix s then return s else f (step s))\n```\n\n\nI believe, this is the definition of ```\niterateUntilM```\n.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to protect widgets from forged requests\r\n                \r\nLets say you have a JavaScript widget which needs to fire off a request to your web application if and only if the user wants to click on it.   You don't want this request to be vulnerable to CSRF so you write an iframe to the page.  Based on the origin inheritance rules the parent site won't be able to read the CSRF token.  However what about clickjacking (or likejacking )?  Because of CSRF you must be within an iframe and there for the x-frame-options cannot help, and the same holds true for frame-busters.\n\nThe attacker is going to apply an SVG mask the iframe after the widget has loaded.  This mask will make the iframe invisible.   At this point the attacker can either resize the iframe to be the size of the page or have this now invisible iframe follow the cursor.  Either way whenever the user clicks anywhere on the page,  the iframe receives the click event and its game over. \n\nSo there is a duality,  it seems you are stuck between CSRF and Clickjacking.   What the best solution (if any) to this problem?\n    ", "Answer": "\r\nClicking on the widget needs to open a pop-up window containing a new page -- an iframe is not good enough, it must be a new window -- which is entirely under the control of your web application.  Confirm the action, whatever it is, on that page.\n\nYes, this is somewhat inelegant, but the present Web security architecture doesn't give you any better options.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "In a String, how can I separate & store the characters and integers?\r\n                \r\nMy task is to create a Bubble Breaker type game, I broke my task into several smaller tasks, and I hit a wall.\n\nI created a 2D Array Grid which will, whenever the program starts, be randomized with different coloured Bubbles. Each Line and Each Column is numbered, Lines range in Numbers, Columns range in Letters.\n\nMy goal is to have the user input choosing a String (Note I can only use String, as I'm programming in a pre-designed console), for example B10, B9 or 10B.\n\nI'm able to check if the characters are numbers or letters via \n\n```\ncommand.charAt(i) >= '0' && command.charAt(i) <= '9' // i is a counter in a for\n```\n\n\nThe above allows me to find if it's a digit or a number, the problem is that to select the Exact grid position, I need to, and can't:\n\n\nSeparate the String into Integrers AND character\nJoin the two Integrers\n(note they can be B9, B10 or 10B)\n\n\nThis is an example of the duality B10 and 10B\n    ", "Answer": "\r\nYou only need two lines:\n```\nint num = Integer.parseInt(str.replaceAll(\"\\\\D\", \"\"));\nString letter = str.replaceAll(\"\\\\d\", \"\");\n```\n\nThe order of letters and digits in the string is irrelevant - this will work either way.\nEdited to cater for requirements as per comments below\nTo process a series of letter-digit pairs in larger string, parsing the letter to an ```\nint x```\n (where A=1, B=2, etc) and assigning the digit(s) to ```\nint y```\n, you can split the string up on whitespace and use code similar to above:\n```\nfor (String pair : command.toUpperCase().split(\"\\\\s+\")) {\n    int x = pair.replaceAll(\"\\\\d\", \"\").charAt(0) - '@';\n    int y = Integer.parseInt(pair.replaceAll(\"\\\\D\", \"\"));\n}\n```\n\nUsing ```\nsplit()```\n means not having to sully yourself with the tedium  of using a loop variable.\nThe reason for subtracting ```\n'@'```\n is that is the character one before ```\n'A'```\n, so subtracting that will convert ```\nA```\n to ```\n1```\n, ```\nB```\n to ```\n2```\n, etc.\n\nHere's some test code:\n```\nString command = \"A5 B10 11C 20D\";\nfor (String pair : command.split(\"\\\\s+\")) {\n    int x = pair.replaceAll(\"\\\\d\", \"\").charAt(0) - '@';\n    int y = Integer.parseInt(pair.replaceAll(\"\\\\D\", \"\"));\n    System.out.format(\"X = %d, Y = %d\\n\", x, y);\n}\n```\n\nOutput:\n```\nX = 1, Y = 5\nX = 2, Y = 10\nX = 3, Y = 11\nX = 4, Y = 20\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Modal from Modal not scrolling in Bootstrap 3 page (modal height must be dynamic)\r\n                \r\nI'm in a Bootstrap 3.3.7 environment (no, I can't go to BS4 here unfortunately) and when opening a modal from a modal, the new child modal will not scroll. \n\nI've tried other fixes such as assigning a height and overflow but the problem then is the modal is at a set height and will not scale with the window size so any responsiveness is thrown out the window. \n\nWas able to make the scroll wheel control the scrolling in the child modal, but that isn't the greatest UX to use (and I had to hide the new scrollbar so there wasn't any duality there to cause confusion). \n\nBootstrap modal inside a modal; Cannot scroll after closing modal looked promising and addresses the issue of modal-open no longer being in the body tag. The problem is the script does not seem to work because modal-open is not being placed in the body tag when the child modal opens. \n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Where does the return value go for a forEach callback? [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        Short circuit Array.forEach like calling break\r\n                            \r\n                                (31 answers)\r\n                            \r\n                    \r\n                Closed 6 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\n... more specefically, is it possible to break out of a forEach loop.  In the code below the return statement in the if statement appears to do nothing.\n\nThis is because it is retuning to the callback function.\n\nHere is a reference:\n\nmsdn - forEach\n\n```\n// underscore equivalent \"cornerstone\" fails b.c. of storage duality\nvar newForEach = function (obj, func, con) {\n    if (Pub.isType(\"Function\", func)) {\n        Object.keys(obj).forEach(function (key) {\n            if (func.call(con, obj[key], key, obj)) {\n                return true;\n            }\n        });\n    }\n};\n```\n\n\nNote, I'm not interested in using another method.  I'm curious as to where the return value goes.\n    ", "Answer": "\r\nYou can break out of the loop, but the return value is unused. \n\nSince ```\nforEach```\n doesn't return anything itself, it wouldn't make much sense to collect return values from the callback.\n\nTo break out, you need to ```\nthrow```\n during the callback:\n\n```\nvar newForEach = function (obj, func, con) {\n    if (Pub.isType(\"Function\", func)) {\n        Object.keys(obj).forEach(function (key) {\n            if (func.call(con, obj[key], key, obj)) {\n                throw new Error('something terrible happened!');\n            }\n        });\n    }\n};\n```\n\n\nHowever, that looks like exceptions as flow control, which is a Very Bad Thing. If that is what you're doing, there are probably other array methods that will be more helpful: perhaps ```\nevery```\n or ```\nfilter```\n.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Split graph into two parts according to min-cut between s and t vertices\r\n                \r\nI am implementing min-cut graph clustering, and I need to be able to split a\ngraph into two parts S and T according to the st min-cut I build on each clustering step for some s and t vertices. Basically, I want to have a function which takes a graph G, a node s, and a node t and returns two disjoint sets of nodes S and T.\n\nTo the best of my knowledge, the easiest way to find an st min-cut is via exploiting min-cut ~ max-flow duality and using Push-relabel algorithm for max-flow calculation. But the push-relabel algorithm doesn't give us any information on what S and T sets are.\n\nSo, what is the right way to get S and T min-cut subsets? Is there a way to use Push-relabel algorithm? Is there an implementation of this in C++ or Python?\n    ", "Answer": "\r\nYou can use the information computed by the push-relabel algorithm to determine a min-cut.\nAs you know, the push-relabel algorithm assigns a value h(v) for each vertex v. The possible values of h(v) are in the interval [0,N], where N is the number of vertices of the graph. It's easy to prove that there exists some number h' such that h(v) != h' for every vertex v (see exercise 26.4-3 of Cormen's book, 2nd Ed). After finding such h', every vertex v with h(v) < h' is in one side of the cut, and every vertex u with h(u) > h' is in the other side.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Auto increment by group mariaDB\r\n                \r\nI have this MariaDB table.\n```\nid   order   name  forum_id\n1      1     ....      1\n2      2     ....      1\n3      3     ....      1\n4      1     ....      2\n5      2     ....      2\n```\n\nwhere id is PK.\norder is the user given numbers to arrange names\nname is , well, name of the topic\nand forum_id is foreign key to another table\nin this table order and forum_id is unique together.```\nUNIQUE('order', 'forum_id')```\n. which means you can not add another order=1 into where forum_id=1. Becasue this duality already exist.\nnow my question is how i can make order is autoincrement field according to forum_id?For instance: when another  forum_id=1 is added order will get the value of  4. and another forum_id=2 is added order will get number 3.so my database will look like this\n```\nid   order   name  forum_id\n1      1     ....      1\n2      2     ....      1\n3      3     ....      1\n4      1     ....      2\n5      2     ....      2\n6      4     ....      1 \n7      3     ....      2\n```\n\nI saw this question has been asked in different shapes in the past. But most of the asked questions is coming from 10-15 years ago. so i thought maybe this problem got an answer as i use mariaDB 11.\n    ", "Answer": "\r\nAUTO_INCREMENT has to fulfill exactly 2 tasks:\n\nGenerate a unique integer value that can be used to efficiently and quickly access a data set.\nreflect the chronological order (without time specification) in which the data sets were generated.\n\nAUTO_INCREMENT should not be used for other logical constructs, particularly those that assume that the auto_increment values ​​represent a series of consecutively numbered values.\nUsing a composite index with an auto_increment has two serious disadvantages: querying a composite index is slower and the chronological order of the records is no longer available.\nTo avoid redundancy, ORDER should be a computed column and not stored in the database.\nAs already suggested in Ahmed's comment, a window function should be used. Since the auto_increment values ​​are unique, it doesn't matter whether RANK, DENSE_RANK or ROW_NUMBER is used.\n```\nSELECT id, RANK() OVER (PARTITION BY forum_id ORDER BY id) AS `order`,\n       name, forum_id FROM yourtable\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Pressing ENTER inside CDF Player inputfield duplicates line. How to change behavior?\r\n                \r\nI have created a CDF that has some InputFields in the middle of the text, for the reader to enter his own values.\n\nEverything works fine on the CDF Player (8.0.3) except when the user, after changing a value inside a field, presses ENTER instead of: \"Return\" or \"Tab\" or \"mouse selecting other field\".\n\nIf he presses ENTER, the CDF player does exactly the same thing that Mathematica does: a line duplication, with eventually some internal cell structure showing in the middle.\n\nAll Mathematica users can easily avoid pressing ENTER, but the CDF Player users are most likely not aware of this ENTER/RETURN duality.\n\nI've tried all the notebook options I could remember: deployed, editable, etc., with no success,\n\nAnother thing I remembered was to remove the ENTER action with the NotebookEventAction, but could not find how to do it: {\"KeyDown\", \"Enter\"}->Null ??? ; tried Enter, EnterKey, [EnterKey], etc, with no success.\n\nCan someone help me to remove this Enter side effect from the CDF Payer?\n    ", "Answer": "\r\nThis works well for numbers:\n\n```\nExpressionCell[InputField[Dynamic[x], Number], Evaluatable -> False, \n Background -> White]\n```\n\n\nFor other input types shift-Enter creates a line-break.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Using Json.NET To Deserialize Multiple Types of Objects Into One List\r\n                \r\nI'm having trouble using Json.NET, which I moved to from LitJSON. It works quite well, other than the fact that I cannot separate different types of objects to force them to use different constructors. \n\nFor example, I could do this with LitJSON:\n\n```\nfor (int i = 0; i < totalAmountOfItems; i++)\n    {\n        if (itemData[i][\"type\"].ToString() == \"Weapons\")\n        {\n            for (int j = 0; j < itemData[i][\"array\"].Count; j++)\n            {\n                database.Add(new Item((int)itemData[i][\"array\"][j][\"id\"], itemData[i][\"array\"][j][\"title\"].ToString(),\n                                  itemData[i][\"array\"][j][\"weaponType\"].ToString(), (bool)itemData[i][\"array\"][j][\"stackable\"], itemData[i][\"array\"][j][\"slug\"].ToString(),\n                                  (int)itemData[i][\"array\"][j][\"damage\"], (int)itemData[i][\"array\"][j][\"durability\"])); //Reads the component in quotes for object\n                                                                                                                        //with address 'i'. Creates new item based\n                                                                                                                        //on this data.\n                                                                                                                        //Note: If using only one .Add method, all items in database must follow it's pattern.\n            }\n        }\n        else if (itemData[i][\"type\"].ToString() == \"Food\")\n        {\n            for (int j = 0; j < itemData[i][\"array\"].Count; j++)\n            {\n                database.Add(new Item((int)itemData[i][\"array\"][j][\"id\"], itemData[i][\"array\"][j][\"title\"].ToString(),\n                                  (bool)itemData[i][\"array\"][j][\"stackable\"], itemData[i][\"array\"][j][\"slug\"].ToString(),\n                                  (int)itemData[i][\"array\"][j][\"hungerAmount\"]));\n            }\n        }\n        else if (itemData[i][\"type\"].ToString() == \"Medicine\")\n        {\n            for (int j = 0; j < itemData[i][\"array\"].Count; j++)\n            {\n                database.Add(new Item((int)itemData[i][\"array\"][j][\"id\"], itemData[i][\"array\"][j][\"title\"].ToString(),\n                                  (bool)itemData[i][\"array\"][j][\"stackable\"], itemData[i][\"array\"][j][\"slug\"].ToString(),\n                                  (int)itemData[i][\"array\"][j][\"healAmount\"]));\n            }\n        }\n        else if (itemData[i][\"type\"].ToString() == \"Equippable\")\n        {\n            for (int j = 0; j < itemData[i][\"array\"].Count; j++)\n            {\n                database.Add(new Item((int)itemData[i][\"array\"][j][\"id\"], itemData[i][\"array\"][j][\"title\"].ToString(),\n                                  (bool)itemData[i][\"array\"][j][\"stackable\"], itemData[i][\"array\"][j][\"slug\"].ToString(),\n                                  (int)itemData[i][\"array\"][j][\"armorAmount\"], (int)itemData[i][\"array\"][j][\"insulationAmount\"]));\n            }\n        }\n        else if (itemData[i][\"type\"].ToString() == \"Resource\")\n        {\n            for (int j = 0; j < itemData[i][\"array\"].Count; j++)\n            {\n                database.Add(new Item((int)itemData[i][\"array\"][j][\"id\"], itemData[i][\"array\"][j][\"title\"].ToString(),\n                                  (bool)itemData[i][\"array\"][j][\"stackable\"], itemData[i][\"array\"][j][\"slug\"].ToString()));\n            }\n        }\n    }\n```\n\n\nThis allowed me to use one container class (Item) to store data for a variety of different objects, using different constructors. How would I go about doing the same thing in Json.NET?\n\nHere is the code I am currently using:\n\n```\npublic void ConstructWeaponDatabase()\n    {\n        using (Stream s = FileOp.Open(@\"Data\\Misc\\Weapons.json\", FileAccessMode.Read)) //Opens file\n        {\n            using (StreamReader r = new StreamReader(s)) //Declares new reader\n            {\n                string json = r.ReadToEnd(); //Reads 'r' and its stream (s) to the end of the file.\n                weaponDatabase = JsonConvert.DeserializeObject<List<Misc.Weapon>>(json); //Json.NET magic to place items from file\n            }                                                                            //into list.\n        }\n    }\n```\n\n\nAs you can see, it only takes in one format of \"Weapon\" (Container class that functions in the same way as the Item class shown above). How can I make it so different constructors are used depending on the Weapon in the JSON file?\n\nThe reason I cannot use LitJSON for this is that it is not a portable library, which is a requirement for all libraries used with Duality (A C# game engine).\n    ", "Answer": "\r\nYou can use a derived ```\nJsonConverter```\n and override the ```\nReadJson```\nmethod to implement your custom logic, and then pass an instance of this converter to ```\nDeserialize```\n- have a look at this answer\n\nAlso, you might want to consider using ```\nItem```\n as a base class and use derived classes to represent your different items (```\nFood```\n, ```\nMedicine```\n, etc.) instead of using a single class to represent conceptually different objects.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "vnode and file descriptor in xnu, where does the file operation vector is stored\r\n                \r\nIn xnu we have the ```\nvnode_t```\n entity which represent the file globally.\n\nEach process can access the file (assuming it has right permissions) by setting new file descriptor and set the vnode under fg_data \n\n```\nfp->f_fglob->fg_data = vp;\n```\n\n\nthe vnode contain a list of basic actions for all relevant operations and is set in according to the file's FS. i.e. HFS+ driver implement such vector and set its vnode accordingly. \n\n```\nint     (**v_op)(void *);       /* vnode operations vector */\n```\n\n\nthis is a vector for function pointers for all actions that may operate on the vnode. \n\nIn addition, we have the fileops struct that is part of the file descriptor (fg_global) which describe a minimal subset of these functions:\n\nHere is a typical definition : \n\n```\nconst struct fileops vnops = {\n .fo_type = DTYPE_VNODE,\n .fo_read = vn_read,\n .fo_write = vn_write,\n .fo_ioctl = vn_ioctl,\n .fo_select = vn_select,\n .fo_close = vn_closefile,\n .fo_kqfilter = vn_kqfilt_add,\n .fo_drain = NULL,\n};\n```\n\n\nand we set it here : \n\n```\nfp->f_fglob->fg_ops = &vnops;\n```\n\n\nI saw that when reading regular file under local filesystem (HFS+), it works through the file_descriptor and not the vnode ...  \n\n```\n * frame #0: 0xffffff801313c67c kernel`vn_read(fp=0xffffff801f004d98, uio=0xffffff807240be70, flags=0, ctx=0xffffff807240bf10) at vfs_vnops.c:978 [opt]\nframe #1: 0xffffff801339cc1a kernel`dofileread [inlined] fo_read(fp=0xffffff801f004d98, uio=0xffffff807240be70, flags=0, ctx=0xffffff807240bf10) at kern_descrip.c:5832 [opt]\nframe #2: 0xffffff801339cbff kernel`dofileread(ctx=0xffffff807240bf10, fp=0xffffff801f004d98, bufp=140222138463456, nbyte=282, offset=<unavailable>, flags=<unavailable>, retval=<unavailable>) at sys_generic.c:365 [opt]\nframe #3: 0xffffff801339c983 kernel`read_nocancel(p=0xffffff801a597658, uap=0xffffff801a553cc0, retval=<unavailable>) at sys_generic.c:215 [opt]\nframe #4: 0xffffff8013425695 kernel`unix_syscall64(state=<unavailable>) at systemcalls.c:376 [opt]\nframe #5: 0xffffff8012e9dd46 kernel`hndl_unix_scall64 + 22\n```\n\n\nMy question is why does this duality needed, and in which cases the operation works through the file_descriptor vector (fg_ops) and which cases the operation works through the vnode vector (vp->v_op).\n\nthanks\n    ", "Answer": "\r\n\n  […] in which cases the\n  operation works through the file_descriptor vector (fg_ops) and which\n  cases the operation works through the vnode vector (vp->v_op).\n\n\nI'm going to start by answering this second part of the question first: if you trace through your call stack further, and look inside the ```\nvn_read```\n function, you'll find that it contains this line:\n\n```\n    error = VNOP_READ(vp, uio, ioflag, ctx);\n```\n\n\nThe ```\nVNOP_READ```\n function (kpi_vfs.c) in turn has this:\n\n```\n_err = (*vp->v_op[vnop_read_desc.vdesc_offset])(&a);\n```\n\n\nSo the answer to your question is that for your typical file, both tables are used for dispatching operations.\n\nWith that out of the way,\n\n\n  My question is why does this duality needed […]\n\n\nNot everything to which a process can hold a file descriptor is also represented in the file system. For example, pipes don't necessarily have to be named. A vnode doesn't make any sense in that context. So in sys_pipe.c, you'll see a different fileops table:\n\n```\nstatic const struct fileops pipeops = {\n    .fo_type = DTYPE_PIPE,\n    .fo_read = pipe_read,\n    .fo_write = pipe_write,\n    .fo_ioctl = pipe_ioctl,\n    .fo_select = pipe_select,\n    .fo_close = pipe_close,\n    .fo_kqfilter = pipe_kqfilter,\n    .fo_drain = pipe_drain,\n};\n```\n\n\nSimilar deal for sockets.\n\nFile descriptors track the state of a process's view of a file or object that allows file-like operations. Things like position in the file, etc. - different processes can have the same file open, and they must each have their own read/write position - so vnode:fileglob is a 1:many relationship.\n\nMeanwhile, using vnode objects to track things other than objects within a file system doesn't make any sense either. Additionally, the v_op table is file system specific, whereas vn_read/VNOP_READ contain code that applies to any file that's represented in a file system.\n\nSo in summary they're really just different layers in the I/O stack.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "vba match method for strings unexpected result\r\n                \r\nI am using Application.WorksheetFunction.Match method for looking a string in a range. It gives me the rows that contain different string values.\nI thought it maybe due to space, but not it is for sure not space in a string not in the worksheet cell value. When I try with rng.Find method it gives me the wanted result. But why I am not using the Find method because, there is a cell in which the word that I am using is there already. The find method goes for that row.\nWhen I delete that duality giving row value  for testing find method it gives expected result.\nMatch is not case sensitive, but finds the values that are totally different. And playing with 0, -1,1 does not differ the result.\nWhat can be reason for such stupid result?\nthe value inside cells are:\nColumn \"A\" (let's assume):rng\n\nNet profit margin\n- profit margin\n\nthe code\n```\nb=    Application.WorksheetFunction.Match(\"net profit\",rng,0)\na=    rng.Find(\"net profit\")\n```\n\nThese are samples, otherwise I cannot share, because there are different function callings from different procedures.\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "MATLAB cell array of structs very slow compared to individual cell arrays for each field\r\n                \r\nI have some code where I have a certain class of objects, each of which has a number of fields. From an object oriented perspective, it's about as classic as you can get.\n\nI initialized the code as:\n\n```\nobject = cell(N, 1);\n% Each field may contain matrices of different dimensions at each iteration\nfor i = 1 : N\n    object{i}.field1 = ones(1000, 3);\n    object{i}.field2 = imread('some_image.png');\n    object{i}.field3 = (1:.002: 4);\n    object{i}.field4 = im > 0;\n    ...\n    % And so on for more large matrices and such\nend\n```\n\n\nI had previous coded this as:\n\n```\nfield1 = cell(N, 1);\nfield2 = cell(N, 1);\nfield3 = cell(N, 1);\nfield4 = cell(N, 1);\n....\nfor i = 1 : N\n    field1{i} = ones(1000, 3);\n    field2{i} = imread('some_image.png');\n    field3{i} = (1:.002: 4);\n    field4{i} = im > 0;\n    ...\n    % And so on for more large matrices and such\nend\n```\n\n\nI then proceed to manipulate the values associated with each of the fields in each object in various ways. The second approach ran about 4 times faster than the first. The inefficiency is definitely due to this duality. The only code I changed was switching from multiple cell arrays to cell a array of structs.\nI know arrays of structs have a reputation for being slower, but I also see structs recommended for passing into functions. What am I missing here?\n\nI really like the coding neatness of the cell array of structures (particularly when you want to take a subset like ```\nsubset = object(1:4)```\n), but I obviously don't want to take the computational hit. What's the right choice here?\n\nBetter yet, is there a hidden, better third option?\n    ", "Answer": "\r\nYou were led astray because in your initial approach, you needed cell arrays in order to house different sized arrays in each ```\nfield*```\n index. \n\nHowever, when you decided to use structures in your second approach (the better approach), you didn't actually need to use cell arrays. So, if you examine this code segment:\n\n```\nfor i = 1 : N\n    object{i}.field1 = ones(1000, 3);\n    object{i}.field2 = imread('some_image.png');\n    object{i}.field3 = (1:.002: 4);\n    object{i}.field4 = im > 0;\n    ...\n    % And so on for more large matrices and such\nend\n```\n\n\nWhat's actually happening here is in each iteration, it is dynamically forming a structure on each iteration. Not only that, but every time you add a new field it is also dynamically adding a new field to that structure. This is only necessary if you are housing different structures in each index of the cell array. \n\nHowever, since you are using the same structure in each index, you can simply use an array of structures. You can preallocate the entire thing by using:\n\n```\nobject = struct('field1', cell(N,1), 'field2', cell(N,1), ...);\n```\n\n\nand then iterate over ```\nobject```\n and fill out each field as needed.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Maintaining staging+prod environments from single repo, 2 remotes with revel buildpack on heroku\r\n                \r\nRevel models are defined under the ```\nmodels```\n package; so in order to import them one must use the full repo path relative to the %GOPATH/src folder which in this case ```\nproject/app/models```\n thus results in\n\n```\nimport PROJECTNAME/app/models\n```\n\n\nso far, so good i'f you'r using your app name as the folder name of your local dev machine and have dev+prod environments only.\n\nHeroku's docs recommends using multiple apps for different environment (i.e. for staging). with the same repository with distinct origins;\n\nThis is where problem starts, now, since the staging enviromnent resides on alternative appname(let's say ```\nPROJECTNAME_STAGING```\n), it's sources are stored under ```\nPROJECTNAME_STAGING```\n but the actual code still ```\nimport PROJECTNAME/app/models```\n instead of ```\nimport PROJECTNAME_STAGING/app/models```\n; so compile fails, etc.\n\nIs there any possibility to manage multiple environments with a single local repo and multiple origins with revel's heroku buildpack? or a feature is needed in the buildpack that is yet to be implemented?\n\nIn addition, there is this possible issue with the ```\n.godir```\n file that is required to be versioned and contain the git path to the app, so what about the multi-environment duality regarding this file?\n    ", "Answer": "\r\nSolution was simple enougth;\nThe buildpack uses the string in ```\n.godir```\n both for the argument for ```\nrevel run```\n as well as the directory name under ```\nGOPATH/src```\n. My ```\n.godir```\n file had a ```\ngit.heroku.com/<APPNAME>.git```\n format; Instead I just used ```\nAPPNAME```\n format.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Duplicated link table between User and Role using Identity\r\n                \r\nOn configuring Identity on net6.0, I've used a custom User and custom Role entities derived from Identity ones.\nEverything was great, working fine till I've tried to list the Roles of my Users.\nThe reality is that the system now has 2 tables: UserRoles (created and maintained by Identity) and another one, a join table between User and Role, called RoleUser, created by convention by having a navigation property on each entity.\n\nQuestions are:\n1.How to unmess this?\n2.Can I keep using the working Roles and still use derived classes for my entities?\n3.Ideally solve this duality, remove the \"RoleUser\" table and make everything work seamlessly.\nBeen trying to fix it by forcing the mapping I want on ModelBuilder:\n```\nbuilder.Entity<User>()\n                .HasMany(e => e.Roles)\n                .WithMany(e => e.Users)\n                .UsingEntity(\n                    \"UserRoles\",\n                    l => l.HasOne(typeof(Role)).WithMany().HasForeignKey(\"RoleId\").HasPrincipalKey(nameof(Role.Id)),\n                    r => r.HasOne(typeof(User)).WithMany().HasForeignKey(\"UserId\").HasPrincipalKey(nameof(User.Id)),\n                    j => j.HasKey(\"UserId\", \"RoleId\"));\n```\n\nAnd deriving a \"UserRole\" from ```\nIdentityUserRole<long>```\n and pointing the framework to the right direction, but all I get is:\nInvalidOperationException: Cannot use table 'UserRoles' for entity type 'UserRole' since it is being used for entity type 'UserRoles (Dictionary<string, object>)' and potentially other entity types, but there is no linking relationship. Add a foreign key to 'UserRole' on the primary key properties and pointing to the primary key on another entity type mapped to 'UserRoles'.\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Undirected graph simple cycles and 3D shapes\r\n                \r\nI have a 3d object made up of vertices and faces. A cube here.\n\n\nI can represent it as a planar undirected graph joining the vertices.\n\n\nNow I'm looking at reconstituting the faces from the 2d graph itself.\nMy intuition is to look at the simple cycles in the graph and keep the ones representing coplanar vertices.\nie:\n\n\nCycle 0 V0,V1,V4,V7\nCycle 1 V0,V7,V6,V3\nCycle 2 V1,V2,V5,V4\nCycle 3 V7,V4,V5,V6\nCycle 4 V0,V1,V2,V3\n\n\n\n\nBut this method totally misses the back face of the cube.\nI realize now, that the back face (V2, V3, V6, V5) is actually the circumference of the graph, or rather the sum of all the simple cycles.\n\nWill this always be the case for any 3d drawing ? Are we sure we'll get all the faces this way. Sorry if it's a bit vague, but I'm looking for an insight I'm missing here in this 3d model / graph duality.\nAlso can you point me to an algorithm to find this back face ? How would I sum cycles to find this one ?\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Undirected graph simple cycles and 3D shapes\r\n                \r\nI have a 3d object made up of vertices and faces. A cube here.\n\n\nI can represent it as a planar undirected graph joining the vertices.\n\n\nNow I'm looking at reconstituting the faces from the 2d graph itself.\nMy intuition is to look at the simple cycles in the graph and keep the ones representing coplanar vertices.\nie:\n\n\nCycle 0 V0,V1,V4,V7\nCycle 1 V0,V7,V6,V3\nCycle 2 V1,V2,V5,V4\nCycle 3 V7,V4,V5,V6\nCycle 4 V0,V1,V2,V3\n\n\n\n\nBut this method totally misses the back face of the cube.\nI realize now, that the back face (V2, V3, V6, V5) is actually the circumference of the graph, or rather the sum of all the simple cycles.\n\nWill this always be the case for any 3d drawing ? Are we sure we'll get all the faces this way. Sorry if it's a bit vague, but I'm looking for an insight I'm missing here in this 3d model / graph duality.\nAlso can you point me to an algorithm to find this back face ? How would I sum cycles to find this one ?\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to manage sharded microcervice local storage?\r\n                \r\nLet's assume there is a single consumer group (from kafka perspective). Consumer group consists of 20 replicas of Service instances. All work is balanced among those 20 instances based on some property (UUID). Each instance manages its own storage/state/read which in turn contains only data belonging to that shard only. So there are 20 separate storages, one for each replica. But what happens in case of scaling up or down those Services? How would the remaining 10 Services manage to get all that data previously belonging to other instances? I assume that each service may emit so-called \"state event\" (stream-table duality?) and other instance may get the responsibility of managing a new part of overall data based on such stream. But this is still a lot of work to do. Such a stream may consist of millions of items (even if compacted). There must be a more efficient way to achieve this. And what if we scale up? Group leader must now inform somehow respective instance to drop part of its data. I have read some books/posts about that matter but I couldn't find any concrete information on how this is managed.\n    ", "Answer": "\r\nUnclear why this is tagged apache-kafka, since sharding isn't a Kafka term. In Kafka Streams, it can handle distribution of state stores across separate instances using the ```\nKTable```\n API. When instances are scaled up and down, the data becomes temporarily unaccessible while the state is rebuilt. Different instances can query each other with \"Interactive Queries\".\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to resolve \"AbstractMethodError\" from LambdaMetafactory\r\n                \r\nI'm getting an ```\nAbstractMethodError```\n from invoking a method defined by a call to ```\nLambdaMetafactory#metafactory()```\n.  I can't figure out what I'm doing wrong to cause it.  I've looked at quite a few examples of using ```\nLambdaMetafactory#metafactory()```\n online, but haven't found anything that exactly matches what I'm trying to do.\n\nHere's the [entire] output of running the attached code:\n\n```\nResult[0] = \"version 1\"\nResult[0] = \"1\"\nException in thread \"main\" java.lang.AbstractMethodError\n    at junk.LMTest.invokeMaker(LMTest.java:52)\n    at junk.LMTest.main(LMTest.java:65)\n```\n\n\nWhat I'm trying to do is create a class that has a single field that can be assigned a lambda directly, or be assigned by a lookup of a class name and method name.  The reason for the duality is to abstract away the way in which the method being invoked was specified (either specified directly in code, or specified in a configuration file).\n\nThe attached code defines a functional interface ```\nListMaker```\n with a method that produces a 1-element list from the string representation of an object.  It contains a static method ```\nlistify```\n that implements a function matching the interface's method's signature, and will be used for the set-the-method-directly portion of the sample.\n\nHere's the code:\n\n```\npackage junk;\n\nimport java.lang.invoke.CallSite;\nimport java.lang.invoke.LambdaMetafactory;\nimport java.lang.invoke.MethodHandle;\nimport java.lang.invoke.MethodHandles;\nimport java.lang.invoke.MethodType;\nimport java.lang.reflect.Method;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class LMTest\n{\n\n  @FunctionalInterface\n  public interface ListMaker\n  {\n    public List<String> makeList(Object obj);\n  }\n\n  private ListMaker maker;\n\n  public static List<String> listify(Object obj)\n  {\n    List<String> l = new ArrayList<>();\n    l.add(obj.toString());\n    return l;\n  }\n\n  public void setMaker(ListMaker maker)\n  {\n    this.maker = maker;\n  }\n\n  public void setMaker(String className, String methodName)\n      throws Throwable\n  {\n    Method m = Class.forName(className).getDeclaredMethod(methodName, Object.class);\n    MethodHandles.Lookup l = MethodHandles.lookup();\n    MethodHandle handle = l.unreflect(m);\n    CallSite cs = LambdaMetafactory.metafactory(l,\n                                                \"makeList\",\n                                                MethodType.methodType(ListMaker.class),\n                                                handle.type().generic(),\n                                                handle,\n                                                handle.type());\n    maker = (ListMaker)cs.getTarget().invoke();\n  }\n\n  public void invokeMaker(Object obj)\n  {\n    String result0 = maker.makeList(obj).get(0);\n    System.out.println(\"Result[0] = \\\"\" + result0 + \"\\\"\");\n  }\n\n  public static void main(String[] args)\n      throws Throwable\n  {\n    LMTest lmt = new LMTest();\n    lmt.setMaker(LMTest::listify);\n    lmt.invokeMaker(\"version 1\");\n    lmt.invokeMaker(1);\n    //\n    lmt.setMaker(\"junk.LMTest\", \"listify\");\n    lmt.invokeMaker(\"version 2\");\n    lmt.invokeMaker(2);\n  }\n}\n```\n\n\nI've been able to understand the similar examples I've found online, but they are all end-results; I haven't been able to find anything  descriptive enough (for me, at least) on how the end-results were derived to help me figure out what I'm doing wrong.\n    ", "Answer": "\r\nI think the error is the use of ```\n.generic()```\n in ```\nhandle.type().generic()```\n in your call to ```\nLambdaMetafactory.metafactory()```\n. \n\nI took your code, removed the call to ```\n.generic()```\n and your code ran successfully.\n\nThe documentation for the ```\ngeneric()```\n method says that this method converts all types within the ```\nMethodType```\n it is called on to Object.  ```\nh.type()```\n is a signature for a method that takes an Object and returns a List, whereas ```\nh.type().generic()```\n is a signature for a method that takes an Object and returns an Object.\n\nI don't think that the ```\ngeneric()```\n method has anything to do with generic types.  Please don't feel you have to use it just because the method in your functional interface has a parameter with a generic type.  I admit I hadn't come across this method before, but I think it has a confusing name.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Java 7 zipfs: File is also a folder\r\n                \r\nI've been using Java 7's ZipFS support.\n\nhttps://gist.github.com/stain/5591420\n\nshows the behaviour, which I find a bit odd. Basically you can create a ZIP file system, make a file with a given name, and then also make a folder with the same name.\n\nThe reason for this seems to be that internally the folder gets \"/\" appended to its name - however this new name is not returned, therefore you end up in a strange situation where Files.isDirectory() returns false immediately after a successful Files.createDirectory().\n\n```\ntry (FileSystem fs = tempZipFS()) {\n        Path folder = fs.getPath(\"folder\");\n        Files.createFile(folder);\n        assertTrue(Files.isRegularFile(folder));\n        assertFalse(Files.isDirectory(folder)); \n//        try {\n            Files.createDirectory(folder);\n//        } catch (FileAlreadyExistsException ex) {              \n//                Is not thrown!\n//        }\n\n        // but a second createDirectory() fails correctly\n        try {\n            Files.createDirectory(folder);\n        } catch (FileAlreadyExistsException ex) {               \n        }\n\n        // Look, it's both a file and folder! \n        Path child = folder.resolve(\"child\");\n        Files.createFile(child);\n\n        // Can this be tested?\n        assertTrue(Files.isRegularFile(folder));\n        // Yes, if you include the final /\n        assertTrue(Files.isDirectory(fs.getPath(\"folder/\")));\n        // But not the parent\n//          assertTrue(Files.isDirectory(child.getParent()));\n        // Or the original Path\n//          assertTrue(Files.isDirectory(folder));\n    }\n```\n\n\nSo as long as you have the \"/\" as the suffix, you can even work with both, and that's how they are listed if you do a directory listing of the root. \n\nNow the ZIP format itself allows this as it only deals with entries in a ZIP file (even allowing multiple entries with the same name), however normal use of a \"FileSystem\" would normally not allow multiple entries with the same name ; as can be seen when I try to create the folder twice.\n\nThe produced ZIP file can be browsed correctly with infozip, 7Zip and Windows 8; but trying to unzip will obviously fail because the native file system don't support such duality.\n\nSo is this a feature, bug or something in between?\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Vectors, gather/scatter and sparse arrays\r\n                \r\nAccording to Computer Architecture: A Quantitative Approach, vector processors, both classic ones like Cray and modern ones like Nvidia, provide gather/scatter to improve performance on sparse arrays, where the array is in sparse form in memory and gathered to dense form in vector registers.\nIt seems to me if the array is so sparse – the density of nonzero elements so low – that it would be inefficient to represent it in dense form in memory, then it must also be inefficient to represent it in dense form in vector registers. For example, if 99% of entries are zero, then representing it in dense form in memory would waste 98% of the memory... but would waste 99% of the vector register capacity and arithmetic operations! That's high enough that you would be better off just processing it with scalar operations. If 75% of entries are zero, then you would be better off to represent it in dense form in memory and avoid the nonsequential gather/scatter operations.\nWhat is the typical density of nonzero elements where gather/scatter is used? Is it very common for it to be in some sweet spot where this duality makes sense - in which case, what workloads generate this particular density range so often - or is there something else I am missing?\n    ", "Answer": "\r\nUpdating comment to answer.\nA useful datapoint to answer to question can be found at docs.nvidia.com/cuda/cusparse/index.html. It recommends using cuSparse library for matrices with >95% zeros. There should be a trial and error to determine the exact sweet spot for your application and hardware where switching from sparse to dense representation provides better performance.\nWithout dedicated hardware to manage math with data in sparse representation, converting to dense representation in datapath is the way to perform math. Although, in a way, scatter/gather is dedicated HW, that delays the sparse->dense conversion until we really need it (i.e. ALUs needing registers with operand values).\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "timezone-independent date/time\r\n                \r\nWhat I am trying to do is a basic alarm app on Android. When I set date and time via UI (say 2012-09-26 at 14:37) I want the alarm go off at that time regardless of the timezone. That setting is serialized as two separate values - date value and offset from the beginning of the day in milliseconds.\n\nI also made a mistake of using Joda library for date/time manipulation. The API confused me by looking very similar to .NETs DateTime API, but still suffering from the same duality issue as default Java framework APIs, where the object value is in UTC, but its properties are in local time (this concept blows my mind btw). It also seems to have trouble picking up Android's time zone change automatically.\n\nThis is a summary of what I have:\n\n```\n// part of reminder class\npublic DateTime getNextAlarm()\n{\n    DateTime now = DateTime.now();\n    DateTime next = date.withMillisOfDay(time);\n    while (next.compareTo(now) <= 0)\n        next = next.plusDays(repeat);\n    return next;\n}\n\n// inside worker thread\nworkerEnabled = true;\nwhile (workerEnabled)\n{\n    try\n    {\n        Thread.sleep(10000);\n    }\n    catch (InterruptedException e)\n    {\n        workerEnabled = false;\n        return;\n    }\n\n    DateTimeZone tz = DateTimeZone.forTimeZone(TimeZone.getDefault());\n    if (nextAlarm != null && nextAlarm.withZoneRetainFields(tz).compareTo(new DateTime(tz)) < 0)\n    {\n        nextAlarm = reminder.getNextAlarm();\n\n        // perform alarm action\n    }\n}\n```\n\n\nEverything is fine and dandy until I try to switch timezones while app is running (after the setting was made). This is where the weird stuff begins. I can't even describe what exactly is wrong other than that not matter what I do it doesn't work right.\n\nI guess what I am looking for is a general direction on how to do timezone-independent math in Java/Android either in Joda or standard APIs.\n    ", "Answer": "\r\nI use ```\nAlarmManager```\n to download files at a particular time of day. Example code from a helper class I have...\n\n```\npublic void createDownloadAlarm() {\n    Intent i = new Intent(MyApp.ACTION_DOWNLOAD_FILES);\n    PendingIntent operation = PendingIntent.getService(context, 0, i, PendingIntent.FLAG_UPDATE_CURRENT);\n\n    Calendar cal = Calendar.getInstance();\n    cal.set(Calendar.HOUR_OF_DAY, 1);\n    cal.set(Calendar.MINUTE, 30);\n    cal.set(Calendar.SECOND, 0);\n\n    AlarmManager am = (AlarmManager) context.getSystemService(Context.ALARM_SERVICE);\n    am.setRepeating(AlarmManager.RTC_WAKEUP, cal.getTimeInMillis(), AlarmManager.INTERVAL_DAY, operation);\n}\n```\n\n\nUsing ```\nCalendar.getInstance()```\n and then using the ```\nset(...)```\n method creates an alarm which will fire at the exact time in whatever time-zone.\n\nTo do what you describe, I would couple the above code with a ```\nBroadcastReceiver```\n which listens for ```\nACTION_TIMEZONE_CHANGED```\n - register it in the manifest as ```\nandroid.intent.action.TIMEZONE_CHANGED```\n.\n\nIn the ```\nBroadcastReceiver```\n I'd get it to call the method I've shown above which should (in theory) cancel the previous alarm and set a new one for local time when the time-zone changes.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to get href element with selector?\r\n                \r\nI am using this to get items from this website and return to a list.\n\n```\n  Document doc = null;\n    try {\n        doc = Jsoup.connect(\"http://www.gamespy.com/index/release.html\").get();\n    } catch (IOException e) {\n        // TODO Auto-generated catch block\n        e.printStackTrace();\n    }\n        // Get all td's that are a child of a row - each game has 4 of these\n        Elements games = doc.select(\"tr>  td.indexList1, tr > td.indexList2\");\n\n        // Iterator over those elements     \n        ListIterator<Element> postIt = games.listIterator();          \n        while (postIt.hasNext()) {     \n            // ...It \n\n            while (postIt.hasNext()) {     \n                // Add the game text to the ArrayList     \n                String name = postIt.next().text();\n                String platform = postIt.next().text();\n                String genre = postIt.next().text();\n                String releaseDate = postIt.next().text();\n                gameList.add(new GameRelease(name, platform, genre, releaseDate));\n                Log.v(TAG, name +platform + genre +releaseDate);\n            }\n```\n\n\nThis is the html for the each item\n\n```\n<tr>\n<td class=\"indexList1\" align=\"left\">\n  <a href=\"http://pc.gamespy.com/pc/hacker-evolution-duality-/\" class=\"b1\">  \n    <em>Hacker Evolution Duality </em>\n  </a>\n</td>\n<td class=\"indexList1\" align=\"center\">\n  PC \n</td>    \n<td class=\"indexList1\" align=\"center\">\n\n  Adventure \n</td>\n<td class=\"indexList1\" align=\"center\">\n    August 15, 2011\n    <!--08/15/2011-->\n</td>\n```\n\n\n\n\nEach item has the same pattern but i want to know could i retreive the url for each item too. You guys may need to view the source of the html too get a better idea.\n\nBut i want to store the url for each item in a string.\n    ", "Answer": "\r\n```\nwhile (postIt.hasNext()) {\n    // Get the title of the game\n    Element title = postIt.next();\n\n    System.out.println(title.text());\n\n    // Get the anchor element\n    Element url = title.select(\"a\").first();\n\n    // Get the URL here @@@\n    System.out.println(url.attr(\"href\"));\n\n    // Unneeded elements\n    Element platform = postIt.next();\n    Element genre = postIt.next();\n\n    // Get the release date of the game\n    Element release = postIt.next();\n    System.out.println(release.text() + \"\\n@@@@@@\");\n}\n```\n\n\nEDIT:  In your case:\n\n```\nElement name = postIt.next();\nString nameString = name.text();\n\nElement url = name.select(\"a\").first();\nString urlString = url.attr(\"href\");\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Lasso regression model has convergence warnings with GridSearchCV\r\n                \r\nHere is the code that I have:\n```\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\n\nalpha_space = {'alpha': np.logspace(-4, 0, 50)}\nlasso = Lasso(normalize=True,  tol=0.0001)\ngrid_search_lr = GridSearchCV (lasso, alpha_space, cv=3, scoring=\"neg_mean_squared_error\")\ngrid_search_lr.fit(X_tr, y_tr)\n\nprint(grid_search_lr.best_params_)\nprint(np.sqrt(-grid_search_lr.best_score_))\n```\n\nBut when I go to run it, I get at least 20 of these warnings before the answer:\n```\n/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8451216620580.201, tolerance: 12888767617.309622\n```\n\npositive)\nWhat should I do in order to fix these warnings or prevent them?\n    ", "Answer": "\r\nThe ```\nLasso```\n estimator uses an iterative algorithm to solve the optimization problem. The iterative algorithm stops when it reaches the required level of convergence (set with the tolerance ```\ntol```\n). To avoid having the algorithm perform too many iterations (and possibly never stop), the algorithm also stops when it has performed a maximum number of iteration (```\nmax_iter```\n). In this case, it raises a warning that it failed to reach the required level of convergence.\nTo avoid the convergence warning, you can either:\n\nincrease the tolerance ```\ntol```\n (to require a less strict convergence level)\nincrease the maximum number of iteration ```\nmax_iter```\n (to spend more time finding the convergence level)\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to silence the output from this R package?\r\n                \r\nI'm playing a bit with the ```\nLowRankQP()```\n package in R, and even setting ```\nverbose=FALSE```\n still produces a lot of outputs (see example below). \n\nThe outputs are coming from the compiled part of the code. Is there a way (a wrapping function?) in R to make a call to ```\nLowRankQP()```\n absolutely silent (i.e. not print anything on the screen) without modifying the underlying compiled code (neither of the email addresses associated with this package is still active)?\n\n```\nlibrary(LowRankQP)\n\nVmat <- matrix(0,6,6)\ndiag(Vmat) <- c(1, 1,1,0,0,0)\ndvec <- c(0,-5,0,0,0,0)\nAmat <- matrix(c(-4,-3,0,-1,0,0,2,1,0,0,-1,0,0,-2,1,0,0,-1),6,3)\nbvec <- c(-8,2,0)\nuvec <- c(100,100,100,100,100,100)\n\naa<-LowRankQP(Vmat,dvec,t(Amat),bvec,uvec,method=\"CHOL\")\n\n# LowRankQP CONVERGED IN 15 ITERATIONS\n# \n#     Primal Feasibility    =   2.5719308e-16\n#     Dual Feasibility      =   7.1949984e-16\n#     Complementarity Value =   3.3066705e-11\n#     Duality Gap           =   3.3065273e-11\n#     Termination Condition =   9.7802929e-12\n```\n\n\nIt's the part that starts with \"LowRankQP CONVERGED IN 15 ITERATIONS\" that i want away with..\n\nUbuntu 11.04, R version 2.12.1 and LowRankQP() 1.0.1.\n    ", "Answer": "\r\nsink(file=NULL) does NOT work, since it closes the last sink, nothing more.\n\n\n  \n    sink(file=NULL) Warning message: In sink(file = NULL) : no sink to remove\n  \n\n\nWhat does work though is:\n\n```\nf = file()\nsink(file=f) ## silence upcoming output using anonymous file connection\n... your code here ...\nsink() ## undo silencing\nclose(f)\n```\n\n\nUsing an anonymous file has the advantage of being platform-agnostic, i.e. you don't have to come up with a temporary file name.\n\nExample:\n\n```\nf = file()\nsink(file=f)\nexample(glm)\nsink()\nclose(f)\n```\n\n\nI've used sink() successfully for other functions (e.g. normalmixEM2comp {mixtools}).\n\n(edit: the first version of this post did not use an explicit file handle, and thus gave a warning -- or even an error if you call the above snippet often enough). This is now fixed by using close(f).\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Generating all possible 3-connected graphs\r\n                \r\nThere is a conjecture by Tutte and Thomassen (Planarity and duality of finite and infinite graphs, 1979) saying this\n\n\n  A 3-connected graph can be obtained\n  from a wheel by succestively adding an\n  edge and splitting a vertex into two\n  adjacent vertices of degree at least\n  three such that the edge joining them\n  is not contained in a 3-cycle. If we\n  apply a more general splitting\n  operation (i.e., we allow the edge\n  joining the two new vertices to be\n  contained in a 3-cycle) then we can\n  start out with K_4, and we need only\n  the splitting operation in order to\n  generate all 3-connected graphs.\n\n\nI am trying to implement the last stated operation using iGraph with Python.\n\nI want to define a function splitVertex(g,v), taking a graph g and a vertex v, and then have it split v in all the possible ways as the operation defines. Then I want a list of all these new graphs, and I will do some further work on them.\n\nAt this point, I have the following function creating two new vertices x and y, which would be the newly created vertices after the split.\n\n```\ndef splitVertex(g,v):\n    numver = g.vcount()\n\n    g.add_vertices(2)\n\n   x = numver\n    y = numver+1\n\n    g.add_edges([(x,y)])\n```\n\n\nCan somebody please help me out with a nice way to implement this? I know this will generate a massive amount of data, but that is alright, I have plenty of time ;)\n\nEdit: Of course this have to be controlled in some way since the number of 3-connected graphs is infinite, but that is not what this question concerns.\n    ", "Answer": "\r\nYour splitting operation should be a bit more involved.  You need to modify all the edges that used to connect to ```\nv```\n to connect to ```\nx```\n or ```\ny```\n instead.\n\n```\ndef splitVertex(g,v):\n  numver = g.vcount()\n  g.add_vertices(2)\n  x = numver\n  y = numver+1\n  g.add_edges([(x,y)])\n\n  neighbors = g.neighbors(v)\n  g.delete_vertices([v])\n\n  new_graphs = []\n  for (neighbors_of_x, neighbors_of_y) in set_split(neighbors):\n    if len(neighbors_of_x) < 2: continue\n    if len(neighbors_of_y) < 2: continue\n    g2 = g.copy()\n    g2.add_edges(map(lambda neighbor_of_x: [neighbor_of_x, x], neighbors_of_x))\n    g2.add_edges(map(lambda neighbor_of_y: [neighbor_of_y, y], neighbors_of_y))\n    new_graphs.add(g2)\n  return new_graphs\n```\n\n\nWhere ```\nset_split```\n should generate all possible ways of splitting ```\nneighbors```\n into two sets.\n\nYou then need to generate all possible choices for ```\nv```\n and apply them to each graph.\n\nYou will likely get lots of isomorphic graphs.  I imagine there is a better way to do all of this, can't think of it off the top of my head.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Splitting Coordinates into 3 Subspaces To Resolve Unboundedness\r\n                \r\nI'm trying to implement the Cascaded Hough Transform (I have already implemented the 'normal' version.) but I'm having trouble understanding the following:\n\nAfter applying HT on an image, I am left with straight lines in hough space. The Cascaded version of the HT requires me to split the hough space into 3 sub-spaces so that the problem of unbounded values is solved.\n\nHow can I go about doing this?\n\nHere's a picture of how the hough space is split: \n\n\n  In order to restore the boundedness of the parameter space while preserving the symmetric space duality, we will split the  (a, b)-space into three bounded subspaces, as shown in the figure below.  The first subspace also has coordinates a and b, but only for | a | <= 1 and | b | <= 1. If | a | > 1 and | b | <= | a | , the point (a, b) turns up in the second subspace, with coordinates 1/a and b/a. If, finally, | b | > 1 and | a | < | b |, we use a third subspace with coordinates 1/b and a/b.\n\n\nHere is where I get seriously confused, suppose I have a line in the hough space. How is it going to be split up if it violates | a | <= 1 and | b | <= 1?\n\nDo I simply go through all the pixels in the line and if the pixel in question has coordinates greater than | a | <= 1 and | b | <= 1, I plot it in the 2nd subspace?\n\nI apologize if this sort of question is not welcomed on Stack Overlow - is there another site where I can ask questions about algorithms?\n\nSource for the image and the above quote\n    ", "Answer": "\r\nSuppose you have a point ```\n(x, y)```\n.  Under the Hough transform as presented, it goes to the line\n\n```\na x + b + y = 0\n```\n\n\nThis corresponds to a different line in each of your subspace plots:\n\n```\nSubspace 1: a x + b + y = 0\nSubspace 2: x + (b/a) + (1/a) y = 0\nSubspace 2: (a/b) x + 1 + (1/b) y = 0\n```\n\n\nFor example with the point ```\n(2, 1)```\n you get the three lines:\n\n```\nSubspace 1: 2a + b + 1 = 0\nSubspace 2: 2 + (b/a) + (1/a) = 0\nSubspace 2: 2(a/b) + 1 + (1/b) = 0\n```\n\n\nOr putting into ```\ny = m x + c```\n form:\n\n```\nSubspace 1: y = -2x - 1\nSubspace 2: y = -x - 2\nSubspace 2: y = -x/2 - 1\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Splitting Coordinates into 3 Subspaces To Resolve Unboundedness\r\n                \r\nI'm trying to implement the Cascaded Hough Transform (I have already implemented the 'normal' version.) but I'm having trouble understanding the following:\n\nAfter applying HT on an image, I am left with straight lines in hough space. The Cascaded version of the HT requires me to split the hough space into 3 sub-spaces so that the problem of unbounded values is solved.\n\nHow can I go about doing this?\n\nHere's a picture of how the hough space is split: \n\n\n  In order to restore the boundedness of the parameter space while preserving the symmetric space duality, we will split the  (a, b)-space into three bounded subspaces, as shown in the figure below.  The first subspace also has coordinates a and b, but only for | a | <= 1 and | b | <= 1. If | a | > 1 and | b | <= | a | , the point (a, b) turns up in the second subspace, with coordinates 1/a and b/a. If, finally, | b | > 1 and | a | < | b |, we use a third subspace with coordinates 1/b and a/b.\n\n\nHere is where I get seriously confused, suppose I have a line in the hough space. How is it going to be split up if it violates | a | <= 1 and | b | <= 1?\n\nDo I simply go through all the pixels in the line and if the pixel in question has coordinates greater than | a | <= 1 and | b | <= 1, I plot it in the 2nd subspace?\n\nI apologize if this sort of question is not welcomed on Stack Overlow - is there another site where I can ask questions about algorithms?\n\nSource for the image and the above quote\n    ", "Answer": "\r\nSuppose you have a point ```\n(x, y)```\n.  Under the Hough transform as presented, it goes to the line\n\n```\na x + b + y = 0\n```\n\n\nThis corresponds to a different line in each of your subspace plots:\n\n```\nSubspace 1: a x + b + y = 0\nSubspace 2: x + (b/a) + (1/a) y = 0\nSubspace 2: (a/b) x + 1 + (1/b) y = 0\n```\n\n\nFor example with the point ```\n(2, 1)```\n you get the three lines:\n\n```\nSubspace 1: 2a + b + 1 = 0\nSubspace 2: 2 + (b/a) + (1/a) = 0\nSubspace 2: 2(a/b) + 1 + (1/b) = 0\n```\n\n\nOr putting into ```\ny = m x + c```\n form:\n\n```\nSubspace 1: y = -2x - 1\nSubspace 2: y = -x - 2\nSubspace 2: y = -x/2 - 1\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "What is the non-synchronized equivalent to a protected type in Ada?\r\n                \r\nAda has a construct called \"protected types\", where you have a collection of variables and subprograms associated with a type, and the subprograms have implicit synchronization. These types can be instantiated and each instance will have its own memory where the variables live. This looks a lot like the class/object duality in mainstream OOP languages such as C++ and Java, minus inheritance, plus mandatory implicit synchronization.\nIs there an equivalent to this construct, minus the synchronization? If not, what's the rationale behind this design choice?\nTo be entirely clear, I'm aware that Ada supports different styles of OOP without any kind of synchronization. My question is about the specific style of OOP I mentioned - as it is one of the most common styles found in mainstream languages, and is indeed also present in Ada in some form.\nTo further clarify the question, which had been intentionally (and misguidedly) left open-ended, I am aware that the answer is \"packages\". But then, consider the following:\n\nWe have packages, which are units containing variables and subprograms, of which several instances can be created\nWe have types, which are enums or projections/mod of built-it types (I know this is a very approximate definition, specifics don't really matter here)\nWe have protected types, which are... units containing variables and subprograms, of which several instances can be created. Plus, they have synchronization.\n\nThis begs the thought: why \"protected types\" and not \"protected packages\"? This thought is the origin of the present question.\n    ", "Answer": "\r\nOOP is a set of concepts in programming without any dependence in a particular syntax. According to the Ada 95 Rationale: \"Type extension in Ada 95 builds upon the existing Ada 83 concept of a derived type. In Ada 83, a derived type inherited the operations of its parent and could add new operations; however, it was not possible to add new components to the type. The whole mechanism was thus somewhat static. By contrast, in Ada 95 a derived type can also be extended to add new components.\"\nIn Ada a type is a type, independently of it providing OOP features or not. Ada 95 provided extension on top of other POO features already provided by Ada 83 types. The advantage of that is that you can turn easily a non-tagged type to a tagged type, if you later need type-extension, without affecting current uses of the type. This also avoids introducing hidden features in the OOP syntax, like friend classes (types sharing the package), static members (global package variables), the implicit ```\nthis```\n, or ```\nconst```\n at the end of a method to indicate that ```\nthis```\n object is not modified, etc.\nWhy protected types do not follow this pattern? They probably follow that of Ada 83 task types, but the latter don't have a ```\nprivate```\n part, so it is still inconsistent. The design probably chose syntax of task types as inspiration, but added private part for efficiency (that was the main concern: \"protected types allows a more efficient implementation of standard problems of shared data access\").\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to test angular $cacheFactory?\r\n                \r\nI am using $resource in an angular service.\nI want to use my own custom cache based upon $cacheFactory, rather than the built-in $http cache, so that I can manipulate the cache when responses arrive back from my REST service.\n\nI am having great difficulty mocking out the $cacheFactory in my unit test, Could someone help me define the right mock and setup for my tests?\n\nHere is the simplified version of the code I am trying to test. Notice that I am telling my angular app to use my custom cache ```\n'DefaultCache'```\n instead of the default ```\n$http```\n cache it would otherwise use, in ```\nmyApp.run()```\n. (I understand this to be the way to replace the default cache for all my $resource services).\n\nThe Code\n\n```\nvar myServices = angular.module('myServices', ['ngResource']);\n\nvar myApp = angular.module('myApp', [\n    'myServices'\n]);\n\nmyApp.run([\n    '$http',\n    '$cacheFactory',\n    function ($http, $cacheFactory) {\n        // Replace default $http cache with one we can control\n        $http.defaults.cache = $cacheFactory('defaultCache');\n    }]);\n\nmyServices.factory('MyService', [\n    '$resource',\n    '$cacheFactory',\n    function($resource, $cacheFactory) {\n\n        var cache = $cacheFactory.get('defaultCache');\n\n        function doSomething(data) {\n            var cached = cache.get('akey');\n            return angular.fromJson(data);\n        }\n\n        return {\n            things: $resource('/api/things/:id', { id: '@id' }, {\n                query: {\n                    method: 'GET',\n                    isArray: true,\n                    cache: true,\n                    transformResponse: function(data) {\n                        return doSomething(data);\n                    },\n                },\n            })\n        }\n    }]);\n```\n\n\nThe Test\n\nand this is my test setup. (Notice: that the provided mockCacheFactory returns an object):\n\n```\n///<reference path=\"~/Scripts/jasminejs/jasmine.js\"/>\n///<reference path=\"../../Web/Scripts/angularjs/angular.js\"/>\n///<reference path=\"../../Web/Scripts/angularjs/angular-mocks.js\"/>\n///<reference path=\"../../Web/Scripts/angularjs/angular-resource.js\"/>\n\ndescribe(\"MyServiceSpec\", function () {\n\n    beforeEach(module('myServices'));\n\n    describe('GivenThingsResource', function () {\n\n        var $httpBackend, MyService, mockCacheFactory;\n\n        beforeEach(module(function ($provide) {\n            mockCacheFactory = {\n                get: function (cacheName) {\n                    return {\n                        get: function (key) { },\n                        put: function (key, value) { },\n                    };\n                },\n            };\n\n            $provide.value('$cacheFactory', mockCacheFactory);\n        }));\n\n        beforeEach(inject(function (_$httpBackend_, _MyService_) {\n            $httpBackend = _$httpBackend_;\n\n            MyService = _MyService_;\n\n            spyOn(mockCacheFactory, 'get').andCallThrough();\n        }));\n\n        it(\"WhenQuery_ThenReturnsData\", function () {\n            $httpBackend.expectGET('/api/things').respond(JSON.stringify({ Things: [{ Id: '1' }, { Id: '2' }] }));\n            var result = MyService.things.query();\n            $httpBackend.flush();\n\n            expect(result).toEqualData({ Things: [{ Id: '1' }, { Id: '2' }] });\n        });\n\n    });\n});\n```\n\n\nTest Results:\n\nThe problem I am seeing is: that when the test runs, I get these two errors:\n\n```\nTypeError: 'undefined' is not an object (evaluating '$httpBackend.expectGET') in http://localhost:35050/Tests.js (line 76)\nTypeError: 'undefined' is not an object (evaluating '$httpBackend.expectGET')\n    at  TestSpec.js: line 76\n    at   jasmine.js: line 1064\n    at   jasmine.js: line 2096\n    at   jasmine.js: line 2086TypeError: '[object Object]' is not a function (evaluating '$cacheFactory('$http')')\nTypeError: '[object Object]' is not a function (evaluating '$cacheFactory('$http')')\n    at   angular.js: line 7527\n    at invoke (  angular.js: line 3966)\n    at   angular.js: line 3808\n    at getService (  angular.js: line 3930)\n    at invoke (  angular.js: line 3957)\n    at   angular.js: line 3808\n    at getService (  angular.js: line 3930)\n    at invoke (  angular.js: line 3957)\n    at   angular.js: line 3808\n    at getService (  angular.js: line 3930)\n    at invoke (  angular.js: line 3957)\n    at workFn (  angular-mocks.js: line 2161)\n    at   jasmine.js: line 1064\n    at   jasmine.js: line 2096\n    at   jasmine.js: line 2086\nundefined\n```\n\n\nSo, I am thinking my mock is wrong, so I changed the provided ```\nmockCacheFactory```\n to a function, so that the call to ```\n$cacheFactory('$http')```\n should succeed:\n\n```\nmockCacheFactory = function () {\n    return {\n        get: function (cacheName) {\n            return {\n                get: function (key) { },\n                put: function (key, value) { },\n            };\n        },\n    };\n};\n```\n\n\nBut I now get these errors:\n\n```\nTypeError: 'undefined' is not a function (evaluating '$cacheFactory.get('defaultCache')')\nTypeError: 'undefined' is not a function (evaluating '$cacheFactory.get('defaultCache')')\n    at  TestSpec.js: line 25\n    at invoke (  angular.js: line 3966)\n    at   angular.js: line 3808\n    at getService (  angular.js: line 3930)\n    at invoke (  angular.js: line 3957)\n    at workFn (  angular-mocks.js: line 2161)\n    at   jasmine.js: line 1064\n    at   jasmine.js: line 2096\n    at   jasmine.js: line 2086\nundefinedTypeError: 'undefined' is not an object (evaluating '$httpBackend.expectGET') in http://localhost:40529/Tests.js (line 78)\nTypeError: 'undefined' is not an object (evaluating '$httpBackend.expectGET')\n    at  TestSpec.js: line 78\n    at   jasmine.js: line 1064\n    at   jasmine.js: line 2096\n    at   jasmine.js: line 2086\n```\n\n\nHelp Please\n\nI don't really understand what is needed here in my mock to satisfy the code that is using my mock. It seems to need to have some javascript duality which I don't know how to mimic in my definition of the mock.\n\nDoes anyone know how my mock should be constructed? Or what else I am missing here?\n    ", "Answer": "\r\nToday I struggled with the same issue and found a different solution to make this work. (Angular 1.3.13)\n\nApperantly $cacheFactory has a get method so you can retrieve the instance for the cacheId.\nThis will enable you to spy on the correct cache instance.\n\n```\nbeforeEach(inject(function (_$cacheFactory_) {\n  mockCache = _$cacheFactory_.get('defaultCache');\n}));\n```\n\n\n\n\n```\nit('your test', function () {\n  spyOn(mockCache, 'get').andCallThrough();\n  ....\n  expect(mockCache.get).toHaveBeenCalledWith('akey'); \n});\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Tomcat not seeing new files\r\n                \r\nI am creating an application which produces some files/directories in my WebContent folder and I would like Tomcat to serve these static files (logs of some background jobs). \n\nHowever Tomcat does not seem to recognize new files (maybe files in new folders), and it keeps returning 404 for them. After Tomcat restart, the files are served Ok.\n\nI am using Tomcat 7.0, form within the Eclipse. The files are served by the default servlet.\n\nI assume that Tomcat somehow traverses WebContent initially and it just uses this cached list of files for faster operation. Is there a way to disable such a behavior (or maybe: what is the right way to serve new files generated by other processes)?\n\nThanks for help/suggestions. I am quite newbie to Tomcat, so I might be overlooking something basic.\n\nUpdate (based on accepted solution)\n\nThere seems to be some duality in the webapp folder. One is in the Eclipse project (and is returned by ```\ngetServletContext().getRealPath```\n, the other is by default somewhere in Eclipse metadata and can be seen in launch config in ```\nwtp.deploy```\n property. The files are somehow copied from Eclipse to the deploy dir. When I started to generate my files under ```\nwtp.deploy```\n, the problem got fixed.\n\nHowever, I still don't know, how to solve this in proper way, which will work both under Eclipse WTP and in normal Tomcat conditions.\n\nUpdate\n\nThe final solution was to avoid ```\nDefaultServlet```\n at all. I used ```\nFileServlet```\n based on http://balusc.blogspot.com/2009/02/fileservlet-supporting-resume-and.html and it works fine.\n    ", "Answer": "\r\nI had similar experince with Netbeans- it usually places compiled files into new folder and works with that folder. Not sure if that's the case with you; but files should be available if placed in the right folder.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Convergence warning: how to do action after it?\r\n                \r\nI am esing the ```\nElasticNet```\n from ```\nsklearn```\n.\nWith the typical commands\n```\nenet = ElasticNet(alpha=a, l1_ratio=l, random_state=42, tol=1e-8)\nenet.fit(X_train, y_train)\n```\n\nsometimes the model does not converge, i.e. I get the following\n```\nConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.378e+00, tolerance: 7.066e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n```\n\nI know this is not a good sign and I would like to handle such cases on my own. I would like to prompt a certain action if the model generates this warning. For example\n```\nif warning \"non convegence\": display something\n```\n\nSomebody can help? Unfortunately I cannot find how to retrieve this type of error so that I can handle it manually\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Customizing msbuild for .NET Core with something like CustomBeforeMicrosoftCommonTargets\r\n                \r\nFor a long time, I have been very successful at non-invasively customizing many .NET Framework builds by setting ```\nCustomBeforeMicrosoftCommonTargets```\n and ```\nCustomAfterMicrosoftCommonTargets```\n as environment variables in a command-line shell that corresponds to a given development/build workspace. \n\nI would set these environment variables to point to custom msbuild targets files that would then be automatically imported (before and after respectively) the import of the standard Microsoft provided targets files. This has worked great for a long time, but now .NET Core comes along and I find no mechanism quite like that. \n\nI am aware of ```\nDirectory.Build.props```\n and that does not appear to be equivalent. For one, it is invasive requiring me to add a file to a source tree that I don't want to necessarily touch in order to customize its build (maybe its an open source project and I don't want to be injecting new files into it). For two, it doesn't provide the dual Before/After import hooks which are very important (if this duality weren't important Microsoft would never have provided it). \n\nI also don't like dropping magic files in magic global locations as my build policies/customizations are themselves versioned source code which can vary from one developer workspace to another (even on the very same machine for the very same developer).\n\nIt seems odd that Microsoft would fail to retain such a long-standing and fundamentally useful msbuild customization capability in .NET Core. Am I missing an equivalently powerful, easy to use and non-invasive mechanism? Is it there and I just haven't found it?\n    ", "Answer": "\r\n```\nCustomBeforeMicrosoftCommonTargets```\n and ```\nCustomAfterMicrosoftCommonTargets```\n are still part of MSBuild 15 which is included in VS 2017 and the .NET Core SDK.\n\nSetting them as global variables will still import them and override the default locations used if not set. Use the ```\n/bl```\n argument to generate a binary build log and the MSBuild structured log viewer to diagnose issues you may have with it.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Windows API vs. UNIX shell (equiv?) -- Or -- When is a programming language a language and not a script? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is off-topic. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.\r\n                \r\n                    \r\n                        Closed 14 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI've seen a number of question's closed as \"Not programming related\" (e.g. https://stackoverflow.com/questions/397854/what-process-accesses-my-hdd)\n\nI understand that their's several alternative site (stackoverflow) themed-forums and to attempt keep site question's to a minimum also some may argue that this is too subjective, o well, I got madly flamed for my first answer, so here's my first question, I'll try to frame it in a psudo-contextual-basis (jepordy style) to keep some regulator's at bay... \n\nIs it not fair to #include UNIX systems's level discussion in the same realm as programming?  One of the most usefull UNIX tools I've ever used, strace/trus/par, is based around system call information and reporting, other tools like ltrace can do similar things for libararies... \n\nSystem admin, I agree is not for this forum, like \"How to I make qmail do X?\", but is \"My smtp virus scanner is not fast enough, based on dnotify?\" (answer) \"Hey, use inotify\", so easy to discreminate?  The latter may either be shell or linux kernel system call's.\n\nI am not much of one for standards (read one too many lately), I'm adding a tag on POSIX \"command language\", to shift some focus on idenitfying some definative info.\n\nSystems level interaction being somewhat of a programming-interface(API)/user-interface(shell) duality (perticularly for UNIX).\n\nIf the context of an inquisitor be primarially interface based and it is an easy quarry (or even typical) to solution an exclusivly programming/API responce, to help man and machiene alike, why require a domain change (body of knowledge or URL domain;)? \n    ", "Answer": "\r\nI'm sorry, I don't understand the distinction you appear to be trying to draw between UNIX and Windows. As someone who uses and programs both of them, the distinction about whether a call to a kernel service is in a library or not seems unimportant. The distinction is - is the call made in a programming context? For example, questions about the UNIX cat command do not, I suggest, belong here, whereas questions about the UNIX read() system call, which cat must use at some level, do.\n\nOh, and there is no \"tight integration\" between the kernel and the shell.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Cannot compile z3 library in Visual Studio 2008\r\n                \r\nI would like to use the z3 4.4 managed API in a winforms application currently built with VS2008 (.net framework 3.5). I can use z3 in with .net 4.x applications without issues, but upgrading the current application to use .net 4.x is not currently feasible for reasons unrelated to z3. I am able to build the api and include Microsoft.z3.dll in my application. However, when compiling the z3 C++ library from the VS2008 command prompt, I get numerous errors where an attempt is made to implicitly convert a const_iterator to an iterator. Example: \n\n\n  duality_solver.cpp\n  ..\\src\\duality\\duality_solver.cpp(243) : error C2440: 'initializing' : cannot convert from 'std::_Tree<_Traits>::const_iterator' to 'std::_Tree<_Traits>::iterator'\n          with\n          [\n              _Traits=std::_Tset_traits,std::allocator,false>\n          ]\n          No constructor could take the source type, or constructor overload resolution was ambiguous\n\n\nChanging std::_Tree<_Traits>::iterator to std::_Tree<_Traits>::const_iterator eliminates those errors. However, the resulting z3lib.dll copied to the bin\\x86 directory of VS2008 project invariably produces the run-time error: \n\n\n  Unable to load DLL 'libz3.dll': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\n\n\nThis also occurs if the libz3.dll is in the same directory as the api dll (Microsoft.z3.dll). I have also ensured that z3 and my project are built for same platform (x86). \nUsing libz3.dll built with VS2013 produces the same run-time error above in the VS2008 project. Can z3 version 4.4.0 be used in a Visual Studio 2008 project? If so, how can I ensure that libz3.dll can be loaded to avoid the error above?\n    ", "Answer": "\r\nWe don't build and test on VS 2008, and furthermore will at some \npoint move to C++ language features that are not supported \non old platforms (but supported across operating systems and \nnewer compilers).\n\nOn one of my machines, I use a community (free) version of VS2013 to build Z3.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Usefulness/point of function \"symbol-name\"?\r\n                \r\nOn first look it seems somewhat silly to have a function which returns the name of a symbol, which must be called using the name of that same symbol. i.e. it should already be obvious in the calling context what the function will return. On the other hand there is ```\nidentity```\n which is sometimes useful (I forget where just now) but I supposed (perhaps wrongly) that ```\nsymbol-function```\n is there for a reason other than simply to act as a kind of identity.\n\nHowever, the hyperspec offers a possible hint:\n\n```\n (symbol-name 'temp) =>  \"TEMP\" \n (symbol-name :start) =>  \"START\"\n (symbol-name (gensym)) =>  \"G1234\" ;for example\n```\n\n\nI note that ```\n:start```\n means get the name of the symbol ```\nstart```\n from the keyword package, where the keyword package is denoted simply by ```\n:```\n. \n(```\n:keyword```\n being its longer form, unnecessary to use). Thus, in this case ```\nsymbol-name```\n plays the role of simply removing the package prefix.\n\nThe other thing it might do is, given an implementation is case insensitive, it would get the actual name by removing case in the symbol name supplied.\n\nIs that roughly it or is there any importance to this function I am missing?\n\nOne thing I was confused by about symbols (cleared up now) is that ```\nsymbol-plist```\n does not tell you everything about the symbol (say, whether it holds the value of a special variable or function). Rather, plist is a mainly legacy feature now largely replaced by hashtables. So, a call to ```\nsymbol-plist```\n is going to return ```\nNIL```\n even if one has set a special variable on the symbol.\n\nOne final question on that, Paul Graham says in Chapter 8 (p133), that \"You can use symbols as data objects and as names for things without understanding how the two are related\". Would it be correct say that if we rarely now use plists, that, today, we generally don't use symbols \"as data objects\" at all, instead, just as names for things (allbeit with the duality in CL of course, i.e. ```\nsymbol-function```\n and ```\nsymbol-value```\n simultaneously).\n    ", "Answer": "\r\nSymbols are objects.  You can create them and pass them around programmatically.  One of the properties of these objects is their name, which is a string.  ```\nSymbol-name```\n is the reader (not accessor) for that.  That's all.\n\nSymbols are also used in the representation of code.  In this case, they are created by the reader and used by the compiler.  This is not their only use, however, and the spec makes no such assumptions either.  I hope that this addresses the core of your question.\n\nHere is a function that, given a symbol, returns a symbol interned in the same package but with a reversed name:\n\n```\n(defun reverse-symbol (symbol)\n  (intern (make-symbol (reverse (symbol-name symbol)))\n          (symbol-package symbol)))\n```\n\n\nHere is a function that, given a string designator, returns the designated string:\n\n```\n(defun designated-string (string-designator)\n  (ctypecase string-designator\n    (string string-designator)\n    (symbol (symbol-name string-designator))))\n```\n\n\nYou can also do all kinds of shenanigans in macros and compiler macros by inspecting the names of the symbols in the given form and applying some conventions (not that you should…).\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "'adb shell' are these two shells chained?\r\n                \r\nSome aspects of ```\nadb shell ...```\n behavior suggests these are two shells chained what stands behind that command. It means one shell of the host the ```\nadb shell```\n sequence is invoked on, followed by target system shell. Command string seems to go through pipe of two shells.\n\n```\nadb -s $AdbID shell echo find  / -type f \\( -name \\*audio\\* -or \\\n  -name \\*alsa\\* \\) \\( -path /usr/lib/\\* -or -path /usr/bin/\\* -or \\\n  -path /etc/\\*  \\)\n```\n\n\nresults in:\n\n```\nfind / -type f ( -name *audio* -or -name *alsa* ) \\\n    ( -path /usr/lib/busybox /usr/lib/dbus /usr/lib/faketime /usr.... long list of matching file system items follows )\n```\n\n\nList of items the patterns have been expanded against shows that expansion took place in target device file system, not on host where ```\nadb shell```\n were invoked. That means glob expansion did not take place on host. It is due to escaping asterisks. It looks like host shell consumed asterisks escape characters and was satisfied. Unescaped asterisks went then to target device shell where they were consumed for globs expansion.\nMyself tried out lot of other ways to escape asterisks in -path patterns. For all of them the same result as described above.\n\nFor Bash removal of quotes is made after expansions of all other kinds. No idea how does it work for shell on adb target.\n\nBut why command grouping - paranthesis - do not show that duality? Grouping escape was consumed, anyhow grouping is passed into goal command 'find', like it was one single shell. This observation belies thesis made above.\n\nAs one additional pro-argument for thesis made on input the naming A.. D.. Bridge (adb) seems to have very good reason - that piece of soft acts as a bridge between two -in this case- shells.\n\nIs it really that way in case of adb shell one deals with chain of two shells?\nOtherwise how to explain made observations? Is it possibly a bug of adb shell or target's shell?\n\nNote: For the case here Busybox runs on target system.\n    ", "Answer": "\r\nYes, there are two shells: the local shell and the remote shell.\n\n```\nadb shell```\n uses ```\nsystem(3)```\n semantics, just like ```\nssh```\n and ```\neval```\n. With this convention, all the arguments are joined with spaces and then evaluated by a shell.\n\nThe alternative is ```\nexecve(2)```\n semantics, used by ```\nsudo```\n and ```\nxargs```\n. With this convention, the first argument is considered the executable name, and the rest are passed verbatim as arguments. This is what you're trying to do, and is generally preferably because it's secure and robust, but ```\nadb shell```\n doesn't support it.\n\nTo run ```\nadb shell```\n with an arbitrary command, you have to escape values as appropriate for the remote shell, and then escape that whole command so that the local shell will pass it on correctly.\n\nIn this case you can simply wrap the escaped command in single quotes:\n\n```\nadb shell 'echo find  / -type f \\( -name \\*audio\\* -or \\\n  -name \\*alsa\\* \\) \\( -path /usr/lib/\\* -or -path /usr/bin/\\* -or \\\n  -path /etc/\\*  \\)'\n```\n\n\n\n\nI can't explain what you say you're seeing with parentheses though. They should definitely be giving an error, and they do for me:\n\n```\n$ adb shell echo find / -type f \\( -name ...\n/system/bin/sh: syntax error: '(' unexpected\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Name assignment and reuse in python namespace\r\n                \r\nI am currently trying to figure out the internals of mappingproxies and namespaces in python. While testing a bit, I came accross some behavior I did not expect.\n\nI define a class, instantiate it, define another one under the same name and instantiate that one.\n\n```\nclass A:\n    color = 'white'\n    def __init__(self, val):\n        self.val = val\n\na1 = A(1)\n\nclass A:\n    color = 'black'\n    def __init__(self, val):\n        self.val = val\n\na2 = A(2)\n```\n\n\nNow, a1 and a2 are instances of different class objects that both still exist. In the namespace, the second, altered version of the class is now assigned to the name A. The first, initial version of the class object can only be addressed via its instance's ```\n__class__```\n attribute. \nStill, you can fully interact with the old class object.\n\n```\nprint(a1.__class__ is a2.__class__)     # False\nprint(a1.__class__ is A)                # False\nprint(a2.__class__ is A)                # True\na3 = a1.__class__(3)\nprint(a3.__class__ is a1.__class__)     # True\nprint(a3.color)                         # white\na3.__class__.color = 'red'\nprint(a1.color)                         # red\n```\n\n\nI am guessing that pythons's object reference counter is responsible for the fact that the old class object still exists, because the counter was not zero as a1 was still holding a ref, when the new class object was assigned to the name A.\n\nAs for my question: Is this intended behavior? If so, what is the reasoning behind it? For me, this looks a bit too implicit. \nI would have expected this to fail and throw some exception, tbh.\n\nEDIT\n\nTo explain why this strikes me and as an answer to Daniel Roseman in the comments below:\n\nBoth, a1 and a2 consider themselves instances of ```\n__main__.A```\n, when in fact one of them is an instance of what used to be ```\n__main__.A```\n. That leaves me with an active, usable object that has no obviously defined handle in my namespace. I think this is exclusive to class objects due to their class-object duality.\n\nI am working on some tool that dynamically builds classes and executes command sequences on instances of them, all based on some strange input. That involves a lot of dynamic imports. Not knowing about this behavior, I could end up debugging classes and their build process when I should actually be looking into some threading issue.\n    ", "Answer": "\r\nIs this intended behavior?\n\nYes.\n\nWhat is the reasoning behind it?\n\nAs Daniel Roseman is getting at in the comments above, this is a specific case of the general rule that everything in Python is an object.\n\nConsider the following code snippet:\n\n```\nsome_string_a = 'white'\nsome_string_b = 'black'\n\na = some_string_a\nprint(a)\n\n    >>> white\n\na = some_string_b\nprint(a)\n\n    >>> black\n\nprint(some_string_a)\n\n    >>> white\n```\n\n\nI'm sure you're not surprised that you can still interact with ```\nsome_string_a```\n, even though a variable name that used to refer to it has been reassigned and now refers to something different.\n\nBut, since the two classes in your question are also objects, it's an analogous case.  Why shouldn't you be able to interact with an object (the first class you defined), just because you've reassigned a variable name (```\nA```\n) such that it now refers to a different object?\n\nAs you mention in your edit, this can lead to some namespace weirdness...but that's the price that Python pays for the gains it gets in consistency by treating everything as an object.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Cannot Use Custom Cursor\r\n                \r\nI am trying to use a custom cursor with a url code, but it seems that it will not work. Here is the link to the cursor I am trying to use: http://www.rw-designer.com/cursor-detail/43903\n\nSnippet:\n\n\r\n\r\n```\n.dropbtn {\r\n  background-color: rgba(0, 0, 0, 0.0);\r\n  font-family: 'Montserrat', sans-serif;\r\n  color: white;\r\n  padding: 5px;\r\n  font-size: 14px;\r\n  border: none;\r\n  cursor: url(http://www.rw-designer.com/cursor-extern.php?id=43903), auto;\r\n}```\n\r\n```\n<div class=\"dropdown\">\r\n  <button onclick=\"myFunction()\" class=\"dropbtn\">&#8883;Featured&#8882;</button>\r\n  <div id=\"myDropdown\" class=\"dropdown-content\">\r\n    <a href=\"walnutwetbar.html\">Walnut Wetbar</a>\r\n    <a href=\"woodandsteel.html\">Wood and Steel</a>\r\n    <a href=\"bluestainpine.html\">Blue Stain Pine Changing Table</a>\r\n    <a href=\"dualityguitar.html\">Duality Guitar</a>\r\n  </div>\r\n</div>```\n\r\n\r\n\r\n\n    ", "Answer": "\r\nSuper close, just add the word 'auto' at the end of cursor. \nIE:\ncursor: url(http://www.rw-designer.com/cursor-extern.php?id=43903),auto;\n\nhttps://jsfiddle.net/ttngcLgf/\n\n\r\n\r\n```\n.dropbtn {\r\n  background-color: black;\r\n  font-family: 'Montserrat', sans-serif;\r\n  color: white;\r\n  padding: 5px;\r\n  font-size: 14px;\r\n  border: none;\r\n  cursor: url(http://www.rw-designer.com/cursor-extern.php?id=43903),auto;\r\n}```\n\r\n```\n<div class=\"dropdown\">\r\n  <button onclick=\"myFunction()\" class=\"dropbtn\">&#8883;Featured&#8882;</button>\r\n  <div id=\"myDropdown\" class=\"dropdown-content\">\r\n    <a href=\"walnutwetbar.html\">Walnut Wetbar</a>\r\n    <a href=\"woodandsteel.html\">Wood and Steel</a>\r\n    <a href=\"bluestainpine.html\">Blue Stain Pine Changing Table</a>\r\n    <a href=\"dualityguitar.html\">Duality Guitar</a>\r\n  </div>\r\n</div>```\n\r\n\r\n\r\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Capturing Popups, Alerts, and Exceptions from Excel with VB 2010\r\n                \r\nThis is my first time posting in stackoverflow.  I started learning VB 2010 yesterday (though I do know some Ruby) and have googled this problem a lot but haven't found much.  \n\nI've written a program that takes a CSV list of filepaths (all .XLS files) and attempts to open them.  These excel workbooks were flagged as unreadable by another program; my program tries to capture the warning, popup, or exception that caused the error.  It works for most exceptions (password protected, Unreadable Content, Dangerous File, etc.), but some popups that require you to click the 'OK' button to continue aren't caught.  Maybe they aren't categorized as Exceptions or something, I'd love to know. It would be great to at least get the text form of them.  Here is my script:\n\n```\nPrivate Sub runReportButton_Click(ByVal sender As System.Object, ByVal e As        System.EventArgs) Handles runReportButton.Click\n    Dim Exl As New Excel.Application()\n    Exl.Visible = False\n    Exl.DisplayAlerts = False\n\n    For Each row As DataGridViewRow In dgvReport.Rows\n        If Not IsNothing(row.Cells(0).Value) Then\n            If row.Cells(0).Value.ToString.Contains(\".xls\") Then\n\n                Try\n                    'Open the workbook and attempt to catch the error!'\n                    'Use bogus passwords to cause Password Protected Error, Readonly disabled so the Password popup shows.  Update links disabled because it wasn't being caught anyways'\n                    Dim wb As Excel.Workbook = Exl.Workbooks.Open(row.Cells(0).Value.ToString, [ReadOnly]:=False, [WriteResPassword]:=\"WWWWWWWWWWW\", [Password]:=\"WWWXWXWWWXW\", [UpdateLinks]:=False)\n                    row.Cells(4).Value = \"Could not catch an error :(\"\n                    wb.Close(0)\n                    dgvReport.Refresh()\n                Catch ex As Exception\n                    'Writes the Exception Message to the data grid view'\n                    row.Cells(4).Value = ex.Message\n                End Try\n                ProgressBar1.Value += 1\n            End If\n        End If\n        Exl.Quit()\n    Next row\n    dgvReport.Refresh()\nEnd Sub\n```\n\n\nThe reason I'm having a problem is that certain popups only occur when I open the file manually.  Even with Excel set to visible and display alerts on, programmatically the file opens and closes without any popups.  One particular warning is the following:\n\n\n  \"One or more worksheets in this workbook have names that contain square brackets:[]. To avoid unexpected results when referencing these worksheets, remove any square brackets from their names.\"\n\n\nIt doesn't seem like a fatal error, but it causes the other program to flag it as unreadable because we cannot be certain of the integrity of the contents (i.e. the unexpected results).  So my need isn't to ignore these popups or improve the other program, it's to capture this pesky popup message.  If anyone can shed any light on the duality of this popup's behavior or provide a different approach to capturing alerts it would be much appreciated!\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Which is a more efficient __hash__ implementation in Python objects? Hashing self.__str__, a tuple of attributes, or a real hash routine?\r\n                \r\nIt seems a common and quick way to create a stock ```\n__hash__()```\n for any given Python object is to ```\nreturn hash(str(self))```\n, if that object implements ```\n__str__()```\n.  Is this efficient, though?  Per this SO answer, a hash of a tuple of the object's attributes is \"good\", but doesn't seem to indicate if it's the most efficient for Python.  Or would it be better to implement a ```\n__hash__()```\n for each object and use a real hashing algorithm from this page and mixup the values of the individual attributes into the final value returned by  ```\n__hash__()```\n?\n\nPretend I've implemented the Jenkins hash routines from this SO question.  Which ```\n__hash__()```\n would be better to use?:\n\n```\n# hash str(self)\ndef __hash__(self):\n    return hash(str(self))\n\n# hash of tuple of attributes\ndef __hash__(self):\n    return hash((self.attr1, self.attr2, self.attr3,\n                 self.attr4, self.attr5, self.attr6))\n\n# jenkins hash\ndef __hash__(self):\n    from jenkins import mix, final\n    a = self.attr1\n    b = self.attr2\n    c = self.attr3\n    a, b, c = mix(a, b, c)\n    a += self.attr4\n    b += self.attr5\n    c += self.attr6\n    a, b, c = final(a, b, c)\n    return c\n```\n\n\nAssume the attrs in the sample object are all integers for simplicity.  Also assume that all objects derive from a base class and that each objects implements its own ```\n__str__()```\n.  The tradeoff in using the first hash is that I could implement that in the base class as well and not add additional code to each of the derived objects.  But if the second or third ```\n__hash__()```\n implementations are better in some way, does that offset the cost of the added code to each derived object (because each may have different attributes)?\n\nEdit: the ```\nimport```\n in the third ```\n__hash__()```\n implementation is there only because I didn't want to draft out an entire example module + objects.  Assume that ```\nimport```\n really happens at the top of the module, not on each invocation of the function.\n\nConclusion: Per the answer and comments on this closed SO question, it looks like I really want the tuple hash implementation, not for speed or efficiency, but because of the underlying duality of ```\n__hash__```\n and ```\n__eq__```\n.  Since a hash value is going to have a limited range of some form (be it 32 or 64 bits, for example), in the event you do have a hash collision, object equality is then checked.  So since I do implement ```\n__eq__()```\n for each object by using tuple comparison of self/other's attributes, I also want to implement ```\n__hash__()```\n using an attribute tuple so that I respect the hash/equality nature of things.\n    ", "Answer": "\r\nYour second one has an important performance pessimization: it's importing two names each time the function is called. Of course, how performant it is relative to the string-hash version depends on how the string is generated.\n\nThat said, when you have attributes that define equality for the object, and those attributes are themselves hashable types, the simplest (and almost certainly best-performing) approach is going to be to hash a tuple containing those attribute values.\n\n```\ndef __hash__(self):\n    return hash((self.attr1, self.attr2, self.attr3))\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Add an enter to string every 22 characters, waiting until a space [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        A good way to make long strings wrap to newline?\r\n                            \r\n                                (8 answers)\r\n                            \r\n                    \r\n                Closed 4 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI am trying to get my code to insert a ```\n\\n```\n into my code every 22 characters, but if the 22nd character is not a space it waits till there is one then inserts the ```\n\\n```\n there.\n\nI have tried looking up some code for the past hour on StackOverflow, but most seem to break with some changes, because they where specifically made for that problem.\n\nHere is some code I have tried\n\n```\ncount = 0\ns = \"I learned to recognise the through and primitive duality of man; I saw that, of the two natures that contended in the field of my consciousness, even if I could rightly be said to be either, it was only because I was radically both\"\nnewS = \"\"\nenterASAP = False\nwhile True:\n    count += 1\n    if enterASAP == True and s[count-1] == \" \":\n        newS = (s[:count] + \"\\n\" + s[count:])\n    if count % 22 == 0:\n        if s[count-1] == \" \":\n            newS = (s[:count] + \"\\n\" + s[count:])\n        else:\n            enterASAP = True\n    if count == len(s):\n        print(newS)\n        print(\"Done\")\n        break\n```\n\n\nI am wanting it to produce a text like \n```\nI learned to recognise\n the thorough and primitive```\n .......\nNote that it waits for the space and then the count resets at from ```\nthe```\n to ```\nprimitive```\n rather than adding on the 5 extra letters that the code waited for the space.\n\nThe code that I have produces the exact string it starts with. Which baffles me\n    ", "Answer": "\r\nAs discussed in the comments, the version with ```\ntextwrap```\n (doc):\n\n```\nimport textwrap\n\ns = \"I learned to recognise the through and primitive duality of man; I saw that, of the two natures that contended in the field of my consciousness, even if I could rightly be said to be either, it was only because I was radically both\"\n\nprint('\\n'.join(textwrap.wrap(s, 22)))\n```\n\n\nPrints:\n\n```\nI learned to recognise\nthe through and\nprimitive duality of\nman; I saw that, of\nthe two natures that\ncontended in the field\nof my consciousness,\neven if I could\nrightly be said to be\neither, it was only\nbecause I was\nradically both\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "share functions between two files\r\n                \r\nI am creating a quiz program in which I have a front end file where the user inputs answers and a back end question storing file. I want to share functions which have been defined in each of these files between both the files however I can only seem to share functions from one file to the other and not from both files with each other\n\ni have tried in file1 doing: from file2 import function2 and then in file2 doing: from file1 import function1. However this doesnt work. I just get a cannot import function1 error.  \n\n```\n#file1 (backend)\nfrom physicstester_frontend import answer\n\ndef quantum_test():\n\n    while True:\n        qq1 = \"describe the experiments that lead to wave particle duality.\"\n        print(qq1)\n        answer()\n        qq1_words = [\"double slit\", \"diffraction\", \"interference\", \"wave\", \"photoelectric\", \"effect\", \"photon\"]\n        if all(word in ans for word in qq1_words):\n            print(\"correct\") #prints correct if all required words are in string\n            break  \n        else:\n            print(\"not a full description, try again\")\n            continue\n\n#file2 (frontend)\nfrom physicstester_data import quantum_test\n\nprint(\"physics tester\")\nprint(\"topics: \\nQuantum\\n..\\n..\\n..\")\ntopics = input(\"which topic would you like to be tested on?: \")\n\nif topics.lower() == \"quantum\":\n    quantum_test()\n\ndef answer():\n    global ans\n    ans = input(\"answer: \")\n```\n\n\nwhen i do this i get \n\n```\nImportError: cannot import name 'quantum_test' from 'physicstester_data'\n```\n\n    ", "Answer": "\r\n```\nimport```\n cycles are Bad.\n\nPut ```\ndef answer()```\n in its own file, ```\nanswer.py```\n, to break the cycle.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "I seem to have two different Vim environments. What is causing this?\r\n                \r\nI am trying to set up a development environment on Windows 10. So far I've installed Vim and Cmder (the full version with Git for Windows). \n\nPlaying around, I noticed some strange behavior which I don't understand, but I feel like it is important that I understand.\n\nCase A  \n\n\nI open PowerShell\nLocate the folder that contains ```\nvim.exe```\n\nRun ```\n.\\vim.exe```\n\nVim pops up and displays the default screen (VIM - Vi IMproved, version 8.1.1, etc.)\nIn Normal Mode I type ```\n:version```\n to check the version number and to see where my ```\n_vimrc```\n file is located\nVim gives me the expected output  \n\n\nCase B  \n\n\nI open Cmder and open a new PowerShell tab (I am assuming that that gives me access to the PowerShell instead of the default cmd.exe, but please correct me if I am wrong.)\nNOW THIS IS WHERE IT GETS INTERESTING\nIf I repeat steps 2-6 exactly as in Case A, I get exactly the same result.\n\n\nBUT:\nIf instead of locating the folder that stores ```\nvim.exe```\n I just type in ```\nvim```\n and hit ```\nEnter```\n it opens Vim once again, but this time it has a tab on the bottom that says \"unix\". See attached images. \n\nOut of curiosity, in Normal Mode I type ```\n:version```\n, just like in Case A, but this time I am getting a different date in the version section, a different selection of options, and a different Unix-like path to the vimrc file which in now ```\n.vimrc```\n instead of ```\n_vimrc```\n. \n\n  \n\n\n\nWhat gives? My guess is that Git for Windows that came with Cmder is simulating a Unix environment and accessing a different Vim version that was compiled for Unix?  \n\nIf this is true, then could you help me make sense of this Windows/Unix environment duality? Do I now have two HOME folders, two copies of the vimrc file, and two copies of who knows what else? What is simulating this Unix environment - Cmder?\n\nThanks!\n    ", "Answer": "\r\nI don't have experience with Cmder, but I use Git for Windows a lot.\nGit for Windows comes with some Unix utilities and uses Cygwin which is Unix emulator for running those. Vim is among them as default text editor for commit messages, etc. So it might be it.\n\nI tried to reproduce this on my machine. but I cannot reproduce what you are seeing. Nonetheless I found the vimrc file for the Vim you are probably using in the second case.\nIt is in ```\n<Cmder-dir>\\vendor\\git-for-windows\\etc\\vimrc```\n.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Graph theory questions from my Algorithms quiz today that I'd like help understanding\r\n                \r\nToday I had my algorithms quiz for the semester and I can't figure out these two questions and they've been bugging me all day. I've gone through my notes and the lecture notes and I'm still unsure. I would appreciate it if someone could take a look and provide some insight into these questions. These are not homework and I've already sat the quiz.\n\nTrue or False questions\n\n1) [Paraphrased] The maximum number of edges in a bipartite graph with n vertices is n(n-1)/2.\n\nI put this down as False, my logic is that n verticies means we have two n/2 rows. The first node has n/2 connections to the second row, the second row has n/2 connections to the second row... etc... \n\nHence, I calculated the maximum number of edges in a bipartite graph with n vertices to be (n^2/4). \n\n2) [Paraphrased] Is it possible to take a cut, that is not necessarily the minimum s-t cut in a graph with directed flows (Ford–Fulkerson algorithm) such that the flow capacity is greater than the s-t cut capacity? \n\nI put down false, but I don't understand the question... Is it possible to take an s-t cut such that the flow capacity is greater? I know the weak duality theorem and 'max flow = min cut' so I put down false, but I have no idea.\n\nShort answer question:\n\n1) Explain an efficient way to test weather a graph is connected.\n\nI suggested doing a breadth first search and if there were nodes that were not found by the BFS algorithm in the graph, then it was not connected. I wrote down the running time was O(m+n) hence it was an efficient algorithm to use. It was worth two marks and it was the final question but I'm now worried it was a trick question.\n\n2) In the graph: \n\n\n\nList the sets of vertices which demonstrate minimum vertex cover [paraphrased]\n\nMy answer was {A, D}, {A, E}, {B, C}, {B, D}, {C, E}, but now I'm worried it was just {A}, {B}, {C}, {D}, {E}...\n\nThanks for taking the time to read! :)\n    ", "Answer": "\r\nI only have the answer to the first graph right now, but you are correct.\n\nIn a bipartite graph, there have to be two sets of nodes - say x in the first group and (n - x) in the second.  \n\nThe maximum number of edges in this graph will then be x(n-x), or nx - x^2.\n\nThe maximum value of nx - x^2 is x = (n/2)\n\nSo the maximum number of edges in the graph is (n/2) * (n - (n/2)) = (n^2)/4, as you pointed out.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to get command line application output to a variable in background in PowerShell 5.1?\r\n                \r\nSOLVED\nThanks to @mklement0 's advice, I tried to get an exit code from rstcli64.exe:\n\nfrom cmd I get 0\nfrom zabbix-agent I get 3 (INVALID_DEVICE, according to manual)\nSo, the culprit is not PowerShell, but rstcli64.exe exiting with an error in conditions: Windows Server 2019 and ran from PS script ran by zabbix-agent. I've updated rstcli from Intel's website and new version has the same syntax and works perfectly in new conditions.\n\nORIGINAL POST\nI have Windows Zabbix Agent, which runs a PowerShell script, which runs a command line application, parses output and gives 1 or 0.\n```\n$states = C:\\util\\rstcli64.exe --information --volume 2> $null | select-string -Pattern \"State:\"\n\n$notNormalStates = $states | Select-String -Pattern \"Normal\" -NotMatch\nif ($states.Count -gt 0 -and $notNormalStates.Count -eq 0){\n    \"1\"\n} Else {\n    \"0\"\n}\n```\n\nThis script worked on Windows Server 2012 R2, but after migration to Windows Server 2019 (with PowerShell 5.1) it began to output only 0.\nThis is a wave-particle duality situation: if I run this script from command line (User, Administrator, System - the same), it gives 1, because it receives the output from rstcli64.exe; and if zabbix-agent runs this exact script, it gets nothing from rstcli64.exe, thus gives 0.\nSo I guess the difference is that I run the script from an interactive shell and zabbix-agent runs the script from background.\nAnd the question is: how do I get the output from a command line application in PowerShell 5.1 (Windows Server 2019), when run in background?\nMORE INFO\nIf I just use this:\n```\n$states = C:\\util\\rstcli64.exe --information --volume\n$states\nexit\n```\n\nIt shows a lot of data if I run the script in command line:\n\n--VOLUME INFORMATION--\nName:              HDD_MIRROR Raid Level:        1 Size:\n1863 GB StripeSize:        64 KB Num Disks:         2 State:\nNormal System:            True Initialized:       True Cache Policy:\nR\n--DISKS IN VOLUME: HDD_MIRROR --\nID:                0-0-0-0 Type:              Disk Disk Type:\nSATA Disk State:             Normal\n\nBut if ran from zabbix - there's nothing:\n\n6304:20201014:170446.686 EXECUTE_STR()\ncommand:'%SystemRoot%\\system32\\WindowsPowerShell\\v1.0\\powershell.exe\n-nologo -ExecutionPolicy ByPass -File \"C:\\util\\intel_rst_raid.ps1\"' len:0 cmd_result:''   6304:20201014:170446.686 Sending back []\n8208:20201014:170446.687 End of collect_perfstat()\n\nMORE INFO\nIt just does it with rstcli64.exe. With few other command line tools I get the same output when manually running script in cmd and triggering it from zabbix-agent. Again, only in PowerShell 5.1 in Windows Server 2019, so...\n    ", "Answer": "\r\nThis sounds like an issue with redirection and streams.  The information stream was introduced in 5.0 and Windows 2012R2 comes with 4.0.  Which might explain the different behavior.\nAbout_Redirection\nI'd play around with the redirection operators to see if you can get what you need piped to ```\nSelect-String```\n.  It might look something like:\n```\n$states = C:\\util\\rstcli64.exe --information --volume *>&1 | select-string -Pattern \"State:\" \n```\n\nThis takes all streams and redirects them to the success stream, this way everything goes down the pipeline to ```\nSelect-string```\n.\nI'd also advise you can make your RegEx a little more precise. Maybe ```\n\"^State:\"```\n so you are capturing lines that start with \"State:\". Though I don't know if there may be preceding white space.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "What could be the equivalent of a PHP array in ColdFusion?\r\n                \r\nWorking on some tutorials, I have seen PHP arrays are quite different from ColdFusion arrays, and that PHP does not have structures. I need to know what part of the following PHP code is possible in ColdFusion:\n\n```\npublic $colors = array(\n    array(27,78,181), // blue\n    array(22,163,35), // green\n    array(214,36,7),  // red\n);\n\npublic $fonts = array(\n    'Antykwa'  => array('spacing' => -3, 'minSize' => 27, 'maxSize' => 30, 'font' => 'AntykwaBold.ttf'),\n    'Candice'  => array('spacing' =>-1.5,'minSize' => 28, 'maxSize' => 31, 'font' => 'Candice.ttf'),\n    'DingDong' => array('spacing' => -2, 'minSize' => 24, 'maxSize' => 30, 'font' => 'Ding-DongDaddyO.ttf'),\n    'Duality'  => array('spacing' => -2, 'minSize' => 30, 'maxSize' => 38, 'font' => 'Duality.ttf'),\n    'Heineken' => array('spacing' => -2, 'minSize' => 24, 'maxSize' => 34, 'font' => 'Heineken.ttf'),\n    'Jura'     => array('spacing' => -2, 'minSize' => 28, 'maxSize' => 32, 'font' => 'Jura.ttf'),\n    'StayPuft' => array('spacing' =>-1.5,'minSize' => 28, 'maxSize' => 32, 'font' => 'StayPuft.ttf'),\n    'Times'    => array('spacing' => -2, 'minSize' => 28, 'maxSize' => 34, 'font' => 'TimesNewRomanBold.ttf'),\n    'VeraSans' => array('spacing' => -1, 'minSize' => 20, 'maxSize' => 28, 'font' => 'VeraSansBold.ttf'),\n);\n```\n\n\nAnother part of PHP is the ```\nforeach```\n loop like:\n\n```\nforeach($list as key=>$value) {\n\n}\n```\n\n\nI think this could be done as a loop over a structure, but I am not sure.\n    ", "Answer": "\r\nThe first example is just analogous to a CFML array, eg:\n\n```\ncolors = [\n    [27,78,181], // blue\n    [22,163,35], // green\n    [214,36,7]  // red\n];\n```\n\n\nWhilst it's true that PHP doesn't have something called a \"struct\", it has an associative array, which is the same thing, for all intents and purposes. And your latter example is one of those. The CFML equiv (abbreviated) would be:\n\n```\nfonts = {\n    'Antykwa' = {'spacing' = -3, 'minSize' = 27, 'maxSize' = 30, 'font' = 'AntykwaBold.ttf'}\n}\n```\n\n\nNote: you don't need to quote the key names in CFML, but ColdFusion will convert them all to upper case if you do not (I don't think Railo does, and there's a setting in CF11 to stop this from happening too). Note that in CF the ordering of the keys in a struct is not preserved; it can be in Railo, if using a linked struct (I'll leave it to you to look up about that)\n\nYou've a couple of options for looping over arrays and structs in CFML:\n\n```\nfor (element in array){\n\n}\n\nfor (key in struct){\n    value = struct[key];\n}\n```\n\n\nOne can also use iteration functions:\n\n```\narray.each(function(index, value, array){\n});\n\nstruct.each(function(key, value, struct){\n\n});\n```\n\n\nThere are also other iteration methods such as ```\nfilter()```\n, ```\nmap()```\n and the like. There are new to Railo 4.2 and COldFusion 11. Previous versions of each had headless functions for ```\neach()```\n, eg: ```\narrayEach(array, callback)```\n and ```\nstructEach(struct, callback)```\n\n\nIt's all in the docs.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How can I toggle my VS 2008 solution's target platform between Windows CE and Winforms?\r\n                \r\nI'm in the process of porting a legacy Windows CE / Compact Framework project from VS 2003 \nin XP Mode with .NET 1.1 to VS 2008 and .NET 3.5\n\nAs debugging is such a pain trying to target a handheld device (there is no emulator for the specific device I'm targeting, a Motorola 3190), I want to toggle my project between targeting Windows CE and Winforms (I will debug it as a Winforms app normally, periodically setting it to Windows CE so as to build and download to the device). How can I do that? I don't see now how Visual Studio knows the project is a Windows CE / CF project.\n\nIt does, because Project Properties has a Devices tab, and when I F5, an emulator (kind of a generic one) is invoked.\n\nBut on the project properties Application tab, the Target Framework dropdown is blank and \ngrayed out. Output type is Windows application. I would think Target Framework would be set \nto Windows CE or some such. Obviously it is set somewhere, but where? How can I toggle \nbetween it being run as a CE / CF and as a \"plain old\" Winforms project?\n\nSelecting Project > Change Target Platform does show \"Windows CE\" as the current value, but \nthe \"Change to:\" dropdown only contains:\n\n```\nPocket PC 2003\nWindows Mobile 5.0 Pocket PC SDK\nWindows Mobile 5.0 Smartphone SDK\nWindows Mobile 6 Professional SDK\n```\n\n\nThe project properties Devies tab has many more options in the \"Target device:\" dropdown, \nbut seemingly nothing of value for me.\n\nIf I unload the project and select \"Edit bla.csproj, I see the following entries in that .csproj file:\n\n```\n<NativePlatformName>Windows CE</NativePlatformName>\n. . .\n<PlatformFamilyName>WindowsCE</PlatformFamilyName>\n. . .\n<Reference Include=\"Microsoft.WindowsCE.Forms\">\n  <Name>Microsoft.WindowsCE.Forms</Name>\n</Reference>\n. . .\n<Import Condition=\"'$(TargetFrameworkVersion)' == 'v3.5'\" \nProject=\"$(MSBuildBinPath)\\Microsoft.CompactFramework.CSharp.targets\" />\n```\n\n\n...and possibly at least one of these is of import here (no pun intended), but if so, what should I change it to, and if I should change it, should I change it directly, or indirectly? If the latter, how?\n\nUPDATE\n\nTrying to add all the *.cs and *.resx files to a Winforms project, and attacking the duality that way, I get the following error on some, but not all of my *.resx files:\n\nInvalid Resx file. ResX input is not valid. Cannot find valid \"resheader\" tags for the ResX reader and writer type names.\n\nWhat does that mean? The solution here C# resx file error:  doesn't seem to apply to my situation, as the out-of-kilter / off-the-rails files already have this format:  \n\n```\n<resheader name=\"resmimetype\">\n  <value>text/microsoft-resx</value>\n</resheader>\n```\n\n    ", "Answer": "\r\nI do not do this anymore (see *note at bottom), but I used to keep all of my various projects under one solution.\n\n\nI had my Main MDI application project.\nI had 3 small, single form projects (one on the server, and 2 different label printing applications)\nThere were 2 Windows Mobile projects (one called Packout, and one called Inspections)\n\n\nThese projects already share their file locations on my PC where I have a folder called Common with classes that are used in all of the whole solution.\n\n\n\nTake the ```\nDatabase.cs```\n class shown above: Whether my project is an MDI Form, a stand alone form, or a Windows Mobile application, they are generally all going to connect to the same company database.\n\nInstead of adding the file to your project (which makes a copy of the file, and places the copy in your project), add the file as a link:\n\n\n\nI must admit: I never noticed the Add button was a Drop-Down until ctacke pointed it out to me years ago.\n\nNow, whenever you edit this ```\nDatabase.cs```\n file in one project, it will automatically be updated in all other projects that have it linked.\n\nWarning!\n\nThis does present issues, though!\n\nSometimes you NEED things in your Windows Forms that Windows Mobile just does not support. Sounds crazy, but it's true. Windows Mobile just won't do it all. So, instead of being stuck writing all of your classes for the weakest link (Windows Mobile), include some ```\n#define```\n statements in your class.\n\nBelow is a screenshot of a WM5 project that now has ```\nSystem.ComponentModel```\n commented out of the code because the BackgroundWorker control is not defined in Windows Mobile:\n\n\n\nWhat does this do for you?\n\nNow you can have multiple projects within your solution. Depending upon which one you want to test your code on, just Right-Click that project, and select Set as StartUp Project.\n\n\n\nNow you can test and develop for a Windows Form application for basic code or whatever emulator you prefer (as long as it isn't one of those icky iPhones and Android devices), then switch back to your old Company Clunker for final testing and fine tuning.\n\n*Since we got VS2010 and VS2012, I have not been able to keep all of my projects under one solution. Most of the files, however, are still linked to the separate projects.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Lasso not converging & ElasticNet uses all coefficients\r\n                \r\nBasically, I am trying to see whether doing Penalized Regression on a Random Forest can help in getting better predictions than the Random Forest itself.\n\nWhat I did:\n\n\nI cleaned the dataset, removed outliers, and so on..\nDid a Train set - Split Test (0.75 (19693 obs)  - 0.25 (6565 obs))\nPerformed a Random Forest on the training dataset then predictions on the test set resulting in a  ```\n(6565,)```\n array with all the predictions.\nGrid Search the best Random Forest resulting in a optimal number of trees ( ```\nn_estimators```\n) of ```\n1200```\n.\nRunning the optimum Random Forest and finding each prediction for each tree using the following code ```\npredictions_all = np.array([tree.predict(test_features) for tree in rf.estimators_])```\n resulting in a ```\n(6565,1200)```\n matrix (i.e if you do the mean of each row you get the prediction of the Random Forest).\nconcatenate this matrix with my target variable resulting in a ```\n(6565,1201)```\n matrix.\nSetting a Train set - Split Test (0.75 (4923 obs)  - 0.25 (1642 obs)).\nDoing a Ridge / Lasso / adaptiveLasso / ElasticNet on the training set and if this latter only consider some coefficients (i.e trees), compare the aggregated mean with the Random Forest we did at step 3 to see if Lasso on a Random Forest performs better than the Random Forest itself.\n\n\nThe problem is that when I try Ridge, Lasso & Adaptive Lasso, it doesn't converge if ```\nalpha != 0```\n (OLS)\n\n```\nfrom sklearn.linear_model import Lasso\nlasso00001 = Lasso(alpha=0.0001, max_iter=10000,normalize=True)\nlasso00001.fit(train_features,train_labels)\ntrain_score00001=lasso00001.score(train_features,train_labels)\ntest_score00001=lasso00001.score(test_features,test_labels)\ncoeff_used00001 = np.sum(lasso00001.coef_!=0)\n\nprint(\"training score for alpha=0.0001:\", train_score00001 )\nprint(\"test score for alpha =0.0001: \", test_score00001)\nprint(\"number of features used: for alpha =0.0001:\", coeff_used00001)\n```\n\n\nResulting in \n\n```\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104843192290351.6, tolerance: 137819106237.78107\n  positive)\n```\n\n\nI tried with ```\nmax_iter=100000```\n and ```\nmax_iter=1000000```\n but it doesn't converge as well. \n\nDoes anybody know why ?\n\nHowever, ElasticNet converge, I tried GridSearchCV and found out the optimal ElasticNet\n\n```\nfrom sklearn.linear_model import ElasticNet\n\n\nEN = ElasticNet(alpha=0.02, max_iter=1000000, normalize=True, l1_ratio = 0.8)\nEN.fit(train_features,train_labels)\ntrain_EN=EN.score(train_features,train_labels)\ntest_EN=EN.score(test_features,test_labels)\ncoeff_used = np.sum(EN.coef_!=0)\n\nprint(\"training score:\", train_EN)\nprint(\"test score: \", test_EN)\nprint(\"number of features used:\", coeff_used)\nprint(\"coefs:\", EN.coef_)\n```\n\n\nResulting in :\n\n```\ntraining score: 0.6679234101432687\ntest score:  0.6414639586584302\nnumber of features used: 1200\ncoefs: [0.00070865 0.00107221 0.00048273 ... 0.00062971 0.00057734 0.00033563]\n```\n\n\nWhich mean that he used every 1200 trees (variables). \nWhat is weird is that I need to have ```\nalpha = 6500```\n so that he only uses 1199 trees (variables).\n\nAm I missing something? Is that because all my variables (trees) are sensibly the same that he uses every single variable (tree) ?\n    ", "Answer": "\r\nWhat you missed\nYes, that's quite normal. In fact, you're doing a penalized regression on very (very very) correlated variables. Basically, each tree learns in the same way, but that's just the dataset on which they train that differs a little bit (that's called bagging). But as they differ only a little, that will result in highly correlated variables.   \n\nA little bit of philosophy\nI don't see why you would want to do that. Penalized regression is used when you want to keep only a few variables that are sufficient to predict (i.e. there is a lot of variables that are useless). If you had a lot of trees that were useless, better to keep less before.   \n\nFinally, in Random Forest, the number of trees are not the better thing to grid search, because more trees generally tends to give better performance. What you want is to have less so as to have less time-consuming algorithms... That's more interesting to grid search the depth of your model.   \n\nBagging : https://en.wikipedia.org/wiki/Bootstrap_aggregating, https://becominghuman.ai/ensemble-learning-bagging-and-boosting-d20f38be9b1e\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "ld linking error while compiling z3\r\n                \r\nI met the following error while compiling z3. It seems to be an error for ld. I wonder what I can do to make it compile. It is a problem from the opt branch in git. I am on iMac with  OS X 10.9.2 (13C1021)\nI am with xcode Version 5.1.1 (5B1008) with xcode-select tools installed to version 2333. I use port with version 2.2.1 with ld installed.\nThe problem seems to be a linking problem. I am using link loader as: ld64 @136_2+llvm33 (active)\nMy gcc is gcc (MacPorts gcc48 4.8.2_0) 4.8.2\n\nThank you very much!\n\n```\ng++ -o z3  shell/datalog_frontend.o shell/dimacs_frontend.o \n shell/gparams_register_modules.o shell/install_tactic.o shell/main.o     \nshell/mem_initializer.o shell/smtlib_frontend.o shell/z3_log_frontend.o api/api.a opt/opt.a parsers/smt/smtparser.a tactic/portfolio/portfolio.a tactic/ufbv/ufbv_tactic.a tactic/smtlogics/smtlogic_tactics.a muz/fp/fp.a muz/duality/duality_intf.a muz/bmc/bmc.a muz/tab/tab.a muz/clp/clp.a muz/pdr/pdr.a muz/rel/rel.a muz/transforms/transforms.a muz/base/muz.a duality/duality.a qe/qe.a tactic/sls/sls_tactic.a smt/tactic/smt_tactic.a tactic/fpa/fpa.a tactic/bv/bv_tactics.a smt/user_plugin/user_plugin.a smt/smt.a smt/proto_model/proto_model.a smt/params/smt_params.a ast/rewriter/bit_blaster/bit_blaster.a ast/pattern/pattern.a ast/macros/macros.a ast/simplifier/simplifier.a ast/proof_checker/proof_checker.a parsers/smt2/smt2parser.a cmd_context/extra_cmds/extra_cmds.a cmd_context/cmd_context.a interp/interp.a solver/solver.a tactic/aig/aig_tactic.a math/subpaving/tactic/subpaving_tactic.a nlsat/tactic/nlsat_tactic.a tactic/arith/arith_tactics.a sat/tactic/sat_tactic.a tactic/core/core_tactics.a math/euclid/euclid.a math/grobner/grobner.a parsers/util/parser_util.a ast/substitution/substitution.a tactic/tactic.a model/model.a ast/normal_forms/normal_forms.a ast/rewriter/rewriter.a ast/ast.a math/subpaving/subpaving.a math/realclosure/realclosure.a math/interval/interval.a math/simplex/simplex.a math/hilbert/hilbert.a nlsat/nlsat.a sat/sat.a math/polynomial/polynomial.a util/util.a  -lpthread  -fopenmp\n0  0x1079c1a68  __assert_rtn + 144\n1  0x107a3bccd  mach_o::relocatable::Parser<x86_64>::parse(mach_o::relocatable::ParserOptions const&) + 1039\n2  0x107a2b899  mach_o::relocatable::Parser<x86_64>::parse(unsigned char const*, unsigned long long, char const*, long, ld::File::Ordinal, mach_o::relocatable::ParserOptions const&) + 313\n3  0x107a290f0  mach_o::relocatable::parse(unsigned char const*, unsigned long long, char const*, long, ld::File::Ordinal, mach_o::relocatable::ParserOptions const&) + 208\n4  0x107a18797  archive::File<x86_64>::makeObjectFileForMember(archive::File<x86_64>::Entry const*) const + 795\n5  0x107a182b3  archive::File<x86_64>::justInTimeforEachAtom(char const*, ld::File::AtomHandler&) const + 139\n6  0x1079c5d46  ld::tool::InputFiles::searchLibraries(char const*, bool, bool, bool, ld::File::AtomHandler&) const + 210\n7  0x107a0b772  ld::tool::Resolver::resolveUndefines() + 200\n8  0x107a0d6e1  ld::tool::Resolver::resolve() + 75\n9  0x1079c1d44  main + 370\nA linker snapshot was created at:\n/tmp/z3-2014-03-25-110931.ld-snapshot\nld: Assertion failed: (cfiStartsArray[i] != cfiStartsArray[i-1]), function parse, file src/ld/parsers/macho_relocatable_file.cpp, line 1555.\ncollect2: error: ld returned 1 exit status\nmake: *** [z3] Error 1\n```\n\n    ", "Answer": "\r\nIt is because we used port and installed gcc and ld and other packages.\n\nAnother possibility is that ld was depend on llvm 3.3 rather than llvm 3.4. The problem was solved after updating ld.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to project a chessboard in camera coordinates to real-world coordinates in OpenCV using rvecs and tvecs outputs of cv.calibrateCamera?\r\n                \r\nSituation\nFollowing the Camera Calibration tutorial in OpenCV I managed to get an undistorted image of a checkboard using ```\ncv.calibrateCamera```\n:\nOriginal image: (named image.tif in my computer)\n\nCode:\n```\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\n# termination criteria\ncriteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\nobjp = np.zeros((12*13,3), np.float32)\nobjp[:,:2] = np.mgrid[0:12,0:13].T.reshape(-1,2)\n# Arrays to store object points and image points from all the images.\nobjpoints = [] # 3d point in real world space\nimgpoints = [] # 2d points in image plane.\n\nimg = cv.imread('image.tif')\ngray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n# Find the chess board corners\nret, corners = cv.findChessboardCorners(gray, (12,13), None)\n# If found, add object points, image points (after refining them)\n\nif ret == True:\n    objpoints.append(objp)\n    corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n    imgpoints.append(corners)\n    # Draw and display the corners\n    cv.drawChessboardCorners(img, (12,13), corners2, ret)\n    cv.imshow('img', img)\n    cv.waitKey(2000)\n\ncv.destroyAllWindows()\n\nret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n\n#Plot undistorted \nh,  w = img.shape[:2]\nnewcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n\ndst = cv.undistort(img, mtx, dist, None, newcameramtx)\n# crop the image\nx, y, w, h = roi\ndst = dst[y:y+h, x:x+w]\nplt.figure()\nplt.imshow(dst)\nplt.savefig(\"undistorted.png\", dpi = 300)\nplt.close()\n```\n\nUndistorted image:\n\nThe undistorted image indeed has straight lines. However, in order to test the calibration procedure I would like to further transform the image into real-world coordinates using the ```\nrvecs```\n and ```\ntvecs```\n outputs of ```\ncv.calibrateCamera```\n. From the documentation:\n\n\nrvecs: Output vector of rotation vectors (Rodrigues ) estimated for each pattern view (e.g. std::vector<cv::Mat>>). That is, each i-th rotation vector together with the corresponding i-th translation vector (see the next output parameter description) brings the calibration pattern from the object coordinate space (in which object points are specified) to the camera coordinate space. In more technical terms, the tuple of the i-th rotation and translation vector performs a change of basis from object coordinate space to camera coordinate space. Due to its duality, this tuple is equivalent to the position of the calibration pattern with respect to the camera coordinate space.\n\ntvecs:   Output vector of translation vectors estimated for each pattern view, see parameter describtion above.\n\n\n\nQuestion: How can I manage this? It would be great if the answers include a working code that outputs the transformed image.\n\nExpected output\nThe image I expect should look something like this, where the red coordinates correspond to the real-world coordinates of the checkboard (notice the checkboard is a rectangle in this projection):\n\n\nWhat I have tried\nFollowing the comment of @Christoph Rackwitz, I found this post, where they explain the homography matrix H that relates the 3D real world coordinates (of the chessboard) to the 2D image coordinates is given by:\n```\nH = K [R1 R2 t]```\n\nwhere ```\nK```\n is the camera calibration matrix, ```\nR1```\n and ```\nR2```\n are the first two columns of the rotational matrix and ```\nt```\n is the translation vector.\nI tried to calculate this from:\n\n```\nK```\n we already have it as the ```\nmtx```\n from ```\ncv.calibrateCamera```\n.\n```\nR1```\n and ```\nR2```\n from ```\nrvecs```\n after converting it to a rotational matrix (because it is given in Rodrigues decomposition): ```\ncv.Rodrigues(rvecs[0])[0]```\n.\n```\nt```\n should be ```\ntvecs```\n.\n\nIn order to calculate the homography from the image coordinates to the 3D real world coordinates then I use the inverse of H.\nFinally I use ```\ncv.warpPerspective```\n to display the projected image.\nCode:\n```\nR = cv.Rodrigues(rvecs[0])[0]\ntvec = tvecs[0].squeeze()\nH = np.dot(mtx, np.concatenate((R[:,:2], tvec[:,None]), axis = 1) )/tvec[-1] \nplt.imshow(cv.warpPerspective(dst, np.linalg.inv(H), (dst.shape[1], dst.shape[0])))\n```\n\nBut this does not work, I find the following picture:\n\nAny ideas where the problem is?\n\nRelated questions:\n\nHow do I obtain the camera world position from calibrateCamera results?\nHomography from 3D plane to plane parallel to image plane\nOpenCV Camera Calibration mathematical background\nCoordinate transformation in OpenCV\ntransform 3d camera coordinates to 3d real world coordinates with opencv\n\n    ", "Answer": "\r\nEvery camera has its own Intrinsic parameters connecting 2D image coordinates with 3D real-world. You should solve a branch of linear equations to find them out. Or look at cameras specification parameters, provided by manufacturers. \nFurthermore, if you want to warp your surface to be parallel to the image border use homography transformations. You need the projective one.  ```\nscikit-image```\n has prepaired tools for parameter estimation.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Defining Python Operators: A List\r\n                \r\nIn Learn Python the Hard Way by Zed Shaw There is a list of operators that weren't defined given as an exercise, and I've had trouble trying to find their definition / purpose around the web. \n\nHere's what I have so far:\n\n```\n+   : addition/concatenation \n-   : subtraction\n*   : multiplication \n**  : exponenttiation\n/   : division\n//  : floor division :: digits after the decimal place are removed\n%   : string type flag?\n<   : less than\n>   : greater than \n<=  : less than / equal \n>=  : greater than / equal\n==  : absolute equality\n!=  : not equal\n<>  : old not equal -- apparently phased out, use above != now\n()  : ________________________\n[]  : ________________________\n{}  : ________________________\n@   : decorators, maybe matrix multiplication in 3.5 future release\n'   : ________________________\n:   : ________________________\n.   : this is generally used as a modifying/linking element to property/subproperty\n=   : equality\n;   : ________________________\n+=  : duality in operation, successively :: x = x + 1 >> x += 1\n-=  : \"                                \" :: x = x - 1 >> x -= 1\n*=  : \"                                \" :: x = x * 1 >> x *= 1\n/=  : \"                                \" :: x = x / 1 >> x /= 1 \n//= : Floor division and assigns a value, performs floor division on operators and assign value to the left operand\n%=  : Modulus AND assignment operator, it takes modulus using two operands and assign the result to the left operand : c%=a == c = c % a\n**= : Exponent AND assignment operator: Performs exponential (power) calculation on operators and assigns value to the left operand : c **= a == c ** a , so c to the exponent of a\n```\n\n\nI'm sure these definitions aren't complete and they're probably poorly worded, so if you want to make corrections to the previous definitions, by all means, however I'm mainly trying to figure out the ones that I have yet to complete--There are blank lines above\n\nLinks I've attempted with: Python Operators 1 || Python Operators 2 || Python 3.0 Operators || 2.7.7 Operator Precedence ||\n    ", "Answer": "\r\n```\n%```\n is modulus. ```\n3 % 2 == 1```\n. You can also use it when formatting strings though, but as an operator, it is modulus. For formatting strings, myString.format() is preferred. \n\n```\n()```\n is either a function call, or order of precedence in general expressions. ```\nf(x)```\n, for example, or ```\n(3 * (1 + 2))```\n. It calls the ```\n__call__```\n  method of an object. It also creates a tuple literal, but only if there is at least one comma in the tuple. ```\n(4,)```\n for example. \n\n```\n[]```\n is indexing - it allows you to select a container by index via the ```\n__getitem__```\n and ```\n__setitem__```\n methods. ```\n[1,2,3,4,5,6][2] == 3```\n. It also creates a list. \n\n```\n{}```\n constructs either a set or a dictionary, depending on the context. \n\n```\n@```\n is used for decorators, not for matrix multiplication.\n\n```\n'```\n is a quote and equivalent to ```\n\"```\n\n\n```\n:```\n is used for list slicing, and to denote a code block. (Such as in a function, an error handling context or loop)\n\n```\n;```\n is not used unless you want to put multiple statements on one line, but that isn't encouraged for readability purposes. \n\nOther than that, I think you have your definitions more-or-less correct.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "_viewStart.cshtml does not inherit System.Web.WebPages.StartPage in web api 2.0 application\r\n                \r\nI have a web api 2.0 application I want to add view handling to.\n\nI am using postal.mvc5 and want to send an email from within the application.\n\nI have the regular controller routing solved, and am now down to the final error to solve.\n\nThe _ViewStart.cshtml page that is implemented with Postal.Mvc5 is:\n\n```\n@{ \n     Layout = null;\n }\n```\n\n\nMy web.config page in the views folder:\n\n```\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<configuration>\n  <system.web.webPages.razor>\n    <pages pageBaseType=\"System.Web.Mvc.WebViewPage\">\n      <namespaces>\n        <add namespace=\"System.Web.Mvc\"/>\n        <add namespace=\"System.Web.Mvc.Html\"/>\n        <add namespace=\"System.Web.Optimization\"/>\n        <add namespace=\"Postal\" />\n      </namespaces>\n    </pages>\n  </system.web.webPages.razor>\n</configuration>\n```\n\n\nThe error I am getting is:\n\n\n  Type 'ASP._Page_Views_Emails__ViewStart_cshtml' does not inherit from\n  'System.Web.WebPages.StartPage'.\n\n\nThe complete error is:\n\n\n  Source: System.Web ----Target Site: CheckAssignableType Timestamp: 10/23/2017 3:05:48 PM Message: Type 'ASP._Page_Views_Emails__ViewStart_cshtml' does not inherit from 'System.Web.WebPages.StartPage'. ----StackTrace: at System.Web.UI.Util.CheckAssignableType(Type baseType, Type type) at System.Web.Compilation.BuildManager.CreateInstanceFromVirtualPath(VirtualPath virtualPath, Type requiredBaseType, HttpContext context, Boolean allowCrossApp) at System.Web.Compilation.BuildManager.CreateInstanceFromVirtualPath(String virtualPath, Type requiredBaseType) at System.Web.WebPages.BuildManagerWrapper.CreateInstanceOfType[T](String virtualPath) at System.Web.WebPages.VirtualPathFactoryExtensions.CreateInstance[T](IVirtualPathFactory factory, String virtualPath) at System.Web.WebPages.VirtualPathFactoryManager.CreateInstanceOfType[T](String virtualPath) at System.Web.WebPages.VirtualPathFactoryExtensions.CreateInstance[T](IVirtualPathFactory factory, String virtualPath) at System.Web.WebPages.StartPage.GetStartPage(WebPageRenderingBase page, IVirtualPathFactory virtualPathFactory, String appDomainAppVirtualPath, String fileName, IEnumerable```\n1 supportedExtensions) at System.Web.WebPages.StartPage.GetStartPage(WebPageRenderingBase page, String fileName, IEnumerable```\n1 supportedExtensions) at System.Web.Mvc.RazorView.RenderView(ViewContext viewContext, TextWriter writer, Object instance) at System.Web.Mvc.BuildManagerCompiledView.Render(ViewContext viewContext, TextWriter writer) at Postal.EmailViewRenderer.RenderView(IView view, ViewDataDictionary viewData, ControllerContext controllerContext, ImageEmbedder imageEmbedder) at Postal.EmailViewRenderer.Render(Email email, String viewName) at Postal.EmailService.CreateMailMessage(Email email) at Postal.EmailService.Send(Email email) at Postal.Email.Send() \n\n\nI know this is pretty unconventional, but how do I get around this last error?\n\nUpdate on further debugging:\n\nI use Enterprise Logging on the web service, and noticed that it wasn't sending error emails until the next call so my error emails were not being sent until the next call to the web service.  I added a system.net section to the main web.config file with the smtp setup, and that actually made it worse.  No emails were being sent while the web service was running.\n\nI tried instantiating a regular web application instance in the global.asax file for the web api, but this seems to have no real effect.\n\nI have added some routing to the web.config file per the answer below, but that also has no effect.  The wep api 2 application has the same references and other configuration items that a regular web application has, but still has the problem.\n\nOne solution would be to recreate the web api 2 as a regular website with web api 2 added.  There are lots of online references on that, and the original application that the web api 2 application was spun off of was a regular website with api capability.\n\nFrom reading the literature, this duality problem I am dealing with is probably cured with .Net Core, but I can't use it on our current system.\n\nI guess the next question is why sendmail is disabled while the web api 2 is running.\n\nWhat about web api 2 would disable sendmail during a web api call?\n    ", "Answer": "\r\nI finally got the problem solved.  It was a problem with the web.config file in the Emails folder used by Postal.\n\nNormally, the web.config files contain the correct information when you instantiate a web application, and so the web.config file for the views folder inherits the necessary types.\n\nWhen starting with a web api 2 application, those types are not defined in the hierarchy and therefore not automatically inherited by the view folder.\n\nThe web.config for the Views/Emails folder was modified to this:\n\n```\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<configuration>\n  <configSections>\n    <sectionGroup name=\"system.web.webPages.razor\"\n  type=\"System.Web.WebPages.Razor.Configuration.RazorWebSectionGroup, System.Web.WebPages.Razor, Version=3.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\">\n      <section name=\"host\"\n    type=\"System.Web.WebPages.Razor.Configuration.HostSection, System.Web.WebPages.Razor, Version=3.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\"\n    requirePermission=\"false\"/>\n      <section name=\"pages\"\n    type=\"System.Web.WebPages.Razor.Configuration.RazorPagesSection, System.Web.WebPages.Razor, Version=3.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\"\n    requirePermission=\"false\"/>\n    </sectionGroup>\n  </configSections>\n  <system.web.webPages.razor>\n    <host factoryType=\"System.Web.Mvc.MvcWebRazorHostFactory, System.Web.Mvc, Version=5.2.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\"/>\n    <pages pageBaseType=\"System.Web.Mvc.WebViewPage\">\n      <namespaces>\n        <add namespace=\"System.Web.Mvc\"/>\n        <add namespace=\"System.Web.Mvc.Html\"/>\n        <add namespace=\"System.Web.Optimization\"/>\n        <add namespace=\"Postal\" />\n      </namespaces>\n    </pages>\n  </system.web.webPages.razor>\n  <appSettings>\n    <add key=\"webpages:Enabled\" value=\"false\"/>\n </appSettings>\n</configuration>\n```\n\n\nThe system then routed to the view and processed the email as expected.\n\nThe problems with emails going through as referenced above were caused by the email sending interface bombing in the middle of a send.  That was not really a problem caused by web api 2.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Defining array of values in Collection in Meteor\r\n                \r\nI have defined the following Collection in my application:\n\n```\nProjects = new Mongo.Collection(\"projects\")\n```\n\n\nIn this Collection, I have inserted:\n\n```\nProjects.insert({\n    source: \"https://upload.wikimedia.org/wikipedia/commons/7/7f/Pug_portrait.jpg\",\n    title: \"pug\",\n    artist: \"pug\",\n    description: \"This piece shows the duality of pug\",\n    price: \"priceless\"\n});\n\nProjects.insert({\n    source: \"https://i.stack.imgur.com/D2ABD.gif\",\n    title: \"doge\",\n    artist: \"doge\",\n    description: \"much doge, many deal with it, wow\",\n    price: \"bout tree fiddy\"\n})\n```\n\n\nI am attempting to create an array of the sources of the images using the following helper function:\n\n```\nsourceArray : function () {\n          // returns array of sources\n          var sources = [];\n          for (var i = 0; i < Projects.find().count(); i++) {\n            sources.push(images[i].source);\n          }\n          return sources;\n\n      }\n```\n\n\nthe \"images variable is previously defined as: ```\nimages = Projects.find().fetch();```\n\n\nI then call the helper function in my HTML.\n\n```\n<p>{{sourceArray}}</p>\n```\n\n\nOn the page, the first source appears fleetingly, but disappears within a few seconds. In the browser console the following is shown:\n\n```\nmeteor.js:888 Exception in template helper: TypeError: Cannot read property 'source' of undefined\n    at Object.Template.body.helpers.sourceArray (http://localhost:3000/art.js?913b8578eb54cde21abc07c994f6b29267232bc5:61:28)\n    at http://localhost:3000/packages/blaze.js?a5c324925e5f6e800a4c618d71caf2848b53bf51:2880:16\n    at http://localhost:3000/packages/blaze.js?a5c324925e5f6e800a4c618d71caf2848b53bf51:1651:16\n    at http://localhost:3000/packages/blaze.js?a5c324925e5f6e800a4c618d71caf2848b53bf51:2928:66\n    at Function.Template._withTemplateInstanceFunc (http://localhost:3000/packages/blaze.js?a5c324925e5f6e800a4c618d71caf2848b53bf51:3476:12)\n    at http://localhost:3000/packages/blaze.js?a5c324925e5f6e800a4c618d71caf2848b53bf51:2927:27\n    at Spacebars.call (http://localhost:3000/packages/spacebars.js?7bafbe05ec09b6bbb6a3b276537e4995ab298a2f:172:18)\n    at Spacebars.mustacheImpl (http://localhost:3000/packages/spacebars.js?7bafbe05ec09b6bbb6a3b276537e4995ab298a2f:109:25)\n    at Object.Spacebars.mustache (http://localhost:3000/packages/spacebars.js?7bafbe05ec09b6bbb6a3b276537e4995ab298a2f:113:39)\n    at null._render (http://localhost:3000/template.art.js?30aa5e2d0b6d3de2f69b7341296ae51b8ce737ba:27:22)\n```\n\n\nThe exception refers to this line of code:\n\n```\nsources.push(images[i].source);\n```\n\n\nHow can this be fixed?\n    ", "Answer": "\r\nTry:\n\n```\nsourceArray : function () {\n      var images = Projects.find().fetch();\n\n      var sources = [];\n      for (var i = 0; i < images.length; i++) {\n        sources.push(images[i].source);\n      }\n      return sources;\n\n  }\n```\n\n\nIf as you said, you defined images as a template helper property, you may need\n\n```\nthis.images[i].source\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "A simple compiler between two ASTs exposing identical language types and operations\r\n                \r\nI'm looking for an elegant way to solve the problem below. All options are welcome, particularly type classes and GADTs :-)\n\nThe scenario is this: there exists a small language with types (Strings and Ints) and operations (+, -, ++ and split). There are two syntax's for the language, each with their own parser. I'd like to write a compiler that can go either from language X to language Y, or from Y to X. Compiling from one to the other is a straight forward mapping over a list of expressions with one of these:\n\n```\nxToY :: ExpX -> ExpY\nyToX :: ExpY -> ExpX\n```\n\n\n.. followed by a ```\nshow```\n over either ```\n[ExpY]```\n or ```\n[ExpX]```\n. Here is a naive implementation of these two compiler functions, using normal data definitions and pattern matching on constructors:\n\n\n{-# LANGUAGE LambdaCase #-}\n\nmodule Compiler where\n\ndata ExpX = StringX String | IntX Int | ArithOpX ArithExpX | StringOpX StringExpX deriving (Show)\ndata ArithExpX = EAddX ExpX ExpX | EMinusX ExpX ExpX deriving (Show)\ndata StringExpX = EAppendX ExpX ExpX | ESplitX ExpX ExpX deriving (Show)\n\ndata ExpY = StringY String | IntY Int | ArithOpY ArithExpY | StringOpY StringExpY deriving (Show)\ndata ArithExpY = EAddY ExpY ExpY | EMinusY ExpY ExpY deriving (Show)\ndata StringExpY = EAppendY ExpY ExpY | ESplitY ExpY ExpY deriving (Show)\n\nxToY :: ExpX -> ExpY\nxToY =\n    \\case\n    StringX s -> StringY s\n    IntX i -> IntY i\n    ArithOpX (EAddX a b) -> ArithOpY (EAddY (xToY a) (xToY b))\n    ArithOpX (EMinusX a b) -> ArithOpY (EMinusY (xToY a) (xToY b))\n    StringOpX (EAppendX a b) -> StringOpY (EAppendY (xToY a) (xToY b))\n    StringOpX (ESplitX a b) -> StringOpY (ESplitY (xToY a) (xToY b))\n\nyToX :: ExpY -> ExpX\nyToX =\n    \\case\n    StringY s -> StringX s\n    IntY i -> IntX i\n    ArithOpY (EAddY a b) -> ArithOpX (EAddX (yToX a) (yToX b))\n    ArithOpY (EMinusY a b) -> ArithOpX (EMinusX (yToX a) (yToX b))\n    StringOpY (EAppendY a b) -> StringOpX (EAppendX (yToX a) (yToX b))\n    StringOpY (ESplitY a b) -> StringOpX (ESplitX (yToX a) (yToX b))\n\n\nTesting the noddy compiler:\n\n\n*Compiler> xToY (ArithOpX (EAddX (IntX 2) (IntX 5)))\nArithOpY (EAddY (IntY 2) (IntY 5))\n*Compiler> yToX (StringOpY (ESplitY (StringY \"foo\") (StringY \"bar\")))\nStringOpX (ESplitX (StringX \"foo\") (StringX \"bar\"))\n\n\nSo it works. Unfortunately, there is a lot code repetition and a pattern is clearly emerging. I'd like to adopt a more elegant feature of Haskell to achieve the same result given by ```\nxToY```\n and ```\nyToX```\n. In particular, I'm looking for a way to define duality between constructors, for example ```\nStringX s```\n gets compiled to ```\nStringY s```\n whilst ```\nStringY s```\n gets compiled back in to ```\nStringX s```\n. Surely there's a nice way to express this? Moreover, the nested ```\nxToY```\n and ```\nyToX```\n calls on the right side of the case matching looks grungy, e.g. ```\nArithOpX (EAddX (yToX a) (yToX b))```\n. There must be a better way?\n    ", "Answer": "\r\nTry replacing ```\nExpX```\n and ```\nExpY```\n with the following single type ```\nExp t```\n.  ```\nt```\n is a tag that is replaced by some type to tag it as being for a specific purpose:\n\n```\ndata Exp t = String String | Int Int | ArithOp (ArithExp t) | StringOp (StringExp t) deriving (Show)\ndata ArithExp t = EAdd (Exp t) (Exp t) | EMinus (Exp t) (Exp t) deriving (Show)\ndata StringExp t = EAppend (Exp t) (Exp t) | ESplit (Exp t) (Exp t) deriving (Show)\n\ndata ForX = ForX\ndata ForY = ForY\n```\n\n\nAnd then use ```\nExp ForX```\n in place of ```\nExpX```\n and ```\nExp ForY```\n in place of ```\nExpY```\n everywhere you care about the difference.\n\nYou can then write functions that work ```\nforall```\n tags. For example, we could replace ```\nxToY```\n and ```\nyToX```\n with a single function ```\nretag```\n:\n\n```\nretag:: Exp t1 -> Exp t2\nretag =\n    \\case\n    String s -> String s\n    Int i -> Int i\n    ArithOp (EAdd a b) -> ArithOp (EAdd (retag a) (retag b))\n    ArithOp (EMinus a b) -> ArithOp (EMinus (retag a) (retag b))\n    StringOp (EAppend a b) -> StringOp (EAppend (retag a) (retag b))\n    StringOp (ESplit a b) -> StringOp (ESplit (retag a) (retag b))\n```\n\n\nThis type ```\nt```\n is an example of a \"phantom type\". A \"phantom type\" is a type that never appears in any constructor.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How do I solve make: None: Command not found issue?\r\n                \r\nI am having trouble understanding this error.\n```\nmake: None: Command not found\nmake: *** [Makefile:3879: api/api_commands.o] Error 127\n```\n\nI have tried looking but I can't find an answer to the specific issue ```\nmake: None:```\n.\nThe full issue and error message is here for clarification.\nHelp on this would be highly appreciated.\nUpdate\nThe ```\nmake```\n file consists of the following (line 3879 separated from the rest for clarification):\n```\n...\n\nincludes_65 = -I../src/tactic/portfolio -I../src/tactic/smtlogics -I../src/ackermannization -I../src/model -I../src/ast/rewriter -I../src/ast -I../src/util -I../src/math/polynomial -I../src/math/automata -I../src/solver -I../src/tactic -I../src/ast/proofs -I../src/sat/sat_solver -I../src/tactic/core -I../src/ast/macros -I../src/ast/normal_forms -I../src/tactic/aig -I../src/tactic/bv -I../src/ast/rewriter/bit_blaster -I../src/tactic/arith -I../src/sat -I../src/sat/tactic -I../src/nlsat/tactic -I../src/nlsat -I../src/smt/tactic -I../src/smt -I../src/cmd_context -I../src/interp -I../src/smt/proto_model -I../src/smt/params -I../src/ast/pattern -I../src/parsers/smt2 -I../src/parsers/util -I../src/ast/substitution -I../src/math/grobner -I../src/math/euclid -I../src/math/simplex -I../src/ast/fpa -I../src/util/lp -I../src/muz/fp -I../src/muz/base -I../src/qe -I../src/muz/pdr -I../src/muz/transforms -I../src/math/hilbert -I../src/muz/dataflow -I../src/muz/clp -I../src/muz/tab -I../src/muz/rel -I../src/muz/bmc -I../src/muz/duality -I../src/duality -I../src/muz/ddnf -I../src/muz/spacer -I../src/tactic/nlsat_smt -I../src/tactic/ufbv -I../src/tactic/fpa -I../src/tactic/sls -I../src/math/subpaving/tactic -I../src/math/subpaving -I../src/math/interval -I../src/math/realclosure -I../src/opt -I../src\napi/z3_macros.h.node: ../src/api/z3_macros.h\n    @echo done > api/z3_macros.h.node\napi/z3_api.h.node: ../src/api/z3_api.h\n    @echo done > api/z3_api.h.node\n...\napi/api_ast_vector$(OBJ_EXT): ../src/api/api_ast_vector.cpp api/z3.h.node api/api_log_macros.h.node api/api_context.h.node api/api_ast_vector.h.node ast/ast_translation.h.node ast/ast_smt2_pp.h.node\n    @echo src/api/api_ast_vector.cpp\n    @$(CXX) $(CXXFLAGS) $(includes_65) $(CXX_OUT_FLAG)api/api_ast_vector$(OBJ_EXT) ../src/api/api_ast_vector.cpp\napi/api_bv$(OBJ_EXT): ../src/api/api_bv.cpp api/z3.h.node api/api_log_macros.h.node api/api_context.h.node api/api_util.h.node ast/bv_decl_plugin.h.node\n    @echo src/api/api_bv.cpp\n    @$(CXX) $(CXXFLAGS) $(includes_65) $(CXX_OUT_FLAG)api/api_bv$(OBJ_EXT) ../src/api/api_bv.cpp\napi/z3_replayer.h.node: ../src/api/z3_replayer.h api/z3.h.node util/z3_exception.h.node\n    @echo done > api/z3_replayer.h.node\napi/api_commands$(OBJ_EXT): ../src/api/api_commands.cpp api/z3.h.node api/z3_replayer.h.node\n    @echo src/api/api_commands.cpp\n\n    @$(CXX) $(CXXFLAGS) $(includes_65) $(CXX_OUT_FLAG)api/api_commands$(OBJ_EXT) ../src/api/api_commands.cpp\n\napi/api_config_params$(OBJ_EXT): ../src/api/api_config_params.cpp api/z3.h.node \n...\n```\n\nSince the previous lines in the ```\nmake```\n file are of similar format and did not cause any errors, the problem must lie within the ```\napi_commands.cpp```\n file. I have looked into this file, but I can't understand what is happening in this code exactly, so I cannot interpret where a ```\nNone```\n variable is created.\nThe ```\napi_commands.cpp```\n file in question is 4856 lines long, but it consists of several functions of ther format\n```\nvoid exec_Z3_params_set_bool(z3_replayer & in) {\n  Z3_params_set_bool(\n    reinterpret_cast<Z3_context>(in.get_obj(0)),\n    reinterpret_cast<Z3_params>(in.get_obj(1)),\n    in.get_symbol(2),\n    in.get_bool(3));\n}\n```\n\nand a function ```\nvoid register_z3_replayer_cmds(z3_replayer & in)```\n containing lines such as\n```\nin.register_cmd(16, exec_Z3_params_set_bool, \"Z3_params_set_bool\");\n```\n\nIf anyone is familiar with such or similar code and would know how this file is creating a ```\nNone```\n variable, your help would be highly appreciated.\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Uncomplete installation of the RASA package with the issue: FileNotFoundError: [Errno 2] No such file or directory: 'HISTORY.rst'\r\n                \r\ni have been using rasa for the past few weeks without problems. But recently i had issues with the installation of Spacy, leading me to uninstall an reinstall python. The issue may have occurred because of some dualities between python3.8 and 3.9 which i wasnt abled to pinpoint.\nAfter deleting all python version from my computer, i just reinstalled python 3.9.2. and reinstall rasa with:\n```\npip3 install rasa\n```\n\nthis gave me the next output:\n```\nCollecting rasa\n  Using cached rasa-1.10.2-py3-none-any.whl (510 kB)\nCollecting sklearn-crfsuite<0.4,>=0.3\n  Using cached sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\nCollecting tensorflow-estimator==2.1.0\n  Using cached tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\nCollecting ruamel.yaml<0.17,>=0.16\n  Using cached ruamel.yaml-0.16.13-py2.py3-none-any.whl (111 kB)\nCollecting pydot<1.5,>=1.4\n  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\nCollecting psycopg2-binary<2.9.0,>=2.8.2\n  Using cached psycopg2_binary-2.8.6-cp39-cp39-win_amd64.whl (1.2 MB)\nCollecting jsonpickle<1.5,>=1.3\n  Using cached jsonpickle-1.4.2-py2.py3-none-any.whl (36 kB)\nCollecting pymongo[srv,tls]<3.9.0,>=3.8.0\n  Downloading pymongo-3.8.0.tar.gz (649 kB)\n     |████████████████████████████████| 649 kB 3.3 MB/s\nCollecting SQLAlchemy<1.4.0,>=1.3.3\n  Using cached SQLAlchemy-1.3.23-cp39-cp39-win_amd64.whl (1.2 MB)\nCollecting coloredlogs<11.0,>=10.0\n  Using cached coloredlogs-10.0-py2.py3-none-any.whl (47 kB)\nCollecting python-dateutil<2.9,>=2.8\n  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\nCollecting sanic<20.0.0,>=19.12.2\n  Using cached sanic-19.12.5-py3-none-any.whl (73 kB)\nRequirement already satisfied: setuptools>=41.0.0 in c:\\users\\louip\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rasa) (49.2.1)\nCollecting pytz<2020.0,>=2019.1\n  Using cached pytz-2019.3-py2.py3-none-any.whl (509 kB)\nCollecting slackclient<3.0.0,>=2.0.0\n  Using cached slackclient-2.9.3-py2.py3-none-any.whl (96 kB)\nCollecting terminaltables<3.2.0,>=3.1.0\n  Using cached terminaltables-3.1.0.tar.gz (12 kB)\nCollecting colorclass<2.3,>=2.2\n  Using cached colorclass-2.2.0.tar.gz (17 kB)\nCollecting twilio<6.27,>=6.26\n  Using cached twilio-6.26.3-py2.py3-none-any.whl (979 kB)\nCollecting pykwalify<1.8.0,>=1.7.0\n  Using cached pykwalify-1.7.0-py2.py3-none-any.whl (40 kB)\nCollecting python-socketio<4.6,>=4.4\n  Using cached python_socketio-4.5.1-py2.py3-none-any.whl (51 kB)\nCollecting webexteamssdk<1.4.0,>=1.1.1\n  Using cached webexteamssdk-1.3.tar.gz (56 kB)\nCollecting PyJWT<1.8,>=1.7\n  Using cached PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\nCollecting tqdm<4.46,>=4.31\n  Using cached tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\nRequirement already satisfied: numpy<2.0,>=1.16 in c:\\users\\louip\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rasa) (1.20.0)\nCollecting tensorflow_hub<0.9,>=0.7\n  Using cached tensorflow_hub-0.8.0-py2.py3-none-any.whl (101 kB)\nCollecting tensorflow-probability<0.10,>=0.7\n  Using cached tensorflow_probability-0.9.0-py2.py3-none-any.whl (3.2 MB)\nCollecting matplotlib<3.3,>=3.1\n  Using cached matplotlib-3.2.2-cp39-cp39-win_amd64.whl (8.9 MB)\nCollecting rasa-sdk<2.0.0,>=1.10.0\n  Using cached rasa_sdk-1.10.3-py3-none-any.whl (39 kB)\nCollecting gevent<1.6,>=1.4\n  Using cached gevent-1.5.0.tar.gz (5.3 MB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n    Preparing wheel metadata ... done\nCollecting sanic-cors<0.11.0,>=0.10.0b1\n  Using cached Sanic_Cors-0.10.0.post3-py2.py3-none-any.whl (17 kB)\nCollecting absl-py<0.10,>=0.9\n  Using cached absl-py-0.9.0.tar.gz (104 kB)\nCollecting colorhash<1.1.0,>=1.0.2\n  Using cached colorhash-1.0.3-py3-none-any.whl (4.0 kB)\nCollecting multidict<5.0,>=4.6\n  Using cached multidict-4.7.6.tar.gz (50 kB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n    Preparing wheel metadata ... done\nCollecting prompt-toolkit<3.0,>=2.0\n  Using cached prompt_toolkit-2.0.10-py3-none-any.whl (340 kB)\nCollecting oauth2client==4.1.3\n  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\nCollecting async_generator<1.11,>=1.10\n  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\nCollecting python-engineio<3.13,>=3.11\n  Downloading python_engineio-3.12.1-py2.py3-none-any.whl (49 kB)\n     |████████████████████████████████| 49 kB 3.2 MB/s\nCollecting questionary<1.6.0,>=1.5.1\n  Using cached questionary-1.5.2-py3-none-any.whl (26 kB)\nCollecting ujson<3.0,>=1.35\n  Downloading ujson-2.0.3.tar.gz (7.1 MB)\n     |████████████████████████████████| 7.1 MB 3.3 MB/s\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Installing backend dependencies ... done\n    Preparing wheel metadata ... done\nCollecting rasa\n  Using cached rasa-1.10.1-py3-none-any.whl (509 kB)\nCollecting packaging<19.1,>=19.0\n  Using cached packaging-19.0-py2.py3-none-any.whl (26 kB)\nCollecting rasa\n  Using cached rasa-1.10.0-py3-none-any.whl (509 kB)\n  Using cached rasa-1.9.7-py3-none-any.whl (497 kB)\nCollecting cloudpickle<1.3.0,>=1.2.0\n  Using cached cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\nCollecting jsonpickle<1.4,>=1.3\n  Using cached jsonpickle-1.3-py2.py3-none-any.whl (32 kB)\nCollecting tensorflow_hub<0.8,>=0.7\n  Using cached tensorflow_hub-0.7.0-py2.py3-none-any.whl (89 kB)\nCollecting rasa\n  Using cached rasa-1.9.6-py3-none-any.whl (497 kB)\n  Using cached rasa-1.9.5-py3-none-any.whl (496 kB)\n  Using cached rasa-1.9.4-py3-none-any.whl (495 kB)\n  Using cached rasa-1.9.3-py3-none-any.whl (495 kB)\n  Using cached rasa-1.9.2-py3-none-any.whl (495 kB)\n  Using cached rasa-1.9.1-py3-none-any.whl (495 kB)\n  Using cached rasa-1.9.0-py3-none-any.whl (495 kB)\n  Using cached rasa-1.8.3-py3-none-any.whl (483 kB)\nCollecting tqdm<4.32.0,>=4.31.0\n  Using cached tqdm-4.31.1-py2.py3-none-any.whl (48 kB)\nCollecting python-socketio<4.5,>=4.4\n  Using cached python_socketio-4.4.0-py2.py3-none-any.whl (50 kB)\nCollecting python-engineio<3.12,>=3.11\n  Using cached python_engineio-3.11.2-py2.py3-none-any.whl (49 kB)\nCollecting rocketchat_API<0.7.0,>=0.6.31\n  Using cached rocketchat_API-0.6.36-py3-none-any.whl (9.5 kB)\nCollecting rasa\n  Using cached rasa-1.8.2-py3-none-any.whl (483 kB)\n  Using cached rasa-1.8.1-py3-none-any.whl (481 kB)\n  Using cached rasa-1.8.0-py3-none-any.whl (481 kB)\n  Using cached rasa-1.7.4-py3-none-any.whl (575 kB)\n  Using cached rasa-1.7.3-py3-none-any.whl (575 kB)\n  Using cached rasa-1.7.2-py3-none-any.whl (575 kB)\n  Using cached rasa-1.7.1-py3-none-any.whl (574 kB)\n  Using cached rasa-1.7.0-py3-none-any.whl (573 kB)\n  Using cached rasa-1.6.2-py3-none-any.whl (559 kB)\n  Using cached rasa-1.6.1-py3-none-any.whl (559 kB)\nCollecting tensorflow-probability~=0.7.0\n  Using cached tensorflow_probability-0.7.0-py2.py3-none-any.whl (981 kB)\nCollecting webexteamssdk~=1.1\n  Using cached webexteamssdk-1.6-py3-none-any.whl (113 kB)\nCollecting tensor2tensor~=1.14.0\n  Using cached tensor2tensor-1.14.1-py2.py3-none-any.whl (1.6 MB)\nCollecting sanic-jwt~=1.3\n  Using cached sanic-jwt-1.6.0.tar.gz (19 kB)\nCollecting sanic-cors==0.9.9.post1\n  Using cached Sanic_Cors-0.9.9.post1-py2.py3-none-any.whl (16 kB)\nCollecting redis~=3.3.5\n  Using cached redis-3.3.11-py2.py3-none-any.whl (66 kB)\nCollecting absl-py>=0.8.0\n  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\nCollecting attrs>=18\n  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\nCollecting twilio~=6.0\n  Using cached twilio-6.54.0.tar.gz (471 kB)\nCollecting rasa-sdk~=1.6.0\n  Using cached rasa_sdk-1.6.1-py2.py3-none-any.whl (32 kB)\nCollecting sanic~=19.9.0\n  Using cached sanic-19.9.0-py3-none-any.whl (73 kB)\nRequirement already satisfied: requests>=2.20 in c:\\users\\louip\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rasa) (2.25.1)\nCollecting rasa\n  Using cached rasa-1.6.0-py3-none-any.whl (558 kB)\n  Using cached rasa-1.5.3-py3-none-any.whl (530 kB)\n  Using cached rasa-1.5.2-py3-none-any.whl (529 kB)\n  Using cached rasa-1.5.1-py3-none-any.whl (529 kB)\n  Using cached rasa-1.5.0-py3-none-any.whl (527 kB)\n  Using cached rasa-1.4.6-py3-none-any.whl (518 kB)\n  Using cached rasa-1.4.5-py3-none-any.whl (517 kB)\n  Using cached rasa-1.4.4-py3-none-any.whl (517 kB)\n  Using cached rasa-1.4.3-py3-none-any.whl (518 kB)\nCollecting networkx~=2.3.0\n  Using cached networkx-2.3.zip (1.7 MB)\nCollecting kafka-python~=1.4\n  Using cached kafka_python-1.4.7-py2.py3-none-any.whl (266 kB)\nCollecting pika~=1.0.0\n  Using cached pika-1.0.1-py2.py3-none-any.whl (148 kB)\nCollecting matplotlib~=3.0\n  Using cached matplotlib-3.3.4-cp39-cp39-win_amd64.whl (8.5 MB)\nCollecting pymongo[srv,tls]~=3.8\n  Using cached pymongo-3.11.3-cp39-cp39-win_amd64.whl (383 kB)\nCollecting scikit-learn~=0.20.2\n  Using cached scikit-learn-0.20.4.tar.gz (11.7 MB)\nCollecting python-telegram-bot~=11.0\n  Using cached python_telegram_bot-11.1.0-py2.py3-none-any.whl (326 kB)\nCollecting rasa\n  Using cached rasa-1.4.2-py3-none-any.whl (516 kB)\n  Using cached rasa-1.4.1-py3-none-any.whl (516 kB)\n  Using cached rasa-1.4.0-py3-none-any.whl (515 kB)\n  Using cached rasa-1.3.10-py3-none-any.whl (507 kB)\nCollecting rasa-sdk~=1.3.0\n  Using cached rasa_sdk-1.3.3-py2.py3-none-any.whl (32 kB)\nCollecting rasa\n  Using cached rasa-1.3.9-py3-none-any.whl (506 kB)\n  Using cached rasa-1.3.8-py3-none-any.whl (505 kB)\n  Using cached rasa-1.3.7-py3-none-any.whl (505 kB)\n  Using cached rasa-1.3.6-py3-none-any.whl (505 kB)\n  Using cached rasa-1.3.4-py3-none-any.whl (504 kB)\n  Using cached rasa-1.3.3-py3-none-any.whl (503 kB)\n  Using cached rasa-1.3.2-py3-none-any.whl (502 kB)\n  Using cached rasa-1.3.1-py3-none-any.whl (502 kB)\n  Using cached rasa-1.3.0-py3-none-any.whl (502 kB)\n  Using cached rasa-1.2.12-py3-none-any.whl (471 kB)\n  Using cached rasa-1.2.11-py3-none-any.whl (471 kB)\n  Using cached rasa-1.2.10-py3-none-any.whl (471 kB)\n  Using cached rasa-1.2.9-py3-none-any.whl (471 kB)\n  Using cached rasa-1.2.8-py3-none-any.whl (471 kB)\n  Using cached rasa-1.2.7-py3-none-any.whl (471 kB)\n  Using cached rasa-1.2.6-py3-none-any.whl (470 kB)\n  Using cached rasa-1.2.5-py3-none-any.whl (470 kB)\n  Using cached rasa-1.2.4-py3-none-any.whl (469 kB)\n  Using cached rasa-1.2.3-py3-none-any.whl (469 kB)\n  Using cached rasa-1.2.2-py3-none-any.whl (468 kB)\n  Using cached rasa-1.2.1-py3-none-any.whl (468 kB)\n  Using cached rasa-1.2.0-py3-none-any.whl (468 kB)\n  Using cached rasa-1.1.8-py3-none-any.whl (464 kB)\n  Using cached rasa-1.1.7-py3-none-any.whl (455 kB)\n  Using cached rasa-1.1.6-py3-none-any.whl (453 kB)\n  Using cached rasa-1.1.5-py3-none-any.whl (452 kB)\n  Using cached rasa-1.1.4-py3-none-any.whl (447 kB)\n  Using cached rasa-1.1.3-py3-none-any.whl (446 kB)\n  Using cached rasa-1.1.2-py3-none-any.whl (444 kB)\n  Using cached rasa-1.1.1-py3-none-any.whl (444 kB)\n  Using cached rasa-1.1.0-py3-none-any.whl (444 kB)\n  Using cached rasa-1.0.9-py3-none-any.whl (440 kB)\n  Using cached rasa-1.0.8-py3-none-any.whl (440 kB)\n  Using cached rasa-1.0.7-py3-none-any.whl (439 kB)\n  Using cached rasa-1.0.6-py3-none-any.whl (438 kB)\n  Using cached rasa-1.0.5-py3-none-any.whl (438 kB)\n  Using cached rasa-1.0.4-py3-none-any.whl (438 kB)\n  Using cached rasa-1.0.3-py3-none-any.whl (438 kB)\n  Using cached rasa-1.0.2-py3-none-any.whl (438 kB)\n  Using cached rasa-1.0.1-py3-none-any.whl (436 kB)\n  Using cached rasa-1.0.0-py3-none-any.whl (436 kB)\n  Using cached rasa-0.1.1-py3-none-any.whl (6.1 kB)\nCollecting rasa-nlu\n  Using cached rasa_nlu-0.15.1-py3-none-any.whl (147 kB)\nCollecting rasa-core\n  Using cached rasa_core-0.14.5-py3-none-any.whl (212 kB)\nCollecting pytz~=2018.9\n  Using cached pytz-2018.9-py2.py3-none-any.whl (510 kB)\nCollecting rasa-core\n  Using cached rasa_core-0.14.4-py3-none-any.whl (212 kB)\n  Using cached rasa_core-0.14.3-py3-none-any.whl (212 kB)\n  Using cached rasa_core-0.14.2-py3-none-any.whl (212 kB)\n  Using cached rasa_core-0.14.1-py3-none-any.whl (212 kB)\n  Using cached rasa_core-0.14.0-py3-none-any.whl (212 kB)\n  Using cached rasa_core-0.13.8-py3-none-any.whl (205 kB)\nCollecting keras-applications==1.0.6\n  Using cached Keras_Applications-1.0.6-py2.py3-none-any.whl (44 kB)\nCollecting fbmessenger~=5.0\n  Using cached fbmessenger-5.6.0-py2.py3-none-any.whl (11 kB)\nCollecting redis~=2.0\n  Using cached redis-2.10.6-py2.py3-none-any.whl (64 kB)\nCollecting rasa-core\n  Using cached rasa_core-0.13.7-py3-none-any.whl (205 kB)\n  Using cached rasa_core-0.13.6-py3-none-any.whl (205 kB)\n  Using cached rasa_core-0.13.5-py3-none-any.whl (204 kB)\n  Using cached rasa_core-0.13.4-py3-none-any.whl (204 kB)\n  Using cached rasa_core-0.13.3-py3-none-any.whl (204 kB)\n  Using cached rasa_core-0.13.2-py3-none-any.whl (204 kB)\n  Using cached rasa_core-0.13.1-py3-none-any.whl (204 kB)\n  Using cached rasa_core-0.13.0-py3-none-any.whl (204 kB)\n  Using cached rasa_core-0.12.4-py2.py3-none-any.whl (204 kB)\nCollecting prompt-toolkit==1.0.14\n  Using cached prompt_toolkit-1.0.14-py3-none-any.whl (248 kB)\nCollecting networkx~=2.0\n  Using cached networkx-2.5-py3-none-any.whl (1.6 MB)\nCollecting python-telegram-bot~=10.0\n  Using cached python_telegram_bot-10.1.0-py2.py3-none-any.whl (298 kB)\nCollecting typing~=3.0\n  Using cached typing-3.7.4.3.tar.gz (78 kB)\nCollecting pika~=0.11.2\n  Using cached pika-0.11.2-py2.py3-none-any.whl (107 kB)\nCollecting fakeredis~=0.10.0\n  Using cached fakeredis-0.10.3-py2.py3-none-any.whl (27 kB)\nCollecting pykwalify<=1.6.0\n  Using cached pykwalify-1.6.0-py2.py3-none-any.whl (38 kB)\nCollecting rasa-core-sdk~=0.12.1\n  Using cached rasa_core_sdk-0.12.2-py2.py3-none-any.whl (18 kB)\nCollecting python-socketio~=2.0\n  Using cached python_socketio-2.1.2-py2.py3-none-any.whl (33 kB)\nCollecting pyyaml~=3.12\n  Using cached PyYAML-3.13.tar.gz (270 kB)\nCollecting scikit-learn~=0.19.0\n  Using cached scikit-learn-0.19.2.tar.gz (9.7 MB)\nCollecting ConfigArgParse~=0.13.0\n  Using cached ConfigArgParse-0.13.0.tar.gz (31 kB)\nCollecting slackclient~=1.0\n  Using cached slackclient-1.3.2.tar.gz (16 kB)\nCollecting flask-cors~=3.0\n  Using cached Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\nCollecting h5py~=2.0\n  Using cached h5py-2.10.0.tar.gz (301 kB)\nRequirement already satisfied: six~=1.0 in c:\\users\\louip\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rasa-core->rasa) (1.15.0)\nCollecting rasa-core\n  Using cached rasa_core-0.12.3-py2.py3-none-any.whl (204 kB)\n  Using cached rasa_core-0.12.2-py2.py3-none-any.whl (203 kB)\nCollecting keras~=2.0\n  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\nCollecting rasa-core\n  Using cached rasa_core-0.12.1-py2.py3-none-any.whl (203 kB)\n  Using cached rasa_core-0.12.0-py2.py3-none-any.whl (201 kB)\n  Using cached rasa_core-0.11.12-py2.py3-none-any.whl (179 kB)\nCollecting graphviz~=0.9.0\n  Using cached graphviz-0.9-py2.py3-none-any.whl (16 kB)\nCollecting rasa-core\n  Using cached rasa_core-0.11.11-py2.py3-none-any.whl (179 kB)\n  Using cached rasa_core-0.11.10-py2.py3-none-any.whl (179 kB)\n  Using cached rasa_core-0.11.9-py2.py3-none-any.whl (179 kB)\n  Using cached rasa_core-0.11.8-py2.py3-none-any.whl (179 kB)\n  Using cached rasa_core-0.11.7-py2.py3-none-any.whl (178 kB)\n  Using cached rasa_core-0.11.6-py2.py3-none-any.whl (178 kB)\n  Using cached rasa_core-0.11.5-py2.py3-none-any.whl (178 kB)\n  Using cached rasa_core-0.11.4-py2.py3-none-any.whl (178 kB)\n  Using cached rasa_core-0.11.3-py2.py3-none-any.whl (168 kB)\nCollecting graphviz~=0.8.0\n  Using cached graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\nCollecting rasa-core\n  Using cached rasa_core-0.11.2-py2.py3-none-any.whl (166 kB)\n  Using cached rasa_core-0.11.1-py2.py3-none-any.whl (166 kB)\nCollecting mattermostwrapper~=2.0\n  Using cached mattermostwrapper-2.2.tar.gz (2.5 kB)\nCollecting rasa-core\n  Using cached rasa_core-0.11.0-py2.py3-none-any.whl (166 kB)\n  Using cached rasa_core-0.10.4-py2.py3-none-any.whl (133 kB)\nCollecting ruamel.yaml~=0.15.0\n  Using cached ruamel.yaml-0.15.100.tar.gz (318 kB)\nCollecting tqdm~=4.0\n  Using cached tqdm-4.59.0-py2.py3-none-any.whl (74 kB)\nCollecting jsonpickle~=0.9.0\n  Using cached jsonpickle-0.9.6.tar.gz (67 kB)\nCollecting flask~=1.0\n  Using cached Flask-1.1.2-py2.py3-none-any.whl (94 kB)\nCollecting future~=0.16\n  Using cached future-0.18.2.tar.gz (829 kB)\nCollecting rasa-nlu\n  Using cached rasa_nlu-0.13.8-py2.py3-none-any.whl (145 kB)\nCollecting rasa-core\n  Using cached rasa_core-0.10.3-py2.py3-none-any.whl (133 kB)\n  Using cached rasa_core-0.10.2-py2.py3-none-any.whl (133 kB)\nCollecting rasa-nlu\n  Using cached rasa_nlu-0.12.3-py2.py3-none-any.whl (131 kB)\nCollecting rasa-core\n  Using cached rasa_core-0.10.1-py2.py3-none-any.whl (132 kB)\n  Using cached rasa_core-0.10.0-py2.py3-none-any.whl (132 kB)\n  Using cached rasa_core-0.9.8-py2.py3-none-any.whl (125 kB)\n  Using cached rasa_core-0.9.7-py2.py3-none-any.whl (125 kB)\n  Using cached rasa_core-0.9.6-py2.py3-none-any.whl (125 kB)\n  Using cached rasa_core-0.9.5-py2.py3-none-any.whl (125 kB)\n  Using cached rasa_core-0.9.4-py2.py3-none-any.whl (125 kB)\n  Using cached rasa_core-0.9.3-py2.py3-none-any.whl (121 kB)\n  Using cached rasa_core-0.9.2-py2.py3-none-any.whl (121 kB)\n  Using cached rasa_core-0.9.1-py2.py3-none-any.whl (121 kB)\n  Using cached rasa_core-0.9.0-py2.py3-none-any.whl (121 kB)\n  Using cached rasa_core-0.8.6-py2.py3-none-any.whl (103 kB)\nCollecting h5py\n  Using cached h5py-3.2.1-cp39-cp39-win_amd64.whl (2.8 MB)\nCollecting fakeredis\n  Using cached fakeredis-1.4.5-py3-none-any.whl (35 kB)\nCollecting fbmessenger<5.0.0\n  Downloading fbmessenger-4.3.1-py2.py3-none-any.whl (10 kB)\nCollecting apscheduler\n  Using cached APScheduler-3.7.0-py2.py3-none-any.whl (59 kB)\nCollecting redis\n  Using cached redis-3.5.3-py2.py3-none-any.whl (72 kB)\nCollecting rasa-nlu\n  Using cached rasa_nlu-0.11.5.tar.gz (55 kB)\nCollecting graphviz\n  Using cached graphviz-0.16-py2.py3-none-any.whl (19 kB)\nCollecting ConfigArgParse\n  Downloading ConfigArgParse-1.4.tar.gz (45 kB)\n     |████████████████████████████████| 45 kB 3.4 MB/s\nCollecting pandoc\n  Using cached pandoc-1.0.2.tar.gz (488 kB)\nCollecting scikit-learn\n  Using cached scikit_learn-0.24.1-cp39-cp39-win_amd64.whl (6.9 MB)\nCollecting jsonpickle\n  Using cached jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\nCollecting python-telegram-bot\n  Using cached python_telegram_bot-13.4.1-py3-none-any.whl (448 kB)\nCollecting rasa-core\n  Using cached rasa_core-0.8.5.tar.gz (76 kB)\nCollecting nbsphinx\n  Using cached nbsphinx-0.8.2-py3-none-any.whl (24 kB)\nCollecting rasa-core\n  Using cached rasa_core-0.8.4.tar.gz (76 kB)\n  Using cached rasa_core-0.8.3.tar.gz (76 kB)\n  Using cached rasa_core-0.8.2.tar.gz (76 kB)\n  Using cached rasa_core-0.8.1.tar.gz (75 kB)\n  Using cached rasa_core-0.8.0.tar.gz (75 kB)\n  Using cached rasa_core-0.7.9.tar.gz (61 kB)\n  Using cached rasa_core-0.7.7.tar.gz (61 kB)\n  Using cached rasa_core-0.7.6.tar.gz (60 kB)\n  Using cached rasa_core-0.7.5.tar.gz (60 kB)\n  Using cached rasa_core-0.7.4.tar.gz (60 kB)\n  Using cached rasa_core-0.7.3.tar.gz (59 kB)\n  Using cached rasa_core-0.7.2.tar.gz (59 kB)\n  Using cached rasa_core-0.7.1.tar.gz (60 kB)\n  Using cached rasa_core-0.7.0.tar.gz (60 kB)\nINFO: pip is looking at multiple versions of rasa to determine which version is compatible with other requirements. This could take a while.\nCollecting rasa\n  Using cached rasa-0.1.0-py3-none-any.whl (6.1 kB)\n  Using cached rasa-0.0.5-py3-none-any.whl\n  Using cached rasa-0.0.4.tar.gz (5.0 kB)\n  Using cached rasa-0.0.3.tar.gz (4.7 kB)\n    ERROR: Command errored out with exit status 1:\n     command: 'c:\\users\\louip\\appdata\\local\\programs\\python\\python39\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\louip\\\\AppData\\\\Local\\\\Temp\\\\pip-install-pjlvx_xv\\\\rasa_2e5bbaea763d4f8b9abf11dcaa6b3e0c\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\louip\\\\AppData\\\\Local\\\\Temp\\\\pip-install-pjlvx_xv\\\\rasa_2e5bbaea763d4f8b9abf11dcaa6b3e0c\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\louip\\AppData\\Local\\Temp\\pip-pip-egg-info-908ibd4q'\n         cwd: C:\\Users\\louip\\AppData\\Local\\Temp\\pip-install-pjlvx_xv\\rasa_2e5bbaea763d4f8b9abf11dcaa6b3e0c\\\n    Complete output (7 lines):\n    Traceback (most recent call last):\n      File \"<string>\", line 1, in <module>\n      File \"C:\\Users\\louip\\AppData\\Local\\Temp\\pip-install-pjlvx_xv\\rasa_2e5bbaea763d4f8b9abf11dcaa6b3e0c\\setup.py\", line 14, in <module>\n        with open('HISTORY.rst', 'r', 'utf-8') as f:\n      File \"c:\\users\\louip\\appdata\\local\\programs\\python\\python39\\lib\\codecs.py\", line 905, in open\n        file = builtins.open(filename, mode, buffering)\n    FileNotFoundError: [Errno 2] No such file or directory: 'HISTORY.rst'\n    ----------------------------------------\nWARNING: Discarding https://files.pythonhosted.org/packages/77/56/5d44415d54043fb441b910bf86fa36bbb3b5565a507ba4ea933117cf109f/rasa-0.0.3.tar.gz#sha256=409e502bc20a29db848b68766decacad15a9cbeb68d1afd90add9945945c9048 (from https://pypi.org/simple/rasa/). Command errored out with exit status 1: python setup.py egg_info \nCheck the logs for full command output.\n  Using cached rasa-0.0.2.tar.gz (3.9 kB)\n  Using cached rasa-0.0.1.tar.gz (1.6 kB)\nRequirement already satisfied: idna<3,>=2.5 in c:\\users\\louip\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->rasa) (2.10)       \nRequirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\louip\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->rasa) (4.0.0) \nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\louip\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->rasa) (2020.12.5)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\louip\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->rasa) (1.26.4)\nInstalling collected packages: rasa\nSuccessfully installed rasa-0.0.5\n```\n\nthe result is that rasa is install in version 0.0.5 when it should be in version 2.4.\ni have no clue why an error occurred at the end as it did not happen the first i downloaded it a few weeks ago.\nWhat should i do to resolve this issue?\nThanks for your time.\n    ", "Answer": "\r\n```\nrasa```\n 2.4 declares compatibility with Python 3.6, 3.7 and 3.8 but not 3.9 so ```\npip```\n is trying to find one compatible with 3.9 or at least one that doesn't declare any restriction. It finds such release at version 0.0.5.\nTo use ```\nrasa```\n 2.4 downgrade to Python 3.8.\nPS. Don't hurry up to upgrade to the latest Python — 3rd-party packages are usually not so fast. Currently Python 3.7 and 3.8 are the best.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Angular 2 MVW - MVC, MVA, MVP, MVVM?\r\n                \r\nAngular 1 (AngularJS) was called an MVW-Framework. MVW stands for Model-View-Whatever. Is Angular 2 still MVW?\n\nIs MVW the same as MV*?\n\nI know that Whatever means that it could be a ViewModel or a Controller. Model and View is still the same.\n\nBut can MVW also mean that there is a Presenter or an Adapter?\n\n\n  I know that the Model can be factories or services, the controller is the component class and the view is the component template (template or templateUrl), if I use the MVC pattern. The Service can be used via Dependecy Injections in the class constructor of my component file.\n  The member variables can be set there. The view binds the member variables.\n\n\nI am not sure, but the ViewModel is also the component class. But I don't understand the difference in Angular 2, because I couldn't find any examples for MVC or MVVM.\n\n\nAt first I want to know if Angular 2 is also MVW?\nThen is MVW the same as MV*?\nAfter that is there a person who know a good example which shows the code difference between MVC and MVVM.\nIf Angular 2 also support Presenter or Adapter, are there any good code examples for this two pattern?\n\n\nI think the theory behind these concepts I have understood really well, but I can't find code examples or clear answers how you can use these patterns. Also I can'f find a clear answer If Adapter and Presenter is also supported by Angular 2.\n\nThese links can help:\nAngular2: MVC, MVVM or MV*?\n\nHow MVC pattern can be explained in Angular 2?\n\nBut it's all theory and no practice.\n\nIn the documentation (angular.io) I only can found these two statements:\n\n\n  The Angular application manages what the user sees and can do, achieving this through the interaction of a component class instance (the component) and its user-facing template.\n  \n  You may be familiar with the component/template duality from your experience with model-view-controller (MVC) or model-view-viewmodel (MVVM). In Angular, the component plays the part of the controller/viewmodel, and the template represents the view.\n\n\nor this\n\n\n  An Angular class responsible for exposing data to a view and handling most of the view’s display and user-interaction logic.\n  \n  The component is one of the most important building blocks in the Angular system. It is, in fact, an Angular directive with a companion template.\n  \n  Apply the @Component decorator to the component class, thereby attaching to the class the essential component metadata that Angular needs to create a component instance and render the component with its template as a view.\n  \n  Those familiar with \"MVC\" and \"MVVM\" patterns will recognize the component in the role of \"controller\" or \"view model\".\n\n\nI am really confused about this topic. I hope there is a person who can help me.\n\nOn this link there is a similar question to MVW. Is the shown example a vaild example for MVC?\nWhat does MVW stand for in Angular2?\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to pass Deterministic variables to Metropolis (PyMC)?\r\n                \r\nI was trying out the examples in the book : Probabilistic-Programming-and-Bayesian-Methods-for-Hackers.\nTowards the end of chapter 2 I got stuck at the block of code below.\nIt purpose is to determine if a simulated data from a posterior distribution matches the original data, the code block is the first step in the process.\nI am using pymc not pymc3.\nCODE BLOCK:\n```\nN = 10000\nwith pm.Model() as model:\n    beta = pm.Normal(\"beta\", mu=0, tau=0.001, testval=0)\n    alpha = pm.Normal(\"alpha\", mu=0, tau=0.001, testval=0)\n    p = pm.Deterministic(\"p\", 1.0/(1. + tt.exp(beta*temperature + alpha)))\n    observed = pm.Bernoulli(\"bernoulli_obs\", p, observed=D)\n    # pytensor.config.compute_test_value = \"warn\"\n\n    simulated = pm.Bernoulli(\"bernoulli_sim\", p,shape= p.shape )\n    step = pm.Metropolis(vars=[p])\n    trace = pm.sample(N, step=step)\n```\n\nERROR:\n```\n\nValueError                                Traceback (most recent call last)\nCell In[32], line 10\n      7 # pytensor.config.compute_test_value = \"warn\"\n      9 simulated = pm.Bernoulli(\"bernoulli_sim\", p,shape= p.shape )\n---> 10 step = pm.Metropolis(vars=[p])\n     11 trace = pm.sample(N, step=step)\n\nFile ~\\.conda\\envs\\bayes_course\\Lib\\site-packages\\pymc\\step_methods\\metropolis.py:168, in Metropolis.__init__(self, vars, S, proposal_dist, scaling, tune, tune_interval, model, mode, **kwargs)\n    166     vars = model.value_vars\n    167 else:\n--> 168     vars = get_value_vars_from_user_vars(vars, model)\n    170 initial_values_shape = [initial_values[v.name].shape for v in vars]\n    171 if S is None:\n\nFile ~\\.conda\\envs\\bayes_course\\Lib\\site-packages\\pymc\\util.py:480, in get_value_vars_from_user_vars(vars, model)\n    477     notin = list(map(get_var_name, notin))\n    478     # We mention random variables, even though the input may be a wrong value variable\n    479     # because most users don't know about that duality\n--> 480     raise ValueError(\n    481         \"The following variables are not random variables in the model: \" + str(notin)\n    482     )\n    484 return value_vars\n\nValueError: The following variables are not random variables in the model: ['p']\n```\n\n    ", "Answer": "\r\nI don't believe you need to provide ```\np```\n to ```\nMetropolis```\n. It should be able to use the deterministic var through ```\nBernoulli```\n where it was provided.\nFrom the documentation here:\n\nDeterministic quantities are just computeed once at the end of the step, with the final values of the other random variables\n\nThis sounds to me like you can remove ```\nvars=[p]```\n and use\n```\nstep = pm.Metropolis()\n```\n\ndirectly.\nI tried it locally with some fake data and it appears that p is in the final trace.\n```\nprint(trace.posterior)\n```\n\n```\nData variables:\n    temperature    (chain, draw) float64 -62.98 -21.79 -13.69 ... 18.63 18.63\n    beta           (chain, draw) float64 -26.23 -26.23 -39.61 ... 25.9 38.93\n    alpha          (chain, draw) float64 -53.5 -53.5 -5.149 ... -0.5374 -0.5374\n    bernoulli_sim  (chain, draw) int64 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0\n    p              (chain, draw) float64 0.0 1.022e-225 ... 4.518e-210 0.0\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to parse GML in C# or JavaScript for use with Unity\r\n                \r\nI want to parse GML and use the data in Unity.\nThis is my C# code for parsing the XML:\n\n```\nusing System.Collections;\nusing System.Collections.Generic;\nusing UnityEngine;\nusing System.IO;\nusing System.Xml.Linq;\nusing System.Linq;\nusing UnityEngine.UI;\n\npublic class Manager_02 : MonoBehaviour \n{\n  public GameObject text01;\n\n  private void Start()\n  {\n    string path = @\"C:unitySample.gml\";\n\n    XDocument xd = XDocument.Load(path);\n    XNamespace gml = \"http://www.opengis.net/gml\";\n\n    Text txt = GameObject.Find(\"Text\").GetComponent<Text>();\n    //this is for unity\n\n    var query = xd.Descendants(gml + \"coord\")\n        .Select(e => new\n        {\n            X = (decimal)e.Element(gml + \"X\"),\n            Y = (decimal)e.Element(gml + \"Y\")\n        });\n\n    foreach (var c in query)\n    {\n      txt.text = c.ToString();\n    }\n  }\n}\n```\n\n\nThis works well when applied to this XML:\n\n```\n<?xml version='1.0' encoding='UTF-8'?>\n<schema xmlns='http://www.w3.org/2000/10/XMLSchema'\n        xmlns:gml='http://www.opengis.net/gml'\n        xmlns:xlink='http://www.w3.org/1999/xlink'\n        xmlns:xsi='http://www.w3.org/2000/10/XMLSchema-instance'\n        xsi:schemaLocation='http://www.opengis.net/gml/feature.xsd'>\n  <gml:Polygon srsName='http://www.opengis.net/gml/srs/epsg.xml#4283'>\n    <gml:outerBoundaryIs>\n      <gml:LinearRing>\n        <gml:coord>\n          <gml:X>152.035953</gml:X>\n          <gml:Y>-28.2103190007845</gml:Y>\n        </gml:coord>\n      </gml:LinearRing>\n    </gml:outerBoundaryIs>\n  </gml:Polygon>\n</schema>\n```\n\n\nHowever, when I use the XML below, it doesn't work.\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<IndoorFeatures xmlns=\"http://www.opengis.net/indoorgml/1.0/core\"\n                xmlns:gml=\"http://www.opengis.net/gml/3.2\" \n                xmlns:ns4=\"http://www.opengis.net/indoorgml/1.0/navigation\" \n                xmlns:xlink=\"http://www.w3.org/1999/xlink\" \n                xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n                gml:id=\"IFs\" xsi:schemaLocation=\"http://www.opengis.net/indoorgml/1.0/core http://schemas.opengis.net/indoorgml/1.0/indoorgmlcore.xsd\">\n    <gml:name>IFs</gml:name>\n    <gml:boundedBy>\n        <gml:Envelope srsDimension=\"3\" srsName=\"EPSG::4326\">\n            <gml:lowerCorner>112.1168351477 48.8817891374 10.0</gml:lowerCorner>\n            <gml:upperCorner>116.7830482115 88.0511182109 20.0</gml:upperCorner>\n        </gml:Envelope>\n    </gml:boundedBy>\n    <primalSpaceFeatures>\n        <PrimalSpaceFeatures gml:id=\"PS2\">\n            <gml:name>PS2</gml:name>\n            <gml:boundedBy xsi:nil=\"true\"/>\n            <cellSpaceMember>\n                <CellSpace gml:id=\"C45\">\n                    <gml:description>Usage=Room</gml:description>\n                    <gml:name>C45</gml:name>\n                    <gml:boundedBy xsi:nil=\"true\"/>\n                    <Geometry3D>\n                        <gml:Solid gml:id=\"SOLID1\">\n                            <gml:exterior>\n                                <gml:Shell>\n                                    <gml:surfaceMember>\n                                        <gml:Polygon gml:id=\"POLY56\">\n                                            <gml:name>POLY56</gml:name>\n                                            <gml:exterior>\n                                                <gml:LinearRing>\n                                                    <gml:pos>114.7255054432 56.357827476 10.0</gml:pos>\n                                                 </gml:LinearRing>\n                                            </gml:exterior>\n                                        </gml:Polygon>\n                                    </gml:surfaceMember>\n                                </gml:Shell>\n                            </gml:exterior>\n                        </gml:Solid>\n                    </Geometry3D>\n                    <duality xlink:href=\"#R1\"/>\n                    <partialboundedBy xlink:href=\"#Door1\"/>\n                    <partialboundedBy xlink:href=\"#CB220\"/>\n                    <partialboundedBy xlink:href=\"#CB221\"/>\n                </CellSpace>\n            </cellSpaceMember>\n        </PrimalSpaceFeatures>\n    </primalSpaceFeatures>\n</IndoorFeatures>\n```\n\n\nI naturally prefer to use simple code like the following:  \n\n```\nvar query = xd.Descendants(gml + \"LinearRing\").Select(\n    e => new\n    {\n        X = (decimal)e.Element(gml + \"pos\")\n    }\n);\n```\n\n\nHow can I parse GML in C# (or JavaScript) in order to use unity?\n    ", "Answer": "\r\nTry code like this.  You have namespace issues :\n\n```\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Xml;\nusing System.Xml.Linq;\n\nnamespace ConsoleApplication65\n{\n    class Program\n    {\n        const string FILENAME = @\"c:\\temp\\test.xml\";\n        static void Main(string[] args)\n        {\n            XDocument doc = XDocument.Load(FILENAME);\n            XElement indoorFeatures = doc.Root;\n\n            XNamespace xsGml= indoorFeatures.GetNamespaceOfPrefix(\"gml\");\n            XNamespace ns = indoorFeatures.GetDefaultNamespace();\n\n            var results = doc.Elements(ns + \"IndoorFeatures\").Select(x => new {\n                name = (string)x.Element(xsGml + \"name\"),\n                lowerCorner = (string)x.Descendants(xsGml +  \"lowerCorner\").FirstOrDefault(),\n                upperCorner = (string)x.Descendants(xsGml + \"upperCorner\").FirstOrDefault(),\n                primalSpaceFeatures = x.Descendants(ns + \"PrimalSpaceFeatures\").Select(y => new {\n                    name = (string)y.Element(xsGml + \"name\"),\n                    cellSpace = (string)y.Descendants(ns + \"CellSpace\").FirstOrDefault().Attribute(xsGml + \"id\"),\n                    description = (string)y.Descendants(xsGml + \"description\").FirstOrDefault(),\n                    cellSpaceName = (string)y.Descendants(ns + \"CellSpace\").FirstOrDefault().Element(xsGml + \"name\")\n                }).ToList()\n            }).FirstOrDefault();\n\n        }\n    }\n\n}\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Meteor application crashing when calling method\r\n                \r\nI have a collection in which I had inserted several documents using the following code: \n\n```\nProjects.insert({\n    source: \"https://upload.wikimedia.org/wikipedia/commons/7/7f/Pug_portrait.jpg\",\n    title: \"Pug\",\n    artist: \"pug\",\n    description: \"This piece shows the duality of pug\",\n    price: \"$50\"\n});\n\nProjects.insert({\n    source: \"http://c.fastcompany.net/multisite_files/fastcompany/poster/2014/01/3025003-poster-p-dog-2.jpg\",\n    title: \"Dog\",\n    artist: \"dog\",\n    description: \"much doge, many deal with it, wow\",\n    price: \"$50\"\n})\n\nProjects.insert({\n    source: \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1280px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg\",\n    title: \"Starry Night\",\n    artist: \"van gogh\",\n    description: \"night sky with stars\",\n    price: \"$75\"\n})\n\nProjects.insert({\n    source: \"http://totallyhistory.com/wp-content/uploads/2012/03/The_Scream.jpg\",\n    title: \"Scream\",\n    artist: \"edvard\",\n    description: \"scream\",\n    price: \"$50\"\n})\n\nProjects.insert({\n    source: \"https://www.petfinder.com/wp-content/uploads/2012/11/dog-how-to-select-your-new-best-friend-thinkstock99062463.jpg\",\n    title: \"Dog 2\",\n    artist: \"Bittu\",\n    description: \"This is a test to see how an actual thing would work\",\n    price: \"$50\"\n})\n```\n\n\nI created the following method:\n\n```\nMeteor.methods({\n  addProject: function (source, title, artist, description, price) {\n    // Make sure the user is logged in before inserting a task\n    if (! Meteor.userId()) {\n      throw new Meteor.Error(\"not-authorized\");\n    }\n\n    Projects.insert({\n      source: source,\n      title: title,\n      artist: artist,\n      description: description,\n      price: price\n    });\n  }\n});\n```\n\n\nWhen I attempt to call the method, the application crashes and refers to the following line of code:\n\n```\nMeteor.call(\"addProject\", \"http://mybuzzblog.com/wp-content/uploads/2014/12/German-Shepherds.jpg\", \"Dog 3\", \"Me\", \"happy dog\", \"$60\");\n```\n\n\nHere is what the console displays.\n\n```\nW20150729-12:26:31.609(-4)? (STDERR)\nW20150729-12:26:31.610(-4)? (STDERR) C:\\Users\\Raj\\AppData\\Local\\.meteor\\packages\n\\meteor-tool\\1.1.3\\mt-os.windows.x86_32\\dev_bundle\\server-lib\\node_modules\\fiber\ns\\future.js:245\nW20150729-12:26:31.610(-4)? (STDERR)\nthrow(ex);\nW20150729-12:26:31.610(-4)? (STDERR)\n      ^\nW20150729-12:26:31.610(-4)? (STDERR) Error: Method not found [404]\nW20150729-12:26:31.610(-4)? (STDERR)     at [object Object]._.extend.apply (pack\nages/ddp/livedata_server.js:1502:1)\nW20150729-12:26:31.613(-4)? (STDERR)     at [object Object]._.extend.call (packa\nges/ddp/livedata_server.js:1472:1)\nW20150729-12:26:31.613(-4)? (STDERR)     at app\\art.js:5:8\nW20150729-12:26:31.613(-4)? (STDERR)     at app\\art.js:137:3\nW20150729-12:26:31.613(-4)? (STDERR)     at C:\\Users\\Raj\\art\\.meteor\\local\\build\n\\programs\\server\\boot.js:222:10\nW20150729-12:26:31.614(-4)? (STDERR)     at Array.forEach (native)\nW20150729-12:26:31.614(-4)? (STDERR)     at Function._.each._.forEach (C:\\Users\\\nRaj\\AppData\\Local\\.meteor\\packages\\meteor-tool\\1.1.3\\mt-os.windows.x86_32\\dev_bu\nndle\\server-lib\\node_modules\\underscore\\underscore.js:79:11)\nW20150729-12:26:31.614(-4)? (STDERR)     at C:\\Users\\Raj\\art\\.meteor\\local\\build\n\\programs\\server\\boot.js:117:5\n=> Exited with code: 8\n=> Your application is crashing. Waiting for file change.\n```\n\n\nWhat can I do to fix this?\n    ", "Answer": "\r\nMake sure your Meteor.methods is under server folder or in Meteor.isServer conditional.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Logical Question\r\n                \r\nConsider a [4x8] matrix \"A\" and [1x8] matrix \"B\". I need to check if there exists a value \"X\" such that\n\n```\n[A]^T * [X] = [B]^T  exists for any x >= 0 { X is a [4X1] matrix,  T = transpose }\n```\n\n\nNow here is the trick/tedious part. The matrix A always has 1 as its diagonal. ```\nA11,A22,A33,A44 = 1```\n This matrix can be considered as two halves with first half being the first 4 columns and the second half being the second 4 columns like something below : \n\n```\n        1 -1 -1 -1   1 0 0 1\n  A =  -1  1 -1  0   0 1 0 0\n       -1 -1  1  0   1 0 0 0 \n       -1 -1 -1  1   1 1 0 0\n```\n\n\nEach row in the first half can have either two or three -1's and if it has two -1's then that corresponding row in the second half should have one \"1\" or if any row has three -1's the second half of the matrix should have two 1's. The overall objective is to have the sum of each row to be 0. \n\nNow B is a [1x8] matrix which can also be considered as two halves as follows:\n\n```\nB = -1 -1 0 0   0 0 1 1\n```\n\n\nHere there can be either one, two, three or four -1's in the first half and there should be equal number of 1's in the second half. It should be done in combinations For example, if there are two -1's in the first half, they can be placed in 4 choose 2 = 6 ways and for each of them there will be 6 ways to place the 1's in the second half which has a total of 6*6 = 36 ways. i.e. 36 different values for B's if there are two -1's in the first half. The placement of 1's in the matrix A should also be the same way. The way I could think of doing this is to consider a ```\nvalarray```\n or something of that sort and make the matrices A and B but I don't know what to do. \n\nNow for every A, I've to test it with every combinations of B to see if there exists \n\n```\n[A]^T * [X] = [B]^T \n```\n\n\nI'm trying to prove a result that I got I need to know if such an X would exist or not. I'm very confused on implementing this. Any suggestions are welcome. This would come under linear programming concept in math. I want it either in C++ or in Matlab. Any other languages are also acceptable but I'm familiar with only these two. Thanks in advance.\n\nUpdate:\n\nHere is my answer for this problem :\n\n```\nclear;\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%# Generating all possible values of vector B\n\n%# permutations using dec2bin (start from 17 since it's the first solution)\nvectorB = str2double(num2cell(dec2bin(17:255)));\n\n%# changing the sign in the first half, then check that the total is zero\nvectorB(:,1:4) = - vectorB(:,1:4);\nvectorB = vectorB(sum(vectorB,2)==0,:);\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%# generate all possible variation of first/second halves\nz = -[0 1 1; 1 0 1; 1 1 0; 1 1 1]; n = -sum(z,2);\nh1 = {\n    [         ones(4,1) z(:,1:3)] ;\n    [z(:,1:1) ones(4,1) z(:,2:3)] ;\n    [z(:,1:2) ones(4,1) z(:,3:3)] ;\n    [z(:,1:3) ones(4,1)         ] ;\n};\nh2 = arrayfun(@(i) unique(perms([zeros(1,4-i) ones(1,i)]),'rows'), (1:2)', ...\n    'UniformOutput',false);\n\n%'# generate all possible variations of complete rows\nrows = cell(4,1);\nfor r=1:4\n    rows{r} = cell2mat( arrayfun( ...\n        @(i) [ repmat(h1{r}(i,:),size(h2{n(i)-1},1),1) h2{n(i)-1} ], ...\n        (1:size(h1{r},1))', 'UniformOutput',false) );\nend\n\n%'# generate all possible matrices (pick one row from each to form the matrix)\nsz = cellfun(@(M)1:size(M,1), rows, 'UniformOutput',false);\n[X1 X2 X3 X4] = ndgrid(sz{:});\nmatrices = cat(3, ...\n    rows{1}(X1(:),:), ...\n    rows{2}(X2(:),:), ...\n    rows{3}(X3(:),:), ...\n    rows{4}(X4(:),:) );\nmatrices = permute(matrices, [3 2 1]);              %# 4-by-8-by-104976\nA = matrices;\nclear matrices X1 X2 X3 X4 rows h1 h2 sz z n r\noptions = optimset('LargeScale','off','Display','off');\nfor i = 1:size(A,3),\n    for j = 1:size(vectorB,1),\n        X = linprog([],[],[],A(:,:,i)',vectorB(j,:)');\n        if(size(X,1)>0)  %# To check that it's not an empty matrix\n            if((size(find(X < 0),1)== 0)) %# to check the condition X>=0\n                if (A(:,:,i)'* X == (vectorB(j,:)'))                \n                    X\n                end\n            end\n        end\n    end\nend\n```\n\n\nI got it with the help of stackoverflow folks. The only problem is the linprog function throws a lot of exceptions in every iteration along with the answers produced. The exception is: \n\n```\n(1)Exiting due to infeasibility: an all-zero row in the constraint matrix does not have a zero in corresponding right-hand-side entry. \n(2) Exiting: One or more of the residuals, duality gap, or total relative error has stalled: the primal appears to be infeasible (and the dual unbounded).(The dual residual < TolFun=1.00e-008.\n```\n\n\nWhat does this mean. How can I overcome this?\n    ", "Answer": "\r\nIt is not clear from your question if you are familiar with system linear equations and their solution, or it is what you are trying to \"invent\". See also here for Matlab-specific explanation.\n\nIf you are familiar with that, you should be more clear in your question about what makes your problem different.\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "jQuery toggle path navigation\r\n                \r\nI want to code a path navigation with jQuery.\n\nThis is how it looks at the moment:\n\n\r\n\r\n```\n$(\"#one_link\").click(function() {\r\n  $(\"#categories\").css(\"display\", \"block\");\r\n  $(\"#text_three\").css(\"display\", \"none\");\r\n  $(\"#cats_text\").css(\"display\", \"none\");\r\n  $(\"#text_two\").css(\"display\", \"none\");\r\n});\r\n\r\n$(\"#cats_link\").click(function() {\r\n  $(\"#cats_text\").css(\"display\", \"block\");\r\n  $(\"#text_two\").css(\"display\", \"none\");\r\n  $(\"#text_three\").css(\"display\", \"none\");\r\n});\r\n\r\n$(\"#two_link\").click(function() {\r\n  $(\"#text_two\").css(\"display\", \"block\");\r\n  $(\"#categories\").css(\"display\", \"none\");\r\n  $(\"#cats_text\").css(\"display\", \"none\");\r\n  $(\"#text_three\").css(\"display\", \"none\");\r\n});\r\n\r\n$(\"#three_link\").click(function() {\r\n  $(\"#text_three\").css(\"display\", \"block\");\r\n  $(\"#categories\").css(\"display\", \"none\");\r\n  $(\"#cats_text\").css(\"display\", \"none\");\r\n  $(\"#text_two\").css(\"display\", \"none\");\r\n});```\n\r\n```\n* {\r\n  list-style-type: none;\r\n  margin: 0;\r\n  padding: 0;\r\n  font-size: 30px;\r\n  line-height: 100%;\r\n  cursor: default;\r\n  font-family: Arial;\r\n}\r\n\r\nhtml,\r\nbody {\r\n  width: 100vw;\r\n  height: 100vh;\r\n  overflow: hidden;\r\n}\r\n\r\n.content {\r\n  display: flex;\r\n  overflow: hidden;\r\n  width: 100vw;\r\n  height: 100vh;\r\n}\r\n\r\n.column {\r\n  border-right: 1px solid;\r\n}\r\n\r\n.column_content {\r\n  overflow-y: scroll;\r\n  width: 100%;\r\n  height: 100%;\r\n  padding: 20px;\r\n}\r\n\r\n.column {\r\n  display: none;\r\n}\r\n\r\n.column:first-child {\r\n  display: block;\r\n}\r\n\r\nli:hover {\r\n  cursor: pointer;\r\n}```\n\r\n```\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n\r\n<div class=\"content\">\r\n\r\n  <div class=\"column\">\r\n    <div class=\"column_content\">\r\n      <ul>\r\n        <li id=\"one_link\">One</li>\r\n        <li id=\"two_link\">Two</li>\r\n        <li id=\"three_link\">Three</li>\r\n      </ul>\r\n    </div>\r\n  </div>\r\n\r\n  <div id=\"categories\" class=\"column\">\r\n    <div class=\"column_content\">\r\n      <ul>\r\n        <li id=\"cats_link\">Cats</li>\r\n      </ul>\r\n    </div>\r\n  </div>\r\n\r\n  <div class=\"column\" id=\"cats_text\">\r\n    <div class=\"column_content\">\r\n      <p>The cat (Felis catus) is a domestic species of small carnivorous mammal. It is the only domesticated species in the family Felidae and is often referred to as the domestic cat to distinguish it from the wild members of the family.</p>\r\n    </div>\r\n  </div>\r\n\r\n  <div class=\"column\" id=\"text_two\">\r\n    <div class=\"column_content\">\r\n      <p>2 (two) is a number, numeral, and glyph. It is the natural number following 1 and preceding 3. It is the smallest and only even prime number. Because it forms the basis of a duality, it has religious and spiritual significance in many cultures.</p>\r\n    </div>\r\n  </div>\r\n\r\n  <div class=\"column\" id=\"text_three\">\r\n    <div class=\"column_content\">\r\n      <p>3 (three) is a number, numeral, and glyph. It is the natural number following 2 and preceding 4, and is the smallest odd prime number. It has religious or cultural significance in many societies.</p>\r\n    </div>\r\n  </div>\r\n\r\n</div>```\n\r\n\r\n\r\n\n\nWhat I need is a toggle function for the links. For example, if you click one link a second time, the content should be hidden. Taking ».toggle« instead of ».click« doesn't work. And in general: Is there an easier way to code this? Or do I have to link it so detailed together as I did?\n\nWould be very grateful for any help! <3\n    ", "Answer": "\r\nAdd a data-target and commom class to the links:\n\n```\n<li class=\"tablink\" id=\"two_link\" data-target=\"text_two\">Two</li>\n```\n\n\nA commom class to the texts:\n\n```\n<div class=\"column tabtext\" id=\"text_two\">\n```\n\n\nMake this hidden by default, and add a ```\nvisible```\n class:\n\n```\n.tabtext {\n  opacity: 0;\n  transition 0.2s;\n}\n.tabtext.visible {\n  opacity: 1;\n}\n```\n\n\nAnd to show/hide:\n\n```\n$(\"body\").on(\"click\", \".tablink\", function(ev) {\n  var target = $(\"#\" + this.dataset.target);\n  var show = !target.hasClass(\"visible\"); // Only show if wasn't visible\n  $(\".tabtext.visible\").removeClass(\"visible\"); // Hide visible\n  if (show) target.addClass(\"visible\"); // Show the selected\n});\n```\n\n\n\r\n\r\n```\n$(\"body\").on(\"click\", \".tablink\", function(e) {\r\n  var target = $(\"#\" + this.dataset.target);\r\n  var show = !target.hasClass(\"visible\");\r\n  $(\".tabtext.visible\").removeClass(\"visible\");\r\n  $(\".tabtext2.visible\").removeClass(\"visible\"); // Hide 2nd level as well\r\n  if (show) target.addClass(\"visible\");\r\n});\r\n\r\n$(\"body\").on(\"click\", \".tablink2\", function(ev) {\r\n  var target = $(\"#\" + this.dataset.target);\r\n  var show = !target.hasClass(\"visible\");\r\n  $(\".tabtext2.visible\").removeClass(\"visible\");\r\n  if (show) target.addClass(\"visible\");\r\n});```\n\r\n```\n.tabtext,\r\n.tabtext2 {\r\n  opacity: 0;\r\n  transition: 0.2s;\r\n  display: none;\r\n  position: absolute;\r\n}\r\n\r\n.visible {\r\n  opacity: 1;\r\n  display: inline-block;\r\n}\r\n\r\n* {\r\n  list-style-type: none;\r\n  margin: 0;\r\n  padding: 0;\r\n  font-size: 22px;\r\n  line-height: 100%;\r\n  cursor: default;\r\n  font-family: Arial;\r\n}\r\n\r\nhtml,\r\nbody {\r\n  width: 100vw;\r\n  height: 100vh;\r\n  overflow: hidden;\r\n}\r\n\r\n.content {\r\n  display: flex;\r\n  overflow: hidden;\r\n  width: 100vw;\r\n  height: 100vh;\r\n  visibility: hidden;\r\n}\r\n\r\n.column {\r\n  border-right: 1px solid;\r\n  visibility: visible;\r\n}\r\n\r\n.column_content {\r\n  height: 100%;\r\n  padding: 20px;\r\n}\r\n\r\n.column_content p {\r\n  font-size: 12px;\r\n}\r\n\r\n.column:first-child {\r\n  display: block;\r\n}\r\n\r\nli {\r\n  z-index: 1\r\n}\r\n\r\nli:hover {\r\n  cursor: pointer;\r\n}\r\n\r\n#categories {\r\n  height: 100%;\r\n}\r\n\r\n#categories div {\r\n  display: inline-block;\r\n}\r\n\r\n.tabtext2 {\r\n  width: 300px;\r\n}```\n\r\n```\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n\r\n<div class=\"content\">\r\n\r\n  <div class=\"column\">\r\n    <div class=\"column_content\">\r\n      <ul>\r\n        <li id=\"one_link\" class=\"tablink\" data-target=\"categories\">One</li>\r\n        <li id=\"two_link\" class=\"tablink\" data-target=\"text_two\">Two</li>\r\n        <li id=\"three_link\" class=\"tablink\" data-target=\"text_three\">Three</li>\r\n      </ul>\r\n    </div>\r\n  </div>\r\n\r\n  <div class=\"texts\">\r\n    <div id=\"categories\" class=\"column tabtext\">\r\n      <div class=\"column_content\">\r\n        <ul>\r\n          <li id=\"cats_link\" class=\"tablink2\" data-target=\"cats_text\">Cats</li>\r\n        </ul>\r\n      </div>\r\n      <div class=\"column tabtext2\" id=\"cats_text\">\r\n        <div class=\"column_content\">\r\n          <p>The cat (Felis catus) is a domestic species of small carnivorous mammal. It is the only domesticated species in the family Felidae and is often referred to as the domestic cat to distinguish it from the wild members of the family.</p>\r\n        </div>\r\n      </div>\r\n    </div>\r\n\r\n    <div class=\"column tabtext\" id=\"text_two\">\r\n      <div class=\"column_content\">\r\n        <p>2 (two) is a number, numeral, and glyph. It is the natural number following 1 and preceding 3. It is the smallest and only even prime number. Because it forms the basis of a duality, it has religious and spiritual significance in many cultures.</p>\r\n      </div>\r\n    </div>\r\n    <div class=\"column tabtext\" id=\"text_three\">\r\n      <div class=\"column_content\">\r\n        <p>3 (three) is a number, numeral, and glyph. It is the natural number following 2 and preceding 4, and is the smallest odd prime number. It has religious or cultural significance in many societies.</p>\r\n      </div>\r\n    </div>\r\n  </div>\r\n</div>```\n\r\n\r\n\r\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Why won't the arrows and close button show up for my lightbox images?\r\n                \r\nI'm using Lightbox in my site so that users can view my images in a larger size, and for some odd reason the controls won't show up. Haven't been able to figure out what the cause would be. Tried comparing my code to the code on the demo site, but couldn't figure out what I had done wrong. Best I can figure is maybe I accidentally did something with my CSS reset?\n\n\r\n\r\n```\n<script src=\"js/lightbox-plus-jquery.js\">\r\n\tlightbox.option({\r\n\t\t  'wrapAround': true,\r\n\t\t  'alwaysShowNavOnTouchDevices': true,\r\n\t\t  'showImageNumberLabel': true,\r\n\t\t})\r\n</script>```\n\r\n```\n/* CSS Reset */\r\n\r\nhtml, body, div, span, applet, object, iframe,\r\nh1, h2, h3, h4, h5, h6, p, blockquote, pre,\r\na, abbr, acronym, address, big, cite, code,\r\ndel, dfn, em, img, ins, kbd, q, s, samp,\r\nsmall, strike, strong, sub, sup, tt, var,\r\nb, u, i, center,\r\ndl, dt, dd, ol, ul, li,\r\nfieldset, form, label, legend,\r\ntable, caption, tbody, tfoot, thead, tr, th, td,\r\narticle, aside, canvas, details, embed, \r\nfigure, figcaption, footer, header, hgroup, \r\nmenu, nav, output, ruby, section, summary,\r\ntime, mark, audio, video {\r\n\tmargin: 0;\r\n\tpadding: 0;\r\n\tborder: 0;\r\n\tfont-size: 100%;\r\n\tfont: inherit;\r\n\tvertical-align: baseline;\r\n}\r\n/* HTML5 display-role reset for older browsers */\r\narticle, aside, details, figcaption, figure, \r\nfooter, header, hgroup, menu, nav, section {\r\n\tdisplay: block;\r\n}\r\nbody {\r\n\tline-height: 1;\r\n}\r\nol, ul {\r\n\tlist-style: none;\r\n}\r\nblockquote, q {\r\n\tquotes: none;\r\n}\r\nblockquote:before, blockquote:after,\r\nq:before, q:after {\r\n\tcontent: '';\r\n\tcontent: none;\r\n}\r\ntable {\r\n\tborder-collapse: collapse;\r\n\tborder-spacing: 0;\r\n}\r\n\r\n/*End CSS Reset */\r\n\r\nbody {\r\n    max-width: 100%; \r\n    margin: 0;   \r\n    font-size: 16px;   \r\n    background-color: #fff;\r\n    color: #000;\r\n    font-family: 'Lato', sans-serif;  \r\n}\r\n\r\na {\r\n    text-decoration: none;   \r\n    color: #555; \r\n}\r\n\r\np {\r\n\ttext-align: center;\t\r\n}\r\n\r\n/* Nav Bar Styles */\r\n\r\nnav {\r\n    text-align: right;\r\n\twidth: 100%;\r\n\tbackground-color: #fff; \r\n\tfont-size: 1.4em;\r\n\tpadding: 0;\r\n\tpadding-top: .5%;\r\n\tpadding-bottom: .6%;\r\n\t  \r\n}\r\n\r\nul {\r\n\tpadding-right: 2%;\t\r\n}\r\n\r\n.navigation {\r\n    display: inline;\r\n    margin: .5%;\r\n\t \r\n}\r\n\r\n.logo {\r\n\tcolor:#000;\t\r\n\tdisplay: inline;\r\n\tfloat: left;\r\n\tmargin: 0 0 0 1%;\r\n}\r\n\r\n/* Footer */\r\n\r\nfooter {\r\n    text-align: center;\r\n\tpadding-top: 2%;\r\n\tpadding-bottom: .5%;  \r\n\tfont-size: 79%;\r\n\tcolor: #000;\r\n\tbackground-color: #fff; \r\n\tclear: left;\r\n\t  \r\n}\r\n\r\n.imageGrid {\r\n\twidth: 100%;\r\n\tdisplay: block;\t\r\n\ttext-align: center;\r\n\r\n}\r\n\r\n.images {\r\n\twidth: 10%;\t\r\n\r\n}\r\n\r\n.categories {\r\n\tfont-size: 1.4em;\t\r\n\ttext-align: center;\r\n\tpadding-top: 2%;\r\n\tpadding-bottom: 1%;\r\n}```\n\r\n```\n<!doctype html>\r\n<html lang=\"en\">\r\n<head>\r\n<meta charset=\"utf-8\">\r\n<title>Brian Funderburke Photography &amp; Design</title>\r\n<link rel=\"stylesheet\" href=\"css/reset.css\">\r\n<link rel=\"stylesheet\" href=\"css/sitewide.css\">\r\n<link href=\"https://fonts.googleapis.com/css?family=Lato\" rel=\"stylesheet\" type=\"text/css\">\r\n<link rel=\"stylesheet\" href=\"css/photography.css\">\r\n<link href=\"css/lightbox.css\" rel=\"stylesheet\">\r\n</head>\r\n\r\n<body>\r\n<header>\r\n  \r\n    <nav>\r\n        <h1 class=\"logo\">B.Fun Photography &amp; Design</h1>\r\n            <ul>\r\n                <li class=\"navigation\"><a href=\"home.html\">Home</a></li>\r\n                <li class=\"navigation\"><a href=\"photography.html\">Photography</a></li>\r\n                <li class=\"navigation\"><a href=\"design.html\">Design</a></li>\r\n                <li class=\"navigation\"><a href=\"about.html\">About</a></li>\r\n                <li class=\"navigation\"><a href=\"contact.html\">Contact</a></li>\r\n            </ul>\r\n    </nav>\r\n    \r\n</header>\r\n\r\n<h2 class=\"categories\">Landscapes</h2>\r\n<div class=\"imageGrid\">\r\n    <a href=\"http://www.alsogroup.org/default/assets/File/Help2-700x394.jpg\" data-lightbox=\"image-1\" data-title=\"Blue Ridge Sunset\"><img src=\"http://www.alsogroup.org/default/assets/File/Help2-700x394.jpg\" alt=\"Blue Ridge Sunset\" class=\"images\"></a>\r\n    <a href=\"http://www.alsogroup.org/default/assets/File/Help2-700x394.jpg\" data-lightbox=\"image-1\" data-title=\"Duality\"><img src=\"http://www.alsogroup.org/default/assets/File/Help2-700x394.jpg\" alt=\"Duality\" class=\"images\"></a>\r\n    <a href=\"http://www.alsogroup.org/default/assets/File/Help2-700x394.jpg\" data-lightbox=\"image-1\" data-title=\"Elakala Falls\"><img src=\"http://www.alsogroup.org/default/assets/File/Help2-700x394.jpg\" alt=\"Elakala Falls\" class=\"images\"></a>\r\n    <a href=\"img/m.jpg\" data-lightbox=\"image-1\" data-title=\"Methuselah\"><img src=\"img/thumbs/m.jpg\" alt=\"Methuselah\" class=\"images\"></a>\r\n    <a href=\"img/occ.jpg\" data-lightbox=\"image-1\" data-title=\"Old City Cemetary\"><img src=\"img/thumbs/occ.jpg\" alt=\"Old City Cemetary\" class=\"images\"></a>\r\n    <a href=\"img/mk.jpg\" data-lightbox=\"image-1\" data-title=\"Mcafee's Knob\"><img src=\"img/thumbs/mk.jpg\" alt=\"Mcafee's Knob\" class=\"images\"></a>\r\n    <a href=\"img/af.png\" data-lightbox=\"image-1\" data-title=\"Appalachian Farmland\"><img src=\"img/thumbs/af.jpg\" alt=\"Appalachian Farmland\" class=\"images\"></a>\r\n    <a href=\"img/bf.jpg\" data-lightbox=\"image-1\" data-title=\"Blackwater Falls\"><img src=\"img/thumbs/bf.jpg\" alt=\"Blackwater Falls\" class=\"images\"></a>\r\n    <a href=\"img/dh.jpg\" data-lightbox=\"image-1\" data-title=\"Dark Hollows Falls\"><img src=\"img/thumbs/dh.jpg\" alt=\"Dark Hollows Falls\" class=\"images\"></a>\r\n    <a href=\"img/ef2.jpg\" data-lightbox=\"image-1\" data-title=\"Elakala Falls\"><img src=\"img/thumbs/ef2.jpg\" alt=\"Elakala Falls\" class=\"images\"></a>\r\n    <a href=\"img/hr.jpg\" data-lightbox=\"image-1\" data-title=\"Humpback Rocks\"><img src=\"img/thumbs/hr.jpg\" alt=\"Humpback Rocks\" class=\"images\"></a>\r\n    <a href=\"img/lp.jpg\" data-lightbox=\"image-1\" data-title=\"Lindy Point\"><img src=\"img/thumbs/lp.jpg\" alt=\"Lindy Point\" class=\"images\"></a>\r\n    <a href=\"img/lps.jpg\" data-lightbox=\"image-1\" data-title=\"Lindy Point Sunset\"><img src=\"img/thumbs/lps.jpg\" alt=\"Lindy Point Sunset\" class=\"images\"></a>\r\n    <a href=\"img/to.jpg\" data-lightbox=\"image-1\" data-title=\"The Overlook\"><img src=\"img/thumbs/to.jpg\" alt=\"The Overlook\" class=\"images\"></a>\r\n    <a href=\"img/golyat.png\" data-lightbox=\"image-1\" data-title=\"Golyat\"><img src=\"img/thumbs/golyat.jpg\" alt=\"Golyat s\" class=\"images\"></a>\r\n</div>\r\n<h2 class=\"categories\">Weddings</h2>\r\n\t<div class=\"imageGrid\">\r\n    <a href=\"img/weddings/sweeny/beforeFirstLook.jpg\" data-lightbox=\"image-2\" data-title=\"#\"><img src=\"img/thumbs/br.jpg\" alt=\"Blue Ridge Sunset\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"#\"><img src=\"img/thumbs/duality.jpg\" alt=\"Duality\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"Elakala Falls\"><img src=\"img/thumbs/ef.jpg\" alt=\"Elakala Falls\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"Methuselah\"><img src=\"img/thumbs/m.jpg\" alt=\"Methuselah\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"Old City Cemetary\"><img src=\"img/thumbs/occ.jpg\" alt=\"Old City Cemetary\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"Mcafee's Knob\"><img src=\"img/thumbs/mk.jpg\" alt=\"Mcafee's Knob\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"Appalachian Farmland\"><img src=\"img/thumbs/af.jpg\" alt=\"Appalachian Farmland\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"Blackwater Falls\"><img src=\"img/thumbs/bf.jpg\" alt=\"Blackwater Falls\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"Dark Hollows Falls\"><img src=\"img/thumbs/dh.jpg\" alt=\"Dark Hollows Falls\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"Elakala Falls\"><img src=\"img/thumbs/ef2.jpg\" alt=\"Elakala Falls\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"Humpback Rocks\"><img src=\"img/thumbs/hr.jpg\" alt=\"Humpback Rocks\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"Lindy Point\"><img src=\"img/thumbs/lp.jpg\" alt=\"Lindy Point\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"Lindy Point Sunset\"><img src=\"img/thumbs/lps.jpg\" alt=\"Lindy Point Sunset\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-2\" data-title=\"The Overlook\"><img src=\"img/thumbs/to.jpg\" alt=\"The Overlook\" class=\"images\"></a>\r\n</div>\r\n<h2 class=\"categories\">Other</h2>\r\n\t<div class=\"imageGrid\">\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"#\"><img src=\"img/thumbs/br.jpg\" alt=\"Blue Ridge Sunset\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"#\"><img src=\"img/thumbs/duality.jpg\" alt=\"Duality\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"Elakala Falls\"><img src=\"img/thumbs/ef.jpg\" alt=\"Elakala Falls\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"Methuselah\"><img src=\"img/thumbs/m.jpg\" alt=\"Methuselah\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"Old City Cemetary\"><img src=\"img/thumbs/occ.jpg\" alt=\"Old City Cemetary\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"Mcafee's Knob\"><img src=\"img/thumbs/mk.jpg\" alt=\"Mcafee's Knob\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"Appalachian Farmland\"><img src=\"img/thumbs/af.jpg\" alt=\"Appalachian Farmland\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"Blackwater Falls\"><img src=\"img/thumbs/bf.jpg\" alt=\"Blackwater Falls\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"Dark Hollows Falls\"><img src=\"img/thumbs/dh.jpg\" alt=\"Dark Hollows Falls\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"Elakala Falls\"><img src=\"img/thumbs/ef2.jpg\" alt=\"Elakala Falls\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"Humpback Rocks\"><img src=\"img/thumbs/hr.jpg\" alt=\"Humpback Rocks\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"Lindy Point\"><img src=\"img/thumbs/lp.jpg\" alt=\"Lindy Point\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"Lindy Point Sunset\"><img src=\"img/thumbs/lps.jpg\" alt=\"Lindy Point Sunset\" class=\"images\"></a>\r\n    <a href=\"img/weddings/#.jpg\" data-lightbox=\"image-1\" data-title=\"The Overlook\"><img src=\"img/thumbs/to.jpg\" alt=\"The Overlook\" class=\"images\"></a>\r\n</div>\r\n\r\n\r\n\r\n<footer>\r\n    <p>&#169; 2016 Brian Funderburke. All Rights Reserved.</p>\r\n</footer>\r\n<script src=\"js/lightbox-plus-jquery.js\">\r\n\tlightbox.option({\r\n\t\t  'wrapAround': true,\r\n\t\t  'alwaysShowNavOnTouchDevices': true,\r\n\t\t  'showImageNumberLabel': true,\r\n\t\t})\r\n</script>\r\n</body>\r\n</html>```\n\r\n\r\n\r\n\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Cannot pull correct data from a Javascript array into an HTML form\r\n                \r\nI am trying to return the description value of the corresponding author name and book title(that are typed in the text boxes). The problem is that the first description displays in the text area no matter what.\n\n```\n<h1>Bookland</h1>\n<div id=\"bookinfo\">\n    Author name: \n    <input type=\"text\" id=\"authorname\" name=\"authorname\"></input><br />\n    Book Title:\n    <input type=\"text\" id=\"booktitle\" name=\"booktitle\"></input><br />\n    <input type=\"button\" value=\"Find book\" id=\"find\"></input>\n    <input type=\"button\" value=\"Clear Info\" id=\"clear\"></input><br />\n    <textarea rows=\"15\" cols=\"30\" id=\"destin\"></textarea>\n</div>\n```\n\n\nJavaScript:\n\n```\nvar bookarray = [{Author: \"Thomas Mann\", Title: \"Death in Venice\", Description: \"One of the most famous literary works of the twentieth century, this novella embodies\" + \"themes that preoccupied Thomas Mann in much of his work:\" + \"the duality of art and life, the presence of death and disintegration in the midst of existence,\" + \"the connection between love and suffering and the conflict between the artist and his inner self.\" },\n                 {Author: \"James Joyce\", Title: \"A portrait of the artist as a young man\", Description: \"This work displays an unusually perceptive view of British society in the early 20th century.\" + \"It is a social comedy set in Florence, Italy, and Surrey, England.\" + \"Its heroine, Lucy Honeychurch, struggling against straitlaced Victorian attitudes of arrogance, narroe mindedness and sobbery, falls in love - while on holiday in Italy - with the socially unsuitable George Emerson.\" },\n                 {Author: \"E. M. Forster\", Title: \"A room with a view\", Description: \"This book is a fictional re-creation of the Irish writer'sown life and early environment.\" + \"The experiences of the novel's young hero,unfold in astonishingly vivid scenes that seem freshly recalled from life\" + \"and provide a powerful portrait of the coming of age of a young man ofunusual intelligence, sensitivity and character. \" },\n                 {Author: \"Isabel Allende\", Title: \"The house of spirits\", Description: \"Allende describes the life of three generations of a prominent family in Chile and skillfully combines with this all the main historical events of the time, up until Pinochet's dictatorship.\" },\n                 {Author: \"Isabel Allende\", Title: \"Of love and shadows\", Description: \"The whole world of Irene Beltran, a young reporter in Chile at the time of the dictatorship, is destroyed when\" + \"she discovers a series of killings carried out by government soldiers.\" + \"With the help of a photographer, Francisco Leal, and risking her life, she tries to come up with evidence against the dictatorship.\" }]\n\n\nfunction searchbook(){\n    for(i=0; i &lt; bookarray.length; i++){\n        if ((document.getElementById(\"authorname\").value &amp; document.getElementById(\"booktitle\").value ) == (bookarray[i].Author &amp; bookarray[i].Title)){\n            document.getElementById(\"destin\").value =bookarray[i].Description\n            return bookarray[i].Description\n        } \n        else {\n            return \"Not Found!\"\n        }\n    }\n}\ndocument.getElementById(\"find\").addEventListener(\"click\", searchbook, false)\n```\n\n    ", "Answer": "\r\nYour code got html escaped for some reason, but I think the problem is in your if. Regardless, this should give you your answer and be slightly faster since it doesn't try to look up the elements in the dom inside a loop\n\n```\nfunction searchbook(){\n  var author = document.getElementById('authorname').value;\n  var title = document.getElementById('booktitle').value;\n  for (var i=0, book; book = bookarray[i]; i++) {\n    if (book.Title == title && book.Author == author) {\n      return book.Description;\n    }\n  }\n  return \"Not Found\"\n}\n```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "What's the best way to display image thumbnails in one large block?\r\n                \r\nI'd like to display my images in a block with rows of five thumbnails each. What's the best way to go about doing this?\n\nCurrently I've got my container div set to 100% width. Would the solution be something along the lines of putting another div within the div that I would limit to a certain width or something?\n\n```\n/* Site Wide CSS */\n\nbody {\n    max-width: 100%; \n    margin: 0;   \n    font-size: 16px;   \n    background-color: #fff;\n    color: #000;\n    font-family: 'Lato', sans-serif;  \n}\n\na {\n    text-decoration: none;   \n    color: #555; \n}\n\np {\n    text-align: center; \n}\n\n/* Nav Bar Styles */\n\nnav {\n    text-align: right;\n    width: 100%;\n    background-color: #fff; \n    font-size: 1.4em;\n    padding: 0;\n    padding-top: .5%;\n    padding-bottom: .6%;\n\n}\n\nul {\n    padding-right: 2%;  \n}\n\n.navigation {\n    display: inline;\n    margin: .5%;\n\n}\n\n.logo {\n    color:#000; \n    display: inline;\n    float: left;\n    margin: 0 0 0 1%;\n}\n\n/* Footer */\n\nfooter {\n    text-align: center;\n    padding-top: 2%;\n    padding-bottom: .5%;  \n    font-size: 79%;\n    color: #000;\n    background-color: #fff; \n    clear: left;\n\n}\n\n/* Font Awesome */\n\ni.fa {\n    font-size: 2.3em;   \n}\n\n.container {\n    padding-top: 2.5%; \n    padding-bottom: 2.5%;  \n}\n\n\n/* Styling for Photography and Design Pages */\n\n.categories {\n    font-size: 1.4em;   \n    text-align: center;\n    padding-top: 2%;\n    padding-bottom: 1%;\n}\n\n.imageGrid {\n    width: 100%;\n    display: block; \n    text-align: center;\n\n}\n\n.images {\n    width:9%;\n    marign: 0;\n    padding: 0;\n\n\n}\n```\n\n\n```\n<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<title>Brian Funderburke Photography &amp; Design</title>\n<link rel=\"stylesheet\" href=\"css/reset.css\">\n<link rel=\"stylesheet\" href=\"css/sitewide.css\">\n<link href=\"https://fonts.googleapis.com/css?family=Lato\" rel=\"stylesheet\" type=\"text/css\">\n<link rel=\"stylesheet\" href=\"css/photography.css\">\n<link href=\"css/lightbox.css\" rel=\"stylesheet\">\n</head>\n<body>\n<header>\n    <nav>\n        <h1 class=\"logo\">B.Fun Photography &amp; Design</h1>\n            <ul>\n                <li class=\"navigation\"><a href=\"home.html\">Home</a></li>\n                <li class=\"navigation\"><a href=\"photography.html\">Photography</a></li>\n                <li class=\"navigation\"><a href=\"design.html\">Design</a></li>\n                <li class=\"navigation\"><a href=\"about.html\">About</a></li>\n                <li class=\"navigation\"><a href=\"contact.html\">Contact</a></li>\n            </ul>\n    </nav>\n</header>\n<h2 class=\"categories\">Landscapes</h2>\n<div class=\"imageGrid\">\n    <a href=\"img/landscapes/br.jpg\" data-lightbox=\"image-1\" data-title=\"Blue Ridge Sunset\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Blue Ridge Sunset\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300y.jpg\" data-lightbox=\"image-1\" data-title=\"Duality\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Duality\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Elakala Falls\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Elakala Falls\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Methuselah\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Methuselah\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Old City Cemetary\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Old City Cemetary\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Mcafee's Knob\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Mcafee's Knob\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Appalachian Farmland\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Appalachian Farmland\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Blackwater Falls\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Blackwater Falls\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Dark Hollows Falls\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Dark Hollows Falls\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Elakala Falls\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Elakala Falls\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Humpback Rocks\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Humpback Rocks\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Lindy Point\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Lindy Point\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Lindy Point Sunset\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Lindy Point Sunset\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"The Overlook\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"The Overlook\" class=\"images\"></a>\n    <a href=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" data-lightbox=\"image-1\" data-title=\"Golyat\"><img src=\"https://lh3.ggpht.com/vFpQP39LB60dli3n-rJnVvTM07dsvIzxrCL5xMiy1V4GV4unC1ifXkUExQ4N-DBCKwI=w300\" alt=\"Golyat s\" class=\"images\"></a>\n</div>\n<footer>\n    <p>&#169; 2016 Brian Funderburke. All Rights Reserved.</p>\n</footer>\n<script src=\"js/lightbox-plus-jquery.js\">\n    lightbox.option({\n          'wrapAround': true,\n          'alwaysShowNavOnTouchDevices': true,\n          'showImageNumberLabel': true,\n        })\n</script>\n</body>\n</html>\n```\n\n\n\n\nI've put in a placeholder image to help you guys see what it looks like currently. I'd to have the thumbnails in rows of five. I've also been having difficulty getting rid of the margins between the thumbnails so help figuring that out would be appreciated as well.\n    ", "Answer": "\r\nhttps://jsfiddle.net/ashus6sy/\n\nThe key thing is ```\nfont-size:0```\n on the containing element. White space takes a non-zero amount of space between each element, thus even with ```\nwidth:20%```\n you wouldn't get exactly 5 objects because of these white spaces.\n\n```\n.imageGrid{\n  margin:0;\n  padding:0;\n  display:block;\n  width:100%;\n  font-size:0;\n}\n```\n\n\nI also set ```\npadding:0```\n and ```\nmargin:0```\n on everything.\n\n```\na```\n has ```\nwidth:20%```\n whereas ```\nimg```\n has ```\nwidth:100%```\n since the image widhth's 100% is relative to the ```\n20%```\n of the ```\na```\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "jQuery: Toggleable path-like navigation with decorations\r\n                \r\nThis is my code:\n\n\r\n\r\n```\n$(\"#one_link\").click(function() {\r\n  $(\"#categories\").toggle();\r\n  $(this).toggleClass(\"active\"); //Active class\r\n  $(this).prepend(\"▶&nbsp;\"); //Should toggle and not insert over and over again\r\n  $(\"#text_three\").hide();\r\n  $(\"#cats_text\").hide();\r\n  $(\"#text_two\").hide();\r\n});\r\n\r\n$(\"#cats_link\").click(function() {\r\n  $(\"#cats_text\").toggle();\r\n  $(this).toggleClass(\"active\"); //Active class\r\n  $(this).prepend(\"▶&nbsp;\"); //Should toggle and not insert over and over again\r\n  $(\"#text_two\").hide();\r\n  $(\"#text_three\").hide();\r\n});\r\n\r\n$(\"#two_link\").click(function() {\r\n  $(\"#text_two\").toggle();\r\n  $(this).toggleClass(\"active\"); //Active class\r\n  $(this).prepend(\"▶&nbsp;\"); //Should toggle and not insert over and over again\r\n  $(\"#categories\").hide();\r\n  $(\"#cats_text\").hide();\r\n  $(\"#text_three\").hide();\r\n});\r\n\r\n$(\"#three_link\").click(function() {\r\n  $(\"#text_three\").toggle();\r\n  $(this).toggleClass(\"active\"); //Active class\r\n  $(this).prepend(\"▶&nbsp;\"); //Should toggle and not insert over and over again\r\n  $(\"#categories\").hide();\r\n  $(\"#cats_text\").hide();\r\n  $(\"#text_two\").hide();\r\n});```\n\r\n```\n* {\r\n  list-style-type: none;\r\n  margin: 0;\r\n  padding: 0;\r\n  font-size: 30px;\r\n  line-height: 100%;\r\n  cursor: default;\r\n  font-family: Arial;\r\n}\r\n\r\nhtml,\r\nbody {\r\n  width: 100vw;\r\n  height: 100vh;\r\n  overflow: hidden;\r\n}\r\n\r\n.content {\r\n  display: flex;\r\n  overflow: hidden;\r\n  width: 100vw;\r\n  height: 100vh;\r\n}\r\n\r\n.column {\r\n  border-right: 1px solid black;\r\n}\r\n\r\n.column_content {\r\n  overflow-y: scroll;\r\n  width: 100%;\r\n  height: 100%;\r\n  padding: 20px;\r\n}\r\n\r\n.column {\r\n  display: none;\r\n}\r\n\r\n.column:first-child {\r\n  display: block;\r\n}\r\n\r\nli:hover {\r\n  cursor: pointer;\r\n}\r\n\r\n.active {\r\n  text-decoration: underline yellow;\r\n}```\n\r\n```\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n\r\n<div class=\"content\">\r\n\r\n  <div class=\"column\">\r\n    <div class=\"column_content\">\r\n      <ul>\r\n        <li id=\"one_link\">One</li>\r\n        <li id=\"two_link\">Two</li>\r\n        <li id=\"three_link\">Three</li>\r\n      </ul>\r\n    </div>\r\n  </div>\r\n\r\n  <div id=\"categories\" class=\"column\">\r\n    <div class=\"column_content\">\r\n      <ul>\r\n        <li id=\"cats_link\">Cats</li>\r\n      </ul>\r\n    </div>\r\n  </div>\r\n\r\n  <div class=\"column\" id=\"cats_text\">\r\n    <div class=\"column_content\">\r\n      <p>The cat (Felis catus) is a domestic species of small carnivorous mammal. It is the only domesticated species in the family Felidae and is often referred to as the domestic cat to distinguish it from the wild members of the family.</p>\r\n    </div>\r\n  </div>\r\n\r\n  <div class=\"column\" id=\"text_two\">\r\n    <div class=\"column_content\">\r\n      <p>2 (two) is a number, numeral, and glyph. It is the natural number following 1 and preceding 3. It is the smallest and only even prime number. Because it forms the basis of a duality, it has religious and spiritual significance in many cultures.</p>\r\n    </div>\r\n  </div>\r\n\r\n  <div class=\"column\" id=\"text_three\">\r\n    <div class=\"column_content\">\r\n      <p>3 (three) is a number, numeral, and glyph. It is the natural number following 2 and preceding 4, and is the smallest odd prime number. It has religious or cultural significance in many societies.</p>\r\n    </div>\r\n  </div>\r\n\r\n</div>```\n\r\n\r\n\r\n\n\nIf you click only »One« and then »Cats«, it looks exactly how it should be. \nBut if you click then for example »Two« or »Three«, then »One« has still a text-decoration. This shouldn't happen, it should also toggle.\nFurthermore, the »▶« should be a part of this marking. It should be inserted at most once before each link.\n\nAh and I will need more categories, so it would be great if it were easily expandable.\n\nCan someone help me?\n\nWould be very happy! :)\n    ", "Answer": "\r\nCan't say that this is perfect, but I made some improvements. \n\nFor starters I cut down on the amount of repetitive Javascript by leveraging HTML attributes like ```\nclass```\n and some ```\ndata-*```\n\n\nSee: https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/data-*\n\nAlso note that I moved your ```\n▶```\n into a pseudo element on the ```\nactive```\n class. \n\nSee: https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-elements \n\n\r\n\r\n```\n$('.tab-opening-button').click(function(){ \r\n  const openId = $(this).attr('data-open');\r\n  const linkParent = $(this).attr('data-parent-link');\r\n  if(!linkParent){\r\n      $('#categories').hide();\r\n  }\r\n  $('.text-panel').hide();\r\n  $(openId).show();\r\n  \r\n  $('.tab-opening-button').not(linkParent).removeClass('active');\r\n  $(this).addClass('active'); \r\n});```\n\r\n```\n* {\r\n  list-style-type: none;\r\n  margin: 0;\r\n  padding: 0;\r\n  font-size: 30px;\r\n  line-height: 100%;\r\n  cursor: default;\r\n  font-family: Arial;\r\n  color: rgb(80, 80, 80);\r\n  box-sizing: border-box;\r\n}\r\n\r\nhtml,\r\nbody {\r\n  width: 100vw;\r\n  height: 100vh;\r\n  overflow: hidden;\r\n}\r\n\r\n.content {\r\n  display: flex;\r\n  overflow: hidden;\r\n  width: 100vw;\r\n  height: 100vh;\r\n}\r\n\r\n.column {\r\n  border-right: 3px solid;\r\n  flex-shrink: 0;\r\n}\r\n\r\n.text-panel {\r\n  flex-shrink: 1;\r\n}\r\n\r\n.column_content {\r\n  overflow-y: auto;\r\n  width: 100%;\r\n  height: 100%;\r\n  padding: 20px;\r\n}\r\n\r\n.column {\r\n  display: none;\r\n}\r\n\r\n.column:first-child {\r\n  display: block;\r\n}\r\n\r\nli:hover {\r\n  cursor: pointer;\r\n}\r\n\r\n.active {\r\n  text-decoration: underline yellow;\r\n}\r\n\r\n.active:before {\r\n  content: \"▶ \"\r\n}```\n\r\n```\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n\r\n<div class=\"content\">\r\n\r\n    <div class=\"column\">\r\n        <div class=\"column_content\">\r\n            <ul>\r\n                <li data-open=\"#categories\" class=\"tab-opening-button\" id=\"one_link\">One</li>\r\n                <li data-open=\"#text_two\" class=\"tab-opening-button\" id=\"two_link\">Two</li>\r\n                <li data-open=\"#text_three\" class=\"tab-opening-button\" id=\"three_link\">Three</li>\r\n            </ul>\r\n        </div>\r\n    </div>\r\n\r\n    <div id=\"categories\" class=\"column\">\r\n        <div class=\"column_content\">\r\n            <ul>\r\n                <li data-open=\"#cats_text\" data-parent-link=\"#one_link\"  class=\"tab-opening-button\" id=\"cats_link\">Cats</li>\r\n            </ul>\r\n        </div>\r\n    </div>\r\n\r\n    <div class=\"column text-panel\" id=\"cats_text\">\r\n        <div class=\"column_content\">\r\n            <p>The cat (Felis catus) is a domestic species of small carnivorous mammal. It is the only domesticated\r\n                species in the family Felidae and is often referred to as the domestic cat to distinguish it from the\r\n                wild members of the family.</p>\r\n        </div>\r\n    </div>\r\n\r\n    <div class=\"column text-panel\" id=\"text_two\">\r\n        <div class=\"column_content\">\r\n            <p>2 (two) is a number, numeral, and glyph. It is the natural number following 1 and preceding 3. It is the\r\n                smallest and only even prime number. Because it forms the basis of a duality, it has religious and\r\n                spiritual significance in many cultures.</p>\r\n        </div>\r\n    </div>\r\n\r\n    <div class=\"column text-panel\" id=\"text_three\">\r\n        <div class=\"column_content\">\r\n            <p>3 (three) is a number, numeral, and glyph. It is the natural number following 2 and preceding 4, and is\r\n                the smallest odd prime number. It has religious or cultural significance in many societies.</p>\r\n        </div>\r\n    </div>\r\n\r\n</div>```\n\r\n\r\n\r\n\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "How to produce (and consume) multiple AARs from one (Android library) Gradle subproject\r\n                \r\nDue to use of Unity-as-a-Library we have an Android library module / Gradle subproject that has a number of AAR (Android archive) files in its \"libs\" directory.\nWe have been using the com.github.kezong:fat-aar Gradle Plugin (https://github.com/kezong/fat-aar-android/) to aggregate all of this into a single AAR result for the module, which works great, but:\n\nThis plugin is no longer maintained\nIt is not compatible with Gradle 8+\n\nSo instead we are looking for a way to:\n\nPublish all of these AARs to a Maven repository as part of the publishing for this module (call this Gradle project \"Child\")\n\nThis seems easy enough...\n\n\nHave one \"parent\" library subproject (call this Gradle project \"Parent\") within the same Gradle root project that depends on the normal AAR output of this subproject plus all of the AARs in (1)\nExpress this dependency such that \"Parent\" uses local artifacts from \"Child\" when building in the same root project, but when \"Parent\" is published to Maven it expresses these dependencies in terms of the appropriate Maven artifacts from (1).\nEnsure that other subprojects using the \"parent\" subproject only need to depend on \"Parent\" project, without mentioning any of the AARs it in turn depends upon\n\nApart from the extra AARs, this is the situation we have today with fat-aar -- and we're trying to reattain it.  Essentially we want the normal subproject vs. remote Maven dependency dualities to be properly handled for the extra AARs in addition to the \"main\" AAR for the project.\nWe've tried various convolutions from https://docs.gradle.org/current/userguide/cross_project_publications.html#sec:simple-sharing-artifacts-between-projects and https://docs.gradle.org/current/userguide/publishing_customization.html#sec:publishing_custom_artifacts_to_maven -- so far to no avail.\nHow can this be achieved?\nIn the very worst case, we could:\n\nPublish the extra AARs from \"Child\"\nManually override/replace Child's POM to include these extra AARs\nManually add dependencies on each of the extra AARs (by direct file reference) to all other subprojects under the same root project\n\nBut (2) would be regrettable and (3) would be an ongoing source of pain.\n    ", "Answer": "", "Knowledge_point": "Duality", "Tag": "算法分析"}
{"Question": "Generating and displaying random platforms in pygame\r\n                \r\nSo this is part of the code for my game, using pygame. I'm trying to generate random platforms (from 3 different options), store them in a list and then blit all platforms in the list to the screen. I am able to generate the platform shapes correctly but other than the first platform i'm unable to position them where i want them.\n\n```\nblue = (0, 255, 255)\nblack = (0, 0, 0)\nred = (255, 0, 0)\n\ni = 0\nc = 0\n\n\nDone = True\nglobalplatpos = pygame.Surface([395, 30])\nglobalplat = globalplatpos.get_rect()\n\nplatform_dimensions = plattop, platleft, platw, plath = 0,0,0,0\n\n\ndef play():\n\n#============GAME SETUP============\n    SIZE = WIDTH, HEIGHT = 800, 600\n    TITLE = \"Duality\"\n    SPEED = 10\n    JUMPHEIGHT = 300\n    JUMPCOUNT = 0\n    JUMPSPEED = 15\n    GRAVITY = 10\n    STANDING = 1\n    JUMPING = 0\n\n    globalplatpos.fill(red)\n    platform = globalplat\n    platform.bottom = HEIGHT\n\n    PLATFORM = []\n    PLATPOS = []\n\n    platstand = True\n\n    screen = pygame.display.set_mode(SIZE)\n    caption = pygame.display.set_caption(TITLE)\n    clock = pygame.time.Clock()\n\n    mainsprite = pygame.image.load(\"images\\mainsprite.png\")\n    mainchar = mainsprite.get_rect()\n    mainchar.left = 177.5\n    mainchar.bottom = 570\n\n    mirrsprite = pygame.image.load(\"images\\mirrsprite.png\")\n    mirrchar = mirrsprite.get_rect()\n    mirrchar.left = mainchar.left + 400\n    mirrchar.bottom = mainchar.bottom\n#============GAME SETUP============\n\n\n\n\n\n\n\n#============PLATFORM GENERATOR============\n    def platform_generator(platform):\n        global globalplat\n        global globalplatpos\n        global platform_dimensions\n\n        globalplat = platform.move(0,-60)\n        globalplatpos.fill(red)\n\n        lastplat = PLATFORM[len(PLATFORM) - 1]\n        platheight = lastplat.top\n\n        leftpos = pygame.Surface([131, 30])\n        leftplat = leftpos.get_rect()\n\n        centrepos = pygame.Surface([100, 30])\n        centreplat = centrepos.get_rect() \n\n        rightpos = pygame.Surface([131, 30]) \n        rightplat = rightpos.get_rect()\n\n        plat_type = random.randrange(0,3)\n\n        if plat_type == 0:\n            globalplat = leftplat\n            globalplatpos = leftpos\n            platform_dimensions = int(globalplat.top + 290), 0, 131, 30\n\n        elif plat_type == 1:\n            globalplat = centreplat\n            globalplatpos = centrepos\n            platform_dimensions = int(globalplat.top + 290), 132, 100, 30\n\n        elif plat_type == 2:\n            globalplat = rightplat\n            globalplatpos = rightpos\n            platform_dimensions = int(globalplat.top + 290), 233, 131, 30\n\n        else:\n            pass\n\n        PLATFORM.append(globalplat)\n        PLATPOS.append(globalplatpos)       \n\n#============PLATFORM GENERATOR============\n\n\n\n\n\n\n\n#============GAME LOOP============    \n    Done = False\n    while not Done:\n        clock.tick(60)\n        fps = clock.get_fps()\n        print(fps)\n        platform = globalplat\n        platpos = globalplatpos\n\n\n\n        mirrchar.left = mainchar.left + 406\n        mirrchar.bottom = mainchar.bottom\n\n        def update():\n            screen = pygame.display.set_mode(SIZE)\n            screen.fill(blue)\n            screen.blit(mainsprite, mainchar)\n            screen.blit(mirrsprite, mirrchar)\n            listpos = 0\n            pos = PLATPOS[listpos]\n            platshape = pygame.Rect(platform_dimensions)\n            platform = pygame.draw.rect(screen, red, platshape, 0)\n            platpos = globalplatpos\n            PLATFORM.append(platform)\n            PLATPOS.append(platpos)\n            for form in PLATFORM:\n                pos = PLATPOS[listpos]\n                listpos += 1\n                screen.blit(pos, form)\n\n            divpos = pygame.Rect(395, 0, 10, HEIGHT)\n            divrect = pygame.draw.rect(screen, black, divpos, 0)\n            pygame.display.update()\n\n\n\n\n        global i\n        if i == 0:\n            globalplat.bottom = HEIGHT\n            i = 1\n            PLATFORM.append(globalplat)\n            PLATPOS.append(globalplatpos)\n            screen.blit(globalplatpos, globalplat)\n\n        elif i == 1 and len(PLATFORM) < 10:\n            platform_generator(platform)\n            plat1 = PLATFORM[0]\n            update()\n\n        elif plat1.top > HEIGHT:\n            plat1 = PLATFORM[0]\n            pos1 = PLATPOS[0]\n            del plat1\n            del pos1\n\n        else:\n            update()\n\n\n\n\n\n        if mainchar.left > 0: #MOVE LEFT\n            if pygame.key.get_pressed()[K_LEFT] or pygame.key.get_pressed()[K_a]:\n                mainchar.left -= SPEED\n        else:\n            mainchar.left = 0\n\n        if mainchar.right < 395: # MOVE RIGHT\n            if pygame.key.get_pressed()[K_RIGHT] or pygame.key.get_pressed()[K_d]:\n                mainchar.right += SPEED\n        else:\n            mainchar.right = 395\n\n\n        jump = pygame.key.get_pressed()[K_SPACE] or pygame.key.get_pressed()[K_UP]\n\n\n        platstand = mainchar.collidelist(PLATFORM)\n        for form in PLATFORM:\n            if mainchar.colliderect(form):\n                STANDING = 1\n                mainchar.bottom = form.top\n\n\n        if JUMPING == 0:\n            if mainchar.collidelist(PLATFORM) > -1:\n                STANDING = 1\n\n\n        if STANDING == 1:\n            if jump:\n                JUMPING = 1\n\n        if JUMPING == 1:\n            if JUMPCOUNT < JUMPHEIGHT/2:\n                mainchar.bottom -= JUMPSPEED\n                mirrchar.bottom -= JUMPSPEED\n                JUMPCOUNT += JUMPSPEED\n            elif JUMPCOUNT > JUMPHEIGHT/2 and JUMPCOUNT < JUMPHEIGHT * 0.75:\n                mainchar.bottom -= JUMPSPEED/2\n                mirrchar.bottom -= JUMPSPEED/2\n                JUMPCOUNT += JUMPSPEED\n            elif JUMPCOUNT > JUMPHEIGHT * 0.75 and JUMPCOUNT < JUMPHEIGHT:\n                mainchar.bottom -= JUMPSPEED/4\n                mirrchar.bottom -= JUMPSPEED/4\n                JUMPCOUNT += JUMPSPEED\n            else:\n                JUMPCOUNT = 0\n                JUMPING = 0\n                STANDING = 0\n                jump = False\n\n        if STANDING == 0:\n            mainchar.bottom += GRAVITY\n            mirrchar.bottom += GRAVITY\n\n\n        def gameover():\n            Done = True\n\n        if mainchar.top > HEIGHT:\n            gameover()\n\n        if pygame.key.get_pressed()[K_ESCAPE]:\n            escape()\n\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT: Done = True\n\n        update()\n#============GAME LOOP============\n```\n\n    ", "Answer": "\r\nI can't run this example but I see one mistake in ```\nblit()```\n\n\nYou use\n\n```\nscreen.blit( position, surface )\n```\n\n\nbut ```\nblit()```\n expects\n\n```\nscreen.blit( surface, position )\n```\n\n\nRead PyGame Documentation: pygame.Surface.blit()\n    ", "Knowledge_point": "Duality", "Tag": "算法分析"}
