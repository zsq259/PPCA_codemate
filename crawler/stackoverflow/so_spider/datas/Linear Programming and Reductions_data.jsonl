{"Question": "Coefficients Reduction in Linear Programming lead to incoherent results\r\n                \r\nI'm a little bit confused about a result that I got after a coefficients reduction on a constraint of  a linear programming problem.\n\nThe problem is:\n\n```\nmaximize z = x1 + x2 + x3 + x4 + x5 + x6\nsubject to: 6*x1 + 3*x2 - 5*x3 + 2*x4 + 7*x5 - 4*x6 <= 15\nwhere:\n      1<=x1<=2 continuos\n      1<=x2<=2 continuos\n      1<=x3<=2 continuos\n      1<=x4<=2 continuos\n      1<=x5<=2 continuos\n      1<=x6<=2 continuos\n```\n\n\nAfter the coefficients reduction the contraints will be:\n\n```\nsubject to: 3*x1 + 3*x2 - 3*x3 + 2*x4 + 3*x5 - 3*x6 <= 8\n```\n\n\nas stated in the Applied Integer Programming book (Der-San Chen - Robert G.Batson - Yu Dang) at page 96 (there is a little error at page 97. The x1 coefficient is 3 not 1).\n\nAfter that I've tried to submit the problem to ampl with and without the coefficients reduction. But I got two different results:\n\n```\n[without coefficients reduction]\nCPLEX 12.6.1.0: optimal integer solution; objective 11.57142857\ndisplay x;\nx1  2\nx2  2\nx3  2\nx4  2\nx5  1.57\nx6  2\n\n[with coefficients reduction]\nCPLEX 12.6.1.0: optimal integer solution; objective 11.33333333\ndisplay x;\nx1  2\nx2  2\nx3  2\nx4  2\nx5  1.33\nx6  2\n```\n\n\nwhy? can the solution be considered correct anyway even if the result for x5 is a little different?\nI've used three different solver (minos, gurobi, cplex) but they output the same results on the problem.\n    ", "Answer": "\r\nIf you are referring to the technique in 4.4.3, then it's clear what's the problem here.\n\n```\nSuppose we are given a constraint of the form\n    a1*y1+ a2*y2 + ... + ai*yi < b\n    where yi = 0 or 1\n```\n\n\nYou are not allowed to use this technique, as your coefficients are continuous ( in [1,2]) and not binary as needed here!\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "Constraint handler implementation\r\n                \r\nConsider that we are solving a mixed integer linear program. We know that constraint handlers with negative checking priorities only have to deal with integral solution. (from documentation, last line of CONSHDLR_CHECKPRIORITY.\nIf we have such a constraint handler, then in the ```\nconscheck```\n callback, we check if any constraint in the constraint handler is violated or not. If a constraint is violated, we return that the solution is infeasible. But, how is this infeasibility resolved? Will ```\nconsenfolp```\n always be called after ```\nconscheck```\n in this case?\nIf SCIP has started branching, then the constraint handler can only be called on the nodes which have integer feasible LP relaxation solutions. If a constraint in the constraint handler is violated in this case, will ```\nconsenfolp```\n be called to resolve the infeasibility in this case?\nAlso, what is the meaning of this boolean parameter - ```\nmisc/allowstrongdualreds```\n? (definition - should strong dual reductions be allowed in propagation and presolving?)\nThanks!\n    ", "Answer": "\r\nThe ```\nconscheck```\n callback does not get called for lp solutions, but rather for heuristic ones (that why it will only determine feasibility but not resolve any infeasibilities).\nThe ```\nconsenfolp```\n callback ALSO checks feasibility (but only for solutions coming from the lp solve) and then attempt to resolve infeasibility, e.g., by branching. I also talk about the difference between checking and enforcing a bit in this talk, around the 25 min mark.\nA strong dual reduction is one that might cut off optimal solutions but leaves at least one optimal solution in the reduced feasible region (symmetry breaking is the obvious example here). In contrast a weak dual reduction might prune feasible solutions but never optimal ones.\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "Approximate a function given pairwise comparison data of entities with N features\r\n                \r\nLet's say I'm looking for an apartment with a roommate, and I want to train/discover a model of preferences that my roommate can use to evaluate if I'll like a potential apartment without needing my input.\nThe dataset has some interval features (rent, bedrooms, etc.) and some nominal/categorical features (has_dishwasher, laundry).\n```\ndata = \"\"\"\nrent,bedrooms,bathrooms,distance_to_work,has_dishwasher,laundry\n3695,3,1,21,no,building\n4200,4,2,27,yes,building\n4500,4,1.5,19,unknown,building\n4200,3,1.5,19,no,building\n3800,3,1,13,no,unit\n4000,3,1,8,no,unknown\n4500,3,2,26,yes,building\n4050,3,1,20,no,unknown\n3800,3,1,13,no,unknown\n\"\"\"\n```\n\nThe preference dataset is generated from pairwise comparisons, such that if there is a path between A and B then A is considered preferable over B. If there is no path between two nodes then they can be treated as ties/incomparable.\n\nI'd like to approximate my preference function for analysis, ideally in a non-black box fashion, so that I can draw conclusions like:\n\n\"I value in unit laundry at approximately $100 (plus/minus $10) rent\"\n\"4 rooms are preferred over 3 rooms all things being equal\"\n\"I prefer in unit laundry > building laundry > unknown\"\n\"Adding an additional bathroom is as preferable as reducing distance_to_work by 2\"\n\"It's important for the distance_to_work to be under 20, but once under 20 additional reductions aren't as important\" (non-linear?)\n\nWhat are some approaches that would be appropriate?\nI've considered:\n\nLinear regression: I would guess that some of the relationships are non-linear like in the last bullet above. Also I'm not sure how this works with categorical features.\nMulti-criteria decision-making methods (MCDM): These often seem to be used in linear programming contexts where as per the above linear relationships seem like they will miss details.\nNeural networks: Would probably determine the preference function, but in a black-box fashion such that analysis is difficult.\nElo systems: Calculating Elo then trying to train some classifier seems doable, but I'm not sure if it's the best approach given that the dataset will be small, and just because node 6 is between 9 and 4 doesn't necessarily mean that its score should be halfway between them, which I believe Elo would tend towards.\nOrdinal regression/ranking learning: Seems like it would be more appropriate.\n\n    ", "Answer": "", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "How to interpret the output of the CPLEX interactive optimizer?\r\n                \r\nI have been using the CPLEX interactive optimizer to solve some linear programming problems. I generate the problem, use the ```\nread```\n command from CPLEX, and then run ```\noptimize```\n. For some problems, CPLEX produces a solution within an hour and I use ```\nwrite <filename> sol```\n to obtain the complete solution. For some problems, however, it seems to get stuck after a point. The output I see looks like this:\n\n```\n       Nodes                                         Cuts/\n   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap\n    .        .        .        .        .        .        .        .        .\n    .        .        .        .        .        .        .        .        .\n    .        .        .        .        .        .        .        .        .\nElapsed time = 816.06 sec. (429933.56 ticks, tree = 8.58 MB, solutions = 13)\n   2884  1809       87.6482 12159      201.6200       80.3540  2100428   60.15%\n   2938  1863      102.4825 11621      201.6200       80.3540  2149201   60.15%\n   3727  2616       93.1194 10858      201.6200       80.3540  2409711   60.15%\n   3743  2632       92.6249 11845      201.6200       80.3540  2437316   60.15%\n   3767  2656       91.7097 12044      201.6200       80.3540  2466252   60.15%\n   3803  2692       91.8088 11972      201.6200       80.3540  2491113   60.15%\n   3805  2694      101.4411 10242      201.6200       80.3540  2497951   60.15%\n   3827  2716       91.7697 12003      201.6200       80.3540  2522926   60.15%\n   3937  2826      102.6357  7167      201.6200       80.3540  2676145   60.15%\n   4175  3056       94.0081  9159      201.6200       83.9275  2783878   58.37%\nElapsed time = 930.33 sec. (472066.00 ticks, tree = 20.04 MB, solutions = 13)\n   4178  3059       88.0621 11735      201.6200       83.9275  2788962   58.37%\n   4190  3071       87.5922 11461      201.6200       83.9275  2809216   58.37%\n   4202  3083       87.7980 11585      201.6200       83.9275  2823899   58.37%\n   4214  3095       87.9296 11733      201.6200       83.9275  2841065   58.37%\n   4215  3096       92.6440 11647      201.6200       83.9275  2844197   58.37%\n   4227  3108       94.0457 12069      201.6200       83.9275  2869047   58.37%\n   4239  3119       93.3760 11843      201.6200       83.9275  2890566   58.37%\n   4251  3131       94.2709 11724      201.6200       83.9275  2916710   58.37%\n   4274  3153       92.6187 11640      201.6200       83.9275  2945659   58.37%\n   4286  3163       91.6257 11632      201.6200       83.9275  2965344   58.37%\nElapsed time = 998.66 sec. (493988.99 ticks, tree = 20.09 MB, solutions = 13)\n   4310  3186       91.8091 10453      201.6200       83.9275  3010401   58.37%\n   4323  3199       96.4584 11813      201.6200       83.9275  3034842   58.37%\n   4335  3211       96.1343 11849      201.6200       83.9275  3057500   58.37%\n   4359  3234       96.8602 11609      201.6200       83.9275  3092422   58.37%\n```\n\n\nIn the beginning, the last column has a higher number (e.g., ```\n99.92%```\n), which starts decreasing quickly. But after a certain point, the last ```\ngap```\n column keeps stating ```\n58.37%```\n without further reduction. What does this value signify? My understanding is that this is the percentage difference between the current optimal solution and the global optimum. (i.e., ```\nx%```\n means that if I stop the optimization at this point, the solution returned is provably within ```\nx%```\n of the global optimum).\n\nIs my understanding correct? Also, what can I do to understand and debug/get-around this phenomenon of \"getting stuck\"?\n    ", "Answer": "\r\nThe % gap is the relative difference between the best solution and the best known bound for a solution.  This is guaranteed to be higher than the gap between the best known solution and the true global optimum.  In your case, the best bound is 83.9275, the best bound is 201.62, and you are minimizing so the gap is \n\n```\n1 - (83.9275 / 201.62)  =  .5837\n```\n\n\nThe \"stuck\" behavior you see is quite common when solving a difficult mixed-integer problem.  It's possible that the solution you have is actually close to optimal, but the bound isn't tight, or that your solution is truly far the optimal, but CPLEX is unable to find anything better.  There are a lot of methods for trying to solve this problem.  Among them are\n\n\nImprove your MIP formulation\nTry different parameters (turn up cuts, probing, switch to strong branching, ...)\nSee if another solver works better on your problem (gurobi or xpressmp)\n\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "how do you create ease in reduction in value in javascript\r\n                \r\nThis more of a math question than programming, but still applicable as i want it to be done javascript.\n\nI am animating stuff and for i need to create reduction that goes from full value to zero per frame. But it should decrease  slowly at first and then increase up the decreasing amount as value gets shorter. And vice versa for ease out.\n\nlinear goes something like this:\n\n```\nspeed -= linear;```\n\n\nothers i don't know and i don't how to classify this one either:\n\n```\nspeed *= .8;```\n\n\n\n\ni guess i am asking for curve that goes from 1 to 0 in square curve fashion but flipped\n    ", "Answer": "\r\nYou could try subtracting your speed by a number that grows exponentially.\n\n```\nvar a = 1;\nspeed -= Math.pow(2, a);\na++;\n```\n\n\nif 2^a is too fast, try a smaller number (greater than 1) or try incrementing the value of \"a\" by a percentage, ie\n\n```\nvar a = 1;\nspeed -= Math.pow(2, a);\na *= 1.1;\n```\n\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "Strange behaviour of HLSL pow() function using DirectX 11\r\n                \r\nI'm programming a DX11 SM5.0 terrain hull shader along the lines of many examples such as Frank Luna's. While investigating the reason for crazy flickering of the (wireframe) terrain, I've homed in on what seems to be a problem with the pow() function.\n\nMy code to calculate tessellation factors is:\n\n```\nfloat CalcTessFactor(float3 p)\n{\n    float d = distance(p, cameraPosition);\n    float s = saturate((d - 1000.0f) / (5000.0f - 1000.0f));\n    //return pow(2, (lerp(6, 1, s)));\n    return saturate((5000.0f - d) / 5000.0f)*64.0f;\n}\n```\n\n\nThe hard-coded numeric constants are part of my debugging reduction.  The commented-out line: \"//return pow(...\" is the original code, which I've replaced by the line that now follows.\n\nWith this replacement the tessellation is completely stable and reduces with distance from the camera.  As expected, the reduction is only linear rather than logarithmic, but at least it works, is nicely tessellated and shows no signs of flicker.\n\nWith the original code, the mesh appeared to be switching at frame rate between apparently random tessellation factors.\n\nCan anyone suggest what might be going wrong?\n\nMy patch constant function is:\n\n```\nstruct HullInputType\n{\n    float3 position : POSITION;\n    float4 color : COLOR;\n};\n\nstruct ConstantOutputType\n{\n    float edges[4] : SV_TessFactor;\n    float inside[2] : SV_InsideTessFactor;\n};\n\nConstantOutputType TerrainPatchConstantFunction(InputPatch<HullInputType, 4> patch, uint patchId : SV_PrimitiveID)\n{\n    ConstantOutputType output;\n\n    // Compute midpoint on edges, and patch center\n    // order of vertices is: 0 1\n    //                       2 3\n    float3 e0 = 0.5f*(patch[0].position + patch[2].position);\n    float3 e1 = 0.5f*(patch[0].position + patch[1].position);\n    float3 e2 = 0.5f*(patch[1].position + patch[3].position);\n    float3 e3 = 0.5f*(patch[2].position + patch[3].position);\n    float3 c = 0.25f*(patch[0].position + patch[1].position + patch[2].position + patch[3].position);\n\n    // Set the tessellation factors for the four edges of the quad.\n    output.edges[0] = CalcTessFactor(e0);\n    output.edges[1] = CalcTessFactor(e1);\n    output.edges[2] = CalcTessFactor(e2);\n    output.edges[3] = CalcTessFactor(e3);\n\n    // Set the tessellation factor for tessallating inside the quad.\n    output.inside[0] = CalcTessFactor(c);\n    output.inside[1] = output.inside[0];\n\n    return output;\n}\n```\n\n    ", "Answer": "\r\nLooking at your return value.  Looks like you are doing your tesselation backwards.  Uncomment the price of code.   Hard code the distance value say to say 1000.  You should get a consistent tesselation.  If you do then you should get no flickering.  If you don't then its something with the power function as you assert or out not then your distance vectors are funky. \n\nEdit: Added my tessellation function for reference.\n\n```\n  struct VertexOut\n{\n    float4 PosW : POSITION0;\n    float4 waterAttributes : POSITION2;\n    float4 direction : POSITION1;\n//    float4 wind : POSITION2;\n    float tessFactor : TESS;\n};\n\n//========================================================================================================================\n\n[domain(\"tri\")]\n[partitioning(\"integer\")]\n[outputtopology(\"triangle_cw\")]\n[outputcontrolpoints(3)]\n[patchconstantfunc(\"PatchHS\")]\nHullOut HSMain(InputPatch<VertexOut, 3> p,\n           uint i : SV_OutputControlPointID,\n           uint patchId : SV_PrimitiveID)\n{\n    HullOut hout;\n\n    // Pass through shader.\n    hout.PosW = p[i].PosW;\n    hout.direction = p[i].direction;\n    hout.waterAttributes = p[i].waterAttributes;\n //   hout.wind = p[i].wind;\n\n    return hout;\n}\n\nPatchTess PatchHS(InputPatch<VertexOut, 3> patch,\n                  uint patchID : SV_PrimitiveID)\n{\n    PatchTess pt;\n\n    // Average tess factors along edges, and pick an edge tess factor for \n    // the interior tessellation.  It is important to do the tess factor\n    // calculation based on the edge properties so that edges shared by \n    // more than one triangle will have the same tessellation factor.  \n    // Otherwise, gaps can appear.\n    pt.EdgeTess[0] = 0.5f * (patch[1].tessFactor + patch[2].tessFactor);\n    pt.EdgeTess[1] = 0.5f * (patch[2].tessFactor + patch[0].tessFactor);\n    pt.EdgeTess[2] = 0.5f * (patch[0].tessFactor + patch[1].tessFactor);\n    pt.InsideTess = pt.EdgeTess[0];\n\n    return pt;\n}\n```\n\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "Efficient way to execute the sequential part(large no of operations + writing file) of a parallel code?\r\n                \r\nI have a C++ code using mpi and is executed in a sequential-parallel-sequential pattern. The above pattern is repeated in a time loop. \nWhile validating the code with the serial code, I could get a reduction in time for the parallel part and in fact the reduction is almost linear with the no of processors.  \n\nThe problem that I am facing is that the time required for the sequential part also increases considerably when using higher no of processors.\n\nThe parallel part takes less time to be executed in comparison with total sequential time of the entire program.  \nTherefore although there is a reduction in time for the parallel part when using higher no of processors, the saving in time is lost considerably due to increase in time while executing the sequential part. Also the sequential part includes a large no of computations at each time step and writing the data to an output file at some specified time.  \nAll the processors are made to run during the execution of sequential part and the data is gathered to the root processor after the parallel computation and only the root processor is allowed to write the file.  \nTherefore can anyone suggest what is the efficient way to calculate the serial part (large no of operations + write the file) of the parallel code ? I would also like to clarify on any of the point if required.\n\nThanks in advance.\n    ", "Answer": "\r\nFirst of all, do file writing from separate thread (or process in MPI terms), so other threads can use your cores for computations. \n\nThen, check why your parallel version is much slower than sequential. Often this means you creates too small tasks so communication between threads (synchronization) eats your performance. Think if tasks can be combined into chunks and complete chunks processed in parallel.\n\nAnd, of course, use any profiler that is good for multithreading environment.\n\n[EDIT]\n\nsequential part = part of your logic that cannot be (and is not) paralleled, do you mean the same? sequential part on multicore can work a bit slower, probably because of OS dispatcher or something like this. It's weird that you see noticable difference. \n\nDisk is sequential by its nature, so writing to disk from many threads don't give any benefits, but can lead to the situation when many threads try to do this simultaneously and waits for each other instead of doing something useful.\n\nBTW, what MPI implementation do you use?\n\nYour problem description is too high-level, provide some pseudo-code or something like this, this can help us to help you. \n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "Programming language suggestion - Dynamic and multidimensional array - cplex or gurobi\r\n                \r\nCurrently I have been using MATLAB to solve the problems that I have been dealing with. In my MATLAB code, I call CPlex or GUROBI solvers to solve large Linear Programming problems. In each call of my MATLAB code, CPlex or GUROBI  is called more than 10^5 times. This causes a high computational load and it takes too much to solve larger problems. However, I want to switch to another programming language which is,\n\n\ncapable of calling one of these (CPlex or GUROBI ),\ncapable of calling one of these solvers (CPlex or GUROBI ) too many times (let's say 10^6 times) and in each call without significant reduction in performance and without any significant increase in run time.\ncapable of using dynamic arrays (namely, when I run my code, It will get some user parameters and it will define matrices of different sizes in each run.)\ncapable of defining multi-dimensional arrays, not array of arrays.\n\n\nAt this point I have found three options\n\n\nFortran: It seems quite OK but I have some concerns whether can it efficiently be able to call solvers too many times. It seems that I can only use Fortran with Cplex. I googled Fortran+GUROBI but results were not encouraging.\nVisual Basic.NET : It seems that calling both Cplex and GUROBI is possible with Visual Basic but I am not sure about the performance.\nPython: Both integrable with CPlex and GUROBI .\n\n\nIn conclusion, I request your suggestions to go forward. My preference is to start with a programming language in which it is possible to use both GUROBI and CPlex.\n    ", "Answer": "\r\nMy recommendation is using Python with \nPyomo. \n\nPyomo (www.pyomo.org) \"... is a Python-based open-source software package that supports a diverse set of optimization capabilities for formulating and analyzing optimization models.\" As such, you can use Python constructs to help build a model. After building the model, you can then run it on gurobi, cplex and many more. And since the solver is just an argument in the solve function, running it in both is just a one word difference. Below is a simple example.\n\n```\n# model.py\nfrom __future__ import division\nfrom pyomo.environ import *\n\nmodel = ConcreteModel()\n\nmodel.x = Var([1,2], domain=NonNegativeReals)\n\nmodel.OBJ = Objective(expr = 2 * model.x[1] + 3 * model.x[2])\n\nmodel.Constraint1 = Constraint(expr=3 * model.x[1] + 4 * model.x[2] >= 1)\n```\n\n\nFrom the command line you could then solve \n\n```\npyomo solve model.py --solver=gurobi\n```\n\n\nor \n\n```\npyomo solve model.py --solver=cplex\n```\n\n\nYou could solve it using a script as well. This sky is the limit and the support group is great.\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "How to know if a problem belongs to NP Class?\r\n                \r\nWhat I know (NOT strictly speaking)\nI know that there is an open question about the equality of P and NP Classes and as long as there is no known algorithm that solves NP problems in P time then we make a distinction about the space-time solvability of such problems.\nAlso, I know that you can make reductions (of polynomial time) between problems, so if you know that a problem belongs to a certain class, then the other problem will also belong to this class.\nAlso, I know that the Simplex algorithm solves problems for linear programming\nWhat I would like to know\nI would like to know how to \"guess\" if a problem belongs to NP Class. Does it have to do with the constraints of the problem, the number of constraints, the \"type\" of constraints?\nAn example\nIn this link https://www.geeksforgeeks.org/maximum-profit-by-buying-and-selling-a-share-at-most-k-times/ we can see an algorithm that solves \"Maximum profit by buying and selling a share at most k times\" with dynamic programming.\nHowever, what if we increase the constraints. Let's say that we are limited to a net worth (we don't have unlimited money) or we can buy and sell more than one stock at a time but we are limited to the amount of stocks we can buy or sell in the given time, or there are multiple stocks of various companies we can choose from but we are limited in the total number of stocks we can have.\nHow can we know what kind of constraints make the problem harder and harder \"moving\" it from P to NP Class ? What kind of constraints should a problem have to be sure that this problem certain belongs either to P or NP Class ?\n    ", "Answer": "\r\nYou can prove NP-Hardness of a problem by reducing a problem known to be NP-Hard to the problem at hand. More correctly, you should first formulate the decision problem version of the optimization at hand. Then, reduce a NP-Complete problem to the decision version. By finding a valid reduction, you can prove your optimization problem is NP-Hard. Check out the idea of reduction on: https://www.wikiwand.com/en/Reduction_(complexity)\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "Complexity of a non-integer K-Commodity Flow without conservation property\r\n                \r\nI'm working on a problem that can be seen as a version of the Santa Claus problem (defined here for example : https://dl.acm.org/citation.cfm?id=1132522) where the goods are divisble instead of indivisible.\n\nFor the indivisible problem, a reduction to the Partitoning problem is possible to classify it as NP-hard (see Golovin 2005 : page 3). However, with divisble goods, I couldn't find much litterature unless i changed the problem to another form.\n\nThe problem can be reduced to the K-commodity problem (an extension of ND38 (from Garey and Johnson) : Directed Two-commodity Integral Flow) with integral flow which is NP-complete, and with non-integral flows it is  poynomially equivalent to Linear Programming (for two or more commodities). \n\nHowever, the edge that I have in my model wouldn't be conservative as the utility of each resources is not the same for each commodities, and thus, a total input flow flow of 1 unit of commodity i into v doesn't means that the output flow is also 1. From Wikipedia it would be defined as preflow because it lacks the \"Flow Conservation\" property, which is essential in the problem also defined on Wikipedia.\n\nIs there a way to prove/explain the complexity class of the K-commodity non-integral flows without the flow conservation property (which my problem can be reduced to) ? \n\n\n\nTo explain a bit more about the problem, i have N employees and M tasks. Each employee i has an efficiency in each task j defined as e_(i,j). The efficiency can be 0 if the employee doesn't know how to do the task. Each employees can work up to H_i hours and can divide his time between the different tasks that he can do. \n\nThe objective here is to maximize to production function of the firm which is a Leontieff production function, which is the last done task (the production is a max-min across the differents tasks). There is no collaboration, so the produced task amount is equal to the contribution of each employee (efficiency multiplies by the number of hours passed on this task). \n\nIf we think of the task as the agents, this problem can be seen as a max-min utility across tasks (agents) of the allocation of divisble goods (worker hours) with differentiated utilities (efficiencies). \n\n\n\nAs I can't use a linear solver insidemy program, i am limited to finding a good greedy or FPTAS algorithm to solve this within an acceptable margin of error.\n\nThank you for reading. I would be grateful if you have any idea or general direction/keywords to guide me in my research.\n    ", "Answer": "", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "Java Program is getting slower over time\r\n                \r\nSo I am actually seeking for suggested list of causes that may cause my java program to get slower overtime.\n\nMy java program keeps reading lines (line by line) from files and then for each line it applies the same set of calculation over it. However the issue as mentioned earlier is that it performance gets slower over time. \n\nNow the drop in performance is not linear meaning that it does not keep slowing down every second. The performance (The speed of reading mainly) drops all at once. After applying a certain function that takes action periodically (Every couple of minutes or so).\n\nNow the first thing that should jump to your mind that this function is doing some of the most obvious actions for performance reduction like\n\n```\n1- Creating large number of objects that stays in memory\n    a) Number of object is minimized\n    b) Each object reference is set to null when not needed to allow the GC (Garbage Collector) to perform well\n    c) I checked on task manager an it shows that memory usage is normal (Because of what I have done)\n    d) I check the heap usage on visalVM also and the usage of the heap was normal and low.\n\n2- I am reading a large number of files, so not closing the files might be the reason\n    a) I made sure that all the opened files are closed after reading them.\n```\n\n\nI tried to figure out if any of the computer resources are enormously consumed over time, however using the task manager and the VisalVM 1.3.8 I couldn't find any.\n\nBesides the fact the GC is behaving normally, where there are no trash in memory that might be affecting the performance and needs to be removed.\n\nSo do you have any suggestion of what cause that issue.\n    ", "Answer": "", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "A way of reduction skyscrapper (latin square with height clues) to SAT\r\n                \r\nI'm trying to implement a reduction from the skyscrapper latin-square problem to SAT.\n\nThe skyscrapper problem is the same of Latin-sqaure but in addition, the skyscraper puzzle asks the player to place buildings of varying & unique heights on a grid so as to satisfy clues given on the grid’s edges. These “edge clues” tell the player how many buildings are visible from the standpoint of a given clue’s placement along the board’s edge. (full explanation)\n\nSo in order to solve this problem using SAT solver, I tried a similar approach of solving a suduko using SAT (which I already did). So first off all I defined n^3 binary variables, X_i,j,k which indicates that in the i,j cell the value k is true (so in the i,j cell we have a skyscrapper with a height of k)\n\nI added the following constarints in the form of a CNF:\n\n\neach cell contains only 1 true var\neach row contains exactly 1 of each value\neach column contains exacly 1 of each value\n\n\nNow I'm having troubles figuring out which constraints should I add for the clues and the heights. \nFirst I thought about the option of adding every possible order for each clue given, for example If from the left I can see 3 skyscrappers ( n = 4) so the possibilities are: \n[[2 ,3 ,4, 1],[1,3,4,2]] but I think it would be O(n!) in total...\n\nI implemnted Suduko solver using ILP so I read about solving this problem usin ILP (integer linear programming). I found this link which describes how to do that. But still I can't find the equivalent for the height constarint they added in the ILP situation that will fit in the SAT solver.\n\nThanks a lot!\n    ", "Answer": "\r\nThere are probably many many approaches, but one that comes to mind can look like the following.\n\nFor each clue ```\nC_i```\n, you introduce new helper variables:\n\n```\n# NV_?_j = position j is not visible (in regards to clue i)\n\nNV_i_1, NV_i_2, ... NV_i_n  \n```\n\n\nA clue than consists in posting the correct cardinality (different approaches; you chose how)\n\n```\nsum(NV_1_?) = clue-hint(C_1)\n```\n\n\nNow the question is how to constrain ```\nNV```\n:\n\n\n```\nNV_i_1 = true```\n is always valid\n```\nNV_i_j = true <-> there exists a HIGHER value EARLIER```\n\n\n\nIt's growing fast, but i recommend the following approach (which should be no problem for those sizes i saw in your linked pages; although SAT is a less natural approach here than CP for example):\n\nFor ```\nN=5```\n, constrained by your all-diff constraint, there are ```\nC(N, 2) = 10```\n symmetry-free unique pairs:\n\n```\n1 2    2 3    3 4    4 5\n1 3    2 4    3 5\n1 4    2 5  \n1 5\n```\n\n\nYou will now use these pairs in regards to:\n\n\npairwise positions (1 - N)\npairwise values (1 - N)\n\n\nAssuming, your decision-variables are that of some tensor of rank 3 (row position, column position, value in unary encoding) with dimensions (N, N, N):\n\n```\nX111 = row = 1 | column = 1 | value = 1\nX112 = row = 1 | column = 1 | value = 2\n...\nX121 = row = 1 | column = 2 | value = 1\n... \n```\n\n\n```\nNV_i_j = true <-> there exists a HIGHER value EARLIER```\n can be expressed as (we assume a clue active on some column here):\n\n```\nNV_i_1 <-> true  # fact\n\n# pairs compared: position 1 2\nNV_i_2 <-> (X115 ^ X124) | (X115 ^ X123) | ...  | (x112 ^ X121)\n\n# pairs compared: position 1 3 + position 2 3\n# 3 compared to 1 and 2 -> existence of HIGHER value EARLIER (2 positions)\nNV_i_3 <-> (X115 ^ X134) | (X115 ^ X133) | ...  | (x112 ^ X131) |\n           (X125 ^ X134) | (X125 ^ X133) | ...  | (x122 ^ X131) \n\n...\n\n# pairs compared: position 1 5 + position 2 5 + position 3 5 + position 4 5 \nNV_i_5 <-> (X115 ^ X154) | (X115 ^ X153) | ...  | (x112 ^ X151) |\n           (X125 ^ X154) | (X125 ^ X153) | ...  | (x122 ^ X151)\n           ...\n           (X145 ^ X154) | (X145 ^ X153) | ...  | (x142 ^ X151)\n```\n\n\nNow there is only one thing left (and i won't show it):\n\n\nconverting these components to cnf\n\n\nyou already did some cardinality-encoding for your all-diff decomposition\n\n\ncan be reused for the cardinality needed for the clues\n\nfor the ```\nNV```\n constraints:\n\n\ni recommend using external tools (sympy, mathematica, ...) instead of doing it manually\ni also recommend outsourcing this into some function which is feeded by something like a sub-matrix of your tensor (tensor where the row or column, where clue is active, is chipped away) + ```\nclue_n```\n\n\n\n\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "sklearn pipeline model predicting same results for all input\r\n                \r\nIn the program, I am scanning a number of brain samples taken in a time series of 40 x 64 x 64 images every 2.5 seconds. The number of 'voxels' (3D pixels) in each image is thus ~ 168,000 ish (40 * 64 * 64), each of which is a 'feature' for an image sample.\n\nI thought of using Recursive Feature Elimination (RFE).  Then follow this up with Principle Component Analysis (PCA) because of the rediculously high n to perform dimensionality reduction. \n\nThere are 9 classes to predict. Thus a multi class classification problem. Starting with RFE:\n\n```\nestimator = SVC(kernel='linear')\nrfe = RFE(estimator,n_features_to_select= 20000, step=0.05)\nrfe = rfe.fit(X_train,y_train)\nX_best = rfe.transform(X_train) \n```\n\n\nNow perform PCA : \n\n```\nX_best = scale(X_best)\n\ndef get_optimal_number_of_components():\n    cov = np.dot(X_best,X_best.transpose())/float(X_best.shape[0])\n    U,s,v = svd(cov)\n    print 'Shape of S = ',s.shape\n\n    S_nn = sum(s)\n\n    for num_components in range(0,s.shape[0]):\n        temp_s = s[0:num_components]\n        S_ii = sum(temp_s)\n        if (1 - S_ii/float(S_nn)) <= 0.01:\n            return num_components\n\n    return s.shape[0]\n\nn_comp = get_optimal_number_of_components()\nprint 'optimal number of components = ', n_comp\n\npca = PCA(n_components = n_comp)\npca = pca.fit(X_best)\nX_pca_reduced = pca.transform(X_best)\n```\n\n\nTrain the reduced component dataset with SVM \n\n```\nsvm = SVC(kernel='linear',C=1,gamma=0.0001)\nsvm = svm.fit(X_pca_reduced,y_train)\n```\n\n\nNow transform the training set to RFE-PCA reduced and make the predictions\n\n```\nX_rfe = rfe.transform(X_test)\nX_pca = pca.transform(X_rfe)\n\npredictions = svm.predict(X_pca) \n\nprint 'predictions = ',predictions\nprint 'actual = ',y_test\n```\n\n\nBut I always get the same values for prediction for every sample!\n\n```\npredictions =  [2 2 2 2 2 2 2 2 2 2 2 2 2] #Why is it the same?!!\nactual = actual =  [[0]\n [0]\n [6]\n [8]\n [4]\n [5]\n [0]\n [6]\n [2]\n [3]\n [0]\n [5]\n [6]]\n```\n\n\nI made sure to use linear kernel. I also considered modifying C,gamma with values like (1,0.001) (1,0.0001) (10, 0.001), (10, 0.0001) ... but I get the same output.\n\nIs there something I'm missing here? \n\nEDIT 1\n\nI executed \n\n```\nprint svm.decision_function(X_pca)\n```\n\n\nand the output was :\n\n```\n[[ -4.79479982e+02  -8.01563453e+02  -9.91453849e+02  -1.34641884e+02\n   -1.02315530e+03  -2.88297991e+02  -8.41843812e+02   4.79807826e+02\n   -3.50485820e+02  -2.31081776e+02  -1.42555136e+02  -4.79034448e+02\n   -6.93029988e+01  -7.34288793e+02  -5.49271317e+01   1.98108304e+02\n    4.80257991e+02   2.46835670e+02   2.90045437e+02   1.53261114e+02\n    9.15742824e+02  -1.28387833e+01  -3.05045240e+02  -2.19268988e+01\n   -2.24896384e+02   1.44501465e+02  -9.17438352e+01  -6.96148972e+01\n   -1.15785658e+02   9.53878230e+01   1.79823987e+01   8.05242433e+01\n    8.33917960e+02  -1.69686889e+01   9.85949158e+01   2.68935397e+02]\n [ -4.62804973e+02  -8.26454112e+02  -9.83214857e+02  -1.43367127e+02\n   -1.03538041e+03  -2.86397664e+02  -8.47539241e+02   4.63709033e+02\n   -3.52018380e+02  -2.49936725e+02  -1.43734219e+02  -4.79498907e+02\n   -6.93338619e+01  -7.51141272e+02  -5.30999658e+01   1.95687050e+02\n    4.69206888e+02   2.46530774e+02   2.92047409e+02   1.47934614e+02\n    9.27901865e+02  -1.21801344e+01  -2.99530129e+02  -2.03238750e+01\n   -2.26862390e+02   1.47692745e+02  -8.81396485e+01  -6.41692405e+01\n   -1.14247569e+02   1.01567350e+02   1.87874038e+01   6.90549126e+01\n    8.41984280e+02  -2.04488188e+01   1.00839951e+02   2.75459577e+02]\n [ -4.49255185e+02  -7.89243063e+02  -9.78820180e+02  -1.29050171e+02\n   -1.01784356e+03  -3.23431625e+02  -7.98795796e+02   4.93058279e+02\n   -3.64674793e+02  -2.46545700e+02  -1.66933546e+02  -4.84571326e+02\n   -9.93316258e+01  -7.36182373e+02  -6.23110881e+01   2.08061873e+02\n    4.28119725e+02   2.75927668e+02   2.36425246e+02   1.69950273e+02\n    9.50488041e+02  -3.17986619e+01  -3.03656967e+02  -4.78710028e+01\n   -2.20752797e+02   1.36973850e+02  -5.31583763e+01  -1.08205173e+02\n   -7.94698530e+01   1.37320498e+02  -2.31183352e+01   8.41399154e+01\n    8.26408412e+02   1.30471236e+01   1.48266050e+02   2.55914495e+02]\n [ -4.80424764e+02  -8.07660826e+02  -9.91911478e+02  -1.35981428e+02\n   -1.02923114e+03  -2.93372818e+02  -8.47420541e+02   4.60149182e+02\n   -3.48333176e+02  -2.37654055e+02  -1.39277819e+02  -4.78486235e+02\n   -6.83571401e+01  -7.34632739e+02  -5.73953318e+01   1.95508198e+02\n    4.80569807e+02   2.37500896e+02   2.89038289e+02   1.49855773e+02\n    9.09217973e+02  -1.04236971e+01  -3.02128880e+02  -2.16485093e+01\n   -2.23313869e+02   1.43686084e+02  -9.74071814e+01  -7.22417410e+01\n   -1.19091495e+02   8.94390723e+01   1.97000084e+01   8.08496457e+01\n    8.39105553e+02  -1.82282013e+01   9.82685256e+01   2.67791421e+02]\n [ -4.74406707e+02  -8.18308535e+02  -9.76126419e+02  -1.74849565e+02\n   -1.02784293e+03  -2.96842934e+02  -8.42749406e+02   4.83769137e+02\n   -3.59483221e+02  -2.24264385e+02  -1.61995143e+02  -4.78030614e+02\n   -8.02309023e+01  -7.54316452e+02  -5.43436450e+01   2.05876768e+02\n    4.33470519e+02   2.67598191e+02   2.75764466e+02   1.53323191e+02\n    9.45967383e+02  -2.93192233e+01  -3.04615693e+02  -3.20731950e+01\n   -2.42783848e+02   1.40891844e+02  -6.13739832e+01  -6.15060481e+01\n   -9.51924850e+01   1.35666499e+02   2.41364468e+00   6.39635318e+01\n    8.37881867e+02  -1.03313421e+01   1.19234038e+02   2.76305651e+02]\n [ -4.84321668e+02  -8.07444080e+02  -1.01507160e+03  -1.28529685e+02\n   -1.05601843e+03  -2.99493242e+02  -8.41745493e+02   4.75608122e+02\n   -3.37295601e+02  -2.49242183e+02  -1.30463265e+02  -4.74284269e+02\n   -6.05670230e+01  -7.34447396e+02  -4.01117838e+01   1.80948824e+02\n    4.80450158e+02   2.19859113e+02   2.94798893e+02   1.35958067e+02\n    9.13259527e+02  -3.52105914e-01  -2.92301811e+02  -1.24432589e+01\n   -2.13204265e+02   1.64167920e+02  -1.02951065e+02  -7.04800774e+01\n   -1.31293866e+02   9.12032854e+01   2.67291593e+01   7.78485633e+01\n    8.74745197e+02  -2.50250734e+01   9.69993408e+01   2.83018293e+02]\n [ -4.68184798e+02  -7.85221871e+02  -9.98980941e+02  -1.08799100e+02\n   -1.02080996e+03  -2.87470373e+02  -8.29552725e+02   4.99360929e+02\n   -3.31724034e+02  -2.56603688e+02  -1.24320652e+02  -4.60348857e+02\n   -6.21852802e+01  -7.31782526e+02  -2.56669989e+01   1.74050279e+02\n    4.74370392e+02   2.26812613e+02   2.78945379e+02   1.29667612e+02\n    9.21512986e+02   3.74936721e+00  -2.77509203e+02  -1.34603952e+01\n   -2.12032693e+02   1.72842580e+02  -9.71967056e+01  -8.19354011e+01\n   -1.32985460e+02   9.55148610e+01   1.66381043e+01   5.88073445e+01\n    8.62770538e+02  -2.37682031e+01   1.06714435e+02   2.94158166e+02]\n [ -4.63681347e+02  -8.22291452e+02  -9.98021515e+02  -1.54810425e+02\n   -1.03372001e+03  -3.34322759e+02  -8.34407336e+02   4.71050572e+02\n   -3.69327864e+02  -2.40580250e+02  -1.65003310e+02  -4.88818830e+02\n   -9.73775374e+01  -7.51246204e+02  -6.69606962e+01   2.13573607e+02\n    4.49817824e+02   2.79532473e+02   2.41873397e+02   1.69963589e+02\n    9.53153717e+02  -2.88140674e+01  -3.13030733e+02  -4.54555034e+01\n   -2.32589565e+02   1.36869994e+02  -6.33773098e+01  -1.06164181e+02\n   -8.91557438e+01   1.24881490e+02  -1.94528381e+01   7.98035685e+01\n    8.22835959e+02   8.75642083e+00   1.43002335e+02   2.61562868e+02]\n [ -4.77620825e+02  -8.40698094e+02  -1.01067455e+03  -1.56851274e+02\n   -1.05031578e+03  -3.14666532e+02  -8.46541414e+02   4.61714738e+02\n   -3.60822150e+02  -2.44485564e+02  -1.53420660e+02  -4.85710648e+02\n   -7.77752216e+01  -7.55747678e+02  -5.87745617e+01   2.04601581e+02\n    4.68781099e+02   2.63234873e+02   2.86306284e+02   1.58817281e+02\n    9.43249321e+02  -1.87631625e+01  -3.06321663e+02  -2.78828679e+01\n   -2.27554363e+02   1.46508283e+02  -7.88844807e+01  -7.41051812e+01\n   -1.05094485e+02   1.12231546e+02   7.97692231e+00   7.67304852e+01\n    8.43518403e+02  -1.12844915e+01   1.13370158e+02   2.70797472e+02]\n [ -4.91420429e+02  -7.90722180e+02  -1.05615447e+03  -1.20351520e+02\n   -1.04098604e+03  -2.92426682e+02  -8.45105853e+02   4.78228854e+02\n   -3.10412377e+02  -2.77543578e+02  -1.09733119e+02  -4.40834428e+02\n   -4.35168704e+01  -7.29088994e+02  -6.64581241e+00   1.48560861e+02\n    4.74565890e+02   2.07485677e+02   2.99817382e+02   1.09936148e+02\n    9.03346951e+02   2.26102442e+01  -2.45854761e+02   8.31279855e+00\n   -1.92441568e+02   2.03079787e+02  -1.05267244e+02  -6.41835912e+01\n   -1.49582656e+02   8.73008441e+01   3.36913246e+01   5.11061286e+01\n    8.79159912e+02  -3.85152954e+01   9.08938445e+01   3.04037825e+02]\n [ -4.85998114e+02  -7.83944995e+02  -9.68132304e+02  -1.54631678e+02\n   -1.01186983e+03  -2.80419560e+02  -8.72211797e+02   4.97352635e+02\n   -3.56256101e+02  -2.23204297e+02  -1.55355470e+02  -4.80882457e+02\n   -7.86287112e+01  -7.58318471e+02  -5.10727433e+01   2.08265151e+02\n    4.49457388e+02   2.65764723e+02   2.72435473e+02   1.53296624e+02\n    9.44654406e+02  -2.50922419e+01  -3.17539501e+02  -3.16241295e+01\n   -2.51387679e+02   1.38109115e+02  -6.97122491e+01  -6.59836763e+01\n   -1.03441764e+02   1.19472073e+02   3.60256872e+00   6.22040523e+01\n    8.19929661e+02  -1.26581261e+01   1.12555974e+02   2.80480600e+02]\n [ -4.70876215e+02  -7.87431621e+02  -9.96007256e+02  -1.30872700e+02\n   -1.03175439e+03  -2.94238915e+02  -8.36753617e+02   4.77420371e+02\n   -3.38091939e+02  -2.44272006e+02  -1.35130348e+02  -4.72973924e+02\n   -6.19636207e+01  -7.37123284e+02  -4.28620473e+01   1.80929974e+02\n    4.67912162e+02   2.22731582e+02   2.93578369e+02   1.34101279e+02\n    9.04139841e+02  -3.91744880e+00  -2.88182153e+02  -1.22493089e+01\n   -2.15621705e+02   1.59580065e+02  -9.57584381e+01  -6.41773592e+01\n   -1.28168370e+02   9.42107498e+01   2.61332125e+01   7.00130475e+01\n    8.58092989e+02  -2.62818439e+01   9.40455319e+01   2.82505159e+02]\n [ -4.70908104e+02  -8.29375323e+02  -9.93882131e+02  -1.47050049e+02\n   -1.03443155e+03  -3.28570789e+02  -8.31014742e+02   4.92865993e+02\n   -3.70050739e+02  -2.35488125e+02  -1.63833070e+02  -4.86930191e+02\n   -9.74429858e+01  -7.48852374e+02  -6.17719584e+01   2.13942179e+02\n    4.52542022e+02   2.83202323e+02   2.43990105e+02   1.72094231e+02\n    9.65225890e+02  -2.92801036e+01  -3.13220814e+02  -4.60705452e+01\n   -2.32787033e+02   1.38783264e+02  -6.23061347e+01  -1.05977672e+02\n   -8.75333469e+01   1.31424380e+02  -1.99414766e+01   7.97712157e+01\n    8.30620576e+02   9.19139268e+00   1.44727040e+02   2.65196706e+02]]\n```\n\n\nSo, the values differ (though slightly) for every sample. I assume the model is doing something. I just dont know whats wrong.\n    ", "Answer": "\r\nIf class 2 is far more likely to occur than any of the other classes and the features are not informative enough to make strong distinctions between classes, then the model will always predict class 2.  Instead use\n    svm.decision_function(X_pca)\nto see the scores for each sample for each class.  If these are all the same, then something is wrong.  You could also look at\n    svm.coef_\nIf all the coefficients are 0, then the model isn't doing anything.  \n\nAnd you didn't scale X_test.\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "parallel algorithm for generalized nonsymmetric eigenproblems\r\n                \r\nI need to efficiently solve large nonsymmetric generalized eigenvalue/eigenvector problems.\nA x = lambda B x\nA, B - general real matrices\nA - dense\nB - mostly sparse\nx - the eigenvector\nlambda - the eigenvalue\nCould someone help me by:\n\nInforming me if the nonsymmetric generalized eigenvalue/eigenvector problems is known to be parallelized. (What are some good algorithms and libraries implementing them if any);\nTelling me if scalapack is an alternative to dense nonsymmetric eigenproblems;\nSuggesting some good computational alternatives to test the use of both sparse matrices and linear-algebra algorithms;\nSuggesting an alternative linear algebra construction that I could use (if there are no simple routines call, perhaps there is a good solution that is not so simple).\n\nI tested code efficiency using matlab, python and C programming. Matlab is said to have builtin lapack functionality. I used intel provided python, with scipy and numpy linking to intel MKL lapack and blas libraries. I also used C code linking to intel MKL lapack and blas libraries.\nI was able to check that for non-generalized eigenvalue problems, the code ran in parallel. I had as many threads as physical cores in my machine. That told me that LAPACK uses parallel code in certain routines. (Either LAPACK itself or the optimized versions shipped within matlab and intel MKL oneapi libraries.\nWhen I started to run generalized eigenvalue routines, I observed that the code ran with only one thread. I tested in matlab and python as distributed by intel.\nI'd like to investigate this further, but first I need to know if it's possible even in theory to run generalized nonsymmetric eigen decompositions in parallel.\nI've seen that scipy have routines for the reduction of a pair of general matrices to a pair of hessenberg/upper triagular matrices. It seems that from hessenberg form, that eigenvalue/eigenvector problems are computationally easier.\nHessenberg for a single matrix runs in parallel. But hessenberg for a pair of matrices, runs only in sequence with one thread. (tested in python scipy). And again, I hit a wall. Which raises the question: is this problem parallelizable?\nOther source of optimization for the problem I have is that I have one of the matrices dense and the other is mostly sparse. I'm still not sure how to exploit this. Are there good implementations of sparse matrices and state of the art linear algebra algorithms that work well together?\nThank you very much for any help supplied! Including books and scientific papers.\n    ", "Answer": "\r\n                \r\nFor MKL-provided routines, you can run it in either parallel mode by using /Qmkl compiler option (Intel compilers) or in sequential mode using /Qmkl:sequential option. For more details, you can refer to the MKL developer reference manual for more details https://www.intel.com/content/www/us/en/develop/documentation/onemkl-linux-developer-guide/top/linking-your-application-with-onemkl.html regarding linking options\nHere is the link which shows the MKL routines that use sparse matrices  https://www.intel.com/content/www/us/en/develop/documentation/onemkl-developer-reference-c/top/sparse-solver-routines.html\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "Non-exhaustive worst-case NP-complete solving algorithm\r\n                \r\nDisclamer:\nFirst of all, I know that not all NP-complete problems have a large 'search space' where they have to look for a solution, but a large amount of the best-known ones do, so I will make this assumption since this is a question about (known) algorithms and not about complexity theory. So it might probably apply more to discrete optimization problems, but I wont restrict it to them.\n\nContext: Most the algorithms for solving this type of NP-complete problems that I know usually have a way of tossing out possible solutions in the search space while the algorithm is running (think of branch-and-bound here for example). However, while in the average and best cases this always yields reductions that are more or less efficient, in all examples I could think of, there is a way of constructing a worst-case problem where you have to go through all points in your search space. So much so, that a colleague of mine suggests this is a fundamental property of NP-complete problems at least (of course, if P = NP then this whole discussion is trivial). \n\nThe Problem: I believe that there has to be an example of an NP-complete problem and an algorithm for solving it, where you can always find reductions of the search space, even in the worst case once you are running the algorithm, even though this might only get you a constant (or more generally polynomial) decrease in the worst case runtime compared to an exhaustive search algorithm. Of course I can think of trivial examples where you synthetically expand the search space, but there you could reduce it a priori, so I am looking for a real algorithm for a real problem, which means you can usually only reduce the space during the execution of the algorithm.\n\nExample: I'll illustrate this all with an example. Mixed-integer linear-programming is known to be NP-hard. However, a lot of research for the simplex algorithm which is used on relaxations in a branch-and-bound usually lets you discard large portions of the search space. A very simple example of this is:\n\n```\nmax x_1 + ... x_n\nw.r.t.\n0 <= x_1 <= x_2 <= x_n <= N*Pi\nx_2,x_4,x_6,..., x_(floor(n/2)*2) integers\n```\n\n\nHere it is pretty obvious that you always want the largest x_i possible, so you can leave out the rest. From the initial relaxation you would choose the largest x_n possible and leave all the rest out. However, you can think of examples where it does not:\n\n```\nmax v_1 * x_1 + ... + v_n * x_n\nw.r.t.\n0 <= x_1,x_2, ..., x_n <= 1\nw_1 * x_1 + ... + w_n * x_n <= W\nx_1, ..., x_n integers\n```\n\n\nwhich is a 0-1 knapsack problem. Depending on the weights, values and the order of the branch and bound, you could have to test every single combination of x_i's to find the maximum.\n    ", "Answer": "\r\nI’m not sure that “non-exhaustive” has a nice definition. I’ll try to answer anyway.\n\nTake the problem of finding a maximum clique. We can parameterize the search space by a Boolean vector indicating whether each vertex belongs to the clique, making 2n possibilities, none excludable a priori, but every n-vertex graph has at most 3n/3 ≤ 1.5n maximal cliques, and even a fairly simple algorithm like Bron–Kerbosch achieves this bound up to polynomial factors. (The Wikipedia article describes subsequent improvements in the exponential base.)\n\nAnother example is Hamiltonian path. There are n! different solutions in a complete graph, none excludable a priori, but there exists a dynamic program to find one that has running time 2n poly(n).\n\nOn the other hand, the Strong Exponential Time Hypothesis is that we can’t do much better than 2n for n-variable satisfiability, which rules out a known algorithm with a better worst-case running time. In practice, the heuristics are so good that we use satisfiability as a reduction target for, e.g., checking the validity of combinatorial circuits. As far as I’m concerned, “NP-hard means that exhaustive search is as good as it gets” is a harmful oversimplification.\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "what is the difference between keras.MeanSquaredError and reduce_sum(square(diff))?\r\n                \r\nI've been trying to figure this out now for a couple hours. The simple solution to make the program below work is to just use keras.MSE, but I want to understand why my version doesn't work more than I want this program to work.\nIt seems to me the mean of the square of the difference aught to be really close to the keras.MSE. I expect differences, but mine seems to start close and just get worse and worse and I can't figure out why.\n```\nstep=0 theirs= 13.1761 mine= 14.0251\nstep=5 theirs= 10.3337 mine= 11.8363\n…\nstep=90 theirs=  0.0361 mine=  6.9888\nstep=95 theirs=  0.0332 mine=  6.9604\n```\n\nI've been source diving all through keras and tensorflow. I got down to keras/losses.py ```\nbackend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)```\n and that seems really similar to me. Although, I admit the code in tf.math.squared_difference makes little sense to me, it works out roughly the same as ```\ntf.square(y_true-y_pred)```\n in ipython.\nI'm definitely missing something.\nHere's my tiny program:\n```\nimport tensorflow as tf\nimport numpy as np\n\ndef small_ds():\n    in_t = tf.cast(np.random.randint(5, size=(24, 2)), tf.float32)\n    out_t = tf.reduce_sum(in_t, axis=-1)\n    return in_t, out_t\n\ndef small_model():\n    i = tf.keras.layers.Input(shape=(2,))\n    d = i\n    d = tf.keras.layers.Dense(32, activation=\"LeakyReLU\")(d)\n    d = tf.keras.layers.Dense(32, activation=\"LeakyReLU\")(d)\n    d = tf.keras.layers.Dense(32, activation=\"LeakyReLU\")(d)\n    o = tf.keras.layers.Dense(1, activation=\"LeakyReLU\")(d)\n    m = tf.keras.Model(inputs=i, outputs=o)\n    return m\n\ndef what_is_happening_here():\n    opt = tf.keras.optimizers.Adam()\n    tf_mse = tf.keras.losses.MeanSquaredError()\n\n    @tf.function\n    def my_mse(y_true, y_pred):\n        return tf.reduce_mean(tf.square(y_true-y_pred))\n\n    m = small_model()\n\n    @tf.function\n    def train_step(x_input, y_true):\n        with tf.GradientTape() as tape:\n            y_pred = m(x_input, training=True)\n            theirs = tf_mse(y_true, y_pred)\n            mine   = my_mse(y_true, y_pred)\n        grad = tape.gradient(theirs, m.trainable_variables)\n        opt.apply_gradients(zip(grad, m.trainable_variables))\n        return theirs, mine\n\n    x_input, y_true = small_ds()\n    for step in range(100):\n        theirs, mine = train_step(x_input, y_true)\n        if (step % 5) == 0:\n            print(f'step={step} theirs={theirs:8.4f} mine={mine:8.4f}')\n\nif __name__ == '__main__':\n    what_is_happening_here()\n```\n\nedit:\nI was initially convinced by the first answer, but I don't think it's quite right. If I generate some completely random vectors and run through mine vs theirs with and without reductions, everything is identical. This version of ```\nmy_mse```\n is slightly difference than the above, but the strange non-linear differences show up as before if I run the modified version through the training loop above.\nI think the optimizer or the graph is doing something else that I can't see.\nI realize this is a trivial problem in the grand scheme of things, but I'd like to be able to write my own loss functions at some point, and I really don't trust them to work the same as the native ones.\nI've also tried wrapping my loss functions in the ```\ntf.keras.losses.Loss```\n class, but everything turns out the same (ie, it doesn't work).\n```\nIn [22]: tf_mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n    ...: my_mse = lambda x,y: tf.reduce_mean(tf.square(x-y), axis=-1)\n    ...:\n    ...: tf_mser = tf.keras.losses.MeanSquaredError()\n    ...: my_mser = lambda x,y: tf.reduce_mean(my_mse(x,y))\n    ...:\n    ...: y_true = tf.cast(np.random.randint(10, size=(6,1)), tf.float32)\n    ...: y_pred = tf.cast(np.random.randint(10, size=(6,1)), tf.float32)\n    ...:\n    ...: i = tf.keras.layers.Input(shape=(1,))\n    ...: o = tf.keras.layers.Dense(32)(i)\n    ...: m = tf.keras.Model(inputs=i, outputs=o)\n    ...:\n    ...: m_pred = m(y_pred)\n    ...:\n    ...: for a,b in [(tf_mse, tf_mser), (my_mse, my_mser)]:\n    ...:     print(f'{a(y_true, y_pred).numpy()} -> {b(y_true, y_pred)}')\n    ...:\n    ...: for a,b in [(tf_mse, tf_mser), (my_mse, my_mser)]:\n    ...:     print(f'{a(y_true, m_pred).numpy()} -> {b(y_true, m_pred)}')\n[ 9.  4.  4.  9. 16.  4.] -> 7.666666507720947\n[ 9.  4.  4.  9. 16.  4.] -> 7.666666507720947\n[20.47 30.15 19.62  9.   12.8  19.62] -> 18.608726501464844\n[20.47 30.15 19.62  9.   12.8  19.62] -> 18.608726501464844\n```\n\nedit2:\nok, I get it. I get it. If I change the small_ds above to do this, everything works fine:\n```\ndef small_ds():\n    in_t = tf.cast(np.random.randint(5, size=(24, 2)), tf.float32)\n    out_t = tf.expand_dims(tf.reduce_sum(in_t, axis=-1), -1)\n    return in_t, out_t\n```\n\nI think the secret to figuring this out was still in the first answer, though it wasn't clear to me exactly... The first mean in the real MSE work on channel -1, so if your shape is (24,), it's always going to reduce it -- regardless of the reduction setting.\nBy adding the expand_dims, my poor man's recreation of mse works just like the native one.\n    ", "Answer": "\r\nAccording to the docs, the ```\nMeanSquaredError```\n loss function has the parameter ```\nreduction```\n, which is set to ```\nlosses_utils.ReductionV2.AUTO```\n by default. Now this means that:\n\nthe reduction option will be determined by the usage context. For almost all cases this defaults to SUM_OVER_BATCH_SIZE.\n\nSo I think it depends on which reduction method you are using and your batch size. Try changing your ```\nsmall_ds()```\n method like this:\n```\ndef small_ds():\n  in_t = tf.cast(np.random.randint(5, size=(1, 2)), tf.float32)\n  out_t = tf.reduce_sum(in_t, axis=-1)\n  return in_t, out_t\n```\n\nYou will notice that your results are identical for the batch size 1:\n```\nInput shape:  (1, 2)\nstep=0 theirs= 30.9056 mine= 30.9056\nstep=5 theirs= 21.4109 mine= 21.4109\nstep=10 theirs= 13.2141 mine= 13.2141\n....\nstep=75 theirs=  0.0004 mine=  0.0004\nstep=80 theirs=  0.0055 mine=  0.0055\nstep=85 theirs=  0.0054 mine=  0.0054\nstep=90 theirs=  0.0015 mine=  0.0015\nstep=95 theirs=  0.0000 mine=  0.0000\n```\n\nExample with ```\nreduction='none'```\n:\n```\ny_true = tf.constant([[0., 2.], [0., 0.]])\ny_pred = tf.constant([[3., 1.], [2., 5.]])\n\ntf_mse = tf.keras.losses.MeanSquaredError(reduction='none')\nprint(tf_mse(y_true, y_pred).numpy())\n\nmy_mse = tf.reduce_mean(tf.square(y_true-y_pred))\nprint(my_mse)\n'''\n[ 5.  14.5]\ntf.Tensor(9.75, shape=(), dtype=float32)\n'''\n```\n\nAnd with ```\ntf.reduce_mean```\n:\n```\ny_true = tf.constant([[0., 2.], [0., 0.]])\ny_pred = tf.constant([[3., 1.], [2., 5.]])\n\ntf_mse = tf.keras.losses.MeanSquaredError(reduction='none')\nprint(tf.reduce_mean(tf_mse(y_true, y_pred).numpy()))\n\nmy_mse = tf.reduce_mean(tf.square(y_true-y_pred))\nprint(my_mse)\n'''\ntf.Tensor(9.75, shape=(), dtype=float32)\ntf.Tensor(9.75, shape=(), dtype=float32)\n'''\n```\n\nAnd with ```\nreduction='sum'```\n:\n```\ny_true = tf.constant([[0., 2.], [0., 0.]])\ny_pred = tf.constant([[3., 1.], [2., 5.]])\n\ntf_mse = tf.keras.losses.MeanSquaredError(reduction='sum')\nprint(tf_mse(y_true, y_pred).numpy())\n\nmy_mse = tf.reduce_mean(tf.square(y_true-y_pred))\nprint(my_mse)\n'''\n19.5\ntf.Tensor(9.75, shape=(), dtype=float32)\n'''\n```\n\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "Adding/cumulating \"line chart components\"\r\n                \r\nI can imagine that there is some algorithmic problem which exactly describes my problem but I could not find any. What I basically want to do is:\n\nLet's say, I have some data structure with an object of type Line which contains two (or more, but in my case two is enough) objects of type Point(x, y).\n\nA Line represents a line in a line chart from one point A(x, y) to another point B(x, y).\n\nNow I have a list of such lines. Note, that they may also overlap in their x-coordinates. For example I have a line from (0, 0) to (3, 1) and another line from (2, 0) to (3, 2). I now want to \"cumulate\" this list of lines and have a list of points as a result (to draw a line chart later).\n\nFor the above example that would mean that I want {(0, 0); (2, 0,67); (3, 2)}. Here is a beautiful image which hopefully makes my issue more clear:\n\n\n\nBackground: I am programming a blood alcohol content level calculator. I have several drinks with attributes like: volume, percent, start time, end time.\n\nI want to assume a linear rise of the blood alcohol content level from the start time to the end time minus the alcohol reduction during that time period. In my thoughts, it would be now easy to calculate the single \"lines\" of each drinks, but to get a full line chart representing your blood alcohol content level over the whole time, I would now have to \"add\"/\"cumulate\" all those \"lines\" together.\n\nAt least that were my thoughts and this would be my approach, if you have different approaches/suggestions, please let me know as well.\n    ", "Answer": "\r\nMain idea of the algorithm:\n\n\nSplit the x axis into intervals.\nThe points defining the intervals correspond to the 'x' attribute of each point of each line.\n\n\n\n\n\nSummation of the lines contained in the intervals.\nNow we generate a new line per interval. This line will be the summation of the lines contained in that interval.\nIn order to be able to sum two lines, we transform both lines into functions (Slope y-intercept form), we perform the sum and we create a new line.\n\n\nThe slope intercept form for the equation of any straight line is given by:\n\n```\ny = mx + b\n```\n\n\nwhere: \n\n\nm is the slope of the line\nb is the y-intercept of the line\n\n\nThe slope m of the line through any two points ```\n(x1, y1)```\n and ```\n(x2, y2)```\n is given by:\n\n\n\nThe y-intercept b of the line is the value of y at the point where the line crosses the y axis. Since for point ```\n(x1, y1)```\n we have ```\ny1 = mx1 + b```\n, the y-intercept b can be calculated by:\n\n```\nb = y1 - mx1\n```\n\n\nThe 'x' values of the points of the new line will be the limits of the interval, the 'y' values will be the result of applying the function to the 'x' value.\n\nThe code: (Note: Getters/setters are ommited)\n\nLineFunction:\n\n```\npublic class LineFunction {\n\n    private final double m, b;\n\n    public LineFunction(Line l) {\n        /**\n         * y= ((y_b-y_a)/(x_b-x_a))*(x-x_a) + y_a\n         * \n         * ((y_b-y_a)/(x_b-x_a))==> m\n         * \n         * y = m *(x-x_a)+y_a\n         * \n         * y= m*x -m*x_a +y_a\n         * \n         * -m*x_a +y_a -> b\n         * \n         * y = m*x + b\n         */\n        double y_a, y_b, x_a, x_b;\n        x_a = l.getP1().getX();\n        y_a = l.getP1().getY();\n        x_b = l.getP2().getX();\n        y_b = l.getP2().getY();\n        m = (y_b - y_a) / (x_b - x_a);\n        b = -m * x_a + y_a;\n\n    }\n\n    private LineFunction(double m, double b) {\n        this.m = m;\n        this.b = b;\n    }\n\n    public double computeFor(double xValue) {\n        return this.m * xValue + this.b;\n    }\n\n    public LineFunction sum(LineFunction other) {\n        return new LineFunction(this.m + other.m, this.b + other.b);\n    }\n\n    @Override\n    public String toString() {\n        return \"y = \" + m + \"x + \" + b;\n    }\n}\n```\n\n\nThis class represent a simple function of type y = mx + b . Basically, takes a line and transforms it into a function.\n\nLine:\n\n```\npublic class Line {\n\n    private final Point p1, p2;\n    private final LineFunction lineFunction;\n\n    public Line(Point p1, Point p2) {\n        this.p1 = p1;\n        this.p2 = p2;\n        this.lineFunction = new LineFunction(this);\n    }\n    public Line(Line o) {\n        this.p1 = o.p1;\n        this.p2 = o.p2;\n        this.lineFunction = new LineFunction(this);\n    }\n    public Line sum(Line other,Point p1,Point p2) {\n        LineFunction s= this.lineFunction.sum(other.lineFunction);\n        return new Line(new Point(p1.getX(),s.computeFor(p1.getX())),new Point(p2.getX(),s.computeFor(p2.getX())));\n    }\n    public boolean isInInterval(Point p) {\n        return p.getX() >= this.p1.getX() && p.getX() < this.p2.getX();\n    }\n\n    @Override\n    public String toString() {\n        return \"{\"+p1+\",\"+p2+\"}\";\n    }\n\n}\n```\n\n\nA ```\nLine```\n is defined by two points, and from a ```\nLine```\n we can get the function that defines it. It has methods for checking if the x value of a point is between the starting and ending x of the line.\n\nIn order to accomplish the point 1 of the algorithm, we need to know all the points of every line:\n\n```\npublic static ArrayList<Point> getAllPoints(ArrayList<Line> lines) {\n        HashSet<Point> points = new HashSet<Point>();\n        for (Line line : lines)\n        {\n            points.add(line.getP1());\n            points.add(line.getP2());\n        }\n        ArrayList<Point> res = new ArrayList<Point>(points);\n        Collections.sort(res);\n        return res;\n    }\n```\n\n\nThis method returns all the points defining the intervals. The points must be ordered, so\n\n```\npublic class Point implements Comparable<Point>{\n    private long x;\n    private double y;\n\n    @Override\n    public int compareTo(Point o) {\n        int cmp1=Long.compare(this.x, o.x);\n        return  cmp1 != 0 ? cmp1 : Double.compare(this.y, o.y) ;\n    }\n\n    @Override\n    public String toString() {\n        return \"(\" + x + \",\" + y + \")\";\n    }\n\n    @Override\n    public int hashCode() {\n        final int prime = 31;\n        int result = 1;\n        result = prime * result + (int) (x ^ (x >>> 32));\n        long temp;\n        temp = Double.doubleToLongBits(y);\n        result = prime * result + (int) (temp ^ (temp >>> 32));\n        return result;\n    }\n\n    @Override\n    public boolean equals(Object obj) {\n        if (this == obj)\n            return true;\n        if (obj == null)\n            return false;\n        if (getClass() != obj.getClass())\n            return false;\n        Point other = (Point) obj;\n        if (x != other.x)\n            return false;\n        if (Double.doubleToLongBits(y) != Double.doubleToLongBits(other.y))\n            return false;\n        return true;\n    }\n\n}\n```\n\n\nFor the second step of the algorithm, we need to know wich lines belong to a given interval:\n\n```\npublic static ArrayList<Line> filter(Point p, ArrayList<Line> lines) {\n        ArrayList<Line> filtered = new ArrayList<Line>();\n        for (Line line : lines)\n            if (line.isInInterval(p))\n                filtered.add(line);\n\n        return filtered;\n    }\n```\n\n\nThe only thing left is the summation of a groups of lines:\n\n```\npublic static ArrayList<Line> sumAll(ArrayList<Line> lines) {\n        ArrayList<Point> points = getAllPoints(lines);\n        ArrayList<Line> result = new ArrayList<>();\n\n        for (int i = 0; i < points.size() - 1; i++)\n        {\n            Point current = points.get(i);\n            Point next = points.get(i + 1);\n            ArrayList<Line> filtered = filter(current, lines);\n            Line acc = new Line(new Point(current.getX(), 0), new Point(\n                    next.getX(), 0));\n\n            for (Line lf : filtered)\n            {\n                acc = acc.sum(lf, current, next);\n            }\n\n            result.add(acc);\n        }\n        return result;\n    }\n```\n\n\nA simple example:\n\n```\npublic static void main(String[] args) {\n        Line l1 = new Line(new Point(0, 0), new Point(3, 1));\n        Line l2 = new Line(new Point(2, 0), new Point(3, 1));\n\n        Line l3 = new Line(new Point(4, 7), new Point(8, 2));\n        Line l4 = new Line(new Point(5, 4), new Point(6, 1));\n\n        Line l5 = new Line(new Point(9, 6), new Point(10, 1));\n        ArrayList<Line> lines = new ArrayList<Line>();\n        lines.add(l1);\n        lines.add(l2);\n        lines.add(l3);\n        lines.add(l4);\n        lines.add(l5);\n        ArrayList<Line> res = sumAll(lines);\n        for (Line line : res)\n        {\n            System.out.println(line);\n        }\n\n\n    }\n```\n\n\nOutput:\n\n```\n{(0,0.0),(2,0.6666666666666666)}\n{(2,0.666666666666667),(3,2.0)}\n{(3,0.0),(4,0.0)} ----> There's no line in this interval.\n{(4,7.0),(5,5.75)}\n{(5,9.75),(6,5.5)}\n{(6,4.5),(8,2.0)}\n{(8,0.0),(9,0.0)}\n{(9,6.0),(10,1.0)}\n```\n\n\nIf I'm missing anything, don't hesitate lo leave a comment.\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "Analysis: Performance of ForkJoinPool\r\n                \r\nQuestion\n\nAs Fork-Join seems to be the current hype and recommended in many answers, I thought: why not do some research on how fast it actually is?\n\nTo measure this, I wrote a small program (see code below) that does some adding of numbers and forked it out with various parameters, including number of threads, fork-depth and fork-spread, then measured the time for execution and especially the time spent for actual calculation vs. time spent on forking.\n\nAbstract Answer\n\nWhile being implemented well, ForkJoin is an extremely inefficient way to parallelize a task, as the cost for each fork is very high. A naive problem-optimized implementation can easily archive 99% thread-execution-time (which beats everything measured with Fork-Join) and therefore such an implementation is always faster than a Fork-Join implementation. In addition, if the actual task per fork is minor, a Fork-Join implementation can be much slower than even a single-threaded linear implementation.\n\nSo Fork-Join is more a question of whether or not it helps the architecture of your code, as it doesn't have any performance benefits over other implementations. Therefore Fork-Join should only be used if:\n\n\nPerformance isn't critical and tasks frequently need to wait for the result of other tasks to continue. So basically if the Fork-Join structure greatly simplifies the task over a naive implementation.\nThe actual task takes greatly out-weights the cost for forking, and the loss therefore becomes negligible. In my test a loop that added 2 values had to loop at least 10000 times per fork to get a reasonable performance.\n\n\nEdit: See here for a more in-depth analysis that I was pointed to.\n\nTest Setup\n\nIn my program I had a RecursiveTask calculate a Fibonacci series for a given N, which reduces the actual calculation to 3 assignments and 1 addition. For any given CPU this should be a minor task. \n\nOver the test I varied the amount of threads, the amount of forks per task and the length of the Fibonacci loop. In addition I did some tests with the async parameter, but setting this one to false only showed a minor reduction in calculation time, so I skipped that. The spread parameter (forks per fork) has as well been mostly skipped, as there was no significant difference in the result.\n\nIn general the calculation time is very stable, the actual percentage of time spent on the task usually varies by less than 1%, therefore each test set has been run about 5 times (or more if the numbers were unstable) on an otherwise idle system with 4 cores (+4 hyper-cores) and then the median execution time has been selected.\n\nThe proper execution has been verified through various test variables, especially the number of actual threads used has been verified to never differ from the initially given parallelism parameter.\n\nDetailed Test Results\n\nWhere:\n\n\n```\nTime total```\n is the total time the entire calculation took from the perspective of the main thread.\n```\nTime task```\n is the time spent on actually calculating the Fibonacci series in all forks combined.\n```\nTime task percentage```\n is the relative gain thanks to threading (time task / time total).\n```\nspread->depth```\n is the (set) spread (fork per fork) and the (calculated) forking-depth.\n```\nthreads```\n is the actual amount of threads used.\n```\ntask-time/thread```\n is the time each thread actually spent on calculating the Fibonacci series over-all.\n\n\nSpread->depth test:\n\n```\nTime total: 8766.670 ms, time task: 1717.418 ms ( 19.59%), spread->depth:  2->26, thread#: 1, task-time/thread: 19.59%\nTime total: 7872.244 ms, time task: 1421.478 ms ( 18.06%), spread->depth: 10-> 8, thread#: 1, task-time/thread: 18.06%\nTime total: 7336.052 ms, time task: 1280.036 ms ( 17.45%), spread->depth: 100-> 4, thread#: 1, task-time/thread: 17.45%\n```\n\n\nConclusion: Number of forks only has a minor effect (still less forks = better), the implementation seems to be fairly sophisticated. Similar results were collected with other settings, so I skip these here.\n\nFib(0) (almost all time spent on forking)\n\n```\nTime total: 7866.777 ms, time task: 1421.488 ms ( 18.07%), spread->depth: 10-> 8, thread#: 1, task-time/thread: 18.07%\nTime total: 7085.142 ms, time task: 1349.207 ms ( 19.04%), spread->depth: 10-> 8, thread#: 2, task-time/thread:  9.52%\nTime total: 6580.609 ms, time task: 1476.467 ms ( 22.44%), spread->depth: 10-> 8, thread#: 4, task-time/thread:  5.61%\n```\n\n\nConclusion: With a very minor task, most time is spent on forking, making a single-threaded implementation about 5 times faster than any Fork-Join setup. Even with multiple threads it is impossible to gain any performance increase using Fork-Join.\n\nFib(100)\n\n```\nTime total: 12487.634 ms, time task: 5707.720 ms ( 45.71%), spread->depth: 10-> 8, thread#: 1, task-time/thread: 45.71%\nTime total:  8386.855 ms, time task: 5768.881 ms ( 68.78%), spread->depth: 10-> 8, thread#: 2, task-time/thread: 34.39%\nTime total:  7078.769 ms, time task: 6086.997 ms ( 85.99%), spread->depth: 10-> 8, thread#: 4, task-time/thread: 21.50%\n```\n\n\nConclusion: seems to be close to the break-even point for single-threaded execution, while multi-threading begins to have an impact. Still a single-threaded implementation would be faster than any Fork-Join setup.\n\nFib(1000)\n\n```\nTime total:  5941.344 ms, time task:  5228.258 ms ( 88.00%), spread->depth: 10-> 7, thread#: 1, task-time/thread: 88.00%\nTime total:  3160.818 ms, time task:  5244.241 ms (165.91%), spread->depth: 10-> 7, thread#: 2, task-time/thread: 82.96%\nTime total: 16301.697 ms, time task: 53351.694 ms (327.28%), spread->depth: 10-> 8, thread#: 4, task-time/thread: 81.82%\n```\n\n\nConclusion: Times start to stabilize here for multi-threading execution with a near linear gain, while still ~20% of the calculation time per thread is spent on forking. While at this point forking can increase performance through threading, a naive implementation would still be noticeably faster.\n\nFib(10000)\n\n```\nTime total:  5204.786 ms, time task:  5119.133 ms ( 98.35%), spread->depth: 10-> 6, thread#: 1, task-time/thread: 98.35%\nTime total: 26033.889 ms, time task: 51084.118 ms (196.22%), spread->depth: 10-> 7, thread#: 2, task-time/thread: 98.11%\nTime total: 13183.573 ms, time task: 51637.471 ms (391.68%), spread->depth: 10-> 7, thread#: 4, task-time/thread: 97.92%\n```\n\n\nConclusion: At this number the calculation out-weights the cost for forking. While a naive implementation would still be slightly faster, the loss caused by forking is negligible if the task would have been much more difficult to implement in another way.\n\nCode\n\n```\npublic class Test {\n\n  static final int NUM_THREADS = 4;\n  static final int SPREAD = 10;\n  static final int LOOPS = 4000000;\n  static final int CALCULATION_N = 10000;\n  static final boolean DO_ASYNC = true;\n  //---\n  static final long MAX_DEPTH = Math.round(Math.log(LOOPS) / Math.log(SPREAD)); // try to have the execution take about the same time\n\n  private static class Task extends RecursiveTask<Integer> {\n\n    final static AtomicLong timeExecute = new AtomicLong(0);\n    final static AtomicLong totalLoops = new AtomicLong(0);\n    final long depth;\n\n    public Task(final long depth) {\n      this.depth = depth;\n    }\n\n    @Override\n    protected Integer compute() {\n      if (depth < MAX_DEPTH) {\n        final Task[] subTasks = new Task[SPREAD];\n        for (int i = 0; i < subTasks.length; ++i) {\n          subTasks[i] = new Task(depth + 1);\n        }\n        try {\n          invokeAll(subTasks);\n          final long startTime = System.nanoTime();\n          int result = 0;\n          for (final Task task : subTasks) {\n            if (task.isCompletedNormally()) {\n              result += task.get();\n            }\n          }\n          timeExecute.addAndGet(System.nanoTime() - startTime);\n          return result;\n        } catch (Exception e) {\n          this.completeExceptionally(e);\n          return null;\n        }\n      } else {\n        totalLoops.incrementAndGet();\n        final long startTime = System.nanoTime();\n        int a = 0, b = 1, h;\n        for (int n = 0; n < CALCULATION_N; ++n) {\n          h = b;\n          b = a + b;\n          a = h;\n        }\n        timeExecute.addAndGet(System.nanoTime() - startTime);\n        return b;\n      }\n    }\n  }\n\n  public static void main(String[] args) {\n    final AtomicInteger threadCount = new AtomicInteger(0);\n    final ForkJoinPool pool = new ForkJoinPool(NUM_THREADS, new ForkJoinPool.ForkJoinWorkerThreadFactory() {\n      @Override\n      public ForkJoinWorkerThread newThread(ForkJoinPool pool) {\n        threadCount.getAndIncrement();\n        final ForkJoinWorkerThread result = ForkJoinPool.defaultForkJoinWorkerThreadFactory.newThread(pool);\n        result.setPriority(Thread.MIN_PRIORITY);\n        return result;\n      }\n    }, null, DO_ASYNC);\n    final long startTime = System.nanoTime();\n    final Integer result = pool.invoke(new Task(0));\n    final double duration = ((double) (System.nanoTime() - startTime)) / 1000000.0;\n    final double executionDuration = ((double) Task.timeExecute.get()) / 1000000.0;\n    final double executionPercent = executionDuration / duration * 100.0;\n    final double executionPercentPerThread = executionPercent / ((double) NUM_THREADS);\n\n    System.out.println(\"Completed: \" + result + \" in \" + Task.totalLoops.get() + \" loops.\");\n    System.out.println(String.format(\"Time total: %8.3f ms, time task: %8.3f ms (%6.2f%%), spread->depth: %2d->%2d, thread#: %1d, task-time/thread: %5.2f%%\", duration, executionDuration, executionPercent, SPREAD, MAX_DEPTH, threadCount.get(), executionPercentPerThread));\n  }\n}\n```\n\n\nFeel free to point out any mistakes or to make suggestions for improvement. I will accept the most valuable answer for some bonus points.\n    ", "Answer": "\r\nSuggestions:\n\n\nPrint the number of forks made + the cost estimation of the work which is done (i.e. the number of additions or a  length of ```\nBigInteger```\ns which are being summed if you switch to them). This proportion will show how effective is your forking strategy and give you an understanding of what is the minimal job size which makes sense.\nCheck your algorithm - Fibonacci has an exponential growth, you task returns  integer, so you should be getting an overflow very soon.\n\n\nSo, the goal is to choose a threshold which would say to fork or not to fork:\n\n\n  One of the main things to consider when implementing an algorithm\n  using fork/join parallelism is choosing the threshold which determines\n  whether a task will execute a sequential computation rather than\n  forking parallel sub-tasks.\n  \n  If the threshold is too large, then the program might not create\n  enough tasks to fully take advantage of the available\n  processors/cores.\n  \n  If the threshold is too small, then the overhead of task creation and\n  management could become significant.\n  \n  In general, some experimentation will be necessary to find an\n  appropriate threshold value. Source\n\n\nThis also could be useful: How to determine the proper work division threshold of a fork-join task.\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "Inlining Algorithm\r\n                \r\nDoes anyone know of any papers discussion inlining algorithms? And closely related, the relationship of parent-child graph to call graph.\n\nBackground: I have a compiler written in ```\nOcaml```\n which aggressively inlines functions, primarily as a result of this and some other optimisations it generates faster code for my programming language than most others in many circumstances (including even ```\nC```\n).\n\nProblem #1: The algorithm has trouble with recursion. For this my rule is only to inline children into parents, to prevent infinite recursion, but this precludes sibling functions inlining once into each other.\n\nProblem #2: I do not know of a simple way to optimise inlining operations. My algorithm is imperative with mutable representation of function bodies because it does not seem even remotely possible to make an efficient functional inlining algorithm. If the call graph is a tree, it is clear that a bottom up inlining is optimal.\n\nTechnical information: Inlining consists of a number of inlining steps. The problem is the ordering of the steps. \n\nEach step works as follows: \n\n\nwe make a copy of the function to be inlined and beta-reduce by\nreplacing both type parameters and value parameters with arguments.\nWe then replace return statement with an assignment to a new variable\nfollowed by a jump to the end of the function body.\nThe original call to the function is then replaced by this body.\nHowever we're not finished. We must also clone all the children of\nthe function, beta-reducting them as well, and reparent the clones to\nthe calling function.\n\n\nThe cloning operation makes it extremely hard to inline recursive functions. The usual trick of keeping a list of what is already in progress and just checking to see if we're already processing this call does not work in naive form because the recursive call is now moved into the beta-reduced code being stuffed into the calling function, and the recursion target may have changed to a cloned child. However that child, in calling the parent, is still calling the original parent which calls its child, and now the unrolling of the recursion will not stop. As mentioned I broke this regress by only allowing inlining a recursive call to a child, preventing sibling recursions being inlined.\n\nThe cost of inlining is further complicated by the need to ```\ngarbage collect```\n unused functions. Since inlining is potentially exponential, this is essential. If all the calls to a function are inlined, we should get rid of the function if it has not been inlined into yet, otherwise we'll waste time inlining into a function which is no longer used. Actually keeping track of who calls what is extremely difficult, because when inlining we're not working with an actual function representation, but an \"unravelled\" one: for example, the list of instructions is being processed sequentially and a new list built up, and at any one point in time there may not be a coherent instruction list.\n\nIn his ML compiler Steven Weeks chose to use a number of small optimisations applied repeatedly, since this made the optimisations easy to write and easy to control, but unfortunately this misses a lot of optimisation opportunities compared to a recursive algorithm.\n\nProblem #3: when is it safe to inline a function call?\n\nTo explain this problem generically: in a lazy functional language, arguments are wrapped in closures and then we can inline an application; this is the standard model for Haskell. However it also explains why ```\nHaskell```\n is so slow. The closures are not required if the argument is known, then the parameter can be replaced directly with its argument where is occurs (this is normal order ```\nbeta-reduction```\n).\n\nHowever if it is known the argument evaluation is not non-terminating, eager evaluation can be used instead: the parameter is assigned the value of the expression once, and then reused. A hybrid of these two techniques is to use a closure but cache the result inside the closure object. Still, GHC hasn't succeeded in producing very efficient code: it is clearly very difficult, especially if you have separate compilation.\n\nIn Felix, I took the opposite approach. Instead of demanding correctness and gradually improving efficiency by proving optimisations preserved semantics, I mandate that the optimisation defines the semantics. This guarantees correct operation of the optimiser at the expense of uncertainty about what how certain code will behave. The idea is to provide ways for the programmer to force the optimiser to conform to intended semantics if the default optimisation strategy is too aggressive.\n\nFor example, the default parameter passing mode allows the compiler to chose whether to wrap the argument in a closure, replace the parameter with the argument, or assign the argument to the parameter. If the programmer wants to force a closure, they can just pass in a closure. If the programmer wants to force eager evaluation, they mark the parameter ```\nvar```\n.\n\nThe complexity here is much greater than a functional programming language: Felix is a procedural language with variables and pointers. It also has Haskell style typeclasses. This makes the inlining routine extremely complex, for example, type-class instances replace abstract functions whenever possible (due to type specialisation when calling a polymorphic function, it may be possible to find an instance whilst inlining, so now we have a new function we can inline).\n\nJust to be clear I have to add some more notes.\n\nInlining and several other optimisations such as user defined term reductions, typeclass instantiations, linear data flow checks for variable elimination, tail rec optimisation,  are done all at once on a given function.\n\nThe ordering problem isn't the order to apply different optimisations, the problem is to order the functions. \n\nI use a brain dead algorithm to detect recursion: I build up a list of everything used directly by a each function, find the closure, and then check if the function is in the result. Note the usage set is built up many times during optimisation, and this is a serious bottleneck.\n\nWhether a function is recursive or not can change unfortunately. A recursive function might become non-recursive after tail rec optimisation. But there is a much harder case: instantiating a typeclass \"virtual\" function can make what appeared to be non-recursive recursive. \n\nAs to sibling calls, the problem is that given f and g where f calls g and g calls f I actually want to inline f into g, and g into f .. once. My infinite regress stopping rule is to only allow inlining of f into g if they're mutually recursive if f is a child of g, which excludes inlining siblings.\n\nBasically I want to \"flatten out\" all code \"as much as possible\".\n    ", "Answer": "\r\nI realize you probably already know all this, but it seems important to still write it in full, at least for further reference.\n\nIn the functional community, there is some litterature mostly from the GHC people. Note that they consider inlining as a transformation in the source language, while you seem to work at a lower level. Working in the source language -- or an intermediate language of reasonably similar semantics -- is, I believe, a big help for simplicity and correctness.\n\n\nGHC Wiki : Inlining (contains a bibliography)\nSecrets of the Glasgow Haskell inliner\n\n\nFor the question of the ordering compiler passes, this is quite arcane. Still in a Haskell setting, there is the Compilation by Transformation in a Non-strict Functional Language PhD Thesis which discusses the ordering of different compiler passes (and also inlining).\n\nThere is also the quite recent paper on Compilation by Equality Saturation which propose a novel approach to optimisation passes ordering. I'm not sure it has yet demonstrated applicability at a large scale, but it's certainly an interesting direction to explore.\n    ", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
{"Question": "", "Answer": "", "Knowledge_point": "Linear Programming and Reductions", "Tag": "算法分析"}
