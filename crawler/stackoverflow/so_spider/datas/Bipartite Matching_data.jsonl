{"Question": "Time complexity of this bipartite matching algorithm\r\n                \r\nI was looking at some different ways to do bipartite matching and found this \nimplementation http://www.geeksforgeeks.org/maximum-bipartite-matching/, am wondering what the time complexity for it is? Most things I've read seem to do bipartite matchings in polynomial time, but  this seems exponential?\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite matching in Python\r\n                \r\nDoes anybody know any module in Python that computes the best bipartite matching?\nI have tried the following two:\n\n munkres \n hungarian \n\nHowever, in my case, I have to deal with non-complete graph (i.e., there might not be an edge between two nodes), and therefore, there might not be a match if the node has no edge. The above two packages seem not to be able to deal with this.\n\nAny advice?\n    ", "Answer": "\r\nSet cost to infinity or a large value for an edge that does not exist.  You can then tell by the result whether an invalid edge was used.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum bipartite matching in disconnected graph\r\n                \r\nHow do you find the maximum bipartite matching when your graph has several components ? Each component can be colored in two ways. How do you decide the two sets X and Y in order to run the maximum matching routine ?\n    ", "Answer": "\r\nIf your graph has several different connected components, you can find the maximum matching in the graph by just finding the maximum matching in each of those components and returning their union.\n\nAs for how to decide the sets X and Y, many algorithms exist for detecting whether a particular graph is bipartite and, if so, assigning labels to the nodes to recover those two groups.  You can do this with a modified DFS or BFS fairly easily.  Consequently, an algorithm for your problem might be\n\n\nRun a DFS over the entire graph to break it into connected components.\nFor each of those components:\n\nRun a DFS on those components to recover which nodes are in the groups X and Y.\nUse a maximum bipartite matching algorithm to find a maximum matching in that component.\n\nCombine all the results together to get the overall answer.\n\n\nHope this helps!\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite Matching\r\n                \r\nHow can I implement a bipartite matching algorithm (probably based on a max-flow algorithm) in C or C++ ?\n\nTo be specific, I have this input in a file:\n(1,3)\n(1,5)\n(2,5)\n\n(M,F) --> where M represents id of MALE and F is id of FEMALE.\n\nI need to find the maximum number of matches and show matched couples.\nLike: \nmatches: 1&3   ,  2&5\n\nI have read in some books I can base this problem on a \"maximum flow in a network\" algorithm, but I couldn't find any specific info other than the sentence \"this problem can be solved by .... algorithm\".\nI have little knowledge about max-flow, and dont know how to implement it either...\n    ", "Answer": "\r\nYes, bipartite matching can be reduced to maximum flow:\n\n\nYou're given sets of nodes ```\nM```\n and ```\nF```\n. Add a directed edge from a node ```\nm```\n in ```\nM```\n to a node ```\nf```\n in ```\nF```\n if you've got the pair ```\n(m, f)```\n in your file.\nAdd a single node ```\nS```\n with a directed edge from ```\nS```\n to every node in ```\nM```\n (this is your \"super-source\" node).\nAdd a single node ```\nT```\n with a directed edge from every node in ```\nF```\n to ```\nT```\n (this is your \"super-sink\" node).\nNow, you need to find the maximum flow (with all your edges of weight 1) from ```\nS```\n to ```\nT```\n.\n\n\nSo what the heck is maximum flow? A flow from ```\nS```\n to ```\nT```\n is a set of edges such that for each node (except ```\nS```\n and ```\nT```\n), the weight of its in-flux edges is the same as the weight of its out-flux edges. Imagine that your graph is a series of pipes, and you're pouring water in the system at ```\nS```\n and letting it out at ```\nT```\n. At every node in between, the amount of water going in has to be the same as the amount of water coming out.\n\nTry to convince yourself that a flow corresponds to a matching of your original sets. (Given a flow, how to you get a matching? Given a matching, how to you get a flow?)\n\nFinally, to find the maximum flow in a graph, you can use the Ford-Fulkerson algorithm. The above wikipedia page gives a good description of it, with pseudo-code.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "how to convert Bipartite Matching to Independent Set\r\n                \r\nI read the book Algorithm Design, chapter 1, it gave a very short description of how to convert Bipartite Matching to Independent Set Problem and I don't get it.\n\nDo anybody know that any detailed matriel to describe this process? Thanks!\n    ", "Answer": "\r\nA maximum bipartite matching is a set of edges in a bipartite graph, no two edges being adjacent. A maximum independent set is a set of nodes (vertices) in a graph, no two vertices being adjacent.\n\nSo, you can convert a bipartite matching problem to independent set by converting every edge in your bipartite graph to a node, and then add an edge between all those newly created nodes that share a common endpoint in the original graph. Then a maximum independent set in the new graph corresponds to a maximum bipartite matching in the original problem.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite matching in graph\r\n                \r\nI have the following code which is an implementation of BPM (bipartite matching, from graph theory)\n\n```\n#include <iostream>\n#include <cstring>\nusing  namespace std;\n#define M 128\n#define N 128\nbool graph[M][N];\nbool seen[N];\nint matchL[M],matchR[N];\nint n=4;\nint m=4;\n\nbool bpm(int u){\n\n    for(int v=0;v<n;v++) if(graph[u][u])\n    {\n                if (seen[v]) continue;\n                seen[v]=true;\n                if(matchR[v] <0 || bpm(matchR[v])){\n                    matchL[u]=v;\n                    matchR[v]=u;\n                    return true;\n                }\n    }\n\n    return false;\n\n}\n\nint main(){\n\n    graph[0][1]=1;\n    graph[0][3]=1;\n    graph[1][3]=1;\n    graph[0][2]=1;\n     memset(matchL,-1,sizeof(matchL));\n     memset(matchR,-1,sizeof(matchR));\n     int cnt=0;\n     // memset(seen,0,sizeof(seen));\n     for(int i=0;i<m;i++){\n\n        memset(seen,0,sizeof(seen));\n          if(bpm(i)) cnt++;\n\n     }\n     cout<<cnt<<endl;\n    return 0;\n}\n```\n\n\nThe definition of ```\ncnt```\n and the purpose of this code are given below.\n\n\n  Given a bipartite graph represented as an m-by-n matrix, where ```\ngraph[i][j]```\n is ```\ntrue```\n iff there is an edge from pigeon ```\ni```\n to hole ```\nj```\n, computes the maximum number of pigeons that can find a hole (one per pigeon) and an optimal assignment.\n\n\n\n```\ngraph[m][n]```\n, ```\nmatchL[n]```\n, ```\nmatchR[m]```\n and ```\nseen[m]```\n are global arrays.\n```\nmain()```\n initializes ```\nmatchL[]```\n and ```\nmatchR[]```\n to ```\n-1```\n in all components.\n```\nmain()```\n does a loop over all pigeons ```\ni```\n and in each iteration\n\n\nclears ```\nseen[]```\n to ```\n0```\n in all components\ncalls ```\nbpm(i)```\n and increments the ```\nmaxflow```\n counter\n```\nbpm(i)```\n returns ```\ntrue```\n iff pigeon ```\ni```\n can be assigned a hole  \n\n```\ncnt```\n contains the number of happy pigeons.\n\n\nIn my case, ```\ncnt```\n's value is output as ```\n0```\n. Does this graph algorithm work correctly or have I made some error? \n    ", "Answer": "\r\nEither your initialization is faulty or this condition in ```\nbpm()```\n is faulty:\n\n```\n       if (graph[u][u])\n```\n\n\nThere is no element of ```\ngraph```\n on the diagonal which is set ```\ntrue```\n, so ```\nbpm()```\n always fails completely.  It is also not clear why you'd be needing to test the diagonal alone.  Maybe it should be ```\nif (graph[u][v])```\n, or maybe something else.\n\n(Your indentation leaves somewhat to be desired; it is extremely aconventional to put an ```\nif```\n condition such as this on the same line as a ```\nfor```\n loop control.  Incidentally, the initialization of ```\nmatchL```\n and ```\nmatchR```\n only works on 2's-complement machines.)\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "maximum bipartite matching (ford-fulkerson)\r\n                \r\nI was reading http://www.geeksforgeeks.org/maximum-bipartite-matching/ and http://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm and am having trouble understanding. It seems the example is under the assumptions that each job can only accept 1 person and each person wants 1 job. I was wondering how the algorithm/code would change if for example, the v set had capacity > 1 (can hire multiple people for that job) and the u set > 1 (each person wants more than 1 job)?\n    ", "Answer": "\r\nTo allow jobs to have more than one person assigned to them, you'd only modify edge capacities from ```\nJobs```\n to ```\nTerminal```\n (Similar to how Niklas B. described in his comment, but not exactly.)\n\nLike this:\n\n\n\nThe capacities of 1 from the ```\nSource```\n to the ```\nPeople```\n, and 1 from ```\nPeople```\n to ```\nJobs```\n guarantees that a person will only ever be selected for one job (because the maximum flow that they can contribute overall is 1). However, the capacities ```\n> 1```\n from ```\nJobs```\n to ```\nTerminal```\n allows that more than one person can be assigned to that job. \n\nIf a person can perform also more than 1 job, then the max flow from ```\nSource```\n to ```\nPerson```\n increases by that amount:\n\n\n\nWhere ```\ni```\n, ```\nj```\n, ```\nk```\n, and ```\nx```\n are stand-ins for integers with values ```\n>= 1```\n\n\nThe key thing to remember here is that flow capacities to the left of ```\nPeople```\n dictate how many jobs they may take, and the flow capacities to the right of ```\nJobs```\n dictate how many people may be assigned that job. The capacities in the middle should not change.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite Matching with a constraint\r\n                \r\nI am trying to get a matching between two sets of vertices, one represents meets between two teams and the other time slots when the meets could happen. The adjacency map represents both teams' availability to meet at any given time slot. This would be bipartite matching. The problem is that I want to constraint this so that any team will not be assigned to consecutive time slots, more specifically to time slots in two consecutive days.\nSo, I've tried adding a check right before adding an edge to the match, at the end of the augmenting path, that checks the previous day's and following day's time slots, if they have been matched to a meet with any of the teams in the meet about to match. I tried it with Hopcroft-Karp and with DFS. It didn't work.\nIs this not bipartite matching anymore?\nAny help will be greatly appreciated.\nEDIT:\nAs suggested in the answer below, I am trying to implement this as an integer linear program. The following code is heavily based on the example from Google OR-tools on assignment matching\nAs it is, it seems to work correctly for matching, but without my specified constraint.\n```\n// [START program]\n// [START import]\nimport com.google.ortools.linearsolver.MPConstraint;\nimport com.google.ortools.linearsolver.MPObjective;\nimport com.google.ortools.linearsolver.MPSolver;\nimport com.google.ortools.linearsolver.MPVariable;\n// [END import]\n\n/** MIP example that solves an assignment problem. */\npublic class GameMatching {\n    static {\n        System.loadLibrary(\"jniortools\");\n    }\n\n    public static void main(String[] args) {\n        // Data\n        // [START data_model]\n        // Adjacency matrix represents which games can happen on which dates\n        int[][] adj = {\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n        };\n\n        int numGames = adj.length;\n        int numDates = adj[0].length;\n\n        //represents which game time slots are on a given day (4 games on sundays, 2 on weekdays)\n        int[][] days = {\n              {0, 1, 2, 3},\n              {4, 5},\n              {6, 7},\n              {8, 9, 10, 11},\n              {12, 13},\n              {14, 15},\n              {16, 17},\n              {18, 19},\n              {20, 21, 22, 23},\n              {24, 25},\n              {26, 27},\n              {28, 29},\n              {30, 31},\n              {32, 33, 34, 35},\n              {36, 37},\n              {38, 39},\n              {40, 41},\n              {42, 43},\n              {44, 45, 46, 47},\n              {48, 49},\n              {50, 51},\n              {52, 53, 54, 55},\n              {56, 57},\n              {58, 59},\n              {60, 61},\n              {62, 63},\n              {64, 65, 66, 67},\n              {68, 69},\n              {70, 71},\n              {72, 73},\n              {74, 75},\n              {76, 77, 78, 79}\n        };\n        //represents what day of the week is a day, a team can play thursday and sunday, but not sunday and monday 0 is sunday, 1 is monday...\n        int[] weekDays = {0, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0};\n\n        // teamToGames[i][j] represents a team i's, games j\n        int[][] teamToGames = {\n              {1, 3, 9, 16, 18, 26},\n              {0, 8, 12, 16, 23, 28},\n              {1, 5, 7, 13, 21, 27},\n              {2, 5, 14, 17, 22, 26},\n              {7, 15, 19, 21, 24, 28},\n              {3, 10, 14, 20, 27, 29},\n              {2, 6, 9, 13, 23, 29},\n              {6, 8, 11, 18, 19, 25},\n              {8, 4, 10, 11, 17, 24},\n              {4, 12, 15, 20, 22, 25},\n        };\n       \n        // [END data_model]\n\n        // Solver\n        // [START solver]\n        // Create the linear solver with the CBC backend.\n        MPSolver solver = new MPSolver(\"AssignmentMip\", MPSolver.OptimizationProblemType.CBC_MIXED_INTEGER_PROGRAMMING);\n        // [END solver]\n\n        // Variables\n        // [START variables]\n        // x[i][j] is an array of 0-1 variables, which will be 1\n        // if a game i is assigned to date j.\n        MPVariable[][] match = new MPVariable[numGames][numDates];\n        for (int i = 0; i < numGames; ++i) {\n            for (int j = 0; j < numDates; ++j) {\n                match[i][j] = solver.makeIntVar(0, 1, \"\");\n            }\n        }\n\n        // [END variables]\n\n        // Constraints\n        // [START constraints]\n        // Each game is assigned to at most one date.\n        for (int i = 0; i < numGames; ++i) {\n            MPConstraint constraint = solver.makeConstraint(0, 1, \"\");\n            for (int j = 0; j < numDates; ++j) {\n                constraint.setCoefficient(match[i][j], 1);\n            }\n        }\n        // Each date is assigned to at most one game.\n        for (int j = 0; j < numDates; ++j) {\n            MPConstraint constraint = solver.makeConstraint(0, 1, \"\");\n            for (int i = 0; i < numGames; ++i) {\n                constraint.setCoefficient(match[i][j], 1);\n            }\n        }\n        // Can only assign respecting adj matrix\n        for (int i = 0; i < numGames; ++i) {\n            for (int j = 0; j < numDates; ++j) {\n                MPConstraint constraint = solver.makeConstraint(0, adj[i][j], \"\");\n                constraint.setCoefficient(match[i][j], 1);\n            }\n        }\n\n        // Cannot assign team to consecutive dates\n        for (int i = 0; i < teamToGames.length; ++i) {\n            for (int j = 0; j < days.length - 1; ++j) {\n                if (weekDays[j] != 4) {\n                    MPConstraint constraint = solver.makeConstraint(0, 1, \"\");\n                    for (int k = 0; k < teamToGames[i].length; ++k) {\n                        for (int l = 0; l < days[j].length; ++l) {\n                            constraint.setCoefficient(match[teamToGames[i][k]][l], 1);\n                        }\n                        for (int l = 0; l < days[j+1].length; ++l) {\n                            constraint.setCoefficient(match[teamToGames[i][k]][l], 1);\n                        }\n                    }\n                }\n            }\n        }\n\n        // [END constraints]\n\n        // Objective\n        // [START objective]\n        MPObjective objective = solver.objective();\n        for (int i = 0; i < numGames; ++i) {\n            for (int j = 0; j < numDates; ++j) {\n                objective.setCoefficient(match[i][j], 1);\n            }\n        }\n\n        objective.setMaximization();\n        // [END objective]\n\n        // Solve\n        // [START solve]\n        MPSolver.ResultStatus resultStatus = solver.solve();\n        // [END solve]\n\n        // Print solution.\n        // [START print_solution]\n        // Check that the problem has a feasible solution.\n        if (resultStatus == MPSolver.ResultStatus.OPTIMAL || resultStatus == MPSolver.ResultStatus.FEASIBLE) {\n            System.out.println(\"Total matches: \" + objective.value() + \"\\n\");\n            for (int i = 0; i < numGames; ++i) {\n                for (int j = 0; j < numDates; ++j) {\n                    // Test if x[i][j] is 0 or 1 (with tolerance for floating point\n                    // arithmetic).\n                    if (match[i][j].solutionValue() > 0.5) {\n                        System.out.println(\"Game \" + i + \" assigned to date \" + j);\n                    }\n                }\n            }\n        } else {\n            System.err.println(\"No solution found.\");\n        }\n        // [END print_solution]\n    }\n\n    // private GameMatching() {\n    // }\n}\n// [END program]\n```\n\nEDIT\nThis is the apparently working code. There is one last thing I need this to do. It is preferable to have two games on one same day (if other constraints allow) rather than one game in each of two separate days. My first thought was finding a way to constrain the games per day to either 0 or 2 (or more on a Sunday), but that may not always be possible. So any help on how I could do this will be appreciated.\nThank you in advance.\n    ", "Answer": "\r\nWe could have an integer linear program, where each constraint for a team to meet includes two additional ```\nbefore```\n variables. For example, for team A to meet on day 4:\n```\n{\n  A_meets_on_4: 1,\n  A_meets_before_4: 1,\n  A_meets_before_5: 1\n}\n```\n\nIf we try to assign A to 3, we get:\n```\n{\n  A_meets_on_3: 1,\n  A_meets_before_3: 1,\n  A_meets_before_4: 1\n}\n```\n\nAnd if we try to assign A to 5, we get:\n```\n{\n  A_meets_on_5: 1,\n  A_meets_before_5: 1,\n  A_meets_before_6: 1\n}\n```\n\nNow if we try to assign, say 3 and 4, together we get:\n```\n{\n  A_meets_on_3: 1,\n  A_meets_on_4: 1,\n  A_meets_before_3: 1,\n  A_meets_before_4: 2\n  A_meets_before_5: 1\n}\n```\n\nBut if we constrain all the ```\nbefore```\n variables, like ```\nA_meets_before_4```\n, to be less than 2, this would not be allowed.\nIf we try to assign A to 3 and 5, together we get:\n```\n{\n  A_meets_on_3: 1,\n  A_meets_on_5: 1,\n  A_meets_before_3: 1,\n  A_meets_before_4: 1\n  A_meets_before_5: 1\n  A_meets_before_6: 1\n}\n```\n\nwhich is allowed.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum weight bipartite matching\r\n                \r\nI have a graph in form of a rectangular grid, i.e. N nodes and 2N edges, all adjacent nodes are connected.\nThis means it is two-colourable, and hence it is possible to do bipartite matching on it.\n\nEach (undirected) edge has a weight assigned to it - either -2, -1, 0, 1 or 2. No other values are allowed\n\nHow would I go about finding the matching on this graph that maximises the sum of the weighs in the matching? Pseudocode would be nice, don't bother with specific languages.\n\nIdeally, I am looking for an algorithm that runs in quadratic time - maybe O(n^2 log n) at worst.\n\n\n\nBefore you propose a solution, I have tried doing a max match using edges of weight 2, then of weight 1 (without going over edges of weight 2). I have scored 98% with this implementation (the problem is from an informatics olympiad), and wondering what is the 100% solution.\n    ", "Answer": "\r\nNot sure why you are thinking of min cut.  A cut  is not guaranteed to give you matching in this case. What you need to do is solve assignment problem.Assignment Problem. The successive shortest math algorithm solves it in O(EV log V) which in your case is O(n^2 log n).\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite-matching with weighted edges\r\n                \r\nI am working on a program where I have divided objects in to two sets, and I have a measurement of how similar each object is with every other object, and I want to find the optimal way to match them together.\n\nIf the sets were to be words and distance defined by edit-distance, then the optimal matching of the set \"this\", \"is\", \"a\", \"test\" with \"and\", \"this\", \"is\", \"best\", then I would match \"this\" with \"this\" (for a score of 0), \"is\" with \"is\" (for a score of 0), \"a\" with \"and\" (for a score of 2), and \"best\" with \"test\" (for a score of 1).\n\nI have reduced the problem to finding a maximal bipartite matching-like problem. Here is a description:\n\nGiven a bipartite graph where edges have integral weights, find a set of edges such that (a) every vertex has only one edge in the set and (b) the sum of the weights in this set is of maximal size.\n\nI don't believe this problem is NP-complete (or, even if it isn't, but if the algorithm could be very slow), is there some way to approximate the answer to some good degree? \n\nCurrently I pick the minimum weight edge, remove it and the nodes it connects to, and repeat, but this seems suboptimal. I've thought about reducing this to some sort of flow-problem (as you do with the normal bipartite matching), but it doesn't work in this case.\n    ", "Answer": "\r\nThis is the maximum bipartite matching problem (weighted).  It has a poly-time solution using augmenting paths.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum bipartite matching\r\n                \r\nCurrently best known algorithm for maximum bipartite matching is O(√VE). \n\nHere is what my algorithm is to solve the above problem:\nGiven two sets S1 and S2 and E edges between them.\n\nstep1: sort both S1 and S2 in increasing order on the basis of their degree\n\nstep 2: pick the element of the set in sorted order and assign it to the next free element of the other set count the number of matching.\n\nstep 3: perform the step 2 on S1 and then on S2.\n\nstep 4: take maximum of step 3.\n\nwhich makes the complexity above algorithm O(Vlog(V)+(V+E)).\n\nI can't prove the correctness of above algorithm so can any one help me with any counter example on which the above example fail, as this algo not works on spoj problem MATCHING so algorithm is wrong but can't figure out the counter example.\n\nThanks\n\n```\n#include<bits/stdc++.h>\n#define ll long long int\nusing namespace std;\n\n\nint main(){\n\n    ll c,b,p;\n    cin >> c >> b >> p;\n    c+=1;\n    b+=1;\n    ll mx = max(c,b);\n    c =mx;\n    b =mx;\n    vector<ll> adjcow[c];\n    vector<ll> adjbull[b];\n\n    for(ll i=0; i<p; i++){\n        ll x,y;\n        cin >> x >> y;\n        adjcow[x].push_back(y);\n        adjbull[y].push_back(x);\n    }\n\n    /*\n    for(ll i=0; i<c; i++){\n        cout << i << \" \";\n        for(auto x:adjcow[i])\n            cout << x << \" \";\n        cout << \"\\n\";\n    }\n\n    for(ll i=0; i<b; i++){\n        cout << i << \" \";\n        for(auto x : adjbull[i])\n            cout << x << \" \";\n        cout << endl; \n    }\n    */\n\n    vector<pair<ll, ll>> deg1(c);\n    vector<pair<ll, ll>> deg2(b);\n\n\n    for(ll i=0; i<c; i++){\n        ll count = 0;\n        for(auto x: adjcow[i])\n            count++;\n        deg1[i] = {count, i};\n    }\n\n    for(ll i=0; i<b; i++){\n        ll count = 0;\n        for(auto x: adjbull[i])\n            count++;\n        deg2[i] = {count,i};\n    }\n\n    sort(deg1.begin(), deg1.end());\n    sort(deg2.begin(), deg2.end());\n\n    vector<bool> isTaken1(c,0);\n    vector<bool> isTaken2(b,0);\n\n    /*\n    for(ll i=0; i<c; i++)\n        cout << deg1[i].first << \" \" << deg1[i].second  << \", \";\n\n    cout << endl;\n\n    for(ll i=0; i<b; i++) \n        cout << deg2[i].first <<\" \"<< deg2[i].second  << \", \";\n\n    cout << endl;\n    */\n\n    ll ansCow =0;\n    for(auto x:deg1){\n        ll node = x.second;\n        for(auto u: adjcow[node]){\n            if(isTaken1[u]==0){\n    //          cout << node << \"-> \" << u << \"\\n\";\n                isTaken1[u] = 1;\n                ansCow++;\n                break;\n            }\n        }\n    }\n\n    //cout << \"\\n\\n\";\n\n    ll ansBull =0;\n    for(auto x:deg2){\n        ll node = x.second;\n        for(auto u: adjbull[node]){\n            if(isTaken2[u]==0){\n    //          cout << node << \"->\" << u << \"\\n\";\n                isTaken2[u] = 1;\n                ansBull++;\n                break;\n            }\n        }\n    }\n\n    cout << max(ansCow, ansBull) << \"\\n\";\n}\n```\n\n\nInput::\n\n```\n5 4 6\n5 2\n1 2\n4 3\n3 1\n2 2\n4 4\n```\n\n    ", "Answer": "\r\nA counter-example is shown below. Note that every node has degree 2, so sorting has no effect. When connecting from left to right, if 1 chooses A, and 2 chooses B, then 3 cannot be connected. So the result is 2. When connecting from right to left, if A chooses 1 and B chooses 2, then C cannot be connected. The result is 2 again. But the correct result is 3, with 1 connected to C, 2 connected to B, and 3 connected to A.\n\n\n\nThe input to the program would be:\n\n```\n3 3 6\n1 1\n1 3\n2 2\n2 3\n3 1\n3 2\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite Matching finding maximum cover\r\n                \r\nThere is Google Code Jam Problem. I came to know that problem is solved using Bipartite matching. But i could not understand how to get final answer using number of match.\nHere is sudo code\n\n```\nint match=0;\n// Right - Right one String\n// Left  - Left one String\nfor(int i=0;i<Right.size();i++)\nmatch+=match_found(i)\n```\n\n\nFinally Why these Two lines of Code\n\n```\nint need = match + (Right.size() + Left.size() - match * 2);\nint answer = n- need;\n```\n\n\nWhy is should not be ```\nanswer = n-match```\n\n\nCan you please explain this. That would be very useful.\n    ", "Answer": "\r\nFrom wikipedia:\n\n\n  A smallest edge cover can be found in polynomial time by finding a maximum matching and extending it greedily so that all vertices are covered\n\n\nThis problem asks you to find the minimum number of edges to cover all the vertices.  This is equal to the number of edges in the maximum matching (match) plus the number of additional edges that need to be added in the greedy extension.\n\nThe maximum matching covers 2*match vertices, which means there must be x = (Right.size()+Left.size()-2*match) vertices still uncovered.\n\nTherefore we need to add x additional edges in the greedy extension process, and the total number of edges is match+x.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite Matching with divisible tasks\r\n                \r\nI am trying to solve an extension of Assignment problem, where both tasks and the man hours are divisible. \n\nfor instance, a man X has 4 hours available in a day, can do 1/3 of task A in 2 hours, 1/4 of task B in 4 hours. Man Y has 10 hours available can do 1/5 of a task A in 1.3 hours, 1/8 of task B in 6 hours. Is there an extension of BiPartite matching which can solve this?\n\nThanks!\n    ", "Answer": "\r\nI don't think that you can easily model this as a bipartite matching. However, it should be fairly easy to create a linear program for your problem. Just have for every worker a set of variables x_{i,j} which indicates how much of person i's time is allocated to task j.\n\nLet h_i be the number of hours available for person i. Then, for every person i it must hold that \n\n\n\nLet a_{i,j} be the \"efficiency\" of person i at task j, i.e., how much of the task the person can do in one hour. Then, for every task j it must hold that:\n\n\n\nThat's it. No integrality constraints or anything.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Symmetric Bipartite Matching of Elements in List\r\n                \r\nStart with a random list of integers, say:\n\n```\nlist = [2,5,7,1,3]\n```\n\n\nObjective: maximally pair each entry in the list with another entry in the list. Entries of values (m,n) can be matched iff log_base_2((m + n) / gcd(m, n)) is NOT an integer. I.e. (7,3) is a valid matching, and (1,3) is not.\n\nI'm pretty sure one way to do this would be to generate two lists, A and B, equivalent to the initial list:\n\n```\nA=B=list=[2,5,7,1,3]\n```\n\n\nAnd then treat it as a Bipartite Matching problem with the additional constraint that if A[m] matches B[n], then A[n] must also match B[m] (again, in addition to the matching constraint above). I would imagine a visualization of the resulting flow network would be horizontally symmetric (i.e. along the source-sink axis, hence the title).\n\nI know how to solve a bipartite matching problem using MaxFlow, but can't figure out how to implement this last, bolded constraint. Any help would be very, uh, helpful.\n    ", "Answer": "\r\nThe additional constraint (if ```\nA[m]```\n matches ```\nB[n]```\n then ```\nA[n]```\n must also match ```\nB[m]```\n) radically changes the nature of the problem. In fact, that constraint destroys the bipartiteness of the input graph and actually turns it into a general undirected graph. Hence, what you're looking for is an algorithm for finding a maximum matching in a general graph.\n\nThe problem can be solved using Edmonds Algorithm which exhibits a different approach from the maximum flow solution for the bipartite case (though it does use the notion of an augmenting path). The algorithm exploits the fact that bipartite matching can be easily solved and is tryig, in a way, to turn the input graph into bipartite by collapsing odd-cycles (a graph is bipartite if and only if it has no odd cycles and thus the number of odd cycles in the graph measures the extent to which the input graph is far from being bipartite). The details of how exactly the algorithm works are well explained in the link above.\n\nHere's a Python implementation of the algorithm. The algorithm is fairly efficient for sparse graphs but not very efficient for dense graphs. The density of your graph depends on how many pairs of entries ```\nm, n```\n satisfy the condition ```\n(m + n) / gcd(m, n)```\n being a power of 2. If most pairs satisfy the condition the runtime is going to be about ```\nO(n^4)```\n. In general the runtime is ```\nO(E•V^2)```\n.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum Weight / Minimum Cost Bipartite Matching Code in Python\r\n                \r\nI'm searching for Python code for maximum weight / minimum cost matching in a bipartite graph.  I've been using the general case max weight matching code in NetworkX, but am finding it too slow for my needs.  This is likely due to both the fact that the general algorithm is slower, and the fact that the NetworkX solution is implemented entirely in Python.  Ideally, I'd like to find a some Python code for the bipartite matching problem that wraps some C/C++ code, but right now, anything faster than the NetworkX implementation would be helpful.\n    ", "Answer": "\r\nHave you tried scipy implementation of the Hungarian algorithm, also known as the Munkres or Kuhn-Munkres algorithm?\n\nscipy.optimize.linear_sum_assignment\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite Matching of Array\r\n                \r\nI have arrays A and B. I have to find a maximum matching for array B, such that every index of B[i] can match with any index of A[j] if and only if A[j]!=B[i] and A[j] is not previously matched. For example:\n\n```\nA = {1 2 3 4}\nB = {2 2 3 4}\nMaximum Matching is 4 A[0]=B[3] , A[1]=B[2] , A[2]=B[1], A[3]=B[0]\n\nA = {1 1 2}\nB  = {1 1 2}\nMaximum Matching 2 A[0]=B[2] , B[1]=No Matching , A[2]=B[0]\n```\n\n\nI know this is a maximum bipartite problem but problem is length of A=B<=10^3 and A[i],B[i]<10^6. Which will time-out my bipartite solution. Is there any better solution?\n\nCode:\n\n```\npublic static boolean is_match(int curr) {\n    for(int i = 0; i < A.length; i++) {\n\n        if(A[i] != curr && !V[i]) {\n\n            V[i] = true;\n            if(P[i] < 0 || is_match(P[i])) {\n                P[i] = curr;\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```\n\n\nI call this function for every B:\n\n```\nfor(int i:B){\n    V = new boolean[n]\n    if(is_match(i)) match++;\n}\n```\n\n\nHow can I improve my solution?\n    ", "Answer": "\r\nThis problem can be visualize as a max flow problem.\n\nSo, as the condition is ```\nA[j]!=B[i] and A[j] is not previously matched```\n, so knowing whether index ```\ni```\n from ```\nA```\n matched to ```\nj```\n or ```\nk```\n in ```\nB```\n with ```\nB[j] == B[k]```\n is not important.\n\nSo, instead of represent the graph as a bipartite of ```\n2*n```\n nodes, each node represent an index in array A and B, we can represent the problem as a flow graph with one source node, one sink node and list of nodes which represent unique values of A and B, and the capacity of node ```\na```\n (which represents ```\na```\n value in A) to source node is the  amount of indexes in ```\nA```\n that has value ```\na```\n. Similarly, the capacity of node ```\nb```\n mapped to the sinking node will be equaled the number of index in B has value ```\nb```\n. Capacity between valid nodes from A to B are infinity.\n\nFor example, with array ```\nA = {1, 1, 2, 2}```\n and ```\nB = {1, 2, 2, 3, 3, 3, 3}```\n\n\nSo, we create a flow graph with a source and a sink node.\n\n\nAdditionally, for array A, we create two additional nodes, one for value 1 and one for value 2. Source node will connect to these two nodes.\nFor node B, we create three nodes, one for value 1, one for value 2, one for value 3.\nNow, source node will connect only to node from array A, with capacity equal : 2 for node represents value 1 (as there are two 1 in array A) and 2 for node represents value 2 (there are two 2 in array A).\nSink node will connect only to node from array B, with capacity:\n1 for node represents value 1 (there is only one 1 in array B); 2 for node represents value 2 (there are two 2 in array B) and 4 for node represents value 3 (there are four 3 in array B).\nConnection between valid nodes from array A to B will have infinity capacity. \n\n\nNow the rest of the job is to run a typical max flow algorithm.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Find the second maximum weighed matching in a complete bipartite graph\r\n                \r\nGiven a weighed complete bipartite graph G=(V, U, E), the maximum weighted bipartite matching problem, i.e., the assignment problem, aims to find a matching in G where the sum of edge weights is maximized. I know there are some methods (e.g., Hungarian algorithm) can solve this problem. Now, I want to solve a slightly different problem:\n\nGiven a weighed complete bipartite graph G=(V, U, E), I would like to find the maximum weighted bipartite matching and the second maximum weighted bipartite matching in G at the same time. Any ideas would be much appreciated.\n    ", "Answer": "\r\nThere is a general algorithm called Lawler-Murty which allows you to find the top K answers to combinatorial algorithms (including matching) in successive calls. It is described at https://core.ac.uk/download/pdf/82129717.pdf in the context of matching.\n\nBasically, after finding the best answer, you add constraints to the problem which create a number of sub-problems such that the answers found so far are ruled out, but all other answers will still turn up as the answer to one of the sub-problems. The second best answer will turn up as the best answer to one of the sub-problems. When you do this repeatedly you end up with a large tree of sub-problems to solve. For matching problems, you can reduce the time take to solve a sub-problem by making use of some of the work from previous problems.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Weighted Bipartite Matching covering one partition\r\n                \r\nI have a problem here, that I managed to reduce to a weighted bipartite match problem. Basically, I have a bipartite graph with partitions A and B, and a set of edges with weights. In my case, |A|~=20 and |B| =300. \n\nI want to find a set of edges which minimizes the weigths AND COVERS 'A' (each edge on A has an associated solution edge)\n\nQuestions:\n\n-Is there a special name for this kind a problem, so I can look for algorithms and solutions?\n\n-I know I can reduce it to a weighted bipartite perfect match, by adding dummy vertices on A, with infinite weigth. But I'm worried about practical performance since |B|>>|A|.\n\n-Any suggestions on Java libraries? I found this: http://algs4.cs.princeton.edu/code/. I think the 'AssignmentProblem.java' is almost what I need - (but I guess it doesn't ensure a perfect matching?)\n\nThanks in advance and sorry about the bad english.\n    ", "Answer": "\r\na) maximum weighted perfect matching\nb) ???\nc) floyd or floyd-warshall alogorithm is your friend\n\nI've found a c-implemenation in the web and also you can use edmond's blossom algorithm, too.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Recuperate maximum bipartite matching from maxFlowFordFulkerson in R\r\n                \r\nI want to find the maximum bipartite matching, so I'll use Flow Ford Fulkerson's algorithm, as explained here.\n\nBut when I implement the function, I only get the value of the maximum flow, but what interests me is the flow itself, so that I can find the matching.\n\nCan anybody help me?\n\nI used the function ```\nmaxFlowFordFulkerson```\n in R.\n    ", "Answer": "\r\nThere is no way to do that using only the output of the function you've found. Besides the value of the maximum flow, it does also provide a minimum cut, which provides some additional information but still not what you're looking for.\n\nUsing the example from the page you refer to (reproduced below for ease of reference):\n\n\n\n```\n> library(\"optrees\")\n> vertices <- 1:14\n> edges <- matrix(c(1,2,1, 1,3,1, 1,4,1, 1,5,1, 1,6,1, 1,7,1, 2,9,1, 2,10,1, 4,8,1, 4,11,1, 5,10,1, 6,11,1, 7,13,1, 8,14,1, 9,14,1, 10,14,1, 11,14,1, 12,14,1, 13,14,1), byrow = TRUE, ncol = 3)\n> maxFlowFordFulkerson(vertices, edges, source.node = 1, sink.node = 14)\n$s.cut\n[1] 1 3\n\n$t.cut\n [1]  2  4  5  6  7  8  9 10 11 12 13 14\n\n$max.flow\n[1] 5\n```\n\n\nHere, the vertices in the two partitions are 2:7 and 8:13 respectively, so this tells us that vertex 3, i.e. the second vertex from the top in the left partition, remains unmatched, but other than that it tells you nothing about the matching.\n\nIf you want to stick to ```\nigraph```\n, you can use ```\nmaximum.bipartite.matching```\n to get what you want. As this one operates on bipartite graphs directly, we don't have to mess with the auxiliary source/sink vertices at all. With the example from above:\n\n```\n> library(\"igraph\")\n> A <- matrix(c(0,1,1,0,0,0, 0,0,0,0,0,0, 1,0,0,1,0,0, 0,0,1,0,0,0, 0,0,1,1,0,0, 0,0,0,0,0,1), byrow = T, ncol = 6)\n> g <- graph.incidence(A)\n> maximum.bipartite.matching(g)\n$matching_size\n[1] 5\n\n$matching_weight\n[1] 5\n\n$matching\n [1]  8 NA  7  9 10 12  3  1  4  5 NA  6\n```\n\n\nHere, the left partition is represented by 1:6, and the right partition by 7:12. From ```\n$matching```\n, we read that the 6 vertices in the left partition are matched with 8, nothing, 7, 9, 10, and 12 respectively.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Algorithm - A variant of Maximum Bipartite Matching\r\n                \r\nI am dealing with a variant of the Maximum Bipartite Matching problem.\nThe original problem is as the following:\nThere are M job applicants and N jobs. Each applicant has a subset of jobs that he/she is interested in. Each job opening can only accept one applicant and a job applicant can be appointed for only one job. Find an assignment of jobs to applicants in such that as many applicants as possible get jobs.\n\nThe additional constraint is that:\nEach applicant belongs to a certain group. Now, instead of maximize the number of applicants, we want to maximize of number of happy groups. A happy group is a group in which all of its applicants can get a job.\nAny ideas/discussions are welcome!\n    ", "Answer": "\r\nConnection to Eternity\n\nIf you could solve this, you could have won a million pounds on the Eternity puzzle.\n\nIn this puzzle you have to fit 209 polygons onto a board.\n\nThe reduction is to have one group for each combination of piece and location.\n\nEach group has a leader who is only interested in the job that corresponds to playing his piece.\n\nEach group also has a person for each square in the tile: that person is only interested in the job of filling the corresponding square on the game board.\n\nIf you can find a solution with 209 happy groups then you have found a solution to the puzzle!\n\nConnection to Independendent set\n\nThis is NP-hard because it can be used to solve maximum independent set which is a known NP-hard problem.\n\nSuppose we have a graph in which we want to find the maximum independent set.\n\nMake a job for each edge.\n\nMake a group for each vertex.\n\nSuppose vertex x is connected to three edges a,b,c.  We would add 3 people to group x.  Each person is only interested in one job.  The first is interested in job a, the second in job b, the third in job c.\n\nFinding the maximum happy groups is then equivalent to the largest independent set.  \n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Solving a Maximum weight bipartite b-matching\r\n                \r\nMy question is regarding the Maximum Weight B-Matching problem. \n\nBipartite matching problems pair two sets of vertices in a bipartite graph. A maximum weighted bipartite matching (MWM) is defined as a matching where the sum of the values of the edges in the matching have a maximal value. A famous polynomial time algorithm for MWM is the Hungarian algorithm. \n\nWhat I am interested in is a specific maximum weighted bipartite matching known as weight bipartite B-matching problem. A weight bipartite B-matching problem (WBM) seeks to match vertices so that each vertex is matched with no more vertices than its capacity ```\nb```\n allows. \n\n\n\nThis figure (from Chen et al.) shows the WBM problem. The input graph has score 2.2, the sum of all its edge weights. The blue edges of the solution H yield the highest score, 1.6, of all sub-graphs satisfying the red degree constraints.\n\nAlthough there are a few recent works addressing the WBM problem (this and this), I cannot find any implementation of the algorithm. Does anybody know if the WBM problem already exists in any library like networkX?\n    ", "Answer": "\r\nLet's try and do this step by step, writing our own function to solve the WBM problem as specified in the question.\n\nUsing ```\npulp```\n it is not too difficult to formulate and solve a weighted bipartite matching (WBM), when we are given two sets of nodes (u and v, edge weights and vertex capacities.)\n\nIn Step 2 below, you'll find a (hopefully easy to follow) function to formulate WBM as an ILP and solve using ```\npulp.```\n Go through it to see if it helps. (You need to ```\npip install pulp```\n)\n\nStep 1: Set up the bipartite graph capacities and edge weights\n\n```\nimport networkx as nx\nfrom pulp import *\nimport matplotlib.pyplot as plt\n\nfrom_nodes = [1, 2, 3]\nto_nodes = [1, 2, 3, 4]\nucap = {1: 1, 2: 2, 3: 2} #u node capacities\nvcap = {1: 1, 2: 1, 3: 1, 4: 1} #v node capacities\n\nwts = {(1, 1): 0.5, (1, 3): 0.3,\n       (2, 1): 0.4, (2, 4): 0.1,\n       (3, 2): 0.7, (3, 4): 0.2}\n\n#just a convenience function to generate a dict of dicts\ndef create_wt_doubledict(from_nodes, to_nodes):\n\n    wt = {}\n    for u in from_nodes:\n        wt[u] = {}\n        for v in to_nodes:\n            wt[u][v] = 0\n\n    for k,val in wts.items():\n        u,v = k[0], k[1]\n        wt[u][v] = val\n    return(wt)\n```\n\n\nStep 2: Solve the WBM (formulated as an integer program)\n\nHere's some description to make the code that follows easier to understand:\n\n\nThe WBM is a variation of the Assignment problem. \nWe 'match' nodes from the RHS to the LHS. \nThe edges have weights \nThe objective is to maximize the sum of the weights of the selected edges. \nAdditional set of constraints: For each node, the number of selected edges has to be less than its 'capacity' which is specified.\nPuLP Documentation if you are not familiar with ```\npuLP```\n\n\n\n.\n\n```\ndef solve_wbm(from_nodes, to_nodes, wt):\n''' A wrapper function that uses pulp to formulate and solve a WBM'''\n\n    prob = LpProblem(\"WBM Problem\", LpMaximize)\n\n    # Create The Decision variables\n    choices = LpVariable.dicts(\"e\",(from_nodes, to_nodes), 0, 1, LpInteger)\n\n    # Add the objective function \n    prob += lpSum([wt[u][v] * choices[u][v] \n                   for u in from_nodes\n                   for v in to_nodes]), \"Total weights of selected edges\"\n\n\n    # Constraint set ensuring that the total from/to each node \n    # is less than its capacity\n    for u in from_nodes:\n        for v in to_nodes:\n            prob += lpSum([choices[u][v] for v in to_nodes]) <= ucap[u], \"\"\n            prob += lpSum([choices[u][v] for u in from_nodes]) <= vcap[v], \"\"\n\n\n    # The problem data is written to an .lp file\n    prob.writeLP(\"WBM.lp\")\n\n    # The problem is solved using PuLP's choice of Solver\n    prob.solve()\n\n    # The status of the solution is printed to the screen\n    print( \"Status:\", LpStatus[prob.status])\n    return(prob)\n\n\ndef print_solution(prob):\n    # Each of the variables is printed with it's resolved optimum value\n    for v in prob.variables():\n        if v.varValue > 1e-3:\n            print(f'{v.name} = {v.varValue}')\n    print(f\"Sum of wts of selected edges = {round(value(prob.objective), 4)}\")\n\n\ndef get_selected_edges(prob):\n\n    selected_from = [v.name.split(\"_\")[1] for v in prob.variables() if v.value() > 1e-3]\n    selected_to   = [v.name.split(\"_\")[2] for v in prob.variables() if v.value() > 1e-3]\n\n    selected_edges = []\n    for su, sv in list(zip(selected_from, selected_to)):\n        selected_edges.append((su, sv))\n    return(selected_edges)        \n```\n\n\nStep 3: Specify graph and call the WBM solver\n\n```\nwt = create_wt_doubledict(from_nodes, to_nodes)\np = solve_wbm(from_nodes, to_nodes, wt)\nprint_solution(p)\n```\n\n\nThis gives:\n\n```\nStatus: Optimal\ne_1_3 = 1.0\ne_2_1 = 1.0\ne_3_2 = 1.0\ne_3_4 = 1.0\nSum of wts of selected edges = 1.6\n```\n\n\nStep 4: Optionally, plot the graph using Networkx\n\n```\nselected_edges = get_selected_edges(p)\n\n\n#Create a Networkx graph. Use colors from the WBM solution above (selected_edges)\ngraph = nx.Graph()\ncolors = []\nfor u in from_nodes:\n    for v in to_nodes:\n        edgecolor = 'blue' if (str(u), str(v)) in selected_edges else 'gray'\n        if wt[u][v] > 0:\n            graph.add_edge('u_'+ str(u), 'v_' + str(v))\n            colors.append(edgecolor)\n\n\ndef get_bipartite_positions(graph):\n    pos = {}\n    for i, n in enumerate(graph.nodes()):\n        x = 0 if 'u' in n else 1 #u:0, v:1\n        pos[n] = (x,i)\n    return(pos)\n\npos = get_bipartite_positions(graph)\n\n\nnx.draw_networkx(graph, pos, with_labels=True, edge_color=colors,\n       font_size=20, alpha=0.5, width=3)\n\nplt.axis('off')\nplt.show() \n\nprint(\"done\")\n```\n\n\n\n\nThe blue edges are the ones that were selected for the WBM. Hope this helps you move forward.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Fast maximum bipartite matching in C or Python\r\n                \r\nIs there a fast off the shelf implementation of maximum cardinality bipartite matching in C or Python?\n\nI tried ```\nnetworkx```\n, but it is very slow. I have a two-layer graph with about 1000 nodes in each layer. The density varies. What is the time I can expect for this setting?\n\nI see this post Fast max-flow min-cut library for Python, but is there anything faster?\n    ", "Answer": "\r\nSciPy, as of version 1.4.0, contains an implementation of Hopcroft--Karp in ```\nscipy.sparse.csgraph.maximum_bipartite_matching```\n that compares favorably to NetworkX, performance-wise. The function exists in previous versions as well but then assumes a perfect matching to; this assumption is lifted in 1.4.0.\nExactly how well it does will depend on the structure of the bipartite graph, but just by taking random graphs (and ignoring the time it will take NetworkX to initialize the underlying data structures), I get around 200x performance improvements:\n```\nimport networkx as nx\nfrom scipy.sparse import rand\nfrom scipy.sparse.csgraph import maximum_bipartite_matching\n\n\nn = 5000\ngraph = rand(n, n, density=.1, format='csr', random_state=42)\nG = nx.algorithms.bipartite.from_biadjacency_matrix(graph)\n```\n\n```\n>>> %timeit maximum_bipartite_matching(graph, perm_type='column')\n8.95 ms ± 183 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n>>> %timeit nx.algorithms.bipartite.maximum_matching(G, top_nodes=range(n))\n2.01 s ± 118 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to implement a 3 dimensional bipartite matching algorithm in PHP\r\n                \r\nI need to implement a 3 dimensional bipartite matching algorithm. I have this code which is a 2 dimensional bipartite matching algorithm. I have been able to convert it to PHP and it works fine. However I just realized that in my program, I need to match courses to rooms for specific time slots. If I use the 2 dimensional bipartite matching algorithm, the rooms already assigned cannot be used for courses in other time slots. I want to be able to have a match where the same room can be used again for another course once the time slot is different. How can I modify this code to use as input a graph with three dimensions: graph[u][v][w], where u is index of course, v is index of room and w is index of time slot?\n    ", "Answer": "\r\nBipartite matching doesn't work this way. 'Bi' means two. However, you can easily convert the graph to bipartite. Instead of thinking courses on the left and rooms on the right, think it this way - courses will still remain on the left, but on the right will be combined nodes of room and timeslot. Like this - \n\n```\nCourse CSE 101------Room 301 Time 10:00 - 11:00\n              \\\n               \\\n                \\               \n                 \\\n                  \\\nCourse CSE 145------Room 301 Time 11:00 - 12:00\n              \\\n               \\\n                \\            \n                 \\\n                  \\-Room 301 Time 12:00 - 13:00 \n```\n\n\nIf you're working on a real world problem, there will be other constraints like assigning 3 class rooms for a course in a week, 2 classes of the same course shouldn't be on the same day etc. In such cases, you'd have to move away from bipartite model of the graph to general flow networks.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite matching with a twist\r\n                \r\nI'm working on a scheduling problem assigning speakers to slots, with speakers having varying availability. A maximum matching unweighed bipartite graph works for a simple solution where each speaker is assigned to a single slot. \n\nNow assume after every slot someone speaks in, an empty slot should follow (except the last). How can this be modelled?\n\nFinally, can graph theory be used when some speakers should speak for consecutive slots?\n\nThanks\n    ", "Answer": "\r\nIf\n\n\nevery speaker who is available for an odd-numbered slot is also available for the following (even-numbered) slot, and\nthere is at most one speaker who needs 2 consecutive slots, and no speakers who need 3 or more,\n\n\nthen a very simple algorithm works: use unweighted maximum bipartite matching, but only allocate odd-numbered slots, leaving every even-numbered slot empty.  If someone needs 2 consecutive slots, all that happens is that, for all pairs of slots following him/her, slot usage is swapped so that odd-numbered slots are left empty and even-numbered slots are used.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "edmonds algorithm for bipartite maximum matching\r\n                \r\nI want to find the maximum matching in a bipartite matching using edmonds algorithm. Unfortunately I am unable to get the pseudo-code. Can anyone help me?\n    ", "Answer": "\r\nThis is a late post for the benefit of future visitors. There is pseudo code available in wikipidia page\n\n\n  Edmonds Algorithm is applicable to general graphs and not just\n  bipartite graphs. The wiki page shows how the general algorithm can be\n  used for bipartite graphs.\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "to generate college time table using bipartite matching\r\n                \r\nI Have an assignment to implement using maximum bipartite matching i.e I want to generate a lecture time table for a week where the condition is i have 5 subjects and the classes commence 5 days in a week and each day there are four hours and each subject should be equally allocated i.e 4 hours. and no two subjects should have consecutive hours. \n\nCan i implement this using Maximum Bipartite Matching?\nI would like to use java.\n\nAnd  should i be using multidimensional matrix?? for subjects, hours, and days.?\n\nI want to take subjects and hours as the two subset of vertices.\nHave five iterations indicating five days.\n\nBut how can I ensure that different subset of subjects get allocated in different iteration \n    ", "Answer": "\r\nYour problem looks more to be  a constraint satisfaction problem. Good old Prolog fd-solver would not require more than 10 lines to solve this ;).\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Min Cost Flow Optimized for a Complete Bipartite Matching in Euclidean Space\r\n                \r\nThe gist is... we have two sets of points A and B. Set A and B have the same number of points n. \n\nFormal Problem:\n\nConstruct a minimum cost complete bipartite matching between points in A and B. The cost of a matching (a, b) is the distance(a, b). Does there exist an algorithm faster than O(n^3)?\n\nNotes:\n\n\nEvery point a in A and point b in B is in a matching (a, b).\nEvery point a in A or B is in exactly one matching.\nsum( distance(a, b) for every (a, b) matching ) is minimized.\n\n\nExample:\n\n\nPoint a (0,0)\nPoint b (2,0)\nPoint c (0,1)\nPoint d (-2,2)\nSet Z {a, d}\nSet Y {b, c}\n\n\nSolution:\n\nMatching 1: (a, b) (d, c)\n\nsum(distance(a, b), distance(d, c)) = 2 + sqrt(5) ~ 4.23\n\nMatching 2: (a, c) (d, b)\n\nsum(distance(a, c), distance(d, b)) = 1 + sqrt(20) ~ 5.47\n\nMatching 1 (a, b) (d, c) is the min cost complete bipartite matching!\n    ", "Answer": "\r\nYes. If the distances between vertices are taken as the weights of the edges between them, then this is a weighted bipartite graph. The task of finding the maximum/minimum weight matching is known as the assignment problem.\n\nThe problem can be solved in O(|V|(|E|+|V| log |V|) time using methods developed in Fredman and Tarjan (1987).\n\nThere are further improvements possible in Euclidean spaces. As discussed here. Notably, Vaidya (1988) presents a O(n² log n) algorithm for the L1, L2, and L∞ metrics which improves to O(n² (log n)³) for the L1 and L∞ metrics. Agarwal, Efrat, and Sharir (2006, Section 7) improve on this, giving an algorithm that runs in O(n^(2+ε)) time.\n\nYou can do even better if you sacrifice exactness. Agarwal and Varadarajan (2004) present a probabilistic algorithm which, given a value 0<ε<1, finds in O(n^(1+ε)) time a matching with expected cost within a multiplicative O(log(1/ε)) of the optimal.\n\nDo your points happen to lie on the edges of a convex polygon? Then Marcotte and Suri (1991) will be of interest: they present an exact O(n log n) algorithm for that. If the polygon is non-convex, but still simple, then you could use their O(n² log n) algorithm in the same paper.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Sample dataset(s) for a maximum bipartite matching algorithm test?\r\n                \r\nI need to test some code I've written to solve the maximum bipartite matching problem. Does anyone know of any examples of large data sets I can use to test? Ideally, these would consist of numerical representations of bipartite graph, preferably of a large size, and even more ideally, containing the solutions ahead of time so that I can check my results.\n    ", "Answer": "\r\nthe simplest way to check ur code is to submit it on the online judge system like uva. below is a problem which should be solved by maximum bipartite matching algorithm. you can have a try. all u need to do is to fit the input/output of the problem and then submit it.\n\nGopher II\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Efficient trick for maximal bipartite matching in bigger graph\r\n                \r\nProblem: We are given two arrays A & B of integers. Now in each step we are allowed to remove any 2 non co-prime integers each from the two arrays. We have to find the maximal number of pairs that can be removed by these steps.\n\nBounds:\nlength of A, B <=105 \nevery integer <=109 \nDinic's algorithm - O(V2E) \nEdmonds-karp algorithm - O(VE2) \nHopcroft–Karp algorithm - O(E sqrt(V)) \n\nMy approach up till now: This can be modeled as bipartite matching problem with two sets A and B and edges can be created between every non co-prime pair of integers from the corresponding set.\nBut the problem is that there can be O(V2) edges in the graph and most Bipartite matching and max-flow algorithms will be super slow for such large graphs.\n\nI am looking for some problem specific or mathematical optimization that can solve the problem in reasonable time. To pass the test cases i need at most O(V log V) or O(V sqrt(V)) algorithm.\n\nThanks in advance.\n    ", "Answer": "\r\nYou could try making a graph with vertices for:\n\n\nA source\nEvery element in A\nEvery prime present in any number in A\nEvery element in B\nA destination\n\n\nAdd directed edges with capacity 1 from source to elements in A, and from elements in B to destination.\n\nAdd directed edges with capacity 1 from each element x in A to every distinct prime in the prime factorisation of x.\n\nAdd directed edges with capacity 1 from each prime p to every element x in B where p divides x\n\nThen solve for max flow from source to destination.\n\nThe numbers will have a small number of factors (at most 9 because 2.3.5.7.11.13.17.19.23.29 is bigger than 10**9), so you will have at most 1,800,000 edges in the middle.\n\nThis is much fewer than the 10,000,000,000 edges you could have had before (e.g. if all 100,000 entries in A and B were all even) so perhaps your max flow algorithm has a chance of meeting the time limit.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Fast Maximum Matching Algorithm for Bipartite Graphs with Initial Guess\r\n                \r\nI am working on a bipartite matching problem where I need to solve an initial graph and then solve multiple variants of the graph where different nodes have been removed. The goal is to solve all of the variants as quickly as possible, so I would like to use the information gained from solving the original graph to solve the variants faster.  \n\nI have experience solving linear programming problems with the simplex method, which benefits from having an initial guess for the solution, but I am new to bipartite matching algorithms. \n\nIs there a bipartite matching algorithm that can utilize an initial guess to speed up the solver?\n    ", "Answer": "\r\n@sascha's mention of decremental bipartite matching should be useful; another possibly useful candidate for search keywords would be \"fully dynamic maximum mathing\".\n\nAt the end of the day, what works best will depend on what exactly is removed; the algorithms will take whatever knowledge about the problem structure you might have.\n\nBut, maybe your problem is so that an offline algorithm is good enough: If G = (V, E) is the bipartite graph you start with, and M a matching of G, and if G' = (V', E') is the graph obtained by removing some of the vertices, so that E' is what you get by removing from E all edges incident to vertices in V \\ V', then clearly M ∩ E' is a (not necessarily maximum) matching of G', and you're looking to extend that. The most common maximum matching algorithms work by extending existing matchings (primal feasible solutions if you like); this includes those based on augmenting path search, so you could take one of those with your restricted matching as an input, and maybe be good to go. A concrete classical example that's also easy to implement is the Hopcroft–Karp algorithm.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How can I find a non-perfect bipartite matching of a graph?\r\n                \r\nThat is, how can I find a bipartite matching of a graph where some vertices may not be connected to any other vertices?\n\nEDIT: One more condition, suppose the edges are also weighted, and I'd like a matching such that the total edge weight is minimized (or maximized).\n    ", "Answer": "\r\nUse Hopcroft-Karp algorithm, it does exactly what you want.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum weighted bipartite matching, constraint: ordering of each graph is preserved\r\n                \r\nLet's say I have two sets: (n_1, n_2, ...) and (m_1, m_2, ...) and a matching function match(n, m) that returns a value from 0 to 1. I want to find the mapping between the two sets such that the following constraints are met:\n\n\nEach element must have at most 1 matched element in the opposite set.\nUnmatched elements will be paired with a dummy element at cost 1\nThe sum of the match function when applied to all elements is maximal\nI am having trouble expressing this formally, but if you lined up each set parallel to each other with their original ordering and drew a line between matched elements, none of the lines would cross. E.x. [n_1<->m_2, n_2<->m_3] is a valid mapping but [n_1<->m_2, n_2<->m_1] is not.\n\n\n(I believe the first three are standard weighted bipartite matching constraints, but I specified them in case I misunderstood weighted bipartite matching)\n\nThis is relatively straight forward to do with an exhaustive search in exponential time (with respect to the size of the sets), but I'm hoping a polynomial time (ideally O((|n|*|m|)^3) or better) solution exists.\n\nI have searched a fair amount on the \"assignment problem\"/\"weighted bipartite matching\" and have seen variations with different constraints, but didn't find one that matched or that I was able to reduce to one with this added ordering constraint. Do you have any ideas on how I might solve this? Or perhaps a rough proof that it is not solvable in polynomial time (for my purposes, a reduction to NP-complete would also work)?\n    ", "Answer": "\r\nThis problem has been studied under the name \"maximum-weight non-crossing matching\". There's a simple quadratic-time dynamic program. Let M(a, b) be the value of an optimal matching on n1, …, na and m1, …, mb. We have the recurrence\n\n\n  M(0, b) = -b\n  M(a, 0) = -a\n  M(a, b) = max {M(a - 1, b - 1) + match(a, b), M(a - 1, b) - 1, M(a, b - 1) - 1}.\n\n\nBy tracing back the argmaxes, you can recover an optimal solution from its value.\n\nIf match has significantly fewer than a quadratic number of entries greater than -1, there is an algorithm that runs in time linearithmic in the number of useful entries (Khoo and Cong, A Fast Multilayer General Area Router for MCM Designs).\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to list all possible maximal bipartite matchings in R?\r\n                \r\nI have an incidence matrix:\n\n```\nQ = matrix(c(0,1,1,1,0,1,1,0,1,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0), nrow = 5, ncol=5)\nrownames(Q) = c(64,32,47,42,58)\ncolnames(Q) = c(49,64,88,31,13)\n```\n\n\nI would like to list all possible max bipartite matchings. \nUsing igraph:\n\n```\nG <- graph_from_incidence_matrix(Q)\nM <- max_bipartite_match(G)\nM$matching\n```\n\n\nwhich gives only one possible maximal matching:\n\n```\n  64   32   47   42   58   49   64   88   31   13 \n\"64\" \"49\" \"88\"   NA   NA \"32\" \"64\" \"47\"   NA   NA \n```\n\n\nFor instance, another one would be:\n\n```\n  64   32   47   42   58   49   64   88   31   13 \n\"64\" \"49\"   NA   NA   88 \"32\" \"64\" \"58\"   NA   NA \n```\n\n\nIs there a way of getting the complete list of all possible bipartite matchings in R?\n\nI have also tried with lpSolve:\n\n```\nres <- lp.assign(Q, \"max\")\n```\n\n\nbut it also only gives me one possible solution instead of all. \n\nThanks for your help!\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Algorithm design for Bipartite Matching.. children and clothing\r\n                \r\nSuppose you are a kindergarten teacher and you need to get your children dressed to go play outside. Each kid needs a hat, mittens, and a coat. Each child has preferences on which clothes they want to wear.\n\nWe have n children, a hats, b pairs of mittens, and c coats. For each child we have a list of acceptable hats, mittens, and coats. Design an algorithm to determine if it's possible to get every child dressed with a hat, mittens, and a coat.\n\nSo this problem is very clearly a bipartite matching problem. I know that bipartite graphs can be solved by attaching a source and a sink, creating edges of weight 1 and solving a typical maximum flow problem.\n\nI'm having a hard time grasping how to solve this problem knowing these things. I'm thinking that each pair (children, hats), (children, mittens), (children, coats) are their own separate bipartite graph. That's about as far as I've gotten so far, any hints or pushes in the right direction are much appreciated. \n    ", "Answer": "\r\nAs there is no relation between hats, mittens and coats, you can safely run three separate bipartite matchings for ```\n(children,hats)```\n, ```\n(children.mittens)```\n, ```\n(children,coats)```\n. Then your solution will be the minimum of these three. So if the minimum of these is equal to the total number of children then you can dress all of the children.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Matching algorithms in R (bipartite matching, Hungarian algorithm)\r\n                \r\nI wonder how to set up some example some fundamental matching procedures in R. There are many examples in various programming languages, but I have not yet found a good example for R. \n\nLet’s say I want to match students to projects and I would consider 3 alternative approaches which I came across when googling on this issue: \n\n1)  Bipartite matching case: I ask each student to name 3 projects to work on (without stating any preference ranking among those 3). \n\n```\nID  T.1 T.2 T.3 T.4 T.5 T.6 T.7\n1   1   1   1   0   0   0   0\n2   0   0   0   0   1   1   1\n3   0   1   1   1   0   0   0\n4   0   0   0   1   1   1   0\n5   1   0   1   0   1   0   0\n6   0   1   0   0   0   1   1\n7   0   1   1   0   1   0   0\n```\n\n\n--\n\n```\nd.1 <- structure(list(Student.ID = 1:7, Project.1 = c(1L, 0L, 0L, 0L, \n1L, 0L, 0L), Project.2 = c(1L, 0L, 1L, 0L, 0L, 1L, 1L), Project.3 = c(1L, \n0L, 1L, 0L, 1L, 0L, 1L), Project.4 = c(0L, 0L, 1L, 1L, 0L, 0L, \n0L), Project.5 = c(0L, 1L, 0L, 1L, 1L, 0L, 1L), Project.6 = c(0L, \n1L, 0L, 1L, 0L, 1L, 0L), Project.7 = c(0L, 1L, 0L, 0L, 0L, 1L, \n0L)), .Names = c(\"Student.ID\", \"Project.1\", \"Project.2\", \"Project.3\", \n\"Project.4\", \"Project.5\", \"Project.6\", \"Project.7\"), class = \"data.frame\", row.names = c(NA, \n-7L))\n```\n\n\n2)  Hungarian algorithm: I ask each student name 3 projects to work on WITH stating a preference ranking among those 3. As far as I understood the reasoning when applying the algorithm in this case would be something like: the better the rank the lower the “costs” to the student.\n\n```\nID  T.1 T.2 T.3 T.4 T.5 T.6 T.7\n1   3   2   1   na  na  na  na\n2   na  na  na  na  1   2   3\n3   na  1   3   2   na  na  na\n4   na  na  na  1   2   3   na\n5   2   na  3   na  1   na  na\n6   na  3   na  na  na  2   1\n7   na  1   2   na  3   na  na\n```\n\n\n--\n\n```\nd.2 <- structure(list(Student.ID = 1:7, Project.1 = structure(c(2L, 3L, \n3L, 3L, 1L, 3L, 3L), .Label = c(\"2\", \"3\", \"na\"), class = \"factor\"), \n    Project.2 = structure(c(2L, 4L, 1L, 4L, 4L, 3L, 1L), .Label = c(\"1\", \n    \"2\", \"3\", \"na\"), class = \"factor\"), Project.3 = structure(c(1L, \n    4L, 3L, 4L, 3L, 4L, 2L), .Label = c(\"1\", \"2\", \"3\", \"na\"), class = \"factor\"), \n    Project.4 = structure(c(3L, 3L, 2L, 1L, 3L, 3L, 3L), .Label = c(\"1\", \n    \"2\", \"na\"), class = \"factor\"), Project.5 = structure(c(4L, \n    1L, 4L, 2L, 1L, 4L, 3L), .Label = c(\"1\", \"2\", \"3\", \"na\"), class = \"factor\"), \n    Project.6 = structure(c(3L, 1L, 3L, 2L, 3L, 1L, 3L), .Label = c(\"2\", \n    \"3\", \"na\"), class = \"factor\"), Project.7 = structure(c(3L, \n    2L, 3L, 3L, 3L, 1L, 3L), .Label = c(\"1\", \"3\", \"na\"), class = \"factor\")), .Names = c(\"Student.ID\", \n\"Project.1\", \"Project.2\", \"Project.3\", \"Project.4\", \"Project.5\", \n\"Project.6\", \"Project.7\"), class = \"data.frame\", row.names = c(NA, \n-7L))\n```\n\n\n3)  ??? approach: This should be pretty much related to (2). However, I think it is probably a better/ fairer approach (at least in the setting of the example). The students cannot pick projects, they even don’t know about the projects, but they have rate their qualifications (1 “not existent”  to 10 “professional level”) with regards to a certain skillset. Further, the lecturer has rated the required skillset for every project. In addition to (2), a first step would be to calculate a similarity matrix and then to run the optimization routine from above. \n\n```\nPS: Programming Skills\nSK: Statistical Knowledge\nIE: Industry Experience\n\nID  PS  SK  IE\n1   10  9   8\n2   1   2   10\n3   10  2   5\n4   2   5   3\n5   10  2   10\n6   1   10  1\n7   5   5   5\n```\n\n\n--\n\n```\nd.3a <- structure(list(Student.ID = 1:7, Programming.Skills = c(10L, 1L, \n10L, 2L, 10L, 1L, 5L), Statistical.knowlegde = c(9L, 2L, 2L, \n5L, 2L, 10L, 5L), Industry.Expertise = c(8L, 10L, 5L, 3L, 10L, \n1L, 5L)), .Names = c(\"Student.ID\", \"Programming.Skills\", \"Statistical.knowlegde\", \n\"Industry.Expertise\"), class = \"data.frame\", row.names = c(NA, \n-7L))\n```\n\n\n--\n\n```\nT: Topic ID\nPS: Programming Skills\nSK: Statistical Knowledge\nIE: Industry Experience\n\nT  PS   SK  IE\n1   10  5   1\n2   1   1   5\n3   10  10  10\n4   2   8   3\n5   4   3   2\n6   1   1   1\n7   5   7   2\n```\n\n\n--\n\n```\nd.3b <- structure(list(Project.ID = 1:7, Programming.Skills = c(10L, \n1L, 10L, 2L, 4L, 1L, 5L), Statistical.Knowlegde = c(5L, 1L, 10L, \n8L, 3L, 1L, 7L), Industry.Expertise = c(1L, 5L, 10L, 3L, 2L, \n1L, 2L)), .Names = c(\"Project.ID\", \"Programming.Skills\", \"Statistical.Knowlegde\", \n\"Industry.Expertise\"), class = \"data.frame\", row.names = c(NA, \n-7L))\n```\n\n\nI would appreciate any help in implementing those 3 approaches in R. Thank you.\n\nUPDATE:\nThe following questions seem to be related, but none show how to solve it in R:\nhttps://math.stackexchange.com/questions/132829/group-membership-assignment-by-preferences-optimization-problem\nhttps://superuser.com/questions/467577/using-optimization-to-assign-by-preference\n    ", "Answer": "\r\nHere are possible solutions using bipartite matching and the Hungarian algorithm.\n\nMy proposed solution using bipartite matching might not be what you have in mind.  All the code below does is sample randomly for a specified number of iterations, after which at least one solution hopefully will have been identified.  This might require a large number of iterations and a long time with large problems.  The code below found three solutions to your example problem within 200 iterations.\n\n```\nmatrix1 <- matrix(c( 1,   1,   1,  NA,  NA,  NA,  NA,\n                    NA,  NA,  NA,  NA,   1,   1,   1,\n                    NA,   1,   1,   1,  NA,  NA,  NA,\n                    NA,  NA,  NA,   1,   1,   1,  NA,\n                     1,  NA,   1,  NA,   1,  NA,  NA,\n                    NA,   1,  NA,  NA,  NA,   1,   1,\n                    NA,   1,   1,  NA,   1,  NA,  NA), nrow=7, byrow=TRUE)\n\nset.seed(1234)\n\niters <- 200\n\nmy.match <- matrix(NA, nrow=iters, ncol=ncol(matrix1))\n\nfor(i in 1:iters) {\n\n     for(j in 1:nrow(matrix1)) {\n\n          my.match[i,j] <- sample(which(matrix1[j,] == 1), 1)\n\n     }\n}\n\nn.unique <- apply(my.match, 1, function(x) length(unique(x)))\n\nmy.match[n.unique==ncol(matrix1),]\n\n#      [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n# [1,]    3    7    4    6    1    2    5\n# [2,]    1    7    4    5    3    6    2\n# [3,]    3    5    4    6    1    7    2\n```\n\n\nHere is code for the Hungarian algorithm using package ```\nclue```\n and ```\nsolve_LSAP()```\n as @jackStinger suggested.  For this to work I had to replace the missing observations and I arbitrarily replaced them with 4.  Person 5 did not get their first choice and Person 7 did not get any of their three choices.\n\n```\nlibrary(clue)\n\nmatrix1 <- matrix(c( 3,   2,   1,   4,   4,   4,   4,\n                     4,   4,   4,   4,   1,   2,   3,\n                     4,   1,   3,   2,   4,   4,   4,\n                     4,   4,   4,   1,   2,   3,   4,\n                     2,   4,   3,   4,   1,   4,   4,\n                     4,   3,   4,   4,   4,   2,   1,\n                     4,   1,   2,   4,   3,   4,   4), nrow=7, byrow=TRUE)\n\nmatrix1\n\nsolve_LSAP(matrix1, maximum = FALSE)\n\n# Optimal assignment:\n# 1 => 3, 2 => 5, 3 => 2, 4 => 4, 5 => 1, 6 => 7, 7 => 6\n```\n\n\nHere is a link to a site showing how the Hungarian algorithm works: http://www.wikihow.com/Use-the-Hungarian-Algorithm\n\nEDIT: June 5, 2014\n\nHere is my first stab at optimizing the third scenario.  I randomly assign each student to a project, then calculate the cost for that set of assignments.  Cost is calculated by finding the difference between a student's skill set and the project's required skills.  The absolute values of those differences are summed to give a total cost for the seven assignments.\n\nBelow I repeat the process 10,000 times and identify which of those 10,000 assignments results in the lowest cost.\n\nAn alternative approach would be to do an exhaustive search of all possible student-project assignments.\n\nNeither the random search nor the exhaustive search is likely what you had in mind.  However, the former will give an approximate optimal solution and the latter would give an exact optimal solution.\n\nI might return to this problem later.\n\n```\nstudents <- matrix(c(10,   9,   8,\n                      1,   2,  10,\n                     10,   2,   5,\n                      2,   5,   3,\n                     10,   2,  10,\n                      1,  10,   1,\n                      5,   5,   5), nrow=7, ncol=3, byrow=TRUE)\n\nprojects <- matrix(c(10,   5,    1,\n                      1,   1,    5,\n                     10,  10,   10,\n                      2,   8,    3,\n                      4,   3,    2,\n                      1,   1,    1,\n                      5,   7,    2), nrow=7, ncol=3, byrow=TRUE)\n\niters <- 10000\n\n# col = student, cell = project\nassignments <- matrix(NA, nrow=iters, ncol=nrow(students))\n\nfor(i in 1:iters) {\n      assignments[i,1:7] <- sample(7,7,replace=FALSE)\n}\n\ncost <- matrix(NA, nrow=iters, ncol=nrow(students))\n\nfor(i in 1:iters) {\n\n     for(j in 1:nrow(students)) {\n\n          student <- j\n          project <- assignments[i,student]\n\n          student.cost <- rep(NA,3)\n\n          for(k in 1:3) {     \n\n               student.cost[k] <- abs(students[student,k] - projects[project,k])\n\n          } \n\n          cost[i,j] <- sum(student.cost)\n\n     }\n\n}\n\n\ntotal.costs <- rowSums(cost)\n\nassignment.costs <- cbind(assignments, total.costs)\nhead(assignment.costs)\n\nassignment.costs[assignment.costs[,8]==min(assignment.costs[,8]),]\n\n#                    total.costs\n# [1,] 3 2 1 4 5 6 7          48\n# [2,] 3 2 1 6 5 4 7          48\n# [3,] 3 2 1 6 5 4 7          48\n\n# student 1, project 3, cost = 3\n# student 2, project 2, cost = 6\n# student 3, project 1, cost = 7\n# student 4, project 4, cost = 3\n# student 5, project 5, cost = 15\n# student 6, project 6, cost = 9\n# student 7, project 7, cost = 5\n\n3+6+7+3+15+9+5\n\n# [1] 48\n```\n\n\nEDIT: June 6, 2014\n\nHere is the exhaustive search. There are only 5040 possible ways to assign projects to the seven students.  This search returns four optimal solutions:\n\n```\nstudents <- matrix(c(10,   9,   8,\n                      1,   2,  10,\n                     10,   2,   5,\n                      2,   5,   3,\n                     10,   2,  10,\n                      1,  10,   1,\n                      5,   5,   5), nrow=7, ncol=3, byrow=TRUE)\n\nprojects <- matrix(c(10,   5,    1,\n                      1,   1,    5,\n                     10,  10,   10,\n                      2,   8,    3,\n                      4,   3,    2,\n                      1,   1,    1,\n                      5,   7,    2), nrow=7, ncol=3, byrow=TRUE)\n\nlibrary(combinat)\n\nn <- nrow(students)\n\nassignments <- permn(1:n)\nassignments <- do.call(rbind, assignments)\ndim(assignments)\n\n# column of assignments = student\n# row of assignments = iteration\n# cell of assignments = project\n\ncost <- matrix(NA, nrow=nrow(assignments), ncol=n)\n\nfor(i in 1:(nrow(assignments))) {\n     for(student in 1:n) {\n\n          project      <- assignments[i,student]\n          student.cost <- rep(NA,3)\n\n          for(k in 1:3) {     \n               student.cost[k] <- abs(students[student,k] - projects[project,k])\n          } \n\n          cost[i,student] <- sum(student.cost)\n     }\n}\n\n\ntotal.costs <- rowSums(cost)\n\nassignment.costs <- cbind(assignments, total.costs)\nhead(assignment.costs)\n\nassignment.costs[assignment.costs[,(n+1)]==min(assignment.costs[,(n+1)]),]\n\n                   total.costs\n[1,] 3 2 5 4 1 6 7          48\n[2,] 3 2 5 6 1 4 7          48\n[3,] 3 2 1 6 5 4 7          48\n[4,] 3 2 1 4 5 6 7          48\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum weights bipartite matching with weighted vertices\r\n                \r\nI have a bipartite graph with two sets of vertices A and B. Edges have no weights. However, vertices in one of the sets(say set B) have positive weights assigned to them (wb1,wb2...) \nI want to find a matching in this bipartite graph so as to maximize the sum of weights of vertices matched from set B.\n\nAfter an extensive online search, this is what I have come up with : Assign weight wbi to all edges incident on vertex bi and run the Hungarian algorithm. \nIs there a more efficient way to look at this problem, since it's different from weighted maximum matching (here vertices have weights as opposed to edges)\n\nIf my language is not clear, feel free to edit. Thank you.\n    ", "Answer": "\r\nIf an improvement from O(V^3) to O(V E) and a simpler algorithm is worth it (it isn't asymptotically for the densest graphs), you could exploit the matroid structure of matchings as follows. Instantiate Ford--Fulkerson by repeatedly choosing a path to an unmatched vertex in B whose weight is as large as possible.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum weighted bipartite matching _with_ directed edges\r\n                \r\nI know various algorithms to compute the maximum weighted matching of weighted, undirected bipartite graphs (i.e. the assignment problem):\n\nFor instance ... The Hungarian Algorithm, Bellman-Ford or even the Blossom algorithm (which works for general, i.e. not bipartite, graphs).\n\nHowever, how can I compute the maximum weighted matching if the edges of the bipartite graph are weighted and directed?\n\nI would appreciate pointers to algorithms with polinomial complexity or prior transformations to make the graph undirected so that I could apply any of the aforementioned algorithms.\n\nEdit: note that the matching should maximize the weight of the edges, that's why having directed edges makes a difference (A->B can have a totally different weight than B->A). \n\nAdmittedly, if I was maximizing cardinality, the directed edges wouldn't make a difference and I could apply any of the well-known algorithms to maximize cardinality: Hopcroft–Karp, Maximum Network Flow ....\n\nEdit 2: Since matching is a term normally applied to undirected graphs, let me clarify what I exactly mean by matching in this question: a set of directed edges that do not share start or end vertices. More formally, if U->V and U'->V' are part of the matching, then V /= U' and V' /= U.\n    ", "Answer": "\r\ndfb's comment is correct, for any two vertices A, B you can discard the cheaper of the two edges AB and BA.\n\nThe proof is a one-liner: \n\nTheorem: A maximum matching M never contains the cheaper edge of AB and BA for any two vertices A,B. \n\nProof: Let M be a maximum matching. Suppose AB is in M and is cheaper than BA. Define M' = M - {AB} + {BA}. M' is clearly still a matching, but it's more expensive. That contraditcs the assumption that M was a maximum matching.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Weighted bipartite matching\r\n                \r\nI'm aware of there's a lot of similar topics. But most of them left me some doubts in my case. What I want to do is find perfect matching (or as close to perfect as possible in case there's no perfect matching of course) and then from all of those matchings where you are able to match k out of n vertexes (where k is highest possible), I want to choose the highest possible total weight.\nSo simply put what I'm saying is following priority:\n\n\nMatch as many vertexes as possible\nBecause (non weighted) maximum matching in most cases is unambiguous, I want choose the one that have the biggest sum of weights on edges. If there are several of them with same weight it doesn't matter which would be chosen.\n\n\nI've heard about Ford-Fulkerson algorithm. Is it working in the way I describe it or I need other algorithm?\n    ", "Answer": "\r\nIf you're implementing this yourself, you probably want to use the Hungarian algorithm.  Faster algorithms exist but aren't as easy to understand or implement.\n\nFord-Fulkerson is a maximum flow algorithm; you can use it easily to solve unweighted matching.  Turning it into a weighted matcing algorithm requires an additional trick; with that trick, you wind up with the Hungarian algorithm.\n\nYou can also use a min-cost flow algorithm to do weighted bipartite matching, but it might not work quite as well.  There's also the network simplex method, but it seems to be mostly of historical interest.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Hungarian Algorithm using Maximum Bipartite Matching for Assignment\r\n                \r\nI am trying to understand the O(N^4) explanation for the assignment problem by reading the topcoder article [1] . Specifically, i am unable to comprehend how the default O(N^5) procedure can be converted to O(N^4). Please read below for details:\n\nAssume for the assignment problem, a complete bipartite graph of N vertices in both sets of vertices, and a edge cost from vertex i to vertex j, denoted by cost[i][j] that is say, integral, non-negative. We are trying to minimize the overall sum of weights of the perfect matching (assuming there is one)\n\nQuoting the O(n^4) algorithm from [1]\n\n```\nStep 0)\n    A. For each vertex from left Set (workers) find the minimal outgoing edge and subtract its weight from all weights connected with this vertex. This will introduce 0-weight edges (at least one).\n    B. Apply the same procedure for the vertices in the right Set (jobs).\n\nStep 1)\n    A. Find the maximum matching using only 0-weight edges (for this purpose you can use max-flow algorithm, augmenting path algorithm, etc.).\n    B. If it is perfect, then the problem is solved. Otherwise find the minimum vertex cover V (for the subgraph with 0-weight edges only), the best way to do this is to use Konig’s graph theorem.\n\nStep 2) \n    Let delta = min(cost[i][j]) for i not belonging to vertex cover, and j not belonging to vertex cover.\n    Then, modify the cost matrix as follows:\n        cost[i][j] = cost[i][j] - delta   for i not belonging to vertex cover, and j not belonging to vertex cover.\n        cost[i][j] = cost[i][j] + delta   for i belonging to vertex cover, and j belonging to vertex cover.\n        cost[i][j] = cost[i][j]           otherwise\n\nStep 3) \n    Repeat Step 1) until problem is solved\n```\n\n\nI understand that the above algorithm is O(n^5) if implemented as-is, since the maximum matching on a bipartite graph takes O(n^3) if we use, say, breadth first search, and there are O(n^2) iterations of the overall algorithm since each edge becomes 0 in an iteration.\n\nBut, [1] also mentions:\n\n\n  finding the maximum matching in step 1 on each iteration will cause the algorithm to become O(n^5). In order to avoid this, on each step we can just modify the matching from the previous step, which only takes O(n^2) operations, making the overall algorithm O(n^4)\n\n\nThis is the part i do not understand. How do we modify the matching from the previous epoch, thereby taking only O(N^2) operations, instead of the normal O(N^3) iterations for maximum bipartite matching?\n\nI referred [2] as well, but in that solution as well, there is only a comment that says:\n\n\n  // to make O(n^4), start from previous solution\n\n\nI fail to understand how to convert the O(N^5) to O(N^4), and what exactly starting from previous solution mean?\nCan someone explain using the algorithm referenced in [1], how to modify it to run in O(N^4)? Pseudo-code would be most welcome.\n\n[1] https://www.topcoder.com/community/data-science/data-science-tutorials/assignment-problem-and-hungarian-algorithm/ \n\n[2] http://algs4.cs.princeton.edu/65reductions/Hungarian.java\n\nThanks in Advance.\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Directed maximum weighted bipartite matching allowing sharing of start/end vertices\r\n                \r\nLet G (U u V, E) be a weighted directed bipartite graph (i.e. U and V are the two sets of nodes of the bipartite graph and E contains directed weighted edges from U to V or from V to U). Here is an example:\n\n\n\nIn this case: \n\n```\nU = {A,B,C} \nV = {D,E,F} \nE = {(A->E,7), (B->D,1), (C->E,3), (F->A,9)} \n```\n\n\nDefinition: DirectionalMatching (I made up this term just to make things clearer): set of directed edges that may share the start or end vertices. That is, if U->V and U'->V' both belong to a DirectionalMatching then V /= U' and V' /= U but it may be that U = U' or V = V'.\n\nMy question: How to efficiently find a DirectionalMatching, as defined above, for a bipartite directional weighted graph which maximizes the sum of the weights of its edges? \n\nBy efficiently, I mean polynomial complexity or faster, I already know how to implement a naive brute force approach.\n\nIn the example above the maximum weighted DirectionalMatching is: {F->A,C->E,B->D}, with a value of 13.\n\nFormally demonstrating the equivalence of this problem to any other well known problem in graph theory would also be valuable.\n\nThanks!\n\nNote 1:  This question is based on Maximum weighted bipartite matching _with_ directed edges but with the extra relaxation that it is allowed for edges in the matching to share the origin or destination. Since that relaxation makes a big difference, I created an independent question.\n\nNote 2: This is a maximum weight matching. Cardinality (how many edges are present) and the number of vertices covered by the matching is irrelevant for a correct result. Only the maximum weight matters.\n\nNote 2: During my research to solve the problem I found this paper, I think it would be helpful to others trying to find a solution: Alternating cycles and paths in edge-coloured\nmultigraphs: a survey\n\nNote 3: In case it helps, you can also think of the graph as its equivalent 2-edge coloured undirected bipartite multigraph. The problem formulation would then turn into: Find the set of edges without colour-alternating paths or cycles which has maximum weight sum.\n\nNote 4: I suspect that the problem might be NP-hard, but I am not that experienced with reductions so I haven't managed to prove it yet.\n\nYet another example: \n\nImagine you had \n\n4 vertices: ```\n{u1, u2}```\n ```\n{v1, v2}```\n \n\n4 edges: ```\n{u1->v1, u1->v2, u2->v1, v2->u2}```\n \n\nThen, regardless of their weights, ```\nu1->v2```\n and ```\nv2->u2```\n cannot be in the same DirectionalMatching, neither can ```\nv2->u2```\n and ```\nu2->v1```\n. However ```\nu1->v1```\n and ```\nu1->v2```\n can, and so can ```\nu1->v1```\n and ```\nu2->v1```\n.\n    ", "Answer": "\r\nDefine a new undirected graph ```\nG'```\n from ```\nG```\n as follows.\n\n\n```\nG'```\n has a node ```\n(A, B)```\n with weight ```\nw```\n for each directed edge ```\n(A, B)```\n with weight ```\nw```\n in ```\nG```\n\n```\nG'```\n has undirected edge ```\n((A, B),(B, C))```\n if (A, B) and (B, C) are both directed edges in G\n\n\nhttp://en.wikipedia.org/wiki/Line_graph#Line_digraphs\n\nNow find a maximal (weighted) independent vertex set in ```\nG'```\n.\n\nhttp://en.wikipedia.org/wiki/Vertex_independent_set\n\nEdit: stuff after this point only works if all of the edge weights are the same - when the edge weights have different values its a more difficult problem (google \"maximum weight independent vertex set\" for possible algorithms)\n\nTypically this would be an NP-hard problem. However, ```\nG'```\n is a bipartite graph -- it contains only even cycles. Finding the maximal (weighted) independent vertex set in a bipartite graph is not NP-hard.\n\nThe algorithm you will run on ```\nG'```\n is as follows.\n\n\nFind the connected components of ```\nG'```\n, say ```\nH_1, H_2, ..., H_k```\n\nFor each ```\nH_i```\n do a 2-coloring (say red and blue) of the nodes. The cookbook approach here is to do a depth-first search on ```\nH_i```\n alternating colors. A simple approach would be to color each vertex in ```\nH_i```\n based on whether the corresponding edge in ```\nG```\n goes from ```\nU```\n to ```\nV```\n (red) or from ```\nV```\n to ```\nU```\n (blue).\nThe two options for which nodes to select from ```\nH_i```\n are either all the red nodes or all the blue nodes. Choose the colored node set with higher weight. For example, the red node set has weight equal to ```\nH_i.nodes.where(node => node.color == red).sum(node => node.w)```\n. Call the higher-weight node set ```\nN_i```\n.\nYour maximal weighted independent vertex set is now ```\nunion(N_1, N_2, ..., N_k)```\n.\n\n\nSince each vertex in ```\nG'```\n corresponds to one of the directed edges in ```\nG```\n, you have your maximal DirectionalMatching.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum bipartite graph (1,n) \"matching\"\r\n                \r\nI have a bipartite graph. I am looking for a maximum (1,n) \"matching\", which means that each vertex from partitation A has n associated vertices from partition B. \n\nThe following figure shows a maximum (1,3) matching in a graph. Edges selected for the matching are red and unselected edges are black.\n\nSee figure http://www.freeimagehosting.net/uploads/9a8df2d97c.gif\n\nThis differs from the standard bipartite matching problem where each vertex is associate with only one other vertex, which could be called (1,1) matching with this notation.\n\nIf the matching cardinality (n) is not enforced but is an upper bound (vertices from A can have 0 < x <= n associated vertices from B), then the maximum matching can be found easily by transforming the graph to a flow network and finding the max flow. However, this does not guarantee that the maximum number of vertices from A will have n associated pairs from B.\n    ", "Answer": "\r\nThis is NP-hard, reduction from maximum independent set problem. For any graph ```\nG```\n you can construct (in polynomial time) an instance of your problem such that:\n\n\nVertices in A represent vertices of ```\nG```\n\nEach vertex of A is connected to exactly n vertices from B\nAny two vertices of A have a common neighbour in B if and only if they are connected in ```\nG```\n. For this to be always possible, pick n=Δ(G). \n\n\nNow the maximum 'matching' in the instance maps back to maximum independent set in ```\nG```\n.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum Bipartite Matching C++\r\n                \r\nI'm solving a matching problem with two ```\nvectors```\n of a ```\nclass```\n\n\n```\nclass matching\n{\npublic:\n    int n;\n    char match;\n};\n```\n\n\nThis is the algorithm I'm trying to implement:\n\n```\nint augment(vector<matching> &left, vector<matching> &right)\n{\n   while(there's no augmenting path)\n     if(condition for matching)\n        <augment>\n  return \"number of matching\";\n}\n```\n\n\nFor the rough matching, if ```\nleft[i]```\n matches with ```\nright[j]```\n, then ```\nleft[i].n = j```\n, ```\nleft[i].match ='M'```\n , ```\nright[j].n = i```\n and ```\nright[j].match = 'M'```\n and the unmatched ones have members ```\nn = -1```\n and ```\nmatch = 'U'```\n\n\nWhile finding the augmenting paths, if one exists for another (i, j), then we change the member ```\nmatch```\n of the one being unmatched from ```\n'M'```\n to ```\n'U'```\n  and its ```\nn = -1```\n  and the two matched with the augmenting path have their members ```\nmatch```\n changed to 'A' while we change their members ```\nn```\n according to their indices.\n\nI don't know if this is the right approach to solving this, this is my first attempt on  maximum matching and I've read a lot of articles and watched tutorials online and I can't get my 'code' to function appropriately.\n\nI do not need a code, I can write my code. I just want to understand this algorithm step by step. If someone can give me an algorithm like the one I was trying above, I would appreciate it. Also, if I have been going the wrong direction since, please correct me.\n    ", "Answer": "\r\nI am not sure if you are finding the augmenting paths correctly. I suggest the following approach.\n\n\nFind an initial matching in a greedy way. To obtain this we travel through every vertex in the left side and greedily try to match it with some free (unmatched) vertex on the right side.\nTry to find an augmenting path P in the graph. For this we need to do a          breadth-first search starting from all the free vertices on the left side and alternating through matched and unmatched edges in the search. (i.e. the second level contains all the right side vertices adjacent to level-1\n       vertices, the third level contains all the left side vertices that are\n       matched to level-2 vertices, the fourth level contains all the right side\n       vertices adjacent to level-3 vertices etc). We stop the search when we\n       visit a free vertex in any future level and compute the augmenting path P\n       using the breadth-first search tree computed so far.\nIf we can find an augmenting path P in the previous step:  Change the matched and unmatched edges in P to unmatched and matched edges respectively and goto step 2.\nElse: The resulting matching obtained is maximum.\n\n\nThis algorithm requires a breadth-first search for every augumentation and so it's worst-case complexity is ```\nO(nm)```\n. Although Hopcroft-Karp algorithm can perform multiple augmentations for each breadth-first search and has a better worst-case complexity, it\nseems (from the Wikipedia article) that it isn't faster in practice. \n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite matchings in multi-graphs\r\n                \r\nI am trying to find literature for a combinatorial optimization problem, in order to prove the NP-hardness (?) of another problem by reduction. The problem could be defined as a maximum weighted matching (assignment) problem in a k-regular complete balanced weighted bipartite multi-graph with integer weights. I know that it can be reduced to a known problem but I can't find a solution. I would appreciate it if someone gave me a hint.\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Fast Maximum Matching Algorithm for Bipartite Graphs\r\n                \r\nI am trying to solve the following problem but my algorithm is too slow. That's because I am using Edmonds - Karp algorithm to find maximum flow which when applied to bipartite graphs gives maximum matching as well. It's running time is n^5. I would like to know any faster algorithms to solve this problem (for bipartite graphs specifically). One algorithm that I am currently studying is Relabel to Front which is n^3.\n    ", "Answer": "\r\nI write bipartite matching using dinitz's algorithm. Also there is a theorem that for the graphs of the type of the maximum bipartite matching problems it has the same complexity as relabel to front(and it is way easier to implement).\n\n\n  In networks arising during the solution of bipartite matching problem,\n  the number of phases is bounded by O(\\sqrt{V}), therefore leading to\n  the O(\\sqrt{V} E) time bound. The resulting algorithm is also known as\n  Hopcroft–Karp algorithm. More generally, this bound holds for any unit\n  network — a network in which each vertex, except for source and sink,\n  either has a single entering edge of capacity one, or a single\n  outgoing edge of capacity one, and all other capacities are arbitrary\n  integers.\n\n\nUnfortunately the wikipedia article on the algorithm is way not enough to implement it and I could not find any better resource online. I have my own implementation, but I have created it using guidance from others in my university a long time ago.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite graph maximum matching\r\n                \r\nI am new to graphs. I have two sets in a bipartite graph. I need to find unique matching of all the possible combinations. So I thought I use Hopcroft-Karp to find maximum matching. Being a newbie I thought I would get the resulting matching graph but all it tells me is 42. Ahhh that really helps. I don't need to know how many matchings there are I need to know the unique matchings themselfs.\n\nAm I missing something? How do I get the resulting matching?\n    ", "Answer": "\r\nI diden't check the datastructures generated by the Hopcroft-Karp match function, only the retrun value. The return value is the number of matchings. However there was also a self.pair dictionary in the python code, the pair dictionary contains the matchings from \"both\" sides, which answers my question.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "bipartite graph matching to match two sets\r\n                \r\nI'm a newbie to ```\nigraph```\n package in R. I have two sets ```\nA```\n and ```\nB```\n, each with ```\nN```\n vertices ```\n(A1, A2, ..., AN)```\n and ```\n(B1, B2, ..., BN)```\n. There is an edge between every element of ```\nA```\n to every element of ```\nB```\n, and I have a function ```\nfWgt(Ai, Bj)```\n that returns the weights of the edge between ```\nAi```\n and ```\nBj```\n. \n\nI have been trying to use the ```\nigraph```\n package in R to do a weighted maximum bipartite matching, but I haven't been able to formulate the problem as per the ```\nigraph```\n package. For instance, in the example given for ```\nmaximum.bipartite.matching```\n function in the ```\nigraph```\n package:\n\n```\nUsage: \n\nmaximum.bipartite.matching(graph, types = NULL, weights = NULL,\n   eps = .Machine$double.eps) \n\nExample: \n\ng2 <- graph.formula( a-b-c-d-e-f-g )\nV(g2)$type <- rep(c(FALSE,TRUE), length=vcount(g2))\nstr(g2, v=TRUE)\nmaximum.bipartite.matching(g2)\n```\n\n\nI couldn't figure out how to reformulate my problem (sets ```\nA```\n, ```\nB```\n, edges by ```\nfWgt```\n function) using ```\ngraph.formula```\n? The ```\nstr```\n function in the example appears to set the edges, but what would be the equivalent of the ```\nstr```\n function for my case?\n\n* EDIT *\n\nThanks for both your replies. I can only select one on SO. \n    ", "Answer": "\r\nI'm not familiar with the ```\nmaximum.bipartite.matching```\n function in the ```\nigraph```\n package, but you can solve this as an assignment problem with the ```\nlp.assign```\n function in the ```\nlpSolve```\n package:\n\n```\nlibrary(lpSolve)\nset.seed(144)\n# For example, generate random weights\nfWgt <- function(Ai, Bj) runif(1)\nN <- 10\nwts <- sapply(1:N, function(col) sapply(1:N, function(row) fWgt(row, col)))\nres <- lp.assign(wts, \"max\")\nres$solution\n#       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#  [1,]    0    0    0    0    0    0    0    1    0     0\n#  [2,]    0    0    0    0    0    0    1    0    0     0\n#  [3,]    0    0    0    0    0    0    0    0    0     1\n#  [4,]    0    0    0    1    0    0    0    0    0     0\n#  [5,]    0    0    0    0    0    0    0    0    1     0\n#  [6,]    0    0    1    0    0    0    0    0    0     0\n#  [7,]    0    0    0    0    0    1    0    0    0     0\n#  [8,]    1    0    0    0    0    0    0    0    0     0\n#  [9,]    0    1    0    0    0    0    0    0    0     0\n# [10,]    0    0    0    0    1    0    0    0    0     0\nres$objval\n# [1] 8.557704\n```\n\n\nIn this solution, the node 1 from ```\nA```\n is assigned to node 8 from ```\nB```\n, node 2 from ```\nA```\n is assigned to node 7 from ```\nB```\n, etc.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How do I complete this BiPartite Matching program?\r\n                \r\nI'm working on an assignment for class where I have to read an adjacency matrix and output the bipartite matches in Java. I've been given two methods to fill out to accomplish this, and I've managed to get it working for one use case, but I'm having some trouble making it work for the other two. I will paste my source code below. There are 3 test cases at the beginning of the program with the expected output of each shown at the end. \n\nI need to implement the matrix as a 2D character array. The problem I'm having seems to be with the backtracking portion of it. The second test case returns the correct result. If someone could help me understand what I'm doing wrong I would greatly appreciate it. My process for finding matches is:\n\n\nBegin on the last row\nIterate through each column\nIf the column is marked Y and the column is not currently taken (marked 'T'), then mark the column as taken 'T'.\nCall method recursively for the next row\nTraverse the matrix, display matches\n\n```\npublic class BiPartiteMatch\n{\n// **************** main  ****************\npublic static void main(String[] args)\n{\n    System.out.println(\"Case 1: No matching exists. \\n\");\n\n    //                     a    b    c    d    e    No matching A, C, E\n    //                    -----------------------   will only take a & d \n    char [][]M = { /*E*/ {'y', 'n', 'n', 'y', 'n'},\n                   /*D*/ {'n', 'y', 'n', 'y', 'n'},\n                   /*C*/ {'y', 'n', 'n', 'y', 'n'},\n                   /*B*/ {'y', 'n', 'y', 'y', 'y'},\n                   /*A*/ {'y', 'n', 'n', 'y', 'n'} };\n\n\n    System.out.println(\"Case 2: Matching with no backtracking needed. \\n\"); \n\n    //                     a    b    c    d    e    Matching with no \n    //                    -----------------------   backtracking needed\n    char [][]M = { /*E*/ {'y', 'n', 'n', 'y', 'y'},\n                   /*D*/ {'n', 'y', 'n', 'y', 'n'},\n                   /*C*/ {'n', 'y', 'y', 'n', 'n'},\n                   /*B*/ {'y', 'n', 'y', 'n', 'n'},\n                   /*A*/ {'n', 'y', 'n', 'n', 'y'} };\n\n\n    System.out.println(\"Case 3: Matching with backtracking. \\n\");\n\n    //                     a    b    c    d    e    Matching with \n    //                    -----------------------   backtracking\n    char [][]M = { /*E*/ {'n', 'y', 'n', 'n', 'y'},\n                   /*D*/ {'y', 'n', 'y', 'n', 'n'},\n                   /*C*/ {'n', 'y', 'y', 'n', 'n'},\n                   /*B*/ {'n', 'y', 'n', 'y', 'n'},\n                   /*A*/ {'y', 'n', 'n', 'y', 'y'} };\n\n\n if (findMatch(M, M.length-1)) // Find matches starting with the last row\n     displayMatches(M); \n else\n     System.out.println(\"There is no matching.\");         \n\n}// end main\n\n\n\n// **************** recursive findMatch  ****************\npublic static boolean findMatch(char [][]M, int myRow)\n{           \n        if(myRow < 0)\n            return false;            \n\n        for(int c = 0; c < M.length; c++)\n        {\n            if(M[myRow][c] == 'y' && !isTaken(M, myRow, c))\n            {\n                M[myRow][c] = 't';\n                break;\n            }\n        }\n\n        findMatch(M, myRow-1);\n\n        return true;\n\n}// end findMatch      \n\n\n// **************** isTaken  ******************\n// *******is this column already taken? ********\npublic static boolean isTaken(char [][]M, int row_Im_In, int col_Im_In)\n{\n        for(int r = row_Im_In+1; r < M.length; r++)\n        {\n            if(M[r][col_Im_In] == 't')\n                return true;\n        }\n\n        return false;\n\n}// end isTaken\n\n\n// **************** displayMatches  ****************\npublic static void displayMatches(char [][]M)\n{\n    final char []MatchFrom = {'E', 'D', 'C', 'B', 'A'};\n    final char []MatchTo   = {'a', 'b', 'c', 'd', 'e'};\n\n            for(int r = M.length-1; r > -1; r--)\n            {\n                for(int c = 0; c < M.length; c++)\n                {\n                    if(M[r][c] == 't')\n                    {\n                        System.out.println(MatchFrom[r] + \" matches to \" + MatchTo[c]);\n                    }\n                }\n            }\n\n\n}// end displayMatches\n\n}// end class declaration\n```\n\n\n\nExpected Results:\n\n```\nCase 1: No mathing exists. \n\nThere is no matching.\n\n\nCase 2: Matching with no backtracking needed. \n\nA matches to b\nB matches to a\nC matches to c\nD matches to d\nE matches to e\n\n\nCase 3: Matching with backtracking. \n\nA matches to a\nB matches to d\nC matches to b\nD matches to c\nE matches to e\n```\n\n    ", "Answer": "\r\nYou need to replace findMatch with something like this:\n\n```\npublic static boolean findMatch(char [][]M, int myRow)\n{           \n        if(myRow < 0)\n            return true;            \n\n        for(int c = 0; c < M.length; c++)\n        {\n            if(M[myRow][c] == 'y' && !isTaken(M, myRow, c))\n            {\n                M[myRow][c] = 't';\n                if (findMatch(M, myRow-1))\n                    return true;\n                M[myRow][c] = 'y';\n            }\n        }\n        return false;\n\n}\n```\n\n\nat the moment, your code will only attempt to find the first possible match for each element.  \n\nTo do proper backtracking you need to call the recursive function from inside the loop, then if it fails to find a complete match you need to test the next position.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "What should I use to implement weighted bipartite matching algorithm in c++?\r\n                \r\nI have a project, it asks me to distribute the courses to the students.All students asks for some of courses but they are only allowed to get some number of them(it could be what they demand,less than it or just 0),all the courses have quotas and i need to find whether the perfect match  (all the quotas are full-filled and students got what they are allowed to) exists or not- if exists the output of that matching.\n\nI just get the input and stored it in objects so far.There is a time restriction in the project,what i don't know is where to start.Any suggestions or method for this project?\n\nI think i should implement bipartite matching algorithm.I am new in c++,so do I need to implement both node class and edge class ? Or should I use adjacency list ? Which one is faster in running ?\n\nFor example , a student asks for lessons numbered 3,4 and 5 but he is allowed to take 2 lessons, so algorithm should give 2 of these choices if there is perfect matching possibility.\n\nWhat i imagined by bipartite problem was this but i think it is hard to implement this.\nhttps://i.stack.imgur.com/wtJ6o.jpg\n\n```\n1.student wants 3 ,4 system allows him to take 2 lessons \n2.student wants 1,2,3,4 system allows him to take 3 lessons \n3.student wants 1,2,3,4 system allows him to take 2 lessons \n4.student wants 1,3,5 system allows him to take 2 lessons\n5.student wants 2,5 system allows him to take 1 lessons\n\n1.lesson's quota = 2\n2.lesson's quota = 1\n3.lesson's quota = 2\n4.lesson's quota = 3\n5.lesson's quota = 2\n\nI just wrote this ,this might not be the best example.\nOne possible solution is = 1 -> (3,4) 2->(1,2,4) 3->(3,4) 4->(1,5) 5->(5)\nAnother is =  1 -> (3,4) 2->(1,2,4) 3->(1,4) 4->(3,5) 5->(5)\n```\n\n\nthere might be more , I don't know.\n\n(student -> lessons)\n    ", "Answer": "\r\nSince one student can be assigned more than one course, I don't think that the problem can be solved by simple maximal bipartite matching algorithm.\n\nThis problem is a type of transportation problem, where the courses are the ```\nsources```\n, and students are the ```\ndestinations```\n. The quota of each course is its ```\ncapacity```\n, the ```\ndemand```\n for each student is the number of lessons that system allows him.\n\nEDIT:  \n\nYou can formulate the transportation problem by following modification:\n\nSplit the lessons such that each lesson has a quote of 1. So in your example case there shall be 10 lessons. Assign the costs as follows:\n\n```\nDemand:  2    3    2    2    1\n        St1  St2  St3  St4  St5\nLess1.1  5    0    0    0    5 \nLess1.2  5    1    1    1    5  // cost for second dummy lesson is slightly high to differentiate.\nLess2.1  5    0    0    5    0\nLess3.1  0    0    0    0    5\nLess3.2  1    1    1    1    5\nLess4.1  0    0    0    5    5\nLess4.2  1    1    1    5    5\nLess4.3  2    2    2    5    5\nLess5.1  5    5    5    0    0\nLess5.2  5    5    5    1    1\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum matching in a bipartite graph\r\n                \r\nUse the following heuristic algorithm:\n\n```\nM = NULL\nwhile E != NULL do {\nif ((∃u vertex) and (gr(u) == 1)) then \n    e ← the incident edge with u\n  else \n    e ← an incident edge with a vertex with the most incident edges\nM ← M ∪ {e}\nE ← E - (all the incident edges with e)\n}\nreturn M //return the matching\n```\n\n\nWhere: M,E - edges ; gr(u) - the grade of u (the number of incident edges with u) ;\n\nWhat we were asked:\n\n```\n  a) Prove that this algorithm returns the maximum matching for a tree.\n  b) Prove that if there is a perfect matching M0 then the algorithm returns it, for any bipartite graph.\n  c) Prove that |M| ≥ (v(G)/2), for any bipartite graph. \n  //G is the graph, v(G) is the matching number, size of the maximum matching.\n```\n\n\nI'm almost sure this algorithm is similar to some classic algorithm that I'm failing to find, or the solution could be completely based on theorems and properties of bipartite graphs.\n\nCan you please give me a starting point.. What am I missing ?\n\nI think a) is easy.. I'm still trying to find the right proof, I think it may be completely based on properties of trees and bipartite graphs.\nFor b) and c) .. I don't have any idea yet.\n    ", "Answer": "\r\nThis is very similar to the greedy matching algorithm. See the wikipedia article for more information.\n\nAs for the questions...\n\n```\na) Show that the matching you get is maximal (there are no larger matchings containing it). What does this imply on a tree?\nb) Show that if M0 is a valid matching that can be found in M ∪ E in a given step, that it can be found in M ∪ E in the next. By induction, the statement holds.\nc) Consider a maximum matching M1. Why must at least one of the vertices adjacent to any given edge in M1 appear as an endpoint for some edge in the matching the algorithm outputs? What does this tell you about a lower bound for its size?\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How do I choose which edge to augment first in bipartite matching algorithm?\r\n                \r\nI am writing a ford fulkerson algorithm to match nodes in a bipartite graph. Currently the algorithm is recursive, and bipartite graphs are stored as dictionaries of lists. \n\ni.e. \n\n```\nbpGraph = {0: [0, 2, 1], 1: [2, 1, 1], 2: [0, 0, 2]}\n```\n\n\nmeans that node 0 in U can move to nodes [0, 2, 1] in V and so on.\n\nThe recursive nature of my function means that my algorithm looks for an available node in V for each node in U, and assigns it if the node in V is free, it does this over all of the nodes in U. If there is a node in U that wants to go somewhere in V it checks recursively whether or not there is an alternative node in V for a node currently assigned to that node if that exists. \n\nThis is great, however it always returns the same matching. I want to be able to find all the possible maximum matchings. Does anyone have any ideas of how to implement ford fulkerson algorithm without using recursion? where I could then declare which edge I want to augment first, rather than doing it in a loop? \n\nThe only solution I can think of is to find the edges in my bipartite matching graph, and cycle through all possible matchings greedily and check whether or not they correspond to max flow at the end. However, this seems like a poor solution. \n\nthanks in advance,\n\nS\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Double-matching in a bipartite graph\r\n                \r\nI've encountered the following problem studying for my Algorithm test, with no answer published to it: \n\n\nMaximum double matching problem- given a bipartite graph G=(V=(LUR),E) describe an algorithm that returns a group of edges M in E s.t for each vertex v in V there are at most 2 edges in M that include v, of a maximum size. \nDefinition: a \"Strong double matching\" is a double matching s.t for each vertice v in V there is at least one edge in M that includes v. Given a bipartite graph G=(V=(LUR),E) and strong double matching M, describe an algorithm that returns a strong double matching M' of maximum size. Prove your answer.\n\n\nso I've already managed to solve \n\n1) using reduction to max-flow: adding vertices's s and t and edges from s to L and edges from R to t each with the capacity of 2, and defining the capacity of each edge between L and R with the infinite capacity. Finding a max flow using Dinic's algorithm and returning all edges with positive flow between L and R.\n\nabout 2) i thought about somehow manipulating the network so that there is positive flow from each vertex then using the algorithm from a somehow to construct a maximum solution. Any thoughts? The runtime restriction is O(V^2E) (Dinics runtime)\n    ", "Answer": "\r\nHere is a solution in O(n^3) using minimum cost flow.\n\nRecall how we make a network for a standard bipartite matching.\n\n\nFor each vertex u from L, add a unit-capacity edge from S to u;\nFor each edge u-v, where u is from L and v is from R, add an edge from u to v. Note that its capacity does not matter as long as it is at least one;\nFor each vertex v from R, add a unit-capacity edge from u to R.\n\n\nNow we keep the central part the same and change left and right parts a bit.\n\n\nFor each vertex u from L, add two unit-capacity edges from S to u, one of them of having cost -1 and another having cost 0;\n\n\nSame for edges v->S.\n\nIgnoring cost, this is the same network you built yourself. The maximum flow here corresponds to the maximum double-matching.\n\nNow let's find the minimum cost flow of size k. It corresponds to some double-matching, and of those it corresponds to the matching that touches the maximum possible number of vertices, because touching a vertex (that is, pushing at least unit flow through it) decreases the cost by 1. Moreover, touching the vertex for the second time doesn't decrease the cost because the second edge has cost 0.\n\nHow we have the solution: for each k = 1, ..., 2n iteratively find the min-cost flow and take the value which corresponds to the minimum cost.\n\nUsing Johnson's algorithm (also called Dijkstra's with potentials) gives O(n^2) per iteration, which is O(n^3) overall.\n\nP.S. The runtime of Dinic's algorithm on unit graphs is better, reaching O(E sqrt(V)) on bipartite graphs.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to find Maximal Matching for non bipartite graph in polynomial time?\r\n                \r\nI know we can use Ford Fulkerson Algorithm of network flow to find Maximum matching in Bipartite graph. But is there any algorithm which uses network flow concept and gives maximum(or even maximal) matching for a non-bipartite graph?\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Reduction to bipartite matching\r\n                \r\nGiven an undirected graph with n vertices and m edges, is there a simple way to say if it is possible to delete edges from the graph so that finally the degree of each vertex is 1 ?\n    ", "Answer": "\r\nWhat you're looking for is an algorithm for finding a perfect matching in general graphs (the definition of perfect matching is a group of edges such that all vertices in the graph are touched exactly once by this group). Obviously perfect matching exists only in graphs with even number of vertices.\n\nTo find if such matching exists you can use an algorithm for finding maximum matching (the largest possible matching in the graph) and check if it's perfect. The blossom algorithm is used for finding maximum matching in general graphs.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximal matching in a bipartite graph [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and  cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened,  visit the help center.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 11 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI am stuck with a maximal matching in a bipartite graph problem. The problem goes something like this:\n\nGiven a board with m circular holes and given a set of n circular discs. Holes are numbered as h1, ..., hm, and discs as d1, ..., dn.\n\nWe have a matrix A of m rows and n columns. A[i][j] = 1 if hi can fit dj (i.e., diameter of hi ≥ diameter of dj), and 0 otherwise.\n\nGiven the condition that any hole can contain at most one disc, I need to find the configuration for which holedisc fitting is maximal.\n\nI have read that this problem can be modelled into network flow problem, but could not exactly follow how.  Can someone explain how to do this?  Also, is there any C code for this that I might be able to look at?\n    ", "Answer": "\r\nThe reduction from bipartite matching to maximum flow is actually quite beautiful.  When you are given a bipartite graph, you can think of the graph as two columns of nodes connected by edges from the first column to the second:\n\n```\n  A ----- 1\n  B --\\   2\n  C    \\- 3\n ...     ...\n  Z       n\n```\n\n\nTo reduce the problem to max-flow, you begin by directing all of the edges from the first column to the second column so that flow can only move from the left column to the right.  After you do this, you introduce two new nodes s and t that act as the source and terminal nodes.  You position s so that it is connected to all of the nodes on the left side and t so that each node in the right side is connected to it.  For example:\n\n```\n     A ----- 1\n /   B --\\   2   \\\ns-   C    \\- 3   - t\n \\  ...     ...  /\n     Z       n\n```\n\n\nThe idea here is that any path you can take from s to t must enter one of the nodes in the left column, then cross some edge to the right column, and from there to t.  Thus there is an easy one-to-one mapping from an edge in a matching and an s-t path: just take the path from s to the source of the edge, then follow the edge, then follow the edge from the endpoint to the node t.  At this point, our goal is to find the way to maximize the number of node-disjoint paths from s to t.  We can accomplish this using a maximum-flow as follows.  First, set the capacity of each edge leaving s to be 1.  This ensures that at most one unit of flow enters each of the nodes in the first column.  Similarly, set the capacity of each edge crossing the two columns to be one, ensuing that we either pick the edge or don't, rather than possibly picking it with some multiplicity.  Finally, set the capacity of the edges leaving the second column into t to be one as well.  This ensures that each node in the right-hand side is only matched once, since we can't push more than one unit of flow past it.\n\nOnce you've constructed the flow network, compute a maximum flow using any of the standard algorithms.  Ford-Fulkerson is a simple algorithm that performs well here, since the maximum flow in the graph is equal to the number of nodes.  It has a worst-case performance of O(mn).  Alternatively, the highly optimized Hopcroft-Karp algorithm can do this in O(m√n) time, which can be much better.\n\nAs for a C implementation, a quick Google search for the Ford-Fulkerson step turned up this link.  You'd need to construct the flow network before passing it into this code, but the construction isn't too complex and I think that you shouldn't have much trouble with it.\n\nHope this helps!\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "bipartite matching in C++, what is wrong in my code?\r\n                \r\nI have worked on a bipartite matching problem, and I obviously got a trouble to solve it.\n\nLet me tell you what the problem is about.\n\nAs an input form, it gives me N, M which is the number of people at the work and the number of different kind of jobs in the work. \nIn the following N lines, it tells us s that tells how many kind of job that ith person can do. In the following s numbers, they will tell us that which jobs can ith person can do. The number of the jobs si will satisfy 1<=si<=M.\nThen, if each person can work on only one or less job at a time, how many jobs can be done at most?\n\nThis is the problem, and I hope this made sense for you;) I apologize my poor english skill. Returning to the point, this is my code.\n\n```\n#include <stdio.h>\n\nint n, m, dfscheck[1003], check[1003], input[1003][1003], back[1003], tmp, count=0;\n\nvoid dfs(int num)\n{\n    int i, j;\n    if(check[num]==0)\n    {\n        tmp=-1;\n        check[num]=1;\n        return;\n    }\n    if(dfscheck[num]==1)\n        return;\n    dfscheck[num]=1;\n    for(j=1; j<=input[back[num]][0]; j++)\n    {\n        dfs(input[back[num]][j]);\n        if(tmp==-1)\n        {\n            back[input[back[num]][j]]=back[num];\n            return;\n        }\n    }\n}\n\nint main(void)\n{\n    int i, j, flag ,k;\n    scanf(\"%d %d\", &n, &m);\n    for(i=1; i<=n; i++)\n    {\n        scanf(\"%d\", &input[i][0]);\n        for(j=1; j<=input[i][0]; j++)\n            scanf(\"%d\", &input[i][j]);\n    }\n    for(i=1; i<=n; i++)\n    {\n        flag=0;\n        for(j=1; j<=input[i][0]; j++)\n            if(check[input[i][j]]==0)\n            {\n                check[input[i][j]]=1;\n                count++;\n                flag=1;\n                back[input[i][j]]=i;\n                break;\n            }\n\n        if(flag==0)\n            for(j=1; j<=input[i][0]; j++)\n            {\n                for(k=0; k<=1001; k++)\n                    dfscheck[k]=0;\n                tmp=0;\n                dfs(input[i][j]);\n                if(tmp==-1)\n                {\n                    back[input[i][j]]=i;\n                    count++;\n                }\n            }\n    }\n    printf(\"%d\", count);\n    return 0;\n}\n```\n\n\nThe name of tmp is really bad to understand code, so... tmp works like a flag in the function dfs. It tells whether it has found a matching.\n\nI got wrong answer, neither runtime error nor time exceed. I have read several different codes that others have written, and I couldn't find which part is wrong in my code. \n\nI have found that my code is distinct from others' in the part that I don't define a array, A[i], showing which job is matched to ith person, exactly opposite to Back array in my code. As far as I understood their codes, the purpose of it is to find out ith person has already been matched before we get into dfs. I don't think this case can be happened. Since no flow has come out of the node of ith person, it is impossible for a flow to go from a node of jobs to the node in max flow. \n\nI wanted to say my thoughts even if it is useless, just in case that it helps you give me some advices. Anyway, let me have your opinions!!!\nThank you so much for your time.\n    ", "Answer": "\r\nOne thing that looks weird is:\n\n```\n            if(tmp==-1)\n            {\n                back[input[i][j]]=i;\n                count++;\n                // I would expect to see \"break;\" here\n            }\n```\n\n\nif you find a way to assign person i to a job you increment the count, and then carry on trying to see if you can find an alternative way to assign the same person.  This means that you may end up assigning the same person to multiple jobs!\n\nI recommend inserting a \"break;\" statement once you have found a job for the person. \n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Why we use max-flow method to solve maximum bipartite matching?\r\n                \r\nfor example\n\nthere is A[0] and A[1] and B[0] and B[1]\n\nLINK(A[0], B[0])\n\nLINK(A[0], B[1])\n\nLINK(A[1], B[0]) \n\nThe maximum match is (A[0].B[1]) and (A[1],B[0])\n\nbut for max-flow finding method that we build a source behind A and sink after B\n\nand the method will find a path every time it tries out there is a path\n\nthat: it first get A[0] pair with B[0]\n\nthen for Path B[0] to sink is used, that no path for A[1] pair B[0]\n\nit definitely cannot solve this but I find textbooks, wikis, blogs and website just say that its result is the same as Maximum Bipartite Matching \n\nPS\n\nLet C(x,y) be x->y 's value,\n\nby applying the alg, \n\n1st iteration: set C(s,A[0]) = 0 ; set C(A[0],s) = 1  (reversing the flow)\n\nand also, A[0] with B[0] , B[0] with t\n\n2nd iteration: it find routes from s to t, only C(B[1],t) = 1\n\nso, 2nd iteration find no point for connecting B[1]\n    ", "Answer": "\r\nActually max-flow will be able to link the things correctly. There will be a second iteration where the flow from A[1] could go to B[0] while reversing the flow going in the link from A[0] to B[0].\n\nYou can look up the Ford-Fulkerson algorithm it can do that. \n\nEDIT : \n\nAssuming you start with a source node S (LINK(S,A0) and LINK(S,A1)) (and an ending node F) if you apply the algorithm on the first iteration you will end up with A0->B0 like you said. I'll go into details for the second iteration. \n\n1) \"S\" ; T = {S} ; E = {}\n\n\nLabel(A1) = {S+, 1}, T = {S A1}\nE = {S}\n\n\n2) \"A1\" ; T = {S A1} ;  E = {S}\n\n\nLabel(B0) = {A1+, 1}, T = {S A1 B0}\nE = {S A1}\n\n\n3) \"B0\" ; T = {S A1 B0} ; E = {S A1}\n\n\nLabel(A0) = {B0-, 1} ; T = {S A1 B0 A0}\nE = {S A1 B0}\n\n\n4) \"A0\" ; T = {S A1 B0 A0} ; E = {S A1 B0}\n\n\nLabel(B1) = {A0+, 1} ; T = {S A1 B0 A0 B1}\nE = {S A1 B0 A0}\nDon't inspect \"S\" because it is already in T!\n\n\n5) \"B1\" ;  T = {S A1 B0 A0 B1}\n\n\nLabel(F) = {B1+, 1} ; T = {S A1 B0 A0 B1 F}\nE = {S A1 B0 A0 B1}\n\n\nAnd it's over,  the flow is now maximised. \n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Why is the time complexity of the following maximum bipartite matching implementation O(m*n^2)?\r\n                \r\nThere is this library that has implementations of many algorithms and one of them is maximum bipartite matching.\n\nHere is the link to the source code: http://shygypsy.com/tools/bpm.cpp\n\nI will include it here as well(without the comments)\n\n```\n#include <string.h>\n\n#define M 128\n#define N 128\n\nbool graph[M][N];\nbool seen[N];\nint matchL[M], matchR[N];\nint n, m;\n\nbool bpm( int u )\n {\n  for( int v = 0; v < n; v++ ) \n   if( graph[u][v] )\n   {\n    if( seen[v] ) continue;\n    seen[v] = true;\n\n    if( matchR[v] < 0 || bpm( matchR[v] ) )\n    {\n        matchL[u] = v;\n        matchR[v] = u;\n        return true;\n    }\n}\nreturn false;\n}\n\nint main()\n{\n  memset( matchL, -1, sizeof( matchL ) );\n  memset( matchR, -1, sizeof( matchR ) );\n  int cnt = 0;\n  for( int i = 0; i < m; i++ )\n  {\n      memset( seen, 0, sizeof( seen ) );\n      if( bpm( i ) ) cnt++;\n  }\n  return 0;\n}\n```\n\n\nWe have a for loop that runs ```\nm```\n times. The number ```\nm```\n refers to the amount of workers.\nThen we enter the ```\nbpm```\n function which has another for loop. This loop runs ```\nn```\n times where ```\nn```\n is the amount of tasks.\n\nUntil now we have ```\nm*n```\n time complexity.\n\nHowever there is a recursive function call of ```\nbpm```\n in the third if statement. The goal of this function is to run a ```\ndfs```\n in order to find an augmented path.\n\nI know that ```\ndfs```\n has a time complexity ```\nO(n+m)```\n. So I would assume that the function ```\nbpm```\n has a complexity of ```\nO(n+m)```\n\n\nThus the total time complexity would be ```\nO(m*(n+m))```\n\n\nHowever the author says it's ```\nO(m*n^2)```\n. Can someone explain me why is this the case? Thank you in advance!\n    ", "Answer": "\r\nThe variables are somewhat confusing here: M and N refer to the number of nodes on each side of the graph.  The runtime of DFS is ```\nO(E+V)```\n where E is the number of edges.  In a bipartite graph |E| is at most N*M and V will be (N+M), thus your DFS is going to take ```\nO(NM)```\n.   The total time complexity is then ```\nO(NM^2)```\n.  Not sure where the ```\nN^2```\n comes in, could be a typo...\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Perfect Matching in Bipartite Graph with mutually exclusive edges [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is not about programming or software development. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about a specific programming problem, a software algorithm, or software tools primarily used by programmers. If you believe the question would be on-topic on another Stack Exchange site, you can leave a comment to explain where the question may be able to be answered.\r\n                \r\n                    \r\n                        Closed 3 months ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nProblem\n\nI would to solve Perfect Matching in Bipartite Graph Problem where some edges are mutually exclusive.\n\nExample\n\nLeft vertices: a,b,c\n\nRight vertices: x,y,z\n\nEdges: (a,x), (a,y), (b,z), (c,y)\n\nExlusive pairs: (b,z) and (c,y)\n\nAnswer: no perfect matching\n\nQuestion\n\nIs the problem in P or NP?\n\nSolution Attempts\n\nI know that Perfect Matching in Bipartite Graph Problem is in P. But I cannot find a polynomial-time algorithms for the above version of this problem. I have also tried proving that it is NP, but without any luck.\n    ", "Answer": "\r\nIf you mean by edges being \"mutually exclusive\" that they don't share a vertex, then the problem you described is a subset of the general Perfect Matching in Bipartite Graph Problem.\n\nAlso try to be more specific with the terms P and NP. P is a subset of NP. Therefore the\nPerfect Matching in Bipartite Graph Problem is also in NP, because it is in P. Something different, what you maybe meant is NP-hardness. This basicially means \"at least as hard as every problem in NP\".\n\nYour question should thus be: \"Is the problem in P?\", because if we had a solution, we could check it easily, thus it is in NP. The property that we can check it in polynomial time is actually the definition of NP.\n\nAnd like I said, from my understanding your problem is only a subset of the problem, thus also in P.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Use O(n^2) time to fix a mistake in bipartite matching\r\n                \r\nThis is a problem from Algorithm Design book.\n\nGiven a bipartite graph with vertices G=(V,E) where V=(A,B) such that |A|=|B|=n.\n\nWe manage to perfectly match n-2 nodes in A to n-2 nodes in B. However, for the remaining two nodes in A we map them both to a certain node in B (not one of the n-2 nodes in B that are already matched to.)\n\nGiven the information from the \"matching\" above, how to use O(n^2) time to decide whether a perfect matching between A and B actually exists? A hint is fine. Thank you.\n    ", "Answer": "\r\nLet's have u and v be the two nodes in A that match to the same node x in B. Pick one of those two nodes - call it u - and remove the edge to x from the matching. You are now left with a graph where you have a matching between n - 1 of the nodes from A and n - 1 of the nodes from B. The question now is whether you can extend this matching to make it even bigger.\n\nThere's a really nice way to do this using Berge's theorem, which says that a matching in a graph is maximum if and only if there is no alternating path between two unmatched nodes. (An alternating path is one that alternates between using edges not included in the matching and edges included in the matching). You can find a path like this by starting from  the node u and trying to find a path to x by doing a modified binary search, where when you go from A to B you only follow unmatched edges and when you go from B back to A you only follow matched edges. If an alternating path exists from u to x, then you'll be sure to find it this way, and if no such path exists, then you can be certain of that as well.\n\nIf you do find an alternating path from u to x, you can \"flip\" it to increase the size of the matching by one. Specifically, take all the edges in the path that aren't in the matching and add them in, and take all the edges that were in the matching and delete them. The resulting is still a valid matching that has one more edge in it than what you started with (if you don't see why this is, play around with some examples and see what you find, or look at the proof of Berge's theorem).\n\nOverall, this approach will require time O(m + n), where m is the number of edges in the graph and n is the number of nodes. The number of edges m is at most O(n2) in a bipartite graph, so this matches your time bound (and, in fact, is actually a bit tighter!)\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Error in an approach to Maximum Bipartite matching\r\n                \r\nA bipartite graph with a source and sink is given as shown below. The capacity of every edge is 1 unit :\nSource : GeeksforGeeks\n\nI'm trying to find the maximum flow from source to sink. One approach would be using the Ford-Fulkerson Algorithm for Maximum Flow Problem, which is applicable to all the graphs.\nI found a simple approach to find the maximum flow(too simple to be correct!) and I'm not able to find any error in the approach.\n\nApproach : \n\nc1 = Count the number of vertices having non zero number of edges originating from it ,in the list of vertices having outgoing edges.\n\nc2 = Count the number of vertices having non zero number of edges converging into it ,in the list of vertices having incoming edges.\n\nThe max flow would be the minimum of both these numbers,i.e., min(c1,c2).[Since any path needs one vertex from the outgoing vertices list, and other from incoming vertices list.]\n\nAny help would be appreciated. \n    ", "Answer": "\r\nConsider a graph like\n\n```\n*--*\n  /\n /\n*  *\n  /\n /\n*--*\n```\n\n\n(The patch of working by connected component doesn't fix things; connect the lower left to the upper right.)\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Is maximum matching in a Bipartite Graph always a perfect matching?\r\n                \r\nCan Hopcroft-Karp algorithm help in determining the perfect matchings for the bipartite graph?\n    ", "Answer": "\r\nNo. A perfect matching is only possible if there's an equal number of vertices in both sets.\n\nIt's not possible to find a perfect matching for this graph:\n\n\n\nEven if both sets have the same number of vertices, the maximum matching won't be perfect if edges are missing:\n\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Why is max flow algorithm in graph theory correct for maximal bipartite matching\r\n                \r\nI have read many articles stating that the maximal matching of a bipartite graph can be found using max flow algorithm. But there is a possibility that the matching we get from max flow is not maximal or the matching does not have maximum edges.\nExample taken from Competitive Programming Handbook by Anti Laaksonen:\n\nBut if I present the graph in a different manner such that the graph now is:\n\nThen as the algorithm of max flow progresses the matching would be\n1----5,\n2----7\nbecause 1 simply erases path to the sink but if it would have gone for the edge\n1----6\nthen the matching could have been\n1----6,\n3----5,\n4----7\n    ", "Answer": "\r\nI was with you up until this point:\n\nThen as the algorithm of max flow progresses the matching would be 1----5, 2----7\n\nWhat you're describing here isn't actually a maximum flow in the graph. We could push more flow across by sending a unit of flow from 1 to 6, a unit of flow from 2 to 7, and a unit of flow from 3 to 5.\nReading over your question, I think the reason you ended up with the (non-maximum) flow rather than a maximum flow is because of this statement:\n\nbecause 1 simply erases path to the sink\n\nFrom what you're describing here, I'm assuming you're using something like the Ford-Fulkerson algorithm to compute the maximum flow: find an augmenting path from the source to the sink and push flow across it. But Ford-Fulkerson also has a second step here: after pushing flow across an edge, we introduce a residual edge in the reverse direction of the flow pushed. This gives the opportunity to \"undo\" the decision we made in the event that we find a better path.\nAs a result, after we push a unit of flow from 1 -- 5, we add in a residual edge from 5 back to 1 with a single unit of capacity. That means that the graph now looks like this:\n\nHere, edges in teal flow from s toward t, and edges in purple flow from t back toward s.\nNotice that we can \"undo\" our decision to assign 1 to 5 as follows. Push a unit of flow on the path\n\ns → 3 → 5 → 1 → 6 → t\n\nto give this flow network:\n\nNow, pushing one more unit of flow on the path\n\ns → 2 → 7 → t\n\ngives the overall matching 1 -- 6, 2 -- 7, 3 -- 5, which is a maximum matching.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Weighted bipartite matching with constraints on degrees of vertices\r\n                \r\nI have a problem that I was able to conceptualize as following:\nWe have a set of n people. And m subsets representing their ethnicity like White, Hispanic, Asian etc.\nGiven any combination of these people, I want to check if it is a diverse group.\nA diverse group is a group that satisfies several requirements, each requirement is of the form \"at least Ki persons in the group belong to subset Si\". Here is the tricky part, one person can only be used to satisfy one requirement. As in, you can't use him/her for multiple requirements.\nAn example:\nGiven:\nAt least two people from Hispanic= {a,b,c}\nAt least two people from Asian={a,d,e}\nIs the group {a,c,d} a diverse group?\nThe group {a,c,d} is not diverse because you cant count a as Hispanic and Asian. But,\nthe group {a,c,d,e,f} is diverse because we have two Hispanics a and c and two Asian d and e.\nAttempt:\nThis is an instance of the Assignment problem. The jobs are the ethnicity and we can put as many ethnicity as the requirement dictate. For example, if we need two Hispanic, then we put two Hispanic jobs. However there only some people are able to do a particular job.\nThis is my attempt so far:\nI will construct a bipartite graph with the set of people P on one hand and the set of ethnicity on the other S. We will put an edge between a person p_i and an ethnicity S_i if he/she belongs to the ethnicity.\nNow, we will modify the graph, for every ethnicity S_i duplicate it k_i times (S_{i,1}, S_{i,2}, ... , S_{i,k_i}). And add new edges accordingly. Find the maximum matching M of this graph.\nNow, merge the S_{i,j} s into one S_i and there you have a diverse group. However, a maximum matching is only a possible solution to to the problem. And my problem is a decision problem, I want to check if a given group is a solution or not.\n    ", "Answer": "\r\nI think this is an instance of the http://en.wikipedia.org/wiki/Assignment_problem, usually described in terms of assigning people to jobs, so in your case the job is \"sit there and look white\" or \"sit there and look hispanic\". Only some people are qualified to do any particular job, and they can only do one job at a time.\n\nNormally the assignment algorithm minimizes a cost, but you can just use cost 0/cost 1 for \"is in the right ethnic group\" or not.\n\nOne means of solving this is the http://en.wikipedia.org/wiki/Hungarian_algorithm. This is often presented for the case in which there are exactly as many workers as jobs, but you can always invent dummy jobs or dummy workers, with all costs associated with dummies the same cost, so that optimizing the problem with dummies reproduces exactly the relative order of costs you would get if you ignored assignments to dummies, and so the optimum with dummies is the same choice, after ignoring dummies, as the optimum without.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Applying maximum bipartite algorithm on text file containing graph info and produce graph(with max matching) as output\r\n                \r\nI want to read text file containing graph information and apply approximation on graph. Output would be graph containing maximum matching nodes information. Algorithm is based on maximum bipartite matching. I am using eclipse PyDev for this. \n\nHere is code: \n\n```\nimport networkx as nx\n\nimport matplotlib.pyplot as plt\n\n\nG = nx.read_edgelist('abc.text', create_using=nx.Graph(), nodetype=int)\n\ndef bipartiteMatch(G):\n\nM = {}\nfor u in G:\n    for v in G[u]:\n        if v not in M:\n            M[v] = u\n            break\n\nwhile 1:\n    preds = {}\n    unmatched = []\n    pred = dict([(u,unmatched) for u in G])\n    for v in M:\n        del pred[M[v]]\n    layer = list(pred)\n\n    while layer and not unmatched:\n        newLayer = {}\n        for u in layer:\n            for v in G[u]:\n                if v not in preds:\n                    newLayer.setdefault(v,[]).append(u)\n\n        layer = []\n        for v in newLayer:\n            preds[v] = newLayer[v]\n            if v in M:\n                layer.append(M[v])\n                pred[M[v]] = v\n            else:\n                unmatched.append(v)\n\n    if not unmatched:\n        unlayered = {}\n        for u in G:\n            for v in G[u]:\n                if v not in preds:\n                    unlayered[v] = None\n        return (M,list(pred),list(unlayered))\n\n\n    def recurse(v):\n        if v in preds:\n            L = preds[v]\n            del preds[v]\n            for u in L:\n                if u in pred:\n                    pu = pred[u]\n                    del pred[u]\n                    if pu is unmatched or recurse(pu):\n                        M[v] = u\n                        return 1\n\n        return 0\n    for v in unmatched: recurse(v)\n\nnx.draw(G)\n\nplt.show()\n```\n\n\nabc.text file containing edge info:e.g.,\n\n```\n1 2\n3 1\n4 5\n3 2\n```\n\n\nProblem: Code is able to read abc.text file and displaying output as graph but it is not applying bipartite algorithm on it. I am new on python. Please suggest where is problem in code so that algorithm apply on text file and give graph as output with max matching.\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Modifying a bipartite graph so that it would have a perfect matching\r\n                \r\nGiven a bipartite graph with equal-sized sides X and Y, how can we efficiently find the minimum number of edges we have to add so that the graph will have a perfect matching? is there a better solution than iterating over all 2^(|X|) subsets and adding edges until Hall's theorem is satisfied?\n\nThanks.\n    ", "Answer": "\r\nIf I understood the question correctly, it should be possible to generate a cardinality-maximal matching of the initial graph efficiently, by either using the so-called Hungarian method or modelization as a network flow problem. Once the cardinality-maximal matching has been found, there must be an equal number of unmatched nodes in either partition, which can be matched using additional edges at will.\n\nIn other words, if ```\nM```\n is the cardinality of a cardinality-maximal matching in the original graph and ```\n|X|=|Y|```\n holds, then at at least ```\nM-|X|```\n edges have to be added in order to have a perfect matching contained in the graph.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite matching to flow network\r\n                \r\nI have a directed graph, with category A that is able to kill category B.\nI'm able to transform it into a flow network but my issue is, if i have some nodes without any arrows, like a lonely node, do I connect it to the source and sink or I remove it from my network flow ?\nThanks\n    ", "Answer": "\r\nIf you're trying to find a bipartite matching using a max flow algorithm, either works, since either way there's no path from source to sink through the isolated node, therefore it does not affect the flow calculation.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to find all perfect matching in bipartite graph using Prolog?\r\n                \r\nI'm trying to find all perfect matching in bipartite graph and then do some nontrivial evaluations of each solution (nontrivial means, I can not use Hungarian algorithm). \nI use Prolog for this, is there any not exponential solution? (If the result is not exponential of course..)\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum weighted bipartite matching for two sets of vertices of drastically different sizes\r\n                \r\nThe abstract problem\n\nI want to find the best maximum matching in a complete weighted bipartite graph where the two sets of vertices differ drastically in size, i.e. one set of vertices is very large and the other one very small.\n\nThe Hungarian algorithm is not a good approach for this problem since it adds dummy vertices to the smaller set such that the two sets have the same size, so I lose all the potential efficiency gains from one of the vertex sets being only very small.\n\nMore concretely\n\nI have divided objects (bounding boxes) into two sets and I have a similarity measure (Jaccard overlap) for how similar any two objects are. I want to produce the matching between the two sets such that the sum of the similarities of all individual matches is maximal.\n\nThe problem is that one of the sets contains only very few objects, say 10, while the second set is very large, say 10,000 objects. Each of the 10 objects in the first set needs to be matched to one of the 10,000 objects in the second set.\n\nThis asymmetry in the sizes of the two sets is what makes me wonder how to do this efficiently. I can't use the Hungarian algorithm and produce a 10,000 by 10,000 matrix.\n    ", "Answer": "\r\nProbably the easiest approach in terms of available software: use a min-cost network-flow solver. This formulation has no trouble with rectangular cost-matrices! The basic idea is simple and an intro is here (one slide shown in following image):\n\nThere is a lot of available software (e.g. Coin-OR Lemon/C++; Google's ortools/C++ with many wrappers).\n\n\n\nGoogle's ortools also has an own documentation-entry on this.\n\nDespite that, the book:\n\n\n  Burkard, Rainer E., Mauro Dell'Amico, and Silvano Martello. Assignment problems, revised reprint. Vol. 125. Siam, 2009.\n\n\nhas a tiny/small chapter (5.4.4 Rectangular cost matrix) outlining other approaches, mostly modifications of other linear-assignment algorithms.\n\nPart of that chapter is the following:\n\n\n  Alternatively, one can use the transformation to a minimum cost flow problem of Section 4.4.1, which does not require that vertex sets U and V have equal cardinality.\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "All possible maximum matchings of a bipartite graph\r\n                \r\nI am using networkx to find the maximum cardinality matching of a bipartite graph.\n\nThe matched edges are not unique for the particular graph.\n\nIs there a way for me to find all the maximum matchings? \n\nFor the following example, all edges below can be the maximum matching:\n\n```\n{1: 2, 2: 1}```\n or ```\n{1: 3, 3: 1}```\n or ```\n{1: 4, 4: 1}```\n\n\n```\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\nG = nx.MultiDiGraph()\nedges = [(1,3), (1,4), (1,2)]\n\nnx.is_bipartite(G)\nTrue\n\nnx.draw(G, with_labels=True)\nplt.show()\n```\n\n\n\n\nUnfortunately, \n\n```\nnx.bipartite.maximum_matching(G)\n```\n\n\nonly returns\n\n```\n{1: 2, 2: 1}\n```\n\n\nIs there a way I can get the other combinations as well?\n    ", "Answer": "\r\nThe paper \"Algorithms for Enumerating All Perfect, Maximum and Maximal Matchings in Bipartite Graphs\" by Takeaki Uno has an algorithm for this. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.8179&rep=rep1&type=pdf\n\nTheorem 2 says \n\"Maximum matchings in a bipartite graph can be enumerated in O(mn^1/2+\nnNm) time and O(m) space, where Nm is the number of maximum matchings in G.\"\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How can I compute the minimum bipartite vertex cover?\r\n                \r\nHow can I compute the minimum bipartite vertex cover in C#? Is there a code snippet to do so?\n\nEDIT: while the problem is NP-complete for general graphs, it is solvable in polynomial time for bipartite graphs. I know that it's somehow related to maximum matching in bipartite graphs (by Konig's theorem) but I can't understand the theorem correctly to be able to convert the result of maximum bipartite matching to vertex cover.\n    ", "Answer": "\r\nI could figure it out:\n\n```\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\n\nclass VertexCover\n{\n    static void Main(string[] args)\n    {\n        var v = new VertexCover();\n        v.ParseInput();\n        v.FindVertexCover();\n        v.PrintResults();\n    }\n\n    private void PrintResults()\n    {\n        Console.WriteLine(String.Join(\" \", VertexCoverResult.Select(x => x.ToString()).ToArray()));\n    }\n\n    private void FindVertexCover()\n    {\n        FindBipartiteMatching();\n\n        var TreeSet = new HashSet<int>();\n        foreach (var v in LeftVertices)\n            if (Matching[v] < 0)\n                DepthFirstSearch(TreeSet, v, false);\n\n        VertexCoverResult = new HashSet<int>(LeftVertices.Except(TreeSet).Union(RightVertices.Intersect(TreeSet)));\n    }\n\n    private void DepthFirstSearch(HashSet<int> TreeSet, int v, bool left)\n    {\n        if (TreeSet.Contains(v))\n            return;\n        TreeSet.Add(v);\n        if (left) {\n            foreach (var u in Edges[v])\n                if (u != Matching[v])\n                    DepthFirstSearch(TreeSet, u, true);\n        } else if (Matching[v] >= 0)\n            DepthFirstSearch(TreeSet, Matching[v], false);\n\n    }\n\n    private void FindBipartiteMatching()\n    {\n        Bicolorate();\n        Matching = Enumerable.Repeat(-1, VertexCount).ToArray();\n        var cnt = 0;\n        foreach (var i in LeftVertices) {\n            var seen = new bool[VertexCount];\n            if (BipartiteMatchingInternal(seen, i)) cnt++;\n        }\n    }\n\n    private bool BipartiteMatchingInternal(bool[] seen, int u)\n    {\n        foreach (var v in Edges[u]) {\n            if (seen[v]) continue;\n            seen[v] = true;\n            if (Matching[v] < 0 || BipartiteMatchingInternal(seen, Matching[v])) {\n                Matching[u] = v;\n                Matching[v] = u;\n                return true;\n            }\n        }\n        return false;\n    }\n\n    private void Bicolorate()\n    {\n        LeftVertices = new HashSet<int>();\n        RightVertices = new HashSet<int>();\n\n        var colors = new int[VertexCount];\n        for (int i = 0; i < VertexCount; ++i)\n            if (colors[i] == 0 && !BicolorateInternal(colors, i, 1))\n                throw new InvalidOperationException(\"Graph is NOT bipartite.\");\n    }\n\n    private bool BicolorateInternal(int[] colors, int i, int color)\n    {\n        if (colors[i] == 0) {\n            if (color == 1) LeftVertices.Add(i);\n            else RightVertices.Add(i);\n            colors[i] = color;\n        } else if (colors[i] != color)\n            return false;\n        else\n            return true;\n        foreach (var j in Edges[i])\n            if (!BicolorateInternal(colors, j, 3 - color))\n                return false;\n        return true;\n    }\n\n    private int VertexCount;\n    private HashSet<int>[] Edges;\n    private HashSet<int> LeftVertices;\n    private HashSet<int> RightVertices;\n    private HashSet<int> VertexCoverResult;\n    private int[] Matching;\n\n    private void ReadIntegerPair(out int x, out int y)\n    {\n        var input = Console.ReadLine();\n        var splitted = input.Split(new char[] { ' ' }, 2);\n        x = int.Parse(splitted[0]);\n        y = int.Parse(splitted[1]);\n    }\n\n    private void ParseInput()\n    {\n        int EdgeCount;\n        ReadIntegerPair(out VertexCount, out EdgeCount);\n        Edges = new HashSet<int>[VertexCount];\n        for (int i = 0; i < Edges.Length; ++i)\n            Edges[i] = new HashSet<int>();\n\n        for (int i = 0; i < EdgeCount; i++) {\n            int x, y;\n            ReadIntegerPair(out x, out y);\n            Edges[x].Add(y);\n            Edges[y].Add(x);\n        }\n    }\n}\n```\n\n\nAs you can see, this code solves the problem in polynomial time.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Construct a bipartite representation of a directed network for use with hopcroft-karp matching function in networkx\r\n                \r\nI am using the hopcroft-karp algorithm in networkx on a directed network which I have transformed into a bipartite representation. However, the bipartite network is not allowed to have the same vertex in both left and right node sets. There is a self loop included in my directed network, so as a workaround, I rename the vertices in the left node set as (X1_+, X2_+,X3_+) and in the right set as (X1_-,X2_-,X3_-). The directed network and the corresponding bipartite representation are as follows:\n\nThe correct result for the maximum matching, in terms of the dictionary output given by the hopcroft-karp algorithm in networkx, should be\n```\n{X2-:X1+,X3-:X3+)]```\n so that ```\nX1-```\n would be the only unmatched node since it does not appear as a key in the output dictionary.\nI followed the networkx documentation to get the corresponding bipartite network and then I used the hopcroft-karp function to obtain the maximum matching. The code that i implemented is outlined below along with the result:\n```\n# Add nodes w/ the node attribute bipartite\nG_eg.add_nodes_from([\"X1_+\", \"X3_+\"], bipartite=1)\nG_eg.add_nodes_from([\"X2_-\", \"X3_-\"], bipartite=0)\n# Add edges only between nodes of opposite node sets\nG_eg.add_edges_from([(\"X1_+\", \"X2_-\"), (\"X1_+\", \"X3_-\"), (\"X3_+\", \"X3_-\")])\n\n#left, right nodes based on node attribute\nleft_nodes = {n for n, d in G_eg.nodes(data=True) if d[\"bipartite\"] == 1}\nright_nodes = set(G_eg) - left_nodes\n\n#apply hopcroft-karp algorithm\nnx.bipartite.hopcroft_karp_matching(G_eg, left_nodes)\n```\n\noutput:\n```\n{'X3_+': 'X3_-', 'X1_+': 'X2_-', 'X3_-': 'X3_+', 'X2_-': 'X1_+'}```\n\nFrom my output, I can see that ```\nX1_-```\n is not listed as a key and therefore it is deemed unmatched. However, why is it that the output gives the result in this way, meaning, it ignores the fact that the network is directed. By including ```\nX1_+:X2_-```\n in the output dictionary, it implies that ```\nX1_+```\n is matched. Is my interpretation incorrect?\n    ", "Answer": "\r\nIndeed, any directions you impose on the edges of the graph are ignored by ```\nhopcroft_karp_matching```\n (and the other implementations of ```\nmaximum_matching```\n). Regarding the format of the output, the documentation specifies that the output is\n\nmatches – The matching is returned as a dictionary, ```\nmatches```\n, such that ```\nmatches[v] == w```\n if node ```\nv```\n is matched to node ```\nw```\n. Unmatched nodes do not occur as a key in ```\nmatches```\n.\n\nIn particular, the matched notes are exactly the keys of the directory, in your case ```\n{'X3_+', 'X1_+', 'X3_-', 'X2_-'}```\n. In particular, this means that the output could always be cut in half, with matched nodes being available as the union of keys and values; I assume the redundant information is included simply because it might be convenient in some cases.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How can this bipartite matching solution be improved?\r\n                \r\nI'm working through codefights and am attempting the busyHolidays challenge from the Instacart company challenges. \n\nThe challenge provides three arrays. Shoppers contains strings representing the start and end times of their shifts. Orders contains strings representing the start and end times of the orders, and leadTime contains integers representing the number of minutes it takes to complete the job. \n\nThe goal is to determine if the orders can be matched to shoppers such that each shopper has only one order and each order has a shopper. An order may only be matched to a shopper if the shopper can both begin and complete it within the order time.\n\nI have a solution that passes 19/20 tests, but since I can't see the last test I have no idea what's going wrong. I originally spent a couple days trying to learn algorithms like Edmond's Algorithm and the Hungarian Algorithm, but my lack of CS background and weakness in math kind of bit me in the ass and I can't seem to wrap my head around how to actually implement those methodologies, so I came up with a solution that involves weighting each node on each side of the graph according to its number of possible connections. I would appreciate it if anyone could help me take a look at my solution and either point out where it might be messing up or suggest a more standard solution to the problem in a way that might be easier for someone without formal training in algorithms to understand. Thanks in advance.\n\nI'll put the code in a gist since it's fairly length\n\nCode: https://gist.github.com/JakeTompkins/7e1afc4722fb828f26f8f6a964774a25\n    ", "Answer": "\r\nWell, I don't see any reason to think that the algorithm you're writing is actually going to work so the question about how you might be messing it up doesn't seem to be relevant.\n\nYou have correctly identified this as an instance of the assignment problem.  More specifically this is the \"maximum bipartite matching\" problem, and the Edmonds-Karp algorithm is the simpliest way to solve it (https://en.wikipedia.org/wiki/Edmonds%E2%80%93Karp_algorithm)\n\nHowever, this is an algorithm for finding the maximum flow in a network, which is a larger problem than simple bipartite matching, and the explanations of this algorithm are really a lot more complicated than you need.  It's understandable that you had some trouble implementing this from the literature, but actually when the problem is reduced to simple (unweighted) bipartite matching, the algorithm is easy to understand:\n\n\nMake an initial assignment\nTry to find an improvement\nRepeat until no more improvements can be found.\n\n\nFor bipartite matching, an \"improvement\" always has the same form, which is what makes this problem easy to solve.  To find an improvement, you have to find a path that connects an unassigned shopper to an unassigned order, following these rules:\n\n\nThe path can go from any shopper to any order he/she could fulfill but does not\nThe path can go from any order only to the shopper that is fulfilling it in the current assignment.\n\n\nYou use bread-first search to find the shortest path, which will correspond to the improvement that changes the smallest number of existing assignments.\n\nThe path you find will necessarily have an odd number of edges, and the even-numbered edges will be assignments.  To implement the improvement, you remove those assignments and replace them with the odd-numbered edges.  There's one more of those, which is what makes it an improvement.  It looks like this:\n\n```\nPREVIOUS       PATH FOUND      IMPROVED ASSIGNMENT\n\n    1              1                  1\n                 /                  /\nA              A                  A\n  \\              \\     \n    2              2                  2\n                 /                  /\nB              B                  B           \n  \\              \\       \n    3              3                  3\n                 /                  /\nC              C                  C\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "R: Implement name matching using bipartite graph\r\n                \r\nI'm trying to do name matching using bipartite graph theory. Ideally I'd like to be able to return the percent match at the end. So here is an example:\n```\nv1 = \"John Alex Smith\"\nv2 = \"John A Smith\"\n```\n\nI want to be able to produce a graph like this:\n```\n\"J\" \"O\" \"H\" \"N\" \"A\" \"L\" \"E\" \"X\" \"S\" \"M\" \"I\" \"T\" \"H\"\n |   |   |   |   |               |   |   |   |   |\n\"J\" \"O\" \"H\" \"N\" \"A\"             \"S\" \"M\" \"I\" \"T\" \"H\"\n```\n\nI have some code I've written based on a few examples I've found online. ```\nvert1```\n and ```\nvert2```\nare character vectors.\n```\nedgeVec <- c(vert1, vert2)\ng <- make_empty_graph(n=0, directed = FALSE)\ng <- add.vertices(g, nv=length(vert1), attr=list(name=paste0(vert1), \n                  type=rep(TRUE, length(vert1))))\ng <- add.vertices(g, nv=length(vert2), attr=list(name=vert2), \n                  type=rep(FALSE, length(vert2)))\n\ng <- add.edges(g, edgeVec)\n\nplot.igraph(g, layout=layout.bipartite, vertex.color=c(\"blue\", \"green\")[V(g)$type+1])\nis.bipartite(g)\n```\n\nRight now it is plotting the vertices (very closely together to the point where you can't tell which letter goes with which circle), 'however, it is not plotting edges connecting the vertices'.\nSo I have 2 questions,\n\nhow do I make the vertices graphically more separated?\nhow do I compose my edge vector?\n\nRight now I'm combining both ```\nvert1```\n and ```\nvert2```\n into \"edgeVec\", which is probably not the best way to do it and probably also my problem.\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Is there a way to return the edges used in a minimum weight matching on a bipartite graph?\r\n                \r\nI've been using networkx to find the minimum weight full matching for my bipartite graph but I have been unable to find the result edges used in this minimum matching (or at least the weight of the result graph). If anyone knows how to do this any help would be appreciated, thank you\n    ", "Answer": "\r\nThis is the graph I am going to use for an example:\n```\nG = nx.Graph()\nedges = [\n    (0, 4, {'weight': 1}), (0, 6, {'weight': 4}),\n    (1, 5, {'weight': 1}), (1, 6, {'weight': 1}),\n    (2, 4, {'weight': 3}), (3, 4, {'weight': 2}),\n]\nG.add_edges_from(edges)\n```\n\nHere is how to get the edges that are part of the minimum matching (if your graph is undirected you'll end up having both (u, v) and (v, u)):\n```\nmin_matching = list(nx.bipartite.minimum_weight_full_matching(G).items())\n```\n\nHere is the output:\n```\n>>> min_matching\n[(0, 6), (1, 5), (3, 4), (6, 0), (5, 1), (4, 3)]\n```\n\nHere is how to get the total weight (remember that you have both (u, v) and (v, u) in the undirected case, that's why you need to divide by two):\n```\nweight = sum(\n    G.edges[u, v]['weight']\n    for u, v in nx.bipartite.minimum_weight_full_matching(G).items()\n) // 2\n```\n\nHere is the output:\n```\n>>> weight\n7\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "JAVA Jgrapht Hopcroft Karp Bipartite Matching\r\n                \r\nI'm trying to make a HopcroftKarpBipartiteMatching but none of demos or I can't really find anything else to help me with using the library.  I can't figure out from documentation how and what is required to instantiate the HopcroftKarpBipartiteMatching class?  I have a set of strings that represent the vertices. Its a list that for each path from vertices.  For an example:\n\n```\nArray{(V1,V7), (V1,V8), (V1,V6)]\nArray{(V2,V8), (V2,V5), (V2, V6)]\nArray{(V3, V4),(V3, V8)}\n```\n\n\nPossible solution with JApplet\n\n```\npublic class GraphDemo  extends JApplet{\n\n     private static final long serialVersionUID = 2202072534703043194L;\n        private static final Dimension DEFAULT_SIZE = new Dimension(530, 320);\n\n\n\n        private JGraphXAdapter<String, DefaultEdge> jgxAdapter;\n\n    public static void main(String[] args) {\n\n\n\n                JGraphAdapterDemo applet = new JGraphAdapterDemo();\n                applet.init();\n\n                JFrame frame = new JFrame();\n                frame.getContentPane().add(applet);\n                frame.setTitle(\"JGraphT Adapter to JGraph Demo\");\n                frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n                frame.pack();\n                frame.setVisible(true);\n            }\n\n    public void init()\n    { \n        UndirectedGraph<String, DefaultEdge> g = \n                new SimpleGraph<String, DefaultEdge>(DefaultEdge.class);\n\n        jgxAdapter = new JGraphXAdapter<String, DefaultEdge>(g);\n\n        getContentPane().add(new mxGraphComponent(jgxAdapter));\n        resize(DEFAULT_SIZE);\n\n        String x1 = \"x1\";\n        String x2 = \"x2\";\n        String x3 = \"x3\";\n\n        String y1 = \"y1\";\n        String y2 = \"y2\";\n        String y3 = \"y3\";\n        String y4 = \"y5\";\n\n        g.addVertex(x1);\n        g.addVertex(x2);\n        g.addVertex(x3);\n\n        g.addVertex(y1);\n        g.addVertex(y2);\n        g.addVertex(y3);\n        g.addVertex(y4);\n\n        g.addEdge(x1, y1);\n        g.addEdge(x1, y2);\n\n        g.addEdge(x2, y1);\n        g.addEdge(x2, y4);\n\n        g.addEdge(x3, y2);\n        g.addEdge(x3, y3);\n\n        Set<String> p1 = new HashSet<String>(Arrays.asList(x1, x2, x3));\n        Set<String> p2 = new HashSet<String>(Arrays.asList(y1, y2, y3, y4));\n\n        HopcroftKarpBipartiteMatching<String, DefaultEdge> alg = \n            new HopcroftKarpBipartiteMatching<String, DefaultEdge>(g, p1, p2);\n\n        Set<DefaultEdge> match = alg.getMatching();\n\n        mxCircleLayout layout = new mxCircleLayout(jgxAdapter);\n        layout.execute(jgxAdapter.getDefaultParent());\n\n        System.out.println(g.toString());\n        System.out.println(match);\n    }\n}\n```\n\n\n\n    ", "Answer": "\r\nHopcroftKarpBipartiteMatching constructor needs a graph and two partitioning sets, ie:  \n\n```\nUndirectedGraph<String, DefaultEdge> g = ...\nSet<String> part1 = ...\nSet<String> part2 = ...\nnew HopcroftKarpBipartiteMatching<String, DefaultEdge>(g, part1, part2);\n```\n\n\nHere is a simple example: \n\n```\nimport java.util.Arrays;\nimport java.util.HashSet;\nimport java.util.Set;\n\nimport org.jgrapht.UndirectedGraph;\nimport org.jgrapht.alg.HopcroftKarpBipartiteMatching;\nimport org.jgrapht.graph.DefaultEdge;\nimport org.jgrapht.graph.SimpleGraph;\n\npublic class GraphDemo {\n\n    public static void main(String[] args) {\n        UndirectedGraph<String, DefaultEdge> g = \n                new SimpleGraph<String, DefaultEdge>(DefaultEdge.class);\n\n        String x1 = \"x1\";\n        String x2 = \"x2\";\n        String x3 = \"x3\";\n\n        String y1 = \"y1\";\n        String y2 = \"y2\";\n        String y3 = \"y3\";\n        String y4 = \"y5\";\n\n        g.addVertex(x1);\n        g.addVertex(x2);\n        g.addVertex(x3);\n\n        g.addVertex(y1);\n        g.addVertex(y2);\n        g.addVertex(y3);\n        g.addVertex(y4);\n\n        g.addEdge(x1, y1);\n        g.addEdge(x1, y2);\n\n        g.addEdge(x2, y1);\n        g.addEdge(x2, y4);\n\n        g.addEdge(x3, y2);\n        g.addEdge(x3, y3);\n\n        Set<String> p1 = new HashSet<String>(Arrays.asList(x1, x2, x3));\n        Set<String> p2 = new HashSet<String>(Arrays.asList(y1, y2, y3, y4));\n\n        HopcroftKarpBipartiteMatching<String, DefaultEdge> alg = \n            new HopcroftKarpBipartiteMatching<String, DefaultEdge>(g, p1, p2);\n\n        Set<DefaultEdge> match = alg.getMatching();\n\n        System.out.println(g.toString());\n        System.out.println(match);\n    }\n}\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Find the minimum vertex cover for a Bipartite Graph, if we are given the maximum Bipartite Matching\r\n                \r\nFrom Konig's Theorem, the size of Maximum Matching (|M|) and minimum vertex cover is the same. Now we can include both ends of the matching in the vertex cover to find a vertex cover, but its size will be 2|M|. So I considered choosing a matching edge and then checking the degree of both ends. And then include the vertex with the higher degree. Suppose the degree of both ends is the same. We can include either. I tried this with a few examples I could think of it worked. But I am not sure of the algorithm. Is this correct? Also, if not, can anyone provide any counter-example?\nI have seen other algorithms for this. I just wanted to see the issue with my approach.\n    ", "Answer": "\r\n\nIs this correct? Also, if not, can anyone provide any counter-example?\n\nConsider the path graph G = (V, E), V = {a, b, c, d, e}, E = {(a,b), (b,c), (c,d), (d,e)}.\nA maximum matching on this graph must have size 2.\nConsider the maximum matching M = {(a,b), (c,d)}.\nYour algorithm must choose which vertex to include in the cover, c or d. Vertices c and d have same degree, so your algorithm might choose c to be in the cover. But that would be a mistake. It must absolutely be d in the cover, otherwise vertex e is not covered.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to solve Subtree Isomorphism using maximum bipartite matching?\r\n                \r\nHow do we determine if a given tree T contains subtree that is isomorphic to another tree S?\n\nTwo trees are called isomorphic if one of them can be obtained from other by a series of flips, i.e. by swapping left and right children of a number of nodes. Any number of nodes at any level can have their children swapped. Two empty trees are isomorphic.\n\nI've read at few places that bipartiate matching algorithms can be used to solve this problem however I can't find any non-paywalled sources for the details. There seems to be many research papers on this problem, most of them are again behind paywall, however I'm not currently interested in latest research algorithm for this problem. My question is how does bipartiate matching applies to this problem?\n\nPS: There seems to be some confusion on Internet about what is meant by \"isomorphic\". Above is definition I found at most places but some places mentioned \"isomorphic\" means trees are of same shape regardless of node values. If someone can clear up this confusion, that had be great too.\n    ", "Answer": "\r\nI'm going to talk about rooted subtree isomorphism; the unrooted case can be handled without regard to efficiency by trying all roots.\n\nThe basic idea is that if you have trees\n\n```\n    A            B\n   /|\\          /|\\\n  / | \\        / | \\\n /  |  \\      /  |  \\\na1 ...  am   b1 ...  bn\n/\\      /\\   /\\      /\\\n```\n\n\nand want to know whether ```\nA```\n is a subtree of ```\nB```\n in such a way that ```\nA```\n maps to ```\nB```\n, then for all ```\ni```\n and ```\nj```\n, you compute recursively whether the subtree rooted at ```\nai```\n is a subtree of the tree rooted at ```\nbj```\n in such a way that ```\nai```\n maps to ```\nbj```\n. (The base cases are when ```\nA```\n or ```\nB```\n is a leaf.) Now, it's not enough that each subtree be mappable, because if some ```\nbj```\n has a particularly rich structure, then several ```\nai```\ns might be subtrees, but the requirements of isomorphism won't let them share that ```\nbj```\n. This is where maximum matching comes in: we try to match all of the ```\nai```\ns with the ```\nbj```\ns in such a way that the subtrees can be mapped.\n\nTo do the general rooted problem, try all possible choices of ```\nB```\n.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Partitioning perfect matchings in a bipartite graph\r\n                \r\nIn the 'marriage problem', we have N boys and N girls and an NxN binary matrix telling us which pairings are suitable, and want to pair each girl to a boy. (i.e. we want to find a perfect matching in a bipartite graph).\n\nHall's theorem says that you can find a perfect matching if every collection of boy-nodes is collectively adjacent to at least as many girl-nodes; and there are fast augmenting-path algorithms that find perfect these matchings.\n\nI'm looking for an efficient way to find collections of boy-nodes that are collectively adjacent to exactly as many girl-nodes (i.e. we have equality in Hall's criterion). These boys must be paired with these girls, and the rest of the boys with the rest of the girls, so that all perfect matchings respect this partitioning.\n\nMy graph theory is a bit rusty, surely there must be a better way than enumerating all 2^N subsets and counting each one's neighbours?\n    ", "Answer": "\r\nThis is possible in polynomial time.  Model your bipartite matching problem as a maximum flow problem in a directed graph.  Then use an algorithm for enumerating minimum cuts.  Search on Google for \"enumerate minimum cuts\", or papers by Vazirani & Yannakakis or Yeh & Wang.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Matching alghoritm in bipartite graph\r\n                \r\nI know, this looks like school homework, but this is a real business problem.\nSince I cannot write, what kind of object we are working with, I will use a bit surrealistic problem description:\n\nThere is a number of cities(a few dozens).\nEach city has maximum number of missiles, that can hit it(ranging from 1 to few hundreds). \n\nThere is also a number of missiles, distributed around the world (about 1-2 thousands).\nEach missile has a list of cities it can target. There can be only one city, there can be a few, or it can contains all possible cities.\n\nTask: \n\nAssign targets to missiles so that the maximum number of missiles can fire.\n\nWhat we are doing now, is \"naive-force-random\" solution:\n\n```\n1. Randomly sort list of missiles\n2. Pass each missile, and set it to target first city from it's list, that still can accept missile\n3. Count number of of targeted missiles\n4. If it's better than best solution so far, save it\n5. Repeat multiple times (we can do this about 1-10 million times in reasonable time).\n```\n\n\nWe can slightly improve results, if we start from targeting cities, that has less missiles than allowed maximum - but the rest is still a matter of randomizing and repetitions. \n\nPhysically test every solution is impossible, as there will more than > 1000! (thousand factorial) combinations.\n\nI am looking for alghoritm, maybe some link, or literature, that can fit my problem.\nThis is a kind of graph theory problem, with bipartite graph - even a name of this kind of graph would be helpful in futher investigation.\n\nWe were thinking about the Hopcroft-Carp alghorithm, but it will not fit - it would be good if only one missile per city would be allowed.\n\nAny help would be appreciated.\n\nFeel free to correct my English.\n    ", "Answer": "\r\nA possible way is to use a genetic algorithm. If there are m missiles, a chromosome would be a vector of m values, each value being an integer in a range (0, 1,..., n). 0 is a special value that means \"no target\". n is a value that depends on the missile (since each missile has its own list of possible targets).\n\nThe function to maximize (chromosome fitness) is the number of non-zero values.\n\nThere is however an issue with crossing and mutation: they can generate invalid solutions (because city capacities may not be satisfied). A workaround is to apply a penalty to the fitness function.\n\nSay we have city 1 with capacity 10 and city 2 with capacity 5. If city 1 receives 12 missiles and city 2 receives 8, we have 2 + 3 = 5 extra missiles. Remove 5*k from the fitness (k is some coefficient that will need to be chosen).\n\nThe genetic algorithm favors chromosomes with a high fitness, which means it should produce solutions that satisfy the capacity constraints.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "how to find the minimum-weight perfect matching if the graph is not bipartite in python\r\n                \r\nthe concept of perfect matching in wiki:\n\nA perfect matching is a matching that matches all vertices of the\ngraph. That is, a matching is perfect if every vertex of the graph is\nincident to an edge of the matching.\n\nSo the minimum-weight perfect matching is one of combinations which has smallest weight. At first, my idea is following greedy algorithm(Notice: my graph is complete, each vertex have edges to rest of vertices):\nPicking one vertex from the graph and find its closest neighbor vertex in each step, then drop them and do the loop until there is no vertex in the graph. However, it is not optimal unless calcualting n! times:\n```\nwhile odd_vert:\n    v = vertices.pop()\n    length = float(\"inf\")\n    closest = 0\n    for u in odd_vert:\n        if graph[v][u][\"weight\"] < length:\n            length = graph[v][u][\"weight\"]\n            closest = u\n    graph_minimum_match.add_edge(v, closest, weight = length)\n```\n\nI find some function in networkx but it ask the graph is bipartite:\n```\nnx.algorithms.bipartite.matching.minimum_weight_full_matching(G, top_nodes=None, weight='weight')\n```\n\nBesides, find the maximum weight matching:\n```\nnx.algorithms.matching.max_weight_matching(G, maxcardinality=True)\n```\n\nThen, I search an article shows blossom belief propagation, but I am not sure if it can be achieved, so any idea of it?\n    ", "Answer": "\r\nYou can reduce minimum weight matching to maximum weight matching\nYou can invert all edge weights in your graph, either by multiplying by -1 or by subtracting them from the maximum weight. Then, if you can find a maximum perfect matching in this transformed graph, that matching is minimal in your original graph.\n```\nnx.algorithms.matching.max_weight_matching```\n has the parameter ```\nmaxcardinality```\n which, if set to ```\nTrue```\n, means that it will only allow for complete matchings if such a matching exists. Thus, you can call the ```\nnetworkx```\n function on your transformed graph and check if indeed the matching is complete. If it is, this matching is your desired result. If it is not, then no perfect matching is possible.\nIn a complete graph with an even number of vertices a complete matching is of course always possible. In addition, if the transformed graph has only positive weights (for example by using the subtraction-based transformation), the maximum weight graph will always have maximum cardinality.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Integer Linear Program, Bipartite Matching with Constraints How To?\r\n                \r\nThe following program produces a matching between two sets of vertices, one represents meets between two teams and the other time slots when the meets could happen. The adjacency map represents both teams' availability to meet at any given time slot, days[][] represents which time slots are on the same date, weekDays[][] represents what day of the week is a given date, and teamToGames maps every meet that includes a given team. The decision variables are in a map match[][], with a value of 1 where a meet is matched to a time slot. Constraints are added so that only 1 meet can be matched to a time slot, only 1 time slot can be matched to a meet, only if allowed by the respective adj[][] value, and so that meets involving the same team cannot be matched to a game slot on the same date nor the following or previous date, excluding thursday-sunday.\nWhat I don't know how to do now, is how can I make it prefer assigning two or more meets on the same date rather than one meet on each of two separate dates? So that there is the least possible amount of dates with only one meet. Kind of like constraining the number of meets on a date to either 0 or >=2 but only if possible.\nThank you for reading and for any help you can offer.\n```\n// [START program]\n// [START import]\nimport com.google.ortools.linearsolver.MPConstraint;\nimport com.google.ortools.linearsolver.MPObjective;\nimport com.google.ortools.linearsolver.MPSolver;\nimport com.google.ortools.linearsolver.MPVariable;\n// [END import]\n\n/** MIP example that solves an assignment problem. */\npublic class GameMatching {\n    static {\n        System.loadLibrary(\"jniortools\");\n    }\n\n    public static void main(String[] args) {\n        // Data\n        // [START data_model]\n        // Adjacency matrix represents which games can happen on which dates\n        int[][] adj = {\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n          {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},\n          {0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n        };\n\n        int numGames = adj.length;\n        int numDates = adj[0].length;\n\n        //represents which game time slots are on a given day (4 games on sundays, 2 on weekdays)\n        int[][] days = {\n              {0, 1, 2, 3},\n              {4, 5},\n              {6, 7},\n              {8, 9, 10, 11},\n              {12, 13},\n              {14, 15},\n              {16, 17},\n              {18, 19},\n              {20, 21, 22, 23},\n              {24, 25},\n              {26, 27},\n              {28, 29},\n              {30, 31},\n              {32, 33, 34, 35},\n              {36, 37},\n              {38, 39},\n              {40, 41},\n              {42, 43},\n              {44, 45, 46, 47},\n              {48, 49},\n              {50, 51},\n              {52, 53, 54, 55},\n              {56, 57},\n              {58, 59},\n              {60, 61},\n              {62, 63},\n              {64, 65, 66, 67},\n              {68, 69},\n              {70, 71},\n              {72, 73},\n              {74, 75},\n              {76, 77, 78, 79}\n        };\n        //represents what day of the week is a day, a team can play thursday and sunday, but not sunday and monday 0 is sunday, 1 is monday...\n        int[] weekDays = {0, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0};\n\n        // teamToGames[i][j] represents a team i's, games j\n        int[][] teamToGames = {\n              {1, 3, 9, 16, 18, 26},\n              {0, 8, 12, 16, 23, 28},\n              {1, 5, 7, 13, 21, 27},\n              {2, 5, 14, 17, 22, 26},\n              {7, 15, 19, 21, 24, 28},\n              {3, 10, 14, 20, 27, 29},\n              {2, 6, 9, 13, 23, 29},\n              {6, 8, 11, 18, 19, 25},\n              {8, 4, 10, 11, 17, 24},\n              {4, 12, 15, 20, 22, 25},\n        };\n       \n        // [END data_model]\n\n        // Solver\n        // [START solver]\n        // Create the linear solver with the CBC backend.\n        MPSolver solver = new MPSolver(\"AssignmentMip\", MPSolver.OptimizationProblemType.CBC_MIXED_INTEGER_PROGRAMMING);\n        // [END solver]\n\n        // Variables\n        // [START variables]\n        // x[i][j] is an array of 0-1 variables, which will be 1\n        // if a game i is assigned to date j.\n        MPVariable[][] match = new MPVariable[numGames][numDates];\n        for (int i = 0; i < numGames; ++i) {\n            for (int j = 0; j < numDates; ++j) {\n                match[i][j] = solver.makeIntVar(0, 1, \"\");\n            }\n        }\n\n        // [END variables]\n\n        // Constraints\n        // [START constraints]\n        // Each game is assigned to at most one date.\n        for (int i = 0; i < numGames; ++i) {\n            MPConstraint constraint = solver.makeConstraint(0, 1, \"\");\n            for (int j = 0; j < numDates; ++j) {\n                constraint.setCoefficient(match[i][j], 1);\n            }\n        }\n        // Each date is assigned to at most one game.\n        for (int j = 0; j < numDates; ++j) {\n            MPConstraint constraint = solver.makeConstraint(0, 1, \"\");\n            for (int i = 0; i < numGames; ++i) {\n                constraint.setCoefficient(match[i][j], 1);\n            }\n        }\n        // Can only assign respecting adj matrix\n        for (int i = 0; i < numGames; ++i) {\n            for (int j = 0; j < numDates; ++j) {\n                MPConstraint constraint = solver.makeConstraint(0, adj[i][j], \"\");\n                constraint.setCoefficient(match[i][j], 1);\n            }\n        }\n\n        // Cannot assign team to consecutive dates\n        for (int i = 0; i < teamToGames.length; ++i) {\n            for (int j = 0; j < days.length - 1; ++j) {\n                if (weekDays[j] != 4) {\n                    MPConstraint constraint = solver.makeConstraint(0, 1, \"\");\n                    for (int k = 0; k < teamToGames[i].length; ++k) {\n                        for (int l = 0; l < days[j].length; ++l) {\n                            constraint.setCoefficient(match[teamToGames[i][k]][l], 1);\n                        }\n                        for (int l = 0; l < days[j+1].length; ++l) {\n                            constraint.setCoefficient(match[teamToGames[i][k]][l], 1);\n                        }\n                    }\n                }\n            }\n        }\n\n        // [END constraints]\n\n        // Objective\n        // [START objective]\n        MPObjective objective = solver.objective();\n        for (int i = 0; i < numGames; ++i) {\n            for (int j = 0; j < numDates; ++j) {\n                objective.setCoefficient(match[i][j], 1);\n            }\n        }\n\n        objective.setMaximization();\n        // [END objective]\n\n        // Solve\n        // [START solve]\n        MPSolver.ResultStatus resultStatus = solver.solve();\n        // [END solve]\n\n        // Print solution.\n        // [START print_solution]\n        // Check that the problem has a feasible solution.\n        if (resultStatus == MPSolver.ResultStatus.OPTIMAL || resultStatus == MPSolver.ResultStatus.FEASIBLE) {\n            System.out.println(\"Total matches: \" + objective.value() + \"\\n\");\n            for (int i = 0; i < numGames; ++i) {\n                for (int j = 0; j < numDates; ++j) {\n                    // Test if x[i][j] is 0 or 1 (with tolerance for floating point\n                    // arithmetic).\n                    if (match[i][j].solutionValue() > 0.5) {\n                        System.out.println(\"Game \" + i + \" assigned to date \" + j);\n                    }\n                }\n            }\n        } else {\n            System.err.println(\"No solution found.\");\n        }\n        // [END print_solution]\n    }\n\n    // private GameMatching() {\n    // }\n}\n// [END program]\n```\n\n    ", "Answer": "\r\nBorrowing a page from the facility location playbook, make a new array of 0-1 variables ```\ncanHaveMatches[j]```\n, add constraints ```\nmatch[i][j] <= canHaveMatches[j]```\n, minimize ```\nsum_j canHaveMatches[j]```\n.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Gale Shapley matching algorithm with Polygamy by Men Upto four Marriages Using Bipartite Graph\r\n                \r\nHow to modify Gale Shapley matching algorithm with Polygamy by Men Upto four Marriages Using Bipartite Graph\nI want to add weights to each node of bipartite graph based on certain criteria for example age, height , education etc after all the nodes are assigned weight algorithm will be executed that recommend best possible stable matches as per the priorities of the men and women.\nConditions:\n\nOne man can marry one women, One man can marry two women, one man can marry three women but not more than four women at a time\n\nIn case of divorce or death of any women a men can get one more.\n\nIf man dies all females could get marry again after three months.\n\nOne women could marry one man at a time.\n\nIn case of divorce female can remarry after three months.\n\n\nImport Python Libraries\n```\nimport networkx as nx\nimport matplotlib.pyplot as plt\n```\n\nExample preference lists for 3 men and 3 women\n```\nmen_prefs = {\n    'm1': ['w2', 'w1', 'w3'],\n    'm2': ['w1', 'w2', 'w3'],\n    'm3': ['w1', 'w3', 'w2']\n}\nwomen_prefs = {\n    'w1': ['m3', 'm1', 'm2'],\n    'w2': ['m2', 'm1', 'm3'],\n    'w3': ['m1', 'm3', 'm2']\n}\n```\n\nCreate the bipartite graph\n```\nB = nx.Graph()\nB.add_nodes_from(men_prefs.keys(), bipartite=0)\nB.add_nodes_from(women_prefs.keys(), bipartite=1)\nfor man, prefs in men_prefs.items():\n    for woman in prefs:\n        B.add_edge(man, woman)\n```\n\nRun the Gale-Shapley algorithm\n```\nfree_men = set(men_prefs.keys())\nengaged = {}\nwhile free_men:\n    man = free_men.pop()\n    woman = men_prefs[man][0]\n    if woman in engaged:\n        current_man = engaged[woman]\n        if women_prefs[woman].index(man) < women_prefs[woman].index(current_man):\n            engaged[woman] = man\n            free_men.add(current_man)\n        else:\n            free_men.add(man)\n    else:\n        engaged[woman] = man\n```\n\nDraw the graph with the new matching\n```\npos = nx.bipartite_layout(B, men_prefs.keys())\nplt.figure(figsize=(6, 4))\nnx.draw_networkx_nodes(B, pos, node_color=['lightblue'])\nnx.draw_networkx_edges(B, pos, edgelist=engaged.items(), edge_color='red', width=2)\nnx.draw_networkx_labels(B, pos, font_size=12, font_family='sans-serif')\nplt.axis('off')\nplt.show()\n```\n\n    ", "Answer": "\r\nMake a number of copies of each man.  Run the usual algorithm.  Recombine men to get your answer.\nMore general variations can be solved by writing it as a max flow problem and then using https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Boost Maximum Weighted Matching in undirected bipartite random graphs hangs in an infinite loop\r\n                \r\nI'm currently working on a project with the goal to compare the boost maximum weighted matching problem with an implementation of the auction algorithm for the transportation problem on c++.\nThe point is that if the number of verticies start to become higher the maximum weighted matching get stuck in a infinite loop, this fact happens also with small number of verticies  like 6 (3 verticies for Bidders and others 3 for Items).\nMoreover if I try to rerun the application sometimes it happens that the execution of the maximum weighted matching runs until number of verticies of 12.\nI though that the problem was the creation of the bipartite graph, but the is_bipartite function of boost return every time true, so I don't understand where the problem is.\n```\n#include <vector>\n#include <chrono>\n#include <string>\n\n#include <boost/graph/adjacency_list.hpp>\n#include <boost/graph/maximum_weighted_matching.hpp>\n#include <boost/graph/graph_utility.hpp>\n#include <boost/graph/properties.hpp>\n#include <boost/graph/grid_graph.hpp>\n#include <boost/graph/graphviz.hpp>\n#include <boost/property_map/function_property_map.hpp>\n#include <boost/property_map/transform_value_property_map.hpp>\n#include <boost/variant.hpp>\n#include <boost/lexical_cast.hpp>\n#include <boost/graph/bipartite.hpp>\n\n\nnamespace Nodes {\n    struct Bidder {\n        int    id;\n        int    best_item = -1;\n        float val_first_best_item = -1.;\n        float val_second_best_item = -1.;\n    };\n\n    struct Item {\n        int    id;\n        float cost = 0.;\n        int    high_bidder = -1;\n        float high_bid = -1.;\n    };\n    \n    static inline std::ostream& operator<<(std::ostream& os, Bidder const& b) {\n        return os << \"BIDDER:\" << b.id << \"|best_item:\" << b.best_item\n            << \"|best1:\" << b.val_first_best_item\n            << \"|best2:\" << b.val_second_best_item;\n    }\n    static inline std::ostream& operator<<(std::ostream& os, Item const& i) {\n        return os << \"ITEM:\" << i.id << \"|cost:\" << i.cost\n            << \"|high_bidder:\" << i.high_bidder\n            << \"|high_bid:\" << i.high_bid;\n    }\n\n    using VertexProp = boost::variant<Bidder, Item>;\n\n    static inline std::istream& operator>>(std::istream& is, VertexProp&) { return is; }\n}\n\nusing Nodes::Bidder;\nusing Nodes::Item;\nusing Nodes::VertexProp;\n\n\nstruct GraphProp {\n    std::vector<int> bidder2item;\n    std::vector<int> item2bidder;\n};\n\nusing EdgeProp = boost::property<boost::edge_weight_t, float, boost::property<boost::edge_index_t, float>>;\nusing Graph = boost::adjacency_list<boost::listS, boost::vecS, boost::undirectedS, VertexProp, EdgeProp, GraphProp>;\nusing vertex_iterator = boost::graph_traits<Graph>::vertex_iterator;\nusing V = Graph::vertex_descriptor;\nusing E = Graph::edge_descriptor;\nusing VertexFilter = std::function<bool(V)>;\nusing EdgeFilter = std::function<bool(E)>;\nusing FMap = boost::filtered_graph<Graph, EdgeFilter, VertexFilter>;\n\n\nGraph generateData(int N) {\n    Graph g;\n\n    //std::uniform_real_distribution<float> distribution(0., 20.);\n\n    for (int i = 0; i < N; ++i) boost::add_vertex(Bidder{ i }, g);\n    for (int i = 0; i < N; ++i) boost::add_vertex(Item{ i }, g);\n\n    GraphProp& gp = g[boost::graph_bundle];\n    gp.bidder2item.assign(N, -1);\n    gp.item2bidder.assign(N, -1);\n\n    // Every left nodes has a connection to every right nodes\n    for (int bidder = 0; bidder < N; ++bidder) {\n        for (int item = 0; item < N; ++item) {\n            //float value = distribution(generator);\n\n            float value = 1 + static_cast <float> (rand()) / (static_cast <float> (RAND_MAX / (40 - 1)));\n            boost::add_edge(bidder, N + item, value, g);\n        }\n    }\n\n    return g;\n}\n\n\nvoid printGraph(Graph& g) {\n    boost::dynamic_properties dp;\n    dp.property(\"node_id\", get(boost::vertex_index, g));\n    dp.property(\"label\", get(boost::vertex_bundle, g));\n    dp.property(\"weight\", get(boost::edge_weight, g));\n    write_graphviz_dp(std::cout, g, dp);\n}\n\n\nvoid maximum_weight_matching(Graph& graph, long long& time_execution, float& total_cost){\n    vertex_iterator vi, vi_end;\n\n    std::vector <boost::graph_traits<Graph>::vertex_descriptor> mate(boost::num_vertices(graph));\n\n    auto t_start = std::chrono::high_resolution_clock::now();\n    boost::maximum_weighted_matching(graph, &mate[0], boost::get(boost::vertex_index, graph));\n    time_execution = std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::high_resolution_clock::now() - t_start).count();\n    total_cost = float(boost::matching_weight_sum(graph, &mate[0]));\n\n\n    std::cout << \"The matching is:\" << std::endl;\n    for (boost::tie(vi, vi_end) = boost::vertices(graph); vi != vi_end; ++vi)\n        if (mate[*vi] != boost::graph_traits< Graph>::null_vertex() && *vi < mate[*vi])\n            std::cout << \"Bidder: \" << *vi << \" has item \" << mate[*vi] % (boost::num_vertices(graph) / 2) << std::endl;\n    \n}\n\n\nconstexpr auto MIN = 3;\nconstexpr auto MAX = 15;\n\nint main(int argc, const char* argv[]) {\n    srand((unsigned int)time(0));\n    for (int n_bidders_items = MIN; n_bidders_items <= MAX; ++n_bidders_items) {\n        std::cout << \"Generation of a Bipartite Graph with \" << n_bidders_items << \" per part\\n\";\n\n        long long time_execution_mwm;\n        float total_cost_mwm = 0.;\n\n        Graph graph = generateData(n_bidders_items);\n        printGraph(graph);\n\n        //MAXIMUM WEIGHTED MATCHING\n        std::cout << \"Execution of Maximum Weighted Matching\\n\";\n        maximum_weight_matching(graph, time_execution_mwm, total_cost_mwm);\n        std::cout << \"Execution time of Maximum Weight Matching: \" << float(time_execution_mwm) / 1000 << \" milliseconds, with total cost: \" << total_cost_mwm << \"\\n\\n\";\n\n    }\n\n    return 0;\n}\n```\n\n    ", "Answer": "\r\nSo - I spent some (a lot of) time to review and play around. Then I remembered I'd seen it all before:\n\nIssue using cpp boost maximum_weighted_matching algorithm with floating point edge weights\n\nIf I say so myself, that analysis is pretty thorough :)\nSome Review Notes\nOkay reviewing from the top.\n\nthere's a lot of unused includes, fine (I commented them out to be sure)\n\nwhy is your ```\nedge_index```\n a ```\nfloat```\n? That seems wrong\n\nyou're ```\nduration_casting```\n to milliseconds, but then still doing ```\ntime_execution/1000```\n - that's wrong. Simplify:\n```\n (now() - start_t) / 1ms\n```\n\nor\n```\n (now() - start_t) / 1.s\n```\n\nfor floating point\n\nYou regressed from using ```\n<random>```\n to (badly) using ```\nrand()```\n. Just don't. Did you mean ```\nstd::uniform_real_distribution<float>(1, 40)```\n?\n\nThe likely cause of big trouble:\n```\n add_edge(bidder, N + item, dist(prng), g);\n```\n\nThis only sets one property value (the generated ```\n[1.f, 40.)```\n value) but the properties are defined:\n```\n using EdgeProp = boost::property<boost::edge_weight_t, float,\n                                  boost::property<boost::edge_index_t, float>>;\n```\n\nThe best you can hope this does is leave the edge index uninitialized. That's not a problem unless it's used.\n\nthere's a number of C-style casts (like ```\nfloat(expr)```\n). Avoid these as they might hide problems\n\nthere's no need to specify the default vertex index\n\n\nApplying some of the fixes, and some related shavings results in: https://godbolt.org/z/4fjvhEr1Y\n```\n#undef NDEBUG\n//#include <boo/lexical_cast.hpp>\n//#include <boost/graph/graph_utility.hpp>\n//#include <boost/graph/grid_graph.hpp>\n//#include <boost/property_map/function_property_map.hpp>\n//#include <boost/property_map/transform_value_property_map.hpp>\n#include <boost/graph/adjacency_list.hpp>\n#include <boost/graph/bipartite.hpp>\n#include <boost/graph/graphviz.hpp>\n#include <boost/graph/maximum_weighted_matching.hpp>\n#include <boost/graph/properties.hpp>\n#include <boost/variant.hpp>\n\n#include <chrono>\nusing namespace std::chrono_literals;\nstatic auto now = std::chrono::high_resolution_clock::now;\nusing duration = std::chrono::high_resolution_clock::duration;\n\n#include <random>\nstatic std::mt19937 prng{std::random_device{}()}; // seeded as well\n\nnamespace Nodes {\n    struct Bidder {\n        int   id;\n        int   best_item            = -1;\n        float val_first_best_item  = -1.;\n        float val_second_best_item = -1.;\n    };\n\n    struct Item {\n        int   id;\n        float cost        = 0.;\n        int   high_bidder = -1;\n        float high_bid    = -1.;\n    };\n\n    static inline std::ostream& operator<<(std::ostream& os, Bidder const& b) {\n        return os << \"BIDDER:\" << b.id << \"|best_item:\" << b.best_item\n                << \"|best1:\" << b.val_first_best_item\n                << \"|best2:\" << b.val_second_best_item;\n    }\n    static inline std::ostream& operator<<(std::ostream& os, Item const& i) {\n        return os << \"ITEM:\" << i.id << \"|cost:\" << i.cost\n                << \"|high_bidder:\" << i.high_bidder\n                << \"|high_bid:\" << i.high_bid;\n    }\n\n    using VertexProp = boost::variant<Bidder, Item>;\n\n    static inline std::istream& operator>>(std::istream& is, VertexProp&) {\n        return is;\n    }\n} // namespace Nodes\n\nusing Nodes::Bidder;\nusing Nodes::Item;\nusing Nodes::VertexProp;\n\nstruct GraphProp {\n    std::vector<int> bidder2item;\n    std::vector<int> item2bidder;\n};\n\nusing EdgeProp        = boost::property< //\n    boost::edge_weight_t, float\n    //, boost::property<boost::edge_index_t, float>\n    >;\nusing Graph           = boost::adjacency_list< //\n    boost::listS, boost::vecS, boost::undirectedS, VertexProp, EdgeProp,\n    GraphProp>;\nusing vertex_iterator = Graph::vertex_iterator;\nusing V               = Graph::vertex_descriptor;\nusing E               = Graph::edge_descriptor;\nusing VertexFilter    = std::function<bool(V)>;\nusing EdgeFilter      = std::function<bool(E)>;\nusing FMap            = boost::filtered_graph<Graph, EdgeFilter, VertexFilter>;\n\nGraph generateData(int N) {\n    Graph g;\n\n    for (int i = 0; i < N; ++i) add_vertex(Bidder{ i }, g);\n    for (int i = 0; i < N; ++i) add_vertex(Item{ i }, g);\n\n    GraphProp& gp = g[boost::graph_bundle];\n    gp.bidder2item.assign(N, -1);\n    gp.item2bidder.assign(N, -1);\n\n    std::uniform_real_distribution<float> dist(1, 40);\n\n    // Every left nodes has a connection to every right nodes\n    for (int bidder = 0; bidder < N; ++bidder)\n        for (int item = 0; item < N; ++item)\n            add_edge(bidder, N + item, dist(prng), g);\n\n    return g;\n}\n\nvoid printGraph(Graph& g) {\n    boost::dynamic_properties dp;\n    dp.property(\"node_id\", get(boost::vertex_index, g));\n    dp.property(\"label\", get(boost::vertex_bundle, g));\n    dp.property(\"weight\", get(boost::edge_weight, g));\n    write_graphviz_dp(std::cout, g, dp);\n}\n\nfloat perform_matching(Graph const& graph, duration& elapsed) {\n    auto const     N = num_vertices(graph);\n    std::vector<V> mate(N);\n\n    auto t_start = now();\n    maximum_weighted_matching(graph, &mate[0]);\n    elapsed = now() - t_start;\n\n    float cost = matching_weight_sum(graph, &mate[0]);\n\n    std::cout << \"The matching is: \";\n\n    for (V v : boost::make_iterator_range(vertices(graph)))\n        if (mate[v] != Graph::null_vertex() && v < mate[v])\n            std::cout << \"(\" << v << \",\" << (mate[v] - (N / 2)) << \")\";\n    // std::cout << \"Bidder: \" << v << \" has item \" << mate[v] % (N / 2) <<\n    // \"\\n\";\n    std::cout << \"\\n\";\n\n    return cost;\n}\n\nstruct fmt {\n    duration const& _d;\n\n    friend std::ostream& operator<<(std::ostream& os, fmt f) {\n        if (f._d >=1min)      return os << (f._d/1min) << \"min \" << (f._d % 1min) / 1s << \"s\";\n        else if (f._d >= 1s)  return os << (f._d/1.0s) << \"s\";\n        else if (f._d >= 1ms) return os << (f._d/1.0ms) << \"ms\";\n        else                  return os << (f._d/1.0us) << \"μs\";\n    }\n};\n\nint main() {\n    for (unsigned n = 3; n <= 15; ++n) {\n        std::cout << \"Generation of a Bipartite Graph with \" << n\n                << \" per part\\n\";\n\n        Graph graph = generateData(n);\n        assert(num_vertices(graph) == 2 * n);\n        assert(num_edges(graph) == n*n);\n        //printGraph(graph);\n\n        //MAXIMUM WEIGHTED MATCHING\n        std::cout << \"Execution of Maximum Weighted Matching\\n\";\n\n        duration elapsed;\n        float total_cost_mwm = perform_matching(graph, elapsed);\n        std::cout << \"Execution time of Maximum Weight Matching: \" << std::fixed\n                << fmt{elapsed} << \", with total cost: \" << total_cost_mwm\n                << \"\\n\\n\";\n    }\n}\n```\n\nIt still has the problem.\nThe Workarounds\n\nUse ```\nbrute_force_maximum_weighted_matching```\n instead. It ... works:\n```\nGeneration of a Bipartite Graph with 3 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,1)(1,2)(2,0)\nExecution time of Maximum Weight Matching: 10.615000μs, with total cost: 89.486351\n\nGeneration of a Bipartite Graph with 4 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,3)(1,2)(2,0)(3,1)\nExecution time of Maximum Weight Matching: 58.851000μs, with total cost: 119.909248\n\nGeneration of a Bipartite Graph with 5 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,0)(1,1)(2,4)(3,2)(4,3)\nExecution time of Maximum Weight Matching: 437.944000μs, with total cost: 159.292282\n\nGeneration of a Bipartite Graph with 6 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,1)(1,4)(2,0)(3,5)(4,3)(5,2)\nExecution time of Maximum Weight Matching: 3.557644ms, with total cost: 153.375183\n\nGeneration of a Bipartite Graph with 7 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,6)(1,1)(2,2)(3,3)(4,0)(5,5)(6,4)\nExecution time of Maximum Weight Matching: 18.509977ms, with total cost: 242.493790\n\nGeneration of a Bipartite Graph with 8 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,1)(1,5)(2,0)(3,7)(4,3)(5,2)(6,6)(7,4)\nExecution time of Maximum Weight Matching: 192.351818ms, with total cost: 270.717896\n\nGeneration of a Bipartite Graph with 9 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,4)(1,2)(2,5)(3,8)(4,1)(5,3)(6,6)(7,7)(8,0)\nExecution time of Maximum Weight Matching: 2.554311s, with total cost: 303.273987\n\nGeneration of a Bipartite Graph with 10 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,9)(1,0)(2,6)(3,2)(4,1)(5,7)(6,4)(7,5)(8,8)(9,3)\nExecution time of Maximum Weight Matching: 38.104204s, with total cost: 328.234894\n\nGeneration of a Bipartite Graph with 11 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,5)(1,9)(2,0)(3,10)(4,4)(5,7)(6,3)(7,2)(8,6)(9,8)(10,1)\nExecution time of Maximum Weight Matching: 10min 32s, with total cost: 364.142242\n\nGeneration of a Bipartite Graph with 12 per part\nExecution of Maximum Weighted Matching\n^C\n```\n\nUsing some napkin math, the 14-item case will take 30 days, 15 would run 1.31 years on my machine. Not the best solution\n\nUp the precision. You use ```\nfloat```\n. They're the type with the least possible precision. Replacing with ```\nlong double```\n still only works some of the time. At least with some luck you'll see that the timing is saner:\n```\nGeneration of a Bipartite Graph with 13 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,1)(1,11)(2,7)(3,0)(4,2)(5,10)(6,12)(7,5)(8,4)(9,9)(10,8)(11,3)(12,6)\nExecution time of Maximum Weight Matching: 518.419000μs, with total cost: 478.816739\n```\n\nYou can try the multiprecision route as described in the answer linked above\n\nFinally, the sane approach is likely to use integral weights. Scaling the weights by, say ```\n10'000```\n: https://godbolt.org/z/7ETs4rK9a\n```\n//#include <boo/lexical_cast.hpp>\n//#include <boost/graph/graph_utility.hpp>\n//#include <boost/graph/grid_graph.hpp>\n//#include <boost/property_map/function_property_map.hpp>\n//#include <boost/property_map/transform_value_property_map.hpp>\n#include <boost/graph/adjacency_list.hpp>\n#include <boost/graph/bipartite.hpp>\n#include <boost/graph/graphviz.hpp>\n#include <boost/graph/maximum_weighted_matching.hpp>\n#include <boost/graph/properties.hpp>\n#include <boost/variant.hpp>\n\n#include <chrono>\nusing namespace std::chrono_literals;\nstatic auto now = std::chrono::high_resolution_clock::now;\nusing duration = std::chrono::high_resolution_clock::duration;\n\n#include <random>\nstatic std::mt19937 prng{std::random_device{}()}; // seeded as well\n\nnamespace Nodes {\n    using Weight = int64_t;\n\n    struct Bidder {\n        int    id;\n        int    best_item            = -1;\n        Weight val_first_best_item  = -1;\n        Weight val_second_best_item = -1;\n    };\n\n    struct Item {\n        int   id;\n        Weight cost        = 0;\n        int    high_bidder = -1;\n        Weight high_bid    = -1;\n    };\n\n    static inline std::ostream& operator<<(std::ostream& os, Bidder const& b) {\n        return os << \"BIDDER:\" << b.id << \"|best_item:\" << b.best_item\n                  << \"|best1:\" << b.val_first_best_item\n                  << \"|best2:\" << b.val_second_best_item;\n    }\n    static inline std::ostream& operator<<(std::ostream& os, Item const& i) {\n        return os << \"ITEM:\" << i.id << \"|cost:\" << i.cost\n                  << \"|high_bidder:\" << i.high_bidder\n                  << \"|high_bid:\" << i.high_bid;\n    }\n\n    using VertexProp = boost::variant<Bidder, Item>;\n\n    static inline std::istream& operator>>(std::istream& is, VertexProp&) {\n        return is;\n    }\n} // namespace Nodes\n\nusing Nodes::Weight;\nusing Nodes::Bidder;\nusing Nodes::Item;\nusing Nodes::VertexProp;\n\nstruct GraphProp {\n    std::vector<int> bidder2item;\n    std::vector<int> item2bidder;\n};\n\nusing EdgeProp        = boost::property< //\n    boost::edge_weight_t, Weight\n    //, boost::property<boost::edge_index_t, Weight>\n    >;\nusing Graph           = boost::adjacency_list< //\n    boost::listS, boost::vecS, boost::undirectedS, VertexProp, EdgeProp,\n    GraphProp>;\nusing vertex_iterator = Graph::vertex_iterator;\nusing V               = Graph::vertex_descriptor;\nusing E               = Graph::edge_descriptor;\nusing VertexFilter    = std::function<bool(V)>;\nusing EdgeFilter      = std::function<bool(E)>;\nusing FMap            = boost::filtered_graph<Graph, EdgeFilter, VertexFilter>;\n\nGraph generateData(int N) {\n    Graph g;\n\n    for (int i = 0; i < N; ++i) add_vertex(Bidder{ i }, g);\n    for (int i = 0; i < N; ++i) add_vertex(Item{ i }, g);\n\n    GraphProp& gp = g[boost::graph_bundle];\n    gp.bidder2item.assign(N, -1);\n    gp.item2bidder.assign(N, -1);\n\n    std::uniform_int_distribution<int64_t> dist(10'000, 400'000);\n\n    // Every left nodes has a connection to every right nodes\n    for (int bidder = 0; bidder < N; ++bidder)\n        for (int item = 0; item < N; ++item)\n            add_edge(bidder, N + item, dist(prng), g);\n\n    return g;\n}\n\nvoid printGraph(Graph& g) {\n    boost::dynamic_properties dp;\n    dp.property(\"node_id\", get(boost::vertex_index, g));\n    dp.property(\"label\", get(boost::vertex_bundle, g));\n    dp.property(\"weight\", get(boost::edge_weight, g));\n    write_graphviz_dp(std::cout, g, dp);\n}\n\nWeight perform_matching(Graph const& graph, duration& elapsed) {\n    auto const     N = num_vertices(graph);\n    std::vector<V> mate(N);\n\n    auto t_start = now();\n    maximum_weighted_matching(graph, &mate[0]);\n    //brute_force_maximum_weighted_matching(graph, &mate[0]);\n    elapsed = now() - t_start;\n\n    Weight cost = matching_weight_sum(graph, &mate[0]);\n\n    std::cout << \"The matching is: \";\n\n    for (V v : boost::make_iterator_range(vertices(graph)))\n        if (mate[v] != Graph::null_vertex() && v < mate[v])\n            std::cout << \"(\" << v << \",\" << (mate[v] - (N / 2)) << \")\";\n    // std::cout << \"Bidder: \" << v << \" has item \" << mate[v] % (N / 2) <<\n    // \"\\n\";\n    std::cout << \"\\n\";\n\n    return cost;\n}\n\nstruct fmt {\n    duration const& _d;\n\n    friend std::ostream& operator<<(std::ostream& os, fmt f) {\n        if (f._d >=1min)      return os << (f._d/1min) << \"min \" << (f._d % 1min) / 1s << \"s\";\n        else if (f._d >= 1s)  return os << (f._d/1.0s) << \"s\";\n        else if (f._d >= 1ms) return os << (f._d/1.0ms) << \"ms\";\n        else                  return os << (f._d/1.0us) << \"μs\";\n    }\n};\n\nint main() {\n    for (unsigned n = 3; n <= 25; ++n) {\n        std::cout << \"Generation of a Bipartite Graph with \" << n\n                  << \" per part\\n\";\n\n        Graph graph = generateData(n);\n        assert(num_vertices(graph) == 2 * n);\n        assert(num_edges(graph) == n*n);\n        //printGraph(graph);\n\n        //MAXIMUM WEIGHTED MATCHING\n        std::cout << \"Execution of Maximum Weighted Matching\\n\";\n\n        duration elapsed;\n        Weight total_cost_mwm = perform_matching(graph, elapsed);\n        std::cout << \"Execution time of Maximum Weight Matching: \" << std::fixed\n                  << fmt{elapsed} << \", with total cost: \" << (total_cost_mwm/10'000.0)\n                  << \"\\n\\n\";\n    }\n}\n```\n\n\n\nI would definitely go this route:\n```\nGeneration of a Bipartite Graph with 15 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,0)(1,11)(2,5)(3,10)(4,12)(5,8)(6,1)(7,6)(8,7)(9,4)(10,3)(11,2)(12,9)(13,14)(14,13)\nExecution time of Maximum Weight Matching: 363.954000μs, with total cost: 544.213200\n\n// ...\n\nGeneration of a Bipartite Graph with 115 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,114)(1,58)(2,55)(3,32)(4,67)(5,76)(6,41)(7,93)(8,48)(9,9)(10,11)(11,38)(12,54)(13,111)(14,90)(15,102)(16,1)(17,113)(18,17)(19,0)(20,86)(21,80)(22,60)(23,75)(24,10)(25,101)(26,61)(27,59)(28,68)(29,100)(30,84)(31,33)(32,5)(33,72)(34,106)(35,98)(36,79)(37,12)(38,3)(39,44)(40,42)(41,78)(42,34)(43,31)(44,28)(45,56)(46,19)(47,25)(48,49)(49,4)(50,70)(51,92)(52,43)(53,45)(54,23)(55,21)(56,103)(57,96)(58,77)(59,81)(60,24)(61,29)(62,66)(63,73)(64,63)(65,16)(66,6)(67,13)(68,51)(69,39)(70,18)(71,82)(72,36)(73,22)(74,53)(75,35)(76,108)(77,105)(78,83)(79,40)(80,14)(81,37)(82,65)(83,89)(84,110)(85,91)(86,15)(87,87)(88,74)(89,95)(90,71)(91,69)(92,112)(93,20)(94,64)(95,99)(96,8)(97,47)(98,88)(99,2)(100,104)(101,94)(102,27)(103,85)(104,57)(105,7)(106,97)(107,46)(108,109)(109,50)(110,107)(111,26)(112,52)(113,30)(114,62)\nExecution time of Maximum Weight Matching: 115.030287ms, with total cost: 4534.587800\n\nGeneration of a Bipartite Graph with 116 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,5)(1,104)(2,29)(3,61)(4,90)(5,102)(6,85)(7,44)(8,21)(9,48)(10,94)(11,1)(12,9)(13,80)(14,56)(15,2)(16,60)(17,37)(18,73)(19,15)(20,105)(21,4)(22,28)(23,78)(24,114)(25,106)(26,27)(27,10)(28,26)(29,6)(30,24)(31,50)(32,82)(33,23)(34,93)(35,30)(36,38)(37,63)(38,57)(39,41)(40,16)(41,79)(42,112)(43,7)(44,46)(45,17)(46,40)(47,33)(48,8)(49,64)(50,68)(51,76)(52,96)(53,19)(54,115)(55,75)(56,13)(57,70)(58,62)(59,98)(60,99)(61,65)(62,69)(63,43)(64,35)(65,59)(66,45)(67,100)(68,109)(69,87)(70,86)(71,72)(72,108)(73,74)(74,101)(75,22)(76,11)(77,3)(78,110)(79,32)(80,89)(81,81)(82,95)(83,67)(84,54)(85,20)(86,51)(87,52)(88,66)(89,25)(90,77)(91,91)(92,47)(93,39)(94,34)(95,71)(96,49)(97,42)(98,107)(99,0)(100,31)(101,83)(102,36)(103,97)(104,18)(105,58)(106,14)(107,55)(108,103)(109,92)(110,88)(111,12)(112,111)(113,113)(114,53)(115,84)\nExecution time of Maximum Weight Matching: 114.140185ms, with total cost: 4578.718400\n\n// ...\n\nGeneration of a Bipartite Graph with 247 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,24)(1,175)(2,102)(3,232)(4,5)(5,6)(6,229)(7,27)(8,38)(9,169)(10,228)(11,149)(12,11)(13,2)(14,192)(15,129)(16,82)(17,190)(18,113)(19,136)(20,174)(21,128)(22,161)(23,196)(24,103)(25,202)(26,23)(27,231)(28,167)(29,59)(30,22)(31,235)(32,110)(33,78)(34,171)(35,195)(36,87)(37,9)(38,131)(39,52)(40,189)(41,49)(42,108)(43,218)(44,181)(45,133)(46,95)(47,182)(48,183)(49,166)(50,241)(51,21)(52,172)(53,222)(54,42)(55,46)(56,225)(57,25)(58,176)(59,144)(60,245)(61,109)(62,73)(63,186)(64,75)(65,213)(66,104)(67,74)(68,69)(69,20)(70,127)(71,41)(72,76)(73,72)(74,97)(75,168)(76,36)(77,83)(78,163)(79,105)(80,224)(81,70)(82,178)(83,141)(84,180)(85,135)(86,32)(87,111)(88,132)(89,234)(90,28)(91,10)(92,185)(93,242)(94,43)(95,210)(96,12)(97,237)(98,60)(99,199)(100,62)(101,123)(102,48)(103,1)(104,243)(105,15)(106,134)(107,211)(108,98)(109,188)(110,0)(111,240)(112,191)(113,106)(114,67)(115,159)(116,30)(117,91)(118,233)(119,230)(120,125)(121,147)(122,164)(123,158)(124,236)(125,184)(126,153)(127,122)(128,146)(129,142)(130,63)(131,143)(132,68)(133,14)(134,170)(135,17)(136,112)(137,145)(138,120)(139,200)(140,215)(141,156)(142,177)(143,162)(144,47)(145,7)(146,34)(147,50)(148,80)(149,107)(150,4)(151,179)(152,150)(153,66)(154,71)(155,8)(156,207)(157,61)(158,205)(159,58)(160,124)(161,116)(162,101)(163,165)(164,88)(165,238)(166,64)(167,100)(168,157)(169,118)(170,84)(171,99)(172,140)(173,18)(174,217)(175,89)(176,138)(177,152)(178,51)(179,197)(180,198)(181,55)(182,204)(183,173)(184,37)(185,92)(186,151)(187,137)(188,13)(189,220)(190,148)(191,33)(192,221)(193,160)(194,29)(195,65)(196,3)(197,114)(198,53)(199,203)(200,212)(201,201)(202,154)(203,130)(204,214)(205,54)(206,219)(207,244)(208,45)(209,77)(210,193)(211,209)(212,39)(213,40)(214,206)(215,35)(216,119)(217,16)(218,246)(219,56)(220,226)(221,19)(222,94)(223,57)(224,81)(225,115)(226,85)(227,223)(228,139)(229,26)(230,90)(231,155)(232,93)(233,86)(234,121)(235,194)(236,96)(237,126)(238,187)(239,117)(240,239)(241,208)(242,44)(243,227)(244,216)(245,31)(246,79)\nExecution time of Maximum Weight Matching: 1.933262s, with total cost: 9819.795300\n\nGeneration of a Bipartite Graph with 248 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,238)(1,217)(2,140)(3,200)(4,193)(5,241)(6,134)(7,19)(8,81)(9,87)(10,118)(11,133)(12,51)(13,41)(14,63)(15,1)(16,5)(17,94)(18,110)(19,103)(20,24)(21,40)(22,155)(23,86)(24,33)(25,239)(26,128)(27,49)(28,104)(29,203)(30,165)(31,15)(32,37)(33,16)(34,84)(35,98)(36,189)(37,108)(38,219)(39,106)(40,150)(41,137)(42,244)(43,183)(44,29)(45,237)(46,213)(47,236)(48,222)(49,60)(50,162)(51,176)(52,114)(53,170)(54,44)(55,6)(56,62)(57,178)(58,220)(59,234)(60,173)(61,221)(62,231)(63,9)(64,168)(65,56)(66,233)(67,172)(68,209)(69,67)(70,167)(71,50)(72,93)(73,169)(74,210)(75,158)(76,75)(77,214)(78,247)(79,182)(80,243)(81,147)(82,188)(83,90)(84,0)(85,55)(86,61)(87,139)(88,21)(89,195)(90,192)(91,224)(92,65)(93,113)(94,196)(95,18)(96,38)(97,199)(98,131)(99,31)(100,57)(101,17)(102,70)(103,187)(104,54)(105,160)(106,130)(107,142)(108,149)(109,76)(110,43)(111,227)(112,73)(113,151)(114,232)(115,216)(116,157)(117,45)(118,135)(119,215)(120,226)(121,132)(122,208)(123,64)(124,223)(125,159)(126,10)(127,171)(128,99)(129,11)(130,127)(131,163)(132,156)(133,48)(134,23)(135,74)(136,27)(137,26)(138,115)(139,78)(140,230)(141,181)(142,198)(143,180)(144,32)(145,72)(146,22)(147,242)(148,36)(149,212)(150,7)(151,191)(152,101)(153,197)(154,143)(155,2)(156,194)(157,59)(158,119)(159,68)(160,225)(161,117)(162,96)(163,34)(164,124)(165,66)(166,14)(167,97)(168,205)(169,235)(170,3)(171,83)(172,89)(173,102)(174,8)(175,53)(176,107)(177,207)(178,12)(179,25)(180,125)(181,146)(182,112)(183,211)(184,164)(185,161)(186,218)(187,46)(188,47)(189,204)(190,77)(191,174)(192,179)(193,120)(194,190)(195,126)(196,100)(197,154)(198,145)(199,138)(200,95)(201,30)(202,185)(203,82)(204,175)(205,69)(206,28)(207,92)(208,229)(209,88)(210,80)(211,4)(212,105)(213,20)(214,52)(215,109)(216,245)(217,35)(218,58)(219,71)(220,136)(221,246)(222,177)(223,148)(224,144)(225,116)(226,91)(227,79)(228,13)(229,201)(230,166)(231,121)(232,122)(233,129)(234,39)(235,228)(236,240)(237,123)(238,141)(239,42)(240,184)(241,153)(242,111)(243,152)(244,206)(245,186)(246,85)(247,202)\nExecution time of Maximum Weight Matching: 2.077972s, with total cost: 9853.318400\n\nGeneration of a Bipartite Graph with 249 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,3)(1,137)(2,86)(3,11)(4,203)(5,132)(6,154)(7,69)(8,163)(9,81)(10,204)(11,114)(12,234)(13,202)(14,147)(15,85)(16,215)(17,45)(18,126)(19,190)(20,5)(21,54)(22,88)(23,151)(24,64)(25,68)(26,87)(27,248)(28,246)(29,123)(30,107)(31,233)(32,12)(33,108)(34,189)(35,175)(36,117)(37,143)(38,70)(39,221)(40,232)(41,56)(42,113)(43,26)(44,236)(45,152)(46,103)(47,244)(48,62)(49,167)(50,208)(51,125)(52,22)(53,160)(54,23)(55,130)(56,32)(57,218)(58,197)(59,205)(60,7)(61,165)(62,33)(63,229)(64,187)(65,185)(66,6)(67,37)(68,172)(69,127)(70,63)(71,46)(72,164)(73,96)(74,95)(75,50)(76,66)(77,166)(78,72)(79,38)(80,61)(81,79)(82,142)(83,227)(84,237)(85,59)(86,24)(87,134)(88,247)(89,27)(90,173)(91,8)(92,245)(93,104)(94,183)(95,240)(96,157)(97,105)(98,111)(99,146)(100,75)(101,133)(102,177)(103,220)(104,217)(105,211)(106,110)(107,17)(108,128)(109,124)(110,223)(111,25)(112,120)(113,14)(114,209)(115,116)(116,176)(117,115)(118,102)(119,119)(120,76)(121,199)(122,52)(123,153)(124,89)(125,10)(126,224)(127,80)(128,222)(129,9)(130,77)(131,179)(132,195)(133,136)(134,16)(135,228)(136,140)(137,231)(138,71)(139,216)(140,65)(141,138)(142,83)(143,225)(144,21)(145,100)(146,212)(147,121)(148,43)(149,55)(150,159)(151,206)(152,129)(153,155)(154,30)(155,29)(156,40)(157,188)(158,139)(159,58)(160,60)(161,182)(162,57)(163,122)(164,49)(165,67)(166,192)(167,158)(168,149)(169,15)(170,230)(171,13)(172,194)(173,91)(174,2)(175,170)(176,39)(177,28)(178,241)(179,207)(180,97)(181,101)(182,19)(183,144)(184,201)(185,1)(186,243)(187,36)(188,168)(189,161)(190,84)(191,181)(192,150)(193,141)(194,171)(195,35)(196,242)(197,112)(198,106)(199,235)(200,78)(201,4)(202,44)(203,98)(204,148)(205,186)(206,191)(207,74)(208,193)(209,239)(210,178)(211,145)(212,51)(213,156)(214,169)(215,0)(216,93)(217,219)(218,174)(219,20)(220,198)(221,90)(222,109)(223,196)(224,31)(225,118)(226,214)(227,82)(228,53)(229,92)(230,131)(231,180)(232,99)(233,41)(234,42)(235,94)(236,47)(237,135)(238,200)(239,34)(240,73)(241,162)(242,18)(243,184)(244,226)(245,238)(246,210)(247,213)(248,48)\nExecution time of Maximum Weight Matching: 2.155353s, with total cost: 9897.323400\n\nGeneration of a Bipartite Graph with 250 per part\nExecution of Maximum Weighted Matching\nThe matching is: (0,70)(1,137)(2,240)(3,35)(4,33)(5,235)(6,242)(7,130)(8,217)(9,215)(10,178)(11,16)(12,3)(13,100)(14,165)(15,197)(16,186)(17,39)(18,239)(19,103)(20,169)(21,129)(22,71)(23,86)(24,198)(25,154)(26,73)(27,206)(28,227)(29,145)(30,61)(31,248)(32,191)(33,171)(34,222)(35,128)(36,185)(37,89)(38,234)(39,168)(40,78)(41,115)(42,193)(43,247)(44,221)(45,162)(46,172)(47,7)(48,30)(49,177)(50,127)(51,184)(52,144)(53,8)(54,80)(55,60)(56,113)(57,243)(58,114)(59,146)(60,229)(61,133)(62,77)(63,118)(64,237)(65,69)(66,21)(67,45)(68,150)(69,25)(70,207)(71,32)(72,40)(73,102)(74,15)(75,66)(76,135)(77,226)(78,43)(79,194)(80,38)(81,12)(82,220)(83,151)(84,182)(85,219)(86,5)(87,0)(88,158)(89,34)(90,50)(91,245)(92,47)(93,200)(94,241)(95,112)(96,203)(97,51)(98,244)(99,131)(100,209)(101,37)(102,54)(103,101)(104,161)(105,46)(106,42)(107,120)(108,218)(109,2)(110,109)(111,166)(112,20)(113,97)(114,67)(115,213)(116,62)(117,212)(118,134)(119,249)(120,159)(121,132)(122,10)(123,68)(124,164)(125,28)(126,18)(127,110)(128,111)(129,160)(130,189)(131,149)(132,76)(133,116)(134,156)(135,142)(136,56)(137,11)(138,64)(139,53)(140,48)(141,148)(142,49)(143,19)(144,208)(145,75)(146,152)(147,119)(148,63)(149,93)(150,29)(151,58)(152,31)(153,214)(154,44)(155,91)(156,153)(157,24)(158,179)(159,108)(160,55)(161,1)(162,236)(163,124)(164,125)(165,188)(166,74)(167,90)(168,141)(169,82)(170,140)(171,96)(172,195)(173,95)(174,180)(175,126)(176,173)(177,4)(178,59)(179,143)(180,22)(181,123)(182,17)(183,176)(184,202)(185,216)(186,121)(187,122)(188,196)(189,27)(190,92)(191,187)(192,138)(193,98)(194,228)(195,23)(196,9)(197,6)(198,205)(199,117)(200,157)(201,36)(202,65)(203,139)(204,85)(205,87)(206,231)(207,147)(208,192)(209,14)(210,88)(211,246)(212,72)(213,26)(214,210)(215,233)(216,52)(217,204)(218,84)(219,181)(220,174)(221,83)(222,163)(223,238)(224,57)(225,79)(226,81)(227,223)(228,225)(229,167)(230,175)(231,230)(232,155)(233,199)(234,201)(235,105)(236,211)(237,106)(238,170)(239,136)(240,107)(241,190)(242,13)(243,183)(244,94)(245,104)(246,99)(247,224)(248,41)(249,232)\nExecution time of Maximum Weight Matching: 2.147109s, with total cost: 9933.882100\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "An extension of bipartite graph maximum matching\r\n                \r\nAssume that there are two graphs like this:\n\n\n\nWe aim to find the matching correspondences between the two graph.And now we use a method to calculate the similarity of two nodes between the two graphs.\nw(A,1) means the similarity of the node A from the left graph between the node 1 from the right graph. Then we can have table like this:\n\n\n\nOur target is to calculate the maximum weight matching of all this nodes. And we can use the algorithm Kuhn－Munkras to solve this problem.\n\nBut now the question is that is if we add the similarity between edges from the two graphs,how can we calulate the maximum weight matching. It means that the table become this:\n\n\n\nAA means the node A, and AB means the edge from A to B. The constraints are that if the final result is that node A matches node 1,the edge AB must matches 12 or 13.So can we use a algorithm like Kuhn－Munkras to solve this problem? If not , how can we find the the maximum weight matching in polynomial time?\n    ", "Answer": "\r\nSuppose we want to know if two graphs are isomorphic, e.g. the two in your example.\n\nIn the first graph we have edges AC and CB, while in the second graph we have edges 13 and 32.\n\nWe can set the weight matrix such that there is a high reward for mapping any edge in the first to an edge in the second.\n\ni.e. AC->13 and AC->32 and CB->13 and CB->32 will all have weight 1, while all other matchings have weight zero.\n\nThere is an isomorphism between the graphs if and only if there is a maximum weight matching with weight equal to the number of edges.\n\nTherefore your problem is at least as hard as graph isomorphism so it is unlikely that the Kuhn algorithm can be efficiently extended to this case.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "how to reduce Maximum cardinality bipartite matching to minimum path cover?\r\n                \r\nI have read these two questions : link1\nlink2\nand also this wikipedia\nbut i can't understand how solving maximum matching problem can be used to solve minimum path cover. I know the solution is n-m where n is the number of vertices in G and m is the maximum matching but i can't find the reason\n    ", "Answer": "\r\nHere is an intuitive explanation of this fact(it is not a rigorous proof): Let's take a look at each path in a path cover. Every vertex, except the first one in a path, has a unique predecessor. Moreover, each vertex has exactly one successor(except the last on in each path). That's why we can say that each vertex is matched to its predecessor. If a vertex is not matched to anything, it is the first vertex in some path. That's why the number of paths is equal to the number of unmatched vertices(each path has exactly one first vertex). The number of unmatched vertices is obviously equal to the total number of vertices minus the number of matched vertices. That's how we get ```\nn - m```\n formula. It is not possible to get less paths then the size of a maximum matching(otherwise ```\nn - m1 < n - m```\n => ```\nm1 > m```\n => ```\nm```\n is not maximum). At the same time, we can construct a solution with ```\nn - m```\n paths explicitly. \n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Guaranteeing Unique Surrogate Key Assignment - Maximum Matching for Non-Bipartite Graph\r\n                \r\nI am maintaining a data warehouse with multiple sources of data about a class of entities that have to be merged.  Each source has a natural key, and what is supposed to happen is that one and only one surrogate key is created for each natural key for all time.  If one record from one source system with a particular natural key represents the same entity as another record from another source system with a different natural key, the same surrogate key will be assigned to both.\n\nIn other words, if source system A has natural key ABC representing the same entity as source system B's natural key DEF, we would assign the same surrogate key to both.  The table would look like this:\n\n```\nSURROGATE_KEY   SOURCE_A_NATURAL_KEY    SOURCE_B_NATURAL_KEY\n 1               ABC                     DEF\n```\n\n\nThat was the plan.  However, this system has been in production for a while, and the surrogate key assignment is a mess.  Source system A would give natural key ABC on one day, before source system B knew about it.  The DW assigned surrogate key 1 to it.  Then source system B started giving natural key DEF, which represents the same thing as source system A's natural key ABC.  The DW incorrectly gave this combo surrogate key 2.  The table would look like this:\n\n```\nSURROGATE_KEY   SOURCE_A_NATURAL_KEY    SOURCE_B_NATURAL_KEY\n 1               ABC                     NULL\n 2               ABC                     DEF\n```\n\n\nSo the warehouse is a mess.  There's much more complex situations than this.  I have a short timeline for a cleanup that requires figuring out a clean set of surrogate key to natural key mappings.\n\nA little Googling reveals that this can be modeled as a matching problem in a non-bipartite graph:\n\nWikipedia - Matching\n\nMIT 18.433 Combinatorial Optimization - Lecture Notes on Non-Bipartite Matching\n\nI need an easy to understand implementation (not optimally performing) of Edmond's paths, trees, and flowers algorithm.  I don't have a formal math or CS background, and what I do have is self-taught, and I'm not in a math-y headspace tonight.  Can anyone help?  A well written explanation that guides me to an implementation would be deeply appreciated.\n\nEDIT:\n\nA math approach is optimal because we want to maximize global fitness.  A greedy approach (first take all instances of A, then B, then C...) paints you into a local maxima corner.\n\nIn any case, I got this pushed back to the business analysts to do manually (all 20 million of them).  I'm helping them with functions to assess global match quality.  This is ideal since they're the ones signing off anyways, so my backside is covered.\n\nNot using surrogate keys doesn't change the matching problem.  There's still a 1:1 natural key mapping that has to be discovered and maintained.  The surrogate key is a convenient anchor for that, and nothing more.\n    ", "Answer": "\r\nI get the impression you're going about this the wrong way; as cdonner says, there are other ways to just rebuild the key structure without going through this mess. In particular, you need to guarantee that natural keys are always unique for a given record (violating this condition is what got you into this mess!). Having both ```\nABC```\n and ```\nDEF```\n identify the same record is disastrous, but ultimately repairable. I'm not even sure why you need surrogate keys at all; while they do have many advantages, I'd give some consideration to going pure-relational and just gutting them from your schema, a la Celko; it might just get you out of this mess. But that's a decision that would have to be made after looking at your whole schema.\nTo address your potential solution, I've pulled out my copy of D. B. West's Introduction to Graph Theory, second edition, which describes the blossom algorithm on page 144. You'll need some mathematical background, with both mathematical notation and graph theory, to follow the algorithm, but it's sufficiently concise that I think it can help (if you decide to go this route). If you need explanation, first consult a resource on graph theory (Wikipedia, your local library, Google, wherever), or ask if you're not finding what you need.\n\n3.3.17. Algorithm. (Edmonds' Blossom Algorithm [1965a]---sketch).\nInput. A graph ```\nG```\n, a matching ```\nM```\n in ```\nG```\n, an ```\nM```\n-unsaturated vertex ```\nu```\n.\nIdea. Explore ```\nM```\n-alternating paths from ```\nu```\n, recording for each vertex the vertex from which it was reached, and contracting blossoms when found. Maintain sets ```\nS```\n and ```\nT```\n analogous to those in Algorithm 3.2.1, with ```\nS```\n consisting of ```\nu```\n and the vertices reached along saturated edges. Reaching an unsaturated vertex yields an augmentation.\nInitialization. ```\nS = {u}```\n and ```\nT = {}```\n (empty set).\nIteration. If ```\nS```\n has no unmarked vertex, stop; there is no ```\nM```\n-augmenting path from ```\nu```\n. Otherwise, select an unmarked ```\nv```\n in ```\nS```\n. To explore from ```\nv```\n, successively consider each ```\ny```\n in ```\nN(v)```\n such that ```\ny```\n is not in ```\nT```\n.\nIf ```\ny```\n is unsaturated by ```\nm```\n, then trace back from ```\ny```\n (expanding blossoms as needed) to report an ```\nM```\n-augmenting ```\n(u, y)```\n-path.\nIf ```\ny```\n is in ```\nS```\n, then a blossom has been found. Suspend the exploration of ```\nv```\n and contract the blossom, replacing its vertices in ```\nS```\n and ```\nT```\n by a single new vertex in ```\nS```\n. Continue the search from this vertex in the smaller graph.\nOtherwise, ```\ny```\n is matched to some ```\nw```\n by ```\nM```\n. Include ```\ny```\n in ```\nT```\n (reached from ```\nv```\n), and include ```\nw```\n in ```\nS```\n (reached from ```\ny```\n).\nAfter exploring all such neighbors of ```\nv```\n, mark ```\nv```\n and iterate.\n\nThe algorithm as described here runs in time O(n^4), where n is the number of vertices. West gives references to versions that run as fast as O(n^5/2) or O(n^1/2 m) (m being the number of edges). If you want these references, or citations to Edmonds' original paper, just ask and I'll dig them out of the index (which kind of sucks in this book).\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Count matchings in bipartite graph\r\n                \r\nI am having a bipartite graph with N nodes in one side and almost 100 in other side.\nNow i need to count the matchings such that each node in first part is having a link to some node in other part such that no two nodes in first part matches to same node in second part.(Just like one job can be assigned to one applicant only)\n\nNow I know that finding this count is not easy and is #P-hard problem ( from link : https://cs.stackexchange.com/questions/19924/counting-and-finding-all-perfect-maximum-matchings-in-general-graphs )\n\nBut what can be the brute solution to do so ?Can someone please explain with some code or pseudocode.\n\nAssume input is like we have X pairs showing u is connected to v\n\nIf N=2 and X=4 and pairs be (1,1),(1,2),(2,3),(2,4).\n    ", "Answer": "\r\nThere may be a dynamic programming solution for small N, where 2^N is a practical number.\n\nRepresent the graph by an N x 100 table, with entries marked true when there is a link from one side to the other side. For i = 1..100 we will work out Count(i, x) where x is in the range 0..2^N-1 and represents a set of the nodes on the N side. Count(i, x) will be a count of the number of matchings between the nodes in set x in the N side and the first i nodes in the 100 side.\n\nWe can work out Count(i, x) from Count(i-1, *) by considering the cases when there is a match between i and one of the nodes in x and the case where there is not. The case where there is not scores Count(i - 1, x) - the number of way to create a matching not using i. For each set bit in x if there is a link from i to the node represented by that bit, let y by be the bit pattern for x with that bit not set and add Count(i - 1, y) to the count so far. Count(i, x) is the sum of all of these counts.\n\nThe final answer is Count(100, 2^N-1) - the number of matchings between the first 100 nodes on one side and all of the N nodes on the other side.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Conditional matching of a weighted bipartite graph\r\n                \r\nI blieve I am trying to solve a subset of the assignment problem, but not certain.\nI have N buckets in a hierarchy and X proucts.\nFor example:\n```\nFor 4 buckets; in priority to fill order: A, B, C, D\nBucket A can take products from B and C.\nBucket B can take poducts from C.\nBuckt C can take products from bucket D.\n```\n\nThen each of these buckets has a current number, and a required number\n\n\n\n\nBucket\nAvailable\nRequirement\nDelta\n\n\n\n\nA\n1\n3\n2\n\n\nB\n0\n1\n1\n\n\nC\n3\n5\n2\n\n\nD\n3\n3\n0\n\n\n\n\nThe challenge is how do I fill up the buckets in the hierarchy?\nThe slution to this example would be:\n```\n2 products move from C to A\n1 product move from C to B\n3 products move from D to C\n```\n\nI'm representing the ```\ntransition```\n matrix as:\n```\n  A B C D\nA(0 0 0 0)\nB(0 0 0 0)\nC(2 1 0 0)\nD(0 0 3 0)\n```\n\nThis matrix is quite easy to come up with if we loop through the possible buckets each bucket can pull from in hierarchy order. I want to know if there is a closed form/vectorised solution/faster approach that will scale to much larger numbers?\n\nCurent approach is looking at how I can model this as a weighted bipartite graph poblem, but that is a bit tricky as multiple products can go to the same bucket.\n\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum product perfect matching in complete bipartite graphs\r\n                \r\nI am trying to solve this problem : Jobs.\nSo far i have thought that the problem is same as the Assignment Problem with the distributors and districts represented as a bipartite graph and the edges representing the probability. But here we would need to maximize the product rather than the sum of weights of matched edges. \n\nOne idea that came to my mind was to change each edge weight to log ( weight ). Then the problem essentially changes to finding the maximum sum, which is can then be solved using the algorithms for Assignment Problem. But this poses a problem, since applying log will make the edge weights non-integer, something which i think the Hungarian Algorithm does not work for.\n\nPlease suggest some other alternative approach.\n    ", "Answer": "\r\nIn theory, the Hungarian algorithm works fine with real weights.\n\nIn practice, it's possible that, since most integer logarithms cannot be represented exactly as floating-point numbers, it could come to pass that rounding would change the optimal solution. There are ways to deal with that even so, but it's unlikely that you'll need them for this programming contest problem.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to modify algorithm to get all maximal matchings in bipartite graph?\r\n                \r\nI use the following code to find maximal matching in bipartite graph\n(I've tried to add a few comments):\n\n```\n#include <iostream>\n\nusing namespace std;\n\n// definition of lists elements\n//-------------------------------\nstruct slistEl\n{\n  slistEl * next;\n  int data;\n};\n\n// definition objective type queue\n//---------------------------------\nclass queue\n{\n  private:\n    slistEl * head;\n    slistEl * tail;\n\n  public:\n    queue();      \n    ~queue();     \n    bool empty(void);\n    int  front(void);\n    void push(int v);\n    void pop(void);\n};\n\nqueue::queue()\n{\n  head = tail = NULL;\n}\n\nqueue::~queue()\n{\n  while(head) pop();\n}\n\nbool queue::empty(void)\n{\n  return !head;\n}\n\nint queue::front(void)\n{\n  if(head) return head->data;\n  else     return -10000;\n}\n\nvoid queue::push(int v)\n{\n  slistEl * p = new slistEl;\n  p->next = NULL;\n  p->data = v;\n  if(tail) tail->next = p;\n  else     head = p;\n  tail = p;\n}\n\nvoid queue::pop(void)\n{\n  if(head)\n  {\n    slistEl * p = head;\n    head = head->next;\n    if(!head) tail = NULL;\n    delete p;\n  }\n}\n\n//---------------\n// main part\n//---------------\n\nqueue Q;                          // queue\nint *Color;                       // colors of vertexes\nslistEl **graf;                   // adjacency array\nint **C;                          // matrix of capacity\nint **F;                          // matrix of nett flow\nint *P;                           // array of prev\nint *CFP;                         // array of residual capacity\nint n,m,fmax,cp,v,u,i,j;          // \nbool esc;                         // \nslistEl *pr, *rr;                 // pointer for list elements\n\n\nint main(int argc, char *argv[])\n{\n\n  // n - number of vertexes\n  // m - number of edges\n\n  cin >> n >> m;\n\n\n  Color = new int [n];             \n  graf = new slistEl * [n];       \n  for(i = 0; i < n; i++)\n  {\n    graf[i] = NULL;\n    Color[i] = 0;\n  }\n\n  C = new int * [n+2];            \n  F = new int * [n+2];            \n  for(i = 0; i <= n + 1; i++)\n  {\n    C[i] = new int [n+2];\n    F[i] = new int [n+2];\n    for(j = 0; j <= n + 1; j++)\n    {\n      C[i][j] = 0;\n      F[i][j] = 0;\n    }\n  }\n\n  P = new int [n+2];             \n  CFP = new int [n+2];           \n\n  // reading edges definition and adding to adjacency list\n\n  for(i = 0; i < m; i++)\n  {\n    cin >> v >> u;\n    pr = new slistEl;\n    pr->data = u;\n    pr->next = graf[v];\n    graf[v]  = pr;\n\n    pr = new slistEl;\n    pr->data = v;\n    pr->next = graf[u];\n    graf[u]  = pr;\n  }\n\nfor(i = 0; i < n; i++){\n         cin>> Color[i];\n      }\n\n\n\n    for(i = 0; i < n; i++)\n      if(Color[i] == -1)\n      {\n        for(pr = graf[i]; pr; pr = pr -> next) // neighbours of blue\n          C[i][pr->data] = 1;     // capacity to red\n        C[n][i] = 1;              // capacity  to source\n      }\n      else C[i][n+1] = 1;         // capacity edges to outfall\n\n    //**  Edmonds-Karp algorithm **\n\n    fmax = 0;\n\n    while(true)\n    {\n      for(i = 0; i <= n + 1; i++) P[i] = -1;\n\n      P[n] = -2;\n      CFP[n] = MAXINT;\n\n      while(!Q.empty()) Q.pop();\n      Q.push(n);\n\n      esc = false;\n\n      while(!Q.empty())\n      {\n        v = Q.front(); Q.pop();\n\n        for(u = 0; u <= n + 1; u++)\n        {\n          cp = C[v][u] - F[v][u];\n          if(cp && (P[u] == -1))\n          {\n            P[u] = v;\n            if(CFP[v] > cp) CFP[u] = cp; else CFP[u] = CFP[v];\n            if(u == n+1)\n            {\n              fmax += CFP[n+1];\n              i = u;\n              while(i != n)\n              {\n                v = P[i];\n                F[v][i] += CFP[n+1];\n                F[i][v] -= CFP[n+1];\n                i = v;\n              }\n              esc = true; break;\n            }\n            Q.push(u);\n          }\n        }\n        if(esc) break;\n      }\n      if(!esc) break;\n    }\n\n    // showing reuslts\n\n\n    if(fmax > 0)\n      for(v = 0; v < n; v++)\n        for(u = 0; u < n; u++)\n          if((C[v][u] == 1) && (F[v][u] == 1))\n            cout << v << \" - \" << u << endl;\n\n  cout << endl;\n\n  // cleaning\n\n  delete [] Color;               \n\n  for(i = 0; i < n; i++)\n  {\n    pr = graf[i];\n    while(pr)\n    {\n      rr = pr;\n      pr = pr->next;\n      delete rr;\n    }\n  }\n\n  delete [] graf;               \n\n  for(i = 0; i <= n + 1; i++)\n  {\n    delete [] C[i];\n    delete [] F[i];\n  }\n  delete [] C;                    \n  delete [] F;                    \n\n  delete [] P;                  \n  delete [] CFP;                \n\n  return 0;\n}\n```\n\n\nIt returns only one maximal matching. For example for data:\n\n```\n6 7\n0 3 0 5\n1 3 1 4 1 5\n2 3 2 5\n1 1 1 -1 -1 -1\n```\n\n\nBut there are more maximal matchings. \n\nI don't know, how should I modify it to get all results and I would like to ask somebody for help. Thank you in advance.\n    ", "Answer": "\r\nThat algorithm is only efficient to get you a maximum matching.\n\nIf you want all maximal matching you have to consider the case where any matching is a maximal matching. In that case you have N! possibilities.\n\nSince you will need to visit all solutions your complexity will be O(N!) at least. Therefore, forget the code you have, you can just try all possible matchings using a recursive algorithm and keep the set of maximal matching you get.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "What is time complexity of maximum bipartitie matching algorithm?\r\n                \r\nHere is the classical problem : - \"There are M job applicants and N jobs. Each applicant has a subset of jobs that he/she is interested in. Each job opening can only accept one applicant and a job applicant can be appointed for only one job. Find an assignment of jobs to applicants in such that as many applicants as possible get jobs.\"\n\nI am using the following code and algorithm to solve the problem : https://www.geeksforgeeks.org/maximum-bipartite-matching/\n\nWhat will be the time complexity of this algorithm ? \n    ", "Answer": "\r\nAccording to this Wikipedia article, the algorithm by Ford & Fulkerson has a runtime complexity of ```\nO(|E|f)```\n, where ```\n|E|```\n is the cardinality of the input's edge set. Note that this runtime bound depends on the optimal value and is pseudo-polynomial.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to convert SPOJ Quest4 to Minimum Vertex Cover\r\n                \r\nThe following is a Maximum Bipartite matching problem : http://www.spoj.com/problems/QUEST4/\nThrough forums i came to know that the problem can be converted into a Minimum Vertex Cover problem, which in turn can be solved by Maximum Bipartite Matching.\nHowever, I do not understand how the problem has been converted into Minimum Vertex Cover.\nPlease help me understand this.\n    ", "Answer": "\r\nLet C , R be the set of all rows and all columns. \nNow let G be a bipartite graph having edges between C and R where there is an edge (i,j) from C to R if there is a hole in ith row and jth column.\n\nNow consider the vertex cover of this graph. The vertex cover of a graph is a minimal set of nodes such that all edges are covered(each edge is incident upon at least one vertex in the vertex cover). \n\nIn our problem graph, each edge represents a hole. Vertices represent rows or columns. Objective-\n             minimize blocks while covering all holes\n             which is equivalent to -\n             minimize vertices while covering all edges.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to return all possible conditional bipartite matchings?\r\n                \r\nSuppose that we have an array ```\nX = (x_1, ..., x_N)```\n of length ```\nN```\n. We want to return all possible arrays of length ```\nM```\n (```\nM```\n is fixed), whose elements can be from ```\n(x_1, ..., x_N, NaN)```\n such that each ```\nx_i```\n is used at most once and the ```\nx_i```\n order is preserved. For example, if ```\nN = 3```\n and ```\nM = 7```\n, a few possible vectors are    \n\n```\n Z = (x_1, NaN, NaN, x_2, x_3, NaN, NaN)\n Z = (NaN, x_1, NaN, NaN, x_3, NaN, NaN)\n Z = (x_3, NaN, NaN, NaN, NaN, NaN, NaN)\n Z = (NaN, NaN, NaN, NaN, NaN, NaN, NaN)\n```\n\n\nBut the following vectors are not acceptable:\n\n```\n Z = (x_1, x_1, NaN, x_2, x_3, NaN, NaN)\n Z = (NaN, x_3, NaN, NaN, x_2, NaN, NaN)\n```\n\n\nThis problem can be viewed as matching some of the ```\nx_i```\ns to locations ```\n1,...,M```\n such that ```\nx_i```\ns order is preserved. How can I do this? I was thinking of using a recursive function ```\nf(X, M)```\n that cuts the vector ```\nZ```\n at every possible point (```\nfor i in range(1,M+1)```\n) and then concatenates ```\nf(x_1, i)```\n (defined as a base case) with ```\nf((x_2, ..., x_N), M-i+1)```\n (recursion). But this approach does not give unique vectors and I have to remove the duplicates afterward and it is not efficient. Is there a better way to solve this? Maybe using itertools?\n    ", "Answer": "\r\nI think something like that should work for you. It is basically iterative filling of ```\nM```\n boxes by taking elements from list ```\nX```\n. Default content is ```\nNone```\n in that case, but you should be able to adjust. You can see how it works on repl\n\n```\nN = 3\nM = 6\n\nX = range(N) # or example, can be [x1,x2,x3]\n\nfor j1 in range(M-N+1):\n  for j2 in range(j1+1,M-N+2):\n    for j3 in range(j2+1,M):\n      r = [None]*M\n      r[j1] = X[0]\n      r[j2] = X[1]\n      r[j3] = X[2]\n      print(r)\n```\n\n\nThis will produce following output:\n\n```\n[0, 1, 2, None, None, None]\n[0, 1, None, 2, None, None]\n[0, 1, None, None, 2, None]\n[0, 1, None, None, None, 2]\n[0, None, 1, 2, None, None]\n[0, None, 1, None, 2, None]\n[0, None, 1, None, None, 2]\n[0, None, None, 1, 2, None]\n[0, None, None, 1, None, 2]\n[0, None, None, None, 1, 2]\n[None, 0, 1, 2, None, None]\n[None, 0, 1, None, 2, None]\n[None, 0, 1, None, None, 2]\n[None, 0, None, 1, 2, None]\n[None, 0, None, 1, None, 2]\n[None, 0, None, None, 1, 2]\n[None, None, 0, 1, 2, None]\n[None, None, 0, 1, None, 2]\n[None, None, 0, None, 1, 2]\n[None, None, None, 0, 1, 2]\n```\n\n\nIdeally, you would want to generalize it for arbitrary N, so that you don't have to hard-code ```\nj1```\n, ```\nj2```\n, and ```\nj3```\n indices.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum Bipartite Graph Matching with some exclusive edges\r\n                \r\nI am trying to solve a bipartite graph problem but I cannot find anything for graphs with some exclusive edges. Say each node on the right can accept 3 normal left nodes or 1 exclusive left node.\nI have tried modifying the Ford-Fulkerson algorithm from GeeksForGeeks, however the issue I have is when removing multiple nodes at once. For example, 0, 1, 2* are the left nodes where 2* is exclusive. A and B are the right nodes. 0 and 1 will go to A, 2* will go to attempt to go to A and should kick 0 and 1 to B, however if only 0 could actually fit in B, then the algorithm falls over. Do I need to use a different algorithm or am I thinking about this wrong? Thanks for the help\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "bipartite graph creation using sparseMatrix\r\n                \r\nI am creating a bipartite graph and computing for the maximal matching as shown below.\n\n```\nadjspars <- sparseMatrix(i=adj.mat[,1], j=adj.mat[,2], x=1, \n    dims=c(npri,ncon), dimnames=list(paste0(\"p\",1:npri),paste0(\"c\",1:ncon)))\nigrph <- graph.incidence(adjspars)\nigrph.match <- maximum.bipartite.matching(igrph)\n```\n\n\nThe output of ```\nprint(igrph)```\n is\n\n```\nIGRAPH UN-B 67368 3344133 --\n+ attr: type (v/l), name (v/c)\n```\n\n\nFor the above graph the amount of time taken is as follows\n\n```\ncreate sparse matrix   .51s\ncreate graph         50.66s\nbipartite matching     .16s\n```\n\n\nIs there a different way of performing the create graph step which would be faster?\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Fast algorithms for finding optimal matchings on weighted bipartite graphs\r\n                \r\nI need to solve the assignment problem (given a complete weighted bipartite graph, choose a perfect matching with maximum total weight) efficiently and I've been using the O(n^3) version from here http://community.topcoder.com/tc?module=Static&d1=tutorials&d2=hungarianAlgorithm. However, a paper I read mentioned a \"more efficient method\" in \"A shortest augmenting path algorithm for dense and sparse linear assignment problems\", which is sadly behind a paywall. Are there any faster algorithms that I should be aware of (either asymptotically, or just with smaller constants/more uniform memory access or whatever else)? I'm working with floating point weights rather than integer weights, which for the Hungarian method doesn't seem to matter, but might be an issue for faster integer implementations. Any relevant links would be much appreciated.\n    ", "Answer": "\r\nThere are a few papers which have fast algorithms for weighted\nbipartite graphs.\n\nA recent paper Ramshaw and Tarjan, 2012 \"On Minimum-Cost Assignments in Unbalanced Bipartite Graphs\" presents an algorithm called FlowAssign and Refine that solves for the min-cost, unbalanced, bipartite assignment problem and uses weight scaling to solve the perfect and imperfect assignment problems, but not incremental with a runtime complexity of \nO(m * sqrt(n) * log(n * C)) \n where m is the number of edges (a.k.a. arcs) in the graph,\n n is the maximum number of nodes in the two graphs to be matched,\n C is a constant greater than or equal to the maximum \n edge weight and is greater than or equal to 1.\n\nThe weight scaling is what allows the algorithm to achieve\n much better performance with respect to s\n where s is the number of matched nodes.\n\nOther fast solutions can be found in the early 1990's.\nA paper from 1993 called \"QuickMatch: A Very Fast Algorithm for\nthe Assignment Problem\" by Lee and Orlin\nproposes an algorithm whose runtime they estimate \nas effectively linear on\nthe size of the graph in terms of arcs.\nhttp://jorlin.scripts.mit.edu/docs/publications/WP4-quickmatch.pdf\n\nThe QuickMatch algorithm solves the assignment problem as a \nsequence of n shortest path problems.  They use alternating \nshortest paths between origin nodes and destination nodes \nalong with heuristics to decrease the number of calculations.\nThe authors estimate the average runtime complexity by \nempirical results and comparisons to theoretically bounded \nalgorithms.  They find their algorithm to be linear w/ the number\nof graph edges (a.k.a. arcs), but the algorithm is\nnot as performant as the \"forward-reverse auction\"\nalgorithm of Bertsekas which also uses\nalternating shortest paths.   The reference for the later\nwas not printed in the paper, but might be in\n\"Reverse auction algorithms for assignment problems\",\nCastanon, 1992,\nMACS Seris in Discrete Mathematics and Computer Science\n\nThere is also the algorithm that the Berkeley segmentation\nbenchmark code uses for bipartite matching during evaluation of segmentation results compared to human drawn boundaries. \nhttp://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/\nThey use the Goldberg CSA package\nhttp://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/code/CSA++/\nwhich is reported to have runtime that is linear with graph size\nand solves for sparse min-cost assignment.\nThe references are\n\"An Efficient Cost Scaling Algorithm for the Assignment Problem\", 1993\nby Goldberg and Kennedy\nand  Cherkassky and Goldberg, \"On Implementing PushRelabel\nMethod for the Maximum Flow Problem,\" Proc. Fourth\nInteger Programming and Combinatorial Optimization Conf., pp. 157-\n171, May 1995.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How can a directed cycle exist in the residual graph of a Bipartite Flow Network with a perfect matching?\r\n                \r\nI am studying the analysis of algorithms. I am currently reading on ```\nNetwork Flow```\n algorithms. I am considering an application of ```\nNetwork Flow```\n algorithms concerning finding ```\nbipartite matchings```\n of minimum cost.\n\n\nLet ```\nG```\n with corresponding Network Flow ```\nG'```\n\nLet ```\nM```\n be a ```\nperfect matching```\n in ```\nG```\n\nLet ```\nG<sub>M</sub>```\n be the ```\nresidual graph```\n associated with this matching\n\n\nFrom Jon Kleinberg and Eva Tardos' Algorithm Design 7.13 on page 406,\n\n```\nTheorem 7.62```\n states: \n\n\n  (7.62) Let M be a perfect matching. If there is a negative-cost directed cycle C in GM, then M is not minimum cost\n\n\nThis theorem makes sense however, I am confused as to how a ```\nbipartite flow network's```\n ```\nresidual graph```\n of a ```\nperfect matching```\n can actually contain a cycle. The only way I could see a cycle is if the ```\nsink```\n or ```\nsource```\n were involved. \n\nHowever in a ```\nperfect matching```\n the ```\nsource```\n would contain no edges leaving it, and the ```\nsink```\n would contain no edges entering it. Also, a cycle occurring in the inner nodes would seem to contradict the definition of a ```\nBipartite graph```\n.\n\nCan someone provide an example of such a cycle in the residual graph? \n    ", "Answer": "\r\nSure.  Consider the graph where a = cost and c = capacity:\n\n```\n  a=3,c=1\nAo----->oB\n  \\    ^\n   \\  /a=1,c=1\n    \\/\n    /\\\n   /  \\a=1,c=1\n  /    v\nCo----->oD\n  a=3,c=1\n```\n\n\nSo there are obviously 2 possible max flows. One uses the horizontal edges and the other the diagonals.  \n\nFor the flow along the horizontals, we have a residual graph:\n\n```\n  a=-3,c=1\nAo<-----oB\n  \\    ^\n   \\  /a=1,c=1\n    \\/\n    /\\\n   /  \\a=1,c=1\n  /    v\nCo<-----oD\n a=-3,c=1\n```\n\n\nNotice the cycle B->A->D->C with capacity 1 and cost -3 + 1 -3 + 1 = -4.\n\nThe intuitive explanation for this cycle is that every increase in flow of one unit going along the edges in the cycle - or conversely every decrease in flow going along its edges in the opposite direction - we will decrease total cost of flow by 4 because we will be substituting flow along the cheaper diagonal edges for flow along the comparatively expensive horizontal edges.\n\nIn the augmenting path algorithm for min cost flow, we'd go ahead and push 1 unit of flow along this cycle and end up with a new, cheaper flow along the diagonals.  This would provide the new residual graph:\n\n```\n  a=3,c=1\nAo----->oB\n  ^    /\n   \\  /a=-1,c=1\n    \\/\n    /\\\n   /  \\a=-1,c=1\n  v    \\\nCo----->oD\n  a=3,c=1\n```\n\n\nNow the cycle is A->B->C->D and has cost 3 - 1 + 3 - 1 = 4, so the max flow along diagonals is a min cost max flow.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Non-bipartite non-weighted maximum matching between users\r\n                \r\nThe situation: A user selects multiple other users as possible partners for a project. The user has no preference for one user he picks over another (i.e. any user in his list is good enough for a partner). Example:\n\n```\n| user_id | preferred_partners |\n| 1       | 2 4                |\n| 2       | 3 1                |\n| 3       | 4 2 1              |\n| 4       | 1                  |\n```\n\n\nThe real list will be much larger.\n\nMy question: given an array of users and their preferred partners (like the list above), I want to generate an array of final partnered pairs. The number of final partnered pairs must be maximized (I want to have as many people in pairs as possible).\n\nThis is the algorithm I think I need: Edmonds's matching algorithm, but as I am not from a mathematical background, I'm having trouble interpreting and implementing it.\n\nAny help would be appreciated. Thanks in advance.\n    ", "Answer": "\r\nEdmonds's matching algorithm is indeed what you want. This is a good link that offers a detailed explanation\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Is finding whether k different perfect matchings exist in a bipartite graph co-NP?\r\n                \r\nFew definitions first. The co-NP problem is a decision problem where the answer \"NO\" can be verified in polynomial time. The perfect matching in a bipartite graph is a set of pairs of nodes (a pair is an edge in the graph) and where every node occurs in this set exactly once.\n\nI am given an n x n bipartite graph, and I am trying to find out if the problem of finding whether k different perfect matchings exist in the graph, where k= polynomial(n), is a co-NP problem.\n\nWork done so far\n\nTo initially simplify the problem, I believe that if k=2, then this is a co-NP problem. I think this is true, because the bipartite graph does not have 2 different perfect matchings, if there does not exist an exchange of neighbors between 2 nodes. I define the exchange of neighbors as the following. Let G1 be the first set in the graph, and G2 be the second set in the graph. The exchange occurs when we have a subset of G1, S1={A,B}, and a second subset of G2, S2={X,Y}, where {(A,X),(A,Y),(B,X),(B,Y)} belongs to the set of edges E. I call it exchange because if A was initially matched with X, and B with Y, then when A gets paired with Y, and B with X, A and B have exchanged their neighbors. I believe that the only way to have 2 different perfect matchings is to have at least one such exchange. \n\nNow, we can verify that no such exchange exist in polynomial time. This is true since getting all the possible subsets S1 and S2 has O(n^4) time complexity. This because we need (n choose 2) from G1 multiplied by (n choose 2) from G2, and this gives us an upper bound of n^4.\n    ", "Answer": "\r\nI am not sure if this is a co-NP problem, but it is NP for certain. I think you have a little mixed up the definition of \"verifying an answer\". In complexity theory verify an answer means that you provide a certificate that proves that your answer is correct, and such certificate may be checked (verified) in polynomial time.\n\nFor example, in the case of your problem, if you have a set k different perfect matchings, that will be a good certificate, verifying it means checking that it is indeed a set of perfect matchings in your input graph. You can check this in polynomial time by checking that all edges are in you graph and in each matching no two edges share a vertex, and all of them are different. Since the number of edges in a matching is linear, then verifying each matching can be done in polynomial time, then, since k is polynomial, we verify that property for all matchings also in polynomial time. Finaly, checking that all are different can be done in k square times something polynomial on n, yielding a polynomial complexity. So yes, your problem can be verified in polynomial time, and thus it is in NP.\n\nNow, if you can find such certificate in polynomial time that will be proof enough that you problem is in P, and all problems in P are in NP and in co-NP. So I see two possible ways to solve this, you may prove that your problem is in P, that will yield a yes answer to your question, or you may prove that your problem is NP-complete, that will prove that your answer is no, since all NP-complete problems are not in co-NP (unless P = NP).\n\nAny other way of proving that your problem is or is not in co-NP, might be very difficult and confusing, in fact the work you have done so far was moving towards proving that you can decide negative cases in polynomial time which is a different thing as verifying them, that would prove that it is co-NP, but because you proved that it is in P.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum weight matching in bipartite graphs with constraints\r\n                \r\nAssume that we have two sets: A=(a_1,a_2,...,a_m) and B=(b_1,b_2,...,a_n) (Not necessarily of same size). A function F assigns a weight to each link from set A to set B: F:A*B->R. So, for example, F(a_1,b_1)=2 means that the weight of the link between a_1 and b_1 is 2.\nThe problem is to connect the elements of set A to those of set B in order to maximize the sum of the link weights satisfying these constraints:\n\n\nThe elements of set A must be matched to exactly one element of set B.\nElements of set B are allowed to have zero or more matching (0,1,2...) although a constraint on the sum of weights C_i exists for the elements of B. That is, if we choose to connect a_1 to b_1, and a_2 to b_1, the sum of weights F(a_1,b_1)+F(a_2,b_1) should be less than or equal to C_1. This constraint is there for all elements of B.\n\n\nI have searched for some ideas and I looked into the assignment problems and the Hungarian algorithm. The additional thing is that none of these consider the second constraint I have. Do you have any ideas on how to solve this?\n\nThanks\n    ", "Answer": "\r\nIt's NP-hard.\n\nTake a subset-sum instance {x1, x2, ..., xn}, where xi > 0 and a number k. Create a bipartite graph where left vertices are {a1, ..., an}, right vertices are {b1,b2}, and:\n\nF(ai, b1) = xi\n\nF(ai, b2) = 0\n\nC1 = k\n\nC2 = 0\n\nSo you can take the number xi by connecting ai with b1, and leave it by connecting with b2. Obviously there is a weight k matching iff the subset sum instance has a solution.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Non bi partite matching algorithm\r\n                \r\nI'm trying to find a specific algorithm allowing me to match people depending of many criterias. All of them are in the same set, and edges cannot have common vertices. Basically like a dating website but as I said : only one set, so not bi partite.\n\nDespite researches I wasn't able to find this algorithm, almost everything is about bipartite, or allow common vertices. I'm specifically looking for a perfect matching (that can be slow).\n\nIt seems the algorithm is supposed to be based on the Ford Furkerson algorithm (which usually is for bipartite matching), but I still don't get how to apply it to that. Do you have any clues ? Thanks\n    ", "Answer": "\r\nYou can find the maximum matching in a non-bipartite graph using the Blossom algorithm (it's quite complicated so I'll not describe it here).\n\nOnce you have the maximum matching, checking if it's perfect is very straightforward (just compare its size with the number of vertices in the graph).\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Minimum Vertex Cover On A Bipartite Graph\r\n                \r\nLet’s say you have a bipartite graph G = (V, U, E)\n\nv1 is connected to u1, u2, and u3\n\nv2 is connected to u2 and u3\n\nv3 is connected to u3.\n\nBy looking at the graph, I know that the minimum vertex covers are {v1, v2, u3} and {v1, u2, u3}, but I’m not sure how to use the bipartite matching/vertex cover algorithm to find this out. Here\nand Here\n\nWhen I perform algorithm by hand, the output is just the trivial minimum vertex cover, all of V. Am I doing something wrong?\n\nEdit:\n\nThe maximum matching for the graph are the edges (v1, u1), (v2, u2), and (v3, u3). Given the maximum matching, the next step is to start at an unsaturated vertex (a vertex that is not one of the endpoints of a matched edge)\n\nBut in this case all the vertices are saturated, so I don't know how to proceed.\n    ", "Answer": "\r\nKonig's theorem has two directions. The easy direction, corresponding to weak linear programming duality, is that the vertex cover is at least as large as the matching. This is because, in every vertex cover, each matching edge has at least one of its endpoints present.\n\nThe hard direction of Konig's theorem, corresponding to strong LP duality, is that there exists a vertex cover where at most (i.e., exactly) one endpoint of each matching edge is present. The thrust of Wikipedia's current proof is to use the matching to construct a vertex cover greedily, showing that, if this algorithm gets stuck, then the allegedly maximum matching has an augmenting path (a contradiction). Every edge is incident to a matched vertex, so the unmatched vertices can be excluded from the cover. Their neighbors in turn must be included. Their neighbors' neighbors can be excluded, etc.\n\nYou've noticed that this process sometimes fails to determine the status of each vertex. For this case, the Wikipedia editors write \"If there is no such vertex, but there remain vertices not included in any previously-defined set Sk, arbitrarily choose one of these and let S2j+1 consist of that single vertex.\" One way to justify this step is as follows. Letting u be the chosen vertex and v be u's mate, we're pretending as though v's mate was not u but a newly created vertex u'. Then u is unmatched, so we reseed the algorithm by excluding u and cover the newly created edge u' -- v when we subsequently include v.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Networkx bipartite graph edge cover\r\n                \r\nI need to compute an edge cover of a weighted bipartite graph which I have built in Networkx. Based on this answer, I have two algorithms that respectively return a minimum weight edge cover and a minimum cardinality (and weight) one. The minimum weight algorithm presents some odd behaviour in the choice of edges, which may be related to an error that happens in the minimum cardinality algorithm, so I'll explain both situations below.\nHere are a few details about the graphs being considered:\n\nMy current test case has about 1200 nodes on one side and 1600 on the other, with over a million edges\nAll nodes have at least one incident edge\nThe graph is typically disconnected in a few blocks\nThe problem is built as an undirected graph, but directed edges would also make sense (they would always be from the set with ```\nbipartite==_og_id```\n to the other)\n\n\nMinimum weight algorithm\nThis algorithm seems to always pick the ```\nvv'```\n edges (i.e., the edges that are between a node in the original graph and its copy in the larger graph). I thought it was because some edges had a weight of 0 (causing the ```\nvv'```\nedge to also have a weight of 0), but adding a minimum weight when building the graph did not change this behaviour. (I use 0.1 since the minimum nonzero weight in the graph should be 1) This basically reverts the algorithm to \"for each node, pick the edge that has the smallest weight\" which is suboptimal.\nCode:\n```\ndef _min_weight_edge_cover(g: nx.Graph):\n    \"\"\"Returns an edge cover that minimizes the total weight of included edges, but not the total number of edges\"\"\"\n    clone = g.copy()\n\n    for node, bi in g.nodes(data='bipartite'):\n        nd = f\"{node}_copy\"\n        clone.nodes[node]['copy'] = False\n        clone.add_node(nd, copy=True, bipartite=(_og_id if bi == _tg_id else _tg_id))  # invert the bipartite flag\n        minw = min([w for u, v, w in g.edges(node, data='weight')])\n        clone.add_edge(node, nd, weight=(2 * minw))\n\n\n    # Now clone contains both the nodes of g and their copies, and should still be bipartite\n    tops = {n for n, d in clone.nodes(data=True) if d['bipartite'] == _og_id}\n    bots = set(clone) - tops\n    print(f\"[cover] we have {len(tops)} tops and {len(bots)} bots\")\n    # Here the matching should always exist and be perfect\n    matching = nx.bipartite.minimum_weight_full_matching(clone, tops)\n    \n    cover = g.copy()\n    cover.clear_edges()\n    keys = {k for k in matching.keys() if clone.nodes[k]['copy'] is False}\n\n    for k in keys:\n        v = matching[k]\n        if g.has_edge(k, v):\n            # We never get here\n            cover.add_edge(k, v)\n        else:\n            # v was a copy - this is always true\n            assert clone.nodes[v]['copy']\n            minw = math.inf\n            mine = None\n            # FIXME should check that we don't add edges between nodes that are already covered\n            for u, va, w in g.edges(k, data='weight'):\n                if w < minw:\n                    minw = w\n                    mine = (u, va)\n            cover.add_edge(*mine)\n\n    return cover\n```\n\nMinimum cardinality (and weight)\nThis algorithm is much simpler (start with a matching and then add the cheapest edge of each node not included in the matching). However, the ```\nnx.bipartite.minimum_weight_full_matching```\n function causes an error with ```\ncost matrix is infeasible```\n in ```\nscipy.optimize.linear_sum_assignment```\n. Unfortunately, there are no details on what makes the cost matrix infeasible. The documentation states that the function takes into account the different number of nodes in the sets, and I've made sure that all nodes have at least one edge. ```\nnetworkx.min_weight matching```\n does work, but it's much, much slower than the bipartite version.\nCode:\n```\ndef _min_cardinality_weight_edge_cover(g: nx.Graph) -> nx.Graph:\n    \"\"\"Returns an edge cover that minimizes\n        1. the number of edges included;\n        2. the total weight of all edges included\n    \"\"\"\n    # get the minimum weight matching.\n    # By definition, it will have at most one edge per node but some node may end up unmatched\n    matching = nx.bipartite.minimum_weight_full_matching(g, top_nodes={n for n, b in g.nodes(data='bipartite') if b ==_og_id})\n    # to make it into a cover, we take all edges from the matching and, for each node not matched, add its cheapest edge\n    cover = nx.Graph()\n    cover.add_edges_from(matching.items())\n    missing = set(g.nodes) - set(cover.nodes)\n    # there shouldn't be a case where two missing nodes could connect to each other or else that edge would have been\n    # included in the matching\n    for node in missing:\n        minw = math.inf\n        mine = None\n        for u, v, w in g.edges(node, data='weight'):\n            if w < minw:\n                minw = w\n                mine = (u, v)\n        cover.add_edge(*mine)\n\n    return cover\n```\n\nAny ideas as to what could be causing these issues?\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Convert Recursive algorithm to Iterative\r\n                \r\nI am trying to implement following algorithm to a iterative one but I am not able to do it properly. Can some one please help me with this. Its a bipartite matching algorithm and I am having trouble in converting the bpm function to iterative one.\n\n```\n// A DFS based recursive function that returns true if a\n// matching for vertex u is possible\nbool bpm(bool bpGraph[M][N], int u, bool seen[], int matchR[]) \n{\n    // Try every job one by one\n    for (int v = 0; v < N; v++)\n    {\n        // If applicant u is interested in job v and v is\n        // not visited\n        if (bpGraph[u][v] && !seen[v])\n        {\n            seen[v] = true; // Mark v as visited\n\n            // If job 'v' is not assigned to an applicant OR\n            // previously assigned applicant for job v (which is matchR[v]) \n            // has an alternate job available. \n            // Since v is marked as visited in the above line, matchR[v] \n            // in the following recursive call will not get job 'v' again\n            if (matchR[v] < 0 || bpm(bpGraph, matchR[v], seen, matchR))\n            {\n                matchR[v] = u;\n                return true;\n            }\n        }\n    }\n    return false;\n}\n\n// Returns maximum number of matching from M to N\nint maxBPM(bool bpGraph[M][N])\n{\n    // An array to keep track of the applicants assigned to\n    // jobs. The value of matchR[i] is the applicant number\n    // assigned to job i, the value -1 indicates nobody is\n    // assigned.\n    int matchR[N];\n\n    // Initially all jobs are available\n    memset(matchR, -1, sizeof(matchR));\n\n    int result = 0; // Count of jobs assigned to applicants\n    for (int u = 0; u < M; u++)\n    {\n        // Mark all jobs as not seen for next applicant.\n        bool seen[N];\n        memset(seen, 0, sizeof(seen));\n\n        // Find if the applicant 'u' can get a job\n        if (bpm(bpGraph, u, seen, matchR))\n            result++;\n    }\n    return result;\n}\n```\n\n    ", "Answer": "\r\nThe trick is that you need a stack of actions.  So when you enter the loop you first add to the stack all of the things you will do after what WOULD have been your recursive call, and THEN put the recursive call in.  They will execute in the opposite order, and when you're doing the second half, you know what happened in the first half.\n\nIn pseudo-code something like this\n\n```\nfunction somethingRecursive(stuff):\n    beforeRecursive(stuff)\n    somethingRecursive(whatever)\n    afterRecursive(stuff)\n```\n\n\nbecomes something like this:\n\n```\nwhile actions:\n   action = actions.pop()\n   if action.unwind:\n       afterRecursive(action.stuff)\n   else:\n       beforeRecursive(action.stuff)\n       actions.push(new Action(unwind, stuff))\n       actions.push(new Action(recurse, whatever))\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "In a bipartite graph finding the edges that are present in all maximum matchings\r\n                \r\nHas anyone written up the algorithm in Sage given by Tamir Tassa in, ``Finding all maximally-matchable edges in a bipartite graph''?\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Algorithm for minimum vertex cover in Bipartite graph\r\n                \r\nI am trying to figure out an algorithm for finding minimum vertex cover of a bipartite graph.\n\nI was thinking about a solution, that reduces the problem to maximum matching in bipartite graph. It's known that it can be found using max flow in networ created from the bip. graph.\n\nMax matching M should determine min. vertex cover C, but I can't cope with choosing the vertices to set C. \nLet's say bip. graph has parts X, Y and vertices that are endpoints of max matching edges are in set A, those who are not belong to B. \n\nI would say I should choose one vertex for an edge in M to C. \nSpecifically the endpoint of edge e in M that is connected to vertex in set B, else if it is connected only to vertices in A it does not matter. \nThis idea unfortunately doesn't work generally as there can be counterexamples found to my algorithm, since vertices in A can be also connected by other edges than those who are included in M.\n\nAny help would be appriciated.\n    ", "Answer": "\r\nKőnig's theorem proof does exactly that - building a minimum vertex cover from a maximum matching in a bipartite graph.\n\nLet's say you have ```\nG = (V, E)```\n a bipartite graph, separated between ```\nX```\n and ```\nY```\n.\n\nAs you said, first you have to find a maximum matching (which can be achieved with Dinic's algorithm for instance). Let's call ```\nM```\n this maximum matching.\n\nThen to construct your minimum vertex cover:\n\n\nFind ```\nU```\n the set (possibly empty) of unmatched vertices in ```\nX```\n1, ie. not connected to any edge in ```\nM```\n\nBuild ```\nZ```\n the set or vertices either in ```\nU```\n, or connected to ```\nU```\n by alternating paths (paths that alternate between edges of ```\nM```\n and edges not in ```\nM```\n)\nThen ```\nK = (X \\ Z) U (Y ∩ Z)```\n is your minimum vertex cover\n\n\nThe Wikipedia article has details about how you can prove ```\nK```\n is indeed a minimum vertex cover.\n\n\n\n1 Or Y, both are symmetrical\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "My collection of maximal matched edges comes back empty (using QuickGraph in C#)\r\n                \r\nI'm trying to use QuickGraph to, well, find a maximal matching in my bipartite graph, but the MatchedEdges collection they return to me is empty. I know there are matchings because I tested it with a K7,7 (complete bipartite) graph. So, I'm confused on what I did wrong.\n\nHere's my code (I wrote Vertex and Edge in place of my actual classes for readability):\n\n```\n    public void findMatchings(List<Friend> setA, List<Friend> setB, List<Edge> candidateEdges) {\n        // we need a graph and two sets of vertices\n        IMutableVertexAndEdgeListGraph<Vertex, Edge> graph = new AdjacencyGraph<Vertex, Edge>();\n\n        foreach (Vertex vertex in setA) {\n            graph.AddVertex(vertex);\n        }\n\n        foreach (Vertex vertex in setB) {\n            graph.AddVertex(vertex);\n        }\n\n        foreach (Edge candidate in candidatesEdges) {\n            graph.AddEdge(candidate);\n        }\n\n        // sets a and b must be distinct, and their union must be equal to the set of all vertices in the graph\n        // (though they're conceptually the same set, to you or me, I created new instances of everything so they should be practically different.)\n        IEnumerable<Vertex> vertexSetA = setA;\n        IEnumerable<Vertex> vertexSetB = setB;\n\n        // These functions are used to create new vertices and edges during the execution of the algorithm.  \n        // All added objects are removed before the computation returns\n        VertexFactory<Vertex> vertexFactory = newVertex; //newVertex() is defined below\n        EdgeFactory<Vertex, Edge> edgeFactory = (source, target) => new Edge(source, target);\n\n        // computing the maximum bipartite match\n        var maxMatch = new MaximumBipartiteMatchingAlgorithm<Vertex, Edge>(\n                graph, vertexSetA, vertexSetB, vertexFactory, edgeFactory);\n\n        Console.WriteLine(maxMatch.MatchedEdges.Count);\n\n    }\n\n    //This is in the same class as the above function:\n    static Vertex newVertex() {\n        return new Vertex(\"\");\n    }\n\n    //This is the constructor in the Edge class:\n    public Edge(Vertex source, Vertex target) {\n        this.source = source;\n        this.target = target;\n    }\n```\n\n\nmaxMatch.MatchedEdges.Count always comes back as 0. That's the problem.\n\nI'm hopeful that there will be an easy solution to this, like I shouldn't be using new AdjacencyGraph() or something, but I'm also open to suggestions to other ways to find maximal matchings in bipartite graphs. \n\nThanks!\n\nBTW, this link is what I used to write my stuff: \nMaximum Bipartite Matching in QuickGraph\n    ", "Answer": "\r\nAfter creating an instance of ```\nMaximumBipartiteMatchingAlgorithm```\n, you need to call the its Compute method so a matching is computed. In terms of your example, this means adding:\n\n```\nmaxMatch.Compute();\n```\n\n\nAlso each call to the ```\nnewVertex()```\n method should return a unique string which differs from the strings identifying the vertices in the input to ```\nMaximumBipartiteMatchingAlgorithm```\n.\n\nFYI: I personally found that sometimes ```\nmaxMatch.MatchedEdges```\n contains too many edges: some vertices are covered twice. Also I've seen ```\nmaxMatch.MatchedEdges```\n contain edges not in the input to MaximumBipartiteMatchingAlgorithm but created internally by the algorithm.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite graph, shortest connection?\r\n                \r\nI have a bipartite graph where each node has connections (edges) of various lengths to the nodes in the other partition. I want to select edges such that the sum of the lengths is as small as possible, but subject to the constraint that every node should have one and only one selected edge (if the number of nodes in the two partitions is equal - if not, one or more nodes will have no selected edge).\n\nI want to find this matching as quick as possible, but until now I have only found the brute-force approach of trying every possibility, which gives me a O(n!) algorith - which is infeasible. Does somebody have a suggestion for a better approach?\n\nMy concrete problem is the following: I have observed more or less randomly moving 3D particles in two different timepoints. I want to know where each particle has moved, i.e. track each particle, assuming that their total movement is as short as possible.\n    ", "Answer": "\r\nYou have described minimum weight bipartite matching.  Also known as the Assignment Problem.  It has been studied extensively and can be solved in polynomial time.\n\nhttps://en.wikipedia.org/wiki/Assignment_problem\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Find minimum vertex Cover for bipartite graph given the maximum matching\r\n                \r\nI seem to have found an algorithm but am having trouble understanding it, I was wondering if any of you knew the generic outline of the algorithm.\n\nHere is the link to the algorithm I found on page 2\n\nhttp://www.cse.iitb.ac.in/~sundar/cs435/lecture23.pdf\n    ", "Answer": "\r\nAlgorithm is simple as that:\n\n\nFind unmatched vertex, mark it as not included in minimum vertex cover.\nMark all matched neighbours of this vertex as included in minimum vertex cover.\nTreat all mates of vertexes from previous step as unmatched vertexes and repeat step 1.\nIf recursion ended, repeat from step 1 (that is case of several connected components of graph).\nIf there is no unmatched vertexes, take all remaining pairs and mark them any way you like (remember that one vertex in pair has to\nbe included in minimum vertex cover, and other one has to be not\nincluded).\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Algorithm : Letters and envelopes pairing\r\n                \r\nDisclaimer : This isn't any kind of homework, the problem just came to my mind while I was going through all the Christmas cards\n\nThe problem is given as follows : We've got M envelopes and N letters, each of which is described as a pair of positive integers. Both envelopes and letters are rectangular and obviously can be rotated. A letter fits into an envelope if both dimensions are smaller or equal to the envelope's ones. The goal is to find maximum envelopes-letters matching.\n\nThe problem is easily convertible to maximum bipartite matching problem, for which an algorithm running in ```\nO(sqrt(M+N) * MN)```\n exists (Hopcroft-Karp, the conversion runs trivially in ```\nO(MN)```\n). I tried to come up with a greedy algorithm or with a dynamic approach, but I haven't found any.\n\nDo you know about any faster solution?\n    ", "Answer": "\r\nThe following \"greedy\"-type approach might help.\n\nDefine m[i] to be the minimum of the two integers of envelope i.\n\n```\nmins = distinct values of m[i], in increasing order\nletters_to_match = all letters\nfor min in mins:\n    envs = envelopes i with m[i] == min\n    match letters_to_match with envs\n    remove matched letters from letters_to_match\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Augmenting Path Algorithm - Maximum Matching\r\n                \r\nI was reading the augmenting path or Kuhn's algorithm to find the maximum matching size in an unweighed bipartite graph. \n\nThe algorithm tries to find an alternating path(consisting of alternating unmatched and matched edges) starting and ending at unmatched vertices. If an alternating path is found, the path is augmented and matching count is increased by 1.\n\nI can understand the algorithm, however I have problem in understanding the way it is generally implemented. Here is a reference implementation - https://sites.google.com/site/indy256/algo/kuhn_matching2 .\n\nAt each stage, we should try to find an alternating path beginning from an unmatched vertex on the left. However, in the given implementation, in each iteration, instead of trying all unmatched vertices as possible start locations, we instead start our search from only a single unmatched vertex, as shown in the following code - \n\n```\nfor (int u = 0; u < n1; u++) {\n      if (findPath(graph, u, matching, new boolean[n1]))\n        ++matches;\n    } \n```\n\n\nThis way, a vertex on left, which is not matched during its iteration, is never tried again. I can't understand why is this optimal?\n    ", "Answer": "\r\nIt's sufficient to prove there will be no augment path left after algorithm ends. Since no augment path means max flow. Let's say A[i] as left i'th vertices, and B[i] right i'th vertices.\n\nIf A[i] has been matched, then it will remain matched in any augmenting path.\n\nSo, our only concern is when we've considered A[i] and found no match but after some iterations in for loop, A[i] suddenly has new augment path. We will show it'll never happen.\n\nLet's consider A[i] has no augmenting path before and say S as set of vertices which can be visited by dfs(i). There are only 2 ways for new vertices(which was not in S before) to be included in S afterwards.\n\n\nFor some A[x] in S, edge A[x] - B[y] is changed from matched to unmatched  (B[y] will be included in S afterwards)\n\nContradiction. Because we should find augmenting path B[y] - A[x] - ... - Sink, but Sink is not in S so we can't do that.\nFor some B[y] in S, edge B[y] - A[x] is changed from unmatched to matched (A[x] will be included in S afterwards)\n\nContradiction again. This time, we should find augmenting path A[x] - B[y] - ... - Sink, but again, we can't reach to Sink from B[y].\n\n\nFor the reasons above, it is impossible to accidentally left augmenting path which implies maximum flow.  \n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "networkx maximal_matching() does not return maximum matching\r\n                \r\nI'm learning to use the networkx python module to do some matchings of a bipartite graph. There are two functions in the module that give the maximum cardinality matching of a graph:\n\n\n```\nnx.maximal_matching()```\n\n```\nnx.bipartite.maxmum_matching()```\n\n\n\nNote that although with the name of ```\nmaximal_matching```\n, its doc does state that it \"Find a maximal cardinality matching in the graph.\"\n\nSince my graph is a bipartite one, I assume these 2 would give same results, at least both with the same number of edges. However my code seems to suggest that the ```\nnx.maximal_matching()```\n gives the wrong answer: it is possible to have one more edge, as the ```\nnx.bipartite.maxmum_matching()```\n suggests.\n\nBelow is my working code:\n\n```\nimport networkx as nx\nfrom networkx import bipartite    \n\ndef plotGraph(graph,ax,title):    \n    pos=[(ii[1],ii[0]) for ii in graph.nodes()]\n    pos_dict=dict(zip(graph.nodes(),pos))\n    nx.draw(graph,pos=pos_dict,ax=ax,with_labels=True)\n    ax.set_title(title)\n    return   \n\nif __name__=='__main__':    \n    #---------------Construct the graph---------------\n    g=nx.Graph()\n    edges=[\n            [(1,0), (0,0)],\n            [(1,0), (0,1)],\n            [(1,0), (0,2)],\n            [(1,1), (0,0)],\n            [(1,2), (0,2)],\n            [(1,2), (0,5)],\n            [(1,3), (0,2)],\n            [(1,3), (0,3)],\n            [(1,4), (0,3)],\n            [(1,5), (0,2)],\n            [(1,5), (0,4)],\n            [(1,5), (0,6)],\n            [(1,6), (0,1)],\n            [(1,6), (0,4)],\n            [(1,6), (0,6)]\n            ]\n\n    for ii in edges:\n        g.add_node(ii[0],bipartite=0)\n        g.add_node(ii[1],bipartite=1)\n\n    g.add_edges_from(edges)\n\n    #---------------Use maximal_matching---------------\n    match=nx.maximal_matching(g)    \n    g_match=nx.Graph()\n    for ii in match:\n        g_match.add_edge(ii[0],ii[1])\n\n    #----------Use bipartite.maximum_matching----------\n    match2=bipartite.maximum_matching(g)    \n    g_match2=nx.Graph()\n    for kk,vv in match2.items():\n        g_match2.add_edge(kk,vv)\n\n    #-----------------------Plot-----------------------\n    import matplotlib.pyplot as plt\n    fig=plt.figure(figsize=(10,8))\n\n    ax1=fig.add_subplot(2,2,1)\n    plotGraph(g,ax1,'Graph')\n\n    ax2=fig.add_subplot(2,2,2)\n    plotGraph(g_match,ax2,'nx.maximal_matching()')\n\n    ax3=fig.add_subplot(2,2,3)\n    plotGraph(g_match2,ax3,'bipartite.maximum_matching()')\n\n    plt.show()\n```\n\n\nAnd here is the generated plot. As is shown subplot-2 has 6 edges while 3 has 7. Is this a bug in the networkx's implementation or I'm doing anything wrong here?\n\nPS: my networkx is version 1.11\n\n\n    ", "Answer": "\r\nThe ```\nnetworkx.maximal_matching```\n algorithm does not give a maximal cardinality match in the manner you intend.  It implements a simple greedy algorithm whose result is maximal purely in the sense that no additional edge can be added to it. \n\nIts counterpart, for the global maximum cardinality match you intend, is ```\nnetworkx.max_weight_matching```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Min cost matching with outliers\r\n                \r\nGiven a complete bipartite graph G = (V1, V2; E), |V1|=|V2|=n and a non-negative cost for each edge the min cost bipartite matching problem finds a partition of G to n pairs of vertices connected by an edge, such that the total sum of the edges costs is minimized.\n\nThis problem can be solved using the min cost flow algorithm, by adding a source and sink vertices connected to each group with a weight 0 and a capacity 1.\n\nBut what if instead we get as an input a number m < n and want to find a partition of m pairs such that the total cost is minimized?\n\nAt first I thought we can just add another vertex at the beginning which is connected to the original source with weight 0 and capacity m and call it the new source, that way the maximum flow would be m and it should choose only m pairs.\n\nHowever when I ran this algorithm using boost's min cost flow function a lot of times there were 2 big problems:\n\n1) The flow in an edge wasn't always an integer (i.e. instead of 0 or 1 the flow was 0.5 for example).\n\n2) There were many possible (non-integer) solutions so even for the same input with different order the algorithm outputted different results.\n\nThe moment I set m to be n both of these problems were resolved.\n\nSo my question is: is there a way to solve this problems and if not is there another algorithm that can solve the min cost bipartite matching with outliers problem?\n    ", "Answer": "\r\nI just found out the algorithm I described in the question and said that didn't work actually did work and it happened because of floating point error caused inside boosts min cost flow function, when I multiplied all the costs by 10000 all the problems were resolved.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Why do we look for the shortest augmenting path in the Hopcroft-Karp algorithm?\r\n                \r\nIn the Hopcroft-Karp algorithm for maximum bipartite matching, why do we always look for the shortest augmenting path in the breadth first search?  Is it because the breadth first search always finds the shortest path?  I'm just confused why it's important for the augmenting path to be the shortest.\n    ", "Answer": "\r\nFinding just one augmenting path is already a Theta(|E|)-time operation. The idea behind Hopcroft–Karp (most augmenting-path algorithms, really, if one squints a bit) is to do more with each Theta(|E|)-time iteration.\n\nWhy shortest augmenting paths? H–K looks for several augmenting paths at once, which must be vertex-disjoint to be useful simultaneously. The vertex-disjointness creates a packing problem, to which the greedy solution is to pack the \"densest\" (best value to space ratio) things first, i.e., the shortest augmenting paths. In practice, greedy algorithms often work well (see, for example, the analyses of set cover, or H–K on random graphs).\n\nThe real answer, though, is that H–K is provably better than Theta(|E| |V|). The formal analysis of H–K uses the length of a shortest augmenting path to measure the progress of the algorithm, and by using a maximal set of these paths, H–K increases this quantity. When the shortest augmenting paths reach length √|V|, it's impossible to pack more than √|V| of them (vertex disjoint), so the algorithm has at most √|V| edges to go, and the total number of iterations is O(√|V|), for a O(|E| √|V|)-step running time.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Implementation of Minimum Vertex Cover in a Bipartite Graph\r\n                \r\nI have a bipartite graph that's quite large (~200 vertices per part, usually with 20,000 or more edges in between), and I'm trying to find a Minimum Vertex Cover in it because I'm looking for an assignment between the vertices of the two parts.\nAccording to Koenig's theorem, there is such a cover with the same size as the cardinality of a Maximum Matching (https://en.wikipedia.org/wiki/K%C5%91nig%27s_theorem_(graph_theory)).\nI have implemented the Hopcroft Karp algorithm which gives me a Maximum Matching. If needed, I can provide my implementation of that, but I doubt that's where my problem is.\nWhat's the actual problem?\nI suspect my implementation, taken from the Wikipedia article above (https://en.wikipedia.org/wiki/K%C5%91nig%27s_theorem_(graph_theory)#Constructive_proof), has an error in it, but after several hours of checking it I am unable to find the cause of the bug: While the Hopcroft Karp algorithm finds a maximum matching with 192 edges, the Minimum Vertex Cover returns 200 vertices. As this is a bipartite graph, these numbers shouldn't differ (because of the theorem). Maybe you can help me out and tell me where my mistake is. Thanks in advance!!\n(```\nStudent```\n's and ```\nProject```\n's are my two types of vertices in the bipartite graph)\n```\ninternal static List<Vertex> FindMinimumVertexCover(IReadOnlyList<Edge> matching, IReadOnlyList<Vertex> studentVertices, IReadOnlyList<Vertex> projectVertices)\n    {\n        var unmatchedStudentNodes = studentVertices.Except(matching.Select(e => e.GetStudentVertex())).ToList();\n        var visitedVertices = new List<Vertex>();\n        var edgeComparer = new EdgeComparer();\n\n        foreach (var unmatchedStudentNode in unmatchedStudentNodes)\n        {\n            visitedVertices = visitedVertices.Union(FindAlternatingNodes(matching, unmatchedStudentNode, visitedVertices, edgeComparer)).ToList();\n        }\n\n        visitedVertices = unmatchedStudentNodes.Union(visitedVertices).ToList();\n\n        return studentVertices.Except(visitedVertices).Union(projectVertices.Intersect(visitedVertices)).ToList();\n    }\n\nprivate static List<Vertex> FindAlternatingNodes(IReadOnlyList<Edge> matching, Vertex initialVertex, List<Vertex> visitedVertices, EdgeComparer edgeComparer)\n    {\n        if (visitedVertices.Contains(initialVertex))\n            return Enumerable.Empty<Vertex>().ToList();\n\n        visitedVertices.Add(initialVertex);\n        List<Edge> unmatchedEdges = initialVertex.Edges.Except(matching, edgeComparer).ToList();\n\n        foreach (Edge unmatchedEdge in unmatchedEdges)\n        {\n            Vertex visitedVertex = unmatchedEdge.GetProjectVertex();\n            Edge matchedEdge = matching.SingleOrDefault(e => e.GetProjectVertex().Equals(visitedVertex));\n\n            if (matchedEdge != default(Edge))\n            {\n                visitedVertices.Add(visitedVertex);\n                visitedVertex = matchedEdge.GetStudentVertex();\n                visitedVertices = visitedVertices.Union(FindAlternatingNodes(matching, visitedVertex, visitedVertices, edgeComparer)).ToList();\n            }\n        }\n\n        return visitedVertices;\n    }\n\nclass EdgeComparer : IEqualityComparer<Edge>\n{\n    public bool Equals(Edge x, Edge y)\n    {\n        if (Object.ReferenceEquals(x, y))\n            return true;\n\n        if (x is null || y is null)\n            return false;\n\n        return Object.ReferenceEquals(x.GetStudentVertex(), y.GetStudentVertex()) && Object.ReferenceEquals(x.GetProjectVertex(), y.GetProjectVertex());\n    }\n\n    public int GetHashCode(Edge edge)\n    {\n        return (Student: edge.GetStudentVertex(), Project: edge.GetProjectVertex()).GetHashCode();\n    }\n}\n```\n\n    ", "Answer": "\r\nI now found the problem. I want to thank @David Eisenstat, as he suggested generating small random graphs repeatedly.\nThe problem was something in my implementation of the ```\nVertex```\n class.\nEvery time I create an instance of the ```\nEdge```\n class, I add that Edge to the corresponding vertices as well (meaning I effectively got 3 references to an edge). Calling the outer algorithm again (which calls the method above) only recreated the edge list, but left the old references in the vertices intact. Thus, following calls didn't start freshly, and the Minimum Vertex Cover found edges in the graph that weren't existent anymore (namely the ```\nList<Edge> unmatchedEdges = initialVertex.Edges.Except(matching, edgeComparer).ToList();```\n line).\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite Graph With Weighted Edges\r\n                \r\nI have a problem where I have a bipartite graph with weighted edges. What I want to do is sum the weights of the edges incident on every vertice, for each vertice individually. \n\nThe eventual goal is to convert the weights incident on every vertice into a %, and use a confidence interval to carry out certain operations. \n\nI'm currently approaching this problem by building an adjacency matrix to represent the bipartite graph. I intend to iterate over one set of nodes of the graph, and update the relevant cells in the matrix with the weight of the connecting edge. \n\nIs there a better way to approach this problem?\n\nNote: I am not looking for a 1:1 matching algorithm like the Hungarian algorithm. I have no need to find a match, just a % based on the weights of the edges. \n    ", "Answer": "\r\nConsider a bipartite graph with 5 vertices and two vertex sets U = {v1, v2, v3} and V = {v4, v5}.Note that, in any bipartite, there will be no edges between elements of the same vertex set e.g., v1 and v2 or v4 and v5.    So you could construct an adjacency matrix with vertices from U as rows and vertices from V as columns:\n\n```\n        v4  v5   |sum(w)\n                 |\n    v1  0   7    | 7\n                 | \n    v2  6   0    | 6 \n                 |\n    v3  10  2    | 12\n__________________\nsum(w)  16  9\n```\n\n\nThis way a row-sum will give you the sum of weights of the edges incident on a vertex in U and a column-sum will be on a vertex in V.   Hope that helps!\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to increase the Java stack size?\r\n                \r\nI asked this question to get to know how to increase the runtime call stack size in the JVM. I've got an answer to this, and I've also got many useful answers and comments relevant to how Java handles the situation where a large runtime stack is needed. I've extended my question with the summary of the responses.\n\nOriginally I wanted to increase the JVM stack size so programs like runs without a ```\nStackOverflowError```\n.\n\n```\npublic class TT {\n  public static long fact(int n) {\n    return n < 2 ? 1 : n * fact(n - 1);\n  }\n  public static void main(String[] args) {\n    System.out.println(fact(1 << 15));\n  }\n}\n```\n\n\nThe corresponding configuration setting is the ```\njava -Xss...```\n command-line flag with a large enough value. For the program ```\nTT```\n above, it works like this with OpenJDK's JVM:\n\n```\n$ javac TT.java\n$ java -Xss4m TT\n```\n\n\nOne of the answers has also pointed out that the ```\n-X...```\n flags are implementation dependent. I was using\n\n```\njava version \"1.6.0_18\"\nOpenJDK Runtime Environment (IcedTea6 1.8.1) (6b18-1.8.1-0ubuntu1~8.04.3)\nOpenJDK 64-Bit Server VM (build 16.0-b13, mixed mode)\n```\n\n\nIt is also possible to specify a large stack only for one thread (see in one of the answers how). This is recommended over ```\njava -Xss...```\n to avoid wasting memory for threads that don't need it.\n\nI was curious how large a stack the program above exactly needs, so I've run it ```\nn```\n increased:\n\n\n-Xss4m can be enough for ```\nfact(1 << 15)```\n\n-Xss5m can be enough for ```\nfact(1 << 17)```\n\n-Xss7m can be enough for ```\nfact(1 << 18)```\n\n-Xss9m can be enough for ```\nfact(1 << 19)```\n\n-Xss18m can be enough for ```\nfact(1 << 20)```\n\n-Xss35m can be enough for ```\nfact(1 << 21)```\n\n-Xss68m can be enough for ```\nfact(1 << 22)```\n\n-Xss129m can be enough for ```\nfact(1 << 23)```\n\n-Xss258m can be enough for ```\nfact(1 << 24)```\n\n-Xss515m can be enough for ```\nfact(1 << 25)```\n\n\n\nFrom the numbers above it seems that Java is using about 16 bytes per stack frame for the function above, which is reasonable.\n\nThe enumeration above contains can be enough instead of is enough, because the stack requirement is not deterministic: running it multiple times with the same source file and the same ```\n-Xss...```\n sometimes succeeds and sometimes yields a ```\nStackOverflowError```\n. E.g. for 1 << 20, ```\n-Xss18m```\n was enough in 7 runs out of 10, and ```\n-Xss19m```\n wasn't always enough either, but ```\n-Xss20m```\n was enough (in all 100 runs out of 100). Does garbage collection, the JIT kicking in, or something else cause this nondeterministic behavior?\n\nThe stack trace printed at a ```\nStackOverflowError```\n (and possibly at other exceptions as well) shows only the most recent 1024 elements of the runtime stack. An answer below demonstrates how to count the exact depth reached (which might be a lot larger than 1024).\n\nMany people who responded has pointed out that it is a good and safe coding practice to consider alternative, less stack-hungry implementations of the same algorithm. In general, it is possible to convert to a set of recursive functions to iterative functions (using a e.g. ```\nStack```\n object, which gets populated on the heap instead of on the runtime stack). For this particular ```\nfact```\n function, it is quite easy to convert it. My iterative version would look like:\n\n```\npublic class TTIterative {\n  public static long fact(int n) {\n    if (n < 2) return 1;\n    if (n > 65) return 0;  // Enough powers of 2 in the product to make it (long)0.\n    long f = 2;\n    for (int i = 3; i <= n; ++i) {\n      f *= i;\n    }\n    return f;\n  }\n  public static void main(String[] args) {\n    System.out.println(fact(1 << 15));\n  }\n}\n```\n\n\nFYI, as the iterative solution above shows it, the ```\nfact```\n function cannot compute the exact factorial of numbers above 65 (actually, even above 20), because the Java built-in type ```\nlong```\n would overflow. Refactoring ```\nfact```\n so it would return a ```\nBigInteger```\n instead of ```\nlong```\n would yield exact results for large inputs as well.\n    ", "Answer": "\r\nHmm... it works for me and with far less than 999MB of stack:\n\n```\n> java -Xss4m Test\n0\n```\n\n\n(Windows JDK 7, build 17.0-b05 client VM, and Linux JDK 6 - same version information as you posted)\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Placing maximum number of rooks\r\n                \r\nProblem:\nI'm given a ```\nNxN```\n chessboard with ```\nM```\n cells with holes on it. I've to find maximum number of rooks that can be placed on it such that each row or column has equal number of rooks on it. (Note that the rooks may attack each other)\n\nI've tried to model this by assuming each row and column to be a node. Add an edge (of capacity 1) between node corresponding to ```\nr_i```\n and node corresponding to ```\nc_j```\n if ```\ncell[i][j]```\n is not hole. Now, I've to find maximum flow in this bipartite graph while making sure flow from each row is same as flow from each column. I doubt if this will be equal to minimum among flows from rows/to columns in case of maximum bipartite matching. Can this statement be proved/disproved? Is there any other way to solve this problem?\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How can I get optimal matching between K groups?\r\n                \r\nI have K sets of data points, I would like to make groups of size K which minimize the total sum of intra group distances. I'm familiar with matching algorithms with bipartite graphs, but I would like this for more than two sets. \n\nAny ideas?\n\nEdit : \n\nEach group would be made of one element of each set, no repetitions allowed.\n\nAn example : you have {a1, a2, a3}, {b1, b2, b3}, {c1, c2, c3}\nYou want to create groups e.g. {a1, b3, c3}, {a2, b1, c2}, {a3, b2, c1} minimizing the sum of intra group distances. \n    ", "Answer": "\r\nThis problem can be reduced to another, similar problem that I have solved for another stackoverflow question before. The idea is to compute all combinations of ```\nn / k```\n sized groups, and weight these according to their intra group distances. Traverse the search space for valid combinations of combinations. Keep record of the minimal sum, and use this to prune dead-end branches. You can speedup the search using dynamic programming by producing optimal subsets of the solution, and building up to the final solution from that (as described in my other post), or you could use a greedy method and some hand wavey tricks to find a nearly optimal (or optimal) solution (also described in said post). Here is a link to the sub problem that you can reduce this to.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "NetworkX bipartite graph issues\r\n                \r\nHere's the set up: I have a data frame, ```\ndf```\n, with columns labeled A,B,...,K. Each entry of column A is unique and will make up one of the two sets of vertices, call it X, in a bipartite graph, ```\nG```\n. The entries of columns B,...,K (not all unique) make up the other set of vertices, call it Y, in the bipartite graph. We draw an edge from vertex y in Y to vertex x in X if y is in the same row as x.\n\nUsing this answer from another post, I have the following code which creates a bipartite graph with vertex sets given by the entries of column A (positioned on the right) and B (positioned on the left)\n\n```\nG = nx.Graph() \nG.add_nodes_from(df['A'], bipartite=0)\nG.add_nodes_from(df['B'], bipartite=1)\nG.add_weighted_edges_from(\n    [(row['B'], row['A'], 1) for idx, row in df.iterrows()], \n    weight='weight')\npos = {node:[0, i] for i,node in enumerate(df['B'])}\npos.update({node:[1, i] for i,node in enumerate(df['A'])})\nnx.draw(G, pos, with_labels = True)\nplt.show()\n```\n\n\nI'm seeking advice/help with a few problems:\n\n\nThe number of vertices is large enough so that the vertices appear very bunched up. Is there a way of spreading out the vertices in each of the two vertex sets?\nAs I mentioned, this code makes a bipartite graph connecting some entries of B with some entries of A (again, based on row matching). How can I do this for each of the other columns (i.e. connecting elements of C,...,K with A in the same way)? I know there is a way to union graphs together with ```\nunion(G1,G2)```\n but I imagine there's a better way to achieve this.\nI'd like to create some kind of edge coloring based on the degree of vertices in Y. I imagine the coloring will be implemented using the ```\nG.degree()```\n, but I'm not sure how that works.\n\n\nPlease let me know if you have any suggestions for my problems. Thanks in advance!\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Best matching in a bipartite graph (e.g.associating labels with points on a plot)\r\n                \r\nI am trying to extract semantics from graphical xy plots where the points are plotted and some or all have a label. The label is plotted \"near the point\" so that a human can normally understand which label goes with which point. For example in this plot it is clear which label(number) belongs to which point(*) and an algorithm based on Euclidian distance would work. (The labels and points have no semantic ordering - e.g. a scatterplot)\n\n```\n *1\n    *2\n\n        *3\n\n      *4\n```\n\n\nIn congested plots the authoring software/human may place the label in different directions to avoid overlap. For example in \n\n```\n1**2\n **4\n 3\n```\n\n\nA human reader can normally work out which label is associated with which label.\n\nOne solution I'd accept would be to create a Euclidean distance matrix and shuffle the rows to get the minimum of a function (e.g. the summed squares of the distances on the diagonal or other heuristic). In the second example (with the points labelled a,b,c,d clockwise from the NW corner) we have a distance matrix (to 1 d.p.)\n\n```\n             a   b   c   d\n 1ab2    1  1.0 2.0 2.2 1.4    \n  dc4    2  2.0 1.0 1.4 2.2\n  3      3  2.0 2.2 1.4 1.0\n         4  2.2 1.4 1.0 2.0\n```\n\n\nand we need to label ```\na1 b2 c4 d3```\n. Swapping rows 3 and 4 gives the minimum sum of the diagonal. Here's a more complex example where simply picking the nearest may fail\n\n```\n *1*2*5\n  **4\n  3 *6\n```\n\n\nIf this is solved then I shall need to go to cases where the number of labels may be smaller or larger than the number of points.\n\nIf the algorithm is standard than I would appreciate a pointer to Open Source Java (e.g. JAMA or Apache maths)\n\nNOTE: This SO answer Associating nearby points with a path doesn't quite work as an answer because the path through the points is given.\n    ", "Answer": "\r\nYou have a complete bipartite graph that one part is numbers and other one is points. Weight's of edge in this graph is euclidean distance between numbers and points. And you're task is finding matching with minimal weight.\nThis is known problem and has a well known algorithm named as ```\nHungarian Algorithm```\n:\nFrom Wiki:\n\nWe are given a nonnegative n×n matrix, where the element in the i-th\nrow and j-th column represents the cost of assigning the j-th point to\nthe i-th number. We have to find an assignment of the point to the\nnumbers that has minimum cost. If the goal is to find the assignment\nthat yields the maximum cost, the problem can be altered to fit the\nsetting by replacing each cost with the maximum cost subtracted by the\ncost.\nThe algorithm is easier to describe if we formulate the problem using\na bipartite graph. We have a complete bipartite graph G=(S, T; E) with\nn number vertices (S) and n point vertices (T), and each edge has a\nnonnegative cost c(i,j). We want to find a perfect matching with\nminimum cost. The Hungarian method is a combinatorial optimization\nalgorithm which solves the assignment problem in polynomial time and\nwhich anticipated later primal-dual methods. f\n\nFor detailed algorithm and code you can take a look at topcoder article\nand this pdf maybe to use\nthere is a media file to describe it.\n(This video explains why the Hungarian algorithm works)\n\nalgorithm :\nstep 1:- prepare a cost matrix.if the cost matrix is not a square\nmatrix then add a dummy row(column) with zero cost element.\nstep 2:- subtract the minimum element in each row from all the\nelements of the respective rows.\nstep 3:- further modify the resulting matrix by subtracting the\nminimum elememnt of each column from all the elements of the\nrespective columns.thus obtain the modified matrix.\nstep 4:- then,draw minimum no of horizontal and vertical lines to\ncover all zeros in the resulting matrix.let the minimum no of lines be\nN.now there are 2 possible cases.\ncase 1 - if N=n,where n is the order of matrix,then an optimal\nassignment can be made.so make the assignment to get the required\nsolution.\ncase 2 - if N less than n then proceed to step 5\nstep 5: determine the smallest uncovered element in the\nmatrix(element not covered by N lines).subtract this minimum element\nfrom all uncovered elements and add the same elements at the\nintersection of horizontal and vertical lines.thus the second modified\nmatrix is obtained.\nstep 6:- repeat step(3) and (4) untill we get the case (1) of step 4.\nstep 7:- (to make zero assignments) examine the rows successively\nuntill a row-wise exactly single zero is found.circle(o) this zero to\nmake the assignment.then mark a cross(x) over all zeros if lying in\nthe column of the circled zero,showing that they can't be considered\nfor future assignment.continue in this manner untill all the zeros\nhave been examined. repeat the same procedure for column also.\nstep 8:- repeat the step 6 succeccively until one of the following\nsituation arises- (i)if no unmarked zeros is left,then the process\nends or (ii) if there lies more than one of the unmarked zero in any\ncolumn or row then,circle one of the unmarked zeros arbitrarily and\nmark a cross in the cell of remaining zeros in its row or\ncolumn.repeat the process untill no unmarked zero is left in the\nmatrix.\nstep 9:- thus exactly one marked circled zero in each row and each\ncolumn of the matrix is obtained. the assignment corresponding to\nthese marked circle zeros will give the optimal assignment.\n\nFor details see wiki and http://www.ams.jhu.edu/~castello/362/Handouts/hungarian.pdf\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to get different maximum matchings\r\n                \r\nI have a large bipartite graph and I can find a maximum matching quickly using Hopcroft-Karp. But what I would really like is a few hundred different maximum matchings for the same graph. How can I get those?\nHere is an example small bipartite graph with a maximum matching shown.\n\nSimilar graphs can be made with:\n```\nimport igraph as ig\nfrom scipy.sparse import random, find\nfrom scipy import stats\nfrom numpy.random import default_rng\nimport numpy as np\nfrom igraph import Graph, plot\nnp.random.seed(7)\nrng = default_rng()\nrvs = stats.poisson(2).rvs\nS = random(20, 20, density=0.35, random_state=rng, data_rvs=rvs)\ntriples = [*zip(*find(S))]\nedges = [(triple[0], triple[1]+20) for triple in triples]\nprint(edges)\ntypes = [0]*20+[1]*20\ng = Graph.Bipartite(types, edges)\nmatching = g.maximum_bipartite_matching()\nlayout = g.layout_bipartite()\nvisual_style={}\nvisual_style[\"vertex_size\"] = 10\nvisual_style[\"bbox\"] = (600,300)\nplot(g, bbox=(600, 200), layout=g.layout_bipartite(), vertex_size=20, vertex_label=range(g.vcount()), \n    vertex_color=\"lightblue\", edge_width=[5 if e.target == matching.match_of(e.source) else 1.0 for e in g.es], edge_color=[\"red\" if e.target == matching.match_of(e.source) else \"black\" for e in g.es]\n    )\n```\n\n    ", "Answer": "\r\nThere’s an enumeration algorithm due to Fukuda and Matsui (“Finding all the perfect matchings in bipartite graphs”), (pdf) which was improved for non-sparse graphs by Uno (“Algorithms for enumerating all perfect,\nmaximum and maximal matchings in bipartite graphs”) at the cost of more implementation complexity.\nGiven the graph G, we find a matching M (e.g., with Hopcroft–Karp) to\npass along with G to the root of a recursive enumeration procedure. On\ninput (G, M), if M is empty, then the procedure yields M. Otherwise, the\nprocedure chooses an arbitrary e ∈ M. A maximum matching in G either\ncontains e or not. To enumerate the matchings that contain e, delete e’s\nendpoints from G to obtain G′, delete e from M to obtain M′, make a\nrecursive call for (G′, M′), and add e to all of the matchings returned.\nTo enumerate the matchings that don’t contain e, delete e from G to\nobtain G′′ and look for an augmenting path with respect to (G′′, M′). If\nwe find a new maximum matching M′′ thereby, recur on (G′′, M′′).\nWith Python you can implement this procedure using generators and then\ngrab as many matchings as you like.\n```\ndef augment_bipartite_matching(g, m, u_cover=None, v_cover=None):\n    level = set(g)\n    level.difference_update(m.values())\n    u_parent = {u: None for u in level}\n    v_parent = {}\n    while level:\n        next_level = set()\n        for u in level:\n            for v in g[u]:\n                if v in v_parent:\n                    continue\n                v_parent[v] = u\n                if v not in m:\n                    while v is not None:\n                        u = v_parent[v]\n                        m[v] = u\n                        v = u_parent[u]\n                    return True\n                if m[v] not in u_parent:\n                    u_parent[m[v]] = v\n                    next_level.add(m[v])\n        level = next_level\n    if u_cover is not None:\n        u_cover.update(g)\n        u_cover.difference_update(u_parent)\n    if v_cover is not None:\n        v_cover.update(v_parent)\n    return False\n\n\ndef max_bipartite_matching_and_min_vertex_cover(g):\n    m = {}\n    u_cover = set()\n    v_cover = set()\n    while augment_bipartite_matching(g, m, u_cover, v_cover):\n        pass\n    return m, u_cover, v_cover\n\n\ndef max_bipartite_matchings(g, m):\n    if not m:\n        yield {}\n        return\n    m_prime = m.copy()\n    v, u = m_prime.popitem()\n    g_prime = {w: g[w] - {v} for w in g if w != u}\n    for m in max_bipartite_matchings(g_prime, m_prime):\n        assert v not in m\n        m[v] = u\n        yield m\n    g_prime_prime = {w: g[w] - {v} if w == u else g[w] for w in g}\n    if augment_bipartite_matching(g_prime_prime, m_prime):\n        yield from max_bipartite_matchings(g_prime_prime, m_prime)\n\n\n# Test code\n\nimport itertools\nimport random\n\n\ndef erdos_renyi_random_bipartite_graph(n_u, n_v, p):\n    return {u: {v for v in range(n_v) if random.random() < p} for u in range(n_u)}\n\n\ndef is_bipartite_matching(g, m):\n    for v, u in m.items():\n        if u not in g or v not in g[u]:\n            return False\n    return len(set(m.values())) == len(m)\n\n\ndef is_bipartite_vertex_cover(g, u_cover, v_cover):\n    for u in g:\n        if u in u_cover:\n            continue\n        for v in g[u]:\n            if v not in v_cover:\n                return False\n    return True\n\n\ndef is_max_bipartite_matching(g, m, u_cover, v_cover):\n    return (\n        is_bipartite_matching(g, m)\n        and is_bipartite_vertex_cover(g, u_cover, v_cover)\n        and len(m) == len(u_cover) + len(v_cover)\n    )\n\n\ndef brute_force_count_bipartite_matchings(g, k):\n    g_edges = [(v, u) for u in g for v in g[u]]\n    count = 0\n    for m_edges in itertools.combinations(g_edges, k):\n        m = dict(m_edges)\n        if len(m) == k and is_bipartite_matching(g, m):\n            count += 1\n    return count\n\n\ndef test():\n    g = erdos_renyi_random_bipartite_graph(7, 7, 0.35)\n    m, u_cover, v_cover = max_bipartite_matching_and_min_vertex_cover(g)\n    assert is_max_bipartite_matching(g, m, u_cover, v_cover)\n\n    count = 0\n    for m_prime in max_bipartite_matchings(g, m):\n        assert is_bipartite_matching(g, m_prime)\n        assert len(m_prime) == len(m)\n        count += 1\n    assert brute_force_count_bipartite_matchings(g, len(m)) == count\n\n\nfor i in range(100):\n    test()\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "A good approximation algorithm for the maximum weight perfect match in non-bipartite graphs?\r\n                \r\nDrake and Hougardy find a simple approximation algorithm for the maximum weighted matching problem. I think my understanding of academic papers is above my capabilities so I'm looking for an easy implementation preferable in php, c, javascript?   \n    ", "Answer": "\r\nProblem Definition and References  \n\nGiven a simple graph (undirected, no self-edges, no multi-edges) a matching\nis a subset of edges such that no two of them are incident to the same vertex.\n\nA perfect matching is one in which all vertices are incident to an edge of\nthe matching, something not possible if there are an odd number of vertices.\nMore generally we can ask for a maximum matching (largest possible number of\nedges in a matching) or for a maximal matching (a matching to which no more\nedges can be added).\n\nIf positive real \"weights\" are assigned to the edges, we can generalize the\nproblem to ask for a maximum-weighted matching, one that maximizes the\nsum of edges' weights.  The exact maximum-weighted matching problem can be\nsolved in O(nm log(n)) time, where n is the number of vertices and m the\nnumber of edges.  \n\nNote that a maximum-weighted matching need not be a perfect matching.  For\nexample:\n\n```\n*--1--*--3--*--1--*\n```\n\n\nhas only one perfect matching, whose total weight is 2, and a maximum\nweighted matching with total weight 3.  \n\nDiscussion and further references for exact and approximate solutions of\nthese, and of the minimum-weighted perfect matching problem, may be found\nin these papers:\n\n\"A Simple Approximation Algorithm for the Weighted Matching Problem\"\nDrake, Doratha E. and Hougardy, Stefan (2002)\n\nImplementation of O(nm log n) Weighted Matchings The Power of Data Structures\nMelhorn, Kurt and Schäfer, Guido (2000)\n\nComputing Minimum-Weight Perfect Matchings\nCook, William and Rohe, André (1997)\n\nApproximating Maximum Weight Matching in Near-linear Time\nDuan, Ran and Pettie, Seth (2010)\n\nDrake and Hougardy's Simple Approximation Algorithm  \n\nThe first approximation algorithm of Drake-Hougardy uses the idea\nof growing paths using the locally heaviest edge at each vertex met.  It\nhas a \"performance ratio\" of 1/2 like the greedy algorithm, but linear\ntime complexity in the number of edges (the greedy algorithm uses\na globally heaviest edge and incurs greater time complexity to find that).\n\nThe main implementation task is to identify data structures that support\nthe steps of their algorithm efficiently.\n\nThe idea of the PathGrowing algorithm:  \n\n```\nGiven: a simple undirected graph G with weighted edges\n\n(0) Define two sets of edges L and R, initially empty.\n(1) While the set of edges of G is not empty, do:\n(2)    Choose arbitrary vertex v to which an edge is incident.\n(3)    While v has incident edges, do:\n(4)        Choose heaviest edge {u,v} incident to v.\n(5)        Add edge {u,v} to L or R in alternating fashion.\n(6)        Remove vertex v (and its incident edges) from G.\n(7)        Let u take the role of v.\n(8)    Repeat 3.\n(9) Repeat 1.\n\nReturn L or R, whichever has the greater total weight.\n```\n\n\nData structures to represent the graph and the output\n\nAs a \"set\" is not in any immediate sense a data structure of C, we\nneed to decide what kinds of container for edges and vertices will\nsuit this algorithm.  The critical operations are removing vertices\nand incident edges in a way that allows us to find if any edges are\nleft and to compare weights of the remaining edges incident to a\ngiven vertex.\n\nThe edges need to be searchable, but only to see if any is still left.\nOne thinks first of a simple linked list of edges, without any special\nordering.  But this list also needs to be maintained through essentially\nrandom deletions.  This suggests a doubly-linked list (back links as\nwell as forward at each node), so that deletion of an edge may be done\nby fixing up the links to skip over any \"removed\" node.  Edge weights\ncan also be stored in this same structure.\n\nFurther we need the ability to scan all (remaining) edges incident to\na given vertex.  We can do this by creating a linked list for each vertex\nof (pointers to) incident edges.  I will assume that the vertices have\nbeen preprocessed to ordinal values that can be used as an index into\nan array of pointers to these linked lists.\n\nFinally we need to represent the edge sets L and R, one of which is to\nbe returned as the approximate maximum matching.  Our requirements\nare to be able to add edges to either set, and to be able to total the\nedge weights for both of them.  Linked lists with dynamically allocated\nnodes can serve this purpose, perhaps storing pointers to the edge nodes\nin the original doubly-linked lists as the weight attribute will still\npersist there even after an edge becomes \"removed\" by link manipulation.\n\nSuch linked and doubly-linked lists can be created in time proportional\nto the number of edges, since the doubly-linked list entries may be\nallocated to vertex-specific links on input.  With such a design in\nmind we can analyze the effort required by each step of the algorithm.\n\n(to be continued)\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Combine dendrogram with bipartite graphs in R (tanglegram)\r\n                \r\nI am currently working on creating a tanglegram where species reared are on one side and substrate reared on is on the other side. However, I need the output to also be a tanglegram, having each side of the chart be the tips of a dendogram. I currently have phylogenies of both the species and substrates in Newick formats. \n\nI successfully used the 'ape' package and the ```\nplot.phylo()```\n function to generate the 2 phylogenies. I then used the following code from this post to export the order of tips:\n\n```\ntree <- ladderize(tree, right = FALSE)\nis_tip <- tree$edge[,2] <= length(tree$tip.label)\nordered_tips <- tree$edge[is_tip, 2]\nx<-tree$tip.label[ordered_tips]\nwrite.csv(x,file=\"test.csv\",sep =\"\\t\")\n```\n\n\nI then used the order of the tips to generate a matrix for use in the 'bipartite' package.\n\nHowever, of course, the spacing on the bipartite graph doesn't match up with the spacing on the dengdrograms, so I can't just copy/paste them next to one another in an outside image manipulation program. I am wondering if there is a way that I can generate a chart that combines the dendrograms and bipartite graph to make a tanglegram in rstudio? \n\nHere is a simplified visual example of what I am hoping to do:\n\nI am looking to combine 2 phylogenetic trees that, for example, look like this\n\n```\ntree1<-read.tree(text=\"((C,B),A);\")\nplot(tree1)\n```\n\n\nOutput: tree1\n\n```\ntree2<-read.tree(text=\"((G,F),(E,D));\")\nplot(tree2)\n```\n\n\nOutput: tree2\n\nWith a bipartite graph\n\n```\nweb = matrix(\nc(0, 5, 0, 10, 10, 0, 0, 3, 0, 0, 0, 1),\nnrow=4,\nncol=3,\nbyrow = TRUE,\ndimnames = list(c(\"D\",\"E\",\"F\",\"G\"),c(\"A\",\"B\",\"C\"))) \nplotweb(web,method=\"normal\",empty=\"false\",text.rot=\"90\")\n```\n\n\nOutput: bipartite plot\n\nTo instead generate a plot that looks like this (I just did the following in an image editor, the expansive dataset I am actually using is far larger)\n\nDesired output: tanglegram\n    ", "Answer": "\r\nA way to draw a tanglegram with trees where the tip labels do not match is to use an association matrix - a matrix that lists corresponding taxa in the respective trees. Using the provided data, the following code will extract the names from columns and rows and the respective weight.\n\n```\n assoc = data.frame()\n temp = matrix(NA, ncol = 3, nrow = ncol(web))\n\n for(i in 1:nrow(web)){\n     for(j in 1:ncol(web)){\n         temp[j,] = c(rownames(web)[i], colnames(web)[j], web[i,j])\n     }\n     assoc = rbind(assoc, temp)\n }\nhead(assoc)\n  V1 V2 V3\n 1  D  A  0\n 2  D  B  5\n 3  D  C  0\n 4  E  A 10\n 5  E  B 10\n```\n\n\nThe last column can be used to set weight of the connecting lines between taxa.\n\n```\nlibrary(ape)\ncophyloplot(tree2, tree1, assoc[,1:2], lwd = as.numeric(as.character(assoc[,3])), space = 15)\n```\n\n\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum median weight matching\r\n                \r\nFinding a maximum total weight matching for a graph is a well studied problem.\n\nIs there any name and/or well defined algorithm for finding a maximal matching that maximizes its median weight instead ? (generalized to any other percentile).\n\nThis problem got me when looking into matters of fairness of assignments.\n\nMy lines of thought for possible solutions:\n\n\nPerhaps the weights can be somehow mapped to use the maximum total weight matching algorithm ? I find this unlikely\nPerhaps the maximum weight matching algorithm can be used repeteadly on different subgraphs in some fashion ?\nSolving the problem as an assignment problem using integer programming. But I wouldn't know how to express the median of the weights of the chosen set.\n\n\nIn the case of bipartite graphs, this paper offers ways to find all maximal, maximum and perfect matchings. Then, if problem size allows, we can choose the matching with the desired properties with any kind of cost function.\n\nBut I'm interested in the non-bipartite case. So, of course a biproduct of this question is: Do you know any implementation/algorithm that enumerates all maximal matchings of a graph ?\n    ", "Answer": "\r\nSuppose first of all that I know the maximum median possible. If I set all weights above or equal to the median value to 1 and all other weights to zero then there is an answer for which at least 1/2 the weights used by the matching are 1 - this is the one produced by taking the maximum median weight matching. If I retrieve that, fine. If I retrieve some other matching it must have at least this many 1s. Each 1 corresponds to a weight of at least the maximum median value, so on the original graph it has a median weight of at least the maximum possible, so it must be equivalent to the maximum.\n\nIf I now try guessing the maximum median and guess too high I must then find that the maximum matching produced has less than 1/2 the weights set equal to 1. If I guess too low, I will find that at least 1/2 the weights are set equal to 1, because I can achieve this using the matching for the correct maximal median.\n\nSo I can binary chop on the guessed maximum median, looking for the highest value that still allows me to retrieve 1/2 of weights that I set equal to 1, and this gets me the matching with maximum median weight.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite selection with associated vertex cost\r\n                \r\nI think I'm looking for an algorithm that can find a \"minimum\" \"selection\" in a bipartite graph. Each vertex has an associated (integer) cost to selecting it. I can only find algorithms that minimise the number of vertices in the selected set, not the cost. I'd previously thought I need a \"matching\", but actually I just need the subset of vertices that cover every edge...\n\nI don't think a greedy solution can work. Suppose our sets are A, B:\n\nVertices 1,2,3 are in A and have cost 1.\nVertex 4 is in B and has cost 2.\n\nThe solution is to remove the most expensive vertex, 4. A greedy solution that chose based on cost would fail. Similarly, if B had cost 10, we could not choose the most connected vertex greedily.\n\nI thought of a different wording: \"Given a bipartite graph where each vertex has an associated cost, find a subset of vertices of minimum cost such that every edge is incident on at least one vertex in your selected subset\".\n    ", "Answer": "\r\nPrimal LP:\n\n```\nmin sum_v c_v x_v\ns.t.\nforall e=vw. x_v + x_w >= 1\nforall v. x_v >= 0\n```\n\n\nDual LP:\n\n```\nmax sum_e y_e\ns.t.\nforall v. sum_{e=vw} y_e <= c_v\nforall e. y_e >= 0\n```\n\n\n\nFind a min cut where the edges are arcs from A to B with infinite capacity, the vertices in A are sources, and the vertices in B are sinks, with all vertices having capacity equal to their cost. (Equivalently, make a supersource with arcs to A and a supersink with arcs from B.) \nTake the As that are on the \"sink\" side of the cut and the Bs that are on the \"source\" side. Every edge vw is covered because if neither v nor w belonged to the cover then vw would be residual.\n\n\nHat tip I think to Jenő Egerváry.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Why Gale Shapley matching algorithm third iteration is not executing?\r\n                \r\nI am executing the following code of Gale Shapley matching algorithm in python, first two iteration are working fine but third iteration system stuck in loop. Kindly help to identify and resolve the issue\n\nLibraries\n```\nimport networkx as nx\nimport matplotlib.pyplot as plt\n```\n\nExample preference lists for 3 men and 3 women\n```\nmen_prefs = {\n    'm1': ['w2', 'w1', 'w3'],\n    'm2': ['w1', 'w2', 'w3'],\n    'm3': ['w1', 'w3', 'w2']\n}\nwomen_prefs = {\n    'w1': ['m3', 'm1', 'm2'],\n    'w2': ['m2', 'm1', 'm3'],\n    'w3': ['m1', 'm3', 'm2']\n}\n```\n\nCreate the bipartite graph\n```\nB = nx.Graph()\nB.add_nodes_from(men_prefs.keys(), bipartite=0)\nB.add_nodes_from(women_prefs.keys(), bipartite=1)\nfor man, prefs in men_prefs.items():\nfor woman in prefs:\nB.add_edge(man, woman)\n```\n\nRun the Gale-Shapley algorithm\n```\nfree_men = set(men_prefs.keys())\nengaged = {}\nwhile free_men:\n    man = free_men.pop()\n    woman = men_prefs[man][0]\n    if woman in engaged:\n        current_man = engaged[woman]\n        if women_prefs[woman].index(man) < women_prefs[woman].index(current_man):\n            engaged[woman] = man\n            free_men.add(current_man)\n        else:\n            free_men.add(man)\n    else:\n        engaged[woman] = man\n```\n\nDraw the graph with the new matching\n```\npos = nx.bipartite_layout(B, men_prefs.keys())\nplt.figure(figsize=(6, 4))\nnx.draw_networkx_nodes(B, pos, node_color=['lightblue'])\nnx.draw_networkx_edges(B, pos, edgelist=engaged.items(), edge_color='red', width=2)\nnx.draw_networkx_labels(B, pos, font_size=12, font_family='sans-serif')\nplt.axis('off')\nplt.show()\n```\n\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Matching algorithm to find an suitable place in a grid\r\n                \r\nI'm trying to solve a task from a programming challenge and it should be really easy with a matching algorithm but I'm pretty lost how it should be transfered in a graph.\nIt should be probably based on max-min-flow or maximum bipartit matching.\nCould anybody give me a little hint on how to solve this or how to transfer the input in a graph? Thanks in advance!\n\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to create \"type\" attribute for bipartite graph with igraph inR\r\n                \r\ni have a two-mode network edgelist data like ```\ntmp```\n below:\n\n```\ntmp <- read.table(text=\"PersonID CompanyID\nP1 C000001\nP2 C000001\nP3 C000001\nP4 C000001\nP5 C000001\nP6 C000002\nP7 C000002\nP8 C000002\nP9 C000003\nP10 C000003\nP11 C000003\nP12 C000003\",header=TRUE)\n\n# make a graph using this data\nel <- graph.edgelist(as.matrix(tmp))\n```\n\n\nAnd I did this to add \"type\" attribute to create a bipartite graph in igraph\n\n```\nV(el)$type <- V(el)$name %in% el[,1]\n```\n\n\nBut it turned that the type is all \"false\" and the names can't match. Does anyone know what's going wrong here? \n\n```\n> table(V(el)$type)\nFALSE \n   15 \n\n> V(el)$name\n [1] \"P1\"      \"C000001\" \"P2\"      \"P3\"      \"P4\"    \"P5\"    \"P6\"    \"C000002\"\n [9] \"P7\"      \"P8\"      \"P9\"      \"C000003\" \"P10\"   \"P11\"   \"P12\"  \n```\n\n    ", "Answer": "\r\nInstead of ```\nel[,1]```\n, use ```\nget.edgelist(el)[,1]```\n. ```\nel[,1]```\n is not the first column of the edge list as you may have expected; indexing a graph object like you did will in fact give you slices of the adjacency matrix instead.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Size of Special Vertex Set on DAG\r\n                \r\nIn Singapore, this year's (2016) NOI (National Olympiad in Informatics) included the following problem \"ROCKCLIMBING\" (I was unable to solve it during the contest.) :\n\nAbridged Problem Statement\n\nGiven a DAG with ```\nN <= 500```\n vertices, find the maximum number of vertices in a subset of the original vertices such that there is no path from 1 vertex in the set to another vertex in the same set, directly or indirectly.\n\nSolution\n\nThe solution was to use transitive closure algorithm, and then to form a bipartite graph by duplicating each vertex ```\ni```\n to form ```\ni'```\n such that if vertex ```\nj```\n can be reached from vertex ```\ni```\n directly or indirectly in the original graph, then there is a directed edge from ```\ni```\n to ```\nj'```\n in the new graph.\n\nHowever, during the solution presentation, the presenters did not explain how or why ```\nN - MCBM```\n (MCBM being the Maximum Cardinality Bipartite Matching) of the new bipartite graph is also the maximum size of the set of vertices that cannot reach each other directly or indirectly in the original DAG. \n\nI looked up other problems related to DAGs and bipartite graphs, such as the Minimum Path Cover problem on DAGs, but I could not find anything that explains this.\n\nDoes anyone know a way in which to prove this equality?\n\nThe problem statement can be found here: ROCKCLIMBING\n\nThank you in advance.\n    ", "Answer": "\r\nThere are two things going on here:\n\n\nA set is independent if and only if its complement is a vertex cover (see wikipedia).  This means that the size of a max independent set is equal to the size of a minimum vertex cover.\nKonig's theorem proves that \n\n\n\n  In any bipartite graph, the number of edges in a maximum matching equals the number of vertices in a minimum vertex cover.\n\n\nTherefore to find the size of the max independent set we first compute the size MCBM of the max matching, and then compute its complement which equals ```\nN-MCBM```\n.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "\"(1:k) Tree-Matching\" - Solvable in polynomial time?\r\n                \r\nSome months ago there was a nice question regarding a \"1:n matching problem\" and there seems to be no poly-time algorithm. \n\nI would like to add constraints to find a maximum matching for the 1:n matching problem with a polynomial algorithm. I would like to say: \"For vertex A1 choose either {B1,B2,B5} or {B2,B3} if the vertices are not already taken from another A-vertex\" i.e. I would not allow all possible combinations.\n\nThis could be expressed if we introduce helper vertices H for each choice and substitute edges with trees => we get a problem similar to the ordinary bipartite matching. Every vertex of A or B can have only one edge in the matching. The edges to or from vertices in H are either all in the matching or none of them is present in the matching. Imagine the following tri-partite graph:\n\n\n\nNow define h_ij=\"tree rooted that contains H_ij\" to express the matching easily:\n\n\nThen in the example M={h12,h22} would be one 'maximum' matching, although not all vertices from B are involved\nThe set {h12,h23} is not a matching because then B3 would have be choosen twice.\n\n\nWould this problem then be solvable in polynomial time? If yes, is there a polytime solution for the weighted (w(h_ij)) variant? If no, could you argue or even proof it for a \"simple-man\" like me or suggest other constraints to solve the 1:n matching problem?\n\nE.g. could the graph transformed to a general graph which then could be solved with the weighted matching for general graphs? Or could branchings or even matching forests help here?\n\nPS: not a homework ;-) \n    ", "Answer": "\r\nThere is a difference between maximal and maximum. I have assumed you meant maximum for the below writeup.\n\nYou don't seem to have defined your problem very clearly, but if I have understood your intent correctly,  It seems like your problem is NP complete (and 'equivalent' to Set Packing).\n\nWe can assume that the allowed sets sizes is the same (k) for all A_i to find a [1:k] matching, as any other set size can be ignored. To find max k, we just run the algorithm for [1:k] for k = 1,2,3.. etc.\n\nSo your problem is (I think...):\n\nGiven m set families ```\nF_i = {S_1i, .., S_n(i)i}```\n (|F_i| = size of F_i = n(i), need not be same as |F_j|), each set of size k, you have to find one set from each family (say S_i) such that\n\n\nS_i and S_j are disjoint for any i neq j.\nnumber of  S_i's is maximum.\n\n\nWe can show that it is NP-Complete for k=3 in two steps:\n\n\nThe NP-Complete problem Set Packing can be reduced it. This shows that it is NP-Hard.\nYour problem is in NP and can be reduced to Set Packing. This and 1) implies your problem is NP-Complete. It also helps you leverage any approximation/randomized algorithms already existing for Set-Packing.\n\n\nSet Packing is the problem:\n\nGiven n sets S_1, S_2, ..., S_n, find the maximum number of pairwise disjoint sets among these. \n\nThis problem remains NP-Complete even if |S_1| = |S_2| = ... = |S_n| = 3 and is called the 3-Set packing problem.\n\nWe will use this to show that your problem is NP-Hard, by providing an easy reduction from 3-Set packing to your problem.\n\nGiven S_1, S_2, .., S_n  just form the families\n\nF_i = {S_i}.\n\nNow if your problem had a polynomial time solution, then we get a set of Sets {S_1, S_2, ..., S_r} such that\n\n\nS_i and S_j are disjoint\nNumber of S_i is maximum.\n\n\nThis easy reduction gives us a solution to the 3-set Packing problem and thus your problem is NP-Hard.\n\nTo see that this problem is in NP, we reduce it to Set-Packing as follows:\n\nGiven F_i = {S_1i, S_2i, ..., S_ni}\n\nwe consider the sets T_ji = S_ji U {i} (i.e. we add an id of the family into the set itself) and run them through the Set-Packing algorithm. I will leave it to you to see why a solution to Set-Packing gives a solution to your problem.\n\n\n\nFor a maximal solution, all you need is a greedy algorithm. Just keep picking up sets till you can pick no more. This would be polynomial time.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartite seating arrangement on round tables\r\n                \r\nImagine we have two groups, women and men. Each women has a set of men they are interested. We represent their interest as edges in a bipartite graph.\n\nNow, we are trying to set up everyone in round tables, such as if you go around the table, each seat will pair of seats will be occupied by a couple with a connection. So, if you go clockwise around the table, for example, a seat may have a woman that is interested on a man seating on the next seat, and this may will also be the interest of the woman sitting on the next seat, and so forth. Each table needs to have at least a number k of guests.\n\nI am trying to design an algorithm using max flow to satisfy those requirements and I would really appreciate some ideas\n    ", "Answer": "\r\nThis problem is in general NP-hard. Imagine that you have a graph with 2n nodes and that you only have one table of size 2n. Now, there's a way to seat everybody around the table in the way you'd like if and only if the graph has a Hamiltonian cycle. Since the Hamiltonian cycle problem on bipartite graphs is NP-hard, your problem is NP-hard as well. As a result, I doubt there's a nice way to use max-flow to solve this particular problem unless you build an exponentially-large graph.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Creating a Bipartite Graph that extends Graph class. Need some guidance\r\n                \r\nLooking for a step in the right direction. I have with me 4 classes that I have made. One is the super class which is graph and 3 subclasses called Edge, DirectedGraph, and BipartiteGraph.\n\nI am having some trouble with creating a bipartite graph. Specifically I am given these directions:\n\n\n  Extend the Graph class to create a new BipartiteGraph class. It should\n  inherit all the functionality of the super class:\n  \n  \n  Automatically designate all even-index vertices (0,2,4) as part of\n  the \"A partition\" from class and all odd-index vertices (1,3,5) as\n  part of the \"B partition\". This requires no new code, just a\n  conceptual expectation.\n  Override the constructor for Graph to have the same input (number of vertices), call the super constructor, and then verify the graph is bipartite. That is, make sure that all existing edges are from a vertex in A to a vertex in B. If the graph is not bipartite, wipe out the internal representation (e.g., for an adjacency matrix, make a size 0x0 array) so it cannot be used!\n  Add a method setPreferences() that takes as a parameter an integer and an array or ArrayList of integers. The first integer is the vertex we want to attach preferences to and the list is that list of preferences, from most to least preferred. Verify that the array of ints contains all the members of the other partition in some order then save that information (you will need a 1-D array of arrays/ArrayLists to store these lists, one per vertex).\n  Add the method stableMatching that has no parameters and returns a stable matching (in the form of an ArrayList of Pairs of ints). It will be helpful to consult Wikipedia: http://en.wikipedia.org/wiki/Stable_marriage_problem . As a start, I suggest verifying that each vertex has a preference list set for it!\n  \n\n\nHere is my constructor in the super class:\n\n```\npublic class Graph {\n\n// Setup privately modified variables which will define the graph\n\n// These two parameters are storage variables for edges and vertices\n// These variables were changed from Vertex and Edge to numVertices and\n// numEdges.\nprivate int numVertices;\nprivate int numEdges;\n\n// This will be the adjacency matrix to represent our graph, this will\n// represent edges.\n// adj_Matrix_Edges was previously static meaning it did not have access to\n// multiple graphs, onyl one graph.\nprotected boolean[][] adj_Matrix_Edges;\n\n// first step will be to setup the graph, using this constructor\npublic Graph(int vertices) {\n\n    numVertices = vertices;\n\n    if (numVertices < 0) {\n        throw new RuntimeException(\n                \"Number of vertices cannot be a nonnegative value\");\n    }\n\n    System.out.println(\"There are now \" + numVertices\n            + \" vertices in the graph.\");\n\n    // A graph is created based on the specifications, N X N or (n^2)\n    // graph.\n    adj_Matrix_Edges = new boolean[vertices][vertices];\n    }\n```\n\n\nAnd here is what I have so far for the BipartiteGraph class:\n\n```\n    public class BipartiteGraph extends Graph{\n\n//Initialize two partitions for bipartite graph.\nboolean[][] a;\nboolean[][] b;\n\n\n//Constructor of BipartiteGraph class\npublic BipartiteGraph(int vertices) {\n    super(vertices);\n\n    //Copy over even elements of graph into partition A.\n    for (int i = 0; i < adj_Matrix_Edges.length; i++){\n        for (int j = 0; j < adj_Matrix_Edges[i].length; j++){\n            if (j%2 == 0){\n                adj_Matrix_Edges[j] = a[j];\n            }\n        }\n    }\n\n    //Copy over odd elements of graph into Partition B.\n    for (int i = 0; i < adj_Matrix_Edges.length; i++){\n        for (int j = 0; j < adj_Matrix_Edges[i].length; j++){\n            if (j%2 != 0){\n                adj_Matrix_Edges[j] = b[j];\n            }\n        }\n    }\n\n}\n\n\npublic void setPreferences(int vertex, int[] preferences){\n\n    if ()\n\n}\n\npublic List stableMatching(){\n    java.util.List<Integer> matching = new ArrayList<Integer>();\n\n\n}\n```\n\n\nAm I making things too complicated, is the code simpler than it seems?\n    ", "Answer": "\r\nI think there is a mistake in the declaration of ```\nBipartiteGraph```\n:\n\n```\npublic class BipartiteGraph extends Graph{\n\nboolean[][] a;\nboolean[][] b;\n```\n\n\nYou declare ```\na```\n and ```\nb```\n as two dimensional arrays that is as matrices. ```\na```\n and ```\nb```\n models complementary subsets of the set of vertices. Therefore, they should be either a list of vertices or an array of boolean which says if the ith vertex is in ```\na```\n. Also you don't need to store both since one is the complementary to the other. \n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "max-flow non-bipartie graph matching\r\n                \r\nI have learned the algorithm for application of max-flow to find maximum matching in bipartite graph. just add s connected to all nodes in L, and t connected to all nodes in R. Then connect nodes in L to those in R with weight all be 1.\n\nBut I am wondering , Why it does not work for non-bipartie graph?\n\nWe could repeat nodes V as V' connect v\\in V->v' \\in V' if (v,v') \\in E.\n\ns- V - V' - t\n\nthen max-flow is 2times the maximum matching?\n\nIt is right? what is wrong with it?\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Find bipartite graph vertex cover with a Very Important Vertex\r\n                \r\nI know that I can find the minimum vertex cover of a bipartite graph by first finding the maximum matching and then using Konig's Theorem to turn this matching into a vertex cover of the same order.  \n\nHowever, the result obtained is only one of what could be many valid vertex covers. In the following graph, {A,B}, {C,D}, and {B,C} are all valid covers. Applying the Konig method yields the cover {A,B}.\n\n```\n(A)=====(C)\n       /\n     /\n   /\n(B)=====(D)\n```\n\n\nHow would you check for the existence of a minimum vertex cover that includes a given important vertex, say, vertex D?\n\nMy first guess is to flip the graph and find another minimum vertex cover. In the above case, this would yield {C,D}. If neither solution contains the important vertex, it's not part of any minimum cover.  However, I haven't thought deeply enough to really prove this to myself.\n    ", "Answer": "\r\nI would suggest the following method \n\n\nFind the size of the minimum vertex cover (Let a vertex cover be $C$ )\nRemove the \"Very Important Vertex\" and all the edges covered by the same (Vertex be $v$)\nRepeat the process and let the new vertex cover be $C'$\n\n\nIf $|C' + V| = |C|$ then report the minimum vertex cover else report no minimum vertex cover exists with the given vertex. \n\nI guess you have the same answer the proof is also along the same lines.\n\nThe new vertex cover cannot be smaller since it would violate the condition that $C$ was one of the minimum vertex cover. \n\nAlso $C'$ is the minimum cover covering the rest of the graph. \n\nIf there is atleast one minimum vertex cover including the vertex $V$ then the rest of the vertices in that set would cover all the vertices except the ones adjacent to $V$, but then it would mean that $|C'|$ is not larger than $|C|-1$ hence a faliure to do this would imply no minimum vertex cover exists including the VIP edge. \n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "unique maximum matching\r\n                \r\nI am trying to use bipartite graph to code my program with following properties:\n\n\nin each side, there is N vertices\nthe graph is connected\n\n\nNow, I wanna add a condition in my code which check if the number of edges is bigger than M, do not allow user to more activities(in a simple sentence print something in that condition) where M is maximum number edges such that it still has a unique maximum matching.\n\nThe question is how can I find M?\n\nAny idea will be appreciated\nThanks\n    ", "Answer": "\r\nif you mean to find maximum m such that there is at least one graph with n vertices and m edges with a unique maximum matching, the answer is (n + 1) * n / 2.\n\nto show that there is at least one graph with this number of edge, consider a graph with vertices x1, x2, .., xn in one part and vertices y1, .. yn in another part. draw an edge between vertex xi and yj iff (i <= j).\n\nto show there can be no more edges, use induction on the number of vertices. first of all we can show if every vertex in the graph is connected to at least two vertex, the graph has at least two different maximum matching. (consider one maximum matching, follow a path from a vertex whose edges alternates between matching edges and non-matching edges, make a circle and reverse all the edges.)\n\nso we know there is one vertex with degree equal to one. remove this vertex and it's neighbor and use induction on the remaining graph.\n\nsorry for bad English.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Find a maximum matching\r\n                \r\n\n  Let ```\nG(A,B,V)```\n, a bipartite graph where ```\n|A|=|B|=n```\n. There's a matching, ```\nM```\n subset of ```\nE```\n where ```\n|M| = n-2013```\n. Describe an efficient algorithm to determine if a maximal matching exists.\n\n\nBasically the given solution is building a flow-network from the graph, by adding ```\ns,t```\n vertices, connecting ```\ns```\n to each vertex ```\nv```\n in ```\nA```\n and each vertex ```\nv```\n in ```\nB```\n to ```\nt```\n. All capacities are ```\n1```\n.\n\nNow, we give a starting flow for all edges ```\nM```\n (And all edges connected to edges of ```\nM```\n, from ```\ns```\n and to ```\nt```\n)\n\nNow we just need to run Fold-Falkerson (or Edmond-Karp) Algorithm and check if we were able to improve ```\n2013```\n paths (i.e. adding more flow for some path). More precisely, we need, at most, to run BFS, ```\n2013```\n  times to decide\n\nMy question is:\nWhy does it work? As I see it, ```\nM```\n is just an arbitrary match. It's like we are assuming that ```\nM```\n is part of a maximal-matching.\n\nI'd be glad for a clarification!\n\nThanks\n    ", "Answer": "\r\nIIUC, the algorithms is this:\n\n\nCreate the flow network s → A → B → t\nOn this network, calculate the flow induced by M.\nNow create the residual flow graph, and continue Edmonds-Karp from here.\n\n\nWhy does this work? The Ford-Fulkerson method guarantees that, given any valid flow (in particular, in this case the one given by M, while the maximal flow is not yet achieved, there is an augmenting path in the residual network. Here, each augmentation increases the flow (and hence the matching) by 1. Hence, if the maximal flow is q, then within q - |M| iterations, it will be achieved.\n\nThe point which seems to confuse you is that it seems that the optimal matching necessarily includes M. This is not the case. Augmentation along the residual network can actually cancel flows in the original network. Hence, the augmentations can actually \"reverse\" some of the matchings of M.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum Independent Set Algorithm\r\n                \r\nI don't believe there exists an algorithm for finding the maximum independent vertex set in a bipartite graph other than the brute force method of finding the maximum among all possible independent sets.\n\nI am wondering about the pseudocode to find all possible vertex sets.\n\nSay given a bipartite graph with 4 blue vertices and 4 red. Currently I would \n\n```\nStart with an arbitrary blue,\n  find all red that don't match this blue\n  put all these red in Independent Set\n  find all blue that dont match these red\n  put these blue in Independent Set\n  Repeat for next vertex in blue\n\nRepeat all over again for all blue then all vertices in red.\n```\n\n\nI understand that this way doesn't give me all possible Independent Set combinations at all, since after the first step I am choosing all of the next colour vertices that dont match rather than stepping through every possiblity.\n\nFor example given a graph with the matching\n\n```\nB  R\n1  1\n1  3 \n2  1\n2  3\n3  1\n3  3\n4  2\n4  4\n\nStart with blue 1\n  Choose red 2 and 4 since they dont match\n  Add 2, 4 to independent Set\n  Choose 2 and 3 from blue since they dont with 2 or 4 from red\n  Add 2 and 3 from blue to independent set as well.\nIndependent Set = 1,2,3 from blue 2,4 from red\nRepeat for blue 2, blue 3, ... red n (storing the cardinality for each set)\n```\n\n\nIs there a way I can improve this algorithm to better search for all possibilities. I know that a |Maximum Set for a bipartite graph| = |Red| + |Blue| - |Maximum Matching|.\n\nThe problem arises with the possibility that by choosing all possible red in the first go for a given blue, if those red connect to all other possible blue then my set only ever has all 1 blue and rest red.\n    ", "Answer": "\r\n\n  I don't believe there exists an algorithm for finding the maximum independent vertex set in a bipartite graph other than the brute force method of finding the maximum among all possible independent sets.\n\n\nThere is: finding the maximum independent set is equivalent to finding the minimum vertex cover (by taking complement of the result), and Konig's theorem states that minimum vertex cover in bipartite graphs is equivalent to maximum matching, and that that can be found in polynomial time. I don't know about finding all matchings, but it seems there can be exponentially many.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Find a perfect matching or proof that it's impossible [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs to be more focused. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI have to either give a tiling of the figure below by dominoes, or give a proof that it is impossible.\n\n\nI think to achieve this I have to find a perfect matching of the asociated graph of the figure (every space is a node of the graph and they are connected by edges in the vertical and horizontal way). So the graph is undirected and not bipartite. The number of nodes is 42, so could be possible due to there are an even number of nodes, but I think it's not possible. I thought about the definition that a graph has a perfect matching iff ```\n|V|=2·v(G)```\n (where ```\nv(G)```\n is the matching number of the graph).\n\nCould you help me to find the tiling if it's exists or continue the proof that it's not possible?\n    ", "Answer": "\r\nAccording to Hall's matching theorem, if you choose any subset from one \"part\" of bipartite graph and the number of vertices adjacent to vertices of this subset is smaller than the subset size, there is no perfect matching. \n\nIf we choose 11 green tiles as shown below, we get only 10 adjacent tiles for them. Which means there is no perfect matching and you cannot cover the figure by dominoes.\n\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How can I get the antichain elements in SPOJ-DIVREL?\r\n                \r\nProblem: http://www.spoj.com/problems/DIVREL\n\nIn question, we just need to find the maximum number of elements which are not multiples (a divisible by b form) from a set of elements given. If we just make an edge from an element to its multiple and construct a graph it will be a DAG.\n\nNow the question just changes to finding the minimum number of chains which contain all the vertices which equals the antichain cardinality using Dilworth's theorem as it is a partially ordered set.\n\nMinimum chains can be found using bipartite matching (How: It is minimum path cover) but now I am unable to find the antichain elements themselves?\n    ", "Answer": "\r\nTo compute the antichain you can:\n\n\nCompute the maximum bipartite matching (e.g. with a maximum flow algorithm) on a new bipartite graph D which has an edge from LHS a to  RHS b if and only if a divides b.\nUse the matching to compute a minimal vertex cover (e.g. with the algorithm described in the proof of Konig's theorem\nThe antichain is given by all vertices not in the vertex cover\n\n\nThere cannot be an edge between two such elements as otherwise we would have discovered an edge that is not covered by a vertex cover resulting in a contradiction.\n\nThe algorithm to find the min vertex cover is (from the link above):\n\n\nLet S0 consist of all vertices unmatched by M. \nFor integer j ≥ 0, let S(2j+1) be the set of all vertices v such that v is adjacent via some edge in E \\ M to a vertex in S(2j) and v has not been included in any\npreviously-defined set Sk, where k < 2j+1. If there is no such vertex,\nbut there remain vertices not included in any previously-defined set\nSk, arbitrarily choose one of these and let S(2j+1) consist of that\nsingle vertex. \nFor integer j ≥ 1, let S(2j) be the set of all vertices u\nsuch that u is adjacent via some edge in M to a vertex in S(2j−1). Note\nthat for each v in S(2j−1) there is a vertex u to which it is matched\nsince otherwise v would have been in S0. Therefore M sets up a\none-to-one correspondence between the vertices of S(2j−1) and the\nvertices of S(2j).\n\n\nThe union of the odd indexed subsets is the vertex cover.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "bipartite graph and dynamic programming\r\n                \r\nI am solving a problem, which has a weighted complete bipartite graph(X,Y,XxY), where X has n nodes and Y has m nodes and n is less than m. I want to have a perfect cross free matching graph, such that no two edges cross while matching set X to set Y and all the nodes in X are taken at the end.The sum of weights of the resulting graph should be minimal, I need to devise a dynammic programming algorithm. This is how I thought of it:\n\nnodes in X and Y are arranged x0, xi can have a horizontal edge to Y0,Yi and so on, but Y has more nodes than X.\nFor every node in X (i) I consider two options either horizontal neighbor which is j in set Y, or diagonal neighbors (i, j-1), (i,j+1) and choose the edge which minimizes the cost.and I keep track of the nodes in X and Y that are already taken.time complexity O(nm)\n\nIs there a better way I can implement this. Any help is appreciated. This is a question I got in my midterm but I left it in choice.\n    ", "Answer": "\r\nLet ```\nw(x, y)```\n be edge weight between nodes ```\nx```\n in ```\nX```\n and ```\ny```\n in ```\nY```\n, and let ```\nM(i, j)```\n be solution (minimum cross free matching graph) for vertices ```\n{x_0, x_1, ..., x_i} subset X```\n and ```\n{y_0, y_1, ..., y_j} subset Y```\n, where ```\ni < |X|```\n and ```\nj < |Y|```\n.\n\nE.g. ```\nM(0, j) = min( w(x_0, y_a) ) for 0 <= a <= j```\n. ```\nM(i, i-1) = infinity```\n since there is no matching when 'right' set is smaller.\n\nFor ```\ni, j```\n there are two possibilities: ```\nx_i```\n is connected to ```\ny_j```\n or not. Because of that recursion holds:\n\n```\nM(i, j) = min( w(i,j) + M(i-1, j-1), M(i, j-1) )\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "edge weight of bipartite graph\r\n                \r\nI have difficulties in understanding certain logic. I have a bi-partite graph as below. \n\n\n\nI wish to find the optimal match for all the vertices in left side (Viz,A1,A2,A3,A4). I got a suggestion from my friend that the summation of edge weight can be used to solve this problem. However, I am not sure, how summation of edge weight will help in this case. For example, for A1 I can say AL2 is the best match and so on. However, my friend suggested that edge weight is much more optimal solution to this problem. I am not able to understand how it can be a optimal solution. His idea was that, all of (A1,A2,A3,A4) will be connected to all of (AL1,AL2,..,AL6) and for each edge we will calculate the summation of edge weights. Can someone please help me understand what he actually means?\n\nEDIT: I think this might not be a case of perfect matching in bipartite graphs as the nodes in left side should equal the nodes in the right side. \n    ", "Answer": "\r\nA maximum weighted bipartite matching can be efficiently computed in polynomial time using a max-flow algorithm, which is a special case of a linear program. There are several relationships between bipartite matchings, max-flow, and linear programs, but the Hopkroft-Karp algorithm is the most concise expression of an algorithm for solving this specific problem.\n\nMaximum matchings for non-bipartite graphs can also be computed efficiently.\n\n(All the algorithms above have weighted versions.)\n\nEDIT: It was unclear from your comments whether you have a slightly different problem. If there can be a one-to-many mapping from left to right, but right nodes can only map to one left node, you effectively have a max-flow problem where the left nodes have infinite-capacity inflow and the right nodes have an outflow capacity of one. Consult max-flow algorithms for different solution methods.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum Matching in a weighted Tree in O(n)\r\n                \r\nis there an algorithm in O(n) to calculate the maximum matching for a weighted Tree?\nI only found algorithms for unweighted trees or bipartite graphs. I have some trouble converting these algorithms for trees.\nWith pen and paper i also found out, that the algorithm for unweighted trees does not work for weighted trees.\nI think recursively it would take more than O(n), what are the alternatives? Dynamic Programming maybe?\nHelp would be much appreciated.\nThank you :)\n    ", "Answer": "\r\nThe O(n) dynamic programming solution is to choose any node as the root, and then recursively calculate the maximum matching in each node's subtree in the root-matched and root-unmatched conditions.\nThe calculation is easy in postorder (DFS):  The max root-unmatched matching for a node is just the sum of the best matchings for each child subtree. The max root-matched matching for a node is the best matching with the root matched to the root-unmatched subtree for one of its children, added to the best matchings from the other children.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to find the strongest competitors or which are largely matched in a Bipartite network?\r\n                \r\nI have nodes and edges:\n\nThe edge lists are [(1, \"A\"), (1, \"B\"), (1, \"C\"), (1, \"D\"), (2, \"A\"), (2, \"D\")]\nSo the strongest competitors here will be 1&2 in the first part and A&D in second part since they are matched more.\nWhich algorithm should I apply for this case?\nA basic illustration is:\n```\n # Initialise graph\nB = nx.Graph()\n# Add nodes with the node attribute \"bipartite\"\ntop_nodes = [1, 2]\nbottom_nodes = [\"A\", \"B\", \"C\", \"D\"]\nB.add_nodes_from(top_nodes, bipartite=0)\nB.add_nodes_from(bottom_nodes, bipartite=1)\n# Add edges only between nodes of opposite node sets\nB.add_edges_from([(1, \"A\"), (1, \"B\"), (1, \"C\"), (1, \"D\"), (2, \"A\"), (2, \"D\")])\n```\n\n    ", "Answer": "\r\nYou have couple of options in your hand:\n\nnx.bipartite.eppstein_matching(G[, top_nodes])\nnx.bipartite.hopcroft_karp_matching(G[, top_nodes])\nnx.bipartite.maximum_matching(G[, top_nodes])\n\nConsider further reading from the official documentation. You can start with the following code to check and compare:\n```\nimport networkx as nx\n\n# Initialise graph\nB = nx.Graph()\n# Add nodes with the node attribute \"bipartite\"\ntop_nodes = [1, 2]\nbottom_nodes = [\"A\", \"B\", \"C\", \"D\"]\nB.add_nodes_from(top_nodes, bipartite=0)\nB.add_nodes_from(bottom_nodes, bipartite=1)\n# Add edges only between nodes of opposite node sets\nB.add_edges_from([(1, \"A\"), (1, \"B\"), (1, \"C\"), (1, \"D\"), (2, \"A\"), (2, \"D\")])\n\nprint(nx.bipartite.eppstein_matching(B))\nprint(nx.bipartite.hopcroft_karp_matching(B))\nprint(nx.bipartite.maximum_matching(B))\n```\n\nSample output:\n```\n{'A': 1, 'D': 2, 1: 'A', 2: 'D'}\n{1: 'A', 2: 'D', 'A': 1, 'D': 2}\n{1: 'A', 2: 'D', 'A': 1, 'D': 2}\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to get max_weight_matching in java\r\n                \r\nI have a Weighted and Non-Bipartite graph and would like to get the maximum weight matching. I have done the task with the python networkx library and looking for an alternative library for java. I looked into the JGraphT library but couldn't find the solution.\n```\nimport networkx as nx\nimport networkx.algorithms.matching as matching\n\nG=nx.Graph()\n\nG.add_edge(1,2,weight = 30)\nG.add_edge(1,3,weight = 100)\nG.add_edge(1,4,weight = 30)\nG.add_edge(2,3,weight = 0)\nG.add_edge(2,4,weight = 30)\nG.add_edge(3,4,weight = 30)\nM = matching.max_weight_matching(G,maxcardinality=True)\nprint(list(M))\n//OUTPUT: [(1, 3), (2, 4)]\n```\n\n    ", "Answer": "\r\nHere's the solution using JGraphT:\n```\nGraph<Integer, DefaultWeightedEdge> g = new SimpleWeightedGraph<>(SupplierUtil.createIntegerSupplier(1), SupplierUtil.createDefaultWeightedEdgeSupplier());\nInteger v1=g.addVertex();\nInteger v2=g.addVertex();\nInteger v3=g.addVertex();\nInteger v4=g.addVertex();\n\nGraphs.addEdge(g, v1, v2, 30);\nGraphs.addEdge(g, v1, v3, 100);\nGraphs.addEdge(g, v1, v4, 30);\nGraphs.addEdge(g, v2, v3, 0);\nGraphs.addEdge(g, v2, v4, 30);\nGraphs.addEdge(g, v3, v4, 30);\n\nMatchingAlgorithm<Integer, DefaultWeightedEdge> alg = new KolmogorovWeightedMatching<>(g, ObjectiveSense.MAXIMIZE);\nSystem.out.println(alg.getMatching());\n```\n\nOutput:\n```\nMatching [edges=[(1 : 3), (2 : 4)], weight=130.0]\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Add capacity to Ford Fulkerson algorithm\r\n                \r\nI have a working php implementation of Ford Fulkerson algorithm, based on this great article http://www.geeksforgeeks.org/maximum-bipartite-matching/\n\nAt the moment, the matrix that control the algorithm can have in its cells a value of 1 or 0, to represent the possibility of every employee to work in that position. I would like to add capacity to the algorithm, basically place in the matrix higher values, like 2, 3 and so on to express the preference to choose an employee instead of another.\n\nDo You have any suggestion on how to edit the algorithm to add capacity?\n\nThis is the algorithm code:\n\n```\nfunction maxMatch($matrix, $cols) {\n    $match = array();\n    foreach ($cols as $v => $item) {\n        $match[$item] = -1;\n    }\n    $result = 0;\n    foreach ($matrix as $u => $row) {\n        $seen = array();\n        foreach ($cols as $v => $item) {\n            $seen[$item] = 0;\n        }\n        if ($this->checkVertex($matrix, $u, $seen, $match)) {\n            print_r($match);\n            $result++;\n        }\n    }\n    return $match;\n}\n\nfunction checkVertex($matrix, $u, &$seen, &$match) {\n    foreach ($matrix[$u] as $v => $row) {\n        if ($matrix[$u][$v] && !$seen[$v]) {\n            $seen[$v] = TRUE;\n            if ($match[$v] < 0 || $this->checkVertex($matrix, $match[$v], $seen, $match)) {\n                $match[$v] = $u;\n                return TRUE;\n            }\n        }\n    }\n    return FALSE;\n}\n```\n\n\nThis is how I create the matrix:\n\n```\nfunction createMatrix($year, $month, $day, $shift) {\n    global $sql;\n\n    $result = $sql->query(\"VERY HUGE SELECT FOR EMPLOYEES AND POSITIONS MATCH\");\n\n    while ($row = $result->fetch_assoc()) {\n        $matrix[$row['employee']][$row['position']] = 1;\n    }\n    return $matrix;\n}\n```\n\n\nThanks a lot, \nMarco\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Copying values from a Map to a 256x256 array in a C++ program\r\n                \r\nI am working on a max bipartite matching algorithim. I am having trouble figuring out how to set values in an array based on the key/value in the map.\n\nUltimately I need iterate through my rows, which correspond to my keys in the map mymap. And then I need to set the appropriate column to true (1) based on the value in mymap. Ultimately it would look something like this \n\n```\nbool bpGraph[V][V] = { {0, 0, 0, 1, 0, ect.... 0}, //Key 1 Value 4\n                        {0, 2, 0, 0, 0, ect.... 0}, // Key 2 Value 2\n                        {0, 0},\n                        {0, 0},\n                        {0, 0},\n                        {0, 0},\n                        {0, 0}\n                      };\n```\n\n\nCurrently my algorithim looks like this, you can see that I am stumped on how to iterate through the map to set the appropriate value in the array:\n\ninline void keep_window_open() {char ch; cin>>ch;}\n// Driver program to test above functions\n\n```\nint main()\n{\n\n    ifstream myfile(\"H:\\\\School\\\\CSC-718\\\\paths.txt\"); \n    std::map<int, int> mymap; // Create the map\n    pair<int,int> me; // Define the pair\n    char commas; // Address the comma in the file\n    int a, b;\n    vector<int> v;\n\n    while (myfile >> a >> commas >> b)\n    {\n    mymap[a] = b; // Transfer ints to the map\n    }\n    mymap;\n```\n\n\n// This code above works\n\n```\n    bool bpGraph[M][N]; // Define my graph array\n\n  for (int i = 0; i <mymap.count; i++) // the plan is to iterate through the keys M\n and set the appropriate value true on N \n  {\n\n    bool bpGraph[M][N] = { \n\n    };\n  }\n    cout << \"Maximum number networks \"\n         << maxBPM(bpGraph); // run it through the BPM algorithim\n    keep_window_open();\n    return 0;\n}\n```\n\n    ", "Answer": "\r\nYou can't access the elements of a map using an index.  You need to use the iterator instead.  And in this case you can use the shorter \"for each\" style loop:\n\n```\nfor (const auto &val: mymap) {\n    bpGraph[val.first][val.second] = true;\n}\n```\n\n\nYou'll have to initialize the ```\nbpGraph```\n array to false before executing this loop.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Bipartie Matching to form an Array\r\n                \r\nI am given a number from ```\n1 to N```\n , and there are ```\nM```\n relationship given in the form ```\na```\n and ```\nb```\n where we can connect number ```\na```\n and ```\nb```\n.\nWe have to form the valid array , A array is said to be valid if for any two consecutive indexes ```\nA[i]  and A[i+1] is  one of the M relationship```\n\n\nWe have to construct a valid Array of Size ```\nN```\n, it's always possible to construct that.\n\nSolution: Make A Bipartite Graph of the following , but there is a loophole on this,\n\n```\nlet N=6\nM=6\n1 2\n2 3\n1 3\n4 5\n5 6\n3 4\n\nSo Bipartite Matching gives this:\nMatch[1]=2 \nMatch[2]=3 \nMatch[3]=1   // Here it form a Loop\nMatch[4]=5\nMatch[5]=6 \n```\n\n\nSo how to i print a valid Array of size ```\nN```\n , since N can be very large so many loops can be formed  ? Is there any other solution ?\n\nAnother Example: \n\n```\nlet N=6\nM=6\n1 3\n3 5\n2 5\n5 1\n4 2\n6 4\n\n\n  It's will form a loop  1->3->5->1\n1 3 5 2 4 6\n```\n\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Match two sets of objects\r\n                \r\nI am trying to figure out how to solve the following problem with a program:\nI have a set of objects A = [Ai] and another set of objects B = [Bj].\nI also have a matrix C=[cij] calculating the similarity between A and B (which is fully dense).\nI want to assign each object to a single other object (min(|A|, |B|) pairings in total) so that the sum of all the used cij is the maximum possible.\n(Also Cij is symmetric)\nI tried to formulate it as a bipartite matching problem but I couldn't find an existing definition and implementation of what I am asking, although it looks really familiar and this is why I ask for your help.\nThank you\n    ", "Answer": "\r\nThe problem is that of unbalanced assignment:\nhttps://en.wikipedia.org/wiki/Assignment_problem\nThere seems to be an implementation in scipy:\nhttps://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.linear_sum_assignment.html\nthat solves it. You need to convert similarities to costs (you can just take the negative).\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "All possible maximum matchings of a bipartite graph\r\n                \r\nI am using networkx to find the maximum cardinality matching of a bipartite graph.\n\nThe matched edges are not unique for the particular graph.\n\nIs there a way for me to find all the maximum matchings? \n\nFor the following example, all edges below can be the maximum matching:\n\n```\n{1: 2, 2: 1}```\n or ```\n{1: 3, 3: 1}```\n or ```\n{1: 4, 4: 1}```\n\n\n```\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\nG = nx.MultiDiGraph()\nedges = [(1,3), (1,4), (1,2)]\n\nnx.is_bipartite(G)\nTrue\n\nnx.draw(G, with_labels=True)\nplt.show()\n```\n\n\n\n\nUnfortunately, \n\n```\nnx.bipartite.maximum_matching(G)\n```\n\n\nonly returns\n\n```\n{1: 2, 2: 1}\n```\n\n\nIs there a way I can get the other combinations as well?\n    ", "Answer": "\r\nThe paper \"Algorithms for Enumerating All Perfect, Maximum and Maximal Matchings in Bipartite Graphs\" by Takeaki Uno has an algorithm for this. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.8179&rep=rep1&type=pdf\n\nTheorem 2 says \n\"Maximum matchings in a bipartite graph can be enumerated in O(mn^1/2+\nnNm) time and O(m) space, where Nm is the number of maximum matchings in G.\"\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Efficiently solving assignment problem with constraints\r\n                \r\nI have a variation of https://en.wikipedia.org/wiki/Assignment_problem#Unbalanced_assignment:\n\nA bipartite graph with vertex sets A and T,\nNon-negative costs on the edges,\nAll vertexes in A and T must occur at most once in a matching.\n\nBut with following modifications:\n\nThe edges in a matching must not intersect, i.e. with vertexes a_i in A and t_j in T sorted by some index value on both sides of the graph, a_(i_1) and t_(j_2) must not be connected in the matching when a_(i_2) and t_(j_1) are with i_1 < i_2 and j_1 < j_2.\nAlso for the smaller vertex set of the bipartite graph, not all vertexes need to be assigned, i.e. the optimal matching might only contain 1 edge when it has extreme costs.\nWe don't provide a constant s for the size of the matching to find.\nWant to MAXIMIZE the sum of edge costs of the assignment.\n\nHow can that be solved most efficiently?\nLinear program seems to be inefficient.\nThe problem can also be formulated as shortest-path problem with vertexes v_(i,j) when a_i and t_j are connected in the original bipartite graph, additional source and sink, and edges where above modifications 1 & 2 are satisfied. This still has |A|!*|T|! edges roughly which would also result in high runtime. Costs of edge from v(i_1,j_1) to v(i_2,j_2) should be set to minus the cost of the edge from a_(i_2) to t(j_2) in the original bipartite graph, so we're replicating cost values many times.\nIs there some more efficient shortest-path variant with costs on vertexes instead of edges?\nOr can the https://en.wikipedia.org/wiki/Hungarian_algorithm be modified to respect above modification 1? For modification 2 and 3 I see a trivial approach by adding rows and columns with values of 0 in order to get a balanced assignment problem, and modification 4 should be just negating the cost function.\n    ", "Answer": "\r\nAccording to above hint from @MattTimmermans, I ended up in the following dynamic programming approach (which is a modification of bipartite graph and dynamic programming):\nLet ```\nw(a, t)```\n be edge weight between nodes ```\na```\n in ```\nA```\n and ```\nt```\n in ```\nT```\n, and let ```\nM(i, j)```\n be solution (maximum cost matching graph without intersecting edges) for vertexes ```\n{a_0, a_1, ..., a_(i-1)} subset A```\n and ```\n{t_0, t_1, ..., t_(j-1)} subset T```\n, where ```\n0 <= i < |A|```\n and ```\n0 <= j < |T|```\n. For ```\ni = 0```\n and ```\nj = 0```\n the vertexes subsets are empty, i.e. prepending the matrix ```\nM```\n by 1 row and 1 column.\n```\nfor i in 0...|A|\n    for j in 0...|T|\n        if (i == 0 and j == 0)\n            M(i,j) = {cost: 0, step_type: null}\n        else\n            candidates = []\n\n            if (i >= 1 and j >= 1)\n                // subtract indexes in w(...) because of prepended artificial row and column in M\n                candidates.add({cost: M(i-1, j-1)[:cost] + w(i-1,j-1), step_type: 'right-down'})\n            end\n            if (i >= 1)\n                candidates.add({cost: M(i-1, j)[:cost], step_type: 'down'})\n            end\n            if j >= 1\n                candidates.add({cost: M(i, j-1)[:cost], step_type: 'right'})\n            end\n\n            M(i,j) = candidates.argmax(|map| map[:cost])\n        end\n    end\nend\n```\n\nAnd then go backwards from ```\nM(|A|,|T|)```\n according to ```\nstep_type```\n in every step, till we reach ```\nM(0,0)```\n. This gives a list of the edges in the best matching (in reverse order).\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Minimum path cover in directed acyclic graph\r\n                \r\nThe question I am going to ask here has already been asked before in stack overflow.\nBut I am not able to understand properly the solutions posted by Skiminok.\n\nHere is the Link .\n\nI tried the solution posted on the above link with the given two sample  test-cases ,but i am not able to get the correct answer.\n\nFor the test case 1::\n\nN=3 and K=2\n\n5 4 7\n\nThe DAG will be::\n\n\n\nNote :I have constructed the above DAG Considering:\n\nLet pi and pj be two different problems. Then we will draw a directed edge from pi to pj if and only if pj can be solved directly after pi on the same day, consecutively. Namely, the following conditions have to be satisfied:\n\ni < j, because you should solve the less difficult problem earlier.\n\n|vi - vj| >= K (the rating requirement).\n\nThen I constructed the Bipartite graph considering::\n\nFor each directed edge (u, v) of the original DAG one should add an undirected edge (au, bv) to the bipartite graph, where {ai} and {bi} are two parts of size n.\n\n\n\nThe answer =maximum cardinality matching in above bipartite graph .\n\nmaximum cardinality matching in above bipartite graph =1 (Green colored egde)\n\nBut the answer is 2.\n\nSimilarly Sample Test Case 2:\n\n5 1\n\n5 3 4 5 6\n\n\n\n\n\nThe MAx cardinality in above graph is MORE THAN ONE ,but the Correct answer is 1.\n\nI think i am not implementing it correctly,please can you tell where i am making mistake Or is there any other Method\n\nThanks!\n    ", "Answer": "\r\nI found the answer myself ,\nthe next day i posted this question.\n\nAnd my-solution passed all test cases .\n\nI was making mistake in the last step.\nActually the Answer/solution is the total Number of vertices in SET B that does not contain the edge of Maximal Bipartite Matching.\n\nFor Example on sample test case 1::\n\nMaximal Matching M={(1A,3B)}.\n\nNo edge of maximal matching is incident upon two vertices (Vertex 1 and Vertex 2).So answer is equal to number of such vertex=2\n\nFor test case 2::\n\nMaximal Matching M={(1A,2B),(2A,3B),(3A,4B),(4A,5B)}.\n\nNo edge of maximal matching is incident upon one vertex (Vertex 1).So answer is equal to 1\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "efficient projection of a bipartite graph in python (using networkx)\r\n                \r\nUsing the networkx module, I do some network analysis under Python 3.2, where I need to project a bipartite graph (of inmates linked to their cell: input graph B in the code below) to a subgraph (linking cellmates to each other if both had an overlapping spell in the same cell: using the input of set nodes defining the inmate-nodes of graph B, generating output graph G). I don't need a special algorithm to come up with any or an optimal matching, I just need to collect all links that satisfy some conditions. Thus other SO posts I found do not really apply. But:\n\nMy current code is blowing up (RAM-, swap-, and CPU-wise) as I give it more and more data. Please let me know if you see ways to streamline the code below with 5 layers of loops. I am not sure any knowledge of networkx is necessary or details of my labeling of edge attributes is relevant. Thanks!\n\n```\ndef time_overlap_projected_graph_parallel(B, nodes):\n    G=nx.MultiGraph()\n    G.add_nodes_from((n,B.node[n]) for n in nodes)\n    for u in nodes:\n        unbrs = set(B[u])\n        nbrs2 = set((n for nbr in unbrs for n in B[nbr])) - set([u])\n        for v in nbrs2:\n            for mutual_cell in set(B[u]) & set(B[v]):\n                for uspell in B.get_edge_data(u,mutual_cell).values():\n                    ustart = uspell[1]\n                    uend = uspell[2]\n                    for vspell in B.get_edge_data(v,mutual_cell).values():\n                        vstart = vspell[1]\n                        vend = vspell[2]\n                        if uend > vstart and vend > ustart:\n                            ostart = max(ustart,vstart)\n                            oend = min(uend,vend)\n                            olen = (oend-ostart+1)/86400\n                            ocell = mutual_cell\n                            if (v not in G[u] or ostart not in [ edict[1] for edict in G[u][v].values() ]):\n                                G.add_edges_from([(u,v,{0: olen,1: ostart,2: oend,3: ocell})])\n    return G\n```\n\n    ", "Answer": "\r\nOne could now use bipartite graphs I guess. Like\n\n```\nimport networkx as nx\nfrom networkx.algorithms import bipartite\n\nB.add_nodes_from(inmates_list, bipartite=0)\nB.add_nodes_from(cells_list, bipartite=1)\n\ninmates = set(n for n,d in B.nodes(data=True) if d['bipartite']==0)\ncells = = set(B) - inmates\nG = bipartite.projected_graph(B, inmates)\n```\n\n\n(http://networkx.lanl.gov/reference/algorithms.bipartite.html)\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Kuhn's algorithm recursion elimination\r\n                \r\nI'm trying to eliminate recursion in the following function (which is the part of Kuhn's algorithm implementation for bipartite graph maximum matching.):\n\n```\nstatic boolean findPath(List<Integer>[] graph, int u1,\n                        int[] matching, boolean[] vis) {\nvis[u1] = true;\n  for (int v : graph[u1]) {\n      int u2 = matching[v];\n      if (u2 == -1 || !vis[u2] && findPath(graph, u2, matching, vis)) {\n        matching[v] = u1;\n        return true;\n      }\n    }\n    return false;\n}\n```\n\n\nHere is what I've got so far:\n\n```\nstatic boolean findPath(ArrayList<ArrayList<Integer>> graph, int u1) {\n    vis[u1] = true;\n\n    Stack<Long> subgraphsToExplore = new Stack<Long>();\n    List<Integer> subGraph = graph.get(u1);\n\n    long container  = 0;\n\n    for(Integer vertex : subGraph){\n        container  = vertex;\n        container <<= 17;\n        container |= u1;\n        subgraphsToExplore.push(container);\n    }\n\n    while(!subgraphsToExplore.empty()){\n\n    container = subgraphsToExplore.pop();\n\n    int v = (int)container >> 17;\n    int u2 = matching[v];\n    if (u2 == -1) { // v - is an exposed vertex in the path,\n                    // the path is augmenting\n\n        matching[v] = (int)(container & 0x1ffff); // first 17 bits others to zero\n        return true;\n      } \n      flag = false;\n      if(!vis[u2]){ // v - is not an exposed vertex,\n                    // but we haven't visited it on our dfs this time \n          List<Integer> subSubGraph = graph.get(u2);\n          vis[u2] = true;\n\n          long container1 = 0;\n\n          for(int v1 : subSubGraph){\n              if(!vis[v1]){\n                  vis[v1] = true;\n                  container1 = v1;\n                  container1 <<= 17;\n                  container1 |= u2;\n                  subgraphsToExplore.push(container1);\n              }\n          }\n      }     \n  }\n\n    return false;\n  }\n```\n\n\nBut I keep getting incorrect results. What am I missing here?\nP.S.\nI took the recursive code from here\n    ", "Answer": "\r\nWhen the first method finds a new path it will potentially update multiple positions in ```\nmatching```\n .\n\nHowever, when the second method finds a new path it only updates a single position in ```\nmatching```\n and immediately returns.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to Import an edge list from a text file into a bipartite graph using C++\r\n                \r\nI have a edge list of 256 inputs/outputs. I need to import these list values into a bipartite graph. I'm new with C++ and don't know where to start. I ultimately need to parse through this list and go to the input line which would be the \"row\" and the output value which would be the \"column\" and set that value to 1 (for true). Hope this makes sense.\n\nSample text file data:\n\n```\n192, 16\n120, 134\n256, 87\n122, 167\n142, 97\n157, 130\n245, 232\n223, 63\n```\n\n\nHere is my program\n\n```\n// A C++ program to find maximal Bipartite matching.\n#include <iostream>\n#include <string.h>\n#include <fstream>\nusing namespace std;\n\n// M is number of inputs and N is number of outputs\n#define M 256\n#define N 256\n\n// A DFS based recursive function that returns true if a\n// matching for vertex u is possible\nbool bpm(bool bpGraph[M][N], int u, bool seen[], int matchR[])\n{\n    // Try every output one by one\n    for (int v = 0; v < N; v++)\n    {\n        // If input u is connected to output v and v is\n        // not already connected to\n        if (bpGraph[u][v] && !seen[v])\n        {\n            seen[v] = true; // Mark v as connected\n\n            // If output 'v' is not assigned to an input OR\n            // previously assigned input for output v (which is matchR[v]) \n            // has an alternate output available. \n            // Since v is marked as visited in the above line, matchR[v] \n            // in the following recursive call will not get output'v' again\n            if (matchR[v] < 0 || bpm(bpGraph, matchR[v], seen, matchR))\n            {\n                matchR[v] = u;\n                return true;\n            }\n        }\n    }\n    return false;\n}\n\n// Returns maximum number of matching from M to N\nint maxBPM(bool bpGraph[M][N])\n{\n    // An array to keep track of the Inputs assigned to\n    // Outputs. The value of matchR[i] is the Input number\n    // assigned to input i, the value -1 indicates nothing is\n    // assigned.\n    int matchR[N];\n\n    // Initially all outputs are available\n    memset(matchR, -1, sizeof(matchR));\n\n    int result = 0; // Count of matches\n    for (int u = 0; u < M; u++)\n    {\n        // Mark all Inputs as not connected for next output.\n        bool seen[N];\n        memset(seen, 0, sizeof(seen));\n\n        // Find if the input'u' can connect to an output\n        if (bpm(bpGraph, u, seen, matchR))\n            result++;\n    }\n    return result;\n}\n\n// Driver program to test above functions\nint main()\n{\n    // Let us create a bpGraph shown in the above example\n\n\n\n    bool bpGraph[M][N] = {};\n\n    cout << \"Maximum number networks \"\n         << maxBPM(bpGraph);\n\n    return 0;\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Which Algorithm to reduce multiple lists (finding the villains)\r\n                \r\nI'm sure this algorithm is used in many areas but i can't find the appropriate name or algorithm, so here is the problem to be solved :\n\n\n  Let's say we have a town and we want to sort out the villains, we know exactly how many there are, but we don't know them, although we have some probabilities and lists in which we know exactly how many villains it contains among other people\n\n\nlet's take this example :\n\n```\nL1 -> [S1, S3, S5, S6]\nL2 -> [S1, S2, S6, S5]\nL3 -> [S2]\nL4 -> [S2, S3]\n```\n\n\nWe know that :\n\n```\nL1 has 1 suspect\nL2 has 1 suspect\nL3 has 0 suspects\nL4 has 0 suspects\n```\n\n\n\nLists can contain similar elements.\nThere are many villains and can appear on the same list\n\n\nBased on this simple example, we can determine that the villain is S1.\n\nThe similar algorithm that i could find is Hopcroft-Karp bipartite matching (https://pypi.python.org/pypi/hopcroftkarp/1.2.3), but it seems that it solves a similar problem but not this particular one.\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Animations for algorithms and data structures?\r\n                \r\nIs there an application that can animate graph algorithms?\n\nI find it much easier to understand a graph algorithm by watching animations. It would be nice if there is an application that can animate some common graph algorithms.\n\nEdit\n\nAny type of animation would be much appreciated. But it would be more desirable to have user interactions (e.g. data input, control of speed, play back).\n\nA list of algorithms here:\n\n\nBreadth-first search: http://www.rci.rutgers.edu/~cfs/472_html/AI_SEARCH/SearchAnimations.html\nDepth-first search: http://www.rci.rutgers.edu/~cfs/472_html/AI_SEARCH/SearchAnimations.html\nDijkstra: http://www.cse.yorku.ca/~aaw/HFHuang/DijkstraStart.html\nminimum spanning tree;\nbipartite match;\nmaximum flow problem;\nbinary tree operations;\nred-black tree;\nB-tree operations: http://slady.net/java/bt/view.php, http://ats.oka.nu/b-tree/b-tree.html\ndisjoint set.\n\n    ", "Answer": "\r\n\nBTree:\nhttp://ats.oka.nu/b-tree/b-tree.html\nBFS & DFS: http://www.rci.rutgers.edu/~cfs/472_html/AI_SEARCH/SearchAnimations.html\nDijkstra: http://www.cs.sunysb.edu/~skiena/combinatorica/animations/dijkstra.html\nMST: http://www.cs.sunysb.edu/~skiena/combinatorica/animations/mst.html\nRed Black Tree: http://aleph0.clarku.edu/~achou/cs102/examples/bst_animation/RedBlackTree-Example.html\nSkip list: http://iamwww.unibe.ch/~wenger/DA/SkipList/\n2-3-4 tree: http://www.cs.unm.edu/~rlpm/499/ttft.html\n\n\nI found a list of different algorithms with their animations but many seem to require Animal (a software for showing them). \n\n\nAnimal Download Link: http://www.algoanim.info/Animal2/?q=taxonomy/term/7\nVisualizations: http://www.animal.ahrgr.de/animations.php3?lang=e\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Generalizing the algorithm for domino tiling?\r\n                \r\nIn this earlier question the OP asked the following problem:\n\n\n  Given a rectangular grid where some squares are empty and some are filled, what is the largest number of 2x1 dominoes that can be placed into the world such that no two dominos overlap and no domino is atop a filled square?\n\n\nThe (quite beautiful!) answer to this problem recognized that this is equivalent to finding a maximum bipartite matching in a specially-constructed graph.  In this graph, each empty square has a node that is linked to each of its neighbors by an edge.  Each domino then corresponds to an edge in the graph such that its endpoints are not covered by any other edge.  Consequently, any set of edges that don't share a vertex (a matching) corresponds to an arrangement of dominoes, and vice-versa.\n\nMy question is a generalization of this earlier one:\n\n\n  Given a rectangular grid where some squares are empty and some are filled, what is the largest number of M x N dominoes (for a given M and N) that can be placed into the world such that no two dominos overlap and no domino is atop a filled square?\n\n\nI cannot see how to convert this into a matching problem as was done in the previous case.  However, I also don't see any particular reason why this problem would immediately be NP-hard, so there may be a polynomial time solution to the problem.\n\nIs there an efficient algorithm for solving this problem?  Or does anyone have a reduction that would show that this problem is NP-hard?\n\nThanks so much!\n    ", "Answer": "\r\nThis problem is definitely NP-hard and I can prove it.  There is a reduction from 3-SAT to this problem.  Specifically, it's a reduction from 3-SAT to the subproblem of this problem in which the dominoes are 1x3.  There may also be other reductions for other specific sizes, but this one definitely works.\n\nEssentially, in this reduction, we're going to use domino positions to encode either true or false.  In specific, I'm going to adopt the same notation as the other solution, which is to say that I'll use asterisks to indicate open spaces on the grid.  I'll also use sets of three capital letters to represent dominoes and lower case letters to represent \"signals\" which are spaces which may or may not be filled depending on the state of the system.\n\nTo embed a 3-SAT problem into this space, we're going to need a set of what I'll call gadgets which allow only certain states to be possible.  Most of these gadgets will have a fixed number of dominoes in them.  The exception will be the gadgets which represent the clauses which will have one extra domino if the clause is true (satisfied) but not when it is false (unsatisfied).  We can interconnect these gadgets using paths.  Together this will allow us to build a 3-SAT circuit.  We will have a base number of dominoes since each path and gadget will take a standard amount of dominoes, we can add those up to get a base number k and then each clause gadget can have one extra domino if it is true, so if all clauses can be made true (and hence the expression satisfied) and there are n clauses, then the maximum number of dominoes will be n+k.  If not, then the maximum number will be less than n+k.  This is the basic form of the reduction.  Next I will describe the gadgets and give examples.\n\nSimilar to the other answer, we're going to have two positions which encode true and false for a given variable.  So, I'll start with a single tile which can be in two possible places.\n\n```\n****\n```\n\n\nThis can either be covered with one domino like\n\n```\nAAA* or *AAA\n```\n\n\nObviously, this cannot be covered with 2 dominoes and covering it with 0 dominoes would never be maximal.  For my purposes, we're going to consider a protrusion to represent the value \"false\" and a lack of protrusion to represent \"true\".  So we can view this part as having carrying two signals:\n\n```\nx**y\n```\n\n\nAnd in this case, only one of x or y will be covered, so we can consider the signals to be x and the logical not of x.  For our purposes, whichever is covered is false, whichever is not covered is true.  Next, we can transmit signals simply through straight can curved paths.  If we have\n\n```\nx*****y\n```\n\n\nWe will again have exactly two dominoes and result in either x or y being covered, but not both.\n\n```\n***y\n*\n*\nx\n```\n\n\nWill have exactly the same behavior.  So we can use this to create long and curving paths in lengths which are increments of 3.  However, not all lengths we might want to use are increments of 3, so we need an additional gadget to move a different distance.  I call this the fiddler gadget and it's only purpose is to move the signal slightly uneven distances to make things connect successfully.  Its input comes from x and output goes to y and it merely transmits the same signal along.  It looks like this:\n\n```\n ***y\n *\n**x\n```\n\n\nIt always contains exactly two dominoes and is filled in one of the following two ways:\n\n```\n BBB*     ABBB\n *        A   \nAAA      *AX  \n```\n\n\nIf we're going to model 3-SAT, however, we need more than this.  Specifically, we need some way to model the clauses.  To do this, we have a gadget where one extra domino can be packed in if the clause is true.  The clause will be true when one or more of its inputs is true.  In this case, that means that we can pack one extra domino in when at least one of the inputs does not protrude.  It will look like this:\n\n```\n*x*y*\n  *\n  z\n```\n\n\nIf we add an extra path to each for clarity, then it looks like this:\n\n```\n * *\n * *\n * *\n*****\n  *\n  ****\n```\n\n\nIf x,y, and z are all false, then they'll all have protrusions and it will be filled like \nthis:\n\n```\n A B\n C D\n C D\n*C*D*\n  *\n  EEEF\n```\n\n\nWhere the rest of dominoes A,B, and F continue on down a path somewhere.  If at least one of inputs is true, then we can pack in one extra domino (G) like so:\n\n```\n C B         A D         A B\n C D         C D         C D\n C D    or   C D    or   C D\nGGGD*       *CGGG       *CGD*\n  *           *           G\n  EEEF        EEEF        GEEE\n```\n\n\nHowever, even if all inputs are true, then we cannot pack in more than one domino.  That scenario would look like this:\n\n```\n C D\n C D\n C D\n*****\n  *\n  *EEE\n```\n\n\nAnd as you can see, we can only insert exactly one extra domino into the empty space, not two.\n\nNow, if terms were never repeated, then we'd be done (or very nearly done).  However, they can be repeated, so next, we need a signal splitter so that one variable can appear in\nmultiple terms.  To do this, we utilize the following gadget:\n\n```\ny*** ***z\n   * *\n   ***\n   ***\n    x\n```\n\n\nIn this gadget x is the input and y and z are the outputs.  In this gadget, we can always pack 5 dominoes.  If x protrudes than packing 5 dominoes will always require covering y and z as well.  If x does not protrude, then covering y and z is not required.  The packing where x does not protrude looks like this:\n\n```\nyAAA BBBz\n   C D  \n   CED \n   CED  \n    E \n```\n\n\nWhen x does protrude (we use X to indicate the end of the domino protruding into space x), the maximal packing necessarily covers both y and z:\n\n```\nAAAC DBBB\n   C D\n   C*D\n   EEE\n    X\n```\n\n\nI will take a moment to note that it would be possible to pack this with five dominoes when x is not protruding in such a way that either y or z protrude.  However, doing so would result in terms which could be true (not protruding) becoming false (protruding).  Allowing some of the terms (not variables, but actual terms in the clauses) to differ in value only by becoming false unnecessarily will never result in being able to satisfy an otherwise unsatisfiable expression.  If our 3-SAT expression was (x | y | z) & (!x | y | !z) then allowing both x and !x to be false would only make things harder.  If we were to allow both ends of something to be true, this would result in incorrect solutions, but we do not do this in this scheme.  To frame it in terms of our specific problem, protruding unnecessarily will never result in more dominoes being able to be packed in later down the line.\n\nWith paths and these three gadgets, we can now solve planar 3-SAT, which would be the sub-problem of 3-SAT where if we draw a graph where the terms and clauses are vertices and there is an edge between every term and every clause which contains that term, that the graph is planar.  I believe that planar 3-SAT is probably NP-hard because planar 1-in-3-SAT is, but in case it's not, we can use gadgets to do a signal crossing.  But it's really quite complex (if anyone sees a simpler way, please let me know) so first I'm going to do an example of solving planar 3-SAT with this system.\n\nSo, a simple planar 3-SAT problem would be (x | y | z) & (!x | y | !z).  Obviously, this is satisfiable, using any assignment where y is true or several other assignments.  We will build our dominoes problem thus:\n\n```\n    *******\n    *     *\n    *     *\n ****   ***\n *       *\n***      ****\n  *         *\n  *         *        \n  * ******* *\n  * *     * *\n  * *     * *\n *z*x*   *****\n   *       *\n   **** ****\n      * *\n      ***\n      ***\n       *\n       *\n       *           \n       y\n```\n\n\nNotice that we had to use fiddlers at the top to get things to space correctly or else this would've been substantially less complex.\n\nAdding up the total dominoes from gadgets and paths we have 1 splitter (5 dominoes), two fiddlers (2 dominoes each), and a total of 13 regular paths, for a grand total of 5 + 2*2 + 13 = 22 dominoes guaranteed, even if the clauses cannot be satisfied.  If they can be, then we will have 2 more dominoes which can be filled in for a total of 24.  One optimal packing with 24 dominoes is as follows:\n\n```\n    QRRRSSS\n    Q     T\n    Q     T\n OPPP   *UT\n O       U\n*ON      UVVV\n  N         W\n  N         W        \n  M IIIJJJK W\n  M H     K X\n  M H     K X\n *zGH*   LLLX*\n   G       *\n   GEEE FFF*\n      B D\n      BCD\n      BCD\n       C\n       A\n       A\n       A\n```\n\n\nThis tiling contains 24 dominoes, so we can know that the original expression is satisfiable.  In this case, the tiling corresponds to make y and x true and z false.  Notice that this is not the only tiling (and not the only satisfying assignment of boolean values), but that there is no other tiling which will increase the number of tiles beyond 24, so it is a maximum tiling.  (If you don't want to count all the dominoes you can note that I used every letter except for Y and Z.)\n\nIf the maximal tiling had contained either 22 or 23 dominoes, then we would know that one of the clauses was not satisfied (GGG and/or LLL dominoes would not be able to be placed) and hence we would know that the original expression was not satisfiable.\n\nIn order to be certain that we can do this even if planar 3-SAT isn't NP-hard, we can build a gadget which allows paths to cross.  This gadget is unfortunately kind of big and complex, but it's the smallest one I was able to figure out.  I'll first describe the pieces and then the whole gadget.\n\nPiece 1: Crossover point.  x and y are the inputs.  a,b,and c are the outputs.  They will need to be combined using other gadgets to actually relay x and y to the opposite side of each other.\n\n```\n   ***c\n   *\n  ***\n  * *\n  * *\n  * *\n  ***\n  ***\n ax*yb\n```\n\n\nThis gadget will always fit exactly 7 dominoes.  There are four possible input combinations.  If neither input protrudes (both are true) than no output will protrude and it will be filled as in (tt1) or (tt2) below.  If only input x protrudes then only c will protrude as in (ft) below.  If only input y protrudes then either output a or c will protrude as in (tf) below.  And if input x and y both protrude then output c protrudes as in (ff) below.\n\n```\n (tt) AAAc         (ft) AAAc         (tf) AAAc         (ff) BAAA     \n      *                 *                 *                 B        \n     BBB               BBB               BBB               CBD       \n     C D               C D               C D               C D       \n     C D               C D               C D               C D       \n     C D               C D               C D               E G       \n     EEE               EEE               EEE               EFG       \n     FFF               FFF               FFF               EFG       \n    aGGGb             aXGGG             GGGYb             aXFYb      \n```\n\n\nI have not included the possibility that in the (ft) or (tf) scenarios that c could be covered instead of a or b.  This is possible within the scope of this gadget but once combined with other gadgets to form the complete crossover, if it were to do so, it would never result in a larger number of clauses being satisfied so we can exclude it.  With that in mind, we can then observe that in this case the value of the input x is equal to the value of b & c and the input y is equal to the value of a & c (note that this would be logical or rather than logical and if protrusion were considered true rather than false).  So we just need to split c and then use a logical and gadget to connect connect the values of c with a and b respectively and we will then have successfully completed our cross over.\n\nThe logical and is our simplest gadget so far and it looks like this:\n\n```\n  ****\n  *\n x*y\n```\n\n\nYou might actually note that there's one embedded towards the top of the crossover point gadget.  This gadget will always contain precisely 2 dominoes.  One will be at the top to serve as the output.  The other one serves as a switch which will be horizontally oriented only if both x and y are true (non-protruding) and vertically oriented otherwise as we can see in the following diagrams:\n\n```\n BBB*     ABBB     ABBB     ABBB\n *        A        A        A   \nAAA      XAy      xAY      XAY  \n```\n\n\nThus we can complete the crossover by splitting c and then adding two of these gates, one for a & c and one for b & c.  Putting it all together requires also adding some fiddler gadgets and looks like this:\n\n```\n             ******* ****\n             *     * *  *\n             *     ***  *\n            ***    *** ***\n              *     *  *\n           ****     *  ****\n           *        *     *\n           *     ****     *\n          ***    *       ***\n            *   ***      *\n         ****   * *      ****\n    y    *      * *         *    x\n    *    *      * *         *    *\n    * ****      ***         **** *\n    ***         ***            ***\n      **********x*y*************\n```\n\n\nI'm not going to fill in example tilings for that.  You'll have to do it yourself if you want to see it in action.  So, hooray!  We can now do arbitrary 3-SAT.  I should take a moment to note that doing this will be a polynomial time transformation because even in the worst case, we can just make a big grid with all of the variables and their opposites along the top and all the terms on the side and do O(n^2) crossovers.  So there is a simple, polynomial-time algorithm for laying this all out and the maximum size of the transformed problem is polynomial in the size of the input problem.  QED.\n\n\n\nEdit note:\nFollowing Tom Sirgedas's excellent work in finding a mistake in the splitter gadget, I've made some changes to the answer.  Essentially, my old splitter looked like this and could be packed with 6 when x does not protrude (rather than the 5 I had intended) like this:\n\n```\ny*** ***z   AAAC DBBB\n   * *         C D\n   ***         C*D\n   ***         EEE\n   *x*         FFF\n```\n\n\nSo I revised it by removing the two spaces on either side of x.  This eliminates the six domino packing while still allowing a 5-domino packing in which y and z are uncovered when x is uncovered.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Algorithm for assigning items to groups based on binary criteria\r\n                \r\nI'm working on an algorithmic problem that has me stumped. It is related to both the assignment problem and maximum cardinality matching. I'll be using it to match large amounts of data so it's important to be fast, ideally O(n2) or better.\nProblem Statement\nConsider a set of universities U and a set of prospective students S. Assume that |U| << |S|. Each university has a specific number of slots available to admit students, and a binary criteria for whether each student in S is eligible or ineligible to attend. The number of prospective students is equal to the total number of slots available across all universities.\nIs there a fast algorithm that will assign students to universities such that:\n\nEach university admits exactly the number of students they wanted\nOnly students eligible for a university will be assigned to that university\nIf those conditions are not possible, it will return some value indicating that it was not possible (either a best possible incomplete match for the conditions or just -1/error/etc)\n\nWhat I've considered\nThis can be modeled as a maximum-cardinality bipartite matching problem.\nConstruct the bipartite as follows:\n\nEach prospective student is a node\nEach university is a node\nFor each university, draw an edge to each eligible student\nDuplicate each university node to represent the number of available slots for that university\n\nThe Hopcraft-Karp algorithm can find a maximum-cardinality matching in roughly O(n2.5) (where n is the number of students). If the cardinality of the match is equal to the number of students, the problem has been solved. If not, a solution is impossible for the given dataset.\nHowever this approach seems to be inefficient because there are far more students than universities. Each university node has to be duplicated many times, resulting in a huge number of edges for the Hopcraft-Karp algorithm to process.\nIs there a better way of abstracting this problem that I'm not seeing? Or is there a clever algorithm that can make use of the fact that there are far fewer universities than students and improve the runtime?\n    ", "Answer": "\r\nThere’s a simple O(|S| |U|²)-time algorithm, which meets your criterion in the worst case if |U| = O(√|S|) and likely does a lot better than the quoted running time in practice. (See also “bipush” variants of standard flow algorithms.)\nThe basis of this algorithm is Ford–Fulkerson. For each student in turn, we try to assign them a university. If we’re lucky, one of their choices has capacity, but in general, we need to shuffle other students around to make capacity (find an augmenting path).\nNow, what typically makes finding an augmenting path expensive is that we have to traverse the whole graph. However! If we keep a |U|×|U| array where the (i, j) entry is a list of students that can move from university i to university j, then this takes O(|U|²) time (breadth-first search from the set of admissible universities of the new student; we only need to know if each cell of the array is empty). We (re)assign at most |U| students, each of which generates O(|U|) work to update the lists, so the total cost per iteration is O(|U|²).\nOne nice property of this algorithm in practice (many flow algorithms, actually) is that, if you feed it a partial assignment with k unmatched students, then the running time is O(|S| |U| + k |U|²). The idea would be to find a fast heuristic that does a reasonable but incomplete job (e.g., shuffle the students and try to assign each one to the admissible university that is least popular with other students).\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "RL + optimization: how to do it better?\r\n                \r\nI am learning about how to optimize using reinforcement learning. I have chosen the problem of maximum matching in a bipartite graph as I can easily compute the true optimum.\nRecall that a matching in a graph is a subset of the edges where no two edges are incident on the same node/vertex.  The goal is to find the largest such subset.\nI show my full code below but first let me explain parts of it.\n```\nnum_variables = 1000\ng = ig.Graph.Random_Bipartite(num_variables, num_variables, p=3/num_variables)\ng_matching = g.maximum_bipartite_matching()\nprint(\"Matching size\", len([v for v in g_matching.matching if v < num_variables and v != -1]))\n```\n\nThis makes a random bipartite graph with 1000 nodes in each of the two sets of nodes. It then prints out the size of the true maximum matching.\nIn the code below, ```\nself.agent_pos```\n is an array representing the current matching found. Its length is the number of edges in the original graph and there is a 1 at index ```\ni```\n if edge ```\ni```\n is included and a 0 otherwise.   ```\nself.matching```\n is the set of edges in the growing matching. ```\nself.matching_nodes```\n is the set of nodes in the growing matching that is used to check to see if a particular edge can be added or not.\n```\nimport igraph as ig\nfrom tqdm import tqdm\nimport numpy as np\nimport gym\nfrom gym import spaces\n\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\n\nclass MaxMatchEnv(gym.Env):\n    metadata = {'render.modes': ['console']}\n    def __init__(self, array_length=10):\n        super(MaxMatchEnv, self).__init__()\n        # Size of the 1D-grid\n        self.array_length = array_length\n        self.agent_pos = [0]*array_length\n        self.action_space = spaces.Discrete(array_length)\n        self.observation_space = spaces.Box(low=0, high=1, shape=(array_length,), dtype=np.uint8)\n        self.matching = set()  # set of edges\n        self.matching_nodes = set() # set of node ids (ints)\n        self.matching_size = len([v for v in g_matching.matching if v < num_variables and v != -1])\n        self.best_found = 0\n        \n    def reset(self):\n        # Initialize the array to have random values\n        self.time = 0\n        #print(self.agent_pos)\n        self.agent_pos = [0]*self.array_length\n        self.matching = set()\n        self.matching_nodes = set()\n        return np.array(self.agent_pos)\n    \n        \n    def step(self, action):\n        self.time += 1 \n        reward = 0\n        edge = g.es[action]\n        if not(edge.source in self.matching_nodes or edge.target in self.matching_nodes):\n            self.matching.add(edge)\n            self.matching_nodes.add(edge.source)\n            self.matching_nodes.add(edge.target)\n            self.agent_pos[action] = 1\n            if sum(self.agent_pos) > self.best_found:\n                self.best_found = sum(self.agent_pos)\n                print(\"New max\", self.best_found)\n            reward = 1\n        elif self.agent_pos[action] == 1:\n            #print(\"Removing edge\", action)\n            self.matching_nodes.remove(edge.source)\n            self.matching_nodes.remove(edge.target)\n            self.matching.remove(edge)\n            self.agent_pos[action] = 0\n            reward = -1\n        done = sum(self.agent_pos) == self.matching_size\n        info = {}\n        return np.array(self.agent_pos), reward, done, info\n\n    def render(self, mode='console'):\n        print(sum(self.agent_pos))\n\n    def close(self):\n        pass\n\n\nif __name__ == '__main__':\n \n    num_variables = 1000\n    g = ig.Graph.Random_Bipartite(num_variables, num_variables, p=3/num_variables)\n    g_matching = g.maximum_bipartite_matching()\n    print(\"Matching size\", len([v for v in g_matching.matching if v < num_variables and v != -1]))\n\n    env = make_vec_env(lambda: MaxMatchEnv(array_length=len(g.es)), n_envs=12)\n\n    model = PPO('MlpPolicy', env, verbose=1).learn(10000000)\n```\n\nThere are a number of problems with this but the main one is that it doesn't optimize well. This code gives just over 550 and then stops improving where the true optimum is over 900 (it is printed out by the code at the start).\nThe main question is:\n\nHow can this be done better so that it gets to a better matching?\n\nA subsidiary question is, how can I print the best matching found so far? My attempt using  self.best_found to maintain the best score does not work as it seems to be reset regularly.\nChanges that haven't help\n\nChanging PPO for DQN makes only a  marginal difference.\nI tried changing the code so that ```\ndone```\n is True after 1000 steps.\n\nThe change is as follows:\n```\nif self.time == 1000:\n    done = True\nelse:\n    done = False\n```\n\nHaving added ```\nprint(max(env.get_attr(\"best_found\")))```\n in place of ```\nprint(\"New max\", self.best_found)```\n this change to ```\ndone```\n shows no advantage at all.\n    ", "Answer": "\r\nTo print the max for each environment you can use ```\nget_attr```\n method from stable baselines. More info in their official docs.\nFor example the lines below will print the max for each of the 12 environments and then the maximum across all environments.\n```\nprint(env.get_attr(\"best_found\"))\nprint(max(env.get_attr(\"best_found\")))\n```\n\nRegarding why it does not converge it could be due a bad reward selected, although looking at your reward choice it seems sensible. I added a debug print in your code to see if some step lead to ```\ndone = True```\n, but it seems that the environment never reaches that state. I think that for the model to learn it would be good to have multiple sequence of actions leading to a state with ```\ndone = True```\n, which would mean that the model gets to experience the end of an episode. I did not study the problem in your code in detail but maybe this information can help debug your issue.\nIf we compare the problem with other environments like CartPole, there we have episodes that end with ```\ndone = True```\n and that helps the model learn a better policy (in your case you could limit the amount of actions per episode instead of running the same episode forever). That could help the model avoid getting stuck in a local optimum as you give it the opportunity to \"try again\" in a new episode.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "(Python) code to count weighted perfect matchings?\r\n                \r\nForgive me if this question is better suited to mathoverflow or some other sister site.\n\nI'm interested in counting the weighted sum of perfect matchings in a (not necessarily bipartite) planar graph.  This is a standard problem; it's frequently solved using the FKT algorithm.  I'd like to find some Python code to solve this (and am not eager to write it myself, because the algorithm is a little complicated).\n\nFailing that, is there code available in some other (relatively mainstream) language?\n\nUser sabbahillel below suggested that I should list some of the software I've found that doesn't work, to avoid reduplication of effort.  To that end:\n\n\nfkt appears only to apply to unweighted graphs, and is in Gforth.\nOBDD by Knuth (!) is only for unweighted bipartite graphs and is in CWEB.\nvaxmaple requires Maple and vaxmacs is an Emacs mode (?!?!); neither support weighted or non-bipartite graphs.\n\n    ", "Answer": "\r\ngoogle is your friend. I found a sourceforge project that implements this in FORTH\n\nFKT Alpha Count perfect matchings in planar graphs.\n\n\n  Description: This project provides an implementation of the FKT\n  algorithm to count the number of perfect matchings in a planar graph.\n  The source code is written in the Forth language, requiring Gforth to\n  run. Computations can be perfored via a command line tool as well as\n  via a library usable with Gforth.\n\n\nSource Code\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to find all systems of distinct representatives using i.e. Hopcroft–Karp algorithm?\r\n                \r\nI would like to find all systems of distinct representatives in bipartite graph. I've found Hopcroft–Karp algorithm, which finds maximal matching, which I would like to implement. But I don't know how should I modify it to find ALL transversals.\n\nOr maybe, someone knows any other solution to solve this problem, it doesn't need to be very quick algorithm.\n\nCould somebody give me some tips? Thank you in advance\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Minimum path cover in DAG\r\n                \r\nI want to know if there exists an efficient algorithm for computing the minimum path-cover in a Directed Acyclic Graph. Please don't confuse the minimum \"path-cover\" with \"vertex-disjoint path-cover\". For the latter, I know an efficient algorithm using Maximum matching of the corresponding Bipartite graph. But that applies only for the vertex-disjoint case. Can the same algorithm be relaxed to obtain the answer for the path cover when each vertex can be visited multiple times?\n    ", "Answer": "\r\nYes, the same algorithm could be relaxed as you wish. Just compute transitive closure of the original graph.\n\nYou can find an explanation of the complete algorithm in Wikipedia article \"Dilworth's theorem\", in section \"Proof via König's theorem\".\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Calculating centrality measures using NetworkX for a bipartite graph and Gephi\r\n                \r\nI am a naive Python programmer and using it for my network data, so pardon me if this sounds silly. I have a two mode network with individuals and organisations. I have this as an edge list saved as a CSV file that I import to python. I have managed to read the CSV, project the graph into a bipartite network and export the file to gephi. After doing this, I am calculating the centrality (degree, eigenvector, closeness and betweenness) for my one mode projected and weighted graph. My code is as follows:\n\n```\norganisation_nodes, individual_nodes = bipartite.sets(B)\nindividual_nodes = set(n for n,d in B.nodes(data=True) if d['bipartite']==1)\norganisation_nodes = set(B) - individual_nodes\norganisation_graph = bipartite.weighted_projected_graph(B, organisation_nodes)org = bipartite.projected_graph(B, organisation_nodes)\nprint nx.info(org)\n#degree centrality\ndeg_cent = nx.degree(org)\nbetween_cent = nx.betweenness_centrality(org)\nprint between_cent\neigenvect_cent = nx.eigenvector_centrality(org)\nprint eigenvect_cent\nclose_cent = nx.closeness_centrality(org)\n```\n\n\nI visualised the graphml file that I got from the projected network onto Gephi and calculated the centrality measures there. However, there is a discrepancy in the centrality values calculated by Gephi and NetworkX. Only the density and the degree centrality values match. Is there something wrong with my code? If not, why the difference?\nAny help would be greatly appreciated,\nThanks\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Solving a graph game\r\n                \r\nI've struggled some time with a problem from a programming contest (Andrew Stankevich Contest 21) about a game that goes like follows:\n\n\n  Nick and Peter like to play the following game [...]. They\n  draw an undirected bipartite graph G on a sheet of paper, and put a token to one of its vertices. After that they make moves in turn. Nick moves first.\n  \n  A move consists of moving the token along the graph edge. After it the vertex where the token was\n  before the move, together with all edges incident to it, are removed from the graph. The player who has\n  no valid moves loses the game.\n\n\nThe graph is given and the task now is to find for a given start node, whether the starting player wins or loses if both players play optimally. To summarize\n\n\nBipartite graph\nWe are given the start node (say on the left side)\nWe move in turns, a move consists of following an edge, but we can't visit a node that was already visited\nThe player who cannot move loses\n\n\nSince the graph is bipartite, Nick (the first player) will always remove a node from the left side and Peter will always remove a node from the right side. \n\nThe graph can have up to 1000 nodes (at most 500 at each side) and 50000 edges, so a good polynomial time algorithm is needed (the time limit here is 2 seconds to solve all starting positions, but I think we can share a lot of information between the different starting positions). \n\nI'm pretty sure that this can be reduced to some kind of vertex covering or packing problem, because the graph is bipartite, but I can't find a strategy that correlates to any of these.\n\nI know the solution for a special case: Let's say the sides have n1 and n2 vertices, respectively. If there is a matching of size min(n1, n2) and if the player on the smaller side begins, than there exists a winning strategy: He just has to follow the matched edges and automatically wins.\n\nAny ideas?\n    ", "Answer": "\r\nProposition. Nick (the first player) wins starting from vertex ```\nv```\n iff this vertex belongs to every possible maximum matching of the given graph. We will prove it in two steps.\n\n\nIf there is a maximum matching without ```\nv```\n, Nick loses.\nIndeed, since the matching is maximum, there is no augmenting path from ```\nv```\n. That means every simple odd-length path from ```\nv```\n can be prolonged by an edge of the matching. In terms of our problem, it means the game can be continued by Peter after every Nick's move.\nIf there is no maximum matching without ```\nv```\n, Nick wins.\nConsider any possible maximum matching. Move along the edge of this matching from ```\nv```\n to, say, ```\nu```\n. Now, the initial matching minus the edge ```\nu-v```\n is a maximum matching of the remaining graph which does not include ```\nu```\n. As we know from step 1, the player to move now (which is Peter) is at a loss.\n\n\n\n\nAs for the implementation, we can first construct a maximum matching in O(VE) utilizing the straightforward algorithm (see here for an example implementation) — turns out the common name is Kuhn's augmenting paths algorithm.\n\nAfter that, you maintain a maximum matching and look at every vertex. If the vertex, say ```\nv```\n, is not currently in the matching, Nick loses. If it is, remove the corresponding edge, say ```\nv-u```\n, from the matching, forbid the vertex ```\nv```\n temporarily and run a search for an augmenting path from ```\nu```\n in O(E). If you don't find such path, Nick wins, and you have to restore the edge you removed. Otherwise, Nick loses again, and the new maximum matching can be left untouched. The total running time is O(VE) again.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Solving a graph game\r\n                \r\nI've struggled some time with a problem from a programming contest (Andrew Stankevich Contest 21) about a game that goes like follows:\n\n\n  Nick and Peter like to play the following game [...]. They\n  draw an undirected bipartite graph G on a sheet of paper, and put a token to one of its vertices. After that they make moves in turn. Nick moves first.\n  \n  A move consists of moving the token along the graph edge. After it the vertex where the token was\n  before the move, together with all edges incident to it, are removed from the graph. The player who has\n  no valid moves loses the game.\n\n\nThe graph is given and the task now is to find for a given start node, whether the starting player wins or loses if both players play optimally. To summarize\n\n\nBipartite graph\nWe are given the start node (say on the left side)\nWe move in turns, a move consists of following an edge, but we can't visit a node that was already visited\nThe player who cannot move loses\n\n\nSince the graph is bipartite, Nick (the first player) will always remove a node from the left side and Peter will always remove a node from the right side. \n\nThe graph can have up to 1000 nodes (at most 500 at each side) and 50000 edges, so a good polynomial time algorithm is needed (the time limit here is 2 seconds to solve all starting positions, but I think we can share a lot of information between the different starting positions). \n\nI'm pretty sure that this can be reduced to some kind of vertex covering or packing problem, because the graph is bipartite, but I can't find a strategy that correlates to any of these.\n\nI know the solution for a special case: Let's say the sides have n1 and n2 vertices, respectively. If there is a matching of size min(n1, n2) and if the player on the smaller side begins, than there exists a winning strategy: He just has to follow the matched edges and automatically wins.\n\nAny ideas?\n    ", "Answer": "\r\nProposition. Nick (the first player) wins starting from vertex ```\nv```\n iff this vertex belongs to every possible maximum matching of the given graph. We will prove it in two steps.\n\n\nIf there is a maximum matching without ```\nv```\n, Nick loses.\nIndeed, since the matching is maximum, there is no augmenting path from ```\nv```\n. That means every simple odd-length path from ```\nv```\n can be prolonged by an edge of the matching. In terms of our problem, it means the game can be continued by Peter after every Nick's move.\nIf there is no maximum matching without ```\nv```\n, Nick wins.\nConsider any possible maximum matching. Move along the edge of this matching from ```\nv```\n to, say, ```\nu```\n. Now, the initial matching minus the edge ```\nu-v```\n is a maximum matching of the remaining graph which does not include ```\nu```\n. As we know from step 1, the player to move now (which is Peter) is at a loss.\n\n\n\n\nAs for the implementation, we can first construct a maximum matching in O(VE) utilizing the straightforward algorithm (see here for an example implementation) — turns out the common name is Kuhn's augmenting paths algorithm.\n\nAfter that, you maintain a maximum matching and look at every vertex. If the vertex, say ```\nv```\n, is not currently in the matching, Nick loses. If it is, remove the corresponding edge, say ```\nv-u```\n, from the matching, forbid the vertex ```\nv```\n temporarily and run a search for an augmenting path from ```\nu```\n in O(E). If you don't find such path, Nick wins, and you have to restore the edge you removed. Otherwise, Nick loses again, and the new maximum matching can be left untouched. The total running time is O(VE) again.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to compute an injective/surjective map with minimum weight?\r\n                \r\nWe are given an ```\nm x n```\n matrix ```\nw```\n which represents the edge weights in a complete bipartite graph ```\nK_m,n```\n. We wish to find a map ```\n{1,...,m} -> {1,...,n}```\n with minimal weight, which is injective or surjective. Choosing a map is equivalent to, for every vertex ```\nv```\n in ```\n{1,...,m}```\n, choosing exactly one edge incident to ```\nv```\n.\n\nLet ```\nm<=n```\n. An injective function with minimal weight can be found by searching for the perfect matching with minimal weight. In Python, this is implemented in ```\nscipy```\n:\n```\nimport numpy as np\nimport scipy, scipy.optimize\nw=np.random.rand(5,10)\nprint(scipy.optimize.linear_sum_assignment(w))\n```\n\n\nLet ```\nm>=n```\n. How can a surjective function with minimal weight be found? I'm looking for a concrete implementation in Python.\n    ", "Answer": "\r\nEDIT: It turns out I might have misunderstood your question.\nFrom injective to surjective\nIf ```\nm > n```\n, and you already have an algorithm that handles the case ```\nm <= n```\n, then swap the two components. Your algorithm will give you an injective function from the second component to the first. Take the inverse of that function; it will be a surjective function from a subset of the first component to the second component.\nUsing ```\nnetworkx```\n\nWhat you are looking for is a maximum-cardinality matching in a bipartite graph.\nThe python library ```\nnetworkx```\n contains several functions for that. Standard problems are \"maximum-cardinality matching\" and \"maximum-weight matching\"; I'd be surprised if there were a function to solve your \"minimum-weight maximum-cardinality matching\" problem directly.\nHowever; it looks to me as if your problem was equivalent to finding a maximum-weight matching in the weighted graph obtained by replacing every weight ```\nw```\n by ```\nW-w```\n, where ```\nW```\n is some very large value (for instance, three times the maximum weight in the original graph).\nBy including this large value ```\nW```\n in the weight of every edge, you're forcing the maximum-weight matching to be a maximum-cardinality matching. And by including the negative value ```\n-w```\n, you're asking the algorithm to find edges with the smallest possible original weight in the original graph.\n\nDocumentation: ```\nnetworkx.algorithms.matching.max_weight_matching```\n\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Hopcroft–Karp algorithm time complexity\r\n                \r\nIn the last 2 paragraphs of the paper about Hopcroft–Karp algorithm to find the maximum cardinality matching in bipartite graph:\n\n\n  https://dl.dropboxusercontent.com/u/64823035/04569670.pdf\n  \n  The execution time of a phase is O(m+n), where m is the number of\n  edges in G, and n is the number of vertices. Hence the execution time\n  of the entire algorithm is O((m+n)s), where s is the cardinality of a\n  maximum matching.\n  \n  If G has n vertices then m <= n^2 / 4 and s < n / 2 so that the execution time is bounded by O(n^(5/2)).\n\n\nI don't understand given:\n\n```\nm <= n^2 / 4\ns <= n / 2\n```\n\n\nwhy they concluded:\n\n```\nO((m+n)s) = O(n^(5/2))\n```\n\n\nShouldn't it be:\n\n```\nO((m+n)s) = O(n^3)\n```\n\n\nAny idea?\n\nEdited: Link fixed. My bad.\n    ", "Answer": "\r\nI believe you are correct and it seems to me there is an error in the paper - they significantly simplified the proof. Have a look at this paper where several Lemmas are used for the proof. \n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "CPLEX Solver Solution\r\n                \r\nI am currently stuck writing a CPLEX Solver.\n\nThe problem is basically a weighted bipartite matching with a twist. \n\nImagine we have 2 shelters and 2 homeless. Every homeless has a risk associated with a certain shelter. below is a matrix of this problem:\n\n```\n    S1   S2\n\nP1  1    5\n\nP2  10   5\n\n```\n\n\nso P1(person1) has risk 1 if it goes to S1(shelter1) and so on. For the above case, the optimal solution is to assign P1 to S1 and P2 to S2 to minimize the risk.\n\nNow here is the twist. We have a [fairness equation (Jain's Fairness)][1]. This fairness equation is a quadratic function that basically calculates the fairness after all the assignment is done. This is the fairness index for the above solution.\n\nFairness = (1+5^2)/(2*(1^2)+(5^2) = 0.9 OR 90% fairness. \n\nI want to write a solver that maximizes fairness. Gurobi couldn't solve my problem because it is a quadratic function. I moved on to CPLEX but I'm still unable to solve the problem. Here is my code:\n\n```\nint NbPeople = ...;\nrange People = 1..NbPeople;\n\nint Shelters = ...;\nrange Shelter=1..Shelters;\n\nint SheltersCapacity[Shelter] = ...;\nint PersonReq[People]=...;\nint GoodnessOfFit[People][Shelter] = ...;\n\ndvar boolean A[p in People][s in Shelter];\ndvar int gof;\n\n//dexpr int Assignment=sum(p in People, s in Shelter) A[p][s] * GoodnessOfFit[p][s] ; \n\nmaximize gof;\n\nsubject to {\n\nforall(s in Shelter)\n    Capacity:\n       sum(p in People)\n         A[p][s] * PersonReq[p]  <= SheltersCapacity[s];\n\nforall (p in People)\n    sum(s in Shelter) A[p][s] <= 1;\n\n    sum (p in People,s in Shelter) A[p][s] == 3;\n\nforall (p in People, s in Shelter)\n   Fairness:\n   (A[p][s] * GoodnessOfFit[p][s] ^ 2)\n    /\n    3 * A[p][s] * GoodnessOfFit[p][s] ^ 2 <= gof;\n\n}```\n\n\n[1]: https://en.wikipedia.org/wiki/Fairness_measure\n```\n\n    ", "Answer": "\r\nYou could try to use CP within CPLEX.\n\nFor instance:\n\n```\nusing CP; // \n\ndvar int x in 10..100;\ndvar int y in 1..10;\n\nminimize x/(y*y+x);\n\nsubject to\n{\nx>=y+2;\n}\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Algorithm to match people in a group based on who they are compatible with\r\n                \r\nI am trying to find the maximum matching in a group of people based on their compatibility. I was headed towards maximum cardinality matching on bipartite graphs when I realized I do not have 2 distinct groups.\nWhere I am at:\nI have a list of their IDs: ```\n[1, 8, 3, 15, 13, 21]```\n\nI have a function called verify that will verify if 2 id's are compatible(there could be an odd number).\nI then create a graph(dictionary) of the indices  each persons indices is compatible with:\n```\n    ids = [1, 8, 3, 15, 13, 21]\n    l = len(ids)\n    matches = {}\n    for x in range(l):\n        matches.setdefault(x,[])\n        for y in range(l):\n            if x != y:\n                if verify(ids[x],ids[y]):\n                    matches[x].append(y)\n```\n\nthis produces:\n```\n{0: [3, 4, 5], 1: [2, 4, 5], 2: [1, 5], 3: [0, 4, 5], 4: [0, 1, 3], 5: [0, 1, 2, 3]}\n```\n\nNow I am unsure where to go from here or if I should be taking another direction.\nCan someone point me in the right direction please?  Thanks\n    ", "Answer": "\r\nLooks as if you are trying to solve the Stable marriage problem. I wrote a Rosetta Code task that has solutions in Python and other languages.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "lemon library file bipartite_matching.h missing\r\n                \r\nI install the library in linux system as described on the following website https://lemon.cs.elte.hu/trac/lemon/wiki/InstallLinux.\n\nI want to find the maximum matching of a lemon bipartite graph, and found that there is a algorithm in lemon library http://lemon.cs.elte.hu/pub/doc/latest-svn/a00381.html.\n\nWhen I ```\n#include <lemon/bipartite_matching.h>```\n, the compiler reports that no file named ```\nbipartite_matching.h```\n exists in lemon, so I checked the file in compressed file download from https://lemon.cs.elte.hu/trac/lemon/wiki/Downloads, and I can't find ```\nbipartite_matching.h```\n.\nDoes anyone know possible reasons for that missing file?\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "count unique pair in graph (vertices repetition not allowed)\r\n                \r\nIs there any Algorithm exists for counting unique pair (pair of vertices) in ```\nundirected graph```\n (vertices repetition not allowed). I think it could be a variation of bipartite graph but if there is any better way to find out .. please comment.\n[I think Problem Belongs to Perfect Matching Algorithm]\nProblem Statement:\n```\nI have an undirected graph which consists of n vertexes and m edges. I can delete edges from the graph. Now I'm interested in one question : is it possible to delete edges in the graph so that the degree of each vertex in the graph will be equal 1.. There can be multiple edges in the graph, but can not be any loops```\n\n\nExample: n = #vertices, m = #edges \nn = 4, m = 6\n1 2\n1 3\n1 4\n2 3\n2 4\n3 4\nUnique sequence could be (1 2, 3 4) (1 4, 2 3) (1 3, 2 4) \n    ", "Answer": "\r\nThe set of edges that covers the entire graph without using the same vertex multiple times is called a matching or independent edge set, see wikipedia.\n\nIn that article is also mentioned that the number of distinct matchings in a graph (which is the number you are after) is called the Hosoya index, see this wikipedia article.\n\nAlgorithms to compute this number are not trivial and Stack Overflow wouldn't be the right place to try to explain them, but I at least I hope you have enough pointers to investigate further.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "networkit bipartite graph connected components only when 2 or more common edges\r\n                \r\nI'm new to the graphs, but trying to get my path through.\nBasically, the idea is very simple - we have \"transactions\" with multiple \"features\" and need to assign the same Id to transactions, which have 2 or more common features (same values). The number of \"transactions\" is about 5500 000 records.\nFor example:\n\n\n\n\nTransaction\nA\nB\nC\nD\n\n\n\n\n0\n1\n1\n1\n2\n\n\n1\n2\n1\n1\n7\n\n\n2\n3\n1\n2\n9\n\n\n3\n4\n1\n3\n8\n\n\n4\n5\n2\n3\n4\n\n\n\n\n\nHere only transactions 0 and 1 have 2 common features, so they should be combined with same id.\n\n\n\n\n\nTransaction\nId\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n2\n2\n\n\n3\n3\n\n\n4\n4\n\n\n\n\nMy first approach was to create a graph with all nodes (transactions), then in dataframe filter out matching pairs with duplicates in 2 or more features and create edges for those nodes. But here I face an issue that it's impossible to process so huge dataframe in normal amount of time, even with multiprocessing.\nSo, the second approach is to create a bipartite graph where source nodes - transactions and target nodes - features.\nThen I was able to extract connected components but the result groups were too huge, as transactions even with a single common edge were grouped to the same Id.\nNow I'm struggling with the task of how to get connected source nodes that have 2 or more common target features..\nAppreciate any help.\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Minimizing the distance of pairing points\r\n                \r\nMy problem is as follows:\n\n```\nGiven a number of 2n points, I can calculate the distance between all points \nand get a symmetrical matrix.\n\nCan you create n pairs of points, so that the sum of the distance of all pairs is \nminimal?\n\nEDIT: Every point has to be in one of the pairs. Which means that\nevery point is only allowed to be in one pair.\n```\n\n\nI have naively tried to use the Hungarian algorithm and hoped that it may give me an assignment, so that the assignments are symmetrical. But that obviously did not work, as I do not have a bipartite graph.\n\nAfter a search, I found the Stable roommates problem, which seems to be similar to my problem, but the difference is, that it just tries to find a matching, but not to try to minimize some kind of distance.\n\nDoes anyone know a similar problem or even a solution? Did I miss something? The problem does actually not seem that difficult, but I just could not come up with an optimal solution.\n    ", "Answer": "\r\nThere's a primal-dual algorithm due to Edmonds (the Blossom algorithm), which you really don't want to implement yourself if possible. Vladimir Kolmogorov has an implementation that may be suitable for your purposes.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Is this combinatorial optimization problem NP-hard?\r\n                \r\nI working on a combinatorial optimization problem that I suspect is NP-hard, and a genetic algorithm has been working well with our dataset.  We're a research group and plan to publish our results in our field (not in math or CS), and I'd like to explore the NP-hard question before sending the manuscript out for review.  \n\nThere are two main questions:  \n\n1) I'd like to know whether this particular optimization problem has been studied.  I've heavily searched the lit but haven't seen anything exactly the same.  \n\n2) If the problem hasn't been studied, I might take a crack at doing a reducibility proof, and would like some pointers to good NP-complete candidates for the reduction.\n\nThe problem can be described in two ways, as a subsequence variant, and as a bipartite graph problem.  \n\nIn the subsequence flavor, I want to find a \"relaxed\" subsequence that allows permutations, and optimize to minimize the permutation count.  For example:  (. = any other char)\n\nQuery: abc, Target: ..b.a.b.c., Result: abc   (normal subsequence)\n\nQuery: abc, Target: ..b.a.c.a., Result: bac   (subsequence with one permutation)\n\nThe bipartite formulation is a matching problem or linear assignment problem, with the graph partitioned into query character nodes and target character nodes.  The edges connect the query characters to the target characters, such that there is exactly one edge from each query char to a target char.  The objective function is to minimize the number of edge crossings (also called \"crossing number\" in the lit).  This is similar to bipartite graph layout algorithms that reorder node placement to minimize edge crossings, but my problem requires the that both node orders stay fixed.  \n\nAny thoughts from the experts on questions 1 or 2?\n\nThanks in advance!\n    ", "Answer": "\r\nJust some idea: Does it somehow equivalent to finding the minimal number of swap needed to sort an array (MIN-SBR)? If yes, this is NP-Hard.\n\n(btw, are you working on something similar to this?)\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Graph that connect between two groups\r\n                \r\nI created a program that accepts two groups of sentences as input and makes some comparison between them.\nEach sentence from group 'A' has one or more matching sentences in group 'B', and sentence from group 'B' can match more than one sentence in 'A'.\nEach relationship has a numeric value.\nI'm trying to create a graph describing these connections for the purpose of easy visualization of the connections.\nI thought to create a bipartite graph so that each arc has value, Somthing like the example image below (group A on the left and group B on the right) (from here).\n\nI am looking for other ideas or maybe an library that I can use for it.\nThank you.\n\n    ", "Answer": "\r\nA bi-partite graph makes a lot of sense for this and if you use the ```\nnetworkX```\n library you can easily create one. Assuming you have your elements in ```\nA```\n and ```\nB```\n and a list containing the edges\n\n```\nA = ['a1', 'a2', 'a3', 'a4']\nB = ['b1', 'b2', 'b3', 'b4']\nedges = [('a1', 'b1', 0.5), ('a1', 'b2', 0.3), ('b3', 'a4', 0.1)]\nG = nx.Graph()\nG.add_nodes_from(A], bipartite=0) # Add the node attribute \"bipartite\"\nG.add_nodes_from(B, bipartite=1)\nG.add_weighted_edges_from(edges)\n```\n\n\nNote that this is just a normal graph and and the only way to tell it is bi-partite is through the property ```\nbipartite```\n. If you need to do stuff like projecting the graph or accessing only one side then there is more on that in the networkX documentation.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Using ford fulkerson to place N employees in M positions with roles\r\n                \r\nI'm trying to solve a mathematical problem using Ford-Fulkerson, but I have some problems.\n\nThis is the problem\n\n```\n    I have a list of employees (Jack, John, Al, ...).\n    I have a list of roles (R1, R2, R3, ...).\n    I have a list of working positions (W1, W2, W3, ...).\n\n    Every employee has a set of roles, like Jack has R1 and R2, ...\n    Every working position has a set of roles that can support,\n    like to work in position W1 you need R1 or R2, ...\n```\n\n\nI need to find the best configuration of employees - working positions, to be sure that every working position has an employee with the right roles to work there (one employee per position).\n\nI tried using this algorithm http://www.geeksforgeeks.org/maximum-bipartite-matching/\n\nI built a matrix where I have a row for every employee and a column for every working position. I put in the X row, Y column the value 1 if the X employee can work in the Y position, otherwise I put 0.\n\nThe algorithm above, rewritten in PHP, works great until the number of employees <= the number of positions.\n\nIf I have more employees than positions, the algorithm calculation time tends to diverge to infinite.\n\nHere is the algorithm code:\n\n```\nfunction maxMatch($matrix, $cols) {\n    $match = array();\n    foreach ($cols as $v => $item) {\n        $match[$item] = -1;\n    }\n    $result = 0;\n    foreach ($matrix as $u => $row) {\n        $seen = array();\n        foreach ($cols as $v => $item) {\n            $seen[$item] = 0;\n        }\n        if ($this->checkVertex($matrix, $u, $seen, $match)) {\n            print_r($match);\n            $result++;\n        }\n    }\n    return $match;\n}\n\nfunction checkVertex($matrix, $u, $seen, &$match) {\n    foreach ($matrix[$u] as $v => $row) {\n        if ($matrix[$u][$v] && !$seen[$v]) {\n            $seen[$v] = TRUE;\n            if ($match[$v] < 0 || $this->checkVertex($matrix, $match[$v], $seen, $match)) {\n                $match[$v] = $u;\n                return TRUE;\n            }\n        }\n    }\n    return FALSE;\n}\n```\n\n\nEverything is like the algorithm in the link above, except that I pass the $cols array, containing the indexes of the columns (because they are position IDs and not numeric ordered).\n\nThis is how I create the matrix:\n\n```\nfunction createMatrix($year, $month, $day, $shift) {\n    global $sql;\n\n    $result = $sql->query(\"VERY HUGE SELECT FOR EMPLOYEES AND POSITIONS MATCH\");\n\n    while ($row = $result->fetch_assoc()) {\n        $matrix[$row['employee']][$row['position']] = 1;\n    }\n    return $matrix;\n}\n```\n\n\nso I put 1 only where I have a match between employees and positions.\n\nAnyone has any clue on how to resolve the problem? Thanks in advance\n    ", "Answer": "\r\nYou pass ```\nseen```\n by value. It is not correct. It should be passed by reference. What you have now is actually some kind of backtracking(the original algorithm time complexity proof is based on a fact that each vertex can be visited at most once during the depth-first-search and it is not true in your current implementation). That's why it works slow. Passing ```\nseen```\n by reference should fix it.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "GraphX Explanation\r\n                \r\nI have a couple of fundamental questions related to GraphX on Spark\nIs there a resource that can help me understand how GraphX works under the covers in terms of \n- how is parallelism done \n- how is the graph partitioned\n- can any graph algorithm be implemented in GraphX or are there only specific problems that can be implemented - for example - for Bipartite Graphs - can we write a matching algorithm using Path Augmentation etc\n\n\nI have basic working knowledge of GraphX - and the methods and operators available there and I have worked on the basic problems in the examples using Scala.\n\n\nAny help would be very appreciated\n    ", "Answer": "\r\n( Answer was provided to me by - Michal Malak - author of upcoming book - GraphX in Action - Manning Press )\n\nThese are great questions, and ones I should make sure are addressed in the book\n\nThree major caveats to GraphX:\n1. It's graph processing, not a graph database (this one is already mentioned in the book)\n2. It's suited for massively parallel vertex-to-vertex communications in a SIMD-style execution model. It is not suited for classic graph algorithms, which is why the implementations in chapter 6 are not a great fit for GraphX\n3. The dirty little secret is that although there is API control to partition the vertices (PartitionStrategy), edges are always randomly partitioned. Worst of all, edges and vertices are partitioned independently, so all opportunity for data locality is lost.\n\nThere is, however, a slightly unexpected optimization intrinsic to GraphX internals, and that is that each edge has routing information to the vertices.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Hungarian algorithm for a single set\r\n                \r\nI tried to adjust a hungarian algorithm in such a way that assignments among a single set are generated, according to https://www.researchgate.net/publication/268292864_The_Hungarian_Algorithm_with_a_Single_Input_Set. But after trying a lot I guess it is just not possible through several reasons: One thing a bipartite algorithm cannot/should not handle slings respectively odd-cycles and, of course, not disjoint sets.\nTheir approach is quite simple and also nice - at the first view. The Ansatz is just to mirror each time each edge (in a separate equality graph/matching) which enters the equality graph/matching. And the matching is perfect when all vertices are in one of both matchings.\nBut as I said I really tried - all - kind of possibilities to get it work..  but it won't. Since I invested a very lot of time I would like to know if I'm right that the approach cannot work.\nThank you in advance!\n\nedit: I found on https://math.stackexchange.com/questions/972936/hungarian-algorithm-on-symmetric-matrix that one had the same question with the same implementation. But I still lack an proof of this approach.\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Subset of vertices\r\n                \r\nI have a homework problem and i don't know how to solve it. If you could give me an idea i would be very grateful.\n\nThis is the problem:\n\"You are given a connected undirected graph which has N vertices and N edges. Each vertex has a cost. You have to find a subset of vertices so that the total cost of the vertices in the subset is minimum, and each edge is incident with at least one vertex from the subset.\"\n\nThank you in advance!\n\nP.S: I have tought about a solution for a long time, and the only ideas i came up with are backtracking or an minimum cost matching in bipartite graph but both ideas are too slow for N=100000.\n    ", "Answer": "\r\nThis may be solved in linear time using dynamic programming.\n\nA connected graph with N vertices and N edges contains exactly one cycle. Start with detecting this cycle (with the help of depth-first search).\n\nThen remove any edge on this cycle. Two vertices incident to this edge are u and v. After this edge removal, we have a tree. Interpret it as a rooted tree with the root u.\n\nDynamic programming recurrence for this tree may be defined this way:\n\n\nw0[k] = 0 (for leaf nodes)\nw1[k] = vertex_cost (for leaf nodes)\nw0[k] = w1[k+1] (for nodes with one descendant)\nw1[k] = vertex_cost + min(w0[k+1], w1[k+1]) (for nodes with one descendant)\nw0[k] = sum(w1[k+1], x1[k+1], ...) (for branch nodes)\nw1[k] = vertex_cost + sum(min(w0[k+1], w1[k+1]), min(x0[k+1], x1[k+1]), ...)\n\n\nHere ```\nk```\n is the node depth (distance from root), w0 is cost of the sub-tree starting from node w when w is not in the \"subset\", w1 is cost of the sub-tree starting from node w when w is in the \"subset\".\n\nFor each node only two values should be calculated: w0 and w1. But for nodes that were on the cycle we need 4 values: wi,j, where i=0 if node v is not in the \"subset\", i=1 if node v is in the \"subset\", j=0 if current node is not in the \"subset\", j=1 if current node is in the \"subset\".\n\nOptimal cost of the \"subset\" is determined as min(u0,1, u1,0, u1,1). To get the \"subset\" itself, store back-pointers along with each sub-tree cost, and use them to reconstruct the subset.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "N bits integer matching algorithm\r\n                \r\nI am trying to write an algorithm to establish correlation between n bits integers for the value “1”.\n\nHere is an exemple of a 5 bits integer: 0,1,0,0,1 \n\nI want to establish the percentage of correlation between this integer and a set of N other integers.\n\nFor example, Integer A(0,1,0,0,1) and Integer B(0,1,0,0,0) have a correlation of 0,5 for the value “1” as only the second bit is matching.\nIn my Firebase database, I have one n bits integer attached to each user_ID that I want to match against the n bits integer of every other user of my application to get a type of correlation between each user.\nThe distribution of the total correlations between users will follow a Gaussian curve that I want to use in the future to match users with each other.\n\nFor example: I want user A to be matched with every other user with these matches sorted by decreasing order of affinity (from high to low correlation between their n bits integers).\n\nDo you guys have any idea how I could perform the algorithm to establish the correlation between the N number of users and then perform another algorithm to sort these correlations from high to low?\nAny help would be greatly appreciated.\n\nThank you for your time,\n\nMaxime\n    ", "Answer": "\r\nyou can use the and operation to get the Result R.\n\nExample:\n\n```\nA = 9  = 01001\nB = 8  = 01000\nC = 7  = 00111\nD = 31 = 11111\n\nR = A & B gives 8 = 01000, the correlation is counting the ones: R/A = 1/2 = 0,5. \n\nR = A & C gives 1 = 00001, the correlation: R/A = 1/2 = 0,5.\n\nR = A & D gives 9 = 01001, R/A = 2/2 = 1.\n```\n\n\nHere we have a problem. you can solve this by using the max of the ones occuring in the num like R/max(A,D)\n\nI believe it is better to use the total bit count (here 5).\n\nresults would be.\n\n```\ncorr AB = 1/5 = 0,2\ncorr AC = 1/5 = 0,2\ncorr AD = 2/5 = 0,4\ncorr CD = 3/5 = 0,6\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Implementation of Auction Algorthm via Boost Graph Library C++\r\n                \r\nAs I cited in previous question:\n\nIs it possible to generate multiple custom vertices using the Bundle Properties from Boost Graph Library?\nBoost Maximum Weighted Matching in undirected bipartite random graphs hangs in an infinite loop\n\nI'm working on an application benchmark that compare the performance of the boost maximum weighted matching and auction algorithm for the transportation problem on solving the assignment problem for bipartite graphs.\nCurrently I've implemented a version of the auction algorithm using the bundle proprieties of boost graph library, this implementation is inspired by a vector version from github. I've done this in order to put on the same level both algorithms, to make a fair benchmark. Here it is:\n```\n#include \"../include/Auction.h\"\n#include \"../include/BipartiteGraph.h\"\n\nvoid auction_algorithm(Graph& graph, const int& n, duration& elapsed) {\n    const Weight eps = 1;\n    int unassigned_bidders = n;\n    GraphProp& gp = graph[boost::graph_bundle];\n\n    EdgeFilter any_interconnect = boost::keep_all{};\n    VertexFilter bidders = [graph](V v) -> bool { return boost::get<Bidder>(&(graph)[v]); };\n    VertexFilter items = [graph](V v) -> bool { return boost::get<Item>(&(graph)[v]); };\n\n    FMap map_bidders = FMap(graph, any_interconnect, bidders);\n    FMap map_items = FMap(graph, any_interconnect, items);    \n    \n    auto iterator_bidder = boost::make_iterator_range(boost::vertices(map_bidders));\n    auto iterator_item = boost::make_iterator_range(boost::vertices(map_items));\n    auto t_start = now();\n\n    while (unassigned_bidders > 0) {\n\n        for (auto uncasted_bidder : iterator_bidder) {\n            if (gp.bidder2item[static_cast<int>(uncasted_bidder)] != -1) continue;\n            Bidder* bidder = boost::get<Bidder>(&graph[uncasted_bidder]);\n\n            \n            // 1 Bid\n\n            int id_item1 = -1;\n            Weight val_item1 = -1;\n            Weight val_item2 = -1;\n\n            for (auto uncasted_item : iterator_item) {\n                Item* item = boost::get<Item>(&graph[static_cast<int>(uncasted_item)]);\n                Weight val = boost::get(boost::edge_weight_t(), graph, (boost::edge(uncasted_bidder, uncasted_item, graph)).first) - item->cost;\n\n                if (val > val_item1) {\n                    val_item2 = val_item1;\n                    val_item1 = val;\n                    id_item1 = item->id;\n                }\n                else if (val > val_item2) {\n                    val_item2 = val;\n                }\n            }\n\n            bidder->best_item = id_item1 + n;\n            bidder->val_first_best_item = val_item1;\n            bidder->val_second_best_item = val_item2;\n\n\n            // 2 Compete\n\n            Weight bid = bidder->val_first_best_item - bidder->val_second_best_item + eps;\n            auto best_item = boost::get<Item>(&graph[bidder->best_item]);\n            if (bid > best_item->high_bid) {\n                best_item->high_bid = bid;\n                best_item->high_bidder = bidder->id;\n            }\n\n        }\n\n\n        // 3 Assign\n\n        for (auto uncasted_item : iterator_item) {\n            Item* item = boost::get<Item>(&graph[uncasted_item]);\n            if (item->high_bid == -1) continue;\n\n            item->cost += item->high_bid;\n\n            if (gp.item2bidder[item->id] != -1) {\n                gp.bidder2item[gp.item2bidder[item->id]] = -1;\n                unassigned_bidders++;\n            }\n\n            gp.item2bidder[item->id] = item->high_bidder;\n            gp.bidder2item[gp.item2bidder[item->id]] = item->id;\n            unassigned_bidders--;\n        }\n    \n    }\n\n    elapsed = now() - t_start;\n}\n\n\n\nWeight perform_au(Graph& graph, duration& elapsed) {\n    int n = int(boost::num_vertices(graph) / 2);\n    Weight total_cost_auction = 0;\n\n    auction_algorithm(graph, n, elapsed);\n\n    std::cout << \"\\nThe matching is: \";\n    for (int bidder = 0; bidder < n; ++bidder) {\n        std::cout << \"(\" << bidder << \",\" << graph[boost::graph_bundle].bidder2item[bidder] << \")\";\n        int item = graph[boost::graph_bundle].bidder2item[bidder];\n        total_cost_auction += boost::get(boost::edge_weight_t(), graph, (boost::edge(bidder, item + n, graph)).first);\n    }\n    std::cout << \"\\n\";\n    return total_cost_auction;\n}\n```\n\nI have compared this to the vector implementation and notice that the latter is much faster than mine (however they return the same amount of total cost). Is it due to the complexity of the boost::get? If so, why is it so heavy?\nI'm using the g++ compiler on a Ubuntu machine and to compile the application I run the following line in my console:\n```\ng++ -std=c++2a -o ../bin/app BipartiteGraph.cpp MaximumWeightedMatching.cpp Auction.cpp AuctionArray.cpp Main.cpp\n```\n\nI share the link of my github repository so you can have a look at the whole project.\nPS: If you have any suggestions for speeding up the algorithm, that would be great!\nUPDATE: 09/08/2022\nRequirement: Make the auction algorithm generic like the style of the Boost Graph Library. This is the last implementation that I've made.\nUPDATE: 10/08/2022\nI've made a class that maintain the all stuff like it was before with the Bundle Properties:\nUPDATE: 14/08/2022\nActual version\n```\nWeight perform_au(const Graph& graph, Duration& elapsed, int& n_iteration_au, bool verbose)\n{\n    int n = int(boost::num_vertices(graph) / 2);\n    std::vector<int> assignments(n);\n\n    Auction<Graph, Weight> auction_problem(n);\n    auto t_start = now();\n    auction_problem.auction_algorithm(graph, assignments);\n    elapsed = now() - t_start;\n\n    std::cout << \" Finished \\nThe matching is: \";\n    for (int bidder = 0; bidder < n; ++bidder)\n        std::cout << \"(\" << bidder << \",\" << assignments[bidder] << \")\";\n    std::cout << \"\\n\";\n\n    if (verbose) auction_problem.printProprieties();\n    n_iteration_au = auction_problem.getNIterationAu();\n\n    return auction_problem.getTotalCost(graph);\n}\n\n\n\n#ifndef _AA_H\n#define _AA_H\n\n#include <vector>\n#include <unordered_map>\n#include <boost/graph/adjacency_list.hpp>\n\n\ntemplate<typename T>\nusing AdjacencyIterator = boost::graph_traits<T>::adjacency_iterator;\n\n\ntemplate<typename Graph, typename Type>\nclass Auction\n{\n    private:\n        struct Bidder {\n            int best_item = -1;\n            double val_first_best_item = -1;\n            double val_second_best_item = -1;\n        };\n\n        struct Item {\n            double cost = 0;\n            int high_bidder = -1;\n            double high_bid = -1;\n        };\n\n        int n_iteration_au = 0;\n        int vertices = 0;\n\n        std::unordered_map<int, Bidder> unassigned_bidder;\n        std::unordered_map<int, Bidder> assigned_bidder;\n        std::unordered_map<int, Item> item_map;\n        \n        bool is_assignment_problem(const Graph& graph);\n        void auctionRound(const Graph& graph, const double& eps, const auto& vertex_idMap);\n        \n    public:\n        void auction_algorithm(const Graph& graph, std::vector<int>& ass);\n        int getNIterationAu();\n        Type getTotalCost(const Graph& graph);\n        void printProprieties();\n        Type getMaximumEdge(const Graph& graph);\n        void reset();\n\n        Auction(int vertices)\n        {\n            this->vertices = vertices;\n            for (int i : boost::irange(0, vertices))\n            {\n                this->unassigned_bidder.insert(std::make_pair(i, Bidder{}));\n                this->item_map.insert(std::make_pair(i, Item{}));\n            }\n        }\n};\n\n\ntemplate<typename Graph, typename Type>\ninline int Auction<Graph, Type>::getNIterationAu() { return n_iteration_au; }\n\n\ntemplate<typename Graph, typename Type>\nType Auction<Graph, Type>::getMaximumEdge(const Graph& graph)\n{\n    Type max = 0;\n    typedef boost::graph_traits<Graph>::edge_iterator edge_iterator;\n\n    std::pair<edge_iterator, edge_iterator> ei = boost::edges(graph);\n    for (edge_iterator edge_iter = ei.first; edge_iter != ei.second; ++edge_iter)\n        if (boost::get(boost::edge_weight_t(), graph, *edge_iter) > max)\n            max = boost::get(boost::edge_weight_t(), graph, *edge_iter);\n        \n    return max;\n}\n\n\ntemplate<typename Graph, typename Type>\ninline Type Auction<Graph, Type>::getTotalCost(const Graph& graph)\n{\n    Type total_cost_auction = 0;\n    for (int bidder = 0; bidder < vertices; ++bidder) \n        total_cost_auction += boost::get(boost::edge_weight_t(), graph, (boost::edge(bidder, assigned_bidder[bidder].best_item + vertices, graph)).first);\n    return total_cost_auction;\n}\n\n\ntemplate<typename Graph, typename Type>\nbool Auction<Graph, Type>::is_assignment_problem(const Graph& graph)\n{\n    for (auto v1 : boost::make_iterator_range(boost::vertices(graph)))\n    {\n        AdjacencyIterator<Graph> ai, a_end;\n        boost::tie(ai, a_end) = boost::adjacent_vertices(v1, graph);\n        if (ai == a_end) return false;\n        else\n            for (auto v2 : boost::make_iterator_range(ai, a_end))\n                if ((v1 < vertices && v2 < vertices) || (v1 > vertices && v2 > vertices))\n                    return false;\n    }\n\n    return true;\n}\n\n\ntemplate<typename Graph, typename Type>\ninline void Auction<Graph, Type>::printProprieties()\n{\n    for (auto& bidder : assigned_bidder)\n        std::cout << \"|Bidder:\" << bidder.first << \"|Best item:\" << bidder.second.best_item << \"|Value first best item:\" << bidder.second.val_first_best_item << \"|Value second best item:\" << bidder.second.val_second_best_item << \"|\\n\";\n    for (auto& item : item_map)\n        std::cout << \"|Item:\" << item.first << \"|Cost:\" << item.second.cost << \"|Higher bidder:\" << item.second.high_bidder << \"|Higher bid:\" << item.second.high_bid << \"|\\n\";\n}\n\n\ntemplate<typename Graph, typename Type>\nvoid Auction<Graph, Type>::auctionRound(const Graph& graph, const double& eps, const auto& vertex_idMap)\n{\n    for (auto& bidder : unassigned_bidder)\n    {\n\n        int id_item1 = -1;\n        double val_item1 = -1;\n        double val_item2 = -1;\n\n        AdjacencyIterator<Graph> ai, a_end;\n        boost::tie(ai, a_end) = boost::adjacent_vertices(vertex_idMap[bidder.first], graph);\n\n        for (auto item : boost::make_iterator_range(ai, a_end)) // itero iniziando da quelli che hanno meno vertici?\n        {\n            double val = (boost::get(boost::edge_weight_t(), graph, (boost::edge(bidder.first, static_cast<int>(item), graph)).first)) // * (vertices))\n                - item_map[static_cast<int>(item) - vertices].cost;\n            if (val > val_item1)\n            {\n                val_item2 = val_item1;\n                val_item1 = val;\n                id_item1 = static_cast<int>(item) - vertices;\n            }\n            else if (val > val_item2) val_item2 = val;\n        }\n\n        bidder.second.best_item = id_item1;\n        bidder.second.val_second_best_item = val_item2;\n        bidder.second.val_first_best_item = val_item1;\n\n        double bid = bidder.second.val_first_best_item - bidder.second.val_second_best_item + eps;\n\n        if (item_map.find(bidder.second.best_item) != item_map.end())\n        {\n            if (bid > item_map[bidder.second.best_item].high_bid)\n            {\n                item_map[bidder.second.best_item].high_bid = bid;\n                item_map[bidder.second.best_item].high_bidder = bidder.first;\n            }\n        }\n\n    }\n    \n    for (auto& item : item_map)\n    {\n        if (item.second.high_bid == -1) continue;\n\n        item.second.cost += item.second.high_bid;\n        int id_to_remove = -1;\n\n        for (auto& ass_bidr : assigned_bidder)\n        {\n            if (ass_bidr.second.best_item == item.first)\n            {\n                id_to_remove = ass_bidr.first;\n                break;\n            }\n        } \n                \n        if (id_to_remove != -1)\n        {\n            unassigned_bidder.insert(std::make_pair(id_to_remove, assigned_bidder[id_to_remove]));\n            assigned_bidder.erase(id_to_remove);\n        }\n\n        assigned_bidder.insert(std::make_pair(item.second.high_bidder, unassigned_bidder[item.second.high_bidder]));\n        unassigned_bidder.erase(item.second.high_bidder);\n\n    }\n}\n\n\ntemplate<typename Graph, typename Type>\nvoid Auction<Graph, Type>::auction_algorithm(const Graph& graph, std::vector<int>& ass)\n{\n    if (!is_assignment_problem(graph)) throw(\"Not an assignment problem\");\n\n    auto vertex_idMap = boost::get(boost::vertex_index, graph);\n\n\n    double eps = static_cast<double>(1.0 / (vertices + 1));\n\n\n        while (unassigned_bidder.size() > 0)\n        {\n            auctionRound(graph, eps, vertex_idMap);\n\n            n_iteration_au += 1;\n        }\n\n    for (auto& a : assigned_bidder) ass[a.first] = a.second.best_item;\n\n}\n\n#endif\n\n```\n\n    ", "Answer": "\r\nWhy would it not be heavy.\nAgain,\n```\nFMap map_bidders = FMap(graph, any_interconnect, bidders);\nFMap map_items = FMap(graph, any_interconnect, items);    \n```\n\nJust \"wishing\" things to be a property map doesn't make them so.\nAlso, your filter predicates:\n```\nEdgeFilter any_interconnect = boost::keep_all{};\nVertexFilter bidders = [graph](V v) -> bool { return boost::get<Bidder>(&(graph)[v]); };\nVertexFilter items = [graph](V v) -> bool { return boost::get<Item>(&(graph)[v]); };\n\nFMap map_bidders = FMap(graph, any_interconnect, bidders);\nFMap map_items = FMap(graph, any_interconnect, items);    \n```\n\nThey...\n\ncopy the entire graph(!), twice\nuselessly ```\nget<>```\n a variant element, just to discard it and return ```\nbool```\n\n\nSlightly better:\n```\nVertexFilter bidders = [&graph](V v) -> bool {\n    return graph[v].which() == 0;\n};\nVertexFilter items = [&graph](V v) -> bool {\n    return graph[v].which() == 1;\n};\n\nFMap map_bidders = FMap(graph, {}, bidders);\nFMap map_items = FMap(graph, {}, items);    \n```\n\nBut it's all kind of useless. I'm not suprised this stuff takes time, because you know your graph is structured (N bidders)(N items), so\n```\nauto iterator_bidder = boost::make_iterator_range(vertices(map_bidders));\nauto iterator_item = boost::make_iterator_range(vertices(map_items));\n```\n\nCouldShould just be:\n```\nauto [b,e] = vertices(graph);\nauto iterator_bidder = boost::make_iterator_range(b, b + n);\nauto iterator_item   = boost::make_iterator_range(b + n, e);\n```\n\nAnd even those are overkill, since your vertex descriptor is integral anyways:\n```\nauto const bidders = boost::irange(0, n);\nauto const items   = boost::irange(n, 2 * n);\n```\n\nI'll read some more later (family time first), because I'm already noticing more (e.g. why is ```\nlistS```\n used as the edge container selector?).\nWill post here when done.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Finding the biggest union of disjoint sets from given sets\r\n                \r\nI have multiple sets (about 100 or so) of numbers ranging from 1 to 32, each one have no more than 32 items.\n\nFor example:\n\n```\n[1,2]\n[3,4]\n[1,2,3]\n```\n\n\nWhat I'm trying to do is to make an algorithm to output the biggest union of sets, which don't have intersections with each other.\n\nAn output from the example is ```\n[[1,2], [3,4]]```\n, where they don't have any intersections with each other, and the union of them are bigger than the set ```\n[[1,2,3]]```\n.\n\nI've tried finding the maximum match of a bipartite graph with sets mapped to the numbers, but I was immediately confused, as the problem is not about finding only one matching, but a set to multiple numbers.\n\nIt seems that writing a algorithm of polynomial time complexity is hard, any ideas of no more than 2^n time complexity would be appreciated.\n    ", "Answer": "\r\nThe problem you’re describing is called the set-packing problem and is known to be NP-hard. As a result, we don’t know of any polynomial-time algorithms for this problem, and if P ≠ NP then none exist.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Implementation of the Hopcroft Karp algorithm for a real-life scheduling problem\r\n                \r\nWe have a maximum bipartite matching problem such that M people need to be assigned N slots such that each slot has at-least one person and a subset of M people will have one out of these N slots each, while others will have 2 of these slots allocated to them.\n\nFor example: 8 slots, 6 people. 4 of these people will only need to cover 1 slot each but other 2 will cover 2 each. Hence, all 8 slots will be allocated (4*1 + 2*2).\n\nThe input data will reflect which of the M people will cover 1 slot each and which will cover 2 slots each.\n\nWe have the following implementation using HopCroft Carp so far:\n\n```\nfrom hopcroftkarp import HopcroftKarp\ngraph = {'john': {12, 3, 5}, 'june': {5, 10, 8}, 'joe': {5, 3}}\nHopcroftKarp(graph).maximum_matching(keys_only=True)\n>> {'joe': 3, 'june': 5, 'john': 12}\n```\n\n\nTo further complicate the issue, each of the users can indicate one of 3 choices: ```\npreferred```\n, ```\nnot preferred but available```\n and ```\nconflict (not available)```\n.\n\nHow do we allocate slots to people such that most people get preferred slots and then 'preferred but not available slots' and nobody gets 'not available'? How do we adapt our existing information above to take into account these 3 choices that people have? Also, how do we further reflect that some people need to be allocated 2 slots?\n\nWe have looked at similar questions, however they carry only 2 choices for people ```\navailable```\n or ```\nnot available```\n.\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Size of maximal subset of directed graph verticies that are not connected?\r\n                \r\nGiven a directed graph, how can I find the size of a maximal subset of verticies such that no two of them are connected by a directed path?\n\nDoes this problem (or the algorithm that solves it) have a common name?\n\n(Hint: \"According to Dilworth's theorem, this problem is actually equivalent to the minimum number of chains cover on a DAG after calculate the transitive closure. Thus, this problem can be reduce to maximum match on bipartite graph.\")\n    ", "Answer": "\r\nI don't know about the name, I guess it's a sub problem of the Disjoint-set data structure\n\nUsing Union Find, you can determine all the connected graph.\n\nInitially, each node is on its group. Check every node and add all its direct children to the node's group root. This is basic Union Find.\n\nThe largest subset is then composed by one vertice from each group.\n\nIn worst case, which when every node is connected to all other nodes, this should take O(n²) as every node is checked n time.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Solving a weighted network flow using Neo4J\r\n                \r\nI have a bipartite graph (guy and girl notes) where nodes are connected with weighted edges (how compatible the girl-guy pair is) and each node has a capacity of 5 (each guy/girl can get matched to 5 people of the opposite gender). I need to find the best possible matching to maximize the weights. \n\nThis can be formulated as a weighted network flow - each guy is a source of 5 units, each girl is a sink of 5 units, and each possible arc has capacity of 1 unit. The problem can be solved either using linear programming, or a graph traversal algorithm (such as  Ford–Fulkerson). \n\nI'm currently looking into possible solutions using Neo4j - does anybody have any idea how to go about it? (or should I just go with a linear programming solution...)\n    ", "Answer": "\r\nI think it is something like this. Find the five most ```\nCOMPATIBLE```\n relationships ordering by the weight of the relationship in descending order and then create them as a separate relationship ```\nMATCH```\n.\n\n```\nmatch (guy:Guy)-[rel:COMPATIBLE]->(girl:Girl)\nwhere guy.id = 'xx'\nwith guy, rel, girl\norder by rel.weight desc\nlimit 5\ncreate (guy)-[:MATCH]->(girl)\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Matching students to courses with course limit (Hungarian, Max Flow, Min-Cost-Flow, ...)\r\n                \r\nI am currently writing a program which maps students to courses. Currently, I am using a SAT-Solver, but I am trying to implement a polynomial time / non greedy algorithm which solves the following sub-problem:\n\n\nThere are students (50-150)\nThere are subjects (10-20), e.g. 'math', 'biology', 'art'\nThere are courses per subject (at least one), e.g. 'math-1', 'math-2', 'biology-1', 'art-1', 'art-2', 'art-3'\nA student selects some (fixed) subjects (10-12) and for each subject the student has to be assigned to exactly one of the existing courses (if possible). It does not matter which course 'math-1' or 'math-2' is being selected.\nThe courses have a maximum number of allowed students (20-34)\nEach course is in a fixed block (= timeslot 1 to 13)\nA student may not be assigned to courses being in the same block\n\n\nI am now describing what I have done so far.\n\n(1) Ignoring the course-student-limit\n\nI was able to solve this with the hungarian algorithm / bipartite matching. Each student may be computed individually by modelling it as following:\n\n\nleft nodes represent the subjects 'math', 'biology', 'art' (of the student)\nright nodes represent the blocks '1', '2', .... '13'\nan edge is inserted for each course from 'subject' to 'block' \n\n\nThis way the student is assigned for every subject to a course while not attending courses which are in the same block. But course-limits are ignored.\n\n(2) Ignoring the selected subjects of the student\n\nI was able to solve this with a max-flow-algorithm. For each student the following is modelled:\n\n\nLayer 1: From source to each student with a flow of 13\nLayer 2: From each student to his/her personal block with a flow of 1\nLayer 3: From each student-block to each course in that block with flow 1\nLayer 4: From each course to the sink with 'max-student-limit'\n\n\nThis way the student selects arbitrary courses and the course-limit is fullfilled. But he/she may be unlucky and be assigned to 'math-1', 'math-2' and 'math-3' ignoring the subjects 'biology' and 'art'.\n\n(3) Greedy Hungarian\n\nAnother idea I had was to match one student at a time with the hungarian algorithm and adjusting the weights so that 'more empty courses' are preferred. For example one could model:\n\n\nleft nodes are subjects of the student\nright nodes are blocks\nfor each course insert an edge from subject to the block of the course with weight = number of free seats\n\n\nAnd then computing a Maximum-Weight-Matching.\n\nI would really appreciate any suggestions / help.\n\nThank you!\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Algorithms, Block Stacking - graph theory\r\n                \r\nI am struggling with this problem for my algorithms class. Its in graph theory section. I think I am suppose to use maximum weighted matching. But not sure how to construct the bipartite graph. Any suggestions?\n\nWe are given n rectangles of sizes a1 × b1, . . . , an × bn. We want to\nbuild the highest tower out of the rectangles. In a tower, if a rectangle of width w is on top of a rectangle of width\nw'\nthen we require w ≤ w'\n. We are allowed to rotate the rectangles (i. e., an a × b rectangle can be changed into a\nb × a rectangle). Give an O(n) algorithm which finds the height of the highest possible tower.\n(For example if the input is 11 × 11, 8 × 2, 1 × 10 then the solution is a tower of height 29 = 11 + 8 + 10.)\n    ", "Answer": "\r\nIf I understand the problem correctly, you can always find the height of the highest possible tower by summing up ```\nMath.max(ai,bi)```\n. Since you don't need to construct the tower, it is only ```\nO(n)```\n. Otherwise you need ```\nO(nlogn)```\n (sort by height of the rectangles).\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "max matching with Edmond Karp\r\n                \r\nI'd please like to ask if someone can please tell me whats wrong with my code.\nI'm trying to solve the problem BerSU Ball on codeforces with Edmond-Karp (I'm aware of the greedy soln)\nProblem: https://codeforces.com/problemset/problem/489/B\nI'm getting a wrong answer on test 37. I'm not able to find my mistake.\nHere is my implementation (The code is clean - adapted from cp-algorithms)\n```\n#include<vector>\n#include<iostream>\n#include<queue>\nusing namespace std;\ntypedef vector<int> vi;\ntypedef vector<vi> vii;\nconst int INF=1e9+5;\nint maxflow(int source, int sink , const vii& graph , vii& capacity);\nint main(){\n    int n;\n    scanf(\"%d\",&n);\n    vi boys(n); \n\n    for(int i = 0 ; i <n ;i++){\n        scanf(\"%d\",&boys[i]);\n    }\n    int m;\n\n    scanf(\"%d\",&m);\n    vi girls(m);\n    for(int i = 0 ; i < m ;i++){\n        scanf(\"%d\",&girls[i]);\n    }\n    int len = n+m+2;\n    int source = len-2;\n    int sink = len-1;\n    vii graph(len);\n    vii capacity(len , vi(len,0));\n    for(int i = 0 ; i < n ; i++){\n        for(int j  = 0 ; j < m ; j++){\n            if(abs(boys[i]-girls[j]) <= 1){\n                graph[i].push_back(j+n);\n                graph[n+j].push_back(i);\n                capacity[i][j+n]=1;\n                capacity[j+n][i]=1;\n            }\n        }\n    }\n    for(int i = 0 ; i < n ;i++){\n        graph[i].push_back(source);\n        graph[source].push_back(i);\n        capacity[i][source]=1;\n        capacity[source][i]=1;\n    }\n\n\n    for(int i = 0 ; i < m ; i++){\n        graph[sink].push_back(n+i);\n        graph[n+i].push_back(sink);\n        capacity[sink][n+i]=1;\n        capacity[n+i][sink]=1;\n    }\n    // for(int i = 0 ; i < len; i++){\n    //      cout << i << \" : \";\n    //      for(int j = 0 ; j < len ; j++){\n    //          cout << capacity[i][j] << \" \";\n    //      }\n    //      cout << endl;\n    //  }\n\n    cout << maxflow(source,sink,graph,capacity) << endl;\n\n    return 0;\n}\n\n\nint bfsEdmond(int source , int sink , const vii& graph , vii& capacity , vi& parent){\n    int len = (int)graph.size();\n    parent.assign(len,-1);\n    parent[source]=-2;\n    queue<pair<int,int>>q;\n    q.push({source,INF});\n    while(!q.empty()){\n        int cnode = q.front().first;\n        int cflow=q.front().second;\n        q.pop();\n        //cout << \"exploring \" << cnode << endl;\n        for(int next: graph[cnode]){\n            //cout << next << \" \" << endl;\n            if(parent[next] == - 1 && capacity[cnode][next]){\n                // explore adjacency list\n                parent[next]=cnode;\n                int newflow = min(cflow,capacity[cnode][next]);\n                if(next == sink){\n                    return newflow;\n                }\n                q.push({next,newflow}); \n            }   \n        }\n    }\n    return 0;\n}\n\nint maxflow(int source, int sink , const vii& graph , vii& capacity){\n    int len = (int)graph.size();\n    vi parent(len);\n    int maxx=0;\n    int cflow=0;\n    while( (cflow = bfsEdmond(source,sink,graph,capacity,parent))){\n        maxx+=cflow;\n        int cnode = sink;\n        while(cnode!=source){\n            int prev = parent[cnode];\n            capacity[prev][cnode]-=cflow;\n            capacity[cnode][prev]+=cflow;\n            cnode=prev;\n            //cout << \"dine \" << endl;\n        }\n    }\n    return maxx;\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Solving Assignment Problem on a dynamically updating tasks and agents\r\n                \r\nI am having agents say A1, A2, A3, and so on. along with tasks say T1, T2, T3, and so on. I have to efficiently assign at most one task to each agent based on some parameter like T1 can be assigned to A1, A2. T2 can be assigned to A2, and A3. and T3 can be assigned to A3, and A1. I have built an unweighted bipartite graph and performed maximum cardinality matching of 1 using the max flow algorithm. Since my list of agents and tasks is changing dynamically. Is there any way where I don't have to rebuild the graph from scratch and rerun the flow algorithm? Can I use the same graph and somehow rerun the max flow algorithm?\n    ", "Answer": "\r\nIt depends on what you mean by \"efficiently assign\".\nAlthough you do not say, I assume that you are optimizing some calculated value that measures how \"efficient\" a particular solution is, compared to others.\nBut perhaps you will be satisfied with a very fast determination of a pretty good solution based on the optimal solution you first found, modified slightly by the change in circumstances ( e.g. assign the cheapest free agent to a new task )  The modified solution might not be optimal, but it will be close or equal.  Every few changes, as the modifications of the optimal solution begin to build up, you can stop and run the whole thing again from scratch.\nHowever, if you insist on the guaranteed optimal solution on every change, then you will have to run from scratch every time.\nIt all depends on whether this is a practical, real world problem you are tackling, where a pretty good, possibly even optimal, solution is fine, or if this is merely an academic exercise.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Organize a trade event || Business \"speed dating\" algorithm\r\n                \r\nI'm Student of software engineering,\nRight now I am working for my final project, scheduling Business matchmaking on a trade day.\n\nThe idea is to bring a seller (developer) and a buyer (A person with financial means) together. The algorithm should be like \"Speed Dating\".\n\nLet's say I have 15 tables and 10 sessions.\nIt means that each session 15 buyers will meet 15 sellers for 20 minutes.\n\nMy question is how do I make the matching?\n\nSuppose each person has 8 attribute that characterize him.\n•   I thinking creating bipartite graph (group A – Sellers, group B - Buyers)\n\n•   Then link up between a seller and buyer based on similar attributes (Should consider what is level of error). dont want to bring together people who are not related\n\n•   Then on each session look for a maximum matching.\n\nConstraints: it's not a real time, I'll close registration a few days before the event. \n\nI'm currently \"idea blocked\" on how to do the linking step (base on a person attributes).\n\nI would appreciate your help,\nEven a dialogue on the matter would help me a lot!:)\n    ", "Answer": "\r\nOften given multi-dimensional data that describe data points, you define a similarity or \"kernel\" between points. This could be the e.g. dot product after you normalize by standard deviation in each dimension for example. Or it could be a Gaussian kernel e^((-d^2)/y) where d is the dot-product between points and y is a constant bandwidth parameter. Also e.g. if certain dimensions are categorical then you could the one-dimensional dot-product to be 1 if the categorical variables agree, otherwise 0. Then you can form the overall dot-product from the multi-dimensional data after normalizing each dimension by its standard deviation. The point is, once you form a similarity or kernel between points, then you can define a weighted bipartite graph where the weight of an edge is equal to the similarity/kernel between points, and your problem is to find a maximum weight matching. This is a well-known problem with solutions in the literature e.g. the Hungarian algorithm, see e.g. http://en.wikipedia.org/wiki/Matching_%28graph_theory%29#In_weighted_bipartite_graphs . \n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Find an algorithm for two meetings occuring at the same time problem\r\n                \r\nI have to solve a simple meeting problem, but i cannot find the right keywords to find a correct mathematic description of the problem i'm trying to solve. Maybe someone can help me there:\nThe problem:\nA number of participants have to meet with each other:\nExemple:\nA have to meet with B and C (ABC)\nP have to meet with O and R (POR)\nA have to meet with D and P (ADP)\nX have to meet with Y and Z (XYZ)\nZ have to meet with O and I (ZOI)\nJ have to meet with S and X (JSX)\nThe constraint is the following: two meetings are occuring at the same time. One person cannot attend two meeting at the same time.\nI have to find a solution for scheduling the meetings:\nWeek 1: ABC (Room 1) - POR (Room 2)\nWeek 2: ADP (Room 1) - XYZ (Room 2)\nWeek 3: ZOI (Room 1) - JSX (Room 2)\nIs a solution\nWeek 1: ABC (Room 1) - ADP (Room 2)\nThis is impossible because A have to be at two meetings at the same time.\nThis exemple is fairly simple, but of course the number of meetings is a lot bigger in the case i waana solve, hence, trying to find an algorithm to solve it in a relevant time.\nCan someone provide a reference to or an algorithm, or the name of the problem?\nDoesn't look like 'Maximum Bipartite Matching' or 'Bin packing'.\n    ", "Answer": "\r\nWhy do you think it isn't a maximum bipartite matching?\nLet's say a node is a set of people who need to meet together. Draw an edge between every pair of nodes that are compatible (have no people in common).\nIn your example, nodes are:\n```\n0 ABC\n1 POR\n2 ADP\n3 XYZ\n4 ZOI\n5 JSX\n```\n\nAnd edges are: (0,1), (0,3), (0,4), (0,5), (1,3), (1,5), (2,3), (2,4), (2,5), (4,5).\nThen the nodes at each end of each edge of a matching are compatible (can meet at the same time). A maximum matching will give you the max number of concurrent pairs of meetings, and if a solution is possible will include all nodes.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Hypergraph assignment?\r\n                \r\nIs there any assigment algorithm that permits to link to groups of elements (nxm), where the nth element can be linked to more than one element in m, but each mth with just one element from n. \n\nThe hungarian algorithm or the Min Cost Flow Problem, consists of finding a matching in a weighted bipartite graph, so it won’t work in my case.\n\nSpecific Problem :\n\nI have a image processing task, where I want to create a cell tracking algorithm. For this I need to apply an assignment method between cells in two correlative images. One cell can divide in two new ones, so my algorithm should allow a double assignment between image I(t) and I(t+dt) ; but since cells can not come from two different cells, my algorithm can’t allow a double assignment between image I(t+dt) and I(t).\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Recommendation engine optimization for newsfeed\r\n                \r\nI am looking to write a recommendation engine to optimize a newsfeed that I want to implement in my app. It would be based on preferences that users pick up during the sign-up phase.\n\nThe logic is the following: a user signs up, and chooses one or several topics of interest amongst 15 of them. In the app, users are able to post content such as photos, text etc..\n\nI wanted to match people using the app with content coming from users that filled the same preferences during the sign up phase (or with a high index of correlation called C).\n\nIn order to do so, I thought about implementing a “relevancy” score that would be attached to each post.\n\nThat score would be calculated as follow: Score= C (index of correlation between the two users’ preferences) x P (popularity of the user who posted the content) x F (freshness of the post in order to display content that has been posted recently). The news feed would then display the posts with the highest to lowest scores in each user’s feed.\n\nThe difficulty here would be to generate a score for each post that would differ for every news feed and to translate that in our database in order to make the right number of requests. I am using Expo (React Native) and Firestore as a database.\n\nHere is a real case example: During the sign up phase let’s say I have the choice between 5 topics of interest: Sport, Photography, Music, Fashion and Travels. I chose Sport and Travels. After completing that phase and ending up on the app’s news feed, I want to be matched with content that is primarily related to Sports and Travels (let’s not even consider weighting the topics here). Therefore, I want to display content from other users that chose the exact same categories (the correlation index would be 1) or the closest (the next best correlation index here would be 0,5).\n\nI would then get content from people that chose Sports and Travels, then content from people that chose Sports or Travels, then content from people that chose Sports and Travels amongst many others (each time reducing our C index).\n\nHow exactly can I translate this into an algorithmic class as I went through a lot of documentation about Assignment problem algorithms, weighted bipartite graphs and combinatorial optimization issues overall but I’m still stuck...\n\nThank you for your time, I really appreciate it.\n    ", "Answer": "\r\nIf there's 15 categories, then a user's preferences can be represented as a 1-bit \"wanted/unwanted\" flag for each category. In other words, a user's preferences can be a simple 15-bit integer.\n\nThe same applies to each news item - it can be put into one or more categories, and which categories it belong to can be represented as another 15-bit integer.\n\nIf you do a bitwise AND of the user's preferences and the categories a news item belongs to; you can count the number of bits set in the result. This count of set bits will give you a score ranging from \"news item matches all categories the user wants\" to \"news item matches none of categories the user wants\". You can use this to filter and/or sort the list of news items.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "How to partition combinations from three categories?\r\n                \r\nI have an array with recipes from 3 categories, breakfast, lunch and dinner. Each of these categories, have 10 unique recipes.\n\n```\n$recipes = [\n    'breakfast' => [\n        0 => [\n            'title' => 'eggless waffles',\n            'calorie' => 210,\n        ],\n        1 => [\n            'title' => 'blueberry oatmeal',\n            'calorie' => 161,\n        ],\n        ...\n     ],\n    'lunch' => [9],\n    'dinner' => [9]\n];\n```\n\n\nI'd like to sort and create a combination of 3 recipes for each day\n\n```\n$days = array_fill(0, 6, [1 => [], 2 => [], 3 => []]);\n```\n\n\nEach recipe has a calorie amount, and each final day should have a combination (consists of 1 breakfast, 1 lunch and 1 dinner) with recipes that was ordered by whichever 3 recipe combo hit closest to 500\n\nFor example, if day 1 combined recipes (breakfast, lunch and dinner) calorie totaled 660, and day 2 was 400. It's possible that switching breakfast from day 2, to day 1 might make both of them hit closest to 500, however it's possible that switching day 3 breakfast to day 1, and day 2 to day 3 might make all 3 hit closer to 500 as well.\n\nSo day 1, 2, 3, 4, 5, 6, and 7 should have 3 recipes (breakfast, lunch and dinner)\n\n```\n$final = [\n    0 => [\n        'breakfast' => [...],\n        'lunch' => [...],\n        'dinner' => [...],\n    ],\n     1 => [\n        'breakfast' => [...],\n        'lunch' => [...],\n        'dinner' => [...],\n    ],\n    2 => [\n        'breakfast' => [...],\n        'lunch' => [...],\n        'dinner' => [...],\n    ],\n    ...\n];\n```\n\n\nIt's been days since I've reached an impasse, and I cannot figure out how to go about sorting these arrays into a combination of 3 for each day. (I know I'm not providing a lot of code to go off of)\n\nEdit 1:\nThis is what I've got so far:\n\n```\nclass Combinations {\n\n    private $days;\n\n    public function __construct(){\n        $this->days = array_fill(1, 7, [1 => [], 2 => [], 3 => []]);\n    }\n\n    public function create(){\n        $median = 600;\n\n        foreach($this->days as $day => $categories){\n            while($this->dayIsIncomplete($day)){\n                $recipes = [];\n                foreach($categories as $category => $value){\n                    $recipes[$category] = $this->getRandomRecipe($category);\n                }\n\n                // add random meals to first day\n                if($day === 1){\n                    $this->days[$day] = $recipes;\n                    continue;\n                }\n\n                foreach($recipes as $category => $recipe){\n                    foreach($this->days as $dayKey => $mealsArray){\n                        $originalMacros = $this->totalMacros($mealsArray);\n\n                        // remove $recipe category from mealsArray, and merge it ($recipe)\n                        $filteredMacros = $this->totalMacros(array_merge([$recipe], array_filter($mealsArray, function($key) use($category){\n                            return $key !== $category;\n                        }, ARRAY_FILTER_USE_KEY)));\n\n                        // if original is not closer to median\n                        if(($originalMacros - $median) * ($originalMacros - $median) < ($filteredMacros - $median) * ($filteredMacros - $median)){\n                            // flip current recipes\n                            // switch D2B ($recipe) with D1B\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    public function getRandomRecipe(int $category){\n        $recipes = []\n\n        if($category === 1){\n            $recipes[] = ['id' => 1, 'calorie' => 310];\n            $recipes[] = ['id' => 2, 'calorie' => 360];\n            $recipes[] = ['id' => 3, 'calorie' => 450];\n            $recipes[] = ['id' => 4, 'calorie' => 330];\n            $recipes[] = ['id' => 5, 'calorie' => 220];\n            $recipes[] = ['id' => 6, 'calorie' => 390];\n            $recipes[] = ['id' => 7, 'calorie' => 400];\n            $recipes[] = ['id' => 8, 'calorie' => 320];\n            $recipes[] = ['id' => 9, 'calorie' => 460];\n        }\n\n        if($category === 2){\n            $recipes[] = ['id' => 10, 'calorie' => 420];\n            $recipes[] = ['id' => 11, 'calorie' => 360];\n            $recipes[] = ['id' => 12, 'calorie' => 450];\n            $recipes[] = ['id' => 13, 'calorie' => 310];\n            $recipes[] = ['id' => 14, 'calorie' => 320];\n            $recipes[] = ['id' => 15, 'calorie' => 490];\n            $recipes[] = ['id' => 16, 'calorie' => 440];\n            $recipes[] = ['id' => 17, 'calorie' => 520];\n            $recipes[] = ['id' => 18, 'calorie' => 560];\n        }\n\n        if($category === 3){\n            $recipes[] = ['id' => 19, 'calorie' => 510];\n            $recipes[] = ['id' => 20, 'calorie' => 660];\n            $recipes[] = ['id' => 21, 'calorie' => 750];\n            $recipes[] = ['id' => 22, 'calorie' => 610];\n            $recipes[] = ['id' => 23, 'calorie' => 580];\n            $recipes[] = ['id' => 24, 'calorie' => 690];\n            $recipes[] = ['id' => 25, 'calorie' => 710];\n            $recipes[] = ['id' => 26, 'calorie' => 620];\n            $recipes[] = ['id' => 27, 'calorie' => 730];\n        }\n\n        return $recipes[array_rand($recipes)];\n    }\n\n    public function dayIsIncomplete($day){\n       return !empty($this->days[$day][1]) && !empty($this->days[$day][2]) && !empty($this->days[$day][3]);\n    }\n\n    public function totalMacros($array){\n        $total = 0;\n        foreach ($array as $key => $value) {\n            $total += $value['calorie'];\n        }\n        return $total / 2;\n    }\n}\n```\n\n\nEdit 2:\n\nI'm trying to figure out what algorithm best fits to sort this issue out. I think using a bipartite matching (maximum) algorithm might be what I need.\n\nEdit 3:\n\nThank you all for taking the time to help, I haven't forgotten about the answers. I had to put this aside for the time being, however soon enough I'll get to it, and the accepted answer will get my remaining 300 bounty.\n    ", "Answer": "\r\nSo I tested a genetic algorithm and it works. I used Jenetics, a Java library (it's not PHP, sorry, but PHP is not suited to heavy computations anyway).\n\nI took 1400 calories as the daily target.\n\nThe function to be minimized is the mean squared error.\n\nHere's the code:\n\n```\nimport java.util.ArrayList;\nimport io.jenetics.*;\nimport io.jenetics.engine.*;\nimport io.jenetics.util.*;\n\npublic class Recipes\n{\n    private static final int TARGET = 1400;\n    private static final int DAYS = 7;\n\n    private static class Recipe\n    {\n        public int id;\n        public int calories;\n\n        public Recipe(int id, int calories)\n        {\n            this.id = id;\n            this.calories = calories;\n        }\n    }\n\n    private static ISeq<Recipe> getSeq(int[] ids, int[] calories)\n    {\n        ArrayList<Recipe> list = new ArrayList<>();\n        for(int i=0;i<ids.length;i++)\n            list.add(new Recipe(ids[i], calories[i]));\n        return ISeq.of(list);\n    }\n\n    private static double meanSquareError(Genotype<EnumGene<Recipe>> gt)\n    {\n        int err = 0;\n        for(int d=0;d<DAYS;d++)\n        {\n            int calories = 0;\n            for(int m=0;m<3;m++)\n                calories += gt.get(m).get(d).allele().calories;\n            err += (calories-TARGET)*(calories-TARGET);\n        }\n        return err / (double)DAYS;\n    }\n\n    public static void main(String[] args)\n    {\n        ISeq<Recipe> recipes1 = getSeq(new int[]{ 1,  2,  3,  4,  5,  6,  7,  8,  9}, new int[]{310, 360, 450, 330, 220, 390, 400, 320, 460});\n        ISeq<Recipe> recipes2 = getSeq(new int[]{10, 11, 12, 13, 14, 15, 16, 17, 18}, new int[]{420, 360, 450, 310, 320, 490, 440, 520, 560});\n        ISeq<Recipe> recipes3 = getSeq(new int[]{19, 20, 21, 22, 23, 24, 25, 26, 27}, new int[]{510, 660, 750, 610, 580, 690, 710, 620, 730});\n\n        Factory<Genotype<EnumGene<Recipe>>> gtf = Genotype.of(\n            PermutationChromosome.of(recipes1, DAYS),\n            PermutationChromosome.of(recipes2, DAYS),\n            PermutationChromosome.of(recipes3, DAYS)\n        );\n\n        Engine<EnumGene<Recipe>, Double> engine = Engine\n            .builder(Recipes::meanSquareError, gtf)\n            .optimize(Optimize.MINIMUM)\n            .populationSize(50)\n            .alterers(new SwapMutator<>(0.2), new PartiallyMatchedCrossover<>(0.2), new Mutator<>(0.01))\n            .build();\n\n        Phenotype<EnumGene<Recipe>, Double> result = engine.stream()\n            .limit(20000)\n            .collect(EvolutionResult.toBestPhenotype());\n\n        for(int m=0;m<3;m++)\n        {\n            for(int d=0;d<DAYS;d++)\n            {\n                Recipe r = result.genotype().get(m).get(d).allele();\n                System.out.print(String.format(\"%2d (%d)  \", r.id, r.calories));\n            }\n            System.out.println();\n        }\n        System.out.println(\"MSE = \" + result.fitness());\n    }\n}\n```\n\n\nA genetic algorithm is non-deterministic so it gives a different result each time. The best solution I could get is:\n\n```\n 3 (450)   4 (330)   5 (220)   2 (360)   7 (400)   1 (310)   8 (320)\n16 (440)  15 (490)  17 (520)  10 (420)  13 (310)  11 (360)  14 (320)\n19 (510)  23 (580)  20 (660)  26 (620)  24 (690)  27 (730)  21 (750)\n\nMSE = 14.285714\n```\n\n\nIt's almost perfect (all days are at 1400 calories except Sunday which has 1390).\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Finding all possible “lists” of possible pairs in Matlab\r\n                \r\nI have been thinking about a problem for the last few days but as I am a beginner in MATLAB, I have no clue how to solve it. Here is the background. Suppose that you have a symmetric ```\nN×N```\n matrix where each element is either ```\n0```\n or ```\n1```\n, and ```\nN = (1,2,...,n)```\n. \n\nFor example:\n\n```\nA =\n\n    0     1     1     0\n\n    1     0     0     1\n\n    1     0     0     0\n\n    0     1     0     0\n```\n\n\nIf ```\nA(i,j) == 1```\n, then it is possible to form the pair ```\n(i,j)```\n and if ```\nA(i,j)==0```\n then it is NOT possible to form the pair ```\n(i,j)```\n. For example, ```\n(1,2)```\n is a possible pair, as ```\nA(1,2)==A(2,1)==1```\n but ```\n(3,4)```\n is NOT a possible pair as ```\nA(3,4)==A(4,3)==0```\n. \n\nHere is the problem. Suppose that a member of the set ```\nN```\n only can for a pair with at most one other distinct member of the set ```\nN```\n (i.e., if 1 forms a pair with 2, then 1 cannot form a pair with 3). How can I find all possible “lists” of possible pairs? In the above example, one “list” would only consist of the pair ```\n(1,2)```\n. If this pair is formed, then it is not possible to form any other pairs. Another “list” would be: ```\n((1,3),(2,4))```\n. I have searched the forum and found that the latter “list” is the maximal matching that can be found, e.g., by using a bipartite graph approach. However, I am not necessarily only interested to find the maximal matching; I am interested in finding ALL possible “lists” of possible pairs. \nAnother example:\n\n```\nA =\n\n    0     1     1     1\n\n    1     0     0     1\n\n    1     0     0     0\n\n    1     1     0     0\n```\n\n\nIn this example, there are three possible lists:\n\n```\n   (1,2)\n   ((1,3),(2,4))\n   (1,4)\n```\n\n\nI hope that you can understand my question, and I apologize if am unclear. I appreciate all help I can get. Many thanks!   \n    ", "Answer": "\r\nThis might be a fast approach.\n\nCode\n\n```\n%// Given data, A\nA =[ 0 1 1 1;\n    1 0 0 1;\n    1 0 0 0;\n    1 1 0 0];\n\n%%// The lists  will be stored in 'out' as a cell array and can be accessed as out{1}, out{2}, etc.\nout = cell(size(A,1)-1,1);\n\n%%// Code that detects the lists using \"selective\" diagonals\nfor k = 1:size(A,1)-1\n    [x,y] = find(triu(A,k).*(~triu(ones(size(A)),k+1)));\n    out(k) = {[x y]};\nend\nout(cellfun('isempty',out))=[]; %%// Remove empty lists\n\n%%// Verification - Print out the lists\nfor k = 1:numel(out)\n    disp(out{k})\nend\n```\n\n\nOutput\n\n```\n 1     2\n\n 1     3\n 2     4\n\n 1     4\n```\n\n\nEDIT 1\n\nBasically I will calculate all the the pairwise indices of the matrix to satisfy the criteria set in the question and then simply map them over the given matrix. The part of finding the \"valid\" indices is obviously the tedious part in it and in this code with some aggressive approach is expensive too when dealing with input matrices of sizes more than 10.\n\nCode\n\n```\n%// Given data, A\nA = [0 1 1 1; 1 0 1 1; 1 1 0 1; 1 1 1 0]\n\n%%// Get all pairwise combinations starting with 1\nall_combs = sortrows(perms(1:size(A,1)));\nall_combs = all_combs(all_combs(:,1)==1,:);\n\n%%// Get the \"valid\" indices\nall_combs_diff = diff(all_combs,1,2);\nvalid_ind_mat = all_combs(all(all_combs_diff(:,1:2:end)>0,2),:);\nvalid_ind_mat = valid_ind_mat(all(diff(valid_ind_mat(:,1:2:end),1,2)>0,2),:);\n\n%%// Map the ones of A onto the valid indices to get the lists in a matrix and then cell array\nout_cell = mat2cell(valid_ind_mat,repmat(1,[1 size(valid_ind_mat,1)]),repmat(2,[1 size(valid_ind_mat,2)/2]));\nA_masked = A(sub2ind(size(A),valid_ind_mat(:,1:2:end),valid_ind_mat(:,2:2:end)));\nout_cell(~A_masked)={[]};\n\n%%// Remove empty lists\nout_cell(all(cellfun('isempty',out_cell),2),:)=[];\n\n%%// Verification - Print out the lists\ndisp('Lists =');\nfor k1 = 1:size(out_cell,1)\n    disp(strcat('  List',num2str(k1),':'));\n    for k2 = 1:size(out_cell,2)\n        if ~isempty(out_cell{k1,k2})\n            disp(out_cell{k1,k2})\n        end\n    end\nend\n```\n\n\nOutput\n\n```\nA =\n\n     0     1     1     1\n     1     0     1     1\n     1     1     0     1\n     1     1     1     0\n\nLists =\n  List1:\n     1     2\n\n     3     4\n\n  List2:\n     1     3\n\n     2     4\n\n  List3:\n     1     4\n\n     2     3\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Maximum weighted Hungarian method Using minimum Hungarian method\r\n                \r\nI have programmed the minimum Hungarian algorithm for a bipartite graph, with Dijkstra's algorithm to find the minimum cost of a maximum matching. However, I want to use such an algorithm to implement the maximum Hungarian algorithm and don't know if it's correct to just negate the edges, because I don't know if the algorithm will handle it.\nMy implementation is based on the explanation on the following site: https://www.ics.uci.edu/~eppstein/163/lecture6b.pdf\nGiven G=(AUB, E), the idea is to label the vertices via an artificial start vertex s which has edges with unsaturated nodes in A, and run Dijkstra's algorithm from s in order to label each vertex, then after labeling each, the edges will be reweighted by their original weight minus the labels of the edge's endpoints.\n\nI have read a lot of articles, and the only I could see is that a minimum Hungarian algorithm can be handled well with maximum cost by negating each edge, however, I am afraid that due to the fact that Dijkstra's algorithm doesn't handle negative edges well, it won't work.\n    ", "Answer": "\r\nFirst find the maximum weight in your graph. Then negate all of the weights and add the maximum weight to them. Adding the original maximum to all of the negated values makes them all positive.\nYou can also use ```\nINT_MAX```\n (or whatever is equivalent to it in the programming language you're using) instead of the maximum weight. This skips the step of finding the maximum weight, but could make the first iteration of the Hungarian Algorithm take longer, or cause you to need an extra iteration of the algorithm to get the result. It probably doesn't make much of a difference either way and the performance difference will vary based on the particular weights in your graph.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Pandas read_csv gives decimal column numbers\r\n                \r\nI've been pulling my hair out trying to make a bipartite graph from a csv file and so far all I have is a panda matrix that looks like this\n\nMy code so far is just\n```\n`\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n# import pyexcel as pe\n# import pyexcel.ext.xlsx\nfrom networkx.algorithms import bipartite\n\nmat = pd.read_csv(\"networkdata3.csv\")\n# mat = pd.read_excel(\"networkdata1.xlsx\",sheet_name=\"sheet_name_1\")\nprint(mat.info)\nsand = nx.from_pandas_adjacency(mat)\n```\n\n`\nand I have no clue what I'm doing wrong. Initially I was trying to read it in as the original xlsx file but then I just converted it to a csv and it started reading. I assume I can't make the graph because the column numbers are decimals and the error that spits out claims that the column numbers don't match up. So how else should I be doing this to actually start making some progress?\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Is it possible to move subgraphs further apart in graphviz\r\n                \r\nI'm drawing a bipartite graph in graphviz and I want it to have two columns of nodes connected by straight lines (to match a style used elsewhere). I can mostly get what I want (see image) but the columns are too close together which makes the edges needlessly hard to follow. \n\nI've tried to add a very low weight connection between the top two nodes in the hope it would push the two subgraphs apart but that doesn't work (and often messes up the rest of the layout). Is there a way of moving the right hand column of nodes further to the right.\n\nHere is an example showing the problem I'm seeing\n\n\n\nand here is the code I used to generate this graph\n\n```\ngraph G {\n      splines=false;\n      node[shape=circle, style=filled]\n      subgraph cluster_1 {\n      subgraph cluster_1r {\n         a12 [label=\"a\",fillcolor=lightgrey]\n         b12 [label=\"b\",fillcolor=lightgrey]\n         c12 [label=\"c\",fillcolor=lightgrey]\n         d12 [label=\"d\",fillcolor=lightgrey]\n         e12 [label=\"e\",fillcolor=lightgrey]\n         a12--b12--c12--d12--e12 [style=invis]\n         }\n      subgraph cluster_1l {\n         a11 [label=\"a\",fillcolor=white]\n         b11 [label=\"b\",fillcolor=white]\n         c11 [label=\"c\",fillcolor=white]\n         d11 [label=\"d\",fillcolor=white]\n         e11 [label=\"e\",fillcolor=white]\n         a11--b11--c11--d11--e11 [style=invis]\n         }\n         c11--a12 [constraint=false]\n         c11--b12 [constraint=false]\n         d11--b12 [constraint=false]\n         e11--a12 [constraint=false]\n         e11--b12 [constraint=false]\n     }\n}\n```\n\n    ", "Answer": "\r\nAdding an invisible node in between the two columns works fine. Basically I added this\n\n```\nsubgraph cluster_1m {\n   color=invis;          \n   a12m [style=invisible]\n   }\n```\n\n\nin between the two subgraphs. This feels quite crude though so any more elegant solutions would be welcomed.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Matching problem with multiples assigment\r\n                \r\nIntroduction\nI have a bipartite graph with workers(W) and Tasks(T).\nTe goal is assign all task to the workers to minimize the maximum time spend. IE finish the last tasks as soon as possible.\nQuestion\n\nWhat modification to the Hungarian algorithm have to be done to accomplish this task.\nIf Hungarian algorithm is not useful what could be a good mathematical approach?\n\nMathematically i don't know how to work with multiple task assignments for workers.\nI will implement it in python once i understand the math theory.\nProblem\nConditions:\n\nA task can only be assigned to one worker\nThere isn't any restriction in the amount of task\nAll task must be assigned\nA worker could have multiple task assigned\nThere isn't any restriction in the amount of workers\nA worker could have no assignation.\nWorkers are not free to start working at the same time\n\nExample\nIf i have 7 task ```\nT={T₁, T₂, T₃, T₄, T₅, T₆, T₇}```\n and 3 workers ```\nW={W₁, W₂, W₃}```\n, workers will be free to start working in ```\nF={4, 7, 8}```\n (where ```\nFᵢ```\n is the time ```\nWᵢ```\n needs to be free to start working) and the cost matrix is:\n\n\nA matching example could be (not necessary correct in this case, is just an example):\n\nW₁ = {T₁, T₂, T₃}\nW₂ = {T₄, T₅}\nW₃ = {T₆, T₇}\n\nin this case the time expend for each worker is:\n\nTime(W₁) = 4+5+4+3 = 16\nTime(W₂) = 7+4+9 = 20\nTime(W₃) = 8+1+7 = 16\n\nExplained as:\n\nFor W₁, we have to wait for:\n\n4 till he is free\nafter that he will finish T₁ in 5\nT₂ in 4\nT₃ in 3\ngiving a total time of 16.\n\n\nFor W₂, we have to wait for:\n\n7 till he is free\nAfter that he will finish T₄ in 4\nT₅ in 9\nGiving a total time of 20.\n\n\nFor W₃, we have to wait for:\n\n8 till he is free\nafter that he will finish T₆ in 1\nT₇ in 7\nGiving a total time of 16.\n\n\n\nGoal\nMinimize the maximum total time. Not the sum of totals.\nIf Total times {9, 6, 6} (sum 21) is a solution then {9, 9, 9} (sum 27) is a solution too and {10, 1, 1} (sum 12) is not because in the first and second case the last task is finished at time 9 and in the third case in time 10.\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "web page change detection\r\n                \r\nCurrently i am doing my project/thesis for the last semester, and i thought of doing it on \"detecting the webpage changes in web\". I have read two paper on this topic but i have some confusions\n\n1. in a paper entitled \n\n\n  An enhanced web page change detection algorithm with application to speeding up mobile web page transcoding 1\n\n\nit is written\n\n\n  first generate subtrees from HTML documents, where each subtree is given a mark according to its tag contents. \n\n\nMy question is here how to generate the subtrees from the HTML documents ?? what is the technique for doing so. and the next question what is it saying by \"giving a mark according to its tag contents\".\n\n2. please look at the image here!! General diagram of proposed approach\n\nIn “Calculate most similar sub-trees” box how matching is done?? in another paper which is entitled \n\n\n  An Efficient Web Page Change Detection System Based on an Optimized Hungarian Algorithm [2]\n\n\nHungarian algorithm is used for matching, a line is quoted from the paper entitled \n\n\n  A fast HTML web page change detection approach based on hashing and reducing the number of similarity computations [3]\n\n\nthe approach in [2] uses the O(N3)Hungarian algorithm to compute the maximum weighted matching on a weighted bipartite graph and has a running time in O(N2 x N1\n3) , where N1 and N2 are, respectively, the number of nodes in the old page and in the new (changed) page.” my question is, as the subtrees are forming why weights are being added, and how they are added ?\n\nThanks for reading my questions/confusions, i really need help here and little soon, please anyone help me with this one, i shall be always grateful.\n    ", "Answer": "\r\nI have a really easy and fast way of doing this I think.\n\nI recently wrote and released jqgram for calculating tree edit distance approximation with an easy-to-use API for comparing DOM-like structures, JSON structures, or tree structures of your own design:\n\nhttps://github.com/hoonto/jqgram\n\nBased on original paper:  http://www.vldb2005.org/program/paper/wed/p301-augsten.pdf\nOriginally ported from Python implementation: https://github.com/Sycondaman/PyGram\n\nThe jqgram tree edit distance approximation module implements the PQ-Gram algorithm for both server-side and browser-side applications; O(n log n) time and O(n) space performant where n is the number of nodes.  The PQ-Gram approximation is much faster than obtaining the true edit distance via Zhang & Shasha, Klein, Guha, or others, whom provide true edit distance algorithms that perform at best O(n^2) or O(n^3) depending on which algorithm you look at.\n\nHere's a start on how I would use jqgram for your specific challenge which I took straight out of the README on github.  To answer one of your questions, you can use the DOM as its own tree structure, in a library such as jQuery (as shown below) or replicate it or generate one from html string in Cheerio or its underlying HTML parsing library or any combination thereof (jqgram provides you this flexibility).  The example here compares the DOM in the current page to a Cheerio representation generated from a string - your known reference.\n\n```\n// This could probably be optimized significantly, but is a real-world\n// example of how to use tree edit distance in the browser.\n\n// For cheerio, you'll have to browserify, \n// which requires some fiddling around\n// due to cheerio's dynamically generated \n// require's (good grief) that browserify \n// does not see due to the static nature \n// of its code analysis (dynamic off-line\n// analysis is hard, but doable).\n//\n// Ultimately, the goal is to end up with \n// something like this in the browser:\nvar cheerio = require('./lib/cheerio');\n\n// But you could use jQuery for both sides of this comparison in which case your\n// lfn and cfn callback functions become the same for both roots. \n\n// The easy part, jqgram:\nvar jq = require(\"../jqgram\").jqgram;\n\n// Make a cheerio DOM:\nvar html = '<body><div id=\"a\"><div class=\"c d\"><span>Irrelevent text</span></div></div></body>';\n\nvar cheeriodom = cheerio.load(html, {\n    ignoreWhitespace: false,\n    lowerCaseTags: true\n});\n\n// For ease, lets assume you have jQuery laoded:\nvar realdom = $('body');\n\n// The lfn and cfn functions allow you to specify\n// how labels and children should be defined:\njq.distance({\n    root: cheeriodom,\n    lfn: function(node){ \n        // We don't have to lowercase this because we already\n        // asked cheerio to do that for us above (lowerCaseTags).\n        return node.name; \n    },\n    cfn: function(node){ \n        // Cheerio maintains attributes in the attribs array:\n        // We're going to put id's and classes in as children \n        // of nodes in our cheerio tree\n        var retarr = []; \n        if(!! node.attribs && !! node.attribs.class){\n            retarr = retarr.concat(node.attribs.class.split(' '));\n        }\n        if(!! node.attribs && !! node.attribs.id){\n            retarr.push(node.attribs.id);\n        }\n        retarr = retarr.concat(node.children);\n        return  retarr;\n    }\n},{\n    root: realdom,\n    lfn: function(node){ \n        return node.nodeName.toLowerCase(); \n    },\n    cfn: function(node){ \n        var retarr = [];\n        if(!! node.attributes && !! node.attributes.class && !! node.attributes.class.nodeValue){\n            retarr = retarr.concat(node.attributes.class.nodeValue.split(' '));\n        }\n        if(!! node.attributes && !! node.attributes.id && !! node.attributes.id.nodeValue) {\n            retarr.push(node.attributes.id.nodeValue);\n        }\n        for(var i=0; i<node.children.length; ++i){\n            retarr.push(node.children[i]);\n        }\n        return retarr;\n    }\n},{ p:2, q:3, depth:10 },\nfunction(result) {\n    console.log(result.distance);\n});\n```\n\n\nNote that the lfn and cfn parameters specify how each tree should determine the node label names and the children array for each tree root independently so that you can compare your DOM to a JSON object or something else that uses different semantics for specifying what are children and what are node labels. Note also in this example that I utilize the DOM entity class attribute, splitting it into its individual classes and the id of the DOM node itself as immediate children of the node in order to provide more clarity on whether two trees are very similar or very different.  You can extend that to include your own attributes.  Or, you can also modify the lfn functions for each tree to include the id in the label like \"tagname:id\" - its up to you and will change how the algorithm performs - perhaps something interesting to investigate in your research.  \n\nSo to summarize all you need to do is provide those lfn and cfn functions along with each root and jqgram will do the rest, calling the lfn and cfn functions to build out the trees. \n\nThe PQ-Gram algorithm implemented by jqgram will provide the edit distance as a number between zero and one and it should be noted that a value of zero does not necessarily indicate absolute equality, only that the two trees are very similar.  If you need to go on to determine if two very similar trees as determined by jqgram are indeed identical you can use Zhang and Shasha, but using jqgram to get the metrics will save you a ton of computations which become extremely critical in client-side browser applications where end-user performance is obviously important.\n\nHope that helps!\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Combinations of \"products\" to form a sales promotion\r\n                \r\nI am re-developing a legacy system that matches a basket of user selected retail products into one or more valid promotions. These promotions are the industry standard BOGOF (buy one get one free), buy two get third free, buy product X and Y and get 10% off, etc... but all require that you can filter the list of potential items into those that satisfy these promotions.\n\nI would like the solution to take an entire basket of retail items and analyse them in one operation, as opposed to the incumbent method of matching a single product as and when it is ordered. (The current solution leads to undesirable limitations)\n\nEach promotion has a series of qualifying products that must be present in order to trigger the promotion. These are arranged in n number of sets (or positions), for example:\n\n```\nExample \"Buy two get third free\" Promotion =\n\n| Item 1 |             | Item 1 |             | Item 2 |\n|   or   |             |   or   |             |   or   |\n| Item 2 |     AND     | Item 4 |     AND     | Item 6 |\n|   or   |             |   or   |             |   or   |\n| Item 3 |             | Item 9 |             | Item 4 |\n\n  Set 1                   Set 2                  Set 3\n```\n\n\nEach promotion must have exactly one product from each group present, unless the item appears in the same set multiple times. The promotion can have an unlimited (but usually < 10) 'sets' of products.\n\nAs a simple example a shopping basket of ```\nItem 1, Item 4 and Item 6```\n would trigger the promotion,\nsimilarly the basket of ```\nItem 1, Item 1 and Item 2```\n would also trigger it.\nHowever the basket of ```\nItem 1, Item 2 and Item 3```\n would not as each set is not satisfied.\n\nAside from the obivious question of the best way to detect when a promotion has been triggered, I will also need to recover the set (position) that the item had been matched into to handle the detail of the pricing etc. It would also be desirable if more expensive (in currency terms) items are favoured over less expensive (equally matched) items when assigning them to the promotion. \n\n\n\nHopefully the next part will aid a solution, not sound so unclear that it will create unnecessary noise, feel free to disregard !\n\nMy best solution so far is to create a new set for each retail item\nin the \"shopping basket\" holding the promotion set (position) that this item will satisfy. \nie.\n\n```\nItem 1 satisifies sets: {1,2}\nItem 4 satisifies sets: {2,3}\nItem 6 satisifies sets: {3}\n```\n\n\nThen my theory is that you \"check\" that this list of sets contains a unique item in each position and that each promotion position is filled. So far my working examples all use brute force, loops or recursion to produce all combinations of the sets (above) in an attempt to check if there is a unique combination. This scales very very badly and with anything other than a very trivial example doesn't work at all in the real world. (This function will be called in realtime as items are added to a basket, so needs to be quick)\n\nLots of research suggest that Bipartite matching would produce some desired outcome, but I can only find research articles and fairly complex mathematical texts on the subject. Some pseudo code or basic logic would be great.\n\n\n\nMy two questions are basically:\n\n1) Does anybody see a better/quicker/simpler way of analysing the customer basket to produce matching promotions.\n2) Assuming I have identified the most efficient way of matching items into the relevant positions, what is the least expensive way of determining the list of retail items to record against the promotion.\n\nAny assistance would be gratefully received as I can no longer see light at the end of the tunnel! \n(The final solution will be in .NET and we use SQL server 2008 R2.)\n    ", "Answer": "\r\nChecking each promotion for validity on a given shopping cart can be reduced to Max Flow. In describing my solution I am assuming you are able to implement and solve a graph-based Max flow problem. If not that is a second problem to solve (and luckily a much more general one).\n\nLet the input to the algorithm be as follows:\n\n\nA set of all valid items ```\nI```\n. Not necessarily used in final coding of algorithm.\nA shopping cart ```\nC```\n of size ```\nn```\n, a subset of ```\nI```\n containing items ```\nC_1 ... C_n```\n. Thus ```\nC = {C_i}```\nfor```\ni = 1...n```\n\nA single promotion ```\nP```\n consisting of ```\nm```\n subsets, each holding a variable number of items. Each subset ```\nS```\n is a subset of ```\nI```\n. Each subset cannot have duplicates, but a single item can be present across multiple subsets. \n\n\nConstruct a graph ```\nG```\n as follows:\n\n\nAdd a super source node, labeled ```\nSOURCE```\n\nAdd a super sink node, labeled ```\nSINK```\n\nFor each unique item ```\nC_i```\n in shopping cart ```\nC```\n, add an available item node ```\nA_i```\n, then add an edge from ```\nSOURCE```\n to ```\nA_i```\n with capacity equal to the number of occurrences of ```\nC_i```\n in ```\nC```\n.\nFor each subset ```\nS_i```\n in promotion ```\nP```\n, add the following:\n\n\nA single set node ```\nS_i```\n, and an edge from ```\nS_i```\n to ```\nSINK```\n with capacity ```\n1```\n. \nFor each required item ```\nI_j```\n for ```\nS_i```\n, a required item node ```\nB_i_j```\n, and an edge from ```\nB_i_j```\n to ```\nS_i```\n with capacity ```\n1```\n.\n\nFinally, for each pair of nodes ```\nA_x```\n and ```\nB_y```\n such that the items they represent are equivalent, an edge from ```\nA_x```\n to ```\nB_y```\n with capacity ```\n1```\n.\n\n\nFinally, run a max flow algorithm with ```\nSOURCE```\n as the source and ```\nSINK```\n as the sink. If the resulting max flow has value equal to the number of subsets (```\nm```\n), then output true - the promotion can be satisfied by this shopping cart. Otherwise output false - the promotion cannot be satisfied by this shopping cart.\n\nFor example, for your set example, with the shopping cart ```\n{1,1,4,6}```\n, the following graph should be created:\n\n\n\n\n\nExpected time complexity, where # of items is ```\nn```\n, and number of subsets in promotion is ```\nm```\n:\n\n\nGraph construction:\n\n\nAdding ```\nSOURCE```\n and ```\nSINK```\n - ```\nO(1)```\n\nAdding unique items from cart and edges from source - ```\nO(N)```\n\nAdding subsets and required item nodes, and edges between - ```\nO(N*M)```\n\nAdding edges from subset nodes to sink - ```\nO(M)```\n\nAdding edges between corresponding item nodes - ```\nO(N^2)```\n\nTotal - ```\nO(N^2 + N*M) = O(N * (N+M))```\n\n\nMax Flow Algorithm - see wikipedia page. Simple implementation cost - ```\nO((N*M)^3)```\n. Can be improved with a more complex algorithm.\nRetrieving solution - ```\nO(1)```\n.\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Counting frequencies with dplyr\r\n                \r\nI'm having a data frame with two columns id_1 and id_2. For each of id_1, I want to count the number of matches it has with all the elements of id_2.\nI imagine the result being a data frame with columns id_1, id_2 and number_of_id_2_found_for_id_1.\nHere's what I'm trying\n```\nset.seed(1)\ndf <- data.frame(\n  id_1 = sample(1:10, size = 30, replace = TRUE),\n  id_2 = sample(1:10, size = 30, replace = TRUE)\n)\n\ndf %>% group_by(id_1, id_2) %>%\n  # id_1 should be unique\n  summarise(~n(.x)) # I want this to be the number of id_2 it has found for each of the elements of id_1\n```\n\nMy expected output would be:\n1    1   0\n1    2   0\n1    3   0\n1    4   1\n1    5   0\n....\n1    9   0\n2    1   0\n...\n2    7   1\n2    8   0\n2    9   1\nAnd so on, basically for each id_1 the number of elements it has found for each_id_2. In the example above it's mostly 1, but in a lot bigger data frame the count would increase. This is like a bipartite graph where the edge would be the number of left-to-right matches between the first component - id_1 and id_2.\nThanks in advance!\n    ", "Answer": "\r\nBased on the updated post, may be we need to do a ```\ncrossing```\n to return all the combinations, do a ```\ncount```\n on the original dataset for both columns and join with the full combination\n```\nlibrary(dplyr)\nlibrary(tidyr)\ncrossing(id_1 = 1:10, id_2 = 1:10)  %>% \n  left_join(., df %>% \n                  count(id_1, id_2)) %>%\n  mutate(n = replace_na(n, 0))\n```\n\n-output\n```\n# A tibble: 100 x 3\n#    id_1  id_2     n\n#   <int> <int> <dbl>\n# 1     1     1     0\n# 2     1     2     0\n# 3     1     3     1\n# 4     1     4     1\n# 5     1     5     0\n# 6     1     6     0\n# 7     1     7     0\n# 8     1     8     0\n# 9     1     9     1\n#10     1    10     0\n# … with 90 more rows\n```\n\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Calling a function inside for loop but how to skip an index inside that function\r\n                \r\nI am trying to code the switch on empty (SOE) algorithm proposed by Yufei Tao in his paper, \"Finding Maximum degrees in hidden bipartite graphs\". I created a function that checks the matching of each element of a list and appends 1 when it matches and appends 0 when it does not. Furthermore, when it appends 0 it switches, as in breaks from the loop.\nNow, this function performs only one iteration. I use a ```\nfor```\n loop to have it perform multiple iterations. But after performing one iteration I need the loop to check in the function the indexes it has already checked and directly go to the indexes that have not been matched yet.\nTo save the indexes already explored I used the concept of memoization and saved them in another list. I did this inside the function. Now I want to perform the loop on the function but need to use the saved indexes list and have the function skip the indexes already explored.\nList C can be taken as some candidates that have qualifications and set B as a job description that shows the requirements. So if a candidate in C has the qualification in B, it forms an edge as 1, and if not then it does not form an edge as 0.\nThis is the example code I have made so far:\n```\nC = [\"s\", \"s\", \"c\", \"d\"]\nB = [\"s\", \"b\", \"e\", \"d\"]\n\ndef code(B,C):\n  idx = []\n  D = []\n  Mat = {}\n  for i in B:\n    D = []\n    idx = []\n    for key,j in enumerate(C):\n      if i == j:\n        D.append(1)\n        idx.append(key)\n      else:\n        D.append(0)\n        idx.append(key)\n        break\n\n    Mat[i] = [D, idx]\n  return Mat\n\nF = {}\nfor i in range(0,len(C)):\n  try:\n      F[i] = code(B,C)\n  except:\n      for value in F[i].items():\n        if value[1] in value:\n          continue\nprint(F)\n```\n\nThe output of F is:\n```\n{0: {'s': [[1, 1, 0], [0, 1, 2]], 'b': [[0], [0]], 'e': [[0], [0]], 'd': [[0], [0]]}, 1: {'s': [[1, 1, 0], [0, 1, 2]], 'b': [[0], [0]], 'e': [[0], [0]], 'd': [[0], [0]]}, 2: {'s': [[1, 1, 0], [0, 1, 2]], 'b': [[0], [0]], 'e': [[0], [0]], 'd': [[0], [0]]}, 3: {'s': [[1, 1, 0], [0, 1, 2]], 'b': [[0], [0]], 'e': [[0], [0]], 'd': [[0], [0]]}}\n```\n\nWhat I need the code to do is in the next iteration, it should start with the next indices, for example, it should be\n```\n    {1: {'s': [1,1,0,0],[0,1,2,3]], 'b': [[0,0],[0,1]], 'e': [[0,0], [0,1]], 'd': [[0,0], [0,1]]} \n```\n\nand so on\n    ", "Answer": "\r\nYou can use function default argument to store values, try this:\n```\ndef f(x,y=[]):\n    y.append(x)\n    return y\n```\n\nf() will remember all arguments it was called with.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "NP-Hardness proof for constrained scheduling with staircase cost\r\n                \r\nI am working on a problem that appears like a variant of the assignment problem. There are tasks that need to be assigned to servers. The sum of costs over servers needs to be minimized. The following conditions hold:\n\n\nEach task has a unit size.\nA task may not be divided among more than one servers. A task must be handled by exactly one server.\nA server has a limit on the maximum number of tasks that may be assigned to it. \nThe cost function for task assignment is a staircase function. A server incurs a minimum cost  'a'. For each task handled by the server, the cost increases by 1. If the number of tasks assigned to a particular server exceeds half of it's capacity, there is a jump in that server's cost equal to a positive number 'd'.\n\n\nTasks have preferences, i.e., a given task may be assigned to one of a few of the servers.\n\n\n\nI have a feeling that this is an NP-Hard problem, but I can't seem to find an NP-Complete problem to map to it. I've tried Bin Packing, Assignment problem, Multiple Knapsacks, bipartite graph matching but none of these problems have all the key characteristics of my problem. Can you please suggest some problem that maps to it?\n\nThanks and best regards\n\nSaqib\n    ", "Answer": "\r\nHave you tried reducing the set partitioning problem to yours? \n\nThe ```\nSET-PART```\n (stands for \"set partitioning\") decision problem asks whether there exists a partition of a given set ```\nS```\n of numbers into two sets ```\nS1```\n and ```\nS2```\n, so that the sum of the elements in ```\nS1```\n equals the sum of elements in ```\nS2```\n. This problem is known to be NP-complete.\n\nYour problem seems related to the ```\nm-PROCESSOR```\n decision problem. Given a nonempty set ```\nA```\n of ```\nn>0```\n tasks ```\n{a1,a2,...,an}```\n with processing times ```\nt1,t2,...,tn```\n, the ```\nm-PROCESSOR```\n problem asks if you can schedule the tasks among ```\nm```\n equal processors so that all tasks finish in at most ```\nk>0```\n time steps. (Processing times are (positive) natural numbers.)\n\nThe reduction of ```\nSET-PART```\n to ```\nm-PROCESSOR```\n is very easy: first show that the special case, with ```\nm=2```\n, is NP-complete; then use this to show that ```\nm-PROCESSOR```\n is NP-complete for all ```\nm>=2```\n. (A reduction in Slovene.)\n\nHope this helps. \n\nEDIT 1: Oops, this ```\nm-PROCESSOR```\n thingy seems very similar to the assignment problem. \n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Algorithm for superimposition of 3d points\r\n                \r\nI need to superimpose two groups of 3D points on top of each other; i.e. find rotation and translation matrices to minimize the RMSD (root mean square deviation) between their coordinates.\n\nI currently use Kabsch algorithm, which is not very useful for many of the cases I need to deal with. Kabsch requires equal number of points in both data sets, plus, it needs to know which point is going to be aligned with which one beforehand. For my case, the number of points will be different, and I don't care which point corresponds to which in the final alignment, as long as the RMSD is minimized.\n\nSo, the algorithm will (presumably) find a 1-1 mapping between the subsets of two point sets such that AFTER rotation&translation, the RMSD is minimized.\n\nI know some algorithms that deal with different number of points, however they all are protein-based, that is, they try to align the backbones together (some continuous segment is aligned with another continuous segment etc), which is not useful for points floating in space, without any connections. (OK, to be clear, some points are connected; but there are points without any connections which I don't want to ignore during superimposition.)\n\nOnly algorithm that I found is DIP-OVL, found in STRAP software module (open source). I tried the code, but the behaviour seems erratic; sometimes it finds good alignments, sometimes it can't align a set of few points with itself after a simple X translation. \n\nAnyone know of an algorithm that deals with such limitations? I'll have at most ~10^2 to ~10^3 points if the performance is an issue.\n\n\n\nTo be honest, the objective function to use is not very clear. RMSD is defined as the RMS of the distance between the corresponding points. If I have two sets with 50 and 100 points, and the algorithm matches 1 or few points within the sets, the resulting RMSD between those few points will be zero, while the overall superposition may not be so great. RMSD between all pairs of points is not a better solution (I think). \n\nOnly thing I can think of is to find the closest point in set X for each point in set Y (so there will be exactly min(|X|,|Y|) matches, e.g. 50 in that case) and calculate RMSD from those matches. But the distance calculation and bipartite matching portion seems too computationally complex to call in a batch fashion. Any help in that area will help as well.\n\nThanks!\n    ", "Answer": "\r\nWhat you said looks like a \"cloud to cloud registration\" task. Take a look into http://en.wikipedia.org/wiki/Iterative_closest_point and http://www.willowgarage.com/blog/2011/04/10/modular-components-point-cloud-registration for example. You can play with your data in open source Point Cloud Library to see if it works for you.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Hopcroft–Karp algorithm in Python\r\n                \r\nI am trying to implement the Hopcroft Karp algorithm in Python using networkx as graph representation.\n\nCurrently I am as far as this:\n\n```\n#Algorithms for bipartite graphs\n\nimport networkx as nx\nimport collections\n\nclass HopcroftKarp(object):\n    INFINITY = -1\n\n    def __init__(self, G):\n        self.G = G\n\n    def match(self):\n        self.N1, self.N2 = self.partition()\n        self.pair = {}\n        self.dist = {}\n        self.q = collections.deque()\n\n        #init\n        for v in self.G:\n            self.pair[v] = None\n            self.dist[v] = HopcroftKarp.INFINITY\n\n        matching = 0\n\n        while self.bfs():\n            for v in self.N1:\n                if self.pair[v] and self.dfs(v):\n                    matching = matching + 1\n\n        return matching\n\n    def dfs(self, v):\n        if v != None:\n            for u in self.G.neighbors_iter(v):\n                if self.dist[ self.pair[u] ] == self.dist[v] + 1 and self.dfs(self.pair[u]):\n                    self.pair[u] = v\n                    self.pair[v] = u\n\n                    return True\n\n            self.dist[v] = HopcroftKarp.INFINITY\n            return False\n\n        return True\n\n    def bfs(self):\n        for v in self.N1:\n            if self.pair[v] == None:\n                self.dist[v] = 0\n                self.q.append(v)\n            else:\n                self.dist[v] = HopcroftKarp.INFINITY\n\n        self.dist[None] = HopcroftKarp.INFINITY\n\n        while len(self.q) > 0:\n            v = self.q.pop()\n            if v != None:\n                for u in self.G.neighbors_iter(v):\n                    if self.dist[ self.pair[u] ] == HopcroftKarp.INFINITY:\n                        self.dist[ self.pair[u] ] = self.dist[v] + 1\n                        self.q.append(self.pair[u])\n\n        return self.dist[None] != HopcroftKarp.INFINITY\n\n\n    def partition(self):\n        return nx.bipartite_sets(self.G)\n```\n\n\nThe algorithm is taken from http://en.wikipedia.org/wiki/Hopcroft%E2%80%93Karp_algorithm\nHowever it does not work. I use the following test code\n\n```\nG = nx.Graph([\n(1,\"a\"), (1,\"c\"),\n(2,\"a\"), (2,\"b\"),\n(3,\"a\"), (3,\"c\"),\n(4,\"d\"), (4,\"e\"),(4,\"f\"),(4,\"g\"),\n(5,\"b\"), (5,\"c\"),\n(6,\"c\"), (6,\"d\")\n])\n\nmatching = HopcroftKarp(G).match()\n\nprint matching\n```\n\n\nUnfortunately this does not work, I end up in an endless loop :(. Can someone spot the error, I am out of ideas and I must admit that I have not yet fully understand the algorithm, so it is mostly an implementation of the pseudo code on wikipedia\n    ", "Answer": "\r\nThe line \n\n```\nif self.pair[v] and self.dfs(v):\n```\n\n\nshould be\n\n```\nif self.pair[v] is None and self.dfs(v):\n```\n\n\nas per the pseudo-code on the Wikipedia page. The only other problem I see is that you are using the deque as a stack and you want to use it as a queue. To remedy that, you just need to popleft rather than pop (which pops right). So the line\n\n```\nv = self.q.pop()\n```\n\n\nshould be\n\n```\nv = self.q.popleft()\n```\n\n\nHopefully everything else works. I was just checking that your Python code works in the same manner as the pseudocode on Wikipedia so hopefully that pseudocode is correct.\n    ", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
{"Question": "Output not shown while running a python code in matlab\r\n                \r\nI have used the thread \nCall Python function from MATLAB \nand have implemented it successfully in Matlab.\n\nHowever, the following code in python reflects no output in Matlab, and due to my lack of familiarity with Python, I can't see where the problem may originate from!\n\nSo here is the python code which takes a graph as input like :\n\n```\nbipartiteMatch({0:[0,1,3],1:[3,4],2:[1,2,4],3:[2,3,4],4:[0,2,3]})\n```\n\n\nand gives the set of maximum matchings in the form above,\n\n```\n# Hopcroft-Karp bipartite max-cardinality matching and max independent set\n# David Eppstein, UC Irvine, 27 Apr 2002\n#import sys\ndef bipartiteMatch(graph):\n'''Find maximum cardinality matching of a bipartite graph (U,V,E).\nThe input format is a dictionary mapping members of U to a list\nof their neighbors in V.  The output is a triple (M,A,B) where M is a\ndictionary mapping members of V to their matches in U, A is the part\nof the maximum independent set in U, and B is the part of the MIS in V.\nThe same object may occur in both U and V, and is treated as two\ndistinct vertices if this happens.'''\n\n# initialize greedy matching (redundant, but faster than full search)\nmatching = {}\nfor u in graph:\n    for v in graph[u]:\n        if v not in matching:\n            matching[v] = u\n            break\n\nwhile 1:\n    # structure residual graph into layers\n    # pred[u] gives the neighbor in the previous layer for u in U\n    # preds[v] gives a list of neighbors in the previous layer for v in V\n    # unmatched gives a list of unmatched vertices in final layer of V,\n    # and is also used as a flag value for pred[u] when u is in the first       layer\n    preds = {}\n    unmatched = []\n    pred = dict([(u,unmatched) for u in graph])\n    for v in matching:\n        del pred[matching[v]]\n    layer = list(pred)\n\n    # repeatedly extend layering structure by another pair of layers\n    while layer and not unmatched:\n        newLayer = {}\n        for u in layer:\n            for v in graph[u]:\n                if v not in preds:\n                    newLayer.setdefault(v,[]).append(u)\n        layer = []\n        for v in newLayer:\n            preds[v] = newLayer[v]\n            if v in matching:\n                layer.append(matching[v])\n                pred[matching[v]] = v\n            else:\n                unmatched.append(v)\n\n    # did we finish layering without finding any alternating paths?\n    if not unmatched:\n        unlayered = {}\n        for u in graph:\n            for v in graph[u]:\n                if v not in preds:\n                    unlayered[v] = None\n        return (matching,list(pred),list(unlayered))\n\n    # recursively search backward through layers to find alternating paths\n    # recursion returns true if found path, false otherwise\n    def recurse(v):\n        if v in preds:\n            L = preds[v]\n            del preds[v]\n            for u in L:\n                if u in pred:\n                    pu = pred[u]\n                    del pred[u]\n                    if pu is unmatched or recurse(pu):\n                        matching[v] = u\n                        return 1\n        return 0\n\n    for v in unmatched: recurse(v)\n```\n\n\nI can see the output and run the code in python successfully, but the output is not shown in Matlab and returns ```\n\" \"```\n as the answer. \n\nSo any kind of help is extremely appreciated!\n    ", "Answer": "", "Knowledge_point": "Bipartite Matching", "Tag": "算法分析"}
