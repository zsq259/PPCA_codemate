{"Question": "Algorithm: How to find the number of independent sets in a tree?\r\n                \r\nI'm thinking that there are two cases for each sub-tree: the root is in the independent set and the root is not in the set. How to write a recursive algorithm for finding the number of independent sets in a tree? The tree is n-ary.\n\nhttps://en.wikipedia.org/wiki/Independent_set_(graph_theory)\n\nThis is my solution so far, but it isn't correct. The variable parentIncluded is equal to true if the parent of the current subtree is already included in the independent set, thus the root of the current subtree can't be added to the independent set. If parentIncluded is equal to false, then the root of the current subtree can be added to the independent set. There are two cases for when parentIncluded is false. The first case: Add the root to the set. Second case: don't add the root.\n\n```\npublic static int numberOfIndependentSets(Binary root) {\n        if (root == null) {\n            return 1;\n        }\n        return numberOfIndependentSets(root, false) + 1;\n    }\n\n    private static int numberOfIndependentSets(Binary current, boolean parentIncluded) {\n        if (current.left == null && current.right == null) {\n            if (parentIncluded) {\n                return 0;\n            } else {\n                return 1;\n            }\n        }\n        int total = 0;\n        if (parentIncluded) {\n            int left = numberOfIndependentSets(current.left, false);\n            int right = numberOfIndependentSets(current.right, false);\n           total += (left + 1) * (right + 1) - 1;\n        } else {\n            // include current node\n            int left = numberOfIndependentSets(current.left, true);\n            int right = numberOfIndependentSets(current.right, true);\n            total = (left+1) *( right +1);\n\n            // not include current node\n            left = numberOfIndependentSets(current.left, false);\n            right = numberOfIndependentSets(current.right, false);\n            total += (left+1) * (right+1) -1;\n        }\n        return total;\n    }\n```\n\n    ", "Answer": "\r\nYour basic idea should work.\n\nYou could defined two mutually recursive functions on the set of rooted trees:\n\n```\nf(T) = number of independent sets containing the root\ng(T) = number of independent sets not containing the root\n```\n\n\nYou want to compute ```\nf(T) + g(T)```\n\n\nFor 1-node trees, ```\nL```\n, as basis cases we have:\n\n```\nf(L) = 1\ng(L) = 1\n```\n\n\nSay that ```\nT_1, T_2, .. T_n```\n are the subtrees of the root. Then the recursive equations are:\n\n```\nf(T) = g(T_1)*g(T_2)* ... *g(T_n)\ng(T) = (f(T_1)+g(T_1))*(f(T_2)+g(T_2)) * ... * (f(T_n)+g(T_n))\n```\n\n\nAs a check: you can use this to get the number of independent sets of full binary trees with ```\nn```\n levels (equivalently, height ```\nn-1```\n). Make the ```\nf```\n, ```\ng```\n a function of level. A Python implementation:\n\n```\ndef f(n):\n    if n == 1:\n        return 1\n    else:\n        return (g(n-1))**2\n\ndef g(n):\n    if n == 1:\n        return 1\n    else:\n        return (f(n-1) + g(n-1))**2\n\ndef h(n): return f(n)+g(n)\n```\n\n\n```\n[h(n) for n in range(1,7)]```\n evaluates to\n\n```\n2, 5, 41, 2306, 8143397, 94592167328105\n```\n\n\nThis is sequence A076725 in the Online Encyclopedia (slightly shifted) which is described as \"the number of independent sets on a complete binary tree with 2^(n-1)-1 nodes\", so it seems that this approach makes sense.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "algorithm to find max independent set in a tree\r\n                \r\nI need an algorithm to find max independent set in a tree. I'm thinking start from all leaf nodes, and then delete the direct parent nodes to these leaf nodes, then choose the parent nodes of the parent nodes we deleted, repeat this procedure recursively until we get to root. and is this done in O(n) time? any reply is appreciated. thanks.\n\nAnd could anyone please point me an algorithm to find the max dominating set in a tree.\n    ", "Answer": "\r\nMAXIMUM INDEPENDENT SET\n\nYou can compute the maximum independent set by a depth first search through the tree.\n\nThe search will compute two values for each subtree in the graph:\n\n\nA(i) = The size of the maximum independent set in the subtree rooted at i with the constraint that node i must be included in the set.\nB(i) = The size of the maximum independent set in the subtree rooted at i with the restriction that node i must NOT be included in the set.\n\n\nThese can be computed recursively by considering two cases:\n\n\nThe root of the subtree is not included.\n\nB(i) = sum(max(A(j),B(j)) for j in children(i))\nThe root of the subtree is included.\n\nA(i) = 1 + sum(B(j) for j in children(i)) \n\n\nThe size of the maximum independent set in the whole tree is max(A(root),B(root)).\n\nMAXIMAL DOMINATING SET\n\nAccording to the definition of dominating set in wikipedia the maximum dominating set is always trivially equal to including every node in the graph - but this is probably not what you mean?\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Maximum independent set in a tree. Review algorithm, need proof\r\n                \r\npseudocode:\n\n```\nvoid recursive('k'){ // 'k' and 'i' vertices\n  sumA = 0;\n  sumB = 0;\n  for each non visited 'i' neighbor do{\n     recursive('i');\n     sumA = sumA + b['i'];\n     sumB = sumB + max(a['i'], b['i']);\n     }\n  a['k'] = 1 + sumA;\n  b['k'] = sumB;\n  }\n\n\nvoid main(){\n a = b = 0; //initialize tables with 0 (zeros)\n recursive('X');  //let 'X' be an arbitrary root\n cout<<max(a['X'], b['X']);\n }\n```\n\n\nneed proof that ```\nmax(a['X'], b['X'])```\n is the cardinal of the maximum independent set in the tree.\nWhat am I missing ?\n\nThank you in advance.\n    ", "Answer": "\r\nThe element a[i] is the size of the maximal independent set in the subtree rooted in i which contains i.\n\nThe element b[i] is the size of the maximal independent set in the subtree rooted in i which doesn't contain i.\n\nThe algorithm computes these recursively, and then chooses the maximal of the two at the root.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Maximum independent set on non-tree representations\r\n                \r\nWhen attempting to derive the maximum (largest size) independent set on a graph of nodes, a solution can be arrived when the graph is a forest/tree structure. The general pseudocode for this implementation is below.\n```\n    S is an empty set\n    While forest F has at least 1 edge\n         Let v be a leaf node and let (u,v) be a lone edge incident to v\n         Add v to s\n    Delete both u and v from the forest, including all incident edges\n    Return s + nodes remaining in forest F\n```\n\nI was wondering, if this graph is not a forest/tree (does not follow the definition) but is instead some other representation, there are obvious reasons as to why this implementation would not work, however is it possible that this algorithm could still provide an independent set within that graph, just not the maximum (largest sized) one? If so, what would that graph look like?\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Finding size of max independent set in binary tree - why faulty \"solution\" doesn't work?\r\n                \r\nHere is a link to a similar question with a good answer: Java Algorithm for finding the largest set of independent nodes in a binary tree.\n\nI came up with a different answer, but my professor says it won't work and I'd like to know why (he doesn't answer email).\n\nThe question:\n\n\n  Given an array A with n integers, its indexes start with 0 (i.e, ```\nA[0]```\n,\n  ```\nA[1]```\n, …, ```\nA[n-1]```\n). We can interpret A as a binary tree in which the two\n  children of ```\nA[i]```\n are ```\nA[2i+1]```\n and ```\nA[2i+2]```\n, and the value of each\n  element is the node weight of the tree. In this tree, we say that a\n  set of vertices is \"independent\" if it does not contain any\n  parent-child pair. The weight of an independent set is just the\n  summation of all weights of its elements. Develop an algorithm to\n  calculate the maximum weight of any independent set.\n\n\nThe answer I came up with used the following two assumptions about independent sets in a binary tree:\n\n\nAll nodes on the same level are independent from each other.\nAll nodes on alternating levels are independent from each other (there are no parent/child relations)\n\n\nWarning: I came up with this during my exam, and it isn't pretty, but I just want to see if I can argue for at least partial credit.\n\nSo, why can't you just build two independent sets (one for odd levels, one for even levels)?\n\nIf any of the weights in each set are non-negative, sum them (discarding the negative elements because that won't contribute to a largest weight set) to find the independent set with the largest weight.\n\nIf the weights in the set are all negative (or equal to 0), sort it and return the negative number closest to 0 for the weight.\n\nCompare the weights of the largest independent set from each of the two sets and return it as the final solution. \n\nMy professor claims it won't work, but I don't see why. Why won't it work?\n    ", "Answer": "\r\nInterjay has noted why your answer is incorrect. The problem can be solved with a recursive algorithm ```\nfind-max-independent```\n which, given a binary tree, considers two cases:\n\n\nWhat is the max-independent set given that the root node is\nincluded? \nWhat is the max-independent set given that the root node\nis not included?\n\n\nIn case 1, since the root node is included, neither of its children can. Thus we sum the value of ```\nfind-max-independent```\n of the grandchildren of root, plus the value of root (which must be included), and return that.\n\nIn case 2, we return the max value of ```\nfind-max-independent```\n of the children nodes, if any (we can pick only one)\n\nThe algorithm may look something like this (in python):\n\n```\ndef find_max_independent ( A ):\n    N=len(A)\n\n    def children ( i ):\n        for n in (2*i+1, 2*i+2):\n            if n<N: yield n\n\n    def gchildren ( i ):\n        for child in children(i):\n            for gchild in children(child):\n                yield gchild\n\n    memo=[None]*N\n\n    def rec ( root ):\n        \"finds max independent set in subtree tree rooted at root. memoizes results\"\n\n        assert(root<N)\n\n        if memo[root] != None:\n            return memo[root]\n\n        # option 'root not included': find the child with the max independent subset value\n        without_root = sum(rec(child) for child in children(root))\n\n        # option 'root included': possibly pick the root\n        # and the sum of the max value for the grandchildren\n        with_root =  max(0, A[root]) + sum(rec(gchild) for gchild in gchildren(root))\n\n        val=max(with_root, without_root)\n        assert(val>=0)\n        memo[root]=val\n\n        return val\n\n\n    return rec(0) if N>0 else 0\n```\n\n\nSome test cases illustrated:\n\n```\ntests=[\n    [[1,2,3,4,5,6], 16], #1\n    [[-100,2,3,4,5,6], 6], #2\n    [[1,200,3,4,5,6], 200], #3\n    [[1,2,3,-4,5,-6], 6], #4\n    [[], 0],\n    [[-1], 0],\n]\n\nfor A, expected in tests:\n    actual=find_max_independent(A)\n    print(\"test: {}, expected: {}, actual: {} ({})\".format(A, expected, actual, expected==actual))\n```\n\n\nSample output:\n\n```\ntest: [1, 2, 3, 4, 5, 6], expected: 16, actual: 16 (True)\ntest: [-100, 2, 3, 4, 5, 6], expected: 15, actual: 15 (True)\ntest: [1, 200, 3, 4, 5, 6], expected: 206, actual: 206 (True)\ntest: [1, 2, 3, -4, 5, -6], expected: 8, actual: 8 (True)\ntest: [], expected: 0, actual: 0 (True)\ntest: [-1], expected: 0, actual: 0 (True)\n```\n\n\nTest case 1 \n\n\n\nTest case 2\n\n\n\nTest case 3\n\n\n\nTest case 4\n\n\n\nThe complexity of the memoized algorithm is ```\nO(n)```\n, since ```\nrec(n)```\n is called once for each node. This is a top-down dynamic programming solution using depth-first-search.\n\n(Test case illustrations courtesy of leetcode's interactive binary tree editor)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Algorithm count of independent sets, always down by 1\r\n                \r\nI'm having trouble writing an algorithm to count the number of independent sets in a tree. (An independent set is where any two nodes have no edge between them.)\n\nHere is my java class for ListNode:\n\n```\n 1public class ListNode\n 2{\n 3    private Object data;\n 4    private ListNode next;\n 5\n 6    public ListNode(Object data, ListNode next)\n 7    {\n 8        this.data = data;\n 9        this.next = next;\n10    }\n11\n12    public Object getData()  {return data;}\n13    public ListNode getNext(){return next;}\n14    public void setNext(ListNode n){next = n;}\n15    public void setData(Object d){data = d;}\n16    public boolean search(ListNode l, Object o)\n17    {\n18        while (l != null){\n19            if (l.getData().equals(o))\n20                return true;\n21            l = l.getNext();\n22        }\n23        return false;\n24    }\n25    public static ListNode rev(ListNode curr)\n26    {\n27        ListNode rev = null;\n28        while (curr != null){\n29            rev = new ListNode(curr.getData(), rev);\n30            curr = curr.getNext();\n31        }\n32        return rev;}}\n```\n\n\nAnd my java class for the TreeNode:\n\n```\n1public class TreeNode\n 2{   ListNode children = null;\n 3    public void addChild(TreeNode t)\n 4    {\n 5        if (children == null)\n 6            children = new ListNode(t, null);\n 7        else{\n 8            ListNode curr = children;\n 9            while (curr.getNext() != null)\n10                curr = curr.getNext();\n11            curr.setNext(new ListNode(t, null));\n12        }}\n13    public void setChildren(ListNode t){this.children = t;}\n14    public int numStableSet()\n15    {\n16\n17        if (children == null || children.getNext() == null)\n18            return 2;\n19        else{\n20            int count = 2;\n21            setChildren(children.getNext());\n22            count *= numStableSet();\n23            return count;\n24        }\n25    }\n```\n\n\nThe method numStableSet is the one where I need some coding help. As it is set up now, it prints out 1 less than the correct answer. I also haven't figured out the case where each Node could be a tree itself.\n\nHelp appreciated\n    ", "Answer": "\r\nI don't trust that your algorithm will always be off by one. Let's consider a few example cases, starting with the most simple ones.\n\n\nNo node => 1 independent set, the empty set\nOne node => 2 independent set, empty and the one node\nOne parent and its sole child => 3 independent sets, empty and either node\n\n\nSince your code seems to give the same result of 2 for both the single node and the node with single child, I believe your code to be wrong.\n\nNow let's consider the recursive case, to find the right algorithm. You are currently visiting a given node. You could decide to not include that node in the stable set, then visit all its children and choose arbitrary stable sets for these. Or you could decide to include the current node, but only if its own parent was not included, and when recursing to the children you have to ensure not to count those. Keep track of all the possible ways to combine these choices, and you have your count. In pythonic pseudocode:\n\n```\ndef combinationsWithoutCurrent(current):\n  num = 1\n  for child in current:\n    num *= stableSet(child)\n  return num\n\ndef combinationsWithCurrent(current):\n  num = 1\n  for child in current:\n    num *= combinationsWithoutCurrent(child)\n  return num\n\ndef stableSet(current):\n  return (combinationsWithCurrent(current) +\n          combinationsWithoutCurrent(current))\n```\n\n\nAs you prefer Java and obscure hand-made container classes, here is some Java code on how I guess your data structures are intended. Since you never call ```\ngetData```\n in the tree traversal, I can't see any actual recursion going on in your code. So my guess might be wrong.\n\n```\nprivate int combinationsWithoutCurrent() {\n  int num = 1;\n  for (ListNode iter = children; iter != null; iter = iter.getNext())\n    num *= ((TreeNode)iter.getData()).numStableSets();\n  return num;\n}\n\nprivate int combinationsWithCurrent() {\n  int num = 1;\n  for (ListNode iter = children; iter != null; iter = iter.getNext())\n    num *= ((TreeNode)iter.getData()).combinationsWithoutCurrent();\n  return num;\n}\n\npublic int numStableSet() {\n  return combinationsWithCurrent() + combinationsWithoutCurrent();\n}\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to find maximum weight independent set for a tree using dynamic programming\r\n                \r\nI have this problem that I am trying to solve:\n\nYou are given a tree T with n nodes. Each node has a non-negative weight assigned to it. Our goal is to\nfind a set S of nodes such that (i)no two nodes in S are adjacent, and (ii)the total weight of all vertices\nin S is maximal. Such a set is called maximum weight independent set.\nAssignment\nImplement a Dynamic Programming algorithm that finds a maximum weight independent set for a given\ntree in O(n)time. If there are multiple such sets, return a set with maximum number of nodes.\nImplementation\n\nI looked everywhere but I couldn't find the answer for a tree (not a path!). By the way, the tree is implemented using an edges double array, and an array of weights. Can someone help me solve it?\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "maximum independent set weight\r\n                \r\nI'm trying to solve the problem outlined in this previously asked question:\n\nFinding size of max independent set in binary tree - why faulty \"solution\" doesn't work?\n\n\n  Given an array A with n integers, its indexes start with 0 (i.e, A[0],  A[1], …, A[n-1]). We can interpret A as a binary tree in which the two children of A[i] are A[2i+1] and A[2i+2], and the value of each element is the node weight of the tree. In this tree, we say that a set of vertices is \"independent\" if it does not contain any parent-child pair. The weight of an independent set is just the summation of all weights of its elements. Develop an algorithm to calculate the maximum weight of any independent set.\n\n\nHowever, I'm trying to solve this in Java. I have looked at the python solution in the linked question, but this line doesn't make sense to me:\n\n```\nwith_root = sum(map(find_max_independent, grandkids))+ max(true_root[root_i],0)\n```\n\n\nIs there a Java equivalent of this solution?\n    ", "Answer": "\r\nOf course there is a Java equivalent. Though might depend on what you mean with \"equivalent\". I'm not fluent in current Java, so I'll just make sense of that line for you.\n\nThe part ```\nsum(map(find_max_independent, grandkids))```\n means:\n\n```\nfind_max_independent(grandkids[0]) + find_max_independent(grandkids[1]) + ...\n```\n\n\nAnd ```\nmax(true_root[root_i], 0)```\n is just the weight of the current node if it's not negative, and zero otherwise (note the weights are just known to be \"integers\", so they could be negative). Although, that's really not necessary to check, as using the zero means not including the node, which is already covered by ```\nwithout_root```\n.\n\nThat algorithm is btw not O(n) as claimed, I wrote a comment there already. Here's one that actually is, and which is also simpler:\n\n```\ndef max_independant_weight(weights):\n    def with_and_without(i):\n        if i >= len(weights):\n            return 0, 0\n        left  = with_and_without(2*i + 1)\n        right = with_and_without(2*i + 2)\n        return (weights[i] + left[1] + right[1],\n                max(left) + max(right))\n    return max(with_and_without(0))\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to correctly implement maximum weight independent set of positive tree using BFS\r\n                \r\ncan someone help me implement the maximum weight independent set for a TREE (not a graph)?\nThe tree is represented by an adjacency matrix, and we have an array for the weights of the vertices.\nBFS output: // 0: distances from start vertex\n// 1: BFS-order\n// 2: parent-IDs\nI tried this code, it doesn't work on all test cases and it says most of the time that the weight is too small.\nCan someone help me find the errors?\n```\nimport java.io.*;\nimport java.util.*;\n\npublic class Lab5\n{\n\n    /**\n     *  Problem: Find a maximum weight independent set using dynammic programming.\n     */\n    \n    \n    private static int[] problem(Tree t, int[] weights)\n    {\n        // Implement me!\n        \n        //base cases\n        if (t.noOfVertices==0) {\n            return new int[] {};\n        }\n        if (t.noOfVertices==1) {\n            return new int[] {weights[0]};\n        }\n        \n        //we will implement this using bfs, we will use 0 as the root\n        int[][] bfs = t.bfs(0);\n        \n        //finding leaves\n        int leaf[] = new int [t.noOfVertices];\n        \n        //now we can implement our algorithm\n        //M is the maximum weight of the tree if it contains i, and M1 is the maximum weight of the tree if it doesn't contain i\n        int M[]=new int[t.noOfVertices];\n        int M1[]=new int[t.noOfVertices];\n        \n        //treating elements that aren't leaves\n        int nodeDiscovered[] = new int[t.noOfVertices];\n        \n        \n        for (int i = 0; i<t.noOfVertices; i++) {\n            if (t.edges[i].length==1) {\n                leaf[i]=1;\n                M[i]=weights[i];\n                nodeDiscovered[i]=1;\n                M1[i]=0;\n            }\n            else {\n                leaf[i]=0;  \n                nodeDiscovered[i]=0;\n                }\n        }\n    \n        for (int i = 1; i<t.noOfVertices; i++) {\n            if (leaf[i]==1) {\n                int node = bfs[2][i];\n                if (nodeDiscovered[node]!=0) {\n                    continue;\n                }\n                while (node>-1) {\n                    int parent = bfs[2][node];\n                    ArrayList<Integer> sibs = new ArrayList<Integer>();\n                    if (parent!=-1) {\n                        for (int j = 0; j<t.edges[parent].length; j++) {\n                            if (t.edges[parent][j]!=bfs[2][parent]) {\n                                sibs.add(t.edges[parent][j]);\n                            }\n                        }\n                    }\n                    else {\n                        sibs.add(node);\n                    }\n                    for (int sib : sibs) {\n                        if (nodeDiscovered[sib]!=0) {\n                            continue;\n                        }\n                        M[sib]=weights[sib];\n                        for (int k : t.edges[sib]) {\n                            if(bfs[0][sib]==bfs[0][k]-1) {\n                                M[sib]=M[sib]+M1[k];\n                                M1[sib]+=(M[k]>M1[k])?M[k]:M1[k];\n                            }\n                        }\n                        nodeDiscovered[sib]=1;\n                    }\n                    \n                    node = bfs[2][node];\n                }\n                \n            }\n        }\n        //putting the answers in an arraylist\n        ArrayList<Integer> set = new ArrayList<Integer>();\n        if (M[0]>M1[0]) {\n            set.add(0);\n        }\n        for (int i = 1; i<t.noOfVertices; i++) {\n            if (!set.contains(bfs[2][i]) && M[i]>=M1[i] ) {\n                set.add(i);\n            }\n        }\n        System.out.println(set);\n        //putting the elements of the arraylist into an array of int\n        int[] set1 = new int[set.size()];\n        for (int i = 0; i<set.size(); i++) {\n            set1[i]=set.get(i);\n        }\n        return set1;\n        \n    }\n\n    // ---------------------------------------------------------------------\n    // Do not change any of the code below!\n    // Do not change any of the code below!\n\n    /**\n     *  Determines if a given set of vertices is an independent set for the given tree.\n     */\n    private static boolean isIndSet(Tree t, int[] set)\n    {\n        if (set == null) return false;\n\n        boolean[] covered = new boolean[t.noOfVertices];\n\n        for (int i = 0; i < set.length; i++)\n        {\n            int vId = set[i];\n            int[] neighs = t.edges[vId];\n\n            if (covered[vId]) return false;\n            covered[vId] = true;\n\n            for (int j = 0; j < neighs.length; j++)\n            {\n                int nId = neighs[j];\n                covered[nId] = true;\n            }\n        }\n\n        return true;\n    }\n\n    private static final int LabNo = 5;\n    private static final String course = \"CS 427\";\n    private static final String quarter = \"Fall 2021\";\n    private static final Random rng = new Random(190817);\n\n    private static boolean testProblem(int[][] testCase)\n    {\n        int[] parents = testCase[0];\n        int[] weights = testCase[1];\n\n        Tree t = Tree.fromParents(parents);\n\n        int[] solution = maxIsWeight(t, weights);\n        int isWeight = solution[0];\n        int isSize = solution[1];\n\n        int[] answer = problem(t, weights.clone());\n\n        if (!isIndSet(t, answer))\n        {\n            System.out.println(\"Not an independent set.\");\n            return false;\n        }\n\n        int ansWeight = 0;\n        for (int i = 0; i < answer.length; i++)\n        {\n            ansWeight += weights[answer[i]];\n        }\n\n        if (ansWeight < isWeight)\n        {\n            System.out.println(\"Weight too small.\");\n            return false;\n        }\n\n        if (answer.length < isSize)\n        {\n            System.out.println(\"Set too small.\");\n            return false;\n        }\n\n        return true;\n    }\n\n    private static int[] maxIsWeight(Tree t, int[] weigh)\n    {\n        int n = t.noOfVertices;\n\n        int[][] dfs = t.dfs(0);\n        int[] post = dfs[2];\n\n        int[] w = new int[n];\n        for (int i = 0; i < n; i++)\n        {\n            w[i] = weigh[i] * n + 1;\n        }\n\n        boolean[] isCandidate = new boolean[n];\n\n        for (int i = 0; i < n; i++)\n        {\n            int vId = post[i];\n            if (w[vId] <= 0) continue;\n\n            isCandidate[vId] = true;\n\n            int[] neighs = t.edges[vId];\n            for (int j = 0; j < neighs.length; j++)\n            {\n                int uId = neighs[j];\n                w[uId] = Math.max(w[uId] - w[vId], 0);\n            }\n        }\n\n        int isWeight = 0;\n        int isSize = 0;\n\n        for (int i = n - 1; i >= 0; i--)\n        {\n            int vId = post[i];\n            if (!isCandidate[vId]) continue;\n\n            isWeight += weigh[vId];\n            isSize++;\n\n            int[] neighs = t.edges[vId];\n            for (int j = 0; j < neighs.length; j++)\n            {\n                int uId = neighs[j];\n                isCandidate[uId] = false;\n            }\n        }\n\n        return new int[] { isWeight, isSize };\n    }\n\n    public static void main(String args[])\n    {\n        System.out.println(course + \" -- \" + quarter + \" -- Lab \" + LabNo);\n\n        int noOfTests = 300;\n        boolean passedAll = true;\n\n        System.out.println(\"-- -- -- -- --\");\n        System.out.println(noOfTests + \" random test cases.\");\n\n        for (int i = 1; i <= noOfTests; i++)\n        {\n            boolean passed = false;\n            boolean exce = false;\n\n            try\n            {\n                int[][] testCase = createProblem(i);\n                passed = testProblem(testCase);\n            }\n            catch (Exception ex)\n            {\n                passed = false;\n                exce = true;\n                ex.printStackTrace();\n            }\n\n            if (!passed)\n            {\n                System.out.println(\"Test \" + i + \" failed!\" + (exce ? \" (Exception)\" : \"\"));\n                passedAll = false;\n               //break;\n            }\n        }\n\n        if (passedAll)\n        {\n            System.out.println(\"All test passed.\");\n        }\n\n    }\n\n    private static int[][] createProblem(int testNo)\n    {\n        int size = rng.nextInt(Math.min(testNo, 5000)) + 5;\n\n        // -- Generate tree. ---\n\n        int[] parents = new int[size];\n        parents[0] = -1;\n\n        for (int i = 1; i < parents.length; i++)\n        {\n            parents[i] = rng.nextInt(i);\n        }\n\n        // -- Generate weights. ---\n\n        int[] weights = new int[size];\n\n        for (int i = 0; i < weights.length; i++)\n        {\n            weights[i] = rng.nextInt(256);\n        }\n\n        return new int[][] { parents, weights };\n    }\n\n}\n```\n\nI attached an image that contains the algorithm that I used.\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Max Independent Set in Prolog\r\n                \r\nI am trying to implement a Prolog predicate that gets a binary tree (represented as t(Left, Root, Right)) and returns a list that is the Maximal Independent Set (MIS) of this tree, and its size.\nI first understood that MIS(T) is the maximum between the MIS with root and the MIS without the root.\nThen, I used two theorems, stating that the MIS with root is the unification of the MIS's without the root for all the subtrees, and that MIS without root is the unification of the MIS's of all the subtrees.\n\n```\n% mis is a predicate for finding the Max Independent Set (MIS) in a binary tree. \n% It has three arguments: one is input - a binary tree T - and the other two are output - List which is a list of elements in the max independent set of tree T, with N being the number of elements in this set.\nmis(Tree, List, N) :-\n    mis_no_root(Tree, List1, N1),       % find mis without root\n    mis_with_root(Tree, List2, N2), % find mis with root\n    max_set(List1, N1, List2, N2, List, N). % choose the bigger set of nodes\n\n% This is a helping predicate, that gets lists List1 and List2 of lengths N1 and N2 respectively, and instantiates List to be the bigger list, with N being its size\nmax_set(List1, N1, _, N2, List, N) :-\n    N1>=N2,             % if N1 is bigger or equal\n    List=List1,         % then max set is List1\n    N=N1.               % of length N1\n\nmax_set(_, N1, List2, N2, List, N) :-\n    N2>N1,              % if N2 is bigger\n    List=List2,         % then max set is List2\n    N=N2.               % of length N2\n\n% a helping predicate to find the max independent set of t(L,_,R), excluding the root\nmis_no_root(nil, [], 0).            % the empty subtree has an empty max independent set of size 0\n\nmis_no_root(t(L,_,R), List, N) :-\n    mis(L, LeftList, LeftN),        % calculate mis of left subtree \n    mis(R, RightList, RightN),      % calculate mis of right subtree\n    conc(LeftList, RightList, List),        % concatenate lists of nodes according to the given formula (unification of all mis of subtrees)\n    N is LeftN + RightN.        % and assign N with the accumulated size of the concatenated independent set, without adding something for the root.\n\n% a helping predicate to find the max independent set of t(L,X,R), including the root\nmis_with_root(nil, [], 0).          % the empty subtree has an empty max independent set of size 0\n\nmis_with_root(t(L,Root,R), [Root|List], N) :-\n    mis_no_root(L, LeftList, LeftN),    % calculate mis of left subtree without root\n    mis_no_root(R, RightList, RightN),  % calculate mis of right subtree without root\n    conc(LeftList, RightList, List),        % concatenate lists of nodes according to the given formula (unification of all mis_no_root of subtrees)\n    N is LeftN + RightN + 1.        % and assign N with the accumulated size of the concatenated independent set, incremented by 1 (including the root).\n```\n\n\nIt does succeed retrieving a set of maximal size, but it does NOT continue searching for other MIS's of the same size. \nThanks in advance for any help!\n    ", "Answer": "\r\nDon't get mad when you see what the annoying issue was! just add = on the second max_set (N2>=N1). :)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "What is Separator concept in Tree Decomposition?\r\n                \r\nI am trying to understand the Maximum Independent Set problem in Tree Decomposition using dynamic programming. However I am not being able to get the notion of \"separator\" in the proposed algorithms. Can someone make me clear on this. Thanks in advance.\n    ", "Answer": "\r\nA separator is a subset of vertices whose removal leaves a graph with several connected components. A separator is balanced if every connected component has less than half the number of vertices compared to the original graph. \n\n\n\nA graph with low treewidth has a small balanced separator. More precisely, a graph of treewidth k has a balanced separator with at most k+1 vertices.\n\nAlgorithms exploit this as follows: \n\n\nremove a small balanced separator from the graph\nrecursively find an optimum solution for the connected components\nadd the separator again (possibly vertex by vertex), and use the solutions for the connected components to find an optimum solution for the whole graph.\n\n\nTo make the above scheme efficient, a few requirements need to be met:\n\n\nthe separator in the first step is small (that is, of constant size)  \nthe connected components in the second step are substantially smaller number of vertices than the original graph (that is, a constant fraction, e.g. 1/2).\nthe above properties are inherited to induced subgraphs (otherwise you cannot recurse efficiently)\nthe partial optimum solutions for the connected components can be efficiently combined to an optimum solution for the whole graph\n\n\nThese requirements are met by graphs of low treewidth - except the last one: this one is specific for each optimization problem, and this is what algorithm designers wrote research papers about.\n\n(Image taken from the wikipedia article on vertex separator.)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "What is the maximum size of an independent set in the following tree?\r\n                \r\nI am trying to solve this and getting 7 as an answer, but can anyone confirm my answer?\n\n    ", "Answer": "\r\nThe maximum size of the independent set in this tree is 10.\n\nThis can be obtained by the following dynamic programming over tree: for each vertex, we will calculate the maximum independent set of a subtree of this vertex with this vertex included and without. Then, if this vertex is not included we will pick a maximum of 2 values from each child and sum them, and for this vertex included we pick non-included values from children, sum them and add 1 (current vertex). For leaves, our dynamic programming is, obviously, (0, 1).\n\nThat is my manual calculation of this dynamic programming. Values are written in the form (not included, included) near each vertex, and colored vertices are the maximum independent set.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Is this algorithm for finding a maximum independent set in a graph correct?\r\n                \r\nWe have the following input for the algorithm:\n\nA graph ```\nG```\n with no cycles (aka a spanning-tree) where each node has an associated weight.\n\nI want to find an independent set ```\nS```\n such that:\n\n\nNo two elements in ```\nS```\n form an edge in ```\nG```\n \nThere is no other possible subset which satisfies the above condition, for which there is a greater weight than ```\nS[0] + S[1] + ... + S[n-1]```\n  (where ```\nlen(S)==n```\n).\n\n\nThis is the high-level pseudocode I have so far: \n\n```\nMaxWeightNodes(SpanningTree S):\n    output = {0}\n    While(length(S)):\n        o = max(node in S)\n        output = output (union) o\n        S = S \\ (o + adjacentNodes(o))\n    End While\n    Return output   \n```\n\n\nCan someone tell me off the bat whether I've made any errors, or if this algorithm will give me the result I want?\n    ", "Answer": "\r\nThe algorithm is not valid, since you'll soon face a case when excluding the adjacent nodes of an initial maximum may be the best local solution, but not the best global decision.\n\nFor example, ```\noutput = []```\n:\n\n```\n        10\n      /    \\\n   100      20\n   /  \\    /  \\\n  80  90  10   30\n```\n\n\n```\noutput = [100]```\n:\n\n```\n         x\n      /    \\\n     x      20\n   /  \\    /  \\\n  x    x  10   30\n```\n\n\n```\noutput = [100, 30]```\n:\n\n```\n         x\n      /    \\\n     x      x\n   /  \\    /  \\\n  x    x  10   x\n```\n\n\n```\noutput = [100, 30, 10]```\n:\n\n```\n         x\n      /    \\\n     x      x\n   /  \\    /  \\\n  x    x  x    x\n```\n\n\nWhile we know there are better solutions.\n\nThis means you're down on a greedy algorithm, without an optimal substructure.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "program of Recursion for Maximum Independent Set in a Graph\r\n                \r\nI am getting difficulty in writing a program for the above mentioned problem.. I have the following graph....\n\n```\nA-----B------C       D\nA is connected to B\nB is connected to C\nD is connected with no body!! \nThe maximum Independent set in this is {A,C, D}... \n```\n\n\nThe Adjacency Matrix for the graph is below:-\n\n\n\nI drew the following decision tree inorder to solve the problem:-\n\n\n\n\nThe first element of each node is the index.\nThe second element of each node is the set which store independent elements of the graph.\nThe left branch says that i will not consider the element, and the right branch says that I will consider the element at index specified by first element of the node.\n\n\nSo as you can see clearly, at each node, I haven't considered the element specified by first element index of the node, and I have consider the element whether it can be inserted in the independent set.\n\nI want to write up a program for this in Python!! I am a newbie, and just still in early stages of implementing the program through recursion.\n\nkindly help!!\n\nI wrote the following code:- but it doesn't looks nice to me.. Its working somehow.. Please experiences People could put in your comments.. I am still learning in recursion..\n\n```\ndef maxset(tab, i, set):\n    global numcalls\n    numcalls += 1\n    if i == 0:\n        flag = 0\n        for s in set:\n            if tab[i][s]:\n                return 0\n        if i not in set:\n            set.append(i)\n        return len(set)\n\n    without_i = maxset(tab, i-1, set)\n\n    flag = 0\n    for s in set:\n        if tab[i][s]:\n            return without_i\n    if i not in set:\n        set.append(i)\n    with_i = maxset(tab,i-1,set)\n    return max(without_i, with_i)\n\n\ntab = [[0,1,0,0],[1,0,1,0],[0,1,0,0],[0,0,0,0]]\n#tab = [[0,1,0,0,0],[1,0,1,1,0],[0,1,0,1,0],[0,1,1,0,1],[0,0,0,1,0]]\nset = []\nnumVertIndex = 3 #### 0,1,2,3\nnumcalls = 0\nprint(maxset(tab, numVertIndex, set))\nprint(set)\nprint (numcalls)\n```\n\n    ", "Answer": "\r\nThere is a well known and simple algorithm to solve this problem:\n\n\nInitially color all your vertices green.\nFind a green vertex.  Color it's neighbors red.\nFor every red vertex, color it's green neighbors red. (Here's the recursion part)\nWhen there are no more red vertices with green neighbors, the set of red vertices determines a maximally connected component.\nRepeat from 2 until all vertices are red and all components are discovered.\n\n\nNow that you know all the components, you can choose the one with the most vertices (i.e. the highest order maximally connected sub-graph).\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Java Algorithm for finding the largest set of independent nodes in a binary tree\r\n                \r\nBy independent nodes, I mean that the returned set can not contain nodes that are in immediate relations, parent and child cannot both be included. I tried to use Google, with no success. I don't think I have the right search words. \n\nA link, any help would be very much appreciated. Just started on this now. \n\nI need to return the actual set of independent nodes, not just the amount. \n    ", "Answer": "\r\nYou can compute this recursive function with dynamic programming (memoization):\n\n```\nMaxSet(node) = 1 if \"node\" is a leaf\nMaxSet(node) = Max(1 + Sum{ i=0..3: MaxSet(node.Grandchildren[i]) },  \n                       Sum{ i=0..1: MaxSet(node.Children[i])      })\n```\n\n\nThe idea is, you can pick a node or choose not to pick it. If you pick it, you can't pick its direct children but you can pick the maximum set from its grandchildren. If you don't pick it, you can pick maximum set from the direct children. \n\nIf you need the set itself, you just have to store how you selected \"Max\" for each node. It's similar to the LCS algorithm. \n\nThis algorithm is O(n). It works on trees in general, not just binary trees.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "how to set id for every node in a angular material tree view, in order that every node is independent\r\n                \r\nI can I set node id for every node in a angular material tree view, in order that every node is independent.\n\nthe HTML code looks like this: \n\n```\n<mat-tree [dataSource]=\"dataSource\" [treeControl]=\"treeControl\">\n  <mat-tree-node *matTreeNodeDef=\"let node\" matTreeNodePadding>\n    <button mat-icon-button disabled></button>\n     <mat-form-field appearance=\"legacy\">\n            <input matInput type=\"text\" [formControl]=\"locationField\"/>\n            <mat-autocomplete #auto=\"matAutocomplete\" >\n              <mat-option *ngFor=\"let filteredFieldResult of locationFieldResults\" [value]=\"filteredFieldResult\">\n                {{filteredFieldResult}}\n              </mat-option>\n            </mat-autocomplete>\n    </mat-form-field>\n  </mat-tree-node>\n  <mat-tree-node *matTreeNodeDef=\"let node; when: hasChild\" matTreeNodePadding>\n    <button mat-icon-button\n            [attr.aria-label]=\"'toggle ' + node.filename\" matTreeNodeToggle>\n      <mat-icon class=\"mat-icon-rtl-mirror\">\n        {{treeControl.isExpanded(node) ? 'expand_more' : 'chevron_right'}}\n      </mat-icon>\n    </button>\n    {{node.item}}\n\n  </mat-tree-node>\n</mat-tree>\n<button (click)=\"addNode()\">Add Node</button>\n<button (click)=\"addSubNode()\">Add SubNode</button>\n<button (click)=\"changeNode()\">Change Node</button>\n```\n\n    ", "Answer": "\r\nYou can include that id into the structure of the node you are creating.\nexample:\n```\nexport class MyFlatNode{\n   constructor(public name: string, public level = 1, public expandable = false, public loadMoreParentItem: string | null = null, public id:number = 0, public parentId: number=0) {}\n}\n```\n\nand while creating the node for the tree, I used the following code in the transformer method given by material angular.\n```\nnewNode = new MyFlatNode(node.name, node.level, node.hasChildren, null, node.id, node.parentId);\n```\n\nAs you can see above, that I have passed all the information like node name, node level and node id etc. you can pass any information that you would possibly need in your tree nodes.\nYou can also do the same for the nested tree node by using the appropriate class constructor.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Having problem in conversion from Recursive solution to DP\r\n                \r\nGiven a Binary Tree of size N, find size of the Largest Independent Set(LIS) in it. A subset of all tree nodes is an independent set if there is no edge between any two nodes of the subset. Your task is to complete the function LISS(), which finds the size of the Largest Independent Set.\n\nI came up with this recursive solution.\n\n```\nint rec(struct Node *root,bool t)\n{\n    if(root==NULL)\n    return 0;\n\n    if(t==true)\n    {\n        return max(1+rec(root->left,!t)+rec(root->right,!t),rec(root->left,t)+rec(root->right,t));\n    }\n    else\n    {\n\n        return max(rec(root->left,!t)+rec(root->right,!t),rec(root->left,t)+rec(root->right,t));\n    }\n}\nint LISS(struct Node *root)\n{\n    int x,y;\n    y=rec(root,true);\n\n    return y;\n}\n```\n\n\nTo solve this problem via DP, I modified the code as follows, but then it gives wrong answer. \nIt doesn't even work with Binary tree with distinct elements. \n\n```\nmap<int,int> mm;\nint rec(struct Node *root,bool t)\n{\n    if(root==NULL)\n    return 0;\n\n    if(mm.find(root->data)!=mm.end())\n    return mm[root->data];\n\n\n    if(t==true)\n    {\n        mm[root->data]=max(1+rec(root->left,!t)+rec(root->right,!t),rec(root->left,t)+rec(root->right,t));\n        return mm[root->data];\n    }else\n    {\n        mm[root->data]=max(rec(root->left,!t)+rec(root->right,!t),rec(root->left,t)+rec(root->right,t));\n        return mm[root-s>data];\n    }\n}\nint LISS(struct Node *root)\n{\n    //Code here\n    mm={};\n    int y=0;\n\n    y=rec(root,true);\n\n    return max(x,y);\n}\n```\n\n\nWhat's the mistake? \n    ", "Answer": "\r\nYou have two states in your function but you are memoizing only one state. Let's say for root x,\n\n```\nrec(x,true) = 5```\n and\n\n```\nrec(x,false) = 10```\n .\n\nYou calculated the ```\nrec(x, true)```\n first and saved it in your map \"mm\" as mm[x] = 5.\n\nSo when you are trying to get the value of ```\nrec(x, false)```\n it is getting the value of ```\nrec(x, true)```\n which is 5.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "XGBoost: minimize influence of continuous linear features as opposed to categorical\r\n                \r\nLets say I have 100 independent features - 90 are binary (e.g. 0/1) and 10 are continuous variables (e.g. age, height, weight, etc). I use the 100 features to predict a classifier problem with an adequate amount of samples.\n\nWhen I set a XGBClassifier function and fit it, then the 10 most important features from the standpoint of ```\ngain```\n are always the 10 continuous variable. For now I am not interested in ```\ncover```\n or ```\nfrequency```\n. The 10 continuous variables take up like .8 to .9 of space in ```\ngain```\n list ( sum(gain) = 1).\n\nI tried tuning the ```\ngamma```\n, ```\nreg_alpha```\n , ```\nreg_lambda```\n , ```\nmax_depth```\n, ```\ncolsample```\n. Still top 10 features by gain are always the 10 continuous features. \n\nAny suggestions?\n\nsmall update -- someone asked why I think this is happening. I believe it's because a continuous variable can be split on multiple times per decision tree. A binary variable can only be split on once. Hence, the higher prevalence of continuous variables in trees and thus a higher ```\ngain```\n score\n    ", "Answer": "\r\nYes, it's well-known that a tree(/forest) algorithm (xgboost/rpart/etc.) will generally 'prefer' continuous variables over binary categorical ones in its variable selection, since it can choose the continuous split-point wherever it wants to maximize the information gain (and can freely choose different split-points for that same variable at other nodes, or in other trees). If that's the optimal tree (for those particular variables), well then it's the optimal tree. See Why do Decision Trees/rpart prefer to choose continuous over categorical variables? on sister site CrossValidated.\n\nWhen you say \"any suggestions\", depends what exactly do you want, it could be one of the following:\n\n\na) To find which of the other 90 binary categorical features give the most information gain\nb) To train a suboptimal tree just to find out which features those are\nc) To engineer some \"compound\" features by combining the binary features into n-bit categorical features which have more information gain (while being sure to remove the individual binary features from the input)\nd) You could look into association rules : What is the practical difference between association rules and decision trees in data mining?\n\n\nIf you want to explore a)...c), suggest something vaguely like this:\n\n\nexclude various subsets of the 10 continuous variables, then see which binary features show up as having the most gain. Let's say that gives you N candidate features. N will be << 90, let's assume N < 20 to make the following more computationally efficient.\nthen compute the pairwise measure of association or correlation (Spearman or Kendall) between each of the N features. Look at a corrplot. Pick the clusters of variables which are most associated with each other. Create compound n-bit variables which combine those individual binary features. Then retrain the tree, including the compound variables, and excluding the individual binary variables (to avoid changing the total variance in the input).\niterate for excluding various subsets of the 10 continuous variables. See which patterns emerge in your compound variables. I'm sure there's an algorithm for doing this (compound feature-engineering of n-bit categoricals) more formally and methodically, I just don't know it.\nAnyway, for hacking a tree-based method for better performance, I imagine the most naive way is \"at every step, pick the two most highly-correlated/associated categorical features and combine them\". Then retrain the tree (include new feature, exclude its constituent features) and use the revised gain numbers.\nperhaps a more robust way might be:\n\n\nPick some threshold T for correlation/association, say start at a high level T = 0.9 or 0.95\nAt each step, merge any features whose absolute correlation/association to each other >= T\nIf there were no merges at this step, reduce T by some value (like T -= 0.05) or ratio (e.g. T *= 0.9 . If still no merges, keep reducing T until there are merges, or until you hit some termination value (e.g. T = 0.03)\nRetrain the tree including the compound variables, excluding their constituent subvariables.\nNow go back and retrain what should be an improved tree with all 10 continuous variables, and your compound categorical features.\nOr you could early-terminate the compound feature selection to see what the full retrained tree looks like. \n\n\n\nThis issue arose in the 2014 Kaggle Allstate Purchase Prediction Challenge, where the policy coverage options A,B,C,D,E,F,G were each categoricals with between 2-4 values, and very highly correlated with each other. (The current option of C, \"C_previous\", is one of the input features). See that competitions's forums and published solutions for more. Be aware that policy = (A,B,C,D,E,F,G) is the output. But C_previous is an input variable.\n\nSome general fast-and-dirty rules-of-thumb on feature selection from Kaggle are:\n\n\nthrow out any near-constant/ very-low-variance variables (because they have near-zero information content)\nthrow out any very-high-cardinality categorical variables (cardinality >~ training-set-size/2), (because they will also tend to have low information content, but cause lots of spurious overfitting and blow up training time). This can include customer IDs, row IDs, transaction IDs, sequence IDs, and other variables which shouldn't be trained on in the first place but accidentally ended up in the training set.\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Generate all solutions in prolog\r\n                \r\nI'm learning prolog in a course. \nI've been given a question similar to this one, and I also got the same problem (in which it doesnt produce all solutions),\n\nany idea why, will using cuts help?\nthanks in advance\n\nEDIT:\nThe exercise I've been given is to generate all possible max independent sets from a binary tree.\nIn the second part of the question, I get an integer binary tree, from which i need to get all the mis's, and from those i need to get the one with the maximum on adding its numbers.\ni.e. if i have a mis with 1,3,9 and a mis with 1,3,4 - i'll return the one with 1,3,9.\n    ", "Answer": "\r\nI changed a little bit the solution from the link ,so it's not entirely my solution it is just the code corrected and i think now it's working fine :\n\n```\n   mis(Tree, List, N) :-\n    mis_no_root(Tree, List1, N1),       \n    mis_with_root(Tree, List2, N2),!, \n    max_set(List1, N1, List2, N2, List, N). \n\n\nmax_set(List1, N1, List2, N2, List, N) :-\n    (N1>N2,List=List1,N=N1;              \n     N2>N1,List=List2,N=N2;\n    N2=:=N1,N=N1,(List=List1;List=List2)).              \n\n\nmis_no_root(nil, [], 0).            \nmis_no_root(t(L,_,R), List, N) :-\n    mis(L, LeftList, LeftN),        \n    mis(R, RightList, RightN),      \n    append(LeftList, RightList, List),      \n    N is LeftN + RightN.        \n\n\nmis_with_root(nil, [], 0).          \n\nmis_with_root(t(L,Root,R), [Root|List], N) :-\n    mis_no_root(L, LeftList, LeftN),\n    mis_no_root(R, RightList, RightN), \n    append(LeftList, RightList, List),      \n    N is LeftN + RightN + 1. \n```\n\n\nIf you want  to return one list with solutions you could write:\n\n```\nfinal_mis(Tree,List,N):-findall(L,mis(Tree, L,_),List),List=[H|_],length(H,N).\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Matroid type class (error) in Haskell\r\n                \r\nA finite matroid M is a pair (E, I), where E is a finite set (called the ground set) and I is a family of subsets of E (called independent sets).\n\nA weighted matroid is a matroid W equipped with a weight function w: E -> Int (positive integers).\n\nWe can define a (weighted) matroid typeclass as follows:\n\n```\n{-# LANGUAGE FlexibleInstances #-}\n{-# LANGUAGE MultiParamTypeClasses #-}\n\nclass Matroid matroid a where\n  weight :: matroid -> a -> Int \n  groundSet :: matroid -> [a]\n  indepSet :: [a] -> Bool\n```\n\n\nWe can then define various algorithms for matroids.  For example choosing a basis set F with minimal weight.  When applied to graphs, this is Kruskal's algorithm for finding a minimal weight spanning tree.\n\nAn instance of a (weighted) matroid is a (weighted) graph G = (E, w) where E is a collection of edges, w is a weight function.  To define a matroid from a graph, we take the ground set to be the collection of edges E and a subset F of E is independent if and only if it is acyclic.\n\n```\ninstance Matroid WGraph Edge where\n  weight = wT \n  groundSet = gSet\n  indepSet = iSet\n\ntype Vertex = Int\ntype Edge = (Vertex, Vertex)\ntype Graph = [Edge]\ntype WtFun = Edge -> Int\ntype WGraph = (Graph, WtFun)\n\ngSet :: WGraph -> [Edge]\ngSet (es,wt) = es \n\nwT :: WGraph -> (WtFun)\nwT (es,wt) = wt\n-- stub\niSet :: [Edge] -> Bool\niSet edges = True\n```\n\n\nHowever given a weighted graph, the following code has a type error \n\n```\nweightedG = (es, wt)::WGraph\nes = [(4,5),(6,7),(5,7)]::[Edge]\nwt :: (Edge -> Int)\nwt (4,5) = 15\nwt (6,7) = 11\nwt (5,7) = 9\ngs = groundSet weightedG\n\nNo instance for (Matroid WGraph a0)\n  arising from a use of `groundSet'\nThe type variable `a0' is ambiguous\n```\n\n\nHow can we specify that a0 should be an Edge type?\n\nCode for copy/paste:\n\n```\n{-# LANGUAGE FlexibleInstances #-}\n{-# LANGUAGE MultiParamTypeClasses #-}\n\nclass Matroid matroid a where\n  weight :: matroid -> a -> Int \n  groundSet :: matroid -> [a]\n  indepSet :: [a] -> Bool\n\ninstance Matroid WGraph Edge where\n  weight = wT \n  groundSet = gSet\n  indepSet = iSet\n\ntype Vertex = Int\ntype Edge = (Vertex, Vertex)\ntype Graph = [Edge]\ntype WtFun = Edge -> Int\ntype WGraph = (Graph, WtFun)\n\ngSet :: WGraph -> [Edge]\ngSet (es,wt) = es \n\nwT :: WGraph -> (WtFun)\nwT (es,wt) = wt\n\n-- fix for real implementation\niSet :: [Edge] -> Bool\niSet edges = True\n\nweightedG = (es, wt)::WGraph\nes = [(4,5),(6,7),(5,7)]::[Edge]\nwt :: (Edge -> Int)\nwt (4,5) = 15\nwt (6,7) = 11\nwt (5,7) = 9\ngs = groundSet weightedG\n```\n\n    ", "Answer": "\r\nThe error message is indicating that GHC doesn't know which ```\nMatroid```\n instance you want for ```\nweightedG```\n.\n\nIt knows that you want a ```\nMatroid WGraph a```\n for some type ```\na```\n, and you have\ndefined an instance ```\nMatroid Graph Edge```\n, but since type classes are open there is no way for GHC conclude that ```\na```\n must be ```\nEdge```\n. Later or in another module you (or someone else) could define a ```\nMatroid WGraph String```\n instance - for instance.\n\nOne way around this is to introduce a functional dependency between the matroid type and the element type like this:\n\n```\n{-# LANGUAGE FunctionalDependencies #-}\n\nclass Matroid matroid a | matroid -> a where\n   ...\n```\n\n\nThis tells GHC that the ```\nmatroid```\n type determines the edge type ```\na```\n. With this change I got your code to compile.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Sticky rows in tree-like nested list structure\r\n                \r\nI have a long list of items that are nested.\n\r\n\r\n```\nsection#container {\n  height: 250px;\n  width: 350px;\n  overflow: auto;\n}\n\nli {\n  position: relative;\n  background: white;\n}\n\ndiv {\n  position: sticky;\n  top: 0;\n}```\n\r\n```\n<section id=\"container\">\n  <ul>\n    <li>\n      <div>Aaaaaaaaaaaa</div>\n      <ul>\n        <li>\n          <div>Bbbbbbbbbbbb</div>\n        </li>\n        <li>\n          <div>Cccccccccc</div>\n        </li>\n        <li>\n          <div>Dddddddddddd</div>\n          <ul>\n            <li>\n              <div>Eeeeeeeeee</div>\n            </li>\n            <li>\n              <div>Fffffffff</div>\n              <ul>\n                <li>\n                  <div>Ggggg</div>\n                </li>\n                <li>\n                  <div>Hhhh</div>\n                </li>\n                <li>\n                  <div>Iiii</div>\n                </li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n    <li>\n      <pre>More<br>content<br>so<br>we<br>can<br>scroll<br>.<br>.<br>.<br>.<br>.<br>.<br>.<br>.</pre>\n    </li>\n  </ul>\n</section>```\n\r\n\r\n\r\n\nWhen scrolling, I want to always see the \"path that led to the current top row\". For example, when scrolling further down, you should see\n```\nA                          # \"Path\"\n   B                       # leading up to\n      D                    # G (breadcrumbs)\n         F                 #\n            G\n            H\n            ...\n```\n\nOr maybe better visualized, see THIS DEMO of marchaos/react-virtualized-sticky-tree. It does exactly what I am looking for. The library however uses JavaScript and just sets the ```\ntop```\n property according to the nest level. I am looking for a simple CSS-only solution (independent on the amount of recursion), which I think should be fairly basic but I cannot seem to find a solution.\nIn the snippet above I attempted so with ```\nposition:sticky```\n on the ```\ndiv```\ns, and it somewhat works, but they are unfortunately all on the same line. Thanks for any hints.\n    ", "Answer": "\r\nYou can simply set ```\nz-index```\n to an individual content in order to differentiate it from the other contents which doesn't have ```\nsticky```\n position and set the ```\ntop```\n of an them.\nRemember to set ```\ntop```\n which is different from the one another in order to align them one under another because if you set the same ```\ntop```\n will cause an overlapping.\nthe following is an example\n\r\n\r\n```\nsection#container {\n  height: 240px;\n  width: 350px;\n  overflow: auto;\n}\n\nli {\n  position: relative;\n  background: white;\n}\n\ndiv {\n  position: sticky;\n}\n\n.first {\n  z-index: 99999;\n  background: red;\n  top: 0;\n}\n\n.second {\n  z-index: 99999;\n  background: blue;\n  top: 15px;\n}\n\n.third {\n  z-index: 99999;\n  background: green;\n  top: 30px;\n}```\n\r\n```\n<section id=\"container\">\n  <ul>\n    <li>\n      <div class=\"first\">Aaaaaaaaaaaa</div>\n      <ul>\n        <li>\n          <div>Bbbbbbbbbbbb</div>\n        </li>\n        <li>\n          <div>Cccccccccc</div>\n        </li>\n        <li>\n          <div class=\"second\">Dddddddddddd</div>\n          <ul>\n            <li>\n              <div>Eeeeeeeeee</div>\n            </li>\n            <li>\n              <div class=\"third\">Fffffffff</div>\n              <ul>\n                <li>\n                  <div>Ggggg</div>\n                </li>\n                <li>\n                  <div>Hhhh</div>\n                </li>\n                <li>\n                  <div>Iiii</div>\n                </li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n    <li>\n      <pre>More<br>content<br>so<br>we<br>can<br>scroll<br>.<br>.<br>.<br>.<br>.<br>.<br>.<br>.</pre>\n    </li>\n  </ul>\n</section>```\n\r\n\r\n\r\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "find all disjoint (non-overlapping) sets from a set of sets\r\n                \r\nMy problem: need to find all disjoint (non-overlapping) sets from a set of sets.\n\nBackground: I am using comparative phylogenetic methods to study trait evolution in birds. I have a tree with ~300 species. This tree can be divided into subclades (i.e. subtrees). If two subclades do not share species, they are independent. I'm looking for an algorithm (and an R implementation if possible) that will find all possible subclade partitions where each subclade has greater than 10 taxa and all are independent. Each subclade can be considered a set and when two subclades are independent (do not share species) these subclades are then disjoint sets. \n\nHope this is clear and someone can help.\n\nCheers,\nGlenn\n\nThe following code produces an example dataset. Where subclades is a list of all possible subclades (sets) from which I'd like to sample X disjoint sets, where the length of the set is Y.\n\n```\n###################################\n# Example Dataset\n###################################\n\n    library(ape)\n    library(phangorn)\n    library(TreeSim)\n    library(phytools)\n\n    ##simulate a tree\n\n    n.taxa <- 300\n    tree <- sim.bd.taxa(n.taxa,1,lambda=.5,mu=0)[[1]][[1]]\n    tree$tip.label <- seq(n.taxa)\n\n    ##extract all monophyletic subclades\n\n    get.all.subclades <- function(tree){\n    tmp <- vector(\"list\")\n    nodes <- sort(unique(tree$edge[,1]))\n    i <- 282\n    for(i in 1:length(nodes)){\n    x <- Descendants(tree,nodes[i],type=\"tips\")[[1]]\n    tmp[[i]] <- tree$tip.label[x]\n    }\n    tmp\n    }\n    tmp <- get.all.subclades(tree)\n\n    ##set bounds on the maximum and mininum number of tips of the subclades to include\n\n    min.subclade.n.tip <- 10\n    max.subclade.n.tip <- 40\n\n\n    ##function to replace trees of tip length exceeding max and min with NA\n\n    replace.trees <- function(x, min, max){\n    if(length(x) >= min & length(x)<= max) x else NA\n    }\n\n\n    #apply testNtip across all the subclades\n\n    tmp2 <- lapply(tmp, replace.trees, min = min.subclade.n.tip, max = max.subclade.n.tip)\n\n    ##remove elements from list with NA, \n    ##all remaining elements are subclades with number of tips between \n##min.subclade.n.tip and max.subclade.n.tip\n\n    subclades <- tmp2[!is.na(tmp2)]\n\n    names(subclades) <- seq(length(subclades))\n```\n\n    ", "Answer": "\r\nHere's an example of how you might test each pair of list elements for zero overlap, extracting the indices of all non-overlapping pairs.\n\n```\nfindDisjointPairs <- function(X) {\n    ## Form a 2-column matrix enumerating all pairwise combos of X's elements\n    ij <- t(combn(length(X),2))    \n    ## A function that tests for zero overlap between a pair of vectors\n    areDisjoint <- function(i, j) length(intersect(X[[i]], X[[j]])) == 0     \n    ## Use mapply to test for overlap between each pair and extract indices \n    ## of pairs with no matches\n    ij[mapply(areDisjoint, ij[,1], ij[,2]),]\n}\n\n## Make some reproducible data and test the function on it\nset.seed(1)\nA <- replicate(sample(letters, 5), n=5, simplify=FALSE)    \nfindDisjointPairs(A)\n#      [,1] [,2]\n# [1,]    1    2\n# [2,]    1    4\n# [3,]    1    5\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "What object types can be used for fetures in decision trees? Do I need to convert my \"object\" type to another type?\r\n                \r\nI imported a table using pandas and I was able to set independent variables (features) and my dependent variable (target). Two of my independent variables are \"object type\" and my others are int64 and float64. Do I need to convert my \"object\" type features to \"class\" or another type? How can I handle these in Sci-kit learn decision trees? \n    ", "Answer": "\r\nBased on the documentation (https://scikit-learn.org/stable/modules/tree.html):\n\n\n  Able to handle both numerical and categorical data. Other techniques\n  are usually specialised in analysing datasets that have only one type\n  of variable. See algorithms for more information.\n\n\nSo you can run it with object type and int64 and float64. This is one of the benefits of the decision trees, that it can also work with non-numeric data.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Why are these string fields getting ignored in this omniORB program, but only when I use my own build script?\r\n                \r\nI'm attempting to wrap my head around omniORB in preparation for using it to interface with a piece of software we'll be getting that uses CORBA. The strategy I'm using is to take an example in omniORB (the echo example, specifically eg3_impl and eg3_cc) and blend in the idl from the received software until it does what I want. In service of that, I'm trying to isolate the software I'm writing from the rest of the omniORB stack (i.e. I'm trying to write an independent makefile that will depend on compiled libraries).  I'm using omniORB-4.2.3, downloaded from sourceforge (via omniORB-support.com link).\nThe problem I'm hitting is, the example compiled from the independent makefile appears to have memory issues that the compiled-in-tree example doesn't have;\n\nThe example compiled from the independent Makefile is trying to deallocate pointers that weren't 'malloc()'ed or 'new'ed. (Annoying, but not a showstopper)\nthe example compiled from the independent Makefile appears not to be recording string pointers properly. (a showstopper).\n\n\nthe source files are the same between the two examples; the only difference is, the non-independent example uses the makefile structure built into the omniORB tree, and the independent software uses a compile script that I wrote, based on what I observed the makefile structure doing when it built the echo example.\nhere's my script:\n```\nWHICH_BUILD_DIR=build2\nWHICH_VERSION=omniORB-4.2.3\nINCLUDE_G_PLUS_PLUS=\"-I./idl_artifacts/ -I../${WHICH_VERSION}/include -I. -I../${WHICH_VERSION}/${WHICH_BUILD_DIR}/include\"\n\nDEFINES_G_PLUS_PLUS=\"-D__OMNIORB4__ -D_REENTRANT -D__OSVERSION__=2 -D__linux__ -D__x86__\"\n\nLIBRARY_G_PLUS_PLUS=\"-L../${WHICH_VERSION}/${WHICH_BUILD_DIR}/lib -L/usr/lib\"\nexport LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/home/jasont/FACE_translator/omniORB-4.2.3/build2/lib\n\nreset\n\nif [ \"~$1\" == \"~debug\" ] ; then DEBUGGER_OPTION=\"-g\"\nelse                            DEBUGGER_OPTION=\"\"   ; fi\nrm -rf ./idl_artifacts *.o eg3_impl eg3_clt eg3_tieimpl\nmkdir idl_artifacts\n\n#compile idl file to skeleton files\n  ../${WHICH_VERSION}/${WHICH_BUILD_DIR}/bin/omniidl -bcxx -Wba -Wbtp -C./idl_artifacts/ echo.idl\n\n#regular compile\n  g++ -c $DEBUGGER_OPTION -O2 -Wall -Wno-unused -fexceptions $INCLUDE_G_PLUS_PLUS $DEFINES_G_PLUS_PLUS -o      echoSK.o  ./idl_artifacts/echoSK.cc\n  g++ -c $DEBUGGER_OPTION -O2 -Wall -Wno-unused -fexceptions $INCLUDE_G_PLUS_PLUS $DEFINES_G_PLUS_PLUS -o    eg3_impl.o                eg3_impl.cc\n# g++ -c $DEBUGGER_OPTION -O2 -Wall -Wno-unused -fexceptions $INCLUDE_G_PLUS_PLUS $DEFINES_G_PLUS_PLUS -o eg3_tieimpl.o             eg3_tieimpl.cc\n  g++ -c $DEBUGGER_OPTION -O2 -Wall -Wno-unused -fexceptions $INCLUDE_G_PLUS_PLUS $DEFINES_G_PLUS_PLUS -o     eg3_clt.o                 eg3_clt.cc\n  \n#regular link\n# g++ -o eg3_impl    -O2 -Wall -Wno-unused -fexceptions    eg3_impl.o echoSK.o $LIBRARY_G_PLUS_PLUS         -lomniORB4 -lomnithread -lpthread\n##g++ -o eg3_tieimpl -O2 -Wall -Wno-unused -fexceptions eg3_tieimpl.o echoSK.o $LIBRARY_G_PLUS_PLUS         -lomniORB4 -lomnithread -lpthread\n# g++ -o eg3_clt     -O2 -Wall -Wno-unused -fexceptions     eg3_clt.o echoSK.o $LIBRARY_G_PLUS_PLUS         -lomniORB4 -lomnithread -lpthread\n  g++ -o eg3_impl    -O2 -Wall -Wno-unused -fexceptions    eg3_impl.o echoSK.o $LIBRARY_G_PLUS_PLUS -static -lomniORB4 -lomnithread -lpthread\n\n./eg3_impl\n```\n\n...here's what I'm seeing my the independent software do (generated by setting the omniORB.cfg tracelevel to maximum)\n```\n...\nomniORB: (0) 2020-11-06 12:50:37.443054: LocateRequest to remote: key<NameService>\nomniORB: (1) 2020-11-06 12:50:37.443022: giopRendezvouser task execute for giop:tcp:10.0.0.247:57082\nomniORB: (2) 2020-11-06 12:50:37.443166: AsyncInvoker: thread id 2 has started. Total threads = 2.\nomniORB: (2) 2020-11-06 12:50:37.443199: AsyncInvoker: thread id 2 assigned to general tasks. Total general threads = 2.\nomniORB: (2) 2020-11-06 12:50:37.443217: AsyncInvoker: thread id 2 performing immediate general task.\nomniORB: (2) 2020-11-06 12:50:37.443232: Scavenger task execute.\nomniORB: (1) 2020-11-06 12:50:37.493125: SocketCollection idle. Sleeping.\nomniORB: (0) 2020-11-06 12:50:38.443279: Client attempt to connect to giop:tcp:10.0.0.247:2809\nomniORB: (0) 2020-11-06 12:50:38.443411: Client opened connection to giop:tcp:10.0.0.247:2809\nomniORB: (0) 2020-11-06 12:50:38.443423: sendChunky: to giop:tcp:10.0.0.247:2809 35 bytes\nomniORB: (0) 2020-11-06 12:50:38.443432: \n4749 4f50 0102 0103 1700 0000 0200 0000 GIOP............\n0000 7665 0b00 0000 4e61 6d65 5365 7276 ..ve....NameServ\n6963 65                                 ice\nomniORB: (0) 2020-11-06 12:50:38.443236: omniORB: (0) 2020-11-06 12:50:37.443107: omniORB: (0) 2020-11-06 12:50:38.444269: inputMessage: from giop:tcp:10.0.0.247:2809 20 bytes\nomniORB: (0) 2020-11-06 12:50:38.444312: \n4749 4f50 0102 0104 0800 0000 0200 0000 GIOP............\n0100 0000                               ....\nomniORB: (0) 2020-11-06 12:50:38.444395: Send codeset service context: (ISO-8859-1,UTF-16)\nomniORB: (0) 2020-11-06 12:50:38.444426: sendChunky: to giop:tcp:10.0.0.247:2809 92 bytes\nomniORB: (0) 2020-11-06 12:50:38.444439: \n4749 4f50 0102 0100 5000 0000 0400 0000 GIOP....P.......\n0300 0000 0000 0000 0b00 0000 4e61 6d65 ............Name\n5365 7276 6963 6578 1100 0000 6269 6e64 Servicex....bind\n5f6e 6577 5f63 6f6e 7465 7874 0069 4f52 _new_context.iOR\n0100 0000 0100 0000 0c00 0000 0100 0000 ................\n0100 0100 0901 0100 0000 0000           ............\nomniORB: (0) 2020-11-06 12:50:38.444419: omniORB: (0) 2020-11-06 12:50:38.444414: JET052\nomniORB: (0) 2020-11-06 12:50:38.444914: inputMessage: from giop:tcp:10.0.0.247:2809 80 bytes\nomniORB: (0) 2020-11-06 12:50:38.444958: \n4749 4f50 0102 0101 4400 0000 0400 0000 GIOP....D.......\n0100 0000 0000 0000 3400 0000 4944 4c3a ........4...IDL:\n6f6d 672e 6f72 672f 436f 734e 616d 696e omg.org/CosNamin\n672f 4e61 6d69 6e67 436f 6e74 6578 742f g/NamingContext/\n496e 7661 6c69 644e 616d 653a 312e 3000 InvalidName:1.0.\n./go.sh: line 46: 28855 Segmentation fault      (core dumped) ./eg3_impl\n\n```\n\n......and here's here's what I'm seeing the echo example do\n```\nomniORB: (0) 2020-11-06 12:59:50.031354: LocateRequest to remote: key<NameService>\nomniORB: (2) 2020-11-06 12:59:50.031466: AsyncInvoker: thread id 2 has started. Total threads = 2.\nomniORB: (2) 2020-11-06 12:59:50.031512: AsyncInvoker: thread id 2 assigned to general tasks. Total general threads = 2.\nomniORB: (2) 2020-11-06 12:59:50.031552: AsyncInvoker: thread id 2 performing immediate general task.\nomniORB: (2) 2020-11-06 12:59:50.031575: Scavenger task execute.\nomniORB: (1) 2020-11-06 12:59:50.081241: SocketCollection idle. Sleeping.\nomniORB: (0) 2020-11-06 12:59:51.031650: Client attempt to connect to giop:tcp:10.0.0.247:2809\nomniORB: (0) 2020-11-06 12:59:51.031799: Client opened connection to giop:tcp:10.0.0.247:2809\nomniORB: (0) 2020-11-06 12:59:51.031812: sendChunky: to giop:tcp:10.0.0.247:2809 35 bytes\nomniORB: (0) 2020-11-06 12:59:51.031822: \n4749 4f50 0102 0103 1700 0000 0200 0000 GIOP............\n0000 206c 0b00 0000 4e61 6d65 5365 7276 .. l....NameServ\n6963 65                                 ice\nomniORB: (0) 2020-11-06 12:59:51.031607: omniORB: (0) 2020-11-06 12:59:50.031417: omniORB: (0) 2020-11-06 12:59:51.032369: inputMessage: from giop:tcp:10.0.0.247:2809 20 bytes\nomniORB: (0) 2020-11-06 12:59:51.032405: \n4749 4f50 0102 0104 0800 0000 0200 0000 GIOP............\n0100 0000                               ....\nomniORB: (0) 2020-11-06 12:59:51.032463: Send codeset service context: (ISO-8859-1,UTF-16)\nomniORB: (0) 2020-11-06 12:59:51.032505: sendChunky: to giop:tcp:10.0.0.247:2809 119 bytes\nomniORB: (0) 2020-11-06 12:59:51.032512: \n4749 4f50 0102 0100 6b00 0000 0400 0000 GIOP....k.......\n0300 0000 0000 0000 0b00 0000 4e61 6d65 ............Name\n5365 7276 6963 656f 1100 0000 6269 6e64 Serviceo....bind\n5f6e 6577 5f63 6f6e 7465 7874 0072 6561 _new_context.rea\n0100 0000 0100 0000 0c00 0000 0100 0000 ................\n0100 0100 0901 0100 0100 0000 0500 0000 ................\n7465 7374 006e 6563 0b00 0000 6d79 5f63 test.nec....my_c\n6f6e 7465 7874 00                       ontext.\nomniORB: (0) 2020-11-06 12:59:51.032501: omniORB: (0) 2020-11-06 12:59:51.032496: JET052\nomniORB: (0) 2020-11-06 12:59:51.033479: inputMessage: from giop:tcp:10.0.0.247:2809 81 bytes\nomniORB: (0) 2020-11-06 12:59:51.033528: \n4749 4f50 0102 0101 4500 0000 0400 0000 GIOP....E.......\n0100 0000 0000 0000 3500 0000 4944 4c3a ........5...IDL:\n6f6d 672e 6f72 672f 436f 734e 616d 696e omg.org/CosNamin\n672f 4e61 6d69 6e67 436f 6e74 6578 742f g/NamingContext/\n416c 7265 6164 7942 6f75 6e64 3a31 2e30 AlreadyBound:1.0\n00                                      .\n```\n\nanalyzing these two runs, I note that the strings for \"test\" and \"my_context\" are missing from the \"bind_new_context\" message in the broken code...  (this is why the naming service responds with an \"invalid name\" exception). In the broken code, the message is smaller, and the size field at the front of the message reflects the smaller size.\nThis is consistant with the \"bind_new_context\" function getting called with no argument (or with a NULL argument) in the broken code. But both examples use the same source code; calling the same bind_new_context function with the same rootContext and contextName variables, and populated the same way. So I presume there's got to be some kind of environment confusion that my build script introduces that isn't present in version compiled from within omniORB. This might also explain why the cleanup code has broken as well. But I've spent 2 days trying to shake it loose and I've come up empty.\nAny ideas?\nedit: this is the output from the tree's makefile that I based my build script on. There are differences, but nothing that seems substantive.\n```\n[jasont@dodeca3 echo]$ make veryclean ; make VERBOSE=1\nrm -f eg1 eg2_impl eg2_clt eg3_impl eg3_clt \\\n    eg3_tieimpl\nrm -f *.o *.a \nrm -f *.d\nrm -f *.pyc\nrm -f ../../../stub/echo.idl ../../../stub/echo.hh ../../../stub/echoSK.cc ../../../stub/echoDynSK.cc ../../../stub/echoSK.o ../../../stub/echoDynSK.o ../../../stub/echoSK.d ../../../stub/echoDynSK.d ../../../stub/dir.mk \ndir=../../../stub;  if [ ! -d $dir ]; then (umask 022; set -x; ../../../../bin/scripts/omkdirhier $dir); fi\nrm -f ../../../stub/echo.idl\n../../../bin/omniidl -bcxx -Wba -Wbtp -C../../../stub  ../../../../idl/echo.idl\n../../../bin/omkdepend -D__cplusplus -D__GNUG__ -D__GNUC__ -D__OMNIORB4__ -I../../../stub -D_REENTRANT -I. -I../../../../src/examples/echo -I../../../include -I../../../../include -D__OSVERSION__=2 -D__linux__ -D__x86_64__ ../../../../src/examples/echo/eg3_clt.cc ../../../../src/examples/echo/eg3_impl.cc ../../../../src/examples/echo/eg2_clt.cc ../../../../src/examples/echo/eg2_impl.cc ../../../../src/examples/echo/eg1.cc\ng++ -c -O2 -Wall -Wno-unused -fexceptions  -D__OMNIORB4__ -I../../../stub -D_REENTRANT -I. -I../../../../src/examples/echo -I../../../include -I../../../../include -D__OSVERSION__=2 -D__linux__ -D__x86_64__ -o eg1.o ../../../../src/examples/echo/eg1.cc\n\ncd ../../../stub\nmake[1]: Entering directory `/home/jasont/FACE_translator/omniORB-4.2.3/build2/stub'\n../bin/omkdepend -D__cplusplus -D__GNUG__ -D__GNUC__ -D__OMNIORB4__ -I../stub -D_REENTRANT -I. -I. -I../include -I/home/jasont/FACE_translator/omniORB-4.2.3/include -D__OSVERSION__=2 -D__linux__ -D__x86_64__ echoDynSK.cc echoSK.cc\ng++ -c -O2 -Wall -Wno-unused -fexceptions  -D__OMNIORB4__ -I../stub -D_REENTRANT  -I. -I. -I../include -I/home/jasont/FACE_translator/omniORB-4.2.3/include -D__OSVERSION__=2 -D__linux__ -D__x86_64__ -o echoSK.o echoSK.cc\nmake[1]: Leaving directory `/home/jasont/FACE_translator/omniORB-4.2.3/build2/stub'\n+ rm -f eg1\n+ g++ -o eg1 -O2 -Wall -Wno-unused -fexceptions -L../../../lib -L../../../../lib eg1.o ../../../stub/echoSK.o -lomniORB4 -lomnithread -lpthread\ng++ -c -O2 -Wall -Wno-unused -fexceptions  -D__OMNIORB4__ -I../../../stub -D_REENTRANT -I. -I../../../../src/examples/echo -I../../../include -I../../../../include -D__OSVERSION__=2 -D__linux__ -D__x86_64__ -o eg2_impl.o ../../../../src/examples/echo/eg2_impl.cc\n+ rm -f eg2_impl\n+ g++ -o eg2_impl -O2 -Wall -Wno-unused -fexceptions -L../../../lib -L../../../../lib eg2_impl.o ../../../stub/echoSK.o -lomniORB4 -lomnithread -lpthread\ng++ -c -O2 -Wall -Wno-unused -fexceptions  -D__OMNIORB4__ -I../../../stub -D_REENTRANT -I. -I../../../../src/examples/echo -I../../../include -I../../../../include -D__OSVERSION__=2 -D__linux__ -D__x86_64__ -o eg2_clt.o ../../../../src/examples/echo/eg2_clt.cc\n+ rm -f eg2_clt\n+ g++ -o eg2_clt -O2 -Wall -Wno-unused -fexceptions -L../../../lib -L../../../../lib eg2_clt.o ../../../stub/echoSK.o -lomniORB4 -lomnithread -lpthread\ng++ -c -O2 -Wall -Wno-unused -fexceptions  -D__OMNIORB4__ -I../../../stub -D_REENTRANT -I. -I../../../../src/examples/echo -I../../../include -I../../../../include -D__OSVERSION__=2 -D__linux__ -D__x86_64__ -o eg3_impl.o ../../../../src/examples/echo/eg3_impl.cc\n+ rm -f eg3_impl\n+ g++ -o eg3_impl -O2 -Wall -Wno-unused -fexceptions -L../../../lib -L../../../../lib eg3_impl.o ../../../stub/echoSK.o -lomniORB4 -lomnithread -lpthread\ng++ -c -O2 -Wall -Wno-unused -fexceptions  -D__OMNIORB4__ -I../../../stub -D_REENTRANT -I. -I../../../../src/examples/echo -I../../../include -I../../../../include -D__OSVERSION__=2 -D__linux__ -D__x86_64__ -o eg3_clt.o ../../../../src/examples/echo/eg3_clt.cc\n+ rm -f eg3_clt\n+ g++ -o eg3_clt -O2 -Wall -Wno-unused -fexceptions -L../../../lib -L../../../../lib eg3_clt.o ../../../stub/echoSK.o -lomniORB4 -lomnithread -lpthread\ng++ -c -O2 -Wall -Wno-unused -fexceptions  -D__OMNIORB4__ -I../../../stub -D_REENTRANT -I. -I../../../../src/examples/echo -I../../../include -I../../../../include -D__OSVERSION__=2 -D__linux__ -D__x86_64__ -o eg3_tieimpl.o ../../../../src/examples/echo/eg3_tieimpl.cc\n+ rm -f eg3_tieimpl\n+ g++ -o eg3_tieimpl -O2 -Wall -Wno-unused -fexceptions -L../../../lib -L../../../../lib eg3_tieimpl.o ../../../stub/echoSK.o -lomniORB4 -lomnithread -lpthread\n```\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Compiling a source file that has dependencies on multiple source code trees\r\n                \r\nHow can I compile a C source file that #include's header files from each of two independent source trees? Each source tree has its own set of makefiles, and the source trees are completely independent of each other.\n\nI'm writing a Wireshark plugin which interprets packets of a particular network protocol. In order to compile the plugin, the compiler needs to resolve symbols against the Wireshark source tree. However, in order for the plugin to actually interpret the network packet contents when Wireshark gives it a byte array, the plugin must also include definitions of data structures and RPC XDR routines from an entirely separate source tree. So the compiler also needs to resolve symbols against both Wireshark and a completely separate source tree containing these files.\n\nIs there an easy way to do this? Any suggestions at all would be very much appreciated.\n    ", "Answer": "\r\nMake sure you don't confuse compile with link. Not saying you are, but just pointing out there are two distinct steps.\n\nTo compile against tree1 and tree2, use the -I include directive to gcc. gcc -c -I/some/include/for/tree1 -I/some/include/for/tree2 input.c -o output.o\n\nto link against two trees, create .so or .la files (static or dynamic libraries ) from each tree. Call them tree1.la tree2.la. put them in /path/to/tree1/libs and /path/to/tree2/libs\n\nthen link\n\ngcc -o prog -ltree1 -ltree2 -L/path/to/tree1/libs -L/path/to/tree2/libs\n\nIf the trees are sufficiently large, they should end up creating static or dynamic libraries of object code. Then you just point to their headers to compile and point to their libs to link.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "SAS CART Analysis\r\n                \r\nTo get started with decision trees I want SAS to produce a decision tree from a data set with one dependent, binary variable (disease 0/1) and several independent, continuous variables (usually I would run logistic regression for these data). The tree should \"decide\" which variables are important risk factors for the disease. Any hints for a beginner in decision trees but fairly experienced SAS user (no access to SAS enterprise miner)?\n    ", "Answer": "\r\nIf you use SAS EG and Miner, you can use function in the Task->Data mining->Rapid Predictive Modeler to run decesion tree. In the process, it allows you to choose model type, CART is in it. Then you export your process to MINER for tweaking your settings. \nHope it could help. \n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to determine the most suitable value for ntree while building random forests in r?\r\n                \r\nI'm doing a task which need to build random forests with regression. In the data set, there are 32 independent variables. How can i determine the value for number of trees I need to grow? Is there any command functions can help me to determine ntree value?\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Feature selection with Decision Tree\r\n                \r\nI'm supposed to perform feature selection of my dataset (independent variables: some aspects of a patient, target varibale: patient ill or not) using a dcision tree. After that with the features selected I've to implement a different ML model.\nMy doubt is: when I'm implementing the decison tree is it necessary having a train and a test set or just fit the model on the whole data?\n    ", "Answer": "\r\nit's necessary to split the dataset into train-test because otherwise you will measure the performance with data used in training and could end up into over-fitting.\nOver-fitting is where the training error constantly decrease but the generalization error increase, where by generalization error is intended as the ability of the model to classify correctly new (never seen before) samples.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "python parse bnf grammar and walk\r\n                \r\nI have thousand independent bnf grammar strings on hand, and try to figure out the deepest one or a set for some conditions, so I try to look for some python packages to help on this purpose. (e.g. parse bnf grammar and walk through the AST tree generated).\n  Does grako help on this?\n  Thanks in advance.\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to compare the results of different statistical tests?\r\n                \r\nI don't know if it is a good question or not. \n\nHere's the case, say I have a scale/continuous dependent variable and a bunch of independent variables. My ultimate goal is to build a model to predict/estimate the dependent variable using these independent variables. I believe it's a common setting.\n\nThe point is that I know the physical meaning of all the variables, but I don't know their detailed relationship (or even related or not). I want to build a model more from an analysis/explanation point of view so that I could get some real-world insights from the model, instead of a black box.\n\nMy approach is trying to use CHAID kind of algorithm to build a decision tree type of model. At every branch, I want to statistically test each independent variable to see if there's relation between it and the dependent variable. Then, based on the test result, I want to pick the most powerful one to build my tree.\n\nThe problem is, unlike CHAID algorithm, where most variables are categorical, in my case, the dependent variable is scale, and independent variables are categorical or scale, which means I might need to do different statistical tests for different variables, e.g. t-test and ANOVA for categorical ones and regression for continuous ones. I'm wondering how should I fairly compare these results to pick the most powerful one? (like the correction step in CHAID)\n\nAny idea on any part of my plan is of great importance to me! Thanks!\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "my Python multiprocesses are apparently not independent\r\n                \r\nI have a very specific problem with python parallelisation let's see if I can explain it,\nI want to execute a function ```\nfoo()```\n using the multiprocessing library for parallelisation.\n```\n# Creation of the n processes, in this case 4, and start it\nthreads = [multiprocessing.Process(target=foo, args=(i)) for i in range(n)]\nfor th in threads:\n    th.start()\n```\n\nThe ```\nfoo()```\n function is a recursive function who explores a tree in depth until one specific event happens. Depending on how it expands through the tree, this event can occur in a few steps, for example 5 or even in millions. The tree nodes are a set of elements and in each step I select a random element from this set with ```\nrand_element = random.sample(node.set_of_elements,1)[0]```\n and make a recursive call accordingly to them, i.e., two different random elements have different tree paths.\nThe problem is that for some unknown reason, the processes apparently does not behave independently. For example, if I run 4 processes in parallel, sometimes they return this result.\n```\n1, Number of steps: 5\n2, Number of steps: 5\n3, Number of steps: 5\n4, Number of steps: 5\n\n```\n\nthat is to say, all the processes take the \"good path\" and ends in a very few steps. On the other hand, other times it returns this.\n```\n1, Number of steps: 6516\n2, Number of steps: 8463\n3, Number of steps: 46114\n4, Number of steps: 56312\n```\n\nthat is to say, all the processes takes \"bad paths\". I haven't had a single execution in which at least one takes the \"good path\" and the rest the \"bad path\".\nIf I run ```\nfoo()```\n multiple times sequentially, more than a half of execution ends with less than 5000 steps, but in concurrency I don't see this proportion, all the processes ends either fast or slow.\nHow is it possible?\nSorry if I can't give you more precise details about the program and execution, but it is too big and complex to explain here.\n    ", "Answer": "\r\nI have found the solution, I post it in case someone finds it helpful\nThe problem was that at some point inside ```\nfoo()```\n, I have used the ```\nmy_set.pop()```\n method instead of ```\nset.remove(random.sample (my_set, 1) [0])```\n. The first one, ```\nmy_set.pop()```\n doesn't actually return a random element. In Python 3.6 sets have a concrete order like lists, the key is that the established order is generated randomly, so, to return a (pseudo)random element, the ```\nmy_set.pop()```\n method, always returns the first element. The problem was that in my case, all processes share that order, so ```\nmy_set.pop()```\n returns the same first element in all of them.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Best test runner? (Unit Testing, .NET) [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is opinion-based. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it can be answered with facts and citations by editing this post.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI'm using MBUnit Framework for unit testing and looking for a good test runner.\n\nMbUnit's runner is fast however lacking lots of stuff such as \n\n\nYou can't set execution path\nIt's collapsing all trees in every run which drives me crazy\nAnd almost all other test runner provides so many extra quite and lovely features\n\n\nI used Zanebug, but:\n\n\nNot properly supported any more, kind of a dead project\nI think it's not compatible with latest MBUnit because it keeps crashing on me\nGot so many weird bugs\n\n\nGallio\n\n\nDon't know why keeps crashing on startup, (Vista x64)\nI've got it run in another setup, it's about 6 times slower than MBUnit GUI and I've got so many test,\n\n\nTest Driven .NET addon\n\n\nThis is great little tool but just for testing one or unit test, doesn't provide a good or VS.NET independent GUI\n\n\nI'm open to any other free test runner which works with or independent from VS 2008\n    ", "Answer": "\r\nI really enjoy NUnit. Now I enjoy even more since I can use it inside the IDE with ReSharper that let me do quick test for a method very fast.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Adaboost and forward stagewise additive modeling\r\n                \r\nAlthough it wasn't originally conceived this way, the standard Adaboost algorithm is equivalent to conducting a forward stagewise additive model estimation using an exponential loss function. That is, given some weak classifiers c1,...,cM, and sample points x1,...,xN the weights coming out of the algorithm:\n\n\nSet F_0(x) = 0\nFor m = 1 to M:\n  Set (w_m, f_m ) = arg min over (w, c_i) of (Loss function(y_i, F_m-1(x_i) + w * c_i(x_i)) applied to all x_i's)\nSet F_m(x) = F_m-1(x) + w_m * f_m(x)\n\n\nThe strong classifier is the output, F_M(x). The loss function that makes this strong learner the same as the Adaboost output is\n\n```\nL(y,f(x)) = exp(-y*f(x))\n```\n\n\nfor classifiers taking values in {-1,1}. This is all explained in Hastie, Tibshirani, Friedman, Elements of Statistical Learning, Section 10.4.\n\nMy question has to do with forward stagewise regression. It is a greedy algorithm, in that once w_i is estimated, it is fixed, then the weight w_i+1 is found, etc. This seems like it is really designed to handle \"independent\" weak classifiers, like stump classifiers, or tree classifiers restricted to mutually exclusive independent variables (features), so that the residual piece after fitting a classifier is not explained by that classifier any more. \n\nIn other words, to fit a set of functions to an given target function, I wouldn't fit the first one, fix that coefficient, then find the optimal coefficient for the second, holding the first constant, etc... unless I knew that the functions were independent. But this is what the algorithm does, more or less.\n\nDoes this explain the success of Adaboost with stump learners or decision trees compared to (from my experience) Adaboost with more comprehensive classifiers like SVM, or a linear model? Can someone give a reference? - I have not seen this aspect discussed in the literature. Thanks.\n    ", "Answer": "\r\nI think you may be a bit confused, or using terminology I'm not familiar with. Nothing in AdaBoost or more general stage wise additive models is independent or mutually exclusive, nor were the designed to be mutually exclusive. \n\n\n  Does this explain the success of Adaboost with stump learners or decision trees compared to (from my experience) Adaboost with more comprehensive classifiers like SVM, or a linear model? \n\n\nNo. Methods that produce an ensemble of classifiers can be powerful, and their power comes mostly from the ability to reduce the error caused by variance of the base model. AdaBoost & others can also reduce the bias, but it is much easier to reduce variance induced error. \n\nFor this reason we use Decision Trees, as we can control the level of bias/variance on the tree by altering the maximum depth of the tree. This makes life easy, but they are not the end all of boosting (example: boosting in a high dimensional space is quite difficult, and trees are horrible in such situations). \n\nWe don't usually use linear models in boosting because they simply aren't that good at it. We can produce \"easy\" data sets that will not converge well being boosted by linear models without too much thought (consider 1 ring in another where each class is of equal size, and a base learner that cuts the inner (and therefor outer) ring in half). A lowly decision stump is often better simply because it has a non-linearity in it, allowing for a much faster adaption to the data. \n\nWe avoid complex models such as SVMs because they take a long time to train. Regardless of what base model you choose, AdaBoost is going to run towards the same type of solution (it tries to maximize the L1 margin, where SVMs maximize the L2 margin). If you have to boost 1000 trees, or 500 SVMs, its going to probably be a lot faster to boost the trees. This doesn't even get into all the parameter search you would have to do for each SVM for each model added. It is simply too time consuming. However, there are cases where this can work well - here is a face detection case.\n\nThere is also the issue of prediction time. If you need to boost 100 or 1000 models, its going to increase the prediction time by a 2 or 3 orders of magnitude. SMVs are already not the fastest predictors, and this only makes the situation worse. \n\nThe details of this are more picked up from the math then discussed in english. If you are interested in more explicit discussion of the issue about why such models work, read some of Leo Breiman's papers. \n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Determing the mode using bagging with decision tree\r\n                \r\nI have a dataset with 5 independent variables and a categorical dependent variable. \n\nI would like to develop a code in R that allows me to predict the final results for a test data set. \n\nI would like to implement bagging using as classifier a decision tree. In order to obtain the final predictions I would like to use the uniform voting procedure. \n\nThe code that I developed is the following\n\n```\nset.seed(10)\n\nall_data<-qwe\n\npositions <- sample(nrow(all_data),size=floor((nrow(all_data)/5)*4))\n\ntraining<- all_data[positions,]\n\ntesting<- all_data[-positions,]\n\nn <-10\n\nfor (i in 1:n ){\n\n  training_positions <- sample(nrow(training), size=floor((nrow(training)/3)))\n\n  train_pos<-1:nrow(training) %in% training_positions\n\n  model_tree <- rpart(UNS~., data=training[train_pos,])\n\n  pred <- predict(model_tree, newdata = testing, type=\"class\")\n\n  print(as.matrix(pred))\n\n  plot(pred)\n\n  text(pred)\n\n}\n```\n\n\nI have the predictions made by each decision tree (10 decision trees), but I do not know how to determine the most common prediction for each observation ( I mean the mode). \n\nAny help would be welcome!\n\nThanks in advance!\n\nBest regards, \n\nLiza Vieira\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Why are these types not assignment compatible, and how can I define an assignment compatible class?\r\n                \r\nI implement a map based on two type arguments ```\n<K,V>```\n, where ```\nK```\n is the key type and ```\nV```\n is the value type.\n\n```\npublic class Map<K,V> implements Map<K,V>\n{ .. implementation .. }\n```\n\n\nOne method in the ```\nMap```\n interfaces returns the set of map entries.\n\n```\npublic Set<java.util.Map.Entry<K,V>> entrySet()\n```\n\n\nSince my map implementation is based on an AVL tree, another class must be implemented as ```\nSet<MapNode>```\n\n\n```\npublic class EntrySet<K,V> implements Set<MapNode<K,V>>\n{ .. implementation ..}\n```\n\n\nIn order to tell that the nodes of the map tree are indeed map entries, they are defined as follows:\n\n```\npublic class MapNode<K,V> implements Map.Entry<K,V>\n{ .. implementation .. }\n```\n\n\nSo EntrySet contains the same tree as the ```\nMap```\n itself, but treats the tree nodes as the set elements (which is why it has to be implemented separately).\n\nThe method in the map implementation, returning the set of entries, should therefore look as follows:\n\n```\n/* (non-Javadoc)\n * @see java.util.Map#entrySet()\n */\n@Override\npublic Set<java.util.Map.Entry<K,V>> entrySet()\n{\n    return new EntrySet<K,V>(this.comparator,this.tree);\n}\n```\n\n\nYet, the compiler gives me the following error:\n\n\"Type mismatch: cannot convert from ```\nEntrySet<K,V>```\n to ```\nSet<Map.Entry<K,V>>```\n\"\n\nMy questions:\n\n\nIs my following assumption correct? (Or if not, what is the problem?)\n\n\nA set of ```\nMap.Entry<K,V>```\n would have to be able to contain all sorts of ```\nMap.Entry<K,V>```\n, not just the ```\nMapNode<K,V>```\n objects. It is therefore, logically, not the case that ```\nEntrySet<K,V>```\n is a ```\nSet<Map.Entry<K,V>```\n, and therefore these two set types are not considered assignment compatible.\n\n\nIs there any other way to define a class ```\nEntrySet<K,V>```\n, based on the same tree structure (I do not want to increase run time by creating or invoking another data structure) such that an object of this class can be returned wherever ```\nSet<Map.Entry<K,V>```\n is required?\n\n\nUpdate:\n\nI have tried the following version:\n\n```\n public class EntrySet<K,V> implements Set<MapNode<K,V>>\n { .. implementation ..}\n```\n\n\nIn this case the iterator creates a similar problem. There exists an iterator class that neatly traverses the whole tree, but it is defined as the iterator of a super class of ```\nMapNode<K,V>```\n, and this iterator cannot be cast to the required ```\nIterator<Map.Entry<K,V>>```\n\n\n```\n@Override\npublic Iterator<Map.Entry<K,V>> iterator()\n{\n    // this iterator type can not be cast to the desired return type\n    return new TreeNodeIterator<MapNode<K,V>,K>(this.tree);\n}\n```\n\n\nI might copy the whole iterator code and rudely use it in a new, independent iterator class, but I'd prefer a more elegant solution.\n\nSo I am still stuck here.\n\nUpdate:\n\nIn the mean time, I have created another independent iterator class that boxes the original iterator and converts the \"next\" element accordingly. This is not really elegant, but at least it works for the time being. Still, any more elegant solution will be very welcome!\n    ", "Answer": "\r\n\n  Why are these types not assignment compatible?\n\n\nThe problem is that the signature of ```\nMap::entrySet()```\n says it is supposed to return a set of any ```\nMap.Entry<K,V>```\n objects.  But your returned object only supports entries that are ```\nMapNode```\n objects.\n\nThe (conceptual) reason that that is a problem, is a ```\nSet```\n allows insertion as well as removal of elements, and the ```\nSet<java.util.Map.Entry<K,V>>::add(...)```\n should be able to add any ```\nMap.Entry<K,V>```\n to the set.  But that would not be allowed by the signature of your ```\nEntrySet```\n implementation.\n\n\n  How can I define an assignment compatible class?\n\n\nI suggest that you try this:\n\n```\npublic class EntrySet<K,V> implements Set<? extends Map.Entry<K,V>>\n  { .. implementation ..}\n```\n\n\nor this\n\n```\npublic class EntrySet<K,V> implements Set<Map.Entry<K,V>>\n  { .. implementation ..}\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Porting and existing nested set hierarchy\r\n                \r\nI have a nested set category table developed with the PHP ORM Doctrine and I would like to port it to a Django app.\n\nI started porting it to django-treebeard, but I am having difficulties and I am not sure it can work.\nThe original table had the needed fields lft, rgt and depth, so I added the tree_id field.\n\nI also had a foreign key to Accounts with one tree/account. Thus the table hold multiple independent trees that are not under a common root, with the lft and depth columns starting at 1 for each tree. So basically one nested set for each account in the table.\n\nI can add nodes to a tree just fine, but when I call the get_last_child method, I get nodes from other accounts.\n\nDoes anyone know if there is a way to use treebeard, mptt or any other package without having to restructure the trees?\n    ", "Answer": "\r\nI made some progress by adding the correct tree_id as a sequential number by account_id, which fixed some of the issues, with the query:\n\n```\nUPDATE category c,\n(SELECT id, DENSE_RANK() OVER (ORDER BY account_id) AS  seq\nFROM category ) tree_rank\nSET c.tree_id = tree_rank.seq\nWHERE c.id = tree_rank.id;\n```\n\n\nNow trying to get the admin to work.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Metalanguage like BNF or XML-Schema to validate a tree-instance against a tree-model\r\n                \r\nI'm implementing a new machine learning algorithm in Java that extracts a prototype datastructure from a set of structured datasets (tree-structure). As im developing a generic library for that purpose, i kept my design independent from concrete data-representations like XML.\n\nMy problem now is that I need a way to define a data model, which is basically a ruleset describing valid trees, against which a set of trees is being matched. I thought of using BNF or a similar dialect.\n\nBasically I need a way to iterate through the space of all valid TreeNodes defined by the ModelTree (Like a search through the search space for algorithms like A*) so that i can compare my set of concrete trees with the model. I know that I'll have to deal with infinite spaces there but first things first.\n\nI know, it's rather tricky (and my sentences are pretty bumpy) but I would appreciate any clues.\n\nThanks in advance,\nStefan\n    ", "Answer": "\r\nI believe that you are talking about a Regular Tree Grammar.  This Wikipedia page is an entry point for the topic, and the book that it links to might be helpful.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Java: Sorting TreeSets based on size\r\n                \r\nI am looking for a way to sort a set of sets - more specifically, the data structure is required to have the following properties:\n\n\nBoth the \"outer\" and the \"inner\" collection should be sets, i.e. there should be no duplicate elements within contained sets and no duplicate sets.\nThe set should be sorted according to the length of the contained sets in ascending order, i.e. {{A}, {A, B}, {A, C, F}, {B, D, F}} is valid whereas {{A, C, F}, {A, B}, {B, D, F}, {A}} is not.\nIt should be possible to iterate over individual contained sets as well as over all sets. Naturally, iterating over all sets should list them in ascending order based on their respective sizes.\nIf two sets have the same size, the order may be arbitrary.\n\n\nMy basic approach is a ```\nTreeSet<TreeSet<T>>```\n, although since the contained TreeSets need to be sorted in a custom behaviour, I have written a wrapper class (unnecessary details omitted, such as additional constructors and methods):\n\n```\nimport java.util.TreeSet;\nimport java.util.Iterator;\nimport java.util.Collection;\n\npublic class WrappedSet< T > implements Comparable< WrappedSet< T >>, Iterable< T >  {\n    protected TreeSet< T > set;\n\n    public WrappedSet( Collection< T > collection ) {\n        set = new TreeSet< T >( collection );\n    }\n\n    public int size() {\n        return set.size();\n    }\n\n    @Override\n    public Iterator< T > iterator() {\n        return set.iterator();\n    }\n\n    @Override\n    public int compareTo( WrappedSet< T > other ) {\n        if ( set.equals( other.set )) {\n            return 0;\n        }\n        else {\n            return ( set.size() >= other.set.size()) ? 1 : -1;\n        }\n    }\n\n    @Override\n    public String toString() {\n        return set.toString();\n    }\n}\n```\n\n\nFor the purpose of showing the problem, I am using this main function:\n\n```\npublic static void main( String[] args ) {\n    TreeSet< WrappedSet< String >> wsets = new TreeSet< WrappedSet< String >>();\n\n    for ( String arg : args ) {\n        wsets.add( new WrappedSet< String >( new TreeSet< String >( Arrays.asList( arg.split( \",\" )))));\n    }\n\n    System.out.println( \"Input sets: \" + Arrays.toString( wsets.toArray()));\n}\n```\n\n\nI understand that if my .equals() for this class was based on testing the individual sets for equality, my \"class [would have] a natural ordering that is inconsistent with equals\", as the CompareTo documentation phrases it. I also understand that this is probably the reason why the output is (sometimes) incorrect. Consider the following example:\n\nInput (command line): A,B,E A,C,F B,D,F A A,B,E\nOutput: Input sets: [[A], [A, B, E], [A, C, F], [B, D, F], [A, B, E]]\n\nAs you can see, {A, B, E} comes up twice, and I suppose this is because the TreeSet traverses the tree in order to find an existing entry with this value, but ends up not finding it because the order of the elements is independent of their actual values - only their sizes.\n\nHow could I achieve the desired behaviour in a consistent way? Please note that this is not homework. Solutions not based on TreeSets are therefore naturally welcome.\n    ", "Answer": "\r\nFor your outer ```\nTreeSet```\n to accept two different sets of the same size as different elements, you need to decide a sorting order of them even when you don’t care about their order. Otherwise your set will not work as you expected.\n\nRather then a wrapper class for the inner ```\nTreeSet```\ns I think I’d prefer just to write a comparator. But make sure your comparator defines a total ordering on the inner sets and only declares two sets equal of they are indeed equal also in the sense that only one of them should be in the set. And as RealSkeptic and others have said in comments, in order to fulfil the ```\nComparator```\n contract, you need to fulfil:\n\n\n  The implementor must ensure that ```\nsgn(compare(x, y)) ==\n  -sgn(compare(y, x))```\n for all ```\nx```\n and ```\ny```\n.\n\n\n(from the documentation)\n\nHere’s just a very rough example of a ```\nComparator```\n that does compare more than just the size when the size is the same. It’s not hard to devise an example where it still doesn’t do well enough, but I will leave it to you to write the right comparator for your situation.\n\n```\n    Comparator<TreeSet<?>> compareBySize \n            = Comparator.comparing((TreeSet<?> s) -> s.size())\n                    .thenComparing(TreeSet::toString);\n\n    TreeSet<TreeSet<Character>> mySet = new TreeSet<>(compareBySize);\n    mySet.addAll(Arrays.asList(\n                new TreeSet<>(Arrays.asList('A', 'B', 'E')),\n                new TreeSet<>(Arrays.asList('A', 'C', 'F')),\n                new TreeSet<>(Arrays.asList('B', 'D', 'F')),\n                new TreeSet<>(Arrays.asList('A')),\n                new TreeSet<>(Arrays.asList('A', 'B', 'E'))\n            ));\n    System.out.println(mySet);\n```\n\n\nThis prints\n\n```\n[[A], [A, B, E], [A, C, F], [B, D, F]]\n```\n\n\nI believe this is correct.\n\nAs an aside, it is generally recommended to program towards interfaces rather than implementations. If you want to do this, depending on your further requirements, either use the ```\nSortedSet```\n or the ```\nNavigableSet```\n interface. You need two changes: First, the comparator should be (using ```\nSortedSet```\n in my example):\n\n```\n    Comparator<SortedSet<?>> compareBySize \n            = Comparator.comparing((SortedSet<?> s) -> s.size())\n                    .thenComparing(SortedSet::toString);\n```\n\n\nSecond declare your set as ```\nSortedSet<SortedSet<Character>> mySet```\n, but still use ```\nnew TreeSet<>(…)```\n in the instantiations.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Is there a package that I can use in order to get rules for a target outcome in R\r\n                \r\nFor example In this given data set I would like to get the best values of each variable that will yield a pre-set value of \"percentage\" : for example I need that the value of \"percentage\" will be >=0.7 so in this case the outcome should be something like: \n\n```\nbirds >=5,1<wolfs<=3 , 2<=snakes <=4\n```\n\n\nExample data set: \n\n```\ndat <- read.table(text = \"birds    wolfs     snakes  percentage\n3         8          7         0.50\n1         2          3         0.33\n5         1          1         0.66\n6         3          2         0.80\n5         2          4         0.74\",header = TRUE\n```\n\n\nI can't use decision trees as I have a large data frame and I can't see all tree correctly. I tried the ```\n*arules*```\n package as but it requires that all variables will be factors and I have mixed dataset of factor,logical and continuous variables and I would like to keep the variables and the Independent variable continues .Also I need \"percentage\" variable to be the only one that I would like to optimize. \nThe code that I wrote with ```\n*arules*```\n package is this:\n\n```\nlibrary(arules)\ndat$birds<-as.factor(dat$birds)\ndat$wolfs<-as.factor(dat$wolfs)\ndat$snakes<-as.factor(dat$snakes)\ndat$percentage<-as.factor(dat$percentage)\nrules<-apriori(dat, parameter = list(minlen=2, supp=0.005, conf=0.8))\n```\n\n\nThank you\n    ", "Answer": "\r\nI may have misunderstood the question but to get the maximum value of each variable with the restriction of ```\npercentage >= 0.7```\n you could do this:\n\n```\nlapply(dat[dat$percentage >= 0.7, 1:3], max)\n\n$birds\n[1] 6\n\n$wolfs\n[1] 3\n\n$snakes\n[1] 4\n```\n\n\nEdit after comment:\n\nSo perhaps this is more what you are looking for:\n\n```\n> as.data.frame(lapply(dat[dat$percentage >= 0.7,1:3], function(y) c(min(y), max(y))))\n  birds wolfs snakes\n1     5     2      2\n2     6     3      4\n```\n\n\nIt will give the min and max values representing the ranges of variables if ```\npercentage >=0.7```\n\n\nIf this is completely missing what you are trying to achieve, I may not be the right person to help you.\n\nEdit #2:\n\n```\n> as.data.frame(lapply(dat[dat$percentage >= 0.7,1:3], function(y) c(min(y), max(y), length(y), length(y)/nrow(dat))))\n  birds wolfs snakes\n1   5.0   2.0    2.0\n2   6.0   3.0    4.0\n3   2.0   2.0    2.0\n4   0.4   0.4    0.4\n```\n\n\nRow 1: min\nRow 2: max\nRow 3: number of observations meeting the condition\nRow 4: percentage of observations meeting the condition (relative to total observations)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Training a decision tree with K-Fold - Is this the correct approach?\r\n                \r\nI've used two approaches with the same SKlearn decision tree, one approach using a validation set and the other using K-Fold. I'm however not sure if I'm actually achieving anything by using KFold. Technically the Cross Validation does show a 5% rise in accuracy, but I'm not sure if that's just the pecularity of this particular data skewing the result.\n\nFor my implementation of KFold I first split the training set into segments using:\n\n```\n f = KFold(n_splits=8)\n f.get_n_splits(data)\n```\n\n\nAnd then got data-frames from it by using \n\n```\ny_train, y_test = y.iloc[train_index], y.iloc[test_index]\n```\n\n\nIn a loop, as witnessed in many online tutorials on how to do it. However, here comes the tricky part. The tutorial I saw had a .train() function which I do not think this decision tree classifier does. Instead, I just do this:\n\n```\n    tree = tree.DecisionTreeClassifier()\n    tree.fit(X_train, y_train)\n    predictions = tree.predict(X_test)\n```\n\n\nThe accuracy scores achieved are:\n\n```\nAccuracy score: 0.79496591505\nAccuracy score: 0.806502359727\nAccuracy score: 0.800734137389\n... and so on\n```\n\n\nBut I am not sure if I'm actually making my classifier any better by doing this, as the scores go up and down. Isn't this just comparing 9 independent results together? Is the purpose of K-fold not to train the classifier to be better?\n\nI've read similar questions and found that K-fold is meant to provide a way to compare between \"independent instances\" but I wanted to make sure that was the case, not that my code was flawed in some way. \n    ", "Answer": "\r\n\n  Is the purpose of K-fold not to train the classifier to be better?\n\n\nThe purpose of the K-fold is to prevent the classifier from over fitting the training data. So on each fold you keep a separate test set which the classifier has not seen and verify the accuracy on it. You average your prediction to see how best your classifier is performing. \n\n\n  Isn't this just comparing 9 independent results together?\n\n\nYes, you compare the different scores to see how best your classifier is performing\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Independent Eyes and Mouth animations in unity3d\r\n                \r\nI am trying to independently animate mouth, eyes and facial expressions on a 3D humanoid character in Unity. The problem I am having is the animation system always blends the eyes and mouth, making the character look like a slack-jawed yokel.\n\nI have bones for neck, head, jaw, and 1 for each eye.\n\nWhat I have tried.\n\nAttempt 1\n\nCreate 3 layers. 1 for a body, 1 for a mouth, 1 for eyes. Add a head mask to the mouth and eye layers. Set the weight to 1, Blending to override for all layers.\n\nWhat happens is the blend weight just gets set to 0.5 for both head layers.\n\nAttempt 2\n\nUse 1 body layer and 1 head layer with a head mask. In the head layer, use a Blend tree with a Direct Blend type. Have nested blend types for eye movement and jaw movement.\n\nWhat happens is the blend weight just gets divided up between them. Mouth hangs open.\n\nAttempt 3.\n\nUse a transformed mask on the model animations. Restrict the Eye movement to just the transforms for the eye. Mouth animations to the jaw. Under mask restrict using Humanoid head and then Transform body or eyes, depending on the animation.\n\nThe Transform I need to mask it to a greyed out (because it's a humanoid model). Restricting it to a mesh makes the whole mesh move based on jaw movement or other weird things.\n\nThe question is how do you make parts of the face move independently from other parts. I want my character to be able to talk and look separately from each other, like in the real world.\n    ", "Answer": "\r\nI got this working by using only the jaw bone in the animator and using scripts to control the eyes and blend shapes (blinking).\n\nFor anyone trying to do the same thing.\n\nI have seen YouTube video where they control multiple blend shapes using a blend tree with blend type of direct, but could not get that working. I suspect they did not have any bones in the face. \n\nAnother YouTube video of a red breasted robin animation who mixed shape keys and bone animations using the NLA Editor. \n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How good can Nearest Neighbor, Naive Bayes and a Decision Tree classifier solve the given classification problem?\r\n                \r\nThe 3 diagramms (i), (ii), (iii)  show training sets having 2 numerical attributes (x and y axis) and a target attribute with two classes (circle and square).\nI am now wondering how good the data mining algorithms (Nearest Neighbor, Naive Bayes and Decision Tree) solve each of the classification problems.\nI suppose that the Naive Bayes (with the naive assumption that the attributes are uncorrelated) solves the second problem better than (i) and (iii) because here the numerical attributes tend to be more independent from each other.\n    ", "Answer": "\r\nIf you want to use each of given methods on such scenarios:\n\nFirst one could be solved best with a decision tree approach cos classes can separate by axises. I mean draw a perpendicular line on x axis that separates values into left and right side and draw another line perpendicular on y axis so you will see that classes will be separated well.\n\nSecond one can be considered as a Naive Bayes problem as you mentioned.\n\nThird one can be solved with k nearest neighborhood approach. Square classes are at near positions on coordinate system and circle classes can be classified with some error too.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Stackless pre-order traversal in a binary tree\r\n                \r\nIs it possible to perform iterative *pre-order* traversal on a binary tree without using node-stacks or  \"visited\" flags? \n\nAs far as I know, such approaches usually require the nodes in the tree to have pointers to their parents. Now, to be sure,   I know how to perform pre-order traversal using parent-pointers and visited-flags thus eliminating any requirement of stacks of nodes for iterative traversal.\n\nBut, I was wondering if visited-flags are really necessary. They would occupy a lot of memory if the tree has a lot of nodes. Also, having them would not make much sense if many pre-order tree traversals of a binary-tree are going on simultaneously in parallel.\n\nIf it is possible to perform this, some pseudo-code  or better a short C++ code sample would be really useful. \n\nEDIT: I specifically do not want to use recursion for pre-order traversal. The context for my question is that I have an octree (which is like a binary tree) which I have constructed on the GPU. I want to launch many threads, each of which does a tree-traversal independently and in parallel.\n\nFirstly, CUDA does not support recursion. \nSeoncdly, the concept of visited flags applies only for a single traversal. Since many traversals are going on simultaneously , having visited-flags field in the node data structure is of no use. They would make sense only on the CPU where all independent tree traversals are/can be serialised. To be more specific,  after every tree-traversal we can set the visited-flags to false before performing another pre-order tree-traversal\n    ", "Answer": "\r\nYou can use this algorithm, which only needs parent pointers and no additional storage:\n\nFor an inner node, the next node in a pre-order traversal is its leftmost child.\n\nFor a leaf node: Keep going upwards in the tree until you are coming from the left child of a node with two children. That node's right child will then be the next node to traverse.\n\n```\nfunction nextNode(node):\n    # inner node: return leftmost child\n    if node.left != null:\n        return node.left\n    if node.right != null:\n        return node.right\n\n    # leaf node\n    while (node.parent != null)\n        if node == node.parent.left and node.parent.right != null:\n            return node.parent.right\n        node = node.parent\n\n    return null  #no more nodes\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Neos CMS 7: Newly created node disappears in the document tree until cache cleared\r\n                \r\nIs the document tree cached in the Neos CMS backend? I have created two pages under \"Home\": \"Neos CMS\" and \"Blog\" and they are displayed correctly in the main menu of the page preview, but when I click on one of the two page nodes in the document tree, the \"Blog\" node disappears in the document tree. Only when I click on the \"Home\" node or the tree refresh button, the \"Blog\" node temporarily reappears. When flushing the cache via CLI command ```\n./flow flow:cache:flush```\n the node becomes permanently visible.\nThis behavior is browser independent; normally I use Firefox, just now I used Vivaldi with default settings.\nI used the CodeQ Skeleton as the base distribution, but others have confirmed the behavior for the official Neos Base Distribution as well.\nI can provide a bash script that builds up a Neos instance for repeating reproduction of this behaviour.\n    ", "Answer": "\r\nJust for reference here is the link to the Github issue https://github.com/neos/neos-ui/issues/3248\nBest would be to reproduce the issue without the Skeleton Package.\nI'm not aware of anything in the cache that should influence the document tree. Maybe it's another plugin installed with the Skeleton distribution.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Data binding to jsTree\r\n                \r\nWhat I'm looking to do is bind some dynamic data to a jsTree (i.e. a tree component from this library) tree using a JS framework. I'm incidentally using vue.js but this problem is totally framework independent. At the moment it looks like jsTree only supports setting the tree data on initialization, i.e. when you call ```\n$().jstree()```\n, which is not what I want, as my data will change over time, and I want this to be reflected in the tree itself.\n\nThe most obvious way, binding to HTML and then creating jsTree on these elements doesn't work because jsTree removes the original HTML from the DOM when it initializes: \n\n```\n<div id=\"jsTree\">\n    <!--This is all destroyed :( -->\n    <ul>\n        <li v-repeat=\"nodes\"> {{$value}} </li>\n    </ul>\n</div>\n```\n\n\nHowever if you just play with the DOM and manually add nodes to the tree after it has initialized, it looks fine. But you can't bind data to the DOM after the page has been compiled by the framework (without difficulty).\n\nSo how can jsTree be used with data binding?\n    ", "Answer": "\r\nSince I found no existing solutions, I made two of my own.\n\nFirstly is jsTreeBind. It does exactly what I wanted when I made this post. You create a hidden tree of standard HTML elements with DOM templating (```\n<div>s```\n for example), and then the plugin converts this tree into a jsTree, updating on the fly to keep up with DOM updates. \n\nHowever I eventually realized that this isn't actually a very good solution, since scope data was being duplicated 4 times. If you think about the original scope data used to generate the jsTree, this data was being stored once in the framework's scope (1), once in the DOM view it's bound to (2), once in the jsTree json data (3), and once in the jsTree DOM (4). \n\nSo in light of this, I made Botany, a library that makes tree views (like jsTree), but declaratively, meaning that you just bind data to the DOM, and apply the ```\n.botany```\n class, and it suddenly looks like a tree. The data doesn't go through a convoluted series of transforms, and will update automatically because that's how CSS works. The project isn't totally finished, but I recommend having a look, and helping out with suggestions or contributions if you can!\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Full training set used by dask_lightgbm?\r\n                \r\nI'm reading over the implementation of the dask-lightgbm estimators (specifically, the ```\n_train_part```\n function in dask_lightgb.core.py), and I'm failing to see how the entirety of the training set gets used to fit the final estimator?\nThe ```\n_train_part```\n function accepts the boolean argument ```\nreturn_model```\n, and in the implementation of the ```\ntrain```\n function (which uses ```\nclient.submit```\n to call ```\n_train_part```\n on each worker), ```\nreturn_model```\n is only true when the worker is the \"master_worker\" (which itself appears to be a randomly chosen Dask worker). Logically, each worker gets dispatched 1/n chunks of the overall model training set - where n = total number of workers - then each worker trains its own independent model on its own subset of the training set. The ```\nreturn_model```\n parameter controls whether each worker's model gets returned by ```\n_train_part```\n, so it returns None for all workers - and therefore, models - except for one worker.\nCode:\n```\ndef _train_part(params, model_factory, list_of_parts, worker_addresses, return_model, local_listen_port=12400,\n                time_out=120, **kwargs):\n\n    network_params = build_network_params(worker_addresses, get_worker().address, local_listen_port, time_out)\n    params.update(network_params)\n\n    # Concatenate many parts into one\n    parts = tuple(zip(*list_of_parts))\n    data = concat(parts[0])\n    label = concat(parts[1])\n    weight = concat(parts[2]) if len(parts) == 3 else None\n\n    try:\n        model = model_factory(**params)\n        model.fit(data, label, sample_weight=weight)\n    finally:\n        _safe_call(_LIB.LGBM_NetworkFree())\n\n    return model if return_model else None\n```\n\nIs this not equivalent to training a non-distributed version of a lightgbm estimator on a 1/n subsample of the training set? Am I missing something? I feel like I am missing a part where either the workers' independent models get combined into one, or where a single estimator is getting updated with the individual trees learned by separate workers.\nThank you!\n    ", "Answer": "\r\nAh the answer is yes - dask_lightgbm uses all available training samples. Dask's responsibility is only to distribute data across workers. LightGBM handles all distributed learning once its network parameters are set. It's not that each worker is training its own independent model - LightGBM is training a single model - but each worker will get a copy of it. For this reason, only the chosen worker returns the fitted estimator, and everyone else returns None.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to maintain multiple independent stable git branches\r\n                \r\nHere's a git problem. I'm making a programming study review app in pure (command line) Ruby. This app allows the user to design and schedule reviews of programming tasks, manage the files in which the tasks are performed, and run the result automatically from the app. For these purposes, I don't need git when there's a single file. But most advanced and web programming tasks involve editing and using multiple files, and to manage that, I need to use git, and I'm not great with git.\n\nIn the app, the maker of these more complex \"repotasks\" is expected to make questions based on a git branch (of his choice) of a repo (of his choice). So I figure what this requires is that, for each repo, there is a series of branches, each of which is maintained independently of each other, and each of which is relatively stable; and the app basically checks out branches as needed to answer questions. It sounds simple...\n\nThe problems are:\n\n\nAfter I make new branches (by hand, with ```\ngit checkout -b branch_name```\n) and add new files, I seem to be prevented from checking out some previous branches. For example:\n\n```\n$ git checkout foobar_JS_enabled_missing_prompt\nerror: The following untracked working tree files would be overwritten by checkout:\n    display_nodename.html\nPlease move or remove them before you switch branches.\nAborting```\n\nI (think I) need to ```\ngit reset --hard```\n branches after a user finishes answering a question. But doing this seems to have inadvertently blanked a file I worked hard on in setting up a later branch. I think it's because I hard-reset an earlier branch in which said file was blank.\n\n\nThe git interaction the app does (mostly using ruby-git) so far is:\n\n\nActually create repos and branches by hand.\nList branches for question-makers to choose from.\nCheckout branches when they are chosen, using\n\n```\ng = Git.open(\"data/repos/#{repo}\")\ng.branch(branch).checkout```\n\nDo a hard reset of a branch that a question is based on when the user starts answering the question, using:\n\n```\ng = Git.open(\"data/repos/#{repo}\")\ng.reset_hard```\n\nI haven't done this yet, but I want to create an archive branch for each question, i.e., I want to let a question-answerer to review an old answer, then switch to the main branch for that question in order to create a new answer.\n\n\nBasically, I want frozen versions of each branch, but the process (described above) seems to create unwanted interactions. I thought branches were isolated from each other automatically. What am I doing wrong? What do I need to do in order to freeze the last-committed version of each branch, regardless of what happens in other branches, while I switch frequently between branches?\n\nUPDATE (11/18): I will leave this as a comment rather than an answer, because the question is a little obscure. I never realized that the index and tree are independent of branches. So my code actually had a few subtle bugs relating to the fact that I was letting my tree get unclean. In a couple of places, I needed to hard reset the code before letting an answerer start work on an answer, even if, most of the time, that isn’t necessary.  I also needed to hard reset the code after an answerer finishes.  Another thing I needed to do was to check what branch is currently checked out and switch to the right one ( I had already done this, but not everywhere I should’ve). \n\nSeems to be working now, and I’m not able to replicate the bugs anymore. \n    ", "Answer": "\r\nYou can save your work in stash before you switch branches. Read here .\nJust before switching to other branch, use ```\ngit stash```\n.\n When you come back in this branch again, you can load your work saved in stash by ```\ngit stash pop```\n.\n\"pop\" will delete your stash after applying, you can also name your stashes, and do other stuffs like not deleting a stash after applying.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Random forest regression - cumulative MSE?\r\n                \r\nI am new to Random Forests and I have a question about regression. I am using R package randomForests to calculate RF models.\n\nMy final goal is to select sets of variables important for prediction of a continuous trait, and so I am calculating a model, then I remove the variable with lowest mean decrease in accuracy, and I calculate a new model, and so on. This worked with RF classification, and I compared the models using the OOB errors from prediction (training set), development and validation data sets. Now with regression I want to compare the models based on %variation explained and MSE. \n\nI was evaluating the results for MSE and %var explained, and I get exactly the same results when calculating manually using the prediction from ```\nmodel$predicted```\n. But when I do ```\nmodel$mse```\n, the value presented corresponds to the value of MSE for the last tree calculated, and the same happens for % var explained.\n\nAs an example you can try this code in R:\n\n```\nlibrary(randomForest)\ndata(\"iris\")\nhead(iris)\n\nTrainingX<-iris[1:100,2:4] #creating training set - X matrix\nTrainingY<-iris[1:100,1]  #creating training set - Y vector\n\nTestingX<-iris[101:150,2:4]  #creating test set - X matrix\nTestingY<-iris[101:150,1]  #creating test set - Y vector\n\nset.seed(2)\n\nmodel<-randomForest(x=TrainingX, y= TrainingY, ntree=500, #calculating model\n                    xtest = TestingX, ytest = TestingY)\n\n#for prediction (training set)\n\npred<-model$predicted\n\nmeanY<-sum(TrainingY)/length(TrainingY)\n\nvarpY<-sum((TrainingY-meanY)^2)/length(TrainingY)\n\nmseY<-sum((TrainingY-pred)^2)/length(TrainingY)\n\nr2<-(1-(mseY/varpY))*100\n\n#for testing (test set)\n\npred_2<-model$test$predicted\n\nmeanY_2<-sum(TestingY)/length(TestingY)\n\nvarpY_2<-sum((TestingY-meanY_2)^2)/length(TestingY)\n\nmseY_2<-sum((TestingY-pred_2)^2)/length(TestingY)\n\nr2_2<-(1-(mseY_2/varpY_2))*100\n\ntraining_set_mse<-c(model$mse[500], mseY)\ntraining_set_rsq<-c(model$rsq[500]*100, r2)\ntesting_set_mse<-c(model$test$mse[500],mseY_2)\ntesting_set_rsq<-c(model$test$rsq[500]*100, r2_2)\n\nc<-cbind(training_set_mse,training_set_rsq,testing_set_mse, testing_set_rsq)\nrownames(c)<-c(\"last tree\", \"by hand\")\nc\nmodel\n```\n\n\nAs a result after running this code you will obtain a table containing values for MSE and %var explaines (also called rsq). The first line is called \"last tree\" and contains the values of MSE and %var explained for the 500th tree in the forest. The second line is called \"by hand\" and it contains results calculated in R based on the vectors ```\nmodel$predicted```\n and ```\nmodel$test$predicted```\n.\n\nSo, my questions are:\n\n1- Are the predictions of the trees somehow cumulative? Or are they independent from each other? (I thought they were independent)\n\n2- Is the last tree to be considered as an average of all the others?\n\n3- Why are MSE and %var explained of the RF model (presented in the main board when you call ```\nmodel```\n) the same as the ones from the 500th tree (see first line of table)? Do the vectors ```\nmodel$mse```\n or ```\nmodel$rsq```\n contain cumulative values?\n\nAfter the last edit I found this post from Andy Liaw (one of the creators of the package) that says that MSE and %var explained are in fact cumulative!: https://stat.ethz.ch/pipermail/r-help/2004-April/049943.html.\n    ", "Answer": "\r\nNot sure I understand what your issue is; I'll give it a try nevertheless...\n\n\n  1- Are the predictions of the trees somehow cumulative? Or are they\n  independent from each other? (I thought they were independent)\n\n\nYou thought correctly; the trees are fit independently of each other, hence their predictions are indeed independent. In fact, this is a crucial advantage of RF models, since it allows for parallel implementations.\n\n\n  2- Is the last tree to be considered as an average of all the others?\n\n\nNo; as clarified above, all trees are independent.\n\n\n  3- If each tree gets a prediction, how can I get the matrix with all the trees, since what I need is the MSE and % var explained for the forest?\n\n\nHere is where what you ask starts being really unclear, given your code above; the MSE and r2 you say you need are exactly what you are already computing in ```\nmseY```\n and ```\nr2```\n:\n\n```\nmseY\n[1] 0.1232342\n\nr2\n[1] 81.90718\n```\n\n\nwhich, unsurpizingly, are the very same values reported by ```\nmodel```\n:\n\n```\nmodel\n# result:\n\nCall:\n randomForest(x = TrainingX, y = TrainingY, ntree = 500) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 1\n\n          Mean of squared residuals: 0.1232342\n                    % Var explained: 81.91\n```\n\n\nso I'm not sure I can really see your issue, or what these values have to do with the \"matrix with all the trees\"...\n\n\n  But when I do ```\nmodel$mse```\n, the value presented corresponds to the value\n  of MSE for the last tree calculated, and the same happens for % var\n  explained.\n\n\nMost certainly not: ```\nmodel$mse```\n is a vector of length equal to the number of trees (here 500), containing the MSE for each individual tree; (see UPDATE below) I have never seen any use for this in practice (similarly for ```\nmodel$rsq```\n):\n\n```\nlength(model$mse)\n[1] 500\n\nlength(model$rsq)\n[1] 500\n```\n\n\nUPDATE: Kudos to the OP herself (see comments), who discovered that the quantities in ```\nmodel$mse```\n and ```\nmodel$rsq```\n are indeed cumulative (!); from an old (2004) thread by package maintainer Andy Liaw, Extracting the MSE and % Variance from RandomForest:\n\n\n  Several ways:\n  \n  \n  Read ?randomForest, especially the `Value' section.\n  Look at str(myforest.rf).\n  Look at print.randomForest.\n  \n  \n  If the forest has 100 trees, then the mse and rsq are vectors with 100\n  elements each, the i-th element being the mse (or rsq) of the forest\n  consisting of the first i trees.  So the last element is the mse (or\n  rsq) of the whole forest.\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Common test data for multiple independent maven projects\r\n                \r\nI have a maven project that converts text files of a specific format to another format. \nFor testing I have put in src/test/resources a large amount of test files.\n\nI also have another project that uses the first one to do the conversion and then do some extra stuff on the output format. I also want to test this project against the same test dataset, but I dont want to have duplicate data sets and I want to be able to test the first project alone since it is also a standalone converter project. \n\nIs there any common solution for doing that? I dont mind not having the test dataset inside the projects source tree as long as each project can access the data set independently of the other. I dont want to setup a database for that also. I am thinking something like a repository of test data simpler than an RDBMS. Is there any application for this kind of need that I can use with a specific maven plugin?  Ease of setup and simplicity is my priority. Also I m thinking something like packaging the test data and putting it in a internal maven repo and then downloading it and unzip it in the junit code. Or better, is there a maven plugin that can do this for me? \n\nAny ideas? \n    ", "Answer": "\r\nIt is possible to share resources with Maven, for example with the help of the Assembly and Dependency plugins. Basically:\n\n\nCreate a module with a packaging of type ```\npom```\n to hold the shared resources\nUse the assembly plugin to package the module as a zip\nDeclare a dependency on this zip in \"consumer\" modules\nAnd use ```\ndependency:unpack-dependencies```\n (plus some exclusion rules) to unpack the zip\n\n\nThis approach is detailed in How to share resources across projects in Maven. It requires a bit of setup (which is \"provided\") and is not too complicated.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Jython, where should i put my .py files\r\n                \r\nI am really new to Java/Eclipse and I am trying to do this Jython tutorial.\n\nI do not understand where I should put my python files the IDE's tree directory structure. I've tried placing the file in several locations without success (I must be missing something). This is the error message I get: \n\n```\n<module 'sys' (built-in)>\nException in thread \"main\" Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nImportError: No module named Employee\n```\n\n\nMy tree directory structure for this tutorial is as follows:\n\n```\nJythonTest\n---src\n------jyinterface\n---------factory\n------------EmployeeFactory.java\n------------Employee.py\n---------interfaces\n------------EmployeeType.java\n------------Employee.py\n---------Main.java\n---------Employee.py\n---Employee.py\n---lib\n------jython-2.5.2.jar\n------Employee.py \n```\n\n\n\n\nEDIT : So I'm partially answering myself, for the first part I have found this link with explanations of the same kind of situation, and it works!\n\n\n\nThe remaining issue is, how will I handle the import path of my future python libraries, are there any tricks? It seems that I will have to use something like:\n\n```\nPySystemState sys = Py.getSystemState();\nsys.path.append(new PyString(\"isItHereThatIShouldPointToJython-2.5.2.jar???\"));\n```\n\n\nIs there any way to set a relative path or something installation independent?\n\nThanks.\n    ", "Answer": "\r\n\n  run:\n  Exception in thread \"main\" Traceback (most recent call last):\n    File \"\", line 1, in \n  ImportError: No module named Employee\n  C:\\Users\\A\\AppData\\Local\\NetBeans\\Cache\\8.1\\executor-snippets\\run.xml:53: Java returned: 1\n  BUILD FAILED (total time: 2 seconds)\n\n\nI tried two things when  I had this issue. I stopped using the standalone jar, due to cmd errors. Then when trying this code https://wiki.python.org/jython/JythonMonthly/Articles/October2006/3\nInstead of placing the Employee.py in the jyinterface.interfaces package I placed it free floating in the src folder. (I am using Netbeans with py plug in)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Is Grails suitable for complex applications?\r\n                \r\nOur organization is planning to use Grails to realize a complex\napplication with a REST interface. I have concerns on the scalability\nof the framework, given that:\n\n\ndomain classes will for sure make heavy use of polymorphism. I heard people have trouble with inheritance in Grails, for instance because of this problem on JIRA.\nTrees of objects will be saved in the database. In GORM this would be\nsomething like:\n\n```\nclass Node\n{\n  static def hasMany = [children: Node]\n}\n```\n\n\nI thought we could benefit of cascading operation to manage dependencies, but I am not sure how it would work in this case.\nthe database is supposed to grow to store millions of objects\nand should work with Oracle, SQL Server and PostgreSQL. How realistic is it to count on Grails DB mapping to have this compatibility for free?\nwe plan to leverage custom domain constraints to check\nthe consistency of domain objects. But I have the feeling that what you can do in a validator is limited (I am not sure if you can, for instance, load a set of other objects)\nbusiness logic implemented in services will be multi-threaded\n\n\nMost examples in books and on the web show very simple\napplication with CRUD operation on independent sets of objects.\n\nI am afraid that I end up using a very small subset of the feature of\nGrails when the application grows, as scaffolding, web flows, ajax, or\neven the DB schema generated by domain classes may not correspond\nexactly to the needs of my application.\n\nHas anybody experience to share on using Grails for such an\napplication?\n    ", "Answer": "\r\n\n  domain classes will for sure make heavy use of polymorphism. I heard\n  people have trouble with inheritance in Grails, for instance because\n  of this problem on JIRA.\n\n\nInheritance has improved in Grails 2.0. See the section on Abstract Inheritance. The issue mentioned in the JIRA bug reported can be worked around via declaring the property as transient.\n\n\n  Trees of objects will be saved in the database. In GORM this would be something like:\n\n\nSelf referential relationships are fine. For more info, see Grails in Action chapter 3.\n\n\n  the database is supposed to grow to store millions of objects and should work with Oracle, SQL Server and PostgreSQL. How realistic is it to count on Grails DB mapping to have this compatibility for free?\n\n\nGrails is built on Hibernate, an enterprise quality ORM layer used in a variety of large J2EE applications. Depending on the types of queries you're running, you may need to use criteria and tweak things at that level, but Grails provides no inherent limitations that keep it from scaling.\n\n\n  we plan to leverage the custom domain constraint mechanism to check the consistency of domain objects. But I have the feeling what you can do in a validator is limited (I am not sure if you can, for instance, load a set of other objects)\n\n\nYou can do cross-field validation with this. You can also define your own custom validator classes.\n\n\n  business logic implemented in services will be multi-threaded\n\n\nIt is recommended not to store state in services, but you can use them in multi-threaded operations as there are different scopes available. Of course, the onus is then on you to control concurrent access.\n\n\n  Our organization is planning to use Grails to realize a complex application with a REST interface.\n\n\nREST interfaces are fairly fun and easy with Grails. See Grails in Action Chapter 11 or Chapter 9/13 of Beginning Groovy and Grails from Novice to Professional.\n\nGrails is built on tried and proven J2EE technologies like Spring and Hibernate. While the \"out of the box\" may only take you so far, the framework is configurable at various levels to meet your needs. So you're essentially asking if J2EE scales nicely. Many people seem to say yes.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Enumerate all possible combined probabilities of a series of Bernoulli trials with different probabilities\r\n                \r\nSuppose I have a series of n probabilities for success of independent Bernoulli trials, p1 to pn such that p1 != p2 != ... != pn. Give each trial a unique name.\n\n```\n    p <- c(0.5, 0.12, 0.7, 0.8, .02)\n    a <- c(\"A\",\"B\",\"C\",\"D\",\"E\")\n```\n\n\nI know from searching stack exchange (e.g., here and here) that I can find the cdf, pmf, etc. using the Poisson Binomial distribution function. \n\nWhat I'm interested in is the exact probability of every possible combination of success and failures. (E.g. If I drew a probability tree, I want to know the probability at the end of each branch.) \n\n```\n    all <- prod(p)\n    all\n    [1] 0.000672\n    o1 <- (0.5 * (1-0.12) * 0.7 * 0.8 * .02)\n    o1\n    [1] 0.004928\n    o2 <- (0.5 * 0.12 * (1-0.7) * 0.8 * .02)\n    o2\n    [1] 0.000288\n```\n\n\n...for all 2^5 possible combinations of success/failure.\n\nWhat's an efficient way to go about this in R? \n\nIn the case of my actual data set, the number of trials is 19, so we're talking about 2^19 total paths on the probability tree.\n    ", "Answer": "\r\nThe key to making this computation fast is to do it in log-probability space so that the product for each branch of the tree is a sum that can be computed as the inner sum of a matrix multiply. In this manner, all the branches can be computed together in vectorized fashion.\n\nFirst, we construct an enumeration of all branches. For this, we use the ```\nintToBin```\n function from ```\nR.utils```\n package:\n\n```\nlibrary(R.utils)\nenum.branches <- unlist(strsplit(intToBin(seq_len(2^n)-1),split=\"\"))\n```\n\n\nwhere ```\nn```\n is the number of Bernoulli variables. For your example, ```\nn=5```\n:\n\n```\nmatrix(enum.branches, nrow=n)\n##     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17]\n##[1,] \"0\"  \"0\"  \"0\"  \"0\"  \"0\"  \"0\"  \"0\"  \"0\"  \"0\"  \"0\"   \"0\"   \"0\"   \"0\"   \"0\"   \"0\"   \"0\"   \"1\"  \n##[2,] \"0\"  \"0\"  \"0\"  \"0\"  \"0\"  \"0\"  \"0\"  \"0\"  \"1\"  \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"0\"  \n##[3,] \"0\"  \"0\"  \"0\"  \"0\"  \"1\"  \"1\"  \"1\"  \"1\"  \"0\"  \"0\"   \"0\"   \"0\"   \"1\"   \"1\"   \"1\"   \"1\"   \"0\"  \n##[4,] \"0\"  \"0\"  \"1\"  \"1\"  \"0\"  \"0\"  \"1\"  \"1\"  \"0\"  \"0\"   \"1\"   \"1\"   \"0\"   \"0\"   \"1\"   \"1\"   \"0\"  \n##[5,] \"0\"  \"1\"  \"0\"  \"1\"  \"0\"  \"1\"  \"0\"  \"1\"  \"0\"  \"1\"   \"0\"   \"1\"   \"0\"   \"1\"   \"0\"   \"1\"   \"0\"  \n##     [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32]\n##[1,] \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"  \n##[2,] \"0\"   \"0\"   \"0\"   \"0\"   \"0\"   \"0\"   \"0\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\"  \n##[3,] \"0\"   \"0\"   \"0\"   \"1\"   \"1\"   \"1\"   \"1\"   \"0\"   \"0\"   \"0\"   \"0\"   \"1\"   \"1\"   \"1\"   \"1\"  \n##[4,] \"0\"   \"1\"   \"1\"   \"0\"   \"0\"   \"1\"   \"1\"   \"0\"   \"0\"   \"1\"   \"1\"   \"0\"   \"0\"   \"1\"   \"1\"  \n##[5,] \"1\"   \"0\"   \"1\"   \"0\"   \"1\"   \"0\"   \"1\"   \"0\"   \"1\"   \"0\"   \"1\"   \"0\"   \"1\"   \"0\"   \"1\"  \n```\n\n\nresults in a matrix where each column is the outcomes from a branch of the probability tree.\n\nNow, use that to construct a matrix of log probabilities of the same size as ```\nenum.branches```\n where the value is ```\nlog(p)```\n if ```\nenum.branches==\"1\"```\n and ```\nlog(1-p)```\n otherwise. For your data, with ```\np <- c(0.5, 0.12, 0.7, 0.8, .02)```\n, this is:\n\n```\nlogp <- matrix(ifelse(enum.branches == \"1\", rep(log(p), 2^n), rep(log(1-p), 2^n)), nrow=n)\n```\n\n\nThen, sum the log-probabilities and take the exponential to get the product of the probabilities:\n\n```\nresult <- exp(rep(1,n) %*% logp)\n##         [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]     [,9]   [,10]\n##[1,] 0.025872 0.000528 0.103488 0.002112 0.060368 0.001232 0.241472 0.004928 0.003528 7.2e-05\n        [,11]    [,12]    [,13]    [,14]    [,15]    [,16]    [,17]    [,18]    [,19]    [,20]\n##[1,] 0.014112 0.000288 0.008232 0.000168 0.032928 0.000672 0.025872 0.000528 0.103488 0.002112\n        [,21]    [,22]    [,23]    [,24]    [,25]   [,26]    [,27]    [,28]    [,29]    [,30]\n##[1,] 0.060368 0.001232 0.241472 0.004928 0.003528 7.2e-05 0.014112 0.000288 0.008232 0.000168\n        [,31]    [,32]\n##[1,] 0.032928 0.000672\n```\n\n\nThe ```\nresult```\n will be in the same order as the numeration of branches in ```\nenum.branches```\n. \n\nWe can encapsulate the computation into a function:\n\n```\nenum.prob.product <- function(n, p) {\n  enum.branches <- unlist(strsplit(intToBin(seq_len(2^n)-1),split=\"\"))\n  exp(rep(1,n) %*% matrix(ifelse(enum.branches == \"1\", rep(log(p), 2^n), rep(log(1-p), 2^n)), nrow=n))\n}\n```\n\n\nTiming this with ```\n19```\n independent Bernoulli variables:\n\n```\nn <- 19\np <- runif(n)\nsystem.time(enum.prob.product(n,p))\n##   user  system elapsed \n## 24.064   1.470  26.082 \n```\n\n\nThis is on my 2 GHz MacBook (circa 2009). It should be noted that the computation itself is quite fast; it is the enumeration of the branches of the probability tree (I would guess the ```\nunlist```\n within that) that is taking the bulk of the time. Any suggestions from the community on another approach to do that will be appreciated.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Feature selection based on groups during bagging and boosting step\r\n                \r\nIs there an ml library, with the implementation of ensemble trees (RF or Boosted) which allows randomized feature selection (max_features in sklearn implementation of RFR and GBR or colsample_bytree in xgboost implementation) based on some feature grouping, rather than randomized over complete feature set, for each tree.  \n\ne.g. Say I have 10 independent features namely (F1,....F10) but these features can be grouped based on subject knowledge in 4 broad group as  \n\n```\n{## FG short for feature_group\nFG1 : [F1, F2],\nFG2: [F3, F4, F5],\nFG3: [F6,F7,F8],\nFG4: [F9, F10]\n}\n```\n\n\nNow with setting of ```\nmax_feature = 0.2```\n in current randomized feature selection methodology, each tree will get any of 10 choose 2 features from 10 features. But I want to constraint feature selection at the group level, such that for one tree if FG1 and FG4 are chosen then all features in those groups are selected [F1,F2,F9,F10].\n\nP.S. I have already created a Random forest Classifier to handle this using ML-From-Scratch library and find much robust result compared to randomized feature selection, but using post modeling steps such as MLI (shap or lime) is a challenge.\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "What Transaction Manager (JTA) should I use to learn Hibernate?\r\n                \r\nI am learning Hibernate from the latest 2016 edition (2nd) of the Java Persistence with Hibernate book.  It appears I need a JTA Transaction Manager (TM), but I do not want to have to learn Spring at this point (as suggested in answers to other questions on this) because I perceive it as yet another huge set of infrastructure to learn with its own recursively huge tree of further topics to learn.\n\nIs there a simple TM alternative I can use, or some other path I should be taking?  Perhaps my perception of Spring is wrong and its TM is independent of its other pieces?\n    ", "Answer": "\r\nlook at this answer, maybe you should what you are looking for.\n\nPersistence unit as RESOURCE_LOCAL or JTA?\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "R rpart: No splits if I remove less important variables\r\n                \r\nI am trying to understand how rpart works in a project that I am trying to complete. I am relatively new to R but I have a lot of experience using SAS to build a variety of analytical models.\n\nFirst I ran this piece of code\n\n```\nmtree1 <- rpart(X17~., data = mydata, method=\"class\", control = rpart.control(minsplit = 20, minbucket = 7, maxdepth = 10, usesurrogate = 2, xval =10 ))\n```\n\n\nI get a tree with X12 as the top split, X10 is the next split on the LHS, X69 on the RHS, and then X68 and X70 on that branch.\n\nNext I ran the following piece\n\n```\nmtree1 <- rpart(X17~ X12+X10+X69+X68+X70, data = mydata, method=\"class\", control = rpart.control(minsplit = 20, minbucket = 7, maxdepth = 10, usesurrogate = 2, xval =10 ))\n```\n\n\nI get the exact same tree\n\nFinally I ran this \n\n```\nmtree1 <- rpart(X17~ X12+X69+X68+X70, data = mydata, method=\"class\", control = rpart.control(minsplit = 20, minbucket = 7, maxdepth = 10, usesurrogate = 2, xval =10 ))\n```\n\n\nNow I get no splits at all. (BTW, my data set has 234144 observations & 90 independent variables with 210205 goods & 23839 bads.)\n\nHere is an image of the code and output\n\n\n\nWhat is the reason for this? I would appreciate any help. Thanks.\nKK\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Add conditioning variables to a random forest model in R\r\n                \r\nI want to train a random forest to make a categorical prediction. If I want to include a fixed set of independent variables in the prediction model (e.g. x1, x2, and x3 in ```\nY~.+x1+x2+x3```\n), but exclude them from the set of independent variables (represented by . in the example) that can be used to partition the data/create branches/trees in the forest, is there a simple way to do this using ```\ncaret```\n, ```\ngrf```\n, or another package in R?\nHere's an example:  If I wanted to predict which flowers had sepal width over 3.2 in the iris dataset, but I wanted to condition on flower species  when deciding whether to create a new branch while excluding flower species as a possible variable to split on. Imagine that I know that flower species is a good predictor of sepal width, but I want to know what other factors predict sepal width, conditional on species:\n```\ndata(iris)\nd <- iris\n\nd$sepal_width_over3point2<-as.factor(d$Sepal.Width>3.2)\nd$Type1<-as.numeric(d$Species=='versicolor')\nd$Type2<-as.numeric(d$Species=='virginica')\nd$Type3<-as.numeric(d$Species=='setosa')\n\nd<-subset(d,select=-c(Species,Sepal.Width))\n\n\n## Set parameters to train models\n# Run algorithms using 10-fold cross validation\ncontrol <- trainControl(method=\"cv\", number=10)\nmetric <- \"Accuracy\"\n\n# Random Forest\nset.seed(11)\nrf <- train(sepal_width_over3point2~.+Type1+Type2+Type3, data=d, method=\"rf\", metric=metric, trControl=control)\nprint(rf)\n\nexample_varImp_rf<-varImp(rf)\n```\n\nWhen I look at the variable importance in this model, I'd like to know that the estimates for the other parameters (Sepal.length, Petal.length, and Petal.width) are conditional on flower Type1, Type2, and Type3, but exclude these variables as possible variables to branch on. Is there a way to tell the random forest to ignore these three variables as possible splits?\n    ", "Answer": "\r\nThat would require your node splits to have one threshold for each flower species, which would be more computationally expensive than most tree learners.  I don't know of any package that implements this.\nOne possible workaround is to do some feature engineering.  In this case, where your condition on is a smallish categorical, you could standardize each feature relative to their flower species, so that a split would be something like \"sepal length is at least 20% higher than species average\" or \"sepal length is at least one (species) standard deviation higher than species average.\"\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Jackson xml deserialization - serialize to a list with arbitrary elements in between\r\n                \r\nI am using Jackson to deserialize XML. It works fine when serializing into a list when there are no other elements in between, but if i insert some other field in the middle somewhere, it seems to only put the things below the field into my list. See below only the ProductA objects after the Product B tag are being included.\nI set a breakpoint to get the JsonNode object using the xmlMapper readTree method, and the properties above the ProductB tag are not there in the node tree.\nIs there a way using jackson (or another library) to get all ProductA elements inside the Warehouse element, independent of the ordering of the Warehouse child elements?\n```\npublic class Warehouse {\n@JacksonXmlElementWrapper(useWrapping = false)\n@JacksonXmlProperty(localName = \"ProductA\")\nprivate List<ProductA> productAList;\n\n@JacksonXmlProperty(localName = \"ProductB\")\nprivate String productB;\n//getters and setters\n\n}\n```\n\n```\npublic class ProductA {\n@JacksonXmlProperty(localName = \"PropA\")\nprivate String propA;\n\n//getters and setters\n}\n```\n\n```\n<Warehouse>\n <ProductA>\n  <propA>abc</propA>\n </ProductA>\n <ProductA>\n  <propA>abc</propA>\n </ProductA>\n <ProductB>def</ProductB>\n <ProductA>\n  <propA>abc</propA>\n </ProductA>\n</Warehouse>\n```\n\n    ", "Answer": "\r\nChange your Warehouse class to use a method just for setting the value of productAList from XML, and remove the annotations from the productAList property.\n```\n@JsonSetter(value =  \"ProductA\")\npublic void setProductAListFromXml(ProductA productA) {\n    if (this.productAList == null) {\n        this.productAList = new ArrayList<ProductA>();\n    } \n    this.productAList.add(productA);\n}\n```\n\nHere is the full Warehouse class:\n```\n@JacksonXmlRootElement(localName = \"Warehouse\")\npublic class Warehouse {\n    private List<ProductA> productAList;\n\n    @JacksonXmlProperty(localName = \"ProductB\")\n    private String productB;\n\n    public List<ProductA> getProductAList() {\n        return productAList;\n    }\n\n    public void setProductAList(List<ProductA> productAList) {\n        this.productAList = productAList;\n    }\n\n    @JsonSetter(value =  \"ProductA\")\n    public void setProductAListFromXml(ProductA productA) {\n        if (this.productAList == null) {\n            this.productAList = new ArrayList<ProductA>();\n        } \n        this.productAList.add(productA);\n    }\n    \n    public String getProductB() {\n        return productB;\n    }\n    \n    public List<ProductA> getProductA() {\n        return productAList;\n    }\n}\n```\n\nUsing the class like this:\n```\nString str = \"<Warehouse>\\r\\n\" + \n                \" <ProductA>\\r\\n\" + \n                \"  <propA>abc</propA>\\r\\n\" + \n                \" </ProductA>\\r\\n\" + \n                \" <ProductA>\\r\\n\" + \n                \"  <propA>abc</propA>\\r\\n\" + \n                \" </ProductA>\\r\\n\" + \n                \" <ProductB>def</ProductB>\\r\\n\" + \n                \" <ProductA>\\r\\n\" + \n                \"  <propA>abc</propA>\\r\\n\" + \n                \" </ProductA>\\r\\n\" + \n                \"</Warehouse>\";\n        \nXmlMapper mapper = new XmlMapper();\nWarehouse warehouse = mapper.readValue(str, Warehouse.class);\nSystem.out.println(warehouse.getProductB());\nSystem.out.println(warehouse.getProductA());\n```\n\nProduces this output:\n```\ndef\n[ProductA [propA=abc], ProductA [propA=abc], ProductA [propA=abc]]\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "ExtJS4: Find DOM element of tree node\r\n                \r\nI want to run automated UI tests in my ExtJS4 application. I don't want to use Siesta, the Testing Tool from Sencha. Instead, I want to use a custom tool.\n\nThe application uses a TreePanel. To support the automated UI test, it is mandatory that each treenode (Ext.data.NodeInterface) has a unique and language independent identifier as attribute in its HTML representation. \n\nThis identifier should be set at the treenode when added to the tree. A custom ExtJS plugin for the treepanel should then render the identifier from the treenode object to its HTML representation.\n\nSo, my problem is: How do I get the DOM element of an Ext.data.NodeInterface?\n\nThanks in advance.\n    ", "Answer": "\r\nIf you know the record ID of the node you are trying to target then you can try the following:\n\n```\nvar myNode = tree.getStore().getNodeById(id);\nvar nodeElement = tree.getView().getNode(myNode);\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "sklearn random forest regressor predict -inf when train with negative weights\r\n                \r\nI am using a random forest regressor from the sklearn package. The independent variables(X) I use are demographics, and the dependent variable(y) is supposed to be income. In my training dataset, I have sampling weights, and some(<1%) of them are negative. The negative weights are usually small in their absolute values.\nThis is what happens:\n\nUsing default settings, the fitted model sometimes, but not always predicts a \"-inf\".\nSwitch over to the regression tree, the problem disappears.\nTry multiple times with fewer trees in the forest, most of the time it is fine, but occasionally the same problem occurs.\nDropping all negative weights make the problem disappear.\nFor samples with negative weights, make the weights their absolute value and make the income negative, the problem disappear.\n\nIs it because a specific tree has only samples with negative weights and therefore fails? Does anyone have an idea or solution?\nTo reproduce the error, use the following code:\n```\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestRegressor\n\ndf = pd.DataFrame([[2,1,-1],[2,2,2],[3,3,1]])\n\nweight = df[2]\nX = df[[0]]\ny = df[1]\n\nt = RandomForestRegressor(n_estimators=10,random_state=0).fit(X,y,weight)\nprint(t.predict([[1]]))\n```\n\nThis gives: [inf]\n    ", "Answer": "\r\nI'm really not sure whether negative sample weights make any sense in the tree construction.  The weights are used to obtain a weighted average in the splitting criterion, so negative weights make the row's contribution to impurity negative, I suppose meaning the tree would prefer to be more wrong about its prediction for that row.\nThe cause of your infinities though is when the bootstrapped sample contains the first row twice and the second row once: the total weight is 0, and so the weighted averages divide by zero.  The \"value\" at the node becomes ```\nnp.inf```\n, and the impurity at the node ```\nnp.nan```\n.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "OutOfMemory Exception when recursively drawing rectangles in GDI+\r\n                \r\nI have a problem drawing and filling rectangles in C# using GDI+. I'm trying to render a treemap and have therefore constructed a recursive algorithm which traverses the tree structure from root to leaf levels and draws a rectangle in any case, but also fills the rectangle if the node happens to be a leaf node.\n\nThe code works fine for smaller trees, but reproducably crashes for a larger data set which has 42 layers of nodes. The upper ```\nDrawRectangle```\n call throws an ```\nOutOfMemoryException```\n when trying to render a node below the 16th layer, independent of 32-/64-bit or debug and release configurations.\n\nBrushes and Pens are not subject to change, so they are stored in an array outside the method. There is no problem with creating or disposing objects.\n\nHere is the recursive method I use to render the treemap:\n\n```\n/// <summary>\n/// Renders a certain <see cref=\"Tree\"/> onto the canvas.\n/// </summary>\n/// <param name=\"tree\">The tree node to be rendered.</param>\n/// <param name=\"g\">The <see cref=\"Graphics\"/> canvas to render the tree to.</param>\n/// <param name=\"bounds\">The rectangle available for the specified <paramref name=\"tree\"/>.</param>\nprotected void RenderTree(Tree tree, Graphics g, RectangleF bounds)\n{\n    if (tree.IsLeaf)\n    {\n        g.FillRectangle(brushes[tree.Depth], bounds);\n        g.DrawRectangle(pens[tree.Depth], bounds);\n    }\n    else\n    {\n        g.DrawRectangle(pens[tree.Depth], bounds);\n\n        if (bounds.Width >= bounds.Height)\n        {\n            float widthPerChild = bounds.Width / (float)tree.Children.Count;\n            for (int i = 0; i < tree.Children.Count; ++i)\n            {\n                RenderTree(tree.Children[i], g, new RectangleF(bounds.X + i * widthPerChild, bounds.Y, widthPerChild, bounds.Height));\n            }\n        }\n        else\n        {\n            float heightPerChild = bounds.Height / (float)tree.Children.Count;\n            for (int i = 0; i < tree.Children.Count; ++i)\n            {\n                RenderTree(tree.Children[i], g, new RectangleF(bounds.X, bounds.Y + i * heightPerChild, bounds.Width, heightPerChild));\n            }\n        }\n    }\n\n}\n```\n\n\nAre there any ideas on what is wrong with the code? Or could it be a problem with GDI+?\n    ", "Answer": "\r\nThank you for all the comments; I could solve the problem. I also tested an iterative version of the drawing process and it did not change anything but gave me better debugging options. The problem seems to have been that the rectangles I tried to draw were too small (width and height > 0, but around 10^(-5)): Before drawing the rectangles, I added a threshold if the width or height of the rectangle is less than 1/1000. Of course, this makes an ```\nOutOfMemoryException```\n not very helpful as none of the memory issues you remarked showed any suspicious behavior.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "$PYTHONPATH not working on OSX\r\n                \r\nI have been at this for a day and have found no solution. My python project is very levels deep and some of the modules have to be run independently (no -m flag, no relative imports). For this reason we decided to add the root folder to the PYTHONPATH. I am running OSX 10.11.3. Everything had been running smoothly until yesterday. I could run independent modules from the terminal with no issues in both Python 2.7 and 3.5. Yesterday, without modifying my PYTHONPATH or any other environment setting, running any of these independent modules from the terminal now gives me import errors in both Python 2 and 3. \n\nHere is my working tree:\n\n```\n/Users/sintrafico/Documents/code/central_maestra\n- reports_server.py\n- api_server.py\n- sintrafico\n    - sql\n        - SQLConnection\n    - api\n        - incident\n            - csv (not package)\n                - independent_module\n            - tests\n```\n\n\nI was running my tests yesterday with coverage with no problem, but now I can't. \n\nPython 2 ```\npython csv/independent_module.py```\n gives error:\n\n```\nTraceback (most recent call last):\n  File \"csv/independent_module.py\", line 13, in <module>\n    from sintrafico.sql import SQLConnection\nImportError: No module named sintrafico.sql\n```\n\n\nPython 3 ```\npython3 csv/independent_module.py```\n gives error:\n\n```\nTraceback (most recent call last):\n  File \"csv/create_bemobile_csv.py\", line 13, in <module>\n    from sintrafico.sql import SQLConnection\nImportError: No module named 'sintrafico'\n```\n\n\nFrom within the incident folder, yesterday this command was working fine: ```\ncoverage run -m unittest discover```\n. Now all the tests fail because ```\nImportError: No module named 'reports_server'```\n.\n\nSince that started happening yesterday, I have been messing with my PYTHONPATH. I left it blank and it didn't work (as expected), I have added the path now several ways:\n\n\n```\nexport PYTHONPATH=“${PYTHONPATH}:/Users/sintrafico/Documents/code/central_maestra\"```\n\n```\nexport PYTHONPATH=“/Users/sintrafico/Documents/code/central_maestra:${PYTHONPATH}\"```\n\n```\nexport PYTHONPATH=“${PYTHONPATH}:/Users/sintrafico/Documents/code/central_maestra/\"```\n\n```\nexport PYTHONPATH=“/Users/sintrafico/Documents/code/central_maestra:${PYTHONPATH}\"```\n\n\n\nAnd also setting it without appending the PYTHONPATH since it was empty to begin with. I restarted my computer several times with no success. Also note, I have a .bash_profile and .bashrc with the following contents:\n\n```\n# Setting PATH for Python 3.5\n# The orginal version is saved in .bash_profile.pysave\nPATH=\"/Library/Frameworks/Python.framework/Versions/3.5/bin:${PATH}\"\nexport PATH\nPYTHONPATH=“/Users/sintrafico/Documents/code/central_maestra:${PYTHONPATH}“\nexport PYTHONPATH\n```\n\n\nAnd lastly, what bugs me the most is that if I run the tests inside PyCharm they all run and pass, I get no import errors at all.\n    ", "Answer": "\r\nHave you tried setting the path without the quotes and braces? You are setting the python path as a string representation of the path instead of a list of paths\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Button should not scale dependend of Dpi\r\n                \r\nI've made a little WPF test-application with buttons in different units.\nNow I run this on a Screen with 96dpi and another with 226dpi.\n\nWhat I expect is that the button without unit and the button with px unit would get smaller than the other buttons on the 226dpi display - but they keep all the same size.\n\nHow do I force the \"pixel\"-Buttons to use real pixels? Independent of the dpi-resolution or if the user set the scaling to 200%.\n\nIn my real application I want the Menüs and Trees and so on to be dpiaware, but in the middle I have some sort of graphics in a usercontrol and I want this usercontrol to use real pixels.\n\nHere is the democode:\n\n```\n<Window x:Class=\"WpfApp2.MainWindow\"\n    xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\n    xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\n    xmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\n    xmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\n    mc:Ignorable=\"d\"\n    Title=\"MainWindow\" Height=\"450\" Width=\"800\">\n  <Grid>\n    <Grid.RowDefinitions>\n        <RowDefinition Height=\"*\" />\n        <RowDefinition Height=\"*\" />\n        <RowDefinition Height=\"*\" />\n        <RowDefinition Height=\"*\" />\n    </Grid.RowDefinitions>\n    <Button Grid.Row=\"0\" Grid.Column=\"0\" Content=\"96 x 48\" Width=\"96\" Height=\"48\" />\n    <Button Grid.Row=\"1\" Grid.Column=\"0\" Content=\"96px x 48px\" Width=\"96px\" Height=\"48px\" />\n    <Button Grid.Row=\"2\" Grid.Column=\"0\" Content=\"1.0in x 0.5in\" Width=\"1.0in\" Height=\"0.5in\" />\n    <Button Grid.Row=\"3\" Grid.Column=\"0\" Content=\"2.54cm x 1.27cm\" Width=\"2.54cm\" Height=\"1.27cm\" />\n  </Grid>\n</Window>  \n```\n\n    ", "Answer": "\r\nI found this little Decorator-Class and using it solves my problem.\n\nDecorator\n\nBut now there is a problem if someone has e.g. three monitors and uses different scaling on each monitor. The Decorator doesn't use the the setting for the monitor where the application is running.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Workflow for many interdependent submodules\r\n                \r\nAt my company we have several pseudo-independent teams, owning several repositories each (but sometimes editing code from another team). Most of the modules are interdependent, although the modules closest to our \"infrastructure\" level are basically independent of the others.\n\nCurrently we have a bunch of scripts to handle things like cloning and updating all the modules, requiring also the (in this case mostly automated) maintenance of text lists of the modules. Obviously this is a role I believe/hope ```\ngit submodule```\n could fill.\n\nWhat I would like, at a minimum, is the ability to:\n\nClone the entire source tree with a single command analogous to ```\ngit clone main_repository```\n.\n\nUpdate the entire source tree with a command analagous to ```\ngit pull```\n. It looks like this is simply ```\ngit submodule foreach git pull```\n, although I will probably make an alias for ```\ngit submodule foreach git```\n. Our current setup does this step in parallel (four at a time), I'd like the submodule setup to do the same. It also looks like updating the submodules makes them show up as changed (for committing). I can understand the logic behind this, but our current system has the pseudo-submodules in .gitignore, as you usually only care about your own module's changes.\n\nI would like an analogue for ```\ngit grep```\n that works over the entire tree. At first blush it seemed ```\ngit submodule foreach git grep hello```\n would work, but if the search string is ever not found (we have a couple tiny submodules, so this is usually true) then grep returns ```\n1```\n and the entire command stops.\n\nI'd like similarly useful analogues for diff and status.\n\nI can think of some workarounds for parts of this, but we already have a set of hacky scripts doing most of what I want, I was hoping/wondering if there was a nice standard easy way to do it.\n    ", "Answer": "\r\n\n  I can think of some workarounds for parts of this, but we already have a set of hacky scripts doing most of what I want, I was hoping/wondering if there was a nice standard easy way to do it.\n\n\nNot with submodules; not with your described use case. Submodules don't perform very well for highly interdependent, oft-updated code, as has been documented in various SO answers and on the web. That second link (aptly titled \"Why your company shouldn't use git submodules\") lists a few alternatives that might work for you, the best of which based on your description is probably repo, a multi-git-repository management tool built by google.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to include CMake files from source tree of included project\r\n                \r\nI'm setting up a CMake based build system for an old framework, written in C. It consists of a single binary, some core libraries and many dynamically linked libraries, which are built against the core libraries. My goal is to structure those libraries in several CMake projects (\"base framework\", \"extension libraries\", …), supporting two scenarios:\n\n\nIndependent build of extension libraries against base framework's build tree:\n\n```\n- base_framework/\n  - cmake/\n    - functions.cmake\n  - core_libraries/\n  - CMakeLists.txt\n- extension_libs/\n  - lib1/\n  - lib2/\n  - CMakeLists.txt\n```\n\n\nFor this scenario, I use\n\n```\nexport(EXPORT foo\n  FILE FooFrameworkConfig.cmake)\n```\n\n\nand\n\n```\nfind_package(FooFramework)\n```\n\n\nand add the build tree to ```\nCMAKE_PREFIX_PATH```\n when configuring the ```\nextension_libs```\n project.\nUsing base framework and extension libraries as sub-projects (e.g. as git submodules) of an application specific project:\n\n```\n- my_project/\n  - base_framework/\n    - cmake/\n      - functions.cmake\n    - core_libraries/\n    - CMakeLists.txt\n  - extension_libs/\n    - lib1/\n    - lib2/\n    - CMakeLists.txt\n  - my_lib1/\n  - CMakeLists.txt\n```\n\n\nFor this scenario, I use ```\nadd_subdirectory()```\n for both, the base framework and the extension libs.\n\n\n(A third scenario would be building the extension libraries against an install tree of the base framework. Unfortunately, this scenario is currently prevented by other CMake problems.)\n\nNow, I want to include the ```\nbase_framework/cmake/functions.cmake```\n file, containing some custom CMake functions for all libraries, into all projects' top-level ```\nCMakeLists.txt```\ns in both scenarios.\n\nFor the second scenario, I simply set a cached CMake variable in ```\nbase_framework/CMakeLists.txt```\n:\n\n```\nset(BASE_FRAMEWORK_DIR ${CMAKE_CURRENT_SOURCE_DIR}\n    CACHE PATH \"\" FORCE)\n```\n\n\nand use this variable for including the functions file in ```\nextension_libraries/CMakeLists.txt```\n as well as ```\nmy_project/CMakeLists.txt```\n:\n\n```\ninclude(${BASE_FRAMEWORK_DIR}/cmake/functions.cmake)\n```\n\n\nBut how do I find the ```\nfunction.cmake```\n file in the base framework's source tree from ```\nextenstion_libs/cmake```\n in the first scenario? All the directories (```\nbase_framework```\n, ```\nextension_libs```\n, base framework's build tree) may be anywhere on my computer.\n    ", "Answer": "\r\nTo expand on my comment regarding your first scenario, it looks like you can set one of the properties of your exported ```\ncore_libraries```\n targets to contain the path to the ```\nbase_framework/cmake```\n modules. So you can set this in the ```\nbase_framework/CMakeLists.txt```\n file, let's set it in the ```\nLABELS```\n target property. Then, we tell CMake to export the ```\nLABELS```\n property using ```\nEXPORT_PROPERTIES```\n:\n\nYour```\nbase_framework/CMakeLists.txt```\n file:\n\n```\n# Define the path to 'base_framework/cmake'\nset(BASE_FRAMEWORK_CMAKE_MODULES \"${CMAKE_CURRENT_SOURCE_DIR}/cmake\")\n\nadd_library(CoreLibrary1 ...)\n# Set the LABELS property, and tell CMake to export it.\nset_target_properties(CoreLibrary1 PROPERTIES \n    LABELS \"${BASE_FRAMEWORK_CMAKE_MODULES}\"\n    EXPORT_PROPERTIES \"LABELS\"\n)\n# Define the export 'foo'.\ninstall(TARGETS CoreLibrary1 EXPORT foo DESTINATION /path/to/install/targets)\nexport(EXPORT foo FILE FooFrameworkConfig.cmake)\n```\n\n\nThis will ensure the path to the ```\nbase_framework```\n CMake modules gets exported explicitly, and can be accessed when imported by another project:\n\nYour ```\nextension_libs/CMakeLists.txt```\n file:\n\n```\nfind_package(FooFramework)\n# Get the LABELS property from the imported target.\nget_target_property(BASE_FRAMEWORK_MODULE_DIR CoreLibrary1 LABELS)\nmessage(STATUS \"BASE_FRAMEWORK_MODULE_DIR: ${BASE_FRAMEWORK_MODULE_DIR}\")\n```\n\n\nWith a debug ```\nmessage()```\n, we can verify the CMake modules directory was imported:\n\n```\nBASE_FRAMEWORK_MODULE_DIR: /your/path/to/base_framework/cmake\n```\n\n\n\n\nEDIT: Instead of hijacking the ```\nLABELS```\n target property, you could also use ```\ndefine_property()```\n to define your own custom property for the target.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "sklearn decision tree classifier: How to control max number of branches of each split\r\n                \r\nI am trying to code a two class classification DT problem that I used SAS EM before. But trying to do it in Sklearn. The target variable is a two class categorical variable. But there are a few continuous independent variables. In SAS I could specify the \"Maximum Number of Branches\" for each split. So when it is set to 4, some leaf will split into 2 and some in 4 (especially for continuous variables). I could not find an equivalent parameter in sklearn. Looked at \"max_leaf-nodes\". But that controls the total number of \"leaf\" nodes of the entire tree. I am sure some of you probably has faced the same situation and already found a solution. Please help/share. I will really appreciate it.\n    ", "Answer": "\r\nI don't think this option is available in sklearn, You will find this Post very useful for your Classification DT; as it lists all the options you have available.\n\nI would recommend creating Bins for your continues variables; this way you force the branches to be the number of bins you have.\n\nExample:  For continuous variable COl1 has values between 1-100; you can create a 4 bins 1-25, 26-50 , 51-75, 76-100. or you can create the bins bases on the median.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "In Entity framework 4.0 how can we fetch multiple record set from database in one call & pass all data to View\r\n                \r\nIn Entity framework 4.0 how can we fetch multiple record set from database in one call like we do in ado.net dataset?\n\nSoppose we have 3 table T1,T2 and T3. We need to fetch data from all tree table and pass to view(ASP.NET MVC3). No JOIN is to be used as all are independent table. Instead of making 3 call to database we want to wrap up all select statement in one SP and make only one call to database and pass all data to view.\n\nIn case of dataset if stored procedure return data from multiple select statement dataset populate each recordset in different table.\n\nHow can we achieve it in EF? Please help me.\n\nThanks,\n\nPaul\n    ", "Answer": "\r\nThere is no out of the box feature to batch queries in EF. But there are some efforts made by others to extend EF to support this.\n\n\nEntity Framework Batch Update and Future Queries \nMultiQuery\n(more queries in one batch) in Entity Framework using LINQ\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Unsure how to change Root Directory to point away from my HTTP sites content\r\n                \r\nI am currently SSH'd into my AWS VM IP address on Ubuntu.\nI've installed the Apache SSL module, copied my server certificate and private key to ```\n/etc/pki/tls/certs```\n and ```\n/etc/pki/tls/private```\n. Changed the configuration within ```\n/etc/httpd/conf.d/ssl.conf```\n so that it would be listening for port 4443.\nFrom here, I need to change the document root to something different than my nginx HTTP site or else both HTTPS and HTTP will point to the same content.\nI was told to use independent directory trees but unsure how to set it up.\nI attempted by going to ```\n/etc/httpd/conf/httpd.conf```\n and changed the document root to a directory I setup to separate them within ```\n/etc/```\n but still gives me the same message when trying to access the website as shown in the screenshot.\n\n\nurl of test page HTTPS\ntest page HTTPS\n    ", "Answer": "\r\nDoes your site show up if you add the port? For example, https://yoursite.com:4443. Port 4443 isn't the default https port (that's 443), so you'll need to reference it explicitly.\nYou might want to, instead, consider using an ALB in front of the EC2 instance and terminate SSL there, leaving the httpd/nginx server on the EC2 instance only running on port 80 (default). This offloads the SSL handling to the load balancer and also enables you to do things like rolling upgrades to a new EC2 instance instead of keeping a \"pet\" web server.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Fast pseudo random number generator for procedural content\r\n                \r\nI am looking for a pseudo random number generator which would be specialized to work fast when it is given a seed before generating each number. Most generators I have seen so far assume you set seed once and then generate a long sequence of numbers. The only thing which looks somewhat similar to I have seen so far is Perlin Noise, but it generates too \"smooth\" data - for similar inputs it tends to produce similar results.\n\nThe declaration of the generator should look something like:\n\n```\nint RandomNumber1(int seed);\n```\n\n\nOr:\n\n```\nint RandomNumber3(int seedX, int seedY, int seedZ);\n```\n\n\nI think having good RandomNumber1 should be enough, as it is possible to implement RandomNumber3 by hashing its inputs and passing the result into the RandomNumber1, but I wrote the 2nd prototype in case some implementation could use the independent inputs.\n\nThe intended use for this generator is to use it for procedural content generator, like generating a forest by placing trees in a grid and determining a random tree species and random spatial offsets for each location.\n\nThe generator needs to be very efficient (below 500 CPU cycles), because the procedural content is created in huge quantities in real time during rendering.\n    ", "Answer": "\r\nSeems like you're asking for a hash-function rather than a PRNG. Googling 'fast hash function' yields several promising-looking results.\n\nFor example:\n\n```\nuint32_t hash( uint32_t a)\n    a = (a ^ 61) ^ (a >> 16);\n    a = a + (a << 3);\n    a = a ^ (a >> 4);\n    a = a * 0x27d4eb2d;\n    a = a ^ (a >> 15);\n    return a;\n}\n```\n\n\nEdit: Yep, some hash functions definitely look more suitable than others.\n\nFor your purposes, it should be sufficient to eyeball thefunction and check that a single-bit change in the input will propagate to lots of output bits.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Facade library/bundling pattern in CMake\r\n                \r\nWe want to create and install a \"facade\" static library with a public self-contained/independent API on top of an existing CMake build structure using CMake. It must hide the underlying complexity of the CMake targets when installed.\nWe have a rather complicated hierarchy of own and 3rd-party C and C++ targets that I want to present through a pure C \"facade\" static library aka public API/lib to end-users; basically a set of dependent static libraries and a very small set of independent header files ONLY from the facade library; aka the public API. The facade library must hide all the underlying complexity of the targets when installed i.e. all target include directories, public headers etc. should be ignored for the facade target.\nThe otherwise excellent target oriented structure of CMake is working against us in this case e.g. when configuring we get errors about include directories which are prefixed in the source directories, however these include dirs are not needed when the facade target/library is used, since it by design hides all this complexity.\nIs there a recommended CMake pattern for this case? We have tried capping the dependeny hierarchy by doing library bundling using a 3rd party cmake library that traversed the dependency tree and collects static library paths, thereby avoiding all the target inheritance in that way, however it has drawbacks and it tricky to maintain xplat and we would prefer a CMake idiomatic solution.\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "method for implementing regression tree on raster data - python\r\n                \r\nI'm trying to build and implement a regression tree algorithm on some raster data in python, and can't seem to find the best way to do so. I will attempt to explain what I'm trying to do:\n\nMy desired output is a raster image, whose values represent lake depth, call it depth.tif. I have a series of raster images, each representing the reflectance values in different Landsat bands, say [B1.tif, B2.tif, ..., B7.tif] that I want to use as my independent variables to predict lake depth.\n\nFor my training data, I have a shapefile of ~6000 points of known lake depth. To create a tree, I extracted the corresponding reflectance values for each of those points, then exported that to a table. I then used that table in weka, a machine-learning software, to create a 600-branch regression tree that would predict depth values based on the set of reflectance values. But because the tree is so large, I can't write it in python manually. I ran into the python-weka-wrapper module so I can use weka in python, but have gotten stuck with the whole raster part. Since my data has an extra dimension (if converted to array, each independent variable is actually a set of ncolumns x nrows values instead of just a row of values, like in all of the examples), I don't know if it can do what I want. In all the examples for the weka-python-wrapper, I can't find one that deals with spatial data, and I think this is what's throwing me off.\n\nTo clarify, I want to use the training data (which is a point shapefile/table right now but can- if necessary- be converted into a raster of the same size as the reflectance rasters, with no data in all cells except for the few points I have known depth data at), to build a regression tree that will use the reflectance rasters to predict depth. Then I want to apply that tree to the same set of reflectance rasters, in order to obtain a raster of predicted depth values everywhere.\n\nI realize this is confusing and I may not be doing the best job at explaining. I am open to other options besides just trying to implement weka in python, such as sklearn, as long as they are open source. My question is, can what I described be done? I'm pretty sure it can, as it's very similar to image classification, with the exception that the target values (depth) are continuous and not discrete classes but so far I have failed. If so, what is the best/most straight-forward method and/or are there any examples that might help?\n\nThanks\n    ", "Answer": "\r\nI have had some experience using LandSat Data for the prediction of environmental properties of soil, which seems to be somewhat related to the problem that you have described above.  Although I developed my own models at the time, I could describe the general process that I went through in order to map the predicted data.\n\nFor the training data, I was able to extract the LandSat values (in addition to other properties) for the spatial points where known soil samples were taken.  This way, I could use the LandSat data as inputs for predicting the environmental data.  A part of this data would also be reserved for testing to confirm that the trained models were not overfitting to training data and that it predicted the outputs well.\n\nOnce this process was completed, it would be possible to map the desired area by getting the spatial information at each point of the desired area (matching the resolution of the desired image).  From there, you should be able to input these LandSat factors into the model for prediction and the output used to map the predicted depth.  You could likely just use Weka in this case to predict all of the cases, then use another tool to build the map from your estimates.\n\nI believe I whipped up some code long ago to extract each of my required factors in ArcGIS, but it's been a while since I did this.  There should be some good tutorials out there that could help you in that direction.\n\nI hope this helps in your particular situation.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "how basic instructions run in parallel\r\n                \r\nMaybe this is a stupid question but I am trying to gain a better understanding of hardware inner workings...\n\nif a cpu has multi threads and we have a group of instruction set to assign it. as i read how it work from http://www.lighterra.com/papers/basicinstructionscheduling/ link. it says compiler will create a dependency tree of instructions and than instructions will run in parallel.how cpu will know dependent instruction has been finished or not. will it increase complexity.\n\ni write a c code to see this\n\n```\nint main()\n{\ngetchar();\nputchar('a'); \nreturn 0;    \n}\n```\n\n\ni think that instructions of getchar() and putchar() are independent and when i am not giving input from keyboard than on other thread instructions of putchar('a') should be executed and it should show output before asking for input. but it wait fist for input all time.\n\nthanks in advance.\n    ", "Answer": "\r\nThat article mentions the CDC 6600, one of the first computers to implement scoreboarding .\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Remove/hide git branches without deleting commit histories\r\n                \r\nSituation:\n\nI have a main repo with a main dev branch and lots of \"experiment\" branches sprouting off from it (e.g., ```\nexp1```\n and ```\nexp2```\n).  The purpose of these experiment branches is to serve as placeholders for experiments that generate numerical results.  I record the branch name (and commit ID) of the experiment branches so I can return to the commits to see precisely the code and history behind the results.\n\nBut, now, there are so many experiment branches that it's getting hard to see the main tree.  So, I'm rethinking my strategy for keeping placeholders to the code behind each set of results (i.e., each experiment).  Obviously I could just save the working dir at each branch, but it would be nice to keep the commit history also.\n\nPossible solution:\n\nOne way to deal with this is to move the experiment branches into their own independent repos, each being rooted at the child node of the appropriate node in the commit history of the dev branch.  Here's an illustration of what I mean:\n\n\n\nClick here for larger version of image (on imgur.com).\n\nSo, for example, for branch ```\nexp1```\n, I would like to export commits ```\nA->B->C```\n to a separate repo rooted at commit ```\nA```\n.  Then, I can just record the hash of commit ```\nP1```\n so that I know where the ```\nexp1```\n branch descended from.\n\nQuestion:\n\nHow can I do that?\n\nBetter question:\n\nOn the other hand, I strongly suspect there is a much better strategy for doing what I want to do---namely, unclutter the tree for visual inspection but keep placeholders to prior branches so I can return to them if needed.  So, can anyone recommend a strategy for this?\n    ", "Answer": "\r\nHere's one alternative: use non-branch references to save the branch-tips before deleting the branch names.\nSince these are non-branch references, they won't show up in ```\ngit branch```\n output, nor in stuff shown by ```\ngit log --branches```\n and ```\ngitk --branches```\n, for instance.  However, they will show up in ```\n--all```\n listings, and will retain repository objects.\nTo create or update a non-branch reference, use ```\ngit update-ref```\n.  Choose a name-space within ```\nrefs/```\n that you think will not collide with some future use (current uses are ```\nrefs/heads/```\n for branches, ```\nrefs/tags/```\n for tags, ```\nrefs/remotes/```\n for remote branches, ```\nrefs/notes/```\n for notes, and ```\nrefs/stash```\n for the stash). [Edit, July 2022: ```\nrefs/namespaces/```\n is now reserved as well, and ```\nrefs/replace/```\n is used by ```\ngit replace```\n. ```\nrefs/bisect/```\n, ```\nrefs/rewritten/```\n, and ```\nrefs/worktree/```\n are reserved; ```\nrefs/original/```\n is reserved if you will use ```\ngit filter-branch```\n.  Gerrit, if you use it, has more reserved names.  The list never seems to stop growing, so use care here.]\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Is there a way to prevent CALayer shadows from overlapping adjacent layers?\r\n                \r\nI have a collection of ```\nCALayers```\n. Each layer is a sublayer of the same parent ```\nCALayer```\n, and each has a shadow applied to it. The layers are positioned dynamically, and there are many of them, so I can't predict how they'll be arranged ahead of time.\n\nIf the layers are adjacent to each other (close enough that they are almost touching) the shadow of one of the ```\nCALayers```\n is rendered on top of the other ```\nCALayer```\n. That's probably the desired effect in most cases, but I want my layers to exist in the same z-plane. (An example of this is the way CSS3 shadows are applied to block elements in web design.)\n\nIs this possible? How can I achieve this?\n\n(I had this idea: Adding a 'shadow' sublayer to each ```\nCALayer```\n with my own shadow image, and setting the z-position to a lower value. But doesn't the layer-tree make this impossible? Z-positions in one layer's coordinate system are independent from z-positions in another layer's coordinate system, right?)\n    ", "Answer": "\r\nIf all of the shadowed layers have the same shadow settings, put them into a container layer and set the shadow on the container layer.  Example:\n\n```\n- (void)viewDidLoad\n{\n    [super viewDidLoad];\n\n    CALayer *containerLayer = [CALayer layer];\n    containerLayer.frame = self.view.bounds;\n    containerLayer.shadowRadius = 10;\n    containerLayer.shadowOpacity = 1;\n    [self.view.layer addSublayer:containerLayer];\n\n    CAShapeLayer *layer1 = [CAShapeLayer layer];\n    layer1.bounds = CGRectMake(0, 0, 200, 200);\n    layer1.position = CGPointMake(130, 130);\n    layer1.path = [UIBezierPath bezierPathWithOvalInRect:layer1.bounds].CGPath;\n    layer1.fillColor = [UIColor redColor].CGColor;\n    [containerLayer addSublayer:layer1];\n\n    CAShapeLayer *layer2 = [CAShapeLayer layer];\n    layer2.bounds = CGRectMake(0, 0, 200, 200);\n    layer2.position = CGPointMake(170, 200);\n    layer2.path = [UIBezierPath bezierPathWithOvalInRect:layer2.bounds].CGPath;\n    layer2.fillColor = [UIColor blueColor].CGColor;\n    [containerLayer addSublayer:layer2];\n}\n```\n\n\nOutput:\n\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Fuzzy decision trees (ID3). From ID3 to FuzzyID3\r\n                \r\ni have the following question about the fuzzy decision trees: I have a training data(10 columns, 1,000,000 rows), how can a decision tree(e.g ID3) \"work\" with fuzzy sets? This training set has to be \"fuzzified\" before the FuzzyID3 algorithm uses it?. I have worked with decision trees algorithms but never with fuzzy logic, i'm studying fuzzy logic to understand how can i \"wrap\" fuzzy logic with ID3 algorithm.\n\nThese questions arise from: I need to give a prediction, where some variables have influence in others(some are independent too), that's the reason why i think that fuzzy-ID3 can \"solve\" that problem.\nAnother important question, some variables that are not in the training data(no historic register) have a clearly influence in variables in the training data. Is there any way to include this variables to the final prediction?.\nLet me give a situation: This prediction is based in the historical data, but clearly don't include the actual real-world situation, for example, a prediction of a \"forest fire(a dumb example)\", this consider only the historical data, and indeed the prediction could be good, but did not consider that it's been raining for 1 week...\n\nSorry for my bad english and my poor knowledges about fuzzy logic.\nThanks for reading my questions!\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "WPF Buttons ContentTemplate getting overridden when set through the style\r\n                \r\nIf I set ```\nContentTemplate```\n on Content Presenter directly it works fine, if I use ```\nStyle```\n it gets overridden:\n\nInside Buttons ```\nControlTemplate```\n:\n\n```\n<ContentPresenter ContentTemplate=\"{StaticResource Default}\"/>\n```\n\n\nvs\n\n```\n<ContentPresenter Style=\"{StaticResource MyContentStyle}\"/>\n```\n\n\nWorks fine:\n\n```\n<DataTemplate x:Key=\"Default\">\n    <StackPanel>\n        <TextBlock>this is the</TextBlock>\n        <TextBlock>default view</TextBlock>\n        <TextBlock Text=\"{Binding}\"></TextBlock>\n    </StackPanel>\n</DataTemplate>\n\n<ControlTemplate x:Key=\"ButtonTemplate\" TargetType=\"Button\">\n    <Grid Margin=\"20\">\n        <ContentPresenter HorizontalAlignment=\"Center\" VerticalAlignment=\"Center\"\n                                      ContentTemplate=\"{StaticResource Default}\"\n                                      />\n        </Border>\n    </Grid>\n</ControlTemplate>\n</Grid.Resources>\n<Button Template=\"{StaticResource ButtonTemplate}\">Click Me</Button>\n```\n\n\nDefault ```\nDataTemplate```\n is not applied, it says overridden in visual tree.\n    \n        \n            this is the\n            default view\n            \n        \n    \n\n```\n<Style x:Key=\"MyContentStyle\" TargetType=\"ContentPresenter\">\n    <Setter Property=\"ContentTemplate\" Value=\"{StaticResource Default}\"/>\n</Style>\n\n<ControlTemplate x:Key=\"ButtonTemplate\" TargetType=\"Button\">\n    <Grid Margin=\"20\">\n        <ContentPresenter HorizontalAlignment=\"Center\" VerticalAlignment=\"Center\" \n                                      Style=\"{StaticResource MyContentStyle}\"\n                                      />\n        </Border>\n    </Grid>\n</ControlTemplate>\n</Grid.Resources>\n<Button Template=\"{StaticResource ButtonTemplate}\">Click Me</Button>\n```\n\n\nIf I use ```\nContentPresenter```\n independently from button it works fine:\n\n```\n<Grid>\n    <ContentPresenter Style=\"{StaticResource MyContentStyle}\" Content=\"Work fine even with Style\" />\n</Grid>\n```\n\n    ", "Answer": "\r\nThe ```\nButton```\n has its own ```\nContentTemplate```\n property. Set this one directly:\n\n```\n<Button Template=\"{StaticResource ButtonTemplate}\" ContentTemplate=\"{StaticResource Default}\">Click Me</Button>\n```\n\n\nOr in a ```\nStyle```\n that you apply to the ```\nButton```\n:\n\n```\n<Style x:Key=\"ButtonStyle\" TargetType=\"Button\" >\n    <Setter Property=\"ContentTemplate\" Value=\"{StaticResource Default}\"/>\n    <Setter Property=\"Template\">\n        <Setter.Value>\n            <ControlTemplate TargetType=\"Button\">\n                <Grid Margin=\"20\">\n                    <ContentPresenter HorizontalAlignment=\"Center\" VerticalAlignment=\"Center\"  />\n                </Grid>\n            </ControlTemplate>\n        </Setter.Value>\n    </Setter>\n</Style>\n...\n<Button Style=\"{StaticResource ButtonStyle}\">Click Me</Button>\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "\"Statically linking\" a typescript library with Angular\r\n                \r\nI have a project with an Angular Frontend, a CLI frontend and a core set of files that are independent from Angular. Currently I create the Angular Application via the Angular CLI and the CLI frontend via a standalone ```\ntsconfig.json```\n from the same directory tree:\n```\nangular-client/src/main.ts        // Angular entry point\nangular-client/src/main.cli.ts    // CLI entry point\nangular-client/src/core/index.ts  // Doesn't use any Angular imports\n```\n\nSo I basically have two applications in the same source tree. This worked fine until now where I want to add another API frontend using e.g. Nest.js. I would therefore like to split up my project structure \"properly\" using 4 distinct folders:\n```\ncore/index.ts                  // Doesn't use any Angular imports\nangular-client/src/main.ts     // Angular entry point\ncli-app/main.ts                // CLI entry point\napi-app/main.ts                // API webserver entry point\n```\n\nI discovered npm workspaces and they seemed to be the solution to my problem: After setting them up I can compile the Angular application just fine. But when I run the application every function of my core library isn't available. It seems that the Typescript compiler is happily finding my type definitions from the ```\ncore```\n folder but is not \"linking\" the actual JavaScript code into the generated Angular application. I have a minimal project available on GitHub and I will try to reproduce the most relevant excerpts here.\n```\nnpm install\ncd angular-client\nnpx ng serve\n```\n\nIf you now surf to ```\nhttp://localhost:4200```\n you will get an error like:\n```\nERROR TypeError: core__WEBPACK_IMPORTED_MODULE_0__.libraryFunction is not a function\n```\n\n```\n// @file package.json\n// Setting up workspaces\n{\n  \"devDependencies\": {\n    \"prettier\": \"^2.3.2\"\n  },\n  \"workspaces\": [\n    \"angular-client\",\n    \"core\"\n  ]\n}\n```\n\n```\n// @file core/package.json\n{\n  \"name\": \"core\",\n  \"version\": \"0.1.0\",\n  \"devDependencies\": {\n    \"barrelsby\": \"2.2.0\",\n    \"typescript\": \"4.2.4\"\n  }\n}\n```\n\n```\n// @file core/index.ts\nexport function libraryFunction() {\n  console.log(\"index.ts from library\");\n}\n```\n\n```\n// @file angular-client/package.json\n// This links to `core/package.json`\n{\n  \"name\": \"angular-client\",\n  \"version\": \"0.0.0\",\n  \"scripts\": {\n    \"ng\": \"ng\",\n    \"start\": \"ng serve\",\n    \"build\": \"ng build\",\n    \"watch\": \"ng build --watch --configuration development\"\n  },\n  \"private\": true,\n  \"dependencies\": {\n    \"@angular/animations\": \"~12.1.1\",\n    \"@angular/common\": \"~12.1.1\",\n    \"@angular/compiler\": \"~12.1.1\",\n    \"@angular/core\": \"~12.1.1\",\n    \"@angular/forms\": \"~12.1.1\",\n    \"@angular/platform-browser\": \"~12.1.1\",\n    \"@angular/platform-browser-dynamic\": \"~12.1.1\",\n    \"@angular/router\": \"~12.1.1\",\n    \"rxjs\": \"~6.6.0\",\n    \"tslib\": \"^2.2.0\",\n    \"zone.js\": \"~0.11.4\",\n    \"core\": \"0.1.0\"\n  },\n  \"devDependencies\": {\n    \"@angular-devkit/build-angular\": \"~12.1.1\",\n    \"@angular/cli\": \"~12.1.1\",\n    \"@angular/compiler-cli\": \"~12.1.1\",\n    \"@types/node\": \"^12.11.1\",\n    \"typescript\": \"~4.3.2\"\n  }\n}\n```\n\n```\n// @file angular-client/src/app/app.component.ts\n// This uses the `libraryFunction` defined by `core`\nimport { Component, OnInit } from '@angular/core';\n\nimport { libraryFunction } from 'core';\n\n@Component({\n  selector: 'app-root',\n  templateUrl: './app.component.html',\n  styleUrls: ['./app.component.css'],\n})\nexport class AppComponent implements OnInit {\n  libraryFunction = libraryFunction();\n\n  ngOnInit(): void {\n    console.log(this.libraryFunction);\n  }\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How can I make my Express use an independent user's rate instead of the server itself?\r\n                \r\nI currently have an Express app running as a back end hosted on onRender for free that serves API for my front end. The Express is using another third-party extension to get the data. And their rate limit is 90 requests per minute for every user. (I'm getting images and descriptions, etc. and they allow it for non-commercial purposes). I made the site as a hobby project and for free for me and a couple of my friends to use, so the traffic of use might go over 90 rates per minute for the server itself, but that'll not be the case if I can somehow make my app use user rate independently, mean 90 requests per minute for each user independently.\nThis is their rate limit policy: Anilist rate limit  policy\nI'm using this npm to get their data: Anilist node extension\nBut I think that whenever someone uses my app in the front end that connects to the back end, the third-party extension counts my Express server as 1 user only.\nBecause: User goes to my page => API from my Express come to serve => Express itself has its own domain and counts as only 1 due to it having its own IP address.\nSo 90 requests, but if 10 people use my app, each of them will only have 9 requests per minute, what if later on there are 90 people using my app, if so, each person will only have 1 request?\nPlease correct me if my way of thinking is wrong.\nIf I'm not wrong, is there anyways I can make my user use their own rate instead of the server's rate itself?\nThis is how I set up my Express (I minify it a bit, but the whole Express app is following this structure).\nMy tree structure is only like this:\n```\n.\n└── Express root folder/\n    └── src/\n        ├── model.js\n        ├── routes.js\n        ├── controller.js\n        └── index.js\n```\n\nThis is my ```\nindex.js```\n and how I set up Express file:\n```\nconst express = require(\"express\")\nconst cors = require(\"cors\")\nconst path = require(\"path\")\nconst routes = require(\"./routes\")\nconst app = express()\nconst PORT = process.env.PORT || 3000\n\napp.use(cors())\napp.set(\"trust proxy\", true)\n\napp.use((req, res, next) => {\n    res.setHeader(\"Access-Control-Allow-Origin\", \"*\")\n    res.header(\n        \"Access-Control-Allow-Headers\",\n        \"Origin, X-Requested-With, Content-Type, Accept\"\n    )\n    next()\n})\napp.use(\"/api\", routes)\napp.listen(PORT, () => {\n    console.log(\"Server is running\", PORT)\n})\n```\n\nIn the ```\nroutes.js```\n file I config it like this:\n```\nconst express = require(\"express\")\nconst controller = require(\"./controller\")\nconst router = express.Router()\n\nrouter.get(\"/\", controller.getData)\nmodule.exports = router\n```\n\nHow I set up my controller:\n```\nconst Model = require(\"./model\")\nclass Controller {\n    static async getData(req, res, next) {\n        try {\n            const data = await Model.getData()\n            res.json({ success: true, data  })\n        } catch (err) {\n            res\n                .status(404)\n                .send({ success: false, data: \"Fail and get 404\" })\n        }\n    }\n  }\nmodule.exports = Controller\n```\n\nMy ```\nmodel.js```\n:\n```\nconst anilist = require(\"anilist-node\")\nconst Anilist = new anilist() <==== extension I use to get data, or it could be any other extension\nclass Model {\n    static async getData() {\n\n        //DOING SOMETHING WITH THE ANILIST EXTENSION WILL COUNT THE SERVER RATE, NOT USER RATE\n\n        return data\n    }\n}\nmodule.exports = Model\n```\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Adobe CQ5 component properties for templates\r\n                \r\nIt seems to be quite basic problem, but I still cannot find a nice solution.\nI made a component that uses a dialog property.\n\nHow could I avoid setting this property for every single page if this component is used also in template?\n\nWhat I already have tried:\n\n\nI set ```\nname```\n attribute in dialog.xml to absolute path - Component stops working as standalone (dropped into ```\nparsys```\n).\nMove it to ```\ndesign_dialog.xml```\n - First of all it's conceptually content, so I do not like such move, and again it doeas not make much sense for standalone versions.\nChange resource path to absolute, while including in template:\n\n```\n<cq:include path=\"/content/site/somepage\" resourceType=\"/apps/portal/components/myComponent\" />\n```\n\n\nFor the first look it was almost it. Instances included via ```\nparsys```\n has it's own path, and Content for template is fetched from single resource... But where to store it, to make template code independent from pages tree structure?\n\n\nIs there any other nice way to do so? or at least way to improve 3.?\n    ", "Answer": "\r\nTo the original poster, the functionality you are looking for is now supported by Shared Component Properties in ACS AEM Commons (http://adobe-consulting-services.github.io/acs-aem-commons/features/shared-component-properties.html)\n\nCompared to your suggested solutions:\n\n\nNo need for absolute property path required for SCP\nAgreed these are \"content\" properties, so they should be stored as \"content\" instead of \"design\".  SCP stores these values under the homepage node of a site, making them as genuine of content as any other piece of content.\nAgreed that it is bad to have a template hard-coded to a content path of a single site, especially since this makes a multi-site implementation impossible without creating a bunch of templates.  SCP does not have this problem, because each site has its own homepage under which the properties are stored.\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to use Doctrine nested set for storing multiple trees in one single table?\r\n                \r\nI am planning on using the nested set feature the orm doctrine provides to have threaded comments. In other words, i want to have multiple independent trees stored in one table. In my specific case there would be some entity \"news\" having lots of \"comment\"s. \n\n```\nNews:\n  columns:\n    content: clob\n\nComment:\n  actAs:\n    NestedSet:\n      hasManyRoots: true\n      rootColumnName: root_id\n columns:\n    benutzer_id:       { type: integer, notnull: true }\n    ref_id:            { type: integer, notnull: true }\n    content:            { type: clob, notnull: true}\n  relations:\n    News:\n      class: News\n      local: ref_id\n      foreign: id\n```\n\n\nHow do i tell doctrine to use comment.ref_id as discrimminator-column? So as a result only nodes having the same ref_id relate to one tree. Currently all tree operations effect all nodes stored in the comment-table. Desired is, that only nodes with a given column name (\"ref_id\") will act as one single tree.\n\nupdate\nFor solving the issue I was thinking of producing a way to have many hasManyRoots-trees in one table.\nTo load a tree one would have to create a tree like this:\n\n```\n$category->$treeObject = Doctrine_Core::getTable('Category')->getTree('ref_id',12);\n```\n\n\nAll tree manipulation actions should then include \"WHERE ref_id=12 AND ...\". In my case you'd manipulate the comments-tree for news #12. Hereby the database-update-statements would be less. Since ref_id relates to the news, there's already an index on ref_id and so it should run quite fast.\n\nfinal solution - NOT PART OF THE QUESTION\n\nthrough a lot of discussion and sleeping over it i came up with the following schema. it includes reduction of columns in the comment-table (kicked out the ref_id, root_id now references the root-comment not the news anymore).\n\n```\nNews:\n  columns:\n    content: clob\n    comment_root_id:      { type: integer, notnull: false }\n  relations:\n    CommentRoot:\n      class: Comment\n      local: comment_root_id\n      type: one\n\nComment:\n  actAs:\n    NestedSet:\n      hasManyRoots: true\n  columns:\n    content:            { type: clob, notnull: true}\n```\n\n\nI think this is more clean this way. Creating a News requires to create a dummy-root-node.\n\n```\n        $treeObject = Doctrine_Core::getTable('Comment')->getTree();\n\n        $root = new Comment();\n        $root ->content = 'root';\n        $root->save();\n        $root = $treeObject->createRoot($root);\n\n        $news->setCommentRoot($root);\n        $news->save();\n```\n\n\nAnd finally you can use a left join when querying \"News\" to fetch the root-comment to tell you how many children there are.\n\nFor performance issues you may wanna put an index manually on the root_id-column. Done.\n    ", "Answer": "\r\nthe value for ```\nrootColumnName```\n is the descriminator so if you wan tto use ref id your would do:\n\n```\n  actAs:\n    NestedSet:\n      hasManyRoots: true\n      rootColumnName: ref_id\n```\n\n\nUPDATE:\n\n\n  For solving the issue I was thinking of producing a way to have many hasManyRoots-trees in one table. \n\n\nYoure trying to rework additional functionality! :-) \n\nCalling ```\ngetTree```\n doesnt actually runa query... it just returns the implementation instance - ```\nDoctrine_Tree_NestedSet```\n. YOu have a chance to what you want before you query...\n\nTo just get a certain tree:\n\n```\n$category->$treeObject = Doctrine_Core::getTable('Category')->getTree()->fetchTree(array('root_id' => 12));\n```\n\n\nThe first argument to fetchTree is an array of options you can specify mutltiple things here including\n\n\nthe ```\nroot_id```\n (will be translated to whatever you supplied as the root_id option in your schema)\nthe depth to fetch as ```\ndepth```\n\n\n\nAdditionally, if you need more complex options than that you can supply a base query before you fetch the tree that has whatever query criteria you want on it:\n\n```\n// join you news item\n$q = Doctrine_Core::getTable('Category')->create('c')\n  ->leftJoin('c.News n with n.id = ?', $articleId);\n\n$tree = Doctrine_Core::getTable('Category')->getTree();\n$tree->setBaseQuery($q);\n$nodes = $tree->fetchTree(array('root_id' => 12));\n```\n\n\nThe root_id of the tree should always point to another node in the tree... not something external. By using setting the base query you can run your join on the entire tree or supply other qualifying conditions.\n\n\n\nHowever not that ```\nref_id```\n should not have a FK constraint applied. Roots and trees are managed with the Tree and Node API's which takes care of all this for you. The SQL it will produce for the NestedSet related columns something like this:\n\n```\nCREATE TABLE category (id BIGINT AUTO_INCREMENT,  \nref_id INT, \nlft INT, \nrgt INT, \nlevel SMALLINT, \nPRIMARY KEY(id)) ENGINE = INNODB\n```\n\n\nIf you ant to save yourself headaches leave these column definitions (Aside from naming if thats not agreeable) you will save yourself headaches. If you need to relate back to news use a separate column/relation thats not associated with the actual nested set.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Import of files in one folder from another folder\r\n                \r\nI know there are similar questions asked but what I found is not very clear to me in this simple setting. Given this directory tree how can I import a function from ```\nfile1.py```\n into ```\nfile2```\n (we call the interpreter from the ```\nfile2.py```\n)? I would like this setting to work independently on where ```\nmain_folder```\n is, that is if I copy ```\nmain_folder```\n to a different directory, the imports would still work well.\n```\nmain_folder\n    folder1\n        file1.py (with a function func())\n    folder2\n        file2.py\n```\n\n    ", "Answer": "\r\nYou can use ```\nSourceFileLoader```\n from ```\nimportlib.machinery```\n to import from a path.\nSo you can use:\n```\n# file2.py\n\nfrom importlib.machinery import SourceFileLoader\n\nPATH = \"../folder1/file1.py\"\nfile1 = SourceFileLoader(\"module.name\", PATH).load_module()\n```\n\nOr if you would ```\nimport```\n from a package then you can use:\n```\n# file2.py\n\nfrom folder1.file1 import func\n```\n\nIf you would like to use the package approach then you will need to run it from ```\nmain_folder```\n.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "HOWTO: Install python2.x within virtualenv? [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 10 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\n\n  Possible Duplicate:\n  Python - It is possible to install another version of Python to Virtualenv?  \n\n\n\n\nWithin my (virtualenv activated) env folder, it appears as though the python2.7 folder has symlinks to absolute paths for my system python installation.  \n\nThis is not ideal.  \n\nEven when I install from a local path, and use virtualenv to set and environment in a folder ```\nenv```\n, the paths to Python are absolute, and a dependency on the OS environment is established.  I want to rid this dependency and make the python interpreter, as well as all software relying upon it, completely independent.\n\nLet's imagine that I want python2.6 to be included IN the env tree as a STAND-ALONE installation without symlinks to my system folders.\n\nHow does one accomplish this feat of extraordinary non-linkage?\n\n```\n$ > pwd \n/Users/foo/development/v1/bar/env\n(env)\n$ > ls -l lib/python2.7/\ntotal 920\nlrwxr-xr-x  1 foo  staff     82 Oct 15 16:48 UserDict.py -> /System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/UserDict.py\n...\nlrwxr-xr-x  1 foo  staff     85 Oct 15 16:48 _weakrefset.py -> /System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/_weakrefset.py\n```\n\n\nThank you for your help.\n\nEDIT:  Moreover, it will be most ideal to have the virtualenv (including the local python install) relocatable.\n    ", "Answer": "\r\nUPDATE: Please ALSO refer to Is it possible to install another version of Python to Virtualenv?\n\nBig thanks to @millimoose, et al.\n\nHere's what I ended up doing, very specifically.  I will update if I encounter problems in the future.\n\n\nSet up environment folders.\n\n```\n$ mkdir env\n$ mkdir pyenv\n$ mkdir dep\n```\n\nGet Python-2.7.3, and virtualenv without any form of root OS installation.\n\n```\n$ cd dep\n$ wget http://www.python.org/ftp/python/2.7.3/Python-2.7.3.tgz\n$ wget https://raw.github.com/pypa/virtualenv/master/virtualenv.py\n```\n\nExtract and install Python-2.7.3 into the ```\npyenv```\n dir. ```\nmake clean```\n is optional if you are doing this a 2nd, 3rd, Nth time...\n\n```\n$ tar -xzvf Python-2.7.3.tgz\n$ cd Python-2.7.3\n$ make clean\n$ ./configure --prefix=/path/to/pyenv\n$ make && make install\n$ cd ../../\n$ ls\ndep    env    pyenv\n```\n\nCreate your virtualenv\n\n```\n$ dep/virtualenv.py --python=/path/to/pyenv/bin/python --verbose env\n```\n\nFix the symlink to python2.7 within ```\nenv/include/```\n\n\n```\n$ ls -l env/include/\n$ cd !$\n$ rm python2.7\n$ ln -s ../../pyenv/include/python2.7 python2.7\n$ cd ../../\n```\n\nFix the remaining python symlinks in env.  You'll have to delete the symbolically linked directories and recreate them, as above.  Also, here's the syntax to force in-place symbolic link creation.\n\n```\n$ ls -l env/lib/python2.7/\n$ cd !$\n$ ln -sf ../../../pyenv/lib/python2.7/UserDict.py UserDict.py\n[...repeat until all symbolic links are relative...]\n$ cd ../../../\n```\n\nTest\n\n```\n$ python --version\nPython 2.7.1\n$ source env/bin/activate\n(env)\n$ python --version\nPython 2.7.3\n```\n\n\n\nAloha.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Fusing learners with preprocessing in mlr - what settings to use?\r\n                \r\nI am conducting a benchmark analysis comparing different learners (logistic regression, gradient boosting, random forest, extreme gradient boosting) with the ```\nmlr```\n package.\n\nI understand that there are two different types of preprocessing (data and learner dependent and independent). Now I would like to conduct the data dependent preprocessing using the ```\nmlr```\n's wrapper functionality ```\nmakePreprocWrapperCaret()```\n.\n\nHowever, I am unsure about the settings. As far as I understand correctly, I should impute missings with median (or mean) for logistic regression, however for tree-based models for example with very great values. \n\nQuestion 1) How would I impute NAs with very great values in the code below (for the tree-based models)?\n\nNext, as far as I understand correctly, I should cut off outliers for the logistic regression (e.g. at 99%, and 1%). However, for tree-based models that is not necessary. \n\nQuestion 2) How can I cut off outlier (e.g. at 99%, and 1%) in the code below? \n\nLastly, (again, if I understood correctly) I should standardize the data for the logistic regression. However, I can only find the \"center\" option within the ```\nmakePreprocWrapperCaret()```\n which is not exactly the same.\n\nQuestion 3) How can I standardize in the code below? \n\nMany thanks in advance!!\n\n```\nlrn_logreg = makePreprocWrapperCaret(\"classif.logreg\", method = c(\"medianImpute\")) #logistic regression --> include standardization + cutoff outliers\nlrn_gbm = makePreprocWrapperCaret(\"classif.gbm\") #gradient boosting --> include imputation with great values\nlrn_rf = makePreprocWrapperCaret(\"classif.randomForest\") #Random Forest --> include imputation with great values\nlrn_xgboost = makePreprocWrapperCaret(\"classif.xgboost\") #eXtreme Gradient Boosting --> include imputation with great values\n```\n\n    ", "Answer": "\r\nYou can have a look at the mlr tutorial for imputation: https://mlr.mlr-org.com/articles/tutorial/impute.html\n\n1)\nYou can use the ```\nmakeImputeWrapper```\n of mlr. For the maximum you can use ```\nimputeMax```\n in ```\nmakeImputeWrapper```\n. \n\n2)\nFor cutting of the highest and lowest values you can write your own preprocWrapper: https://mlr.mlr-org.com/articles/tutorial/preproc.html\n\n3)\nFor normalization there is already a preprocWrapper function: ```\nnormalizeFeatures```\n.\nSee also here: https://mlr.mlr-org.com/reference/normalizeFeatures.html\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "JavaFX: CheckBoxTreeItem item not selected when checked\r\n                \r\nBefore finding out about CheckBoxTreeItem, I used a regular TreeItem, with a ComboBox. The CellFactory had an onAction property which I passed into the CheckBox onAction method. The onAction EventHandler came from the Controller, so when I checked/unchecked that action method in the controller was called. The problem was the TreeItem did not get selected.\n\nNow trying to use CheckBoxTreeItem instead. However I have a few problems with it regarding selection and action.\n\nI need to perform an action when a CheckBox has been checked/unchecked. I want the checkbox to change state when the TreeItem has been selected. I need the TreeItem to be selected when a CheckBox is changed.\n\n1)\nSelecting the TreeItem does not change the selected state of the CheckBox. I had to write an onMousePressed action to do that.\n\n```\n@FXML public void performSelection() {\n    TreeItem<Mine> selectedItem = treeView.getSelectionModel().getSelectedItem();\n    boolean selected = ((CheckBoxTreeItem<Mine>) selectedItem).isSelected();\n((CheckBoxTreeItem<Mine>) selectedItem).setSelected(!selected);\n}\n```\n\n\nHowever, when a CheckBox on the TreeItem is checked/unchecked, that TreeItem is not selected. Is not that the point of CheckBoxTreeItem?\n\n2)\nI have created a ChangeListener that listens to the state of the CheckBoxTreeItem selectedProperty. This listener is registered on each items in the tree. It is the only way I can create an action to do some work on checked/unchecked.\n\nHowever, checking an TreeItem, since it does not select the TreeItem I cannot access it with tree.getSelectionModel().getSelectedItem() in the listener. A CheckBox action where I cannot access the TreeItem data of that CheckBox's item is pointless. If I select a TreeItem it stays on that TreeItem, and if I check on a different TreeItem CheckBox, the selectedItem is Wrong.\n\nIf I select the top item and I want to perform some action on that items data, the change listener is called for ALL the children. This complicates matters. I only care of the state of the selected TreeItem which got checked/unchecked.\n\nIs there no better way to add an action to the CheckBoxTreeItem than registering a ChangeListener?\n\n3)\nUncheck the child will uncheck the parent, if there are no other siblings. I don't want that. However I want the children to be \"gone\"/unchecked if the parent is unchecked, but I don't want to be notified of it. If I uncheck and there are children, all the children should be unchecked. However I am not interesting in the change event of subitems of the unchecked item. My problem is still that all items below will fire a change event, and not just on the item I am interested in.\n\nI could set each TreeItem independent. Then collapse the expanded item when it is unchecked. The children would still have its state independent from its parent checked or unchecked, but will not be visible.\n\nIssue 1 are the most important problem I have. Checking the CheckBox needs to select the TreeItem of that CheckBox.\n\nIssue 2 works with ChangeListener though I wish there was a better option, and the problem here can be circumvented by setting all items as independent.\n\nIssue 3 I can also circumvent by setting all items to independent and hide them when parent is unchecked. They still maintain their state, but are out of sight.\n\nA small test application\n\n```\npackage com.company;\n\nimport javafx.application.Application;\nimport javafx.application.Platform;\nimport javafx.beans.value.ChangeListener;\nimport javafx.beans.value.ObservableValue;\nimport javafx.scene.Scene;\nimport javafx.scene.control.CheckBoxTreeItem;\nimport javafx.scene.control.TreeItem;\nimport javafx.scene.control.TreeView;\nimport javafx.scene.layout.GridPane;\nimport javafx.scene.text.Text;\nimport javafx.stage.Stage;\n\npublic class MineAppTest extends Application {\n\n    private TreeView<Mine> treeView;\n\n    private MineChangeListener mineChangeListener = new MineChangeListener();\n\n    public static void main(String[] argv) {\n        MineAppTest.launch();\n    }\n\n    /* (non-Javadoc)\n     * @see javafx.application.Application#start(javafx.stage.Stage)\n     */\n    @Override\n    public void start(Stage primaryStage) throws Exception {\n        GridPane contentPane = new GridPane();\n        contentPane.getChildren().add(new Text(\"Hello World!\"));\n\n        treeView = new TreeView<>();\n        treeView.setCellFactory(new MineTreeCellFactory());\n        treeView.setOnMousePressed(event -> {\n            TreeItem<Mine> selectedItem = treeView.getSelectionModel().getSelectedItem();\n            boolean selected = ((CheckBoxTreeItem<Mine>)selectedItem).isSelected();\n            ((CheckBoxTreeItem<Mine>)selectedItem).setSelected(!selected);\n        selectedItem.setExpanded(!selected);\n        });\n\n        treeView.setShowRoot(false);\n\n        Mine mine1 = new Mine(\"mine\", true);\n        CheckBoxTreeItem<Mine> rootItem = new CheckBoxTreeItem<>(mine1, null, true);\n        rootItem.setExpanded(true);\n        treeView.setRoot(rootItem);\n\n        Mine mine2 = new Mine(\"test1\", true);\n        CheckBoxTreeItem<Mine> item1Level1 = new CheckBoxTreeItem<>(mine2, null, mine2.isEnabled());\n        item1Level1.setExpanded(true);\n        //item1Level1.setIndependent(true);\n        item1Level1.selectedProperty().addListener(mineChangeListener);\n        rootItem.getChildren().add(item1Level1);\n\n        Mine mine3 = new Mine(\"subtest1\", true);\n        CheckBoxTreeItem<Mine> item1Level2 = new CheckBoxTreeItem<>(mine3, null, mine3.isEnabled());\n        item1Level2.setExpanded(true);\n        //item1Level2.setIndependent(true);\n        item1Level2.selectedProperty().addListener(mineChangeListener);\n        item1Level1.getChildren().add(item1Level2);\n\n        Mine mine4 = new Mine(\"subtest2\", true);\n        CheckBoxTreeItem<Mine> item2Level2 = new CheckBoxTreeItem<>(mine4, null, mine4.isEnabled());\n        item2Level2.setExpanded(true);\n        //item2Level2.setIndependent(true);\n        item2Level2.selectedProperty().addListener(mineChangeListener);\n        item1Level1.getChildren().add(item2Level2);\n\n        Mine mine5 = new Mine(\"test2\", true);\n        CheckBoxTreeItem<Mine> item2Level1 = new CheckBoxTreeItem<>(mine5, null, mine5.isEnabled());\n        item2Level1.setExpanded(true);\n        //item2Level1.setIndependent(true);\n        item2Level1.selectedProperty().addListener(mineChangeListener);\n        item1Level1.getChildren().add(item2Level1);\n\n        Mine mine6 = new Mine(\"subtest2\", true);\n        CheckBoxTreeItem<Mine> item4Level2 = new CheckBoxTreeItem<>(mine6, null, mine6.isEnabled());\n        item4Level2.setExpanded(true);\n        //item4Level2.setIndependent(true);\n        item4Level2.selectedProperty().addListener(mineChangeListener);\n        item2Level1.getChildren().add(item4Level2);\n\n        Mine mine7 = new Mine(\"subtest3\", true);\n        CheckBoxTreeItem<Mine> item5Level2 = new CheckBoxTreeItem<>(mine7, null, mine6.isEnabled());\n        item5Level2.setExpanded(true);\n        //item5Level2.setIndependent(true);\n        item5Level2.selectedProperty().addListener(mineChangeListener);\n        item4Level2.getChildren().add(item5Level2);\n\n        contentPane.getChildren().add(treeView);\n\n        primaryStage.setScene(new Scene(contentPane));\n        primaryStage.setWidth(200);\n        primaryStage.setHeight(400);\n        primaryStage.setTitle(\"JavaFX 8 app\");\n        primaryStage.setOnCloseRequest(event -> Platform.exit());\n        primaryStage.show();\n    }\n\n    private class MineChangeListener implements ChangeListener<Boolean>    {\n\n        /* (non-Javadoc)\n         * @see     javafx.beans.value.ChangeListener#changed(javafx.beans.value.ObservableValue, java.lang.Object, java.lang.Object)\n         */\n        @Override\n        public void changed(ObservableValue<? extends Boolean> observable, Boolean oldValue, Boolean newValue) {\n            CheckBoxTreeItem<Mine> item = (CheckBoxTreeItem<Mine>) treeView.getSelectionModel().getSelectedItem();\n            if (newValue) {\n                // Do some work on the data in the selected TreeItem\n            }\n        }\n\n    }\n\n}\n\npackage com.company;\n\nimport javafx.scene.control.TreeCell;\nimport javafx.scene.control.TreeView;\nimport javafx.scene.control.cell.CheckBoxTreeCell;\nimport javafx.util.Callback;\n\npublic class MineTreeCellFactory implements Callback<TreeView<Mine>, TreeCell<Mine>> {\n\n    /* (non-Javadoc)\n     * @see javafx.util.Callback#call(java.lang.Object)\n     */\n    @Override\n    public TreeCell<Mine> call(TreeView<Mine> param) {\n        CheckBoxTreeCell<Mine> cell = new CheckBoxTreeCell<Mine>() {\n\n            /* (non-Javadoc)\n             * @see javafx.scene.control.Cell#updateItem(java.lang.Object, boolean)\n             */\n            @Override\n            public void updateItem(Mine item, boolean empty) {\n                if (item == getItem() || (item != null && item.equals(getItem()))) {\n                    return;\n                }\n\n                super.updateItem(item, empty);\n\n                if (empty) {\n                    setText(null);\n                    setGraphic(null);\n                } else {\n                    if (item != null) {\n                        setText(item.getName());\n                    } else {\n                        setText(null);\n                        setGraphic(null);\n                    }\n                }\n            }\n        };\n        return cell;\n    }\n}\n\npackage com.company;\n\nimport javafx.beans.property.SimpleBooleanProperty;\n\npublic class Mine {\n\n    private final String name;\n\n    private final SimpleBooleanProperty enabled;\n\n    public Mine(String name, boolean enabled) {\n        this.name = name;\n        this.enabled = new SimpleBooleanProperty(enabled);\n    }\n\n    /**\n     * @return the name\n     */\n    public String getName() {\n        return name;\n    }\n\n    /**\n     * @return the description\n     */\n    public String getDescription() {\n        return description;\n    }\n\n    public SimpleBooleanProperty enabledProperty() {\n        return enabled;\n    }\n\n    /**\n     * @return the isDisabled\n     */\n    public boolean isEnabled() {\n        return enabled.get();\n    }\n\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Can DEFLATE only compress duplicate strings up to 32 KiB apart?\r\n                \r\nAccording to DEFLATE spec:\n\n\nCompressed representation overview\n\nA compressed data set consists of a series of blocks, corresponding to successive blocks of input\ndata. The block sizes are arbitrary, except that non-compressible\nblocks are limited to 65,535 bytes.\nEach block is compressed using a combination of the LZ77 algorithm and\nHuffman coding. The Huffman trees for each block are independent of\nthose for previous or subsequent blocks; the LZ77 algorithm may use a\nreference to a duplicated string occurring in a previous block, up to\n32K input bytes before.\nEach block consists of two parts: a pair of Huffman code trees that\ndescribe the representation of the compressed data part, and a\ncompressed data part. (The Huffman trees themselves are compressed\nusing Huffman encoding.) The compressed data consists of a series of\nelements of two types: literal bytes (of strings that have not been\ndetected as duplicated within the previous 32K input bytes), and\npointers to duplicated strings, where a pointer is represented as a\npair <length, backward distance>. The representation used in the\n\"deflate\" format limits distances to 32K bytes and lengths to 258\nbytes, but does not limit the size of a block, except for\nuncompressible blocks, which are limited as noted above.\n\nSo pointers to duplicate strings only go back 32 KiB, but since block size is not limited, could the Huffman code tree store two duplicate strings more than 32 KiB apart as the same code? Then is the limiting factor the block size?\n    ", "Answer": "\r\nThe Huffman tree for distances contains codes 0 to 29 (table below); the code 29, followed by 8191 in \"plain\" bits, means \"distance 32768\". That's a hard limit in the definition of Deflate. The block size is not limiting. Actually the block size is not stored anywhere: the block is an infinite stream. If you want to stop the block, you send an End-Of-Block code for that.\n```\n                             Distance Codes\n                             --------------\n       Extra           Extra             Extra               Extra\n  Code Bits Dist  Code Bits  Dist   Code Bits Distance  Code Bits Distance\n  ---- ---- ----  ---- ---- ------  ---- ---- --------  ---- ---- --------\n    0   0    1      8   3   17-24    16    7  257-384    24   11  4097-6144\n    1   0    2      9   3   25-32    17    7  385-512    25   11  6145-8192\n    2   0    3     10   4   33-48    18    8  513-768    26   12  8193-12288\n    3   0    4     11   4   49-64    19    8  769-1024   27   12 12289-16384\n    4   1   5,6    12   5   65-96    20    9 1025-1536   28   13 16385-24576\n    5   1   7,8    13   5   97-128   21    9 1537-2048   29   13 24577-32768\n    6   2   9-12   14   6  129-192   22   10 2049-3072\n    7   2  13-16   15   6  193-256   23   10 3073-4096\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Tips for a light PHP Framework\r\n                \r\n\nI'm trying to write down some concrete ideas for a light framework (on PHP5), with the purpose to handle a lot of requests and to make it scale well in terms of high traffic eventualities.\nI've already started it, but I'm not really satisfied about the coding style, which is basically composed by simple classes and helpers, with a main one to load them all.\n\n```\nclass Settings {\n    // I provide settings for everyone and I'm called by everyone via singleton.\n     // $settings = instance(Settings);\n}\n\nclass Database {\n    // I provide the db connection.\n}\n\nclass Session {\n    // I handle the sessions.\n}\n\n[...]\n\nclass Core {\n    // I start every class we need.\n}\n```\n\n\nThe structure is a kinda basic one. APP is a public tree, SYSTEM is a private tree.\n\n```\napp\n |-- css\n |-- js\n |-- page_name\n       |-- index.php\n [...]\n\nsystem\n |-- settings\n |-- libs\n |-- helpers\n |-- langs\n [...]\n```\n\n\nBasically what I do is setting the paths in the constants on the index.php file, which calles a boot.php file that includes the libraries that we need (Settings, Database, Session), then includes the core.php file that starts every class using objects.\nOf course this is a synthesis. \nI designed everything to be more independent from the core, so if I need, for example, some settings, I just refer to the settings class (by singleton), instead recall the core and then get the data.  \nThe main problem is that I don't know if this \"style\" could be good for my goals, 'cause it looks nooby to me, compared to the others main frameworks. I don't also get why everyone uses things like Implements, Extends, Interface, or others, which I find more confusing than putting everything into a single class with public and private visibility or just using functions. \nCan I get some advanced tips, examples, or whatever can help reaching my goals?  \nThanks!\n    ", "Answer": "\r\nHave you looked at CodeIgniter? Seems to do everything you're doing. What is does (and looks like you're trying to do) is create a super object which loads and manages requests.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Merkle tree for difference comparison, in Cassandra\r\n                \r\nI'm reading an document about repair in Cassandra, it says\n\n\n  The comparison begins with the top node of the Merkle tree. If no difference is detected, the process proceeds to the left child node and compares and then the right child node.\n\n\nHowever, Merkle tree's non-leaf nodes represents:\n\n\n  Each Parent node higher in the tree is a hash of its respective children. Because higher nodes in the Merkle tree represent data further down the tree, Casandra can check each branch independently without requiring the coordinator node to download the entire data set.\n\n\nAccording to this, and other data structure articles I have found, they all indicates a following comparison deeper than the root only be proceed if two Merkle trees has the root that differs. I'm not sure if the document describes it correctly that I may understood something wrong, or it actually has an error?\n    ", "Answer": "\r\nThere is a mistake in Datastax docs.\n\nThere's is a good explanation of Merkle tree's comparison:\n\nhttp://distributeddatastore.blogspot.co.il/2013/07/cassandra-using-merkle-trees-to-detect.html\n\nMany eventual consistency databases using Merkle tree for anti-entropy. You can review the documentation and explanation of it in Riak/DynamoDB documentation.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Heterogeneous (JavaEE+JavaScript) application construction\r\n                \r\nImagine a software system that consists of JavaEE backend and JavaScript frontend. Each component employs its own complex build process (Maven for JavaEE backend, Grunt for JavaScript frontend). Each component should remain an independent module, with their own branching and versioning schemes. Moreover, different developer teams will work on backend and frontend. But the final build artifact should be an integrated WAR file with a self-contained (backend+frontend) application.\n\nI'm thinking about implementing the above in the following way:\n\n\nset up individual VCS repositories for backend and frontend;\nwithin backend tree, establish a dependency on frontend via SVN externals or git submodule;\nuse grunt-maven-plugin to build frontend code from within backend build process.\n\n\nThe only thing that seems fishy to me is maintaining a dependency on a VCS level (SVN externals or git submodule). Any thoughts/suggestions/alternatives? Can this all be done in a better way?\n    ", "Answer": "\r\nHave you looked at this answer which recommends maven-frontend-plugin?\n\nHow to organize full build pipeline with Gulp, Maven and Jenkins, all the way to integration tests?\n\nI have had good success building a JavaEE project using the maven-frontend-plugin to run a grunt process as part of the build. We use a dedicated build server and the plugin takes care of the node, npm, grunt installation as part of the build task.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "CTest CDash: SubProject xml elements missing under Sites using include(CTest) only to submit test results\r\n                \r\nI built a source tree with several independent projects using CMake to build each individual project.\n\nImportant: I do NOT have a global CMakeLists.txt file to perform the whole build, I use generic scripts (windows (.cmd) and unix (.sh)) to loop on all subprojects. I want to keep projects independent and yet have the ability to build them all automatically.\n\nIn CDash on the other hand, I'd like to see all these independent projects as CDash subprojects as part of a bigger unique artificial CDash project.\n\nTo work with CDash, I followed the method described at:\nhttp://www.cmake.org/Wiki/CMake/Testing_With_CTest\n\nI'll name this method A.\n\nNamely, I do:\n\n```\nenable_testing()\ninclude(CTest)\n```\n\n\nAnd, then put some tests of my own.\n\nAfterwards, I tried to follow following page indications to make my individual projects seen as subprojects:\nhttp://www.kitware.com/media/html/CDashSubprojects.html\n\nI'll name this method B.\n\nThe problem is that the xml that are submited to CDash lack the ```\nSubProject```\n and ```\nLabels```\n xml elements (tags for xml abusers), those under ```\nSites```\n, although my CMakeLists.txt (actually my CTestConfig.cmake) file has the following global property settings (I tried to put it in both files):\n\n```\nset_property(GLOBAL PROPERTY SubProject ${CMAKE_PROJECT_NAME})\nset_property(GLOBAL PROPERTY Label ${CMAKE_PROJECT_NAME})\n```\n\n\nwhere CMAKE_PROJECT_NAME is -of course- well defined.\n\n\nDo you know wjy ```\nSubProject```\n and ```\nLabels```\n elements are missing under ```\nSites```\n element of submited xml files?\nCan methods A and B be mixed?\n\n\nFurthermore, I checked CTest source, these global properties are added by this function (I took it from 2.8.10, couldn't download the source of 2.8.11 I'm using, so I hope there's no change it that otherwise sorry):\n\n```\n//----------------------------------------------------------------------\nvoid cmCTest::AddSiteProperties(std::ostream& ostr)\n{\n  cmCTestScriptHandler* ch =\n    static_cast<cmCTestScriptHandler*>(this->GetHandler(\"script\"));\n  cmake* cm =  ch->GetCMake();\n  // if no CMake then this is the old style script and props like\n  // this will not work anyway.\n  if(!cm)\n  {\n    return;\n  }\n  // This code should go when cdash is changed to use labels only\n  const char* subproject = cm->GetProperty(\"SubProject\", cmProperty::GLOBAL);\n  if(subproject)\n  {\n    ostr << \"<Subproject name=\\\"\" << subproject << \"\\\">\\n\";\n    const char* labels =\n      ch->GetCMake()->GetProperty(\"SubProjectLabels\", cmProperty::GLOBAL);\n    if(labels)\n    {\n      ostr << \"  <Labels>\\n\";\n      std::string l = labels;\n      std::vector<std::string> args;\n      cmSystemTools::ExpandListArgument(l, args);\n      for(std::vector<std::string>::iterator i = args.begin();\n          i != args.end(); ++i)\n      {\n        ostr << \"    <Label>\" << i->c_str() << \"</Label>\\n\";\n      }\n      ostr << \"  </Labels>\\n\";\n    }\n    ostr << \"</Subproject>\\n\";\n  }\n\n  // This code should stay when cdash only does label based sub-projects\n  const char* label = cm->GetProperty(\"Label\", cmProperty::GLOBAL);\n  if(label)\n  {\n    ostr << \"<Labels>\\n\";\n    ostr << \"  <Label>\" << label << \"</Label>\\n\";\n    ostr << \"</Labels>\\n\";\n  }\n}\n```\n\n\n\nDoes ```\nch->GetCMake()```\n return NULL somehow in my case?\n\n\nThanks in advance for your help. Regards.\n\n\n\nP.-S.: Please refrain yourself from asking me why I do this or that (unless you have a relevante point to make), because -one- it doesn't help, -two- if I do it, it's because I've got a good reason where this place is not a good one to expose it. I come here to seek your kind help preferably from someone who knows what s/he's talking about or a clear final \"no it's not possible that way, do it that other way, because of this\" (the because being mandatory - please no peremptory answers).\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Amortized runtime for insertion in scapegoat tree\r\n                \r\nI am working on the following problem, from a problem set for a course I am self studying.\n\n\n\nI have solved the first part.  I'm stuck on the second.  These are my thoughts so far.  I think that the proper way to rebuild the subtree rooted at v would be to traverse it once to copy the values into an array in sorted order, and then, traverse it once again to build it into a balanced binary tree.  Thus, this would be linear in v.size.  However, I don't see where the potential and the constant can turn this into a O(1), let alone how such a constant could depend upon alpha.  As I thought the rebuild operation was independent of alpha, and alpha simply affects how often you have to rebuild?  So would the alpha come out of the potential function?  And then the c just serves to cancel the alpha?  If so, could I have some guidance as to how to rewrite the potential function?\n    ", "Answer": "\r\nYou don't need to rewrite the potential function. The way that c and alpha interact is in the part of (2) in which \"a subtree that is not alpha-balanced\". That should help you derive a lower bound on the potential of that subtree. Part (1) helps you derive an upper bound on the potential of that subtree after the rebuilding. The resulting difference in potential should help you pay for the rebuilding.\n\nIn particular, the lower bound will be something like f(c,alpha) * m for some function f. This problem wants you to find an expression for c in terms of alpha so that f(c,alpha) >= 1.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Multiple websites sharing content from one central location?\r\n                \r\nAt the moment I have three umbraco websites that each have their own content trees, but all have one page in common. At the moment, since all three sites are independent, the data is just copied into each site.\n\nHowever our client is now asking that all the pages can be managed from one site. Ie. the data is updated in one umbraco installation and somehow mirrored across the other sites. Bear in mind this page is password protected and contains sensitive data.\n\nHow can I achieve this?\n\nMy first thought was maybe to expose an xml feed that contained all of the relevant data however I have no idea how I'd keep all the data secure. Would it be a case of encrypting and setting over https? I literally have no idea where to begin here.. can anyone point me in the correct direction?\n\nI'm really looking for the simplest solution here.\n\nThanks\n    ", "Answer": "\r\nIf you have three separate web sites as implied by you saying coping data from one site to another, I would set up a web service on the main site where the data is edited. Then just put  macros on the other sites to display the data.\n\nIf it is sensitive data add a login and password to the web service and it would all have to be https.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Retaining the state (collapsed/expanded nodes) of a NestedTree when using BookmarkablePageLink\r\n                \r\nI have a problem that I can't find an elegant solution for. I want to use a ```\nNestedTree```\n (or something similar) as a simple menu for my page. Each node links to a ```\nPage```\n that shows content that is identified by an ID. To get nice URLs and easy bookmarking I'd like to use ```\nBookmarkablePageLinks```\n to link to these pages.\n\nBut doing it that way creates a completely new ```\nPage```\n each time, thus destroying and recreating the tree, resetting it's state. So with each link click the complete tree collapses and the user has to open it again to choose another link.\nI can't find a solution, that satisfies these criteria:\n\n\nEach tab/window retains a separate state\nOpening a new tab copies the state from the tab it's opened from, but is then independent\nEasy to use, meaning you don't have to manually set and restore state for each link\n\n\nIt would be okay if the state is not restored when the bookmarked URL is called.\n\nWith Wicket 1.4 I was able to use the ```\npageMapName```\n to maintain a map of ```\nPageMaps```\n and their menu states in the session. But that functionality got altered substantially with Wicket 1.5 (I'm using 6.8 now).\n\nI would be quite grateful for solutions or tips on how to do this.\n    ", "Answer": "\r\n\n  But doing it that way creates a completely new Page each time, thus\n  destroying and recreating the tree, resetting it's state. So with each\n  link click the complete tree collapses and the user has to open it\n  again to choose another link.\n\n\nThe tree collapses because its model is being recreated on page load. You are probably keeping the tree's model as a member variable on the page. To get around this issue you should store the tree's model in the session object instead. This way you can retain the state across multiple pages.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "CMake: Do I need to set POSITION_INDEPENDENT_CODE here and what exactly is its purpose?\r\n                \r\nI am currently reading \"Modern CMake for C++\" ([1]) and I am at page 193 where the concept of \"position independent code\" is explained. However it is only explained in one page and I didn't completely understand what its purpose is exactly and when I need to set it manually. I am still a noob when it comes to the details of how compiling/linking in C++ works, that's part of why I bought this book. It explains the basic concepts of how compilation/linking works in the previous chapters and I felt like I understood those concepts fairly well (how static libraries are basically archived object files and shared libraries being similar to final executables that can be loaded into runtime dynamically, for example). However, I am not sure how \"position indenpendent code\" fits in here, or, in other words, I am not sure if I understood it correctly.\nFrom what I have read ([2], [3]) my current understanding is this:\n\nStatic libraries produce position dependent (machine) code by default. Their variables are\nmapped to hardcoded virtual memory addresses which is more efficient.\nShared libraries produce position independent machine code. Since they are dynamically loaded into the process runtime, it can't be known to which address their variables will be mapped to. For this purpose, they have a global offset table that acts as a placeholder address that will be resolved to some spot in the virtual memory when they are executed\nWhen a static library is linked to a shared library, it itself must also be position independent, otherwise... (I don't actually know what would happen otherwise. The book I read just says \"you'll run into trouble with CMake\" but I don't know what that means).\n\nPlease tell me if there is anything wrong in that explanation.\nSo, let's look at an example project that looks like this:\n```\nexample/\n└── src\n    ├── CMakeLists.txt\n    ├── hiprinter\n    │   ├── CMakeLists.txt\n    │   ├── hiprinter.cpp\n    │   ├── hiprinter.h\n    │   └── printer\n    │       ├── CMakeLists.txt\n    │       ├── printer.cpp\n    │       └── printer.h\n    ├── prog\n    │   ├── CMakeLists.txt\n    │   └── main.cpp\n    └── warning_props.cmake\n```\n\nContent of the files (from top to bottom):\n```\n# src/CMakeLists.txt\n\ncmake_minimum_required(VERSION 3.25)\nproject(Prog LANGUAGES CXX)\n\nset(CMAKE_CXX_STANDARD 20)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nset(CMAKE_CXX_EXTENSIONS OFF)\n\ninclude(warning_props.cmake)\n\nadd_subdirectory(prog)\nadd_subdirectory(hiprinter)\n\n# Create Graphviz Tree visualizing dependencies\nadd_custom_target(graphviz ALL\n    COMMAND ${CMAKE_COMMAND} \"--graphviz=dtree.dot\" .\n    COMMAND dot -Tpng dtree.dot -o dtree.png\n    WORKING_DIRECTORY \"${CMAKE_BINARY_DIR}\"\n)\n```\n\n\n```\n# src/hiprinter/CMakeLists.txt\n\nadd_subdirectory(printer)\n\nadd_library(hiprinter STATIC hiprinter.cpp)\ntarget_include_directories(hiprinter PRIVATE .)\ntarget_link_libraries(hiprinter PRIVATE printer warning_props)\n```\n\n\n```\n// src/hiprinter/hiprinter.cpp\n\n#include \"hiprinter.h\"\n#include \"printer/printer.h\"\n#include <iostream>\n\nvoid printHi()\n{\n    print(\"hi\");\n}\n```\n\n\n```\n// src/hiprinter/hiprinter.h\n\n#pragma once\n\nvoid printHi();\n```\n\n\n```\n# src/hiprinter/printer/CMakeLists.txt\n\nadd_library(printer SHARED printer.cpp)\ntarget_include_directories(printer PRIVATE .)\ntarget_link_libraries(printer PRIVATE warning_props)\n```\n\n\n```\n// src/hiprinter/printer/printer.cpp\n\n#include \"printer.h\"\n#include <iostream>\n#include <string>\n\nvoid print(std::string s)\n{\n    std::cout << s << std::endl;\n}\n```\n\n\n```\n// src/hiprinter/printer/printer.h\n\n#pragma once\n\n#include <string>\n\nvoid print(std::string s);\n```\n\n\n```\n# src/prog/CMakeLists.txt\n\nadd_executable(Prog main.cpp)\ntarget_link_libraries(Prog PRIVATE hiprinter warning_props)\ntarget_include_directories(Prog PRIVATE ..)\n```\n\n\n```\n// src/prog/main.cpp\n\n#include \"hiprinter/hiprinter.h\"\n\nint main()\n{\n    printHi();\n}\n```\n\n\n```\n# src/warning_props.cmake\n\nadd_library(warning_props INTERFACE)\n\n# Enable ALL warnings and treat them as errors\ntarget_compile_options(warning_props INTERFACE\n    -Wall\n    -Wextra\n    -Wpedantic\n    -Werror\n)\n```\n\n\nGraphViz dependency tree:\n\nProg depends on hiprinter, a static library. Since hiprinter itself is static and it depends on a shared library, printer, according to the reasons stated above, I would have to configure hiprinter as position-independent right? Because it is a static library and is position-dependent by default.\nSo, I'd have to edit ```\nsrc/hiprinter/CMakeLists.txt```\n like this:\n```\n# src/hiprinter/CMakeLists.txt\n\nadd_subdirectory(printer)\n\nadd_library(hiprinter STATIC hiprinter.cpp)\ntarget_include_directories(hiprinter PRIVATE .)\ntarget_link_libraries(hiprinter PRIVATE printer warning_props)\n\n# Add this:\nset_target_properties(hiprinter\n    PROPERTIES POSITION_INDEPENDENT_CODE\n    ON\n)\n```\n\nAm I doing this right?\nAlso, are there any mistakes in my \"explanation\" above?\nBy the way, this project compiles fine with or without the addition for the PIC property. (I am on Ubuntu 20.04, using GCC 10.3.0)\nPS: Another question: If a static library depends on another static library that is PIC, the first static library must also be configured as PIC, right?\n1 https://en.wikipedia.org/wiki/Position-independent_code\n2 GCC -fPIC option\n3 Combining CMake object libraries with shared libraries\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to watch a member of a struct for every struct variable that has that type?\r\n                \r\nI'm getting corruption of a struct member, where struct is used to build a\nbig tree.  I'm attempting to set a watchpoint, but the \"variable\" has \nvarious names (all examples Ive seen use explicit global variables, \nso dont show examples of what Im looking for).\n\n\n(gdb) watch *(OP*)->op.sibling\nA syntax error in expression, near `->op.sibling'.\n(gdb) watch *(struct op*)->op.sibling\nA syntax error in expression, near `->op.sibling'.\n(gdb) watch (struct op*)->op.sibling\nA syntax error in expression, near `->op.sibling'.\n\n\nthe closest I get to acceptable syntax doesnt work\n\n\n(gdb) watch (struct op*)o->op.sibling\nNo symbol \"o\" in current context.\n\n\nIs there an expression form that Im missing that would be independent\nof the variable name, and attend to the fact that its a particular\nkind of structure ?\n\nWould this be able to detect memset overwrites of the struct ?\n(even if not, it would help me to rule out some causes)\n\nIs there a gdb reference that goes beyond basic usage ?\n(for some defs of 'basic')\n    ", "Answer": "\r\nAs ninjalj says, you do have to have an address to watch; that's the whole point of watchpoints. Consider the following example:\n\n```\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n\ntypedef struct node {\n  long value;\n  struct node *next;\n} node;\n\nnode *build_node(int x, node *next)\n{\n  node *n = malloc(sizeof(*n));\n  n->value = x;\n  n->next = next;\n  return n;\n}\n\nint main()\n{\n  node *n = build_node(1, NULL);\n  n = build_node(2, n);\n  n = build_node(3, n);\n\n  memset(&n->next->value, 0xFF, sizeof(long) + 3);  // corrupt the list\n\n  return 0;\n}\n```\n\n\nHere I am generating a list of integers, then corrupt it. Let's see what this looks like in GDB:\n\n```\ngdb -q ./a.out\nReading symbols for shared libraries .. done\n(gdb) b main\nBreakpoint 1 at 0x100000e0c: file foo.c, line 20.\n(gdb) r\nStarting program: /tmp/a.out \nReading symbols for shared libraries +. done\n\nBreakpoint 1, main () at foo.c:20\n20    node *n = build_node(1, NULL);\n\n(gdb) b 26\nBreakpoint 2 at 0x100000e8d: file foo.c, line 26.\n(gdb) c\nContinuing.\n\nBreakpoint 2, main () at foo.c:26\n26    return 0;\n(gdb) p *n\n$1 = {\n  value = 3, \n  next = 0x100100090\n}\n(gdb) p *n.next\n$2 = {\n  value = -1, \n  next = 0x100ffffff\n}\n```\n\n\nHere we clearly see that ```\nn->next```\n as been thoroughly corrupted. Suppose we didn't know where that is happening, and wanted to find out via GDB watchpoint.\n\nFirst, we need to establish the address that has been corrupted:\n\n```\n(gdb) print &n.next.value\n$3 = (long int *) 0x100100090\n(gdb) watch *$3\nHardware watchpoint 3: *$3\n```\n\n\nHere I just set a watchpoint on address 0x100100090 for 8 bytes.\n\n```\n(gdb) run\nThe program being debugged has been started already.\nStart it from the beginning? (y or n) y\nStarting program: /private/tmp/a.out \nwarning: Could not set watchpoint 3\nwarning: Could not set watchpoint 3\n\nBreakpoint 1, main () at foo.c:20\n20    node *n = build_node(1, NULL);\n```\n\n\nI am using a rather old version of GDB, which doesn't understand how to properly disable and re-enable hardware watchpoints across program restart. If you use a more recent version, you'll likely not see above warnings. I can simply re-enable the watchpoint when I am stopped at breakpoint 1:\n\n```\n(gdb) enable 3\n(gdb) c\nContinuing.\nHardware watchpoint 3: *$3\n\nOld value = 0\nNew value = 2\nbuild_node (x=2, next=0x100100080) at foo.c:14\n14    n->next = next;\n```\n\n\nOk, we've reached the expected point and the expected value. The next modification will corrupt it, and we want to know where that's happening.\n\n```\n(gdb) c\nContinuing.\nHardware watchpoint 3: *$3\n\nOld value = 2\nNew value = 255\n0x00007fff82fae450 in memset ()\n(gdb) bt\n#0  0x00007fff82fae450 in memset ()\n#1  0x0000000100000ebe in __inline_memset_chk (__dest=0x100100090, __val=255, __len=11) at _string.h:80\n#2  0x0000000100000e8d in main () at foo.c:24\n```\n\n\nVoilà, you now know where the unexpected modification comes from.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to generate an ordered list of parent-child elements from multiple lists, WITH MULTIPLE ROOTS?\r\n                \r\nI recently asked a question here, and got some very elegant answers. Here it is:\n\nVisit How to generate an ordered list of parent-child elements from multiple lists?\n\nI have a similar problem, in which there can be multiple roots, which means there are separate trees. Here is an example (in perl);\n\n```\nmy @rules = (\n  [ qw( A B C ) ],\n  [ qw( B D E ) ],\n  [ qw( C H G ) ],\n  [ qw( G H   ) ],\n  [ qw( Z C   ) ]\n);\n```\n\n\nIn the list of lists ```\n@rules```\n, A is parent of B and C. Generally, the first element is the parent of rest of the elements in the list.\n\nI would like to process this set of arrays, and generate a list which contains the correct order. Here, A and Z must come before the other elements (the order of A and Z is not important, since they are independent). Here are two example solutions:\n\n```\n(A,Z,B,C,D,E,F,G,H), or (Z,A,B,D,E,F,C,G,H)\n```\n\n\nImportant: Look at array number 3; H comes before G, even though it's a child of G in the fourth array. So there is not particular order of children in each array, but in the final result (as shown over) must have any parent before it's child/ren.\n\n\n    ", "Answer": "\r\nHow about this? It's pretty straight-forward, though.\n\n```\nmy @rules = (\n  [ qw( A B C ) ],\n  [ qw( B D E F ) ],\n  [ qw( C H G ) ],\n  [ qw( G H   ) ],\n  [ qw( Z C   ) ]\n);\n\nmy %weight_for;\nfor (@rules) {\n  my ($parent, @children) = @{$_};\n  $weight_for{$_}++ for ($parent, @children);\n  $weight_for{$_} += $weight_for{$parent} \n    for @children; \n}\n\nprint \"$_ = $weight_for{$_}\\n\" \n  for sort { $weight_for{$a} <=> $weight_for{$b} } keys %weight_for;\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "multinomial logistic multilevel models in R\r\n                \r\nProblem: I need to estimate a set of multinomial logistic multilevel models and can’t find an appropriate R package. What is the best R package to estimate such models? STATA 13 recently added this feature to their multilevel mixed-effects models – so the technology to estimate such models seems to be available.\n\nDetails: A number of research questions require the estimation of multinomial logistic regression models in which the outcome variable is categorical. For example, biologists might be interested to investigate which type of trees (e.g., pine trees, maple trees, oak trees) are most impacted by acid rain. Market researchers might be interested whether there is a relationship between the age of customers and the frequency of shopping at Target, Safeway, or Walmart. These cases have in common that the outcome variable is categorical (unordered) and multinomial logistic regressions are the preferred method of estimation. In my case, I am investigating differences in types of human migration, with the outcome variable (mig) coded 0=not migrated, 1=internal migration, 2=international migration. Here is a simplified version of my data set:\n\n```\nmigDat=data.frame(hhID=1:21,mig=rep(0:2,times=7),age=ceiling(runif(21,15,90)),stateID=rep(letters[1:3],each=7),pollution=rep(c(\"high\",\"low\",\"moderate\"),each=7),stringsAsFactors=F)\n\n   hhID mig age stateID pollution\n1     1   0  47       a      high\n2     2   1  53       a      high\n3     3   2  17       a      high\n4     4   0  73       a      high\n5     5   1  24       a      high\n6     6   2  80       a      high\n7     7   0  18       a      high\n8     8   1  33       b       low\n9     9   2  90       b       low\n10   10   0  49       b       low\n11   11   1  42       b       low\n12   12   2  44       b       low\n13   13   0  82       b       low\n14   14   1  70       b       low\n15   15   2  71       c  moderate\n16   16   0  18       c  moderate\n17   17   1  18       c  moderate\n18   18   2  39       c  moderate\n19   19   0  35       c  moderate\n20   20   1  74       c  moderate\n21   21   2  86       c  moderate\n```\n\n\nMy goal is to estimate the impact of age (independent variable) on the odds of (1) migrating internally vs. not migrating, (2) migrating internationally vs. not migrating, (3) migrating internally vs. migrating internationally. An additional complication is that my data operate at different aggregation levels (e.g., pollution operates at the state-level) and I am also interested in predicting the impact of air pollution (pollution) on the odds of embarking on a particular type of movement. \n\nClunky solutions: One could estimate a set of separate logistic regression models by reducing the data set for each model to only two migration types (e.g., Model 1: only cases coded mig=0 and mig=1; Model 2: only cases coded mig=0 and mig=2; Model 3: only cases coded mig=1 and mig=2). Such a simple multilevel logistic regression model could be estimated with lme4 but this approach is less ideal because it does not appropriately account for the impact of the omitted cases. A second solution would be to run multinomial logistic multilevel models in MLWiN through R using the R2MLwiN package. But since MLWiN is not open source and the generated object difficult to use, I would prefer to avoid this option. Based on a comprehensive internet search there seem to be some demand for such models but I am not aware of a good R package. So it would be great if some experts who have run such models could provide a recommendation and if there are more than one package maybe indicate some advantages/disadvantages. I am sure that such information would be a very helpful resource for multiple R users. Thanks!!\n\nBest,\nRaphael\n    ", "Answer": "\r\nThere are generally two ways of fitting a multinomial models of a categorical variable with J groups: (1) Simultaneously estimating J-1 contrasts; (2) Estimating a separate logit model for each contrast.\n\nProduce these two methods the same results? No, but the results are often similar\n\nWhich method is better? Simultaneously fitting is more precise (see below for an explanation why)\n\nWhy would someone use separate logit models then? (1) the ```\nlme4```\n package has no routine for simultaneously fitting multinomial models and there is no other multilevel R package that could do this. So separate logit models are presently the only practical solution if someone wants to estimate multilevel multinomial models in R. (2) As some powerful statisticians have argued (Begg and Gray, 1984; Allison, 1984, p. 46-47), separate logit models are much more flexible as they permit for the independent specification of the model equation for each contrast.\n\nIs it legitimate to use separate logit models? Yes, with some disclaimers. This method is called the “Begg and Gray Approximation”. Begg and Gray (1984, p. 16) showed that this “individualized method is highly efficient”. However, there is some efficiency loss and the Begg and Gray Approximation produces larger standard errors (Agresti 2002, p. 274). As such, it is more difficult to obtain significant results with this method and the results can be considered conservative. This efficiency loss is smallest when the reference category is large (Begg and Gray, 1984; Agresti 2002). R packages that employ the Begg and Gray Approximation (not multilevel) include ```\nmlogitBMA```\n (Sevcikova and Raftery, 2012).\n\n\n\nWhy is a series of individual logit models imprecise? \nIn my initial example we have a variable (```\nmigration```\n) that can have three values ```\nA```\n (no migration), ```\nB```\n (internal migration), ```\nC```\n (international migration). With only one predictor variable ```\nx```\n (age), multinomial models are parameterized as a series of binomial contrasts as follows (Long and Cheng, 2004 p. 277):\n\n```\nEq. 1:  Ln(Pr(B|x)/Pr(A|x)) = b0,B|A + b1,B|A (x) \nEq. 2:  Ln(Pr(C|x)/Pr(A|x)) = b0,C|A + b1,C|A (x)\nEq. 3:  Ln(Pr(B|x)/Pr(C|x)) = b0,B|C + b1,B|C (x)\n```\n\n\nFor these contrasts the following equations must hold:\n\n```\nEq. 4: Ln(Pr(B|x)/Pr(A|x)) + Ln(Pr(C|x)/Pr(A|x)) = Ln(Pr(B|x)/Pr(C|x))\nEq. 5: b0,B|A + b0,C|A = b0,B|C\nEq. 6: b1,B|A + b1,C|A = b1,B|C\n```\n\n\nThe problem is that these equations (Eq. 4-6) will in praxis not hold exactly because the coefficients are estimated based on slightly different samples since only cases from the two contrasting groups are used und cases from the third group are omitted. Programs that simultaneously estimate the multinomial contrasts make sure that Eq. 4-6 hold (Long and Cheng, 2004 p. 277). I don’t know exactly how this “simultaneous” model solving works – maybe someone can provide an explanation? Software that do simultaneous fitting of multilevel multinomial models include MLwiN (Steele 2013, p. 4) and STATA (xlmlogit command, Pope, 2014).\n\n\n\nReferences:\n\nAgresti, A. (2002). Categorical data analysis (2nd ed.). Hoboken, NJ: John Wiley & Sons.\n\nAllison, P. D. (1984). Event history analysis. Thousand Oaks, CA: Sage Publications.\n\nBegg, C. B., & Gray, R. (1984). Calculation of polychotomous logistic regression parameters using individualized regressions. Biometrika, 71(1), 11-18.\n\nLong, S. J., & Cheng, S. (2004). Regression models for categorical outcomes. In M. Hardy & A. Bryman (Eds.), Handbook of data analysis (pp. 258-285). London: SAGE Publications, Ltd.\n\nPope, R. (2014). In the spotlight: Meet Stata's new xlmlogit command. Stata News, 29(2), 2-3.\n\nSevcikova, H., & Raftery, A. (2012). Estimation of multinomial logit model using the Begg & Gray approximation.\n\nSteele, F. (2013). Module 10: Single-level and multilevel models for nominal responses concepts. Bristol, U.K,: Centre for Multilevel Modelling.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Socketstream(0.3) server-side code confusion\r\n                \r\nI'm trying to understand exactly where/how I should implement node.js/socketstream server side code that runs independent of client rpc calls.  As a simple example I'm trying to push a regular clock update to connected clients using something like this on the server side:\n\n```\nvar pushTime = function() {\n    d = new Date();\n    ss.publish.all('newServerTime', d);\n    return;\n};\n\nsetInterval(pushTime, 1000);\n```\n\n\nAnd setting up the client to subscribe to that publish event sorta like this:\n\n```\nss.event.on('newServerTime', function(time) {\n    return $('#serverTime').val(time);\n});\n```\n\n\nProblem: where do I put/execute the server side pushTime function?  The docs suggest the /server/rpc tree so I put it in /server/rpc/demo.js but that yields this error:\n\nReferenceError: ss is not defined\n\nMind you, I'm not putting the code in the export.actions block; I believe that's only for client rpc calls.\n\nI tried setting ss at the top of the file:\n\n```\nss = require('socketstream');\n```\n\n\nbut that's gotta be wrong - now the 'publish.all' method doesn't exist.\n\nI tried putting the code at the bottom of app.js, right after the ss.start call.  Again that says the publish.all method doesn't exist (maybe not until there's a client attached?).  I'm lost. Any help appreciated; hope this was clear.\n    ", "Answer": "\r\nYup, you could put that code in your actions, nothing to stop you, but better to put it in your 'app.js' file.\n\nTo access the internal API from app.js (the one that's sent through to /server/rpc action files) use ss.api\n\nHence you will need to call:\n\n```\nss.api.publish.all()\n```\n\n\nfrom your 'app.js' file.\n\nApologies this wasn't documented before. I will update the docs shortly.\n\nOwen\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How does binding elementname work exactly?\r\n                \r\nI remember reading a couple of weeks ago that it sometimes doesn't work inside templates, and I recently tried to bind things in two different windows and it couldn't find the name declarations, so I assumed that it was local to the namespace of the class and just bound by setting the datacontext instead. However, I'm really curious when I am able to use binding elementname and when I cannot, because it's far more convenient when it is possible.\n\nedit: In reading that article, I found this to be interesting:\n\n\"For this reason, styles and templates both define their own XAML namescopes, independent of whatever location in an object tree where the style or template is applied.\"\n\nif this is true, doesn't that mean that Binding ElementName should not work in templates at all?  But then I definitely have some working bindings on ElementName within my templates. That is the most confusing part, why do some bindings randomly work inside the templates and others do not?  It must have some method for trying to resolve the name even if it isn't in the template or same namescope\n    ", "Answer": "\r\nBasically you need to be in the same name scope (read this). Most UI elements are in the same tree sharing the same name scope, however there can be breaks and barriers (styles/templates) and if you have abstract objects like ```\nDataGrid```\n columns they do not have a name scope at all.\n\nI've been working with WPF long enough to guess when i'll run into problems and i know common areas but don't think there's an easy way to tell in all situations up-front.\n\n\n\n\n  if this is true, doesn't that mean that Binding ElementName should not work in templates at all? But then I definitely have some working bindings on ElementName within my templates.\n\n\nWithin is just fine, that is the same scope. The point here is that if you apply the template and they would not have their own scopes there would be conflicts.\n\ne.g.\n\n```\n<Button/>\n<Button/>\n```\n\n\nIf we expand the ```\nControlTemplate```\n you would get something like:\n\n```\n<Border Name=\"bd\" Background=\"{TemplateBinding Background}\">...</Border>\n<Border Name=\"bd\" Background=\"{TemplateBinding Background}\">...</Border>\n```\n\n\nObviously we would get a name conflict.\n\nSame for ```\nDataTemplates```\n in ```\nItemsControls```\n, if you name controls in the template that name would conflict with the same control instance in the applied template of other items.\n\n\n\nOn another note, you can bind from inside a template to the outside because logically there can only be one instance with that name or you can give them a distinct precedence based on how \"close\" the name scope is, e.g.\n\n```\n<TextBox Name=\"tb\" Text=\"Test\"/>\n<ItemsControl ItemsSource=\"ABC\">\n    <ItemsControl.ItemTemplate>\n        <DataTemplate>\n            <TextBlock Text=\"{Binding Text, ElementName=tb}\"/>\n        </DataTemplate>\n    </ItemsControl.ItemTemplate>\n</ItemsControl>\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "install npm package from bitbucket without npm-shrinkwrap.json\r\n                \r\nThe question: \n\nIn NodeJS how can I ignore the shrinkwrap of a dependency \"Package B\" on an \"npm install\" in the higher order \"Project A\", when \"Package B\" comes from a private repo.\n\nThe background:\n\nLet's say we develop on a private npm-package \"fancy-frontend\" and got a CI system for that, which requires to keep a npm-shrinkwrap.json next to the package.json (to have a deterministic snapshot of all dependencies).\n\nIn another repo we do the development on the higher system with the node project \"fancy-system\". That project has a dependency to a tagged version of \"fancy-frontend\". So we do an install of that project with the command\n\n```\nnpm i git+ssh://git@bitbucket.org/myteam/fancy-frontend.git#v1.0.2 --save```\n\n\nBecause of the existing npm-shrinkwrap.json in our sub-dependency \"fancy-frontend\" npm seems to use that sub-shrinkwrap and builds up a complete independent package-tree within the \"fancy-frontend\" modules. Ending up with this huge dependency file tree:\n\n```\nfancy-system/\n   package.json\n   npm-shrinkwrap.json\n   node_modules/\n     react-16.13.1\n     fancy-frontend/\n        package.json\n        npm-shrinkwrap.json\n        node-modules/\n          react-16.13.1      // e.g. same react dep as in parent, but has it's own instance\n          other-deps\n     other deps\n```\n\n\nNOTE: I added react as sample dependency that should be shared by both modules, but is not.\n\nThe issues:\n\nWe got a huge dependency mass with a lot of duplicated packages (although \"fancy-system\" and \"fancy-frontend\" are referencing the same version!).\nWe got issues with react and multiple instances (although we set react as peer dependency in \"fancy-frontend\"!).\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Compare performance of linear regression models that differ by predictors used using cross validation\r\n                \r\nI would like to compare, using tidymodels and cross-validation, 3 linear regression models that can be specified as the following:\n\n(model_A) ```\ny ~ a```\n\n(model_B) ```\ny ~ b```\n\n(model_AB) ```\ny ~ a + b```\n\n\nIn the following ```\ny```\n will denote the target variable, while ```\na```\n and ```\nb```\n will denote independent variables.\nWithout using cross validation it is (I hope) quite clear to me what I have to do:\n\nSplit my data into train and test set\n\n```\nset.seed(1234)\nsplit <- data %>% initial_split(strata = y)\ndata_train <- training(split)\ndata_test <- training(split)\n```\n\n\nI can specify, fit, and evaluate my model in one go (for example for model_AB)\n\n```\nlinear_reg() %>%\n    set_engine(\"lm\") %>%\n    fit(y ~ a + b, data = data_train) %>%\n    augment(new_data = data_test) %>%\n    rmse(truth = y, estimate = .pred)\n```\n\nThe output looks something like this:\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       x.xxx\n```\n\nI can repeat step 2 for the other two models and compare the three models based on the RMSE metric (since this is the choice for this example).\nFor example I can create a dummy dataset and run the steps described above.\n```\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nset.seed(1234)\nn <- 1e4\ndata <- tibble(a = rnorm(n),\n               b = rnorm(n),\n               y = 1 + 3*a - 2*b + rnorm(n))\n\nset.seed(1234)\nsplit <- data %>% initial_split(strata = y)\ndata_train <- training(split)\ndata_test <- training(split)\n```\n\n\nModel_A\n\n```\nlinear_reg() %>%\n    set_engine(\"lm\") %>%\n    fit(y ~ a, data = data_train) %>%\n    augment(new_data = data_test) %>%\n    rmse(truth = y, estimate = .pred)\n```\n\nresult\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        2.23\n```\n\n\nModel_B\n\n```\nlinear_reg() %>%\n    set_engine(\"lm\") %>%\n    fit(y ~ b, data = data_train) %>%\n    augment(new_data = data_test) %>%\n    rmse(truth = y, estimate = .pred)\n```\n\nresult\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        3.17\n```\n\n\nModel_AB\n\n```\nlinear_reg() %>%\n    set_engine(\"lm\") %>%\n    fit(y ~ a + b, data = data_train) %>%\n    augment(new_data = data_test) %>%\n    rmse(truth = y, estimate = .pred)\n```\n\nresult\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.00\n```\n\nMy question is: how can I evaluate the RMSE after performing cross validation on three models that differ by the list of possible features?\nIn this video Julia Silge does the job with three different models (logistic regression, knn, and decision trees) using the same set of predictors. However what I aim to do is to compare models that differ in the set of predictors.\nAny suggestion and/or reference?\n    ", "Answer": "\r\nWhen you have a lot of different models you want to compare, one way to deal with that is to use the workflowsets package.\nThis way you can specify any number of models and preprocessors and it will run all of them and give you back the results in a tidy format.\nNotice how we are using ```\nrecipe()```\n just denotes what variables are used in each model.\nAdditionally you can pass a ```\nmetric_set()```\n to the ```\nmetrics```\n in ```\nworkflow_map()```\n if you want to use different metrics than the defaults.\n```\nlibrary(tidymodels)\nset.seed(1234)\nn <- 1e4\ndata <- tibble(a = rnorm(n),\n               b = rnorm(n),\n               y = 1 + 3*a - 2*b + rnorm(n))\n\nset.seed(1234)\nsplit <- data %>% initial_split(strata = y)\ndata_train <- training(split)\ndata_test <- training(split)\n\nlm_spec <- linear_reg()\n\nrec_a <- recipe(y ~ a, data = data_train)\nrec_b <- recipe(y ~ b, data = data_train)\nrec_ab <- recipe(y ~ a + b, data = data_train)\n\nall_models_wfs <- workflow_set(\n  preproc = list(a = rec_a, b = rec_b, c = rec_ab),\n  models = list(lm = lm_spec),\n  cross = TRUE\n)\n\nall_models_wfs\n#> # A workflow set/tibble: 3 × 4\n#>   wflow_id info             option    result    \n#>   <chr>    <list>           <list>    <list>    \n#> 1 a_lm     <tibble [1 × 4]> <opts[0]> <list [0]>\n#> 2 b_lm     <tibble [1 × 4]> <opts[0]> <list [0]>\n#> 3 c_lm     <tibble [1 × 4]> <opts[0]> <list [0]>\n\nall_models_fit <- workflow_map(\n  all_models_wfs, \n  resamples = vfold_cv(data_test),\n  metrics = metric_set(rmse, rsq, mape)\n)\n\nall_models_fit %>%\n  collect_metrics()\n#> # A tibble: 9 × 9\n#>   wflow_id .config           preproc model .metric .esti…¹    mean     n std_err\n#>   <chr>    <chr>             <chr>   <chr> <chr>   <chr>     <dbl> <int>   <dbl>\n#> 1 a_lm     Preprocessor1_Mo… recipe  line… mape    standa… 261.       10 3.99e+1\n#> 2 a_lm     Preprocessor1_Mo… recipe  line… rmse    standa…   2.26     10 2.89e-2\n#> 3 a_lm     Preprocessor1_Mo… recipe  line… rsq     standa…   0.627    10 7.72e-3\n#> 4 b_lm     Preprocessor1_Mo… recipe  line… mape    standa… 258.       10 2.07e+1\n#> 5 b_lm     Preprocessor1_Mo… recipe  line… rmse    standa…   3.10     10 2.13e-2\n#> 6 b_lm     Preprocessor1_Mo… recipe  line… rsq     standa…   0.298    10 7.61e-3\n#> 7 c_lm     Preprocessor1_Mo… recipe  line… mape    standa… 144.       10 3.66e+1\n#> 8 c_lm     Preprocessor1_Mo… recipe  line… rmse    standa…   1.01     10 6.51e-3\n#> 9 c_lm     Preprocessor1_Mo… recipe  line… rsq     standa…   0.926    10 2.06e-3\n#> # … with abbreviated variable name ¹​.estimator\n```\n\nCreated on 2022-09-19 by the reprex package (v2.0.1)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "What data structure to choose for an ELO rating system with 20k+ entries?\r\n                \r\nI have some Objects (currently 20 000 +) that have the following Attributes\n\n```\nObject\n----------\nString name\nint    rating\n```\n\n\nI want to create an ELO rating for all these Objects. This implies the following:\n\n\nTo adjust the ELO of 2 Objects matched against each other I need to find those Objects in the list by ```\nname```\n.\nTo Display the List I need to get every Object ordered by its ```\nrating```\n.\n\n\nThe whole program will be implemented in Java, but I think its independent from the programming language.\n\nCurrently I am unsure which data model to choose for this Project. A friend advised me to use a 2-4 tree to insert the Objects ordered by ```\nname```\n so I can change the rating of each object fast. \n\nHowever the Objects are printed in order of their ```\nrating```\n rather than by name and I don't want to sort so many Objects every time I output the list.\n\nAs I am pretty new to data structures: What is the usual way to solve this problem? \nCreating another tree ordered by ```\nrating```\n? \nHaving a list of ```\nratings```\n and each rating linked to each Object currently having that rating?\n\nEdit: ELO rating is a mapping from the set of objects to the integers. Each object only gets one rating but a rating can have multiple Objects associated with it.\n    ", "Answer": "\r\n\n  Creating another tree ordered by rating? Having a list of ratings and each rating linked to each Object currently having that rating?  \n\n\nWell , this is one way to do so , but will take huge space also since you have 20K+ entries .  \n\nThe best way i can think of now is :\nUse datastructure like multimap with ```\nkey```\n=```\nname```\n , and ```\nvalue```\n = ```\nratings```\n.\nThis way , everytime you insert a new ```\nobject```\n in multimap , it will take O(logN) time . \n\nTo find all ratings with same ```\nname```\n use equal_range , which is also an O(logN) operation .\n\nHope this helps !\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to know the factor by which a feature affects a model's prediction\r\n                \r\nI have trained my model on a data set and i used decision trees to train my model and it has 3 output classes - Yes,Done and No , and I got to know the feature that are most decisive in making a decision by checking feature importance of the classifier. I am using python and sklearn as my ML library. Now that I have found the feature that is most decisive I would like to know how that feature contributes, in the sense that if the relation is positive such that if the feature value increases the it leads to Yes and if it is negative It leads to No and so on and I would also want to know the magnitude for the same.\n\nI would like to know if there a solution to this and also would to know a solution that is independent of the algorithm of choice, Please try to provide solutions that are not specific to decision tree but rather general solution for all the algorithms. \n\nIf there is some way that would tell me like:\n\nfor feature x1 the relation is 0.8*x1^2\nfor feature x2 the relation is -0.4*x2 \n\njust so that I would be able to analyse the output depends based on input feature x1 ,x2  and so on\n\nIs it possible to find out the whether a high value for particular feature to a certain class, or a low value for the feature.\n    ", "Answer": "\r\nYou can use Partial Dependency Plots (PDPs). scikit has a built-in PDP for their GBM - http://scikit-learn.org/stable/modules/ensemble.html#partial-dependence which was created in Friedman's Greedy Function Approximation Paper http://statweb.stanford.edu/~jhf/ftp/trebst.pdf pp26-28.\n\nIf you used scikit-learn GBM, use their PDP function.  If you used another estimator, you can create your own PDP which is a few lines of code. PDPs and this method is algorithm agnostic as you asked. It just will not scale. \n\nLogic\n\n\nTake your training data \nFor the feature you are examining, get all unique values or some quantiles to reduce the time\nTake a unique value\nFor the feature you are examining, in all observations, replace with the value from (3)\nPredict all training observations\nGet the mean of all predictions\nPlot the point (unique value, mean)\nRepeat 3-7 taking the next unique value until no more values\n\n\nYou now have a 1-way PDP. When the feature increases (X-axis), what on average happens to the prediction (y-axis). What is the magnitude of the change.\n\nTaking the analysis further, you can fit a smooth curve or splines to the PDP which may help understand the relationship. As @Maxim said, there is not a perfect rule so you are looking for the trend here, trying to understand a relationship. We tend to run this for the most important features and/or features you are curious about.\n\nThe above scikit-learn reference has more examples.\n\nFor a Decision Tree, you can use the algorithmic short-cut as described by Friedman and implemented by scikit-learn. You need to walk the tree so the code is tied to the package and algorithm, hence it does not answer your question and I will not describe it. But it is on that scikit-learn page I referenced and in the paper.\n\n```\ndef pdp_data(clf, X, col_index):\n    X_copy = np.copy(X)\n\n    results = {}\n\n    results['x_values'] = np.sort(np.unique(X_copy[:, col_index]))\n    results['y_values'] = []\n\n    for value in results['x_values']:\n        X_copy[:, col_index] = value\n        y_predict = clf.predict_log_proba(X_copy)[:, 1]\n        results['y_values'].append(np.mean(y_predict))\n\n    return results\n```\n\n\nEdited to answer new part of question:\nFor the addition to your question, you are looking for a linear model with coefficients.  If you must interpret the model with linear coefficients, build a linear model. \n\nSometimes how you need to interpret the model guides what type of model you build.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Shiny App reactivity issue and scoping issue\r\n                \r\nI am new to shiny and I am trying to build an app but I have been stuck on this one issue for a while. The purpose of the app is so users can upload their data, select their independent and dependent variables, select their number of trees...etc and eventually have that run through a random forest script and display the outputs. \n\nHowever, right now I am stuck on setting up the drop-down input where users can select their variables (headers from the data they uploaded). It needs to be reactive so they first upload their data and then the app automatically knows what to put in the drop-down menu because it would be NULL otherwise. Here are copies of my ui.R and server.R files. If you know what may be wrong, your help would greatly be appreciated. Also, thank you to the people who helped me last week. I did not upload the actual R code (just images) so it was extra challenging for them.\n\nui.R\n\n```\nlibrary(shiny)\n\nshinyUI(fluidPage(\nheaderPanel(title = \"Upload File\"),\nsidebarLayout(\nsidebarPanel(\n  fileInput(\"file\",\"Upload the file\"),\n  h5(\"Max file size is 5 MB\"),\n  tags$hr(),\n  radioButtons(\"sep\",\"Seperator\", choices = c(Comma = \",\", Period = \".\", Tilde = \"~\",minus = \"-\")),\n  tags$hr(),\n  checkboxInput(\"header\",\"Header\", TRUE),\n  tags$hr(),\n  uiOutput(\"vx\"),\n  tags$hr(),\n  uiOutput(\"vy\"),\n  tags$hr(),\n  numericInput(\"MTRY\", \"Set the MTRY\", 0, min = 0, max = 500, step = 1,\n               width = 100),\n  helpText(\"The MTRY should default to 0\"),\n  numericInput(\"numtree\", \"Number of Trees\", 500, min = 30, max = 10000, step = 100,\n               width = 100)\n),\n\nmainPanel(\n  tableOutput(\"input_file\")\n   )\n  )\n )\n)\n```\n\n\nServer.R\n\n```\nlibrary(shiny)\n\n\nshinyServer(function(input, output) {\n\noutput$input_file <- renderTable({\nfile_to_read = input$file\nif(is.null(file_to_read)){\n  return()\n}\n\ndat1 <- read.table(file_to_read$datapath, sep = input$sep, header = input$header)\n\nreturn(dat1)\n})\n\n\n\nreactive1 = reactive({\n\n\nif(is.null(dat1))\n  return()\nD <- colnames(dat1)\n\nreactive1[[1]] = D\nreactive1[[2]] = D[1]\n\nreactive1\n})\n\noutput$vx <- renderUI({\nselectInput(\"cols\", \"Select Dependent Variable\",\n            choices = colnames(reactive1()[[1]]), selected = reactive1()[[2]][1])\n })\n\n\noutput$vy <- renderUI({\nselectInput(\"cols\", \"Select Independent Variables\",\n            choices = colnames(reactive1()[[1]]), selected = reactive1()[[2]][1], multiple = T)\n})\n\n\n})\n```\n\n\nHere is what the app looks like after uploading a csv:\n\nApp\n    ", "Answer": "\r\nThe key is to make the input data reactive and updateSelectInput based off of the reactive data frame. See below:\n\n```\nui <- fluidPage(\n  titlePanel(\"Uploading Files\"),\n  sidebarLayout(\n    sidebarPanel(\n      fileInput(\"file1\", \"Choose CSV File\",\n                multiple = FALSE,\n                accept = c(\"text/csv\",\n                         \"text/comma-separated-values,text/plain\",\n                         \".csv\")),\n      tags$hr(),\n      checkboxInput(\"header\", \"Header\", TRUE),\n      radioButtons(\"sep\", \"Separator\",\n                   choices = c(Comma = \",\",\n                               Semicolon = \";\",\n                               Tab = \"\\t\"),\n                   selected = \",\"),          \n      tags$hr(),         \n      selectInput(\"vars\", \"Label\",choices = c(\"NULL\"))\n    ),\n    mainPanel(\n      tableOutput(\"contents\")\n    )\n  )\n)\n\nserver <- function(input, output, session) {\n\n  df1 <- reactive({\n           req(input$file1)\n           read.csv(input$file1$datapath,\n                 header = input$header,\n                 sep = input$sep,\n                 quote = input$quote)\n  })\n\n  observeEvent(df1(), {\n    updateSelectInput(session, \"vars\", choices = names(df1()))\n  })\n\n}\n\nshinyApp(ui, server)\n```\n\n\nPlease comment if this answers your question.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Umbraco 7: Get fields from same property based on current page\r\n                \r\nIn my Content section I have a property editor (Archetype) that allows to set content for the site independently from the content tree. It looks like this:\n\n\n\nI need to display only the sub categories from one category based on what page I'm currently on. What I have now is:\n\n```\nvar catItems = Umbraco.Content(1123).categoryItem; //get the Set Content property editor from Content Section\n\nforeach (var item in catItems)\n{\n    foreach (var sub in item.GetValue<ArchetypeModel>(\"subCatItem\"))\n    {\n        <div class=\"tbl_dt\">\n            <p class=\"offerName\">@sub.GetValue(\"offerName\")</p>\n            <p class=\"departurePort\">@sub.GetValue(\"departurePort\")</p>\n        </div>\n    }\n\n}  \n```\n\n\nThis is displaying all the sub category items from all categories. It should display only the sub categories based on current page. How can I make the connection between current page and the sub category item? Or it is best to stick with the property editor in the content tree pages?\n    ", "Answer": "\r\nThe issue is not the code, but rather the structure of your Content Tree.\nYou have nothing to Associate the Category/Offer to the page you want to display it on.\n\nIn order to create an the Association between ContentPage & Category/Offer DocType, you could try one of the following:\n\n\nKeep the Category/Offers as they are, independent of the content tree (i.e. Pool of Categories/Offers etc.) \nThen put a MNTP picker (multi-node tree picker) on the DocType that you want to create the Association between (i.e. 'ProductPage').\n\n\nEach Page where you want to display the Category/Offer(s) you would need to call the MNTP Picker Property to get the NodeId of that specific Category/Offer for \nthe current page.\n\nExample:\n\n```\nvar catNodeId = @CurrentPage.pickerPropertyAliasHere; //this will give us the NodeId of that specific offer selected for the current page, may need to refactor your code to handle parsing etc.\n\nvar catItems = @Umbraco.Content(catNodeId).categoryItem; //Get Categories/Offers from the Offer picked for the current page.\n\nforeach (var item in catItems)\n{\n    foreach (var sub in item.GetValue<ArchetypeModel>(\"subCatItem\"))\n    {\n        <div class=\"tbl_dt\">\n            <p class=\"offerName\">@sub.GetValue(\"offerName\")</p>\n            <p class=\"departurePort\">@sub.GetValue(\"departurePort\")</p>\n        </div>\n    }\n\n}\n```\n\n\n\nPut your ArcheType property editor on the DocType you want to Associate with. \nThen simply call the property for that page and loop over the items again (see example below).\n\n\nExample:\n\n```\nvar catItems = @CurrentPage.categoryItem; //Get Categories/Offers for the current page\n\nforeach (var item in catItems)\n{\n    foreach (var sub in item.GetValue<ArchetypeModel>(\"subCatItem\"))\n    {\n        <div class=\"tbl_dt\">\n            <p class=\"offerName\">@sub.GetValue(\"offerName\")</p>\n            <p class=\"departurePort\">@sub.GetValue(\"departurePort\")</p>\n        </div>\n    }\n\n}  \n```\n\n\nGood Luck\nC\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "CSS position relative : width not considered\r\n                \r\nI try to build a pure CSS tree. I encountered a problem with horizontal lines between blocks (two blocks are at the same level). I isolated the problem in the following jsfiddles:\n\nhttps://jsfiddle.net/8Lsv1ypd/3/\n\nhttps://jsfiddle.net/8Lsv1ypd/4/\n\nHtml : \n\n```\n<span class=\"first\">First</span>\n<span class=\"second\">Second</span>\n```\n\n\nCSS: \n\n```\n.first {\n  background-color: #dc3545;\n  color: #fff;\n  font-size: 1.2rem;\n  border: 1px #ccc solid;\n  border-radius: 20px;\n  padding: 5px 10px;\n  margin-top: 10px;\n}\n\n.second {\n  background-color: #6f42c1;\n  color: #fff;\n  font-size: 1.2rem;\n  border: 1px #ccc solid;\n  border-radius: 5px;\n  padding: 5px 10px;\n  margin-top: 10px;\n  margin-left: 10px;\n}\n\n.second::before {\n  content: \"\";\n  position: relative;\n  top: -13px;\n  left: -30px;\n  border-left: 1px solid #aaa;\n  border-bottom: 1px solid #000;\n  border-radius: 0 0 0 0px;\n  height: 26px;\n  width: 50px !important;\n}\n```\n\n\nWhen the CSS position (in .second::before) is set to relative, the width (fixed in pixels) is not considered, only the vertical line is displayed and width is \"forced by the browser\" to 1 pixel.\n\nWhen the CSS position (in .second::before) is set to absolute, the width is not taken into account and the horizontal line is displayed, but the line is not joining the two block. \n\nI already try many combinations of the following options:\n\n\nposition : absolute / relative / static / fixed\ndisplay : block / inline\noverflow : auto / visible;\n\n\nI already look at the following questions :\n\n\nCSS position relative without relative width?\nCSS relative div's width auto extend by absolute div\nCSS relative, absolute positionings\nCSS Make the absolute child width independent from the relative parent width\nHow does css position impact element width/height?\nHow to use CSS position(relative, absolute) with percentage (height, width) dimension?\n\n\nAnd the following article :\n\nhttps://alistapart.com/article/css-positioning-101\n    ", "Answer": "\r\n\nWhen the CSS position (in .second::before) is set to relative, the width (fixed in pixels) is not considered, only the vertical line is displayed and width is \"forced by the browser\" to 1 pixel.\n\nA pseudo element is an inline element by default, setting ```\nposition:relative```\n will not change this thus you cannot apply width and height to the element. Then the borwser is not forcing the width to ```\n1px```\n, it's the border you have set that is equal to ```\n1px```\n. The height also isn't working and the height of the element and the border is defined by the font property.\nIncrease the height and you will see that nothing will change:\n\r\n\r\n```\n.first {\n  background-color: #dc3545;\n  color: #fff;\n  font-size: 1.2rem;\n  border: 1px #ccc solid;\n  border-radius: 20px;\n  padding: 5px 10px;\n  margin-top: 10px;\n}\n\n.second {\n  background-color: #6f42c1;\n  color: #fff;\n  font-size: 1.2rem;\n  border: 1px #ccc solid;\n  border-radius: 5px;\n  padding: 5px 10px;\n  margin-top: 10px;\n  margin-left: 10px;\n}\n\n.second::before {\n  content: \"\";\n  top: -13px;\n  left: -30px;\n  border-left: 1px solid #aaa;\n  border-bottom: 1px solid #000;\n  border-radius: 0 0 0 0px;\n  height: 600px;\n  width: 50px !important;\n}```\n\r\n```\n<span class=\"first\">First</span>\n<span class=\"second\">Second</span>```\n\r\n\r\n\r\n\nNow increase the ```\nfont-size```\n and you will see some changes\n\r\n\r\n```\n.first {\n  background-color: #dc3545;\n  color: #fff;\n  font-size: 1.2rem;\n  border: 1px #ccc solid;\n  border-radius: 20px;\n  padding: 5px 10px;\n  margin-top: 10px;\n}\n\n.second {\n  background-color: #6f42c1;\n  color: #fff;\n  font-size: 1.2rem;\n  border: 1px #ccc solid;\n  border-radius: 5px;\n  padding: 5px 10px;\n  margin-top: 10px;\n  margin-left: 10px;\n}\n\n.second::before {\n  content: \"\";\n  top: -13px;\n  left: -30px;\n  border-left: 1px solid #aaa;\n  border-bottom: 1px solid #000;\n  border-radius: 0 0 0 0px;\n  height: 600px;\n  font-size:50px;\n  width: 50px !important;\n}```\n\r\n```\n<span class=\"first\">First</span>\n<span class=\"second\">Second</span>```\n\r\n\r\n\r\n\n\n\nWhen the CSS position (in .second::before) is set to absolute, the width is not taken into account and the horizontal line is displayed, but the line is not joining the two block.\n\nWhen adding ```\nposition:absolute```\n the element become a block level element thus you can know control its width and height and both are considered in your case but your element is positionned relatively to the viewport since there is no positionned ancestor. It's hidden because you set a negative left value so you cannot see the border you have set.\nYou need to make the span ```\nposition:relative```\n to make the pseudo element positionned relatively to the span:\n\r\n\r\n```\n.first {\n  background-color: #dc3545;\n  color: #fff;\n  font-size: 1.2rem;\n  border: 1px #ccc solid;\n  border-radius: 20px;\n  padding: 5px 10px;\n  margin-top: 10px;\n}\n\n.second {\n  background-color: #6f42c1;\n  color: #fff;\n  font-size: 1.2rem;\n  border: 1px #ccc solid;\n  border-radius: 5px;\n  padding: 5px 10px;\n  margin-top: 10px;\n  margin-left: 10px;\n  position:relative;\n}\n\n.second::before {\n  content: \"\";\n  position: absolute;\n  top: -13px;\n  left: -30px;\n  border-left: 1px solid #aaa;\n  border-bottom: 1px solid #000;\n  border-radius: 0 0 0 0px;\n  height: 26px;\n  width: 50px !important;\n}```\n\r\n```\n<span class=\"first\">First</span>\n<span class=\"second\">Second</span>```\n\r\n\r\n\r\n\n\n\n10.3.1 Inline, non-replaced elements\nThe 'width' property does not apply ref\n\n\n\n10.6.1 Inline, non-replaced elements\nThe 'height' property does not apply. The height of the content area should be based on the font, ref\n\n\n\nFloats, absolutely positioned elements, block containers (such as inline-blocks, table-cells, and table-captions) that are not block boxes, and block boxes with 'overflow' other than 'visible' (except when that value has been propagated to the viewport) establish new block formatting contexts for their contents. ref\n\n\n\nIn the absolute positioning model, a box is explicitly offset with respect to its containing block\nIf the element has ```\n'position: absolute'```\n, the containing block is established by the nearest ancestor with a 'position' of 'absolute', 'relative' or 'fixed', ... If there is no such ancestor, the containing block is the initial containing block. ref\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Concurrent insertions in a Suffix Tree\r\n                \r\nSome time ago I posted a question about saving/retrieving a Suffix Tree from disk. That's finally working fine, but now the construction is extremely slow, and I don't want to mess with the Ukkonen's algorithm (linear construction) right now.\n\nSo, I wanted to make concurrent insertions to accelerate the process without having to make the tree thread-safe.\n\nThe Suffix Tree stores words by its initial character (look the image posted on my previous question), thus, the word Banana is in the 'B' child of the root node, and Apple would be in the 'A' child and so forth. So, the insertion of a word starting with 'B' will never interfere with a insertion starting with 'A'. My idea is to have a thread for each initial character of the set of words being inserted: a thread inserting 'A's, another thread inserting 'B's, etc.\n\nSo I was thinking about a ```\nExecuter```\n class, that just adds words to queue of words of each\n```\nProcess```\n (first create it if it doesn't exists).\n\n```\nclass Executer:\n    #...\n    def concurrent_insertion(word):\n        k = word[0]\n        processes.get(k, Process()).add(word)\n    # ...\n```\n\n\nAnd the class ```\nProcess```\n is the one that makes the insertions. Each ```\nProcess```\n instance is a independent thread, with a ```\nQueue```\n containing the words that still has to insert.\n\nIn this ```\nProcess```\n class is where I'm having troubles, I'm guessing it should inherit from ```\nthreading.Thread```\n, because each instance should be a thread, but how do I keep it alive until all the text processing is done? I mean, it should be inserting words from its ```\nQueue```\n of words, but when the ```\nQueue```\n is empty the thread should not die, just keep waiting till more words fill the ```\nQueue```\n, \"wake up\" and continue inserting.\n    ", "Answer": "\r\nThreads won't die until they exit, so you can keep them alive with a ```\nwhile True```\n loop.  \n\nThe usual pattern looks like this:\n\n```\nq = Queue.Queue()             # word insertion queue\nterminate = object()          # sentinel value to tell a thread to terminate\n\ndef worker(q):\n    while True:\n         word = q.get()       # block until next word is available\n         if word is terminate:\n             break\n         insert_word(word)\n```\n\n\nAfter launching the workers and sending words to the queue, the main thread needs to wait for all the work to be completed and then it should shut down the workers.\n\n```\nfor word in wordlist:\n    q.put(word)\nfor i in range(numthreads):\n    q.put(terminate)          # terminate all the worker threads\nfor t in threadlist:\n    t.join()                  # wait for them all to finish\n```\n\n\nAn alternative way of waiting for all the work to be done is to use ```\nq.task_done```\n and ```\nq.join```\n.  An example for how to use them is shown at the bottom of the page in the docs for the Queue module.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to automatically execute chunks of C++ code (ideally from python)\r\n                \r\nI have ~10k independent and relatively simple .cpp files (let's assume only one 30-line main() function). I want to understand how each of them runs with many different sets of inputs (which they get via ```\ncin```\n). In particular, I want to do the following procedure thousands of times:\n\nPick one of the files\nGive it a set of inputs\nSelect a chunk of lines in the .cpp file\nObtain which variables have changed and from what values to what values.\n\nAlternatively, selecting a line and getting all the values for each declared variable is also good enough for me.\nI'm trying to code this in Python, but I'm open for other languages as well. Looking at related questions and generic googling I've run into libclang (but seems mostly to look at Abstract Syntax Trees at compile time), gdb (may fit the bill, but not sure exactly how), and pybind11 (seems mostly tuned towards integrating one C++ package at a time and not running line by line).\nIn case of multiple alternatives, I care more about ease of code than compute efficiency when running the analysis.\nHow would you approach this task?\n    ", "Answer": "\r\nYou should look into python's ctypes library:\nhttps://docs.python.org/3.8/library/ctypes.html\nYou can compile you C++ code to a shared object (*.so file in linux),\nand then load it into python using the ctypes library (using ```\nctypes.LibraryLoader```\n class).\nI did this in the past and I remember that I needed a small C code that \"glues\" python and C++ (because you need to convert the C data types that python uses into C++ data types).\nThe C \"glue\" file will look something like this:\n```\n#include \"myCppHeader.h\"  // includes prototype for C++ function myCppFunction\n\nextern \"C\" {\n   int callThisFromPython(int intFromPythonCode)\n   {\n          return myCppFunction(intFromPythonCode);\n   }\n}\n```\n\nFrom the python side you will call the ```\ncallThisFromPython```\n function (using ctypes library). And this function will call your C++ function ```\nmyCppFunction```\n and return the results back to python.\nYou can also pass structs from python to C and vice-versa.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Working directory for google test in Visual Studio\r\n                \r\nI have a Visual Studio 2012 C++ solution generated using CMake in which I use google test for unit tests. This works mostly fine, but in one of my tests I want to read a settings file from a local directory. To find the file I copy the file as a post build step from my source code tree to the build and install directory using the following CMake commands:\n\n```\ninstall(FILES ./adapters/settingFile.txt DESTINATION .)\nadd_custom_command(TARGET testAdapters POST_BUILD \n  COMMAND \"${CMAKE_COMMAND}\" -E copy \n     \"${CMAKE_CURRENT_SOURCE_DIR}/adapters/settingFile.txt\"\n     \"${CMAKE_CURRENT_BINARY_DIR}\"\n  COMMENT \"Copying elastix parameter files\")\n```\n\n\nThis works fine: after building my test the settingFile.txt is in the same location as the testAdapters.exe. Using a right click on the testAdapters project and starting a Debug session also works find.\n\nHowever if I choose to run the test from within the \"Test Explorer\" window, either by \"Run All\" or by right clicking the test and choosing \"Run selected tests\", the test cannot find  settingsFile.txt. By right clicking and choosing \"Debug selected tests\" I found that running the test from the \"Test Explorer\" the working directory defaults to the visual studio program directory: ```\nC:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\Common7\\IDE```\n. I can think of several possible solutions, but don't know how to achieve this:\n\n\nSet the working directory for the \"Test Explorer\"\nSet the working directory for each test executable\nSet the working directory for all google tests\nUsing CMake set some define that points to a user specified location and use that in the test code. (I consider this a rather ugly solution)\n\n\nI need a solution that is platform independent. Does anyone know how to achieve (1) or (2) or do you know of a better solution?\n    ", "Answer": "\r\nWith the current version 0.12.3 of GTA you can at least achieve (1):\n\n\nTools\nOptions\nGoogle Test Adapter (or use Search Options)\nGeneral\nWorking directory (at the bottom)\n\n\nUnfortunately GTA seems to only support ```\n$(ExecutableDir)```\n (the default) and ```\n$(SolutionDir)```\n. It seems that GTA cannot tell which project is the unit test project, so it is not possible to use the project directory as a start directory.\n\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Configuration of build.xml file for Sonar modules with Ant\r\n                \r\nI am setting up a Sonar project (using the delphi plugin), for simplicity sake assume there are two modules I want to report on.\n\nEach module is in it's own sub-folder and each has it's own build.xml file.\n\nAt this point I can successfully run the sonar tasks and generate reports for each module as an independent project. \n\nMy problem is with configuring the \"master\" build.xml file.\n\nThe module build.xml file looks like this:\n\n```\n<?xml version=\"1.0\"?>\n<project name = \"CRM\" default = \"sonar\" basedir = \".\">\n    <!-- Add the Sonar task -->\n    <taskdef uri=\"antlib:org.sonar.ant\" resource=\"org/sonar/ant/antlib.xml\">\n        <classpath path=\"c:/ANT/lib\" />\n    </taskdef>\n\n    <target name=\"sonar\">\n        <property name=\"sonar.projectKey\" value=\"EXO:CRM\" />\n        <property name=\"sonar.host.url\" value=\"http://localhost:9000\" />\n        <sonar:sonar workDir=\".\" key=\"CRM.key\" version=\"0.1\" xmlns:sonar=\"antlib:org.sonar.ant\">\n            <property key=\"sonar.sources\" value=\".\" />      <!-- project sources directories (required) -->\n            <property key=\"sonar.language\" value=\"delph\" />                             <!-- project language -->\n            <property key=\"sonar.delphi.codecoverage.excluded\" value=\".\\tests\" />           <!-- code coverage excluded directories -->\n            <property key=\"sonar.importSources\" value=\"true\" />                         <!-- should we show sources or not? -->     \n            <property key=\"sonar.delphi.sources.excluded\" value=\"\" />                       <!-- excluded directories -->\n            <property key=\"sonar.delphi.sources.include\" value=\".\\includes\" />              <!-- include directories, \",\" separated -->\n            <property key=\"sonar.delphi.sources.include.extend\" value=\"true\" />         <!-- should we extend includes in files? -->\n        </sonar:sonar>\n    </target>\n</project>\n```\n\n\nThe \"Master\" build.xml looks like this:\n\n```\n<?xml version=\"1.0\"?>\n<project name = \"EXO\" default = \"sonar\" basedir = \".\">\n    <taskdef uri=\"antlib:org.sonar.ant\" resource=\"org/sonar/ant/antlib.xml\">\n        <classpath path=\"c:/ANT/lib\" />\n    </taskdef>\n\n    <target name=\"sonar\">\n        <property name=\"sonar.modules\" value=\"exonet6000/build.xml,CRM/build.xml\" />\n        <sonar:sonar workDir=\".\" key=\"EXO.key\" version=\"0.1\" xmlns:sonar=\"antlib:org.sonar.ant\">\n            <!-- project sources directories (required) --> \n            <property key=\"sonar.sources\" value=\".\" />      \n            <property key=\"sonar.language\" value=\"delph\" />\n            <property key=\"sonar.importSources\" value=\"true\" /> \n            <property key=\"sonar.delphi.sources.excluded\" value=\"\" />                       \n            <property key=\"sonar.delphi.sources.include\" value=\".\\includes\" />      \n            <property key=\"sonar.delphi.sources.include.extend\" value=\"true\" />         \n        </sonar:sonar>\n    </target>\n</project>\n```\n\n\nIt is always scanning all sources (required value) i.e. it is not respecting my modules.\nThe only way I can get this to work currently is by limiting the source code like this\n\n```\n<property key=\"sonar.sources\" value=\"./crm/,./exonet6000/\" />   \n```\n\n\nI'm sure I must be mis-configuring something obvious here.\n\nEDIT: I have now what I believe is a more consistent set of files based on examples here https://github.com/SonarSource/sonar-examples/tree/master/projects/languages/java/java-ant-modules \n\nMaster build file:\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project name = \"EXO\" default = \"sonar\" basedir = \".\" xmlns:sonar=\"antlib:org.sonar.ant\">\n    <echo>Root Project</echo>\n\n    <taskdef uri=\"antlib:org.sonar.ant\" resource=\"org/sonar/ant/antlib.xml\">\n        <classpath path=\"c:/ANT/lib\" />\n    </taskdef>\n\n    <property name=\"sonar.host.url\" value=\"http://localhost:9000\" />\n    <property name=\"sonar.modules\" value=\"exonet6000/build.xml,CRM/build.xml\" />\n\n    <target name=\"sonar\">\n        <sonar:sonar key=\"EXO.key\" version=\"0.1\">   \n        </sonar:sonar>\n    </target>\n</project>\n```\n\n\nand one of the submodule files\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project name=\"CRM\" default=\"all\" basedir=\".\">\n    <echo>CRM Module</echo>\n\n    <property name=\"sonar.language\" value=\"delph\" />\n    <property name=\"sonar.projectKey\" value=\"EXO:CRM\" />\n    <property name=\"sonar.sources\" value=\".\" /> \n\n    <target name=\"all\" />\n</project>\n```\n\n\nAt this point the sonar process is completing successfully BUT no actual anlysis is being done. A key point is that I am not seeing the echo of the submodule so I suspect these build tasks are not actually running.\n    ", "Answer": "\r\nIf you look at this sample project using Ant and multimodules, I'd say that you should not specify any property inside the  tag in your master build.xml file, and let the submodules specify those properties.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to ask for to do something in the child component from the parent component in React.js\r\n                \r\nI have one question about the react-way. \n\nI have two components. For example: App & Browser.\n\n\nApp is a general component. It loads inner modules and renders application tree-structure\nBrowser is an inner-component of App. It shows some fetched data by its ID.\n\n\nApp-component doesn't matter about ID and data what currently rendered in Browser-component. App doesn't want to control browser-component's navigation. Browser is mostly independent.\n\nBut sometimes App wanna do one of it:\n\n\nAsk Browser-component for refresh (fetch data again + render it) active page\nAsk Browser-component to load particular ID\n\n\nI don't understand how I can do it using react-way with props.\n\nSome code for example:\n\n```\nclass App extends Component {\n  render(){\n    return ... <Browser server={this.server}/> ...;\n  }\n}\n\nclass Browser extends Component {\n  constructor(props){\n     super(props);\n     this.state = { id: 'default' };\n  }\n\n  componentDidMound() { this.checkData(); }\n  componentWillUpdate() { this.checkData(); }\n\n  async checkData(){\n      if(!this.state.data}{\n          const data = await this.props.server.fetch(this.state.id);\n          this.setState({ data });\n      }\n  }\n\n  onChange(newId){\n     this.setState({ data: null, id: newId });\n  }\n\n  render(){\n    return <div>\n        <Page data={this.state.data}/>\n        <Navigation activeId={this.state.id} onChange={::this.onChange}/>\n    </div>;\n  }\n}\n```\n\n\nI have some bad idea's. Example:\n\n\nI can set Browser to App by ref-attribute. And directly run needed methods\nI can use global variables\nI can provide empty {}-object into Browser-component. In initialization in browser-component set all needed methods into this object. Finally run it from App\n\n\nI think all this variants isn't react-way. How I can do it right? \nI don't use redux in this project. Just react.\n    ", "Answer": "\r\nI found one interesting decision. I can pass observer-method into child components. Example:\n\n```\nclass App extends Component {\n    constructor(props){\n        super(props);\n        this.subscribers = [];\n    }\n\n    subscribe = id => { this.subscribers.push(id); }\n\n    anyMethod(){\n        // ...\n        for(let fn of this.subscribers)\n            fn(newId);\n        // ...\n    }\n\n    render(){\n        return <div>...<Browser subscribe={this.subscribe} />...</div>\n    }\n}\n\nclass Browser extends Component {\n    constructor(props){\n        super(props);\n        props.subscribe(id => { this.forceLoad(id); })\n    }\n}\n```\n\n\nIt's like API for inner component gained from Parent component :)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How could I use repo-specific VIM undo directories (undodir) without revealing my path structure to everyone who clones the repo?\r\n                \r\nI recently discovered VIM's persistent undo feature and I'm loving it because it allows me to go back and fine-tune my git commits if desired.\n\nCurrently, all my VIM undo files are simply created alongside each edited file. This works fine, but it litters the source tree. It looks unprofessional and disorganized.\n\nSo I came across a setting to use in my local (project-specific) ```\n.vimrc```\n that allows me to store all undo files in a directory relative to the working directory. This would be perfect except for the way VIM then chooses to name these files - which is to use the full path to create the file name in order to ensure uniqueness. Clearly this feature was intended for specifying a directory such as ```\n~/.vimundo```\n to keep the undo files of multiple projects. However, that's not how I want to use it. I want it on a per-project basis without having to worry about the rest of the system.\n\n.vimrc:\n\n\n```\nset undodir=./.vimundo/\nset undofile\n```\n\n\n\n\nThat results in something like this being created inside my project's ```\n./.vimundo```\n directory for each edited file in my project (this one is for my project's ```\n.vimrc```\n):\n\n```\n%home%douglas%Projects%auto_gen_projects%cmake_project_files%.vimrc```\n\n\nThat's nearly perfect except I want the filename to be created from the relative path. I might want to reorganize my projects without losing or having to rename the undo files. Additionally, I don't want strangers to have knowledge of my personal file structure when I push the repo.\n\nIs there an effective way to separate undo files from the source tree without the obligation VIM creates from the way it chooses to name files when setting the ```\nundodir```\n option?\n\nOr is there a better way for accomplishing what I want, which is simply to use project-specific, location-independent undo files that don't offend the presentation of my source tree while still keeping them in the repo?\n    ", "Answer": "\r\nI strongly recommend to use Git (private branches, stashes, or something like that - Git is very accommodating here) to be able to \"go back and fine-tune my commits\"? That would make far more sense to me; I see undo as short-term and ephemeral, and Git as long-term and permanent.\n\nI had commented that already, and after your confirmation, I think I've found what at least for me would amount to a shopstopper: Vim's undo tracks all changes, with no possibility to edit those. Now imagine you accidentally paste a password, or access token, or URL of an adult website into Vim (I do that all the time - the accidental pasting, that is), immediately undo that, but it would still be accessible through your persistent undo (as Vim does not only keep a sequential history, but the full branches). You'd have to explicitly clean the undo history (```\n:set ul=-1```\n), or hope that enough (1000 by default) further edits happen so that the change gets evicted from history prior to committing them.\n\nOnce committed to Git (and pushed to a public location like GitHub), the changes are basically a public record, and hard if not impossible to get rid of again. Though the possibility of an actual \"attack\" against you is small, I would not use such a process.\n\nAlternatives\n\nIf you don't want to store your intermediate changes as Git artifacts, there are other possibilities to store certain versions for some time. For example, my writebackup plugin provides a lightweight versioning system that does not interfere with Git at all (you can store the backups outside the working copy, or git-ignore the backup files or a dedicated backup dir that collects all backups from inside the working copy).\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "define animations and triggers as reusable resource?\r\n                \r\nIs there a way to define an animation somewhere in xaml (eg. as a resource) once and then reuse it multiple times? I have a lot of independent brushes across differnt datatemplates that independently need to start the same kind of animation based on a datatrigger. Now since it seems that an animation has to define an Storyboard.TargetName and  Storyboard.TargetProperty. This pretty much defeats the purpose of reusability. I would somehow like to declare \"use this animation form the resource but apply it to another element this time\". \n\nTo me this seems to be a rather basic, important and essential request and I am suprised that its not that straight forward to acomplish. Am I missing something here?\n\nThe same thing applies for triggers. Suppose I have a lot of differnt visual elements that all represent the same type of state using color animations. E.g.  fade to green when \"active\" fade to \"red\" when \"error\" etc. The only difference between the visuals is their shape/visual tree the desired animation behavior is the same, they all have an element somewhere in their visual tree that has a property of type color. I think it is not hard to imagine how tedious it is to redefine the same animations and datatrigger sets over and over again. Every developer hates this. I desperately seek for an easier solution that doesn't require no (or at least very little) c# code behind.\n\nWhat I have come up with so far is this:\n\nDefine the animations in a resource lik this (repeat this for all basic states that there are, like activating, active, inactive, error):\n\n```\n<ColorAnimationUsingKeyFrames x:Key=\"deactivatingColorAnimation\" \n                    Storyboard.TargetProperty=\"Material.(MaterialGroup.Children)[0].Brush.(SolidColorBrush.Color)\"                    \n                    FillBehavior=\"HoldEnd\" RepeatBehavior=\"Forever\" AutoReverse=\"True\">\n      <ColorAnimationUsingKeyFrames.KeyFrames>\n        <LinearColorKeyFrame KeyTime=\"00:00:00\" Value=\"Gray\"/>\n        <LinearColorKeyFrame KeyTime=\"00:00:0.25\" Value=\"Gray\"/>\n        <LinearColorKeyFrame KeyTime=\"00:00:0.5\" Value=\"Gray\" />\n        <LinearColorKeyFrame KeyTime=\"00:00:0.75\" Value=\"Gray\" />\n     </ColorAnimationUsingKeyFrames.KeyFrames>\n</ColorAnimationUsingKeyFrames>\n```\n\n\nThe use it in storyboard in the triggers (repeat this zillions of times for each state X each differnt stateviusal, always come up with a new name for the storyboard):\n\n```\n<DataTrigger Binding=\"{Binding SubstrateHolder.State}\" Value=\"Deactivating\">\n        <DataTrigger.EnterActions>\n            <BeginStoryboard x:Name=\"someStateVisualDeactivatingStoryboard\">\n                <Storyboard Storyboard.TargetName=\"someStateVisual\">\n                    <StaticResource ResourceKey=\"deactivatingColorAnimation\" />\n                </Storyboard>\n            </BeginStoryboard>\n        </DataTrigger.EnterActions>\n        <DataTrigger.ExitActions>\n            <RemoveStoryboard BeginStoryboardName=\"someStateVisualDeactivatingStoryboard\" />\n        </DataTrigger.ExitActions>\n</DataTrigger>\n```\n\n\nYou can easily imagine how much bloat XAML I have to repeatedly copy and paste for all those zillion DataTriggers. \n\nIt would be cool to define all this triggers once and apply it to different state visuals. How is something like this solved in WPF? Any tip?\n    ", "Answer": "\r\nCould you try something like this?  \n\n\nWrap all your current control templates with an invisible root element, e.g. a Border or a StackPanel, whose bounding box will cover the entire control.\nCreate a style or control template for this invisible box that contains all your triggers and animations.  \nHave the animations animate an arbitrary Color property on the invisible box.\nIn the visual trees for all your different controls, bind any properties you want to animate to the Color property on the invisible root element. \n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Automatic minimum width for column '#0' in tkinter.TreeView\r\n                \r\nThe ```\ntkinter.TreeView```\n has a first default column (identifier ```\n#0```\n). For example this is for holding the '+' sing of the tree.\n\nWhen I add other columns this first column is resized and much to wide.\n\n\n\nThis is the code producing this treeview.\n\n```\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nfrom tkinter import *\nfrom tkinter import ttk\n\nroot = Tk()\n\ntree = ttk.Treeview(root, columns=('one'))\nidx = tree.insert(parent='', index=END, values=('AAA'))\ntree.insert(parent=idx, index=END, values=('child'))\n\ntree.column('#0', stretch=False)  # NO effect!\n\ntree.pack()\nroot.mainloop()\n```\n\n\nI would like to have the first column (```\n#0```\n) in a minimum fixed width depending on the + sign in there. The point is that the width for that column differs from system to system because of different desktop environments and user settings. So it would break the plattform independence of Python3 and Tkinter when I would set a fixed size in pixel here.\n    ", "Answer": "\r\nOn windows that expand / collapse button seems to be dynamically drawn based on the size, and according to this ```\nminwidth```\n option defaults to 20. I'd write a method to calculate ```\nminwidth```\n such that it accounts for the depth and image and text width + 20.\n\nThat being said, using this answer a method can be written for fixing the column width at the ```\nminwidth```\n Tk defaults to, by breaking the tagbind at that exact location:\n\n```\n#the minimum width default that Tk assigns\nminwidth = tree.column('#0', option='minwidth')\n\ntree.column('#0', width=minwidth)\n\n#disabling resizing for '#0' column particularly\ndef handle_click(event):\n    if tree.identify_region(event.x, event.y) == \"separator\":\n        if tree.identify_column(event.x) == '#0':\n            return \"break\"\n\n#to have drag drop to have no effect\ntree.bind('<Button-1>', handle_click)\n#further disabling the double edged arrow display\ntree.bind('<Motion>', handle_click)\n```\n\n\n\n\nAnd a complete example:\n\n```\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nfrom tkinter import *\nfrom tkinter import ttk\n\nroot = Tk()\n\ntree = ttk.Treeview(root, columns=('one'))\nidx = tree.insert(parent='', index=END, values=('AAA'))\ntree.insert(parent=idx, index=END, values=('child'))\n\ntree.column('#0', stretch=False)  # NO effect!\n\n#the minimum width default that Tk assigns\nminwidth = tree.column('#0', option='minwidth')\n\ntree.column('#0', width=minwidth)\n\n#disabling resizing for '#0' column particularly\ndef handle_click(event):\n    if tree.identify_region(event.x, event.y) == \"separator\":\n        if tree.identify_column(event.x) == '#0':\n            return \"break\"\n\n#to have drag drop to have no effect\ntree.bind('<Button-1>', handle_click)\n#further disabling the double edged arrow display\ntree.bind('<Motion>', handle_click)\n\ntree.pack()\nroot.mainloop()\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Breaking a large rails app into smaller apps? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                As it currently stands, this question is not a good fit for our Q&A format. We expect answers to be supported by facts, references,  or expertise, but this question will likely solicit debate, arguments, polling, or extended discussion. If you feel that this question  can be improved and possibly reopened, visit the help center for guidance.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 10 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI have a Rails app with 600 models and that will soon grow to 800-1000. I'd like to segment the rails app so that only certain models get loaded and therefore act as a separate app, but all share the same base models. Is there a standard practice for doing this?\n\nEDIT: I am on 2.3.8\n\nEDIT 2:\n\nThe problem is that many models are similar, but different just enough that it warrants writing a new class, i.e. the logic required to put it all in one model would be horrendous. Some of the models could be moved out into rake tasks or the lib directory, but only about 30 or so. Some are abstract classes that act as parents of one arm of the model tree. However, most relate to database tables. I am thinking about at deploy time segmenting parts of the app into plugins via Engines so that one app can only handle one set of models (they are independent) but so that I can keep them all together in development and in one git repo for convenience. I\"m going to go down this route unless someone else has a better idea, and I'll post back to let you know how it goes. \n    ", "Answer": "\r\nDude, thats a pretty insane amount of models... anyways for handling complex logic and easily reuse them across other projects I would recommend to you the engines (from 2.3+ is part of Rails).\n\nWith that in place you can split your model in different modules (engines)\n\nhttp://railscasts.com/episodes/149-rails-engines\n\nToño\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Can a data structure have O(1) access time without using any arrays?\r\n                \r\nI'm taking an introductory CS class, and one of the first projects had the following constraints:\n\nYou may NOT:\n\nMake your program part of a package.\nAdd additional public methods or variables.\nUse any built in Java Collections Framework classes anywhere in your program (e.g. no ```\nArrayList```\n, ```\nLinkedList```\n, ```\nHashSet```\n, etc.).\nUse any arrays anywhere in your program.\nAdd any additional ```\nimport```\n statements (or use the “fully qualified name” to get around adding ```\nimport```\n statements).\n\n\nSeeing the constraints for that project made me wonder what other things one could actually do within those constraints. The main limitation that I saw was the \"no arrays\" clause.\nIs it possible to design a data structure subject to these constraints, which emulates the performance characteristics of an array? Specifically, the data structure should represent a sequence of fixed length, supporting operations to \"get\" or \"set\" by index, and these operations should take O(1) time, independent of the length of the sequence.\nWhile it would be possible to build graph-like structures, like linked lists and trees, the \"get\" and \"set\" operations on these data structures would take O(n) or O(log n) time respectively. The only other thing I can think of is a class with a few thousand private fields and a ```\nswitch```\n statement to \"get\" or \"set\" by index, but this would only work for sequences up to a fixed length.\n    ", "Answer": "\r\nI think if you're following the spirit of the rules, then you provably can't do better than O(log n) time to get or set an element. The reason for this is that every object you instantiate can store at most a fixed number of data items and a fixed number of references to other objects, defined by how many fields that object has.\n\nLet D be the (maximum) number of data items an object holds, and F be the (maximum) number of reference fields an object holds. To be clear, D counts the fields used to store the actual \"array\" data, and F counts the fields which are used for the data structure itself.\n\nIf your access times are O(1) then you can follow at most O(1) references to access the cell, which means your \"array\" size is limited to O(D * F^R) where R is a fixed limit on the number of references you're allowed to follow to fulfil one operation. If all three of D, F and R are constant, then so is the size of your \"array\". It follows that emulating the performance characteristics of an arbitrary-sized array data structure is impossible given the constraints.\n\nThis argument can be extended a little bit further to prove that R must be at least O(log n) in order to reach n distinct data items; i.e. that you must follow at least O(log n) references to access an item. You can use a complete binary tree to actually achieve this bound.\n\n\n\nThat said, there is at least one way to follow the letter of the rules without following the spirit of them.\n\nYou are strictly forbidden from using arrays or JCF library classes, but the only rules about third-party library classes are that you aren't allowed to import them or refer to them by a fully-qualified name. You could use the ```\nClassLoader.loadClass```\n method to load a collection class from a third-party library, instantiate it by reflection, assign it to a variable of type ```\nObject```\n, and then call its methods by reflection. This is technically allowed because ```\nloadClass```\n takes the \"binary name\", not the \"fully qualified name\" of the class you want to load. (I'll leave it to the lawyers to argue whether you would need to load a class whose binary name isn't also a fully qualified name.)\n\nFor the pedants: I interpret the rule about arrays as saying you must have no arrays in your code (except, presumably, ```\nString[] args```\n in the main method), not no arrays in other people's code that your code calls; otherwise e.g. your program is forbidden from printing any output because data written to ```\nSystem.out```\n gets buffered in an array. I think it is unlikely the rule is intended to forbid printing any output.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Fixing Git History after Fetching Wrong Repo\r\n                \r\nI made a mistake setting up a remote on my git repo and fetched from a totally different project.\n\nFortunately, there was no merge, but I now have the history of 2 projects floating around in my repo and I'm trying to figure out how to get my repo back to the state it was in before I made the erroneous fetch.\n\nI've been reading about ```\nreflog```\n, ```\nrebase```\n, ```\ngc```\n and other commands trying to work out which will help me get rid of the stuff I accidentally fetched, but so far haven't got any where.\n\nIt looks like I've got the history of both projects in my repo, but they're totally independent. There are essentially 2 separate trees of commits running in parallel to each other, in fact, this is what I see in ```\ngitk```\n when looking at all branches:\n\n\n\nYou can see that the commits in the middle are not connected to the commits at the beginning and end of the history. Date-wise, they're interleaved, but ```\ngitk```\n doesn't show them interleaved for some reason.\n\nThe isolated commits (in the middle of the pic) are the ones I'm trying to rid myself of, and they don't appear to be attached to any branch. There's no route from any of the HEADs in my repo back to this set of commits.\n\nSo far I've tried (in order in case it makes a difference):\n\n```\ngit remote prune\ngit prune\ngit gc\ngit gc --aggressive --prune=tomorrow\ngit remote update --prune\ngit fetch --all\n```\n\n\nBut nothing has helped yet. Can anyone suggest how I can remove these commits from my repo?\n    ", "Answer": "\r\nYou just need to remove the dangling tag (```\n0.1.something```\n, where ```\nsomething```\n isn't visible in your screenshot) using ```\ngit tag -d 0.1.something```\n. Once this is done, the commits will be gc-able.\n\nAs long as there is a tag that reaches a commit, this commit is considered reachable and will thus persist \"forever\", it's effectively immune to garbage-collection until you remove any refs that point to it (branches, tags, other refs, ...)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How many queues does the linux scheduler use?\r\n                \r\nGiven the following\n\n```\nSCHED_OTHER```\n scheduling policy for all threads\nAll threads are non realtime (```\nsched_priority```\n is 0)\n```\nCONFIG_FAIR_GROUP_SCHED```\n is enabled\nautogrouping is enabled.\nThere are two linux sessions each constituting a process group.\n\nScenario 1: CPU affinities are not set so all threads across both process groups fight over the same cores. Processes in both process groups are single threaded.\nThis is my understanding of how the linux scheduler will deal with scenario 1:\nThreads that are in the same process group will be put in the same task group. Since linux is a CFS scheduler it will ensure that both process groups get roughly equal time on the common cores. The nice value will ONLY affect scheduling order within the same task group. The scheduling order within a task group is determined by the nice value and how much time the thread has spent away from the cores.\nQuestion 1: Does linux maintain a red black tree for every task group? so in this case it will have 2?\nQuestion 2: Since the nice value does not affect scheduling order across a task group then is there a separate queue to determine which task group's red black tree to traverse to get the next thread to be scheduled from?\nQuestion 3: Is it possible to set an inter process group nice value type parameter that will make sure that most of the time one process group is prioritized over another?\nScenario 2: Same as scenario 1 but now all the processes are multithreaded.\nQuestion 4: If the processes are multithreaded then does the linux scheduler maintain another priority queue per process (on top of the one for the processes within a process group) for finding the order of scheduling the threads spawned by a particular process (inter thread scheduling order for every process)? or will all the threads spawned by processes within the same process group get treated like independent tasks and added to the priority queue for the task group?\nScenario 3: Same as scenario 2 but now every single process gets a non overlapping cpu affinity.\nQuestion 5: In this case how do the task groups that were created for every process group make sense anymore? Now threads within every process fight over cpus but threads across processes and across process groups do not fight over cores anymore. How does the CFS scheduler modify task groups? It does not make sense to have a red black tree for a process group anymore.\nQuestion 6: Does each logical cpu get its own queue independent of the scheduler?\nI would expect it to have a priority queue that determines the order of each task group (process group), and another priority queue to determine the order of tasks (processes) within a task group and a final priority queue for threads within a task (process).\nNot sure how the task groups change with cpu affinities.\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "SpriteKit: Determine drawing order for hit test\r\n                \r\ni am using Spritekit and want to have a hit test, that works intuitive.\nIn other words: I got a position x,y and want to to find out which is the top most node that was hit. (And with \"top most\" i mean the one that the user actually sees as topmost.)\n\nI did not find any predefined functionality of SpriteKit that gives me this functionality.\nActually i found that SpriteKit itself uses some counter intuitive hit testing, see here.\n\nMy idea to implement this by myself is to calculate some global z ordering, like described in the answer here, by Dobroćudni Tapir.\n\nI think this may work, what confuses me is the statement in the documentation:\n\n\n  Important: The SKCropNode and SKEffectNode node classes alter the scene rendering behavior. The children of these nodes are rendered independently as a separate node tree, and the results are rendered into the tree that contains the crop or effect node. For more information, see Working with Other Node Types.\n\n\nTo find here, beneath \"Understanding the Drawing Order for a Node Tree\".\n\nI did not find the referred \"Working with Other Node Types\" point, so i have no idea how and why SKCropNodes or SKEffectNodes should change the drawing order ... \n\nSo answers to the following questions could help me:\n\n\nDoes SpriteKit offer some functionality to retrieve the drawing oder?\nIf not, do you think that my custom implementation work? (How could Crop or Effect nodes destroy it?)\nCould you point me to information regarding this question? Like the missing \"Working with other nodes\" article?\n\n\nUpdate:\n\nI just found out that the behaviour reported here is not correct.\n\nAs mentioned in the comments i was pointed to nodeAtPosition or nodesAtPosition. I used the code in here and tested it.\n\nThe result is not satisfying. Two problems:\n\n\nThe set zPosition is ignored in nodesAtPosition. Independent if blue or red square is in front i get the same order in the array returned in nodesAtPosition. \nThese functions use the accumulated frame. But in a prefect case i would like to use the exact size of each node and not the accumulated frame.\n\n\nSome pictures to 1. :\n\n\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Python/Graphs: finding all combinations of paths of certain length that connect all nodes\r\n                \r\nProblem definition\n\nI've got a connected, undirected graph with n nodes and root r. I need to find all combinations of paths with a length in range(l) that connect all the nodes.\n\nIn the end I want to find the optimal combination of paths, where the weight of the edge is determined by both the length and its location in the sequence. \n\nI've tried some solution directions, but end up with so many options that it becomes a computational nightmare.\nIn my case, n = 35, all nodes have degree 8 to 10 and path length should be 7 or 8.\n\nI'm using Python 3.5.\n\nPossible solutions\n\nIn all cases I start with defining all possible paths. Therefor I use a solution with the NetworkX package as found here:\nAll paths of length L from node n using python \n\n```\n# Create a random graph that looks like the real one\nG = nx.dense_gnm_random_graph(n=35, m=164, seed=0)\n\n# Find all paths from root with length 0 to 8\nn = 0\nL = 8\nno_n_node = G.nodes()\nno_n_node.remove(n)\nresult = []\n\nfor paths in (nx.all_simple_paths(G=G, source=n, target=target, cutoff=L) for target in no_n_node):\n    result+=paths\n\n# Only keep paths of length 7 or 8\nres78 = []\nfor path in result:\n    if len(path) >= 8:\n        res78.append(path[1:])\n```\n\n\nThis results in 24,383,690 paths, reduced to 'only' 3,181,622 collections of 7 or 8 points (order of nodes in path neglected)\n\n\n\nThis is where I get stuck, as I now want to find all combinations of the found paths that visit all nodes, but all only once.\n\nHow to proceed, option 1\n\nMy first idea was to brute force:\n- for all unique paths, remove nodes from graph \n- compute all paths of length in range(l) in remaining graph\n- etc\nBut this are way too many computations\n\nHow to proceed, option 2\n\nThe other idea I had was to find, independent of their connections, all possible combinations of nodes that combined contain all nodes once (the spanning set).\nHow to compute a spanning set, I based on Algorithm to generate (not quite) spanning set in Python\n\n```\ndata = G.nodes()\ndata.remove[0]\n\nfrom itertools import combinations\n\ndef cut(lst, indexes):\n    last = 0\n    for i in indexes:\n        yield tuple(lst[last:i])\n        last = i\n    yield tuple(lst[last:])\n\ndef generate(lst, n):\n    for indexes in combinations(tuple(range(1,len(lst))), n - 1):\n        yield (tuple(cut(lst, indexes)))\n```\n\n\nThis results in a list of 2^n. I tried to make a spanning set with only sub_sets of length 7 or 8, but didn't know how to do it.\n\nI guess it's still computational too heavy, but what I then wanted to do is:\n- get out of the spanning sets, only the ones that contain only collections that also can be found in the paths\n- for all this subset, find the shortest path in the collection, starting from the root (traveling salesman problem)\n\nedit/addition\n\nDifferent direction\n\nAn other direction I thought about after a nights sleep, is to find all the spanning trees, only keep the one that don't have sub-branches and only have branches of certain length.\nRemaining question: how to find all spanning trees? \nI found How to efficiently generate all possible spanning trees from a graph that might get me started.\n\nend of edit\n\nDoes anyone have suggestions on how to optimize the algorithms I use or know a function in NetworkX that I missed but will make it all somewhat easier?\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Entity Framework 4.0: when I try to save some changes with unique constraint I get an exception\r\n                \r\nWell, I am trying to save a tree in a database, so I am using the modified preorder tree traversal method.\n\nI have a table with the following columns:\n\n```\nIDNode\nIDRootNode\nIDParentNode\nLeft\nRight\n```\n\n\nIn my table, I have two unique constraints, ```\n(IDRoot, Left)```\n and ```\n(IDRoot, right)```\n because in a tree, there is not possible to have two nodes with the same root and the same left, or the same root and the same right. This is the reason to use this two constraints.\n\nWell, now, I have a tree with three nodes:\n\n```\nNode A\nIDNode = 1\nIDRootNode = 1\nIDParentNode = 1\nLeft = 1\nRight = 6\n\nNode B\nIDNode = 2\nIDRootNode = 1\nIDParentNode = 1\nLeft = 2\nRight = 3\n\nNode C\nIDNode = 3\nIDRootNode = 1\nIDParentNode = 1\nLeft = 4\nRight = 5\n```\n\n\nNow I am trying to add a new child in the B node. So with some operations, before save changes in the database, I get the following state of the nodes:\n\n```\nNode A\nIDNode = 1\nIDRootNode = 1\nIDParentNode = 1\nLeft = 1\nRight = 8\n\nNode B\nIDNode = 2\nIDRootNode = 1\nIDParentNode = 1\nLeft = 2\nRight = 5\n\nNode C\nIDNode = 3\nIDRootNode = 1\nIDParentNode = 1\nLeft = 6\nRight = 7\n\n\nNew node D\nIDNode = 3\nIDRootNode = 1\nIDParentNode = 2\nLeft = 3\nRight = 4\n```\n\n\nThis is the correct data for all the nodes, but when I submit the changes, I get a Unique Key exception, because I am trying to modify the left/right values.\n\nThe problem is with the node B, I am trying to set the right field to 5, but this value is assigned to the node C in the database.\n\nSo it makes me think that when EF makes changes, it apply the changes to the current register and compare the data with the information in the  database, not with the information of the entities in the context. So when I try to update the node B, It does not take account of the entity value but the value in the database, so how in the database the node C has a value of 5 in the right field, SQL Server throw an error because of the unique constraint. If EF would take account of the entity data, in which the node C has a 7 value, there would not be problems.\n\nIf I delete the constraint in the database, the all works fine and the data is coherent, but then I would design the database according to the use of EF, and the design would be independent of the data access technology.\n\nAm I right? is it possible with EF to make changes that take in account other possible changes in other entities?\n\nThanks.\nDaimroc.\n    ", "Answer": "\r\nWhat you show in your example doesn't look like a tree at all. Let's check your modified sample:\n\n\nNode A has ID = 1, RootID = 1 and ParentID = 1. How can a root node have a parent? ParentID should be NULL.\nNode A has LeftID = 1. So it is pointing to itself? What kind of tree is that? Even in threaded tree nodes usually doesn't point to itself.\nNode B has ParentID = 1 but Node A has neither LeftID = 2 or RightID = 2. How can Node A be direct parent of Node B when Node B is not direct child of Node A?\nAnd many more similar issues\nBtw. how do you model leafs or incomplete nodes (node where LeftID = NULL or RightID = NULL) with your unique constraints? Those constrains say that there can be only single node having LeftID = NULL and single node having RightID = NULL\n\n\nNow to the problem with EF. EF doesn't understand unique constraints. EF also doesn't perform any additional queries to database to check the state. All queries are executed by you (even lazy loading is executed by your code). \n\nWhat you found is most probably problem of incorrect order of update commands executed in the database where EF is trying to update Node B before it updates Node C. Order of EF updates is driven by relationships in your database but bidirectional relationship can cause that EF is not able to select correct order of the commands. In such case it usually throws exception so it leads me to suspicion that you don't have tree structure modeled on table with self referencing relationships. In such case EF will not be able to assign correct command order.\n\nI expect that in this case you will have to write updates manually to perform the update.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Ideal classifiers in python to fit sparse high dimensional features (with hierarchical classification)\r\n                \r\nThis is my task:\n\nI have a set of hierarchical classes (ex. \"object/architecture/building/residential building/house/farmhouse\")--and I've written two ways of classifying:\n\n\ntreating each class independently (using one model/classifier overall)\nusing a tree where each node represents a decision (the root represents \"object/\", and each level decreases generality), and a specific model/classifier for each node (here, I consider the c (usually 3) highest probabilities that come out of each node, and propagate the probabilities down (summing the log probs) to the leaves), and choose the highest.\n\nI also had to introduce a way to incentivize going further down the tree (as it could stop at say object/architecture/building (if there is the corresponding training data)), and used an arbitrary trial-and-error process to decide specifically how (I don't feel comfortable with this).:\n\n```\n    if numcategories == 4:\n        tempscore +=1\n    elif numcategories ==5:\n        tempscore +=1.3\n    elif numcategories ==6:\n        tempscore +=1.5\n    elif numcategories >6:\n        tempscore +=2\n```\n\n\n\n\n\nIt is also important to note that I have around 290k training samples and ~150k (currently/mostly) boolean features (represented with 1.0 or 0.0)--although it's highly sparse, so I use scipy's sparse matrices. Also, there are ~6500 independent classes (though many less for each node in method 2)\n\nWith method 1, with scikit's ```\nsgdclassifier(loss=hinge)```\n, I get around 75-76% accuracy, and with linearsvc, I get around 76-77% (although it's 8-9 times slower). \n\nHowever, for the second method (which I think can/should ultimately perform better) neither of these classifiers produce true probabilities, and while I've attempted to scale the confidence scores produced by their ```\n.decision_functions()```\n, it didn't work well (accuracies of 10-25%). Thus, I switched to ```\nlogisticregression()```\n, which gets me ~62-63% accuracy. Also, NB based classifiers seem to perform substantially less well.\n\nUltimately, I have twoish questions:\n\n\nIs there a better classifier (than scikit's ```\nlogisticregression()```\n) around implemented in python (could be scikit or mlpy/nltk/orange/etc) that can (i) handle sparse matrices, (ii) produce (something close to) probabilities, and (iii) work with multiclass classification?\nIs there some way to handle method two better?\n2.a. Specifically, is there some way to better handle incentivizing the classifier to produce results further down the tree?\n\n    ", "Answer": "\r\nA few ideas you could try:\n\n\nApply some embedding technique on your features, so as to avoid a large sparse matrix. However, it doesn't fit every case and also requires a lot of work\nUse XGBoost with a custom loss function. In this loss function you can basically apply the logic you've described regarding the depth of the predicted class and provide an incentive for the model to get deeper classes predicted more often. In addition, a tree-based model will benefit you by taking into consideration the correlations between your features\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "TFS Build -- Get parts of the source code using different labels\r\n                \r\nI'm migrating a homegrown build system to TFS Build and there are some unique challenges with getting the source code.  Originally the code was kept in VSS and to allow the various tiers of the code to be independent, each tier had its own label.  A text file had five labels that represented what was needed to make a final build and this file was under the \"master label\".  At build time the file was read each tier was retrieved from VSS using its specific label and the whole source code tree built.\n\nHow can I can get the source in different folders under individual labels and assemble the source code for a full build?\n\nI've looked in the default template to see how the code is retrieved but it's not clear if I can use a different label for each Source Settings entry as the code is retrieved.\n\nAnother idea I had was to call sub templates from a master template but that really seemed like overkill.\n\nIn TFS Build, I see the general idea is to let the build apply a label to all the source code and then get under that label.  I also see that I can specify a label in the Build Process part of the default template.\n    ", "Answer": "\r\nTeam Build assumes that everything will be under one label. But that label can contain folders at different versions, so instead of your \"Master text file\" you could create a Master Label that contains all the files at different versions. This is a very uncommon practice but it should work:\n\n```\ntf label MasterLabel $/Project/FolderA /recursive /version:c1\ntf label MasterLabel $/Project/FolderB /recursive /version:c50\ntf label MasterLabel $/Project/FolderC /recursive /version:c100\n```\n\n\nAs long as the path you're applying the label to, does not overlap, it should work.\n\nTo get the sources, use:\n\n```\ntf get /resursive /version:LMasterLabel\n```\n\n\nA better way to do it, would be to either package the application using NuGet packages and use a NuGet server for dependency management, or to indeed create multiple build definitions with an optional master definition that \"grabs\" all the outputs of the individual builds. That's basically what the Lab Management Template does as well.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Self referential structs for trees in C99\r\n                \r\nI am attempting to produce a hierarchical tree from textual data using C99. My aim is to ultimately render a diagram akin to the following parse tree.\n\nI am familiar with the concept of a linked list, but less so with its implementation in C as I come from a Java background. I am attempting to implement a tree data structure, which should not be substantially more complicated than a linked list.\nI am trying to create a dynamic array list whose size may be updated as the number of child nodes changes. I have independently tested my code for this section (after replacing ```\nstruct node*```\n with ```\nint*```\n).\n```\ntypedef struct {\n  struct node* array;\n  int used;\n  int size;\n} node_array;\n```\n\nNext, I wish to define a struct to house the node itself and pointers to its parent and children. For the root node in my tree, the depth is set to 0, so the logic of my program should prevent the need of locating its parent.\n```\ntypedef struct node {\n  int depth;\n  char* content;\n  struct node* parent;\n  node_array* children;\n} node;\n```\n\nI receive a collection of two errors and a warning informing me that ```\nstruct node*```\n and ```\nnode*```\n are incompatible.\n```\nmain.c: In function ‘array_insert’:\nmain.c:43:33: error: incompatible types when assigning to type ‘struct node’ from type ‘node *’\n   43 |   array->array[array->used++] = element;\n      |                                 ^~~~~~~\nmain.c: In function ‘print_tree’:\nmain.c:115:37: error: incompatible type for argument 1 of ‘print_tree’\n  115 |     print_tree(root->children->array[i], depth + 1);\n      |                ~~~~~~~~~~~~~~~~~~~~~^~~\n      |                                     |\n      |                                     struct node\nmain.c:99:23: note: expected ‘node *’ but argument is of type ‘struct node’\n   99 | void print_tree(node* root, int depth) {\n      |                 ~~~~~~^~~~\n```\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Avoid diamond problem in abstract + concrete class hierarchies\r\n                \r\nI am working on a game and we want to wrap the physics engine so it can easily be exchanged.\nSo we want to create an abstract class hierarchy as a template, specifying everything the engine has to support and working as an interface for the rest of the game. Then we want to create concrete classes, implementing those abstract classes and wrapping the actual engine. The problem is that this creates a lot of diamonds, for example:\n\nWhere Shape and Circle contain engine-independent functionality but also some engine-dependent abstract methods and P2Shape and P2Circle are wrappers for the P2 engine and implement those engine-specific methods. And from a broader perspective, we don't just have these two classes but a whole hierarchy tree of (not purely) abstract template classes and a whole hierarchy tree of concrete implementations. Each of the concrete classes \"is-a\" -> its abstract template and \"is-a\" -> its base class in the hierarchy:\n\nWe are probably not the first people to encounter this problem and this is probably some symptom of bad design, so I am curious about the proper way to implement this. To make it a bit more interesting, we are working in TypeScript which does not support multiple inheritance.\nHere are the approaches I considered:\n\nFavor composition over inheritance\n\nLet's say a Shape has a position and a Circle has a radius. In my opinion, a Circle clearly \"is a\" Shape that has a position and a radius, it doesn't \"have a\" radius and a shape that has a position. Also, if I access the position I don't want to say myCircle.shape.position. Shapes are a textbook example of inheritance hierarchies. The other option would be that a Shape has a P2Shape but then all engine-specific stuff has to be squeezed in there and the type of the field has to be any or generic. Or a P2Shape has a Shape but then the rest of the game cannot work with it because it is unaware of the P2Shape type.\n\nUse interfaces instead of abstract classes\n\nTypeScript supports a separate concept of interfaces where multiple inheritance and the diamond problem are not an issue. But there we cannot put any implementation whatsoever into the engine-independent parts.\n\nMixins\n\nI feel like the concept of mixins is to create a set of modular and reusable components that can be combined into classes that make use of the functionality. In our case that would mean that P2Shape and Circle are modular components and P2Circle uses them. That somehow doesn't feel semantically right to me.\nAll three solutions feel somewhat unsatisfying. Any help is much appreciated!\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How does one create a symbolic function execution DAGs that is not evaluated immediately in Python?\r\n                \r\nI wanted to create a \"symbolic\" representation of function calls (in my mind right now the best way to represent this is with a Graph or a DAG or a Tree) i.e. set up an execution graph and then execute the graph later, with the possibility with slightly different inputs or the graph having a completely different state when executed (similarly how TensorFlow does it, with feeds and inputs to the graph). \n\nSo for example if I had:\n\n```\ngraph = f( g('a','b', h('c','d') ), seed )\n```\n\n\nI would have the graph:\n\n\n\nand the essentially have control of how I execute the graph:\n\n```\ngraph.execute()\n```\n\n\nI feel this is some sort of design pattern since say TensorFlow, Mathematica and SymPy seem to all use (note it seems language independent). Though, I had a hard time finding the name of the design pattern so that I could implement it myself in Python with my own execution graph nodes and data types. Does anyone know how to do this or have a nice link to the name of the design pattern so that I can build this?\n\nIts important for me that the graph creation is as simple as easy as TensorFlow, SymPy etc. In other words. I'd like that I can have multiple syntaxes to create the same graph. For example It shouldn't be to hard to do:\n\n```\nh = h('c','d')\ng = g('a','b', h )\ngraph = f( g, seed )\n```\n\n\nif the user wanted to.\n    ", "Answer": "\r\nHere's a quick example:\n\n```\n# dataflow constructs\n#####################\n\nclass DelayedFunctionCall:\n    def __init__(self, func, *args):\n        self.func = func\n        self.args = args\n\n    def execute(self):\n        args = [arg.execute() if isinstance(arg, type(self)) else arg for arg in self.args]\n        return self.func(*args)\n\ndef dataflow(func):\n    return lambda *args: DelayedFunctionCall(func, *args)\n```\n\n\nSpecifically I create ```\ndataflow```\n as a wrapper around a python function to store the function and arguments into a ```\nDelayedFunctionCall```\n.\n\nThis mechanism is just storing the function and arguments, but no execution occurs yet.\n\nCalling ```\nexecute()```\n from a ```\nDelayedFunctionCall```\n actually resolves the function and arguments stored. Note that ```\nDelayedFunctionCall```\n takes care to resolve any ```\nDelayedFunctionCall```\n arguments it received first (by calling ```\narg.execute()```\n).\n\n```\n# user code\n###########\n\n@dataflow\ndef f(g, seed):\n    return g**2 % seed\n\n@dataflow\ndef g(a, b, h):\n    return a * b + h\n\n@dataflow\ndef h(c, d):\n    return c / d\n\nseed = 5\n\n# setting up the execution / dataflow\ngraph = f(g(1, 2, h(3, 4)), seed)\n\n# no mathematical operations have happened yet; i.e. bodies of f,g,h functions have not been executed yet\n\n# executing the dataflow\nprint(graph.execute())\n```\n\n\nNote the use of the ```\n@dataflow```\n decorator. If you want you could also define the functions regularly and later convert them into ```\nDelayedFunctionCall```\ns:\n\n```\ndef f(g, seed):\n    return g**2 % seed\n\n# do stuff with regular, non-dataflow f\n\nf = dataflow(f) # now f is a DelayedFunctionCall\n```\n\n\n\n\nYou can check out the code (with support for ```\n**kwargs```\n and the ability to delay binding variables to values until execution time!) on github.com/pcattori/dataflow\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How can i use IoC in a asp.net webforms component (DotNetNuke module) without changing the infrastructure?\r\n                \r\nI'm working on legacy code in a DotNetNuke module, trying to get classes and behaviors under a testing framework: I'm taking this opportunity to follow advice from the \"Working effectively with legacy code\" book, so what happens is that i'm trying to define areas which can be tested thoroughly and then converted to services. Then i'd like to use an IoC framework for it to work. For now, i've set eyes on Ninject.\n\nHowever i'm hitting a design problem: as i'm in a DotNetNuke module, i can't really change application-wide structure: for example i can't derive the Application from NinjectHttpApplication. I can't use these suggestions from SO either.\nI was thinking about having the Kernel in a static class that my module would set up and then use but from what i've read around it's a very bad idea.\n\nSo i'm starting to ask myself if it's possible to use an IoC in an application that hasn't been set up to support it from scratch. If i'm supposed to have a whole dependency tree loaded for each request, how can i rewrite legacy code locally and benefit from IoC? Is there a pattern where IoC use can grow out from very local rewrites?\n\nEven though i'm working with DotNetNuke, any standalone component that can be installed into an independent framework begs the same question. Also i'm not targeting Ninject specifically, if another IoC framework can help in this case i'm willing to consider it.\n    ", "Answer": "\r\nFrom my experience, your best bet to get this type of abstraction within the context of DotNetNuke is by using the WebFormsMVP framework. This is really the only sane way I've found to do unit testing in a DNN module, and if memory serves I spent awhile trying to wire up Ninject a year or so ago.\n\nBut be warned, it is still WebForms and will never be drop dead simple. And without knowing your existing code base, I'd have a hard time knowing how easy it will be to make the migration.\n\nI have a couple of resources on GitHub that you can check out for reference:\n\nThe first is a module template that should act as a solid starting point:\n\nhttps://github.com/irobinson/WebFormsMvp-DNN-Module-Template\n\nThe second is a small example project:\n\nhttps://github.com/irobinson/BeerCollectionMVP\n\nDepending on the version of DNN you're using, it may or may not already ship with WebFormsMVP, but you should be able to either bundle the dependencies w/ your module or upgrade to the newer version of DNN if that's reasonable.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to Drag an EasyUI Tree Node on to a Fabric.js Canvas?\r\n                \r\nI have recently begun noodling with the Jquery-EasyUI Framework and I've come across a bit of a stumper... how can I drag a node out of an EasyUI Tree and into another object? (In my case, a Fabric.js Canvas) The EasyUI Tree object seems to be swallowing up any event which doesn't terminate inside the tree. All I want to be able to do upon dropping on the canvas (or anywhere else) is to either\n\n(A) (Most Preferable): Get access to the \"attributes\" property of the EasyUI Tree node object that's getting dragged out of the tree\n\n(B) (Less Preferable): To at least be able to get the ID or Text of the tree node object that's being dragged.\n\nRight now, I'm getting nothing. As soon as the object is dragged outside the tree area, all I'm getting are null objects on the canvas (or anywhere else I try to set it up).\n\nDoes anybody know how this could be done?\n\nThanks!\n\nI have stripped down my project to more or less the essential elements. When it runs it creates a frame with a left side containing an easyui tree and an easyui project grid, and a right side containing a Fabric.js canvas. What I would like to do is be able to drag an item from the tree and drop it onto the canvas and be able to (ideally) retrieve it's properties contained in the \"attributes\" attribute of the node, or else (at least) be able to retrieve the ID/Text value from the dropped node itself, which I could then lookup independently if necessary. \n\n```\n<!DOCTYPE html>\n<html>\n<head>\n  <title>EasyUI Drag-n-Drop Test</title>\n\n  <style>\n    body, html {\n        width: 100%;\n        height: 100%;\n        overflow: hidden;\n        padding: 3px;\n        box-sizing: border-box;\n        margin: 0;\n        }\n  </style>\n\n  <!-- Load JQuery -->\n  <script type=\"text/javascript\" src=\"https://code.jquery.com/jquery-2.2.3.min.js\"></script>\n  <!-- Load EasyUI Framework -->\n  <script type=\"text/javascript\" src=\"http://www.jeasyui.com/easyui/jquery.easyui.min.js\"></script>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"http://www.jeasyui.com/easyui/themes/default/easyui.css\">\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"http://www.jeasyui.com/easyui/themes/icon.css\">  \n  <!-- Load Other Javascript Modules -->\n  <script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/fabric.js/1.6.1/fabric.min.js\"></script>\n\n  <!-- Direct / Inline Javascript for this Document -->\n  <script type=\"text/javascript\">\n\n\n// Handle Tree & Canvas Drag & Drop Events\nfunction handleStartDrag(e) {\n    console.log('handleStartDrag');\n    console.table(e);\n    var data = e.dataTransfer.getData('text');\n    alert('Drag-n-Dropped ['+text+']');\n    return false;\n};\n\nfunction handleStopDrag(e) {\n    console.log('handleStopDrag');\n    console.table(e);\n    return false;\n};\n\nfunction handleDragEnter(e) {\n    console.log('handleDragEnter');\n    console.table(e);\n    return false;\n};\n\nfunction handleDragOver(e) {\n    console.log('handleDragOver');\n    console.table(e);\n    return false;\n};\n\nfunction handleDragLeave(e) {\n    console.log('handleDragLeave');\n    console.table(e);\n    return false;\n};\n\nfunction handleDrop(e) {\n    console.log('handleDrop');\n    console.table(e);\n    var data = e.dataTransfer.getData('text');\n    alert('Drag-n-Dropped ['+text+']');\n    return false;\n};\n\nfunction loadFilter(data) {\n    var nodes = [];\n    for(var i = 0; i < data.length; i++) {\n    var node = data[i];\n        nodes.push({\n            id:             node.id,\n            text:           node.name,\n            attributes:     node,\n        });\n    }\n    return nodes;\n};\n\nfunction loadPropertyGrid(node) {\n    node = node || {id: '', text: '', attributes: {id: '', name: '', address: '', city: '', state: '', zip: '', phone: ''}};\n\n    $('#pg').propertygrid('loadData', [\n        {name: \"ID\", value: node.attributes.id, group: \"\", editor: 'text'},\n        {name: \"Name\", value: node.attributes.name, group: \"\", editor: 'text'},\n        {name: \"Address\", value: node.attributes.address, group: \"\", editor: 'text'},\n        {name: \"City\", value: node.attributes.city, group: \"\", editor: 'text'},\n        {name: \"State\", value: node.attributes.state, group: \"\", editor: 'text'},\n        {name: \"Zip\", value: node.attributes.zip, group: \"\", editor: 'text'},\n        {name: \"Phone\", value: node.attributes.phone, group: \"\", editor: 'text'},\n        ]);\n    $('#pg').propertygrid('fitColumns');\n};\n\nfunction getData() {\n    return [\n        {id: 1, name: \"Tom Jones\", address: \"123 Blah Lane\", city: \"Somewhereville\", state: \"XY\", zip: \"12345\", phone: \"123-456-7890\"},\n        {id: 2, name: \"Sally Sue\", address: \"162 Foobar Dr\", city: \"Blechtown\", state: \"QZ\", zip: \"98672\", phone: \"345-123-5432\"},\n        {id: 3, name: \"Ralph Slug\", address: \"1762 Uknow St\", city: \"Mumbleville\", state: \"WE\", zip: \"21763\", phone: \"828-462-1786\"},       ];\n};\n\nfunction getPgColumns() {\n    return [[\n        {field: 'name', title: 'Item', width: 30, sortable: true, resizeable: true},\n        {field: 'value', title: 'Value', width: 70, resizeable: true},\n        ]];\n}\n\n//-----------------------------------------------------------------\n$(document).ready(function() {\n    // Set up Fabric.Js Canvas\n    var canvas = new fabric.Canvas('cv');     \n    var gridWidth = 1000; // define canvas grid width\n    var gridHeight= 1000; // define canvas grid height\n\n    canvas.clear(); // Clear (remove) all objects off the canvase\n    setSelectionStyle(); // Set canvase selection style\n    drawGrid(gridWidth, gridHeight, 20); // Draw a grid on the canvas\n\n    // Bind the event listeners for the canvas\n    var canvasWrapper = document.getElementById('cv_wrapper');\n    canvasWrapper.addEventListener('startdrag', handleStartDrag, false);\n    canvasWrapper.addEventListener('stopdrag', handleStopDrag, false);\n    canvasWrapper.addEventListener('dragenter', handleDragEnter, false);\n    canvasWrapper.addEventListener('dragover', handleDragOver, false);\n    canvasWrapper.addEventListener('dragleave', handleDragLeave, false);\n    canvasWrapper.addEventListener('drop', handleDrop, false);\n\n    // Draw something on the canvas\n    var grp = new fabric.Group([]);\n    var r1 = new fabric.Rect({left: 0, top: 0, width: 50, height: 50, fill: '#f00'});\n    var r2 = new fabric.Rect({left: 25, top: 25, width: 50, height: 50, fill: '#00f'});\n\n    grp.addWithUpdate(r1);\n    grp.addWithUpdate(r2);\n    canvas.add(grp);\n    canvas.renderAll();\n\n    loadPropertyGrid(); \n\nfunction setSelectionStyle() {         \n        canvas.selectionColor = 'rgba(0,255,0,0.3)';\n        canvas.selectionBorderColor = '#f33';\n        canvas.selectionLineWidth = 2;\n};\n\nfunction drawGrid(gridWidth, gridHeight, gridSize) {\n        // to manipulate grid after creation\n        var grid = new fabric.Group([], {\n            left:                   0, \n            top:                    0,\n            lockRotation:           true,\n            lockScalingX:           true,\n            lockScalingY:           true,\n            hasControls:            false,\n            hasBorders:             false,\n            hasRotatingPoint:       false,\n            lockMovementX:          true,\n            lockMovementY:          true,\n            selectable:             false,\n            });\n\n        // define presentation option of grid\n        var lineOption = {stroke: 'rgba(0,0,0,.4)', strokeWidth: 1, selectable:false, strokeDashArray: [3, 3]};\n\n        // vertical lines\n        for(var i = Math.ceil(gridWidth/gridSize); i--;){\n            grid.add( new fabric.Line([gridSize*i, 0, gridSize*i, gridHeight], lineOption) );\n            }\n\n        // horizontal lines\n        for(var i = Math.ceil(gridHeight/gridSize); i--;){\n            grid.add( new fabric.Line([0, gridSize*i, gridWidth, gridSize*i], lineOption) );\n            }\n\n        // add group to canvas\n        canvas.add(grid);\n        }; \n});\n</script>\n</head>\n<body>\n    <div class=\"easyui-layout\" style=\"width:100%;height:100%;\">\n        <!-- WEST (LEFT SIDE) -->\n        <div data-options=\"region:'west',split:true\" title=\"EasyUI Tree Widget\" style=\"width:240px;overflow:hidden\">\n          <div class=\"easyui-layout\" style=\"width:100%;height:100%\">\n            <div data-options=\"region:'north',split:true\" style=\"height:60%\">\n              <!-- Network Device Tree -->\n              <ul class=\"easyui-tree\" data-options=\"\n                data: getData(),\n                loadFilter: function(data) { return loadFilter(data); },\n                onClick:    function(node){ loadPropertyGrid(node); },\n                dnd: true,\n                onDragEnter: function(e){ handleDragEnter(e); },\n                onDragOver: function(e) { handleDragOver(e); },\n                onDragLeave: function(e) { handleDragLeave(e); },\n                onDrop: function(e) { handleDrop(e); },\n                \"></ul>\n            </div>\n            <div data-options=\"region:'center'\" title=\"EasyUI PropertyGrid\" style=\"height:40%\">\n              <!-- Property Grid -->\n              <table id=\"pg\" class=\"easyui-propertygrid\" style=\"width:100%\" data-options=\"\n                method:'get',\n                showGroup:false,\n                scrollbarSize:0,\n                columns: getPgColumns(),\n                \">\n              </table>\n            </div>\n      </div>\n    </div>\n    <!-- CENTER -->\n        <div data-options=\"region:'center',title:'Fabric.js Canvas',iconCls:'icon-ok'\">\n            <div data-container=\"FabricCanvas\" id=\"cv_wrapper\">\n                <canvas id=\"cv\" class=\"canvas-container\" width=\"1000\" height=\"1000\"></canvas>\n            </div>\n        </div>\n  </body>\n\n</html>\n```\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "What is the best way to store a table in C++\r\n                \r\nI'm programming a decision tree in C++ using a slightly modified version of the C4.5 algorithm. Each node represents an attribute or a column of your data set and it has a children per possible value of the attribute.\n\nMy problem is how to store the training data set having in mind that I have to use a subset for each node so I need a quick way to only select a subset of rows and columns.\n\nThe main goal is to do it in the most memory and time efficient possible(in that order of priority).\n\nThe best way I have thought is to have an array of arrays(or std::vector) or something like that, and for each node have a list(array, vector, etc) or something with the ```\ncolumn,line```\n(probably a tuple) pairs that are valid for that node.\n\nI now there should be a better way to do this, any suggestions?\n\nUPDATE: What I need is something like this:\n\nOn the beginning I have this data:\n\n```\nParis    4    5.0    True\nNew York 7    1.3    True\nTokio    2    9.1    False\nParis    9    6.8    True\nTokio    0    8.4    False\n```\n\n\nBut for the second node I just need this data:\n\n```\nParis    4    5.0\nNew York 7    1.3\nParis    9    6.8\n```\n\n\nAnd for the third node:\n\n```\nTokio    2    9.1\nTokio    0    8.4\n```\n\n\nBut with a table of millions of records with up to hundreds of columns.\n\nWhat I have in mind is keep all the data in a matrix, and then for each node keep the info of the current columns and rows. Something like this:\n\n```\nParis    4    5.0    True\nNew York 7    1.3    True\nTokio    2    9.1    False\nParis    9    6.8    True\nTokio    0    8.4    False\n```\n\n\nNode 2:\n\n```\ncolumns = [0,1,2]\nrows = [0,1,3]\n```\n\n\nNode 3:\n\n```\ncolumns = [0,1,2]\nrows = [2,4]\n```\n\n\nThis way on the worst case scenario I just have to waste \n\n```\nsize_of(int) * (number_of_columns + number_of_rows) * node\n```\n\n\nThat is a lot less than having an independent data matrix for each node.\n    ", "Answer": "\r\nHow about using at trie: http://en.wikipedia.org/wiki/Trie.\n\nThere is also a discussion on how to implement trie:\nTrie implementation\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "wxPython: How should I organize per-widget data in the controller?\r\n                \r\nI have a widget that displays a filesystem hierarchy for convenient browsing (basically a tree control and some associated toolbar buttons, such as \"refresh\"). Each of these widgets has a set of base directories for it to display (recursively). Assume that the user may instantiate as many of these widgets as they find convenient. Note that these widgets don't correspond to any business data -- they're independent of the model.\n\nWhere should the (per-widget) set of base directories live in good MVC design?\n\nWhen the refresh button is pushed, an event is trapped by the controller, and the event contains the corresponding filesystem-browser widget. The controller determines the base directories for that particular widget (somehow), walks that directory path, and passes the widget some data to render.\n\nTwo places I can think to store the base directories:\n\n\nThe easy solution: make the base directories an instance variable on the widget and have the controller manipulate it to retain state for that widget. There's a conceptual issue with this, though: since the widget never looks at that instance variable, you're just projecting one of the responsibilities of the controller onto the widget.\nThe more (technically, maybe conceptually) complex solution: Keep a ```\n{widget: base_directory_set}```\n mapping in the controller with weak key references.\n\n\nThe second way allows for easy expansion of controller responsibilities later on, as putting things in the controller tends to do -- for example, if I decided I later wanted to determine the set of all the base directories for all those widgets.\n\nThere may be some piece of MVC knowledge I'm missing that solves this kind of problem well.\n    ", "Answer": "\r\nThe anomaly (from the MVC viewpoint) that makes this design difficult to make MVC-conformant is that you want to display information that, by your conceptualization, \"does not live in a model\".  There is no such thing as \"information that does not live in a model\" in MVC: its conceptual root is \"the models hold all the information, the views just do presentation tasks, the controllers mediate user interaction\".\n\nIt's quite possible that the information you're displaying doesn't \"correspond to any business data\", but (in an MVC worldview) this does not mean that info is \"independent of the model\", because there is no such thing -- it just means you need another model class (beyond whatever you're using to hold \"business data\"), to hold this \"non-business\" data!-)\n\nSo when the user \"instantiates a widget\" (creates a directory-display view, presumably by some user action on some master/coordinating view, possibly on another existing widget if \"cloning\" is one of the ways to instantiate a widget), the controller's responsible for creating both a widget object and an instance of the \"directory-display model class\", and establish connection between them (normally by setting on the widget a reference to the relevant model instance), as well as telling the model to do its initial loading of information.  When the user action on the widget implies an action on the model, the controller retrieves from the widget involved in the event the reference to the model instance, and sends that instance the appropriate request(s) (it's the model's business to let the view[s] interested in it know about changes to information -- typically by some observer pattern; it's definitely not the controller's business to feed the view with information -- that's really a very different approach from MVC!).\n\nIs the architectural investment required by MVC worth it, in your case, compared to a rougher approach where the information flows are less pristine and the model that should be there just doesn't exist?  I'm a pragmatist and I definitely don't worship at the altar of MVC, but I think in this case the (relatively small) investment in sound, clear architecture may indeed repay itself in abundance.  It's a question of envisioning the likely directions of change -- for example, what functionality that you don't need right now (but may well enter the picture soon afterwards) will be trivial to add if you go the proper MVC route, and would be a nightmare of ad-hoc kludges otherwise (or require a somewhat painful refactoring of the whole architecture)?  All sort of likely things, from wanting to display the same directory information in different widgets to having a smarter \"directory-information watching\" model that can automatically refresh itself when needed (and supply the new info directly to interested views via the usual observer pattern, with no involvement by the controller), are natural and trivially easy with MVC (hey, that's the whole point of MVC, after all, so this is hardly surprising!-), kludgy and fragile with an ad-hoc corner-cutting architecture -- small investment, large potential returns, go for it!\n\nYou may notice from the tone of the previous paragraph that I don't worship at the \"extreme programming\" altar either -- as a pragmatist, I will do a little \"design up front\" (especially in terms of putting in place a clean, flexible, extensible architecture, from the start, even if it's not indispensable right now) -- exactly because, in my experience, a little forethought and very modest investment, especially on the architectural front, pays back for itself many times over during a project's life (in such varied currencies as scalability, flexibility, extensibility, maintainability, security, and so forth, though not all of them will apply to every project -- e.g., in your case, security and scalability are not really a concern... but the other aspects will likely be!-).\n\nJust for generality, let me point out that this pragmatic attitude of mine does not justify excessive energy and time spent on picking an architecture (by definition of the word \"excessive\";-) -- being familiar with a few fundamental architectural patterns (and MVC is surely one of those) often reduces the initial investment in terms of time and effort -- once you recognize that such a classic architecture will serve you well, as in this case, it's really easy to see how to embody it (e.g., reject the idea of an \"MVC without a M\"!-), and it doesn't really take much more code compared to the kludgiest, ad-hoccest shortcuts!-)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Strategy to implement tree traversing algorithm in parallel?\r\n                \r\nI have implemented an iterative algorithm, where each iteration involves a pre-order tree traversal (sometimes called downwards accumulation) followed by a post-order tree traversal (upwards accumulation).  Each visit to each node involves calculating and storing information to be used for the next visit (either in the subsequent post-order traversal, or the subsequent iteration).  \n\nDuring the pre-order traversal, each node can be processed independently as long as all nodes between it and the root have already been processed.  After processing, each node needs to pass a tuple (specifically, two floats) to each of its children.  On the post-order traversal, each node can be processed independently as long as all of it's subtrees (if any) have already been processed.  After processing, each node needs to pass a single float to its parent.\n\nThe structure of the trees is static and unchanged during the algorithm.  However, during the course of the downward traversal, if the two floats being passed both become zero, the entire subtree under this node does not need to be processed, and the upwards traversal for this node can begin.  (The subtree must be preserved, because the passed floats on subsequent iterations may become non-zero at this node and traversals would resume).\n\nThe intensity of computation at each node is the same across the tree.  The computation at each node is trivial:  Just a few sums and multiply/divides on a list of numbers with length equal to the number of children at the node.\n\nThe trees being processed are unbalanced: a typical node would have 2 leaves plus 0-6 additional child nodes.  So, simply partitioning the tree into a set of relatively balanced subtrees is non-obvious (to me).  Further, the trees are designed to consume all available RAM: the bigger tree that I can process, the better.\n\nMy serial implementation attains on the order of 1000 iterations per second on just my little test trees; with the \"real\" trees, I expect it might slow by an order of magnitude (or more?).  Given that the algorithm requires at least 100 million iterations (possibly up to a billion) to reach an acceptable result, I'd like to parallelize the algorithm to take advantage of multiple cores.  I have zero experience with parallel programming.  \n\nWhat is the recommended pattern for parallelization given the nature of my algorithm?\n    ", "Answer": "\r\nTry to rewrite your algorithm to be composed of pure functions. That means that every piece of code is essentially a (small) static function with no dependence on global variables or static variables, and that all data is treated as immutable--- changes are only made to copies--- and all functions only manipulate state (in a loose sense of the word \"manipulate\") by returning (new) data.\n\nIf every function is referentially transparent--- it only depends on its input (and no hidden state) to compute its output, and every function call with the same input always yields the same output--- then you are in a good position to parallelize the algorithm: since your code never mutates global variables (or files, servers, etc.) the work a function does can be safely repeated (to recompute the function's result) or completely ignored (no future code depends on this function's side effects, so skipping a call completely won't break anything). Then when you run your suite of functions (for example on some implementation of MapReduce, hadoop, etc.) the chain of functions will cause a magical cascade of dependencies based solely on the output of one function and the input of another function, and WHAT you are trying to compute (via pure functions) will be completely separate from the ORDER in which you are trying to compute it (a question answered by the implementation of a scheduler for a framework like MapReduce).\n\nA great place to learn this mode of thinking is write your algorithm in the programming language Haskell (or something F# or Ocaml) which has great support for parallel/multicore programming, out of the box. Haskell forces your code to be pure so if your algorithm works, it IS probably easily parallelizable.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Fast algorithm needed for finding tuples from within one list inside tuples of another list. Sets?\r\n                \r\nI have following lists:\n\n```\nlist_1 = [(0, 1, 7, 6), (1, 2, 8, 7), (2, 3, 9, 8), ...]\nlist_2 = [(0,1), (1,7), (7,8), (3,9), ...]\n```\n\n\nBoth lists have a length of 200000 or more elements.\n\nI need a fast algorithm to check how often an element of ```\nlist_2```\n occurs in an element of ```\nlist_1```\n. In the example above, the second element of ```\nlist_2```\n which is ```\n(1,7)```\n occurs two times in ```\nlist_1```\n, respectively in the first and second list element.\n\nIn my case it is a valid hit, if both numbers are a subset of ```\nlist_1```\n independent of their order. So I thought I go with sets and use ```\n.issubset```\n. \n\n```\nfor item1 in list_1:\n    count = 0\n    for item2 in list_2:\n        if set(item2).issubset(set(item1)):\n            count += count\n    if count == 1:\n        do this\n    if count == 2:\n        do that\n```\n\n\nThe data from the lists are structured in a way, that I know upfront, that the variable ```\ncount```\n can only have the values ```\n1```\n or ```\n2```\n. And I know that a loop of O(N**2) is not smart at all and that the ```\nif```\n statements in it do not boost performance. Actually, in my current implementation the elements of ```\nlist_2```\n are already of type ```\nset```\n, but the snippet above is shorter and easy to read.\n\nI believe that there are smart solutions existing for this task.\n\nMy application uses numpy and scipy, so any KD-tree search or similar (if applicable) would also be fine.\n\nEDIT\n\nI need to be more specific:\n\n\n```\nlist_2```\n always contains pairs. ```\nlist_1```\n can have 3 or more items per list element.\nin ```\ndo this```\n and ```\ndo that```\n I need to keep track of the corresponding elements and their associations, e.g by using a dictionary.\nthere is not more than this to exploit the structure of the data\n\n    ", "Answer": "\r\nYou could first do some preprocessing and build a dictionary keyed by the individual numbers that occur in list_1 providing each key as value the set of tuples in list_1 that have that keys.\n\nThen finding the occurrences of a pair from list_2 is as simple as taking the intersection of the sets found at the two keys, and taking the resulting set's size.\n\n```\nlist_1 = [(0, 1, 7, 6), (1, 2, 8, 7), (2, 3, 9, 8)]\nlist_2 = [(0,1), (1,7), (7,8), (3,9)]\n\n# per number as dictionary key, list the tuples from list_1 that contain it\nd = dict()\nfor lst in list_1:\n    for v in lst:\n        if not v in d: d[v] = set()\n        d[v].add(lst)\n\n# for each pair, take the intersection of the corresponding lists in d\nresult = [(lst, len(d[lst[0]].intersection(d[lst[1]]))) for lst in list_2]\n\nprint(result)\n```\n\n\nIf you need to actually do something with the found tuples from list_1, then you would first gather those tuples without taking their number (so ```\nd[lst[0]].intersection(d[lst[1]])```\n), and do your processing on them based on what ```\nlen()```\n provides (1 or 2).\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Distance measure for categorical attributes for k-Nearest Neighbor\r\n                \r\nFor my class project, I am working on the Kaggle competition - Don't get kicked\n\nThe project is to classify test data as good/bad buy for cars. There are 34 features and the data is highly skewed. I made the following choices:  \n\n\nSince the data is highly skewed, out of 73,000 instances, 64,000 instances are bad buy and only 9,000 instances are good buy. Since building a decision tree would overfit the data, I chose to use kNN - K nearest neighbors.\nAfter trying out kNN, I plan to try out Perceptron and SVM techniques, if kNN doesn't yield good results. Is my understanding about overfitting correct?\nSince some features are numeric, I can directly use the Euclid distance as a measure, but there are other attributes which are categorical. To aptly use these features, I need to come up with my own distance measure. I read about Hamming distance, but I am still unclear on how to merge 2 distance measures so that each feature gets equal weight.\nIs there a way to find a good approximate for value of k? I understand that this depends a lot on the use-case and varies per problem. But, if I am taking a simple vote from each neighbor, how much should I set the value of k? I'm currently trying out various values, such as 2,3,10 etc.\n\n\nI researched around and found these links, but these are not specifically helpful -\na) Metric for nearest neighbor, which says that finding out your own distance measure is equivalent to 'kernelizing', but couldn't make much sense from it.\nb) Distance independent approximation of kNN talks about R-trees, M-trees etc. which I believe don't apply to my case.\nc) Finding nearest neighbors using Jaccard coeff  \n\nPlease let me know if you need more information.  \n    ", "Answer": "\r\n\nSince the data is unbalanced, you should either sample an equal number of good/bad (losing lots of \"bad\" records), or use an algorithm that can account for this. I think there's an SVM implementation in RapidMiner that does this.\nYou should use Cross-Validation to avoid overfitting. You might be using the term overfitting incorrectly here though. \nYou should normalize distances so that they have the same weight. By normalize I mean force to be between 0 and 1. To normalize something, subtract the minimum and divide by the range. \nThe way to find the optimal value of K is to try all possible values of K (while cross-validating) and chose the value of K with the highest accuracy. If a \"good\" value of K is fine, then you can use a genetic algorithm or similar to find it. Or you could try K in steps of say 5 or 10, see which K leads to good accuracy (say it's 55), then try steps of 1 near that \"good value\" (ie 50,51,52...) but this may not be optimal. \n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to dynamically create multiple selectboxes for category tree\r\n                \r\nI have multiple categories with a sub-category-level limited to 6 subcategories. What I want is cascading selectboxes with the content of the parent category. Have a look at my screenshot:\n\nOn the left half-side we have strings of the customers-category (in this expl. it matches the selectable categories, but this is not always the case). The user should select a matching category from the apps category-tree.\nWhen the user selects the main category, another selectbox appears with the contents of main category - and so on....\nMy current problem is that always all selectboxes of a level are set with the selected value, but they should be independant. This is my code:\nHTML:\n```\n<form *ngIf=\"!!customerCategories\" (ngSubmit)=\"onCategorizeSubmit(mapForm.value)\" #mapForm=\"ngForm\">\n        <div *ngFor=\"let customerCategory of customerCategories\" class=\"row\">\n            <div class=\"col\">\n                <div class=\"form-label\" class=\"col-form-label\">{{ customerCategory }}</div>\n            </div>\n            <div class=\"col\">\n                <select *ngIf=\"!!selectLevel0Visible\" class=\"form-select\" class=\"col\" name=\"{{ customerCategory }}_0\"\n                    [(ngModel)]=\"selectedCategoryLevel0\" (change)=\"onSelectLevel0($event.target)\">\n                    <option>Bitte auswählen...</option>\n                    <option *ngFor=\"let googleCategoryLevel0 of googleCategoriesLevel0\"\n                        value=\"{{googleCategoryLevel0.id}}\">\n                        {{ googleCategoryLevel0.pathFragment }}</option>\n                </select>\n                \n                [...]\n                \n                <select *ngIf=\"!!selectLevel6Visible\" class=\"form-select\" class=\"col\" name=\"{{ customerCategory }}_6\"\n                    [(ngModel)]=\"selectedCategoryLevel6\">\n                    <option>Bitte auswählen...</option>\n                    <option *ngFor=\"let googleCategoryLevel6 of googleCategoriesLevel6\"\n                        value=\"{{googleCategoryLevel6.id}}\">\n                        {{ googleCategoryLevel6.pathFragment }}</option>\n                </select>\n            </div>\n        </div>\n        <button type=\"button\" class=\"btn btn-secondary float-start\" (click)=\"cancelAssistant()\">Assistent\n            abbrechen</button>\n            <button *ngIf=\"!currentFeed.isCategorized\" type=\"button\" class=\"btn btn-primary float-end\" type=\"submit\">Kategorisieren</button>\n            <button *ngIf=\"!!currentFeed.isCategorized\" type=\"button\" class=\"btn btn-primary float-end\" matStepperNext>Weiter</button>\n    </form>\n```\n\nTS:\n```\nexport class CategorizeFeedComponentFeature implements OnChanges {\n\n  @Input() currentFeed: FeedmapConfigDto;\n  customerCategories: string[];\n  googleCategoriesLevel0: GCategoryDto[];\n  [...]\n  googleCategoriesLevel6: GCategoryDto[];\n\n  selectedCategoryLevel0: number;\n  [...]\n  selectedCategoryLevel6: number;\n\n  selectLevel0Visible: boolean = true;\n  [...]\n  selectLevel6Visible: boolean = false;\n\n  async ngOnChanges(): Promise<void> {\n    if (!!this.currentFeed?.isImported) {\n      this.customerCategories = await this.productService.getAllCustomerCategoriesByFeedmapConfigId(this.currentFeed.id).toPromise();\n      this.googleCategoriesLevel0 = await this.categoryService.getAllGoogleCategories(0).toPromise();\n    }\n  }\n\n  async onSelectLevel0(eventTarget: EventTarget): Promise<void> {\n    const value = +(eventTarget as HTMLInputElement).value;\n    this.googleCategoriesLevel1 = await this.categoryService.getAllGoogleCategories(value).toPromise();\n    if (this.googleCategoriesLevel1.length > 0) {\n      this.selectLevel1Visible = true;\n    }\n  }\n\n  [...]\n\n  async onSelectLevel5(eventTarget: EventTarget): Promise<void> {\n    const value = +(eventTarget as HTMLInputElement).value;\n    this.googleCategoriesLevel6 = await this.categoryService.getAllGoogleCategories(value).toPromise();\n    if (this.googleCategoriesLevel6.length > 0) {\n      this.selectLevel6Visible = true;\n    }\n  }\n\n  async onSelectLevel6(eventTarget: EventTarget): Promise<void> {\n    const value = +(eventTarget as HTMLInputElement).value;\n    // this.googleCategoriesLevel7 = await this.categoryService.getAllGoogleCategories(value).toPromise();\n  }\n}\n```\n\nNext to my question, I think there should be a better way to solve this - I´m thinking about a material tree with selectboxes. What is your opinion?\nRegards\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to use linux gpio subsystem with PySerial for RS485 DE signal (RTS)\r\n                \r\nI'm using PySerial to communicate to some devices over RS485 multi-drop.  I am bit-banging the DE signal to enable transmission before sending a packet and releasing it at the end.\nThe problem is that the time for release varies, especially under processor load, and the responses from the devices get clobbered (and aren't received).\nI know PySerial has RS485 support, but from everything I've read about my embedded SBC (NXP iMX6 Dual), the RTS signal is not available on the GPIO connector.  I just have arbitrary GPIO to use.\nIs there a way to map an arbitrary GPIO signal to the RTS functionality so that the Linux tty drivers will assert/deassert my desired GPIO pin?\nThe following statement gives me some hope (https://www.kernel.org/doc/html/v4.17/driver-api/gpio/drivers-on-gpio.html)\n\"\"\"\n... there are special GPIO drivers in subsystems like ... the TTY serial subsystem to emulate MCTRL (modem control) signals CTS/RTS by using two GPIO lines.\n\"\"\"\nThere seems to be some kind of support for in the tty driver for /dev/ttyimxN devices.\nhttps://github.com/torvalds/linux/blob/v4.14/drivers/tty/serial/serial_mctrl_gpio.h\nhttps://github.com/torvalds/linux/blob/v4.14/drivers/tty/serial/imx.c\n```\n    unsigned int        have_rtsgpio:1;\n```\n\nBut how can I set this up with PySerial?\nHow can I specify the GPIO port to use (if at all)?\nThanks for any help !!\nEDIT\nI've found info in the kernel sources that match the kernel on my board.  This describes how to specify the gpio for modem control emulation (software control, instead of hardware control).\nhttps://github.com/ADVANTECH-Corp/linux-imx/blob/adv_4.14.98_2.0.0_ga/Documentation/devicetree/bindings/serial/serial.txt\nSo it seems possible by changing the device tree sources and making a new device tree blob for my system.\nThis should all be independent of pyserial.\nI'm not sure if this can be set/overridden at runtime with an ioctl, which would be handy (instead of having to muck around with kernel sources and building device tree blobs, etc).\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Migrating project to Git/Gerrit. Access control questions?\r\n                \r\nWe're in the process of migrating a moderately-sized project from an old SCMS (CMVC) to Git/Gerrit.  For external auditing purposes, we've implemented strict access controls within CMVC by defining 18 \"components\" and then creating ACLs for each of those components.  Thus, the project exists as a large source tree (with a number of subdirectories, etc) in CMVC but a given developer might only have commit access for one particular subtree.\n\n[note that our 'components' aren't independent, standalone apps or jars or libraries...they're just code subtrees that have specific ACLs needed to satisfy external code audits]\n\nIt's not clear to me how to achieve the same level of access control within Gerrit unless I convert each CMVC component into a separate Git project/repository with its own defined set of access groups.\n\nThe prospect of creating 18 separate projects is worrisome... \n\na) because of the risk of components getting out-of-sync (remember, our components aren't standalone apps or libs), and,\n\nb) the number of Gerrit-mandated code reviews that will be required for committed changes that span components\n\nAlso, the thought of how our continuous integration stuff would identify and undo errant commits involving multiple repositories causes the hair on the back of my neck to stand up.\n\nIs there a better way to achieve a fine-grained access control with Gerrit?\n    ", "Answer": "\r\nA crucial problem here is that Git itself doesn't really have any mechanism for operating only on particular directories in a repository: it's pretty much all-or-nothing.  A particular commit can span multiple directories and there is no way to retrieve (or store) a \"partial\" commit.\n\nYou can implement filters that will reject commits that attempt to modify certain subtrees, but there's nothing you can do to limit pull access to these subtrees.\n\nAccess control in Git is typically implemented per-repository and per-branch.\n\nIf you need the sort of granular access control you have described and splitting the project into multiple repositories isn't an option, you probably need to investigate an alternative to Git for version control.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to force .Net ToString to use given Globalization / CultureInfo\r\n                \r\nI'm working with a piece of .Net Core 6 library (dll), in which, amongst other functionality, numbers and date/time information is outputted as strings and this code is required to be globalized ie. to be culture-aware. The library is for a document producing system, so in the same application session, users would produce documents for de-CH, de-FR, en-US etc. So basically, We would like to have the library culture-aware, but the culture outputted should have it's \"standard\" formats, not the ones customised in Operating system level or user level.\nFor example for decimal values, the library code is using these methods to output stuff:\n```\npublic string ToString();\npublic string ToString(string? format);\npublic string ToString(IFormatProvider? provider)\npublic string ToString(string? format, IFormatProvider? provider)\n```\n\nSo calling these overloads by different users in different computers having different culture-settings, will format the output differently: decimal separator can be comma or point and the thousands grouping delimiter might be non-braking-space or ’ etc.\nHowever, when ```\nprovider```\n argument is passed explicitly by using an instance of a specific culture for example \"fr-CH\" (Swiss-French) and with CultureInfo.UseUserOverride == false, I was expecting always the same output string, independent of user and/or computer. So, I was thinking, that .Net would have \"built-in\" values for all the properties of CultureInfo-instances for all culture-types and with argument ```\nuseUserOverride: false```\n I could force the formatting to use these \"Built-in\" values and hence would output always the same string.\nBut this seems not be the case!\nThe code:\n```\nCultureInfo cultInfo = new CultureInfo(name: \"fr-CH\", useUserOverride: false)       //* fr-CH\" is Swiss-French\nDecimal myDec = -123456789123456.987654321M; \nString output = myDec.ToString(format: \"N4\", provider: cultInfo);       // I was expecting always same output independent, which user is calling it in which computer, but this is not the case!\n```\n\nThis example code was compiled with .Net Core 6 as Console application and I run it on a) a Windows 10 Pro PC and b) on a Windows Server 2012R2 and they had having different outputs.\n\nFr-CH/Windows Pro 10 PC: -123 456 789 123 456,9877\nFr-CH/Windows Server 2012R2: -123'456'789'123'456.9877\n\nThe same by setting ```\nCultureInfo cultInfo = CultureInfo.InvariantCulture```\n: Then the result look always the same, which is expected.\nI also tried setting ```\nThread.CurrentThread.CurrentCulture```\n and ```\nThread.CurrentThread.CurrentUICulture```\n using the ```\ncultInfo```\n-variable the above and then calling ```\nToString(format?, provider?)```\n, but there was no effect: the results were exactly like without setting the ```\nCurrentThread```\n. PS. I actually learned from here, here and here that setting ```\nThread.CurrentThread.CurrentUICulture```\n has nothing to do with formatting (my case), but with translation (resx stuff).\nI'm aware of this vaste piece of Microsoft documentation about ```\nCultureInfo```\n-class, but I cannot see the tree from the forest there.\nMy questions are as follows:\n\nHas any version of .Net Core (or any version .Net Framework) a \"built-in values\" for all CultureInfo-properties at all?\nHow could I force my code to use always exactly the culture given culture independent of the environment?\n\nThis would be very important in order to be able to unit-test the library output in a reliable way.\nLikely important this would be, when reading back (utilizing System.Convert(value, provider?) the values outputted by any user in any computer (just knowing the culture they were outputted).\n    ", "Answer": "\r\nYou can set up a custom culture and configure that one according to your needs.\nStart from an existing neutral one, like the ```\nInvariantCulture```\n.\nMake a clone in order to keep that ```\nInvariantCulture```\n as-is.\n```\nvar clone = CultureInfo.InvariantCulture.Clone() as CultureInfo;\n```\n\nThen make the required changes upon that clone - e.g.:\n```\nclone.NumberFormat.NumberDecimalSeparator = \",\";\nclone.NumberFormat.NumberGroupSeparator = \".\";\n```\n\nOptionally but advisable, you might want to make a readonly version of it.\n```\nvar customCulture = CultureInfo.ReadOnly(clone);\n```\n\nUse that culture wherever you need a fixed controlled output - e.g.:\n```\nvar number = -123456789123456.987654321M;\nvar formattedNumber = number.ToString(\"N4\", customCulture)); // -123.456.789.123.456,9877\n```\n\nApply that same culture when parsing the formatted ```\nstring```\n version back to a ```\ndecimal```\n - e.g.:\n```\nvar parsedNumber = decimal.Parse(formattedNumber, customCulture);\n```\n\n\nIf you are interested in how a ```\nCultureInfo```\n is set up have a look at the source code.\nIn short the ```\nInvariantCulture```\n is one with fixed settings, whereas the others rely on the operating system and optional user overrides.\nFrom the documentation:\n\n.NET derives its cultural data from a one of a variety of sources,\ndepending on implementation, platform, and version:\n\nIn .NET Framework 3.5 and earlier versions, cultural data is provided by both the Windows operating system and .NET Framework.\n\nIn .NET Framework 4 and later versions, cultural data is provided by the Windows operating system.\n\nIn all versions of .NET Core running on Windows, cultural data is provided by the Windows operating system.\n\n\n\n\nBecause of this, a culture available on a particular .NET\nimplementation, platform, or version may not be available on a\ndifferent .NET implementation, platform, or version.\nSome CultureInfo objects differ depending on the underlying platform.\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to serve couple containers with domain names with Docker NGINX image\r\n                \r\nI need to host multiple sites with my docker-machine in future, but know i'm trying to launch it on localhost.\n\nThe main purpose is to get certain site, of course I need to start with my ```\n/etc/hosts```\n file on OS X, below is listing:\n\n```\n127.0.0.1   localhost\n255.255.255.255 broadcasthost\n\n127.0.0.1     dev.proling.ru\n127.0.0.1     dev.vshvetsov.ru\n```\n\n\nThis configuration provide for me access to sites with chosen domains independently of DNS settings. Now I'll show my ```\ndocker-compose.yml```\n:\n\n```\nversion: '2'\n\nservices:\n  mysql:\n    build: mysql/\n    restart: always\n    volumes:\n      - mysql_data:/var/lib/mysql\n    container_name: mysql\n  vshvetsov:\n    depends_on:\n      - mysql\n    build: vshvetsov/\n    ports:\n      - 8000:80\n    restart: always\n    container_name: vshvetsov\n  proling:\n    depends_on:\n      - mysql\n    build: proling/\n    ports:\n      - 8003:80\n    restart: always\n    container_name: proling\n  nginx:\n    depends_on:\n      - proling\n      - vshvetsov\n    image: nginx\n    restart: always\n    ports:\n     - \"80:80\"\n    volumes:\n     - ./nginx/volume:/etc/nginx\n    container_name: nginx\nvolumes:\n    mysql_data:\n```\n\n\nBoth site containers works perfectly on ```\nlocalhost:8000```\n and ```\nlocalhost:8003```\n and below is my ```\nnginx/volume```\n folder tree:\n\n```\nvolume\n    ├── conf.d\n    │   ├── default.conf\n    │   ├── proling.ru\n    │   └── vshvetsov.ru\n    ├── fastcgi_params\n    ├── koi-utf\n    ├── koi-win\n    ├── mime.types\n    ├── modules -> /usr/lib/nginx/modules\n    ├── nginx.conf\n    ├── scgi_params\n    ├── uwsgi_params\n    └── win-utf\n```\n\n\nSo the only way to impact on my NGINX configuration is to put ```\n.conf```\n files in ```\nconf.d```\n directory and below are both of them:\n\ndev.proling.ru\n\n```\nserver {\n    listen  80;\n    server_name  www.proling.ru;\n    rewrite ^ http://proling.ru$request_uri? permanent; #301 redirect\n}\n\nserver {\n    listen 80;\n\n    server_name proling.ru *.proling.ru;\n\n        location / {\n\n            proxy_pass http://proling;\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection 'upgrade';\n            proxy_set_header Host $host;\n            proxy_cache_bypass $http_upgrade;\n\n            access_log /var/log/nginx/proling.ru-access.log;\n        }\n}\n```\n\n\nAnd dev.vshvetsov.ru\n\n```\nserver {\n    listen 80;\n\n    server_name www.vshvetsov.ru vshvetsov.ru dev.vshvetsov.ru;\n\n    location / {\n        proxy_pass http://vshvetsov;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n        access_log /var/log/nginx/vshvetsov.ru-access.log;\n    }\n}\n```\n\n    ", "Answer": "\r\nThe problem solved with rename nginx config files in ```\nconf.d```\n. They must end with ```\n.conf```\n extension because ```\nnginx.conf```\n have this string by default:\n\n```\ninclude /etc/nginx/conf.d/*.conf;\n```\n\n\nOf course I can mount or copy our config if it's more handy, but I prefer default path.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to force gettext to translate a specific language, independently from current language?\r\n                \r\nHow can i tell the function gettext()  to translate a word to a specific language independently from the language currently set?\n\nLet's take an example\n\nLet us assume the default language is english.\nLet's take the word tree. In italian it will be albero.\n\nIf i am browsing the english version of my website, all the content of the page will be translated in english. In particular, if i have in my php code the line ```\necho _('tree');```\n, tree will be outputted.\n\nWhat i would love to accomplish is to output albero when i'm browsing the english version of the website. I would love to tell _() to translate only that specific word in that specific part of the page in italian, even if the current language is in english. In my head it's something like ```\n_('tree', 'it_IT')```\n where it_IT tells the gettext to ignore the English language and override it with with Italian only for that call.\n\nIs it possible to do that with gettext()?\nIf yes, how? If no, any other solutions?\n    ", "Answer": "\r\nUnfortunately, GNU ```\ngettext```\n does not support this.\n\nYou can fake it by temporarily changing your locale:\n\n```\nsetlocale(LC_ALL, 'it_IT');\necho _('tree');\nsetlocale(LC_ALL, 'en_US');\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to reuse a lookup (popup) component for multiple inputs\r\n                \r\nhere is what i am trying to achieve:\nI have a page that consists of a lot of (autocomplete) inputs that are used to select the same type of object (all in a different context).\nEvery single input has to offer the ability to open a popup where the user can do a specific lookup (using more filter options and selecting the desired object from a list of search results).\n\nSo i thought this would be the perfect reusable component and wrote the following composite component:\n\n```\n<cc:interface>\n    <cc:attribute name=\"value\" type=\"MySelectedObjectType\" />\n    <cc:attribute name=\"render\" type=\"java.lang.String\" />\n</cc:interface>\n<cc:implementation>\n    <rich:popupPanel id=\"dialog\" header=\"#{msg.search}\" autosized=\"true\">\n        <h:form id=\"form\">\n            <h:panelGroup class=\"searchPane\" layout=\"block\">\n                <h:panelGrid>\n                    <o:outputLabel for=\"name\" value=\"#{msg.name}\" />\n                    <h:inputText id=\"name\" value=\"#{lookupModel.name}\" />\n\n                    ...\n                </h:panelGrid>\n                <div class=\"extSearchPaneButton-cntr\">\n                    <a4j:commandButton value=\"Suchen\" action=\"#{lookupModel.doSearch}\" render=\"searchResult\" styleClass=\"buttonDefault\" />\n                </div>\n            </h:panelGroup>\n            <h:panelGroup id=\"searchResult\" layout=\"block\" class=\"searchResult-cntr\">\n                <rich:dataTable id=\"resultTable\" value=\"#{lookupModel.searchResults}\" var=\"entry\" >\n                    <rich:column>\n                        #{entry.name}\n                    <rich:column>\n                    ...\n                    <a4j:ajax event=\"rowclick\" listener=\"#{lookupModel.selectionListener}\" />\n                </rich:dataTable>\n            </h:panelGroup>\n            <div class=\"resultButton-cntr\">\n                <a4j:commandButton id=\"apply\" value=\"#{msg.apply}\" execute=\"searchResult\" oncomplete=\"#{rich:component('dialog')}.hide()\"\n                    styleClass=\"button\" render=\"#{cc.attrs.render}\">\n                    <f:setPropertyActionListener target=\"#{cc.attrs.value}\" value=\"#{lookupModel.selected}\" />\n                </a4j:commandButton>\n                <a4j:commandButton id=\"cancel\" value=\"#{msg.cancel}\" onclick=\"#{rich:component('dialog')}.hide(); return false;\"\n                    styleClass=\"button\" />\n            </div>\n        </h:form>\n    </rich:popupPanel>\n</cc:implementation>\n```\n\n\nThe lookupModel is a ViewScoped (with RequestScope it was not possible to select a row in the datatable) ManagedBean independent from the ManagedBean used on the Page (for reusing it in another page).\n\nMy problem is now, that if i have 5 inputs that use this popup, i have to put 5 popups in my page, bloating the component tree and the resulting page size, where only one can be active at a time.\nI wonder what must be done to be able to use only one lookup component on my page and reuse it for every input that needs it. The problem i face is, that i don't know how to handover the targeted value that the lookup should set on apply (see the setPropertyActionListener).\n\nAs a sidenote, every time the lookup is shown it's content is reset (reseting the backing bean and rendering the page content), there's no need to remember the last search results.\n\nThanks in advance.\n    ", "Answer": "\r\nDoubt it would be possible.\n\nFor something like this, I would more or less skip JSF for rendering and make a Javascript that does what your composite component does now. Then change the component so it simply initializes the Javascript with needed data and handles input from the Javascript so it can be parsed to a managed bean.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Gradle Splitting up Testing Tasks with File Structure\r\n                \r\nI'm trying to make my tasks run tests in a certain directory.  I was looking at sourceSets, however I inferred that they are useful if you are running outside the test/groovy folder.  All of my tests are within the test/groovy folder.\n\nI've got a set of Geb tests as well as a set of service tests.  I would like to run them both together and independently.  Essentially my tree structure would look like this, being able to run all tests.\n\n```\nTest\n--gebTest\n----firefoxTest\n----chromeTest\n----ieTest\n--servicesTest\n----service1Test\n----service2Test\n----service3Test\n----etc.\n```\n\n\nMy file structure is as follows:\n\n```\nproject\n-src\n--test\n---groovy\n----com\n-----acme\n------functional <---where my geb tests sit\n------services <---umbrella for services\n-------service1 <---each unique service\n-------service2\n-------service3\n-------etc\n```\n\n\nCan anyone lend me a hand.  For the life of me I don't know how Gradle picks what tests to execute.\n\nThank you in advanced.\n    ", "Answer": "\r\nSourceSets are indeed a solution to your problem, but I notice you only differentiate your tests by their package names. I'm not sure but that may prove problematic with source sets.\n\nPersonally I would prefer a directory structure like this anyway\n\n```\nsrc\n-test\n--groovy\n---functional\n----com etc\n---services\n----com etc\n```\n\n\nHowever, if you are attached to your current structure then take a look at Gradle's test filtering support, which will allow you to filter by package name.\n\nhttp://www.gradle.org/docs/current/userguide/java_plugin.html#sec:java_test\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Using decision tree regression and cross-validation in sklearn\r\n                \r\nI am a novice in statistical methods so please excuse any naivety. I am having a problem understanding the execution of cross validation when using Decision tree regression from sklearn (e.g. DecisionTreeRegressor and RandomForestRegressor). My dataset varies from having multiple predictors (y = single dependent variable; X = multiple independent variables) to having a single predictor and consists of enough cases (> 10k). The following explanation applies for all cases. \n\nWhen fitting and scoring the regressors with the standard methods:\n\n```\ndt = DecisionTreeRegressor()\nrf = RandomForestRegressor()\n\ndt.fit(X,y)\nrf.fit(X,y)\n\ndt_score = dt.score(X,y)\nrf_score = rf.score(X,y)\n```\n\n\nThe dt_score and rf_score returns promising R-squared values (> 0.7), however I am aware of the over-fitting properties of the DT and to lesser extent the RF. Therefore I tried to score the regressors with cross-validation (10 fold) to get a more true representation of the accuracy:\n\n```\ndt = DecisionTreeRegressor()\nrf = RandomForestRegressor()\n\ndt.fit(X,y)\nrf.fit(X,y)\n\ndt_scores = cross_val_score(dt, X, y, cv = 10)\nrf_scores = cross_val_score(rf, X, y, cv = 10) \n\ndt_score = round(sum(dt_scores )/len(dt_scores ), 3)\nrf_score = round(sum(rf_scores )/len(rf_scores ), 3)\n```\n\n\nThe results of this cross validation always returns negative values. I assume they are R squared values according to the sklearn guidlines: By default, the score computed at each CV iteration is the score method of the estimator  (the score method of both the regressors is R squared). The explanation given from the guidelines for the basic KFold cross validation is: Each fold is then used once as a validation while the k - 1 remaining folds form the training set.\n\nHow I understand this, when using 10 old cv, is: my dataset is split into 10 equal parts, for each part the remaining 9 parts are used for training (I am not sure if this is a fit operation or a score operation) and the remaining part is used for validation (not sure what is done for validation). These regressors are a complete \"black box\" for me, so I have no idea on how a tree is used for regression and where the cross validation gets its R square values from. \n\nSo to summarize, I am struggling to understand how the cross validation can decrease the accuracy (R squared) so dramatically? Am I using the cross validation right for a regressor? Does it make sense to use cross validation for a decision tree regressor? Should I be using another cross-validation method?\n\nThank you     \n    ", "Answer": "\r\nHave put together a small code-snippet articulating how on using DecisionTreeRegressor and cross-validation. \n\nA. In the first code-snippet 'cross_val_score' is used. But, r2_score  might have negative score, giving insight about the poor learning by the model. \n\n```\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \ntest_size=0.20, random_state=0)\n\ndt = DecisionTreeRegressor(random_state=0, criterion=\"mae\")\ndt_fit = dt.fit(X_train, y_train)\n\ndt_scores = cross_val_score(dt_fit, X_train, y_train, cv = 5)\nprint(\"mean cross validation score: {}\".format(np.mean(dt_scores)))\nprint(\"score without cv: {}\".format(dt_fit.score(X_train, y_train)))\n\n# on the test or hold-out set\nfrom sklearn.metrics import r2_score\nprint(r2_score(y_test, dt_fit.predict(X_test)))\nprint(dt_fit.score(X_test, y_test))\n```\n\n\nB. In this next section, using cross-validation for performing GridSerach on the parameter 'min_samples_split', then using the best estimator for scoring on the valiation/holdout set. \n    # Using GridSearch:\n    from sklearn.model_selection import GridSearchCV\n    from sklearn.metrics import make_scorer\n    from sklearn.metrics import mean_absolute_error\n    from sklearn.metrics import r2_score\n\n```\nscoring = make_scorer(r2_score)\ng_cv = GridSearchCV(DecisionTreeRegressor(random_state=0),\n              param_grid={'min_samples_split': range(2, 10)},\n              scoring=scoring, cv=5, refit=True)\n\ng_cv.fit(X_train, y_train)\ng_cv.best_params_\n\nresult = g_cv.cv_results_\n# print(result)\nr2_score(y_test, g_cv.best_estimator_.predict(X_test))\n```\n\n\nHoping, this was useful. \n\nReference:\n\nhttps://www.programcreek.com/python/example/75177/sklearn.cross_validation.cross_val_score\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Nested resources - How to avoid redundant routes?\r\n                \r\nI have this resource tree:\n\n\nForum\n\nTopic\n\nPost\n\n\n\n\nI want to be able to access them independently wherever possible. I want to avoid redundant routes like ```\n/forum/:forum_id/topic/:topic_id/post/:id```\n because I can just do ```\n/post/:id```\n. \n\nThe ideal routes look like this:\n\n```\n/forums => Forums#index              # Lists every forum\n/forum/new => Forums#new             # New forum\n/forum/edit => Forums#edit           # Edit forum\n/forum/:id  => Forums#show           # Shows forum\n/forum/:id/forums Forums#index       # Lists nested forums\n/forum/:id/topics => Topics#index    # Lists topics inside forum\n/forum/:id/topic/new => Topics#new   # New topic\n/topics => Topics#index              # Lists every topic\n/topic/:id => Topics#show            # Shows topic\n/topic/:id/posts => Posts#index      # Lists posts inside topic\n/topic/:id/post/new => Posts#new     # New post\n/posts => Posts#index                # Lists every post\n/post/:id => Posts#show              # Shows post\n```\n\n\nWhat is the best way to model this situation?\n\nHere's what I tried:\n\n```\nresources :forums\nresources :topics\nresources :posts\n\nresources :forums do\n  resources :topics\nend\n\nresources :topics do\n  resources :posts\nend\n```\n\n\nThe problem is that these settings create a lot of useless routes, like:\n\n```\n/forums/:forum_id/topic/:id # Redundant - /topic/:id\n/topics/:topic_id/post/:id  # Redundant - /post/:id\n/topics/new                 # No current forum\n/posts/new                  # No current topic\n```\n\n\nIs there any way to specify which routes to create?\n\nIn the controllers, how do I handle multiple routes mapped to the same action? For example, inside ```\nTopics#index```\n how do I find out if I should handle ```\nGET /forum/:id/topics```\n or ```\nGET /topics```\n?\n    ", "Answer": "\r\nNested routes are only needed on ```\nindex```\n actions where a collection of resources is found by a parent object. Otherwise it is about SEO. Most users will not notice how their urls are getting generated nor care so it's all about search engines. I see where you are going but it's going to be more work to not generate routes as the convention in this example is listing a resource with one line of code. And of course you already know this but this is just my take on things.\n\n```\na) forms_path #if you want to find all forms\nb) topics_path #if you want to find all topics #possible use, maybe in a tag listing.\nc) posts_path #if you want to find all posts #probably never use\n```\n\n\nYou will probably never want to find all topics and especially posts, but those would be the routes to use.\n\n```\nd) form_topics_path(form) #find all topics of a given form \ne) form_topic_path(form, topic)  #only find one topic on a give form\nf) topic_path #find a given topic\n```\n\n\nIn the last two, e and f, the form is not needed since you know which topic you want. If you are concerned about SEO and getting your urls nice for search engines then probably want to use e.\n\n```\ng) form_topic_posts_path(form, topic) #I'm already confused \nh) form_topic_post_path(form, topic, post) #still to deep\ni) topic_posts_path(topic) #most rails people think two levels is deep enough\nj) topic_post_path(topic, post) #might be good for seo\n```\n\n\nIt's really a matter of SEO and keeping your urls friendly besides the nested resource that need their parent id to find the associated posts such as passing the ```\nform```\n to find the related topics, and passing the ```\ntopic```\n to find the related posts.\n\nIf you use ```\ntopic_path```\n, ```\ntopics_path```\n ```\npost_path```\n, ```\npost_path```\n you are surly missing out on better urls but in terms of having better urls for engines to read but they really are unnecessary.\n\nIn terms of not generating the routes there really isn't a demand for this because it would makes this more complicated than just declaring a resource in one line where the end goal is just housekeeping.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How do parent famo.us modifiers influence their children?\r\n                \r\nIt seems I'm a bit confused as to how the render tree works, or more specifically how modifiers affect their descendants.\n\nFor example, if I have a render tree that looks like:\n\n```\n                     -------------------\n                     | Global Modifier |\n                     -------------------\n                             |\n            ---------------------------------------\n            |                |                    |\n    ----------------  ----------------   --------------------\n    | Blue Surface |  | Top Left Mod |   | Bottom Right Mod |\n    ----------------  ----------------   --------------------\n                             |                    |\n                      -----------------    ---------------\n                      | Green Surface |    | Red Surface |\n                      -----------------    --------------- \n```\n\n\n\nThe global modifier sets the overall size. \nThe blue surface fills the space. \nAnd the top-left and bottom-right modifiers have smaller sizes and use ```\norigin```\n and ```\nalign```\n to align their child surfaces to in the corners. \n\n\nSo far, so good. It all works well. But if I put a transform on the global modifier, rotating it, for example, what I would expect would be for the whole unit to rotate, but instead it looks like each of my three surfaces are rotating independently around their own origins. \n\nWhy is it doing that? \n\nHow do I turn this into a unit that I can manipulate as a whole? \n\nThanks.\n\nHere's some code:\n\nhttp://jsfiddle.net/scucLw0h/1/\n\n```\nvar Surface = famous.core.Surface;\nvar View = famous.core.View;\nvar Modifier = famous.core.Modifier;\nvar StateModifier = famous.modifiers.StateModifier;\nvar Engine = famous.core.Engine;\nvar Transform = famous.core.Transform;\nvar Transitionable = famous.core.Transitionable;\n\n\nvar globalModifier = new StateModifier({\n    size: [100, 100],\n    origin: [.5, .5],\n    align: [.5, .5]\n});\n\nvar topLeftModifier = new Modifier({\n    size: [50, 50],\n    align: [0, 0],\n    origin: [0, 0]\n});\n\nvar bottomRightModifier = new Modifier({\n    size: [50, 50],\n    align: [1, 1],\n    origin: [1, 1]\n});\n\nvar blueSurface = new Surface({\n    properties: {\n        backgroundColor: 'blue'\n    }\n});\n\nvar redSurface = new Surface({\n    properties: {\n        backgroundColor: 'red'\n    }\n});\n\nvar greenSurface = new Surface({\n    properties: {\n        backgroundColor: 'green'\n    }\n});\n\n\nvar mainContext = Engine.createContext();\n\nvar globalContext = mainContext.add(globalModifier);\n\nglobalContext.add(blueSurface);\n\nglobalContext.add(topLeftModifier).add(greenSurface);\nglobalContext.add(bottomRightModifier).add(redSurface);\n\n\nglobalModifier.setTransform(Transform.rotate(0, 45, 0), {duration: 1000});\n```\n\n    ", "Answer": "\r\nTo have it transition as a whole with respect to the origin point, there needs to be a positioning modifier and a separate transitioning modifier. In your example above, the position modifier is also transitioning the render nodes based on it's own origin. You want it to transition from the root origin of the position (center of context in this case).\n\n```\n                     -------------------\n                     | Global Modifier | <=== Modifier for position\n                     -------------------\n                             |\n                     -------------------\n                     |  Root Modifier  | <=== Modifier that will transition\n                     -------------------        the root node from/to position\n                             |\n            ---------------------------------------\n            |                |                    |\n    ----------------  ----------------   --------------------\n    |   Blue Mod   |  |  Green Mod   |   |     Red Mod      | <=== Positions each renderable\n    ----------------  ----------------   --------------------        with respect to the root\n            |                |                    |\n    ----------------  -----------------    ----------------\n    | Blue Surface |  | Green Surface |    | Red Surface  |\n    ----------------   -----------------    --------------- \n```\n\n\nHere is some code to show how it can be done.  \n\nClick Here for a running example\n\n```\nvar globalModifier = new Modifier({\n  size: [100, 100],\n  origin: [0, 0],\n  align: [0.5, 0.5],\n  transform: Transform.translate(0, 0, 0.0001)\n});\n\nvar rootModifier = new Modifier({\n  size: [undefined, undefined],\n  origin: [0, 0],\n  align: [0, 0],\n  transform: Transform.translate(0, 0, 0.0001)\n});\n\nvar blueModifier = new Modifier({\n  size: [100, 100],\n  origin: [0.5, 0.5],\n  align: [0, 0],\n  transform: Transform.translate(0, 0, 1)\n});\n\nvar greenModifier = new Modifier({\n  size: [50, 50],\n  origin: [0, 0],\n  align: [0, 0],\n  transform: Transform.translate(0, 0, 2)\n});\n\nvar redModifier = new Modifier({\n  size: [50, 50],\n  origin: [1, 1],\n  align: [0, 0],\n  transform: Transform.translate(0, 0, 2)\n});\n\nvar blueSurface = new Surface({\n  content: 'blue',\n  size: [undefined, undefined],\n  classes: ['double-sided'],\n  properties: {\n    color: 'white',\n    textAlign: 'right',\n    backgroundColor: 'blue'\n  }\n});\n\nvar redSurface = new Surface({\n  content: 'red',\n  size: [undefined, undefined],\n  classes: ['double-sided'],\n  properties: {\n    backgroundColor: 'red'\n  }\n});\n\nvar greenSurface = new Surface({\n  content: 'green',\n  size: [undefined, undefined],\n  classes: ['double-sided'],\n  properties: {\n    backgroundColor: 'green'\n  }\n});\n\nvar mainContext = Engine.createContext();\nmainContext.setPerspective(10000);\n\nvar globalContext = mainContext.add(globalModifier);\nvar rootContext = globalContext.add(rootModifier);\n\nrootContext.add(blueModifier).add(blueSurface);\nrootContext.add(greenModifier).add(greenSurface);\nrootContext.add(redModifier).add(redSurface);\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How do I use Clojure in Android Studio using Graclj?\r\n                \r\nMy ultimate goal is to be able to write Clojure apps for Android, using Android Studio and Cursive. I started with leiningen but found out that it is a build system that is independent of what Andoid Studio uses ie Gradle. So I tried leiningen with Intellij, but couldn't get Android deploys to work except from the command line. Since I wanted to integrate with Android Studio, I decided to try Graclj: https://github.com/graclj/graclj which is a Gradle plugin for Clojure.\n\nI can get the Graclj tutorial running in Android Studio, as per this guide:\nhttps://github.com/graclj/learning-graclj/tree/learning-0.1.0\n\nHowever:\n\n\nGraclj expects the Clojure src and built classes and jars to be in the root project\nAndroid Studio expects src and classes to be in the app subproject\nAfter the tutorial I end up with separate Gradle build tasks for Graclj and Android Studio but I don't know how to integrate them\n\n\nSo, can anyone suggest a way that I can hook into Andoid Studio's build process?\n\n\nDo I need to change some settings to the Graclj plugin to do this? If so, how?\nDo I need to change some Android Studio plugin settings?\nDo I need to add/change something in the Gradle build scripts?\nAm I heading down a dead end?  ;-)\n\n\nI have looked at the Android Studio build process: http://developer.android.com/tools/building/configuring-gradle.html\nbut I don't know enough about Gradle to know what I'm supposed to be doing here.\n\nIf I need to supply any more info, just ask.\n\nAny help appreciated!\n    ", "Answer": "\r\nUnfortuantely, I don't have any Android (let alone Android Studio) experience. However, I'll do my best to answer based on Gradle/Graclj knowledge.\n\nGraclj does not require you to use the root project. You can apply the plugin(s) in any of the projects that you have in your build. However, I don't know how well a model-based plugin like Graclj will work with the \"traditional\" Android plugin. You could try the \"experimental\" one that's using the model approach, though there's a decent chance that it won't be compatible unless there's one that works with Gradle 2.12.\n\nAlternatively, you might be able to add a dependency to the Android app project on the JAR produced by Graclj (which you may still want to put in a project besides the root). Not sure if there's a very good way to do this (haven't tried myself).\n\n```\ndependencies {\n   // my-other-proj being whichever one you use Graclj in\n   compile project(':my-other-proj')\n}\n```\n\n\nOr maybe you would need to add it to a configuration first in the ```\nmy-other-proj```\n to interop with traditional plugins:\n\n```\nartifacts {\n   archives createMainJar\n}\n```\n\n\nIt is possible that you're at a dead end (for now). Graclj is very new, so this stuff should all be possible eventually.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Pod mounts wrong directory on Node when a flexvolume with cifs is configured\r\n                \r\nThe following problem occurs on a Kubernetes cluster with 1 master and 3 nodes and also on a single-machine Kubernetes.\n\nI set up the Kubernetes with flexvolume smb support (https://github.com/Azure/kubernetes-volume-drivers/tree/master/flexvolume/smb). When I apply a new pod with flexvolume the Node mounts the smb share as expected. But the Pod points his share to some docker directory on the Node.\n\nMy installation:\n\n\nlatest CentOS 7\nlatest Kubernetes v1.14.0\n(https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/)\ndisabled SELinux and disabled firewall\nDocker 1.13.1\njq and cifs-utils\nhttps://raw.githubusercontent.com/Azure/kubernetes-volume-drivers/master/flexvolume/smb/deployment/smb-flexvol-installer/smb installed to /usr/libexec/kubernetes/kubelet-plugins/volume/exec/microsoft.com~smb and executable\n\n\nCreate Pod with\n\nsmb-secret.yaml\n\n```\napiVersion: v1\nkind: Secret\nmetadata:\n  name: smb-secret\ntype: microsoft.com/smb\ndata:\n  username: YVVzZXI=\n  password: YVBhc3N3b3Jk\n```\n\n\nnginx-flex-smb.yaml\n\n```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-flex-smb\nspec:\n  containers:\n  - name: nginx-flex-smb\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n  volumes:\n  - name: test\n    flexVolume:\n      driver: \"microsoft.com/smb\"\n      secretRef:\n        name: smb-secret\n      options:\n        source: \"//<host.with.smb.share>/kubetest\"\n        mountoptions: \"vers=3.0,dir_mode=0777,file_mode=0777\"\n```\n\n\nWhat happens\n\n\nMount point on Node is created on ```\n/var/lib/kubelet/pods/bef26895-5ac7-11e9-a668-00155db9c92e/volumes/microsoft.com~smb```\n.\n```\nmount```\n returns ```\n//<host.with.smb.share>/kubetest on /var/lib/kubelet/pods/bef26895-5ac7-11e9-a668-00155db9c92e/volumes/microsoft.com~smb/test type cifs (rw,relatime,vers=3.0,cache=strict,username=aUser,domain=,uid=0,noforceuid,gid=0,noforcegid,addr=172.27.72.43,file_mode=0777,dir_mode=0777,soft,nounix,serverino,mapposix,rsize=1048576,wsize=1048576,echo_interval=60,actimeo=1)```\n\nread and write works as expected on host and on the Node itself\non Pod\n\n\n```\nmount```\nfor /data points to ```\ntmpfs on /data type tmpfs (rw,nosuid,nodev,seclabel,size=898680k,nr_inodes=224670,mode=755)```\n\nbut the content of the directory /data comes from ```\n/run/docker/libcontainerd/8039742ae2a573292cd9f4ef7709bf7583efd0a262b9dc434deaf5e1e20b4002/```\n on the node.\n\n\n\nI tried to install the Pod with a PersistedVolumeClaime and get the same problem. Searching for this problem got me no solutions.\n\nOur other pods uses GlusterFS and heketi which works fine.\n\nIs there maybe a configuration failure? Something missing?\n\nEDIT: Solution\nI upgraded Docker to the latest validated Version 18.06 and everything works well now.\n    ", "Answer": "\r\nI upgraded Docker to the latest validated Version 18.06 and everything works well now.\n\nTo install it follow the instructions on Get Docker CE for CentOS.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "\"Subforms\" associated with tree view in VB\r\n                \r\nI am using VB Express 2008 to demonstrate my ideas for an improved UI for an existing product for my colleagues at work.\n\nThe current UI has a certain page with ten tabs, allowing the user to define up to ten \"things\". The available choices for each of the ten \"things\" are all the same. On each of the ten tabs, there is a checkbox to enable that definition. Generally, a user will never use more than 5 or 6 unique definitions, the rest will remain disabled.\n\nSo far, my prototype has a tree view control with one branch to contain this list of definitions, Add and Delete buttons. My idea is: there is one sub-branch to start with (corresponding to the first tab in the current UI); if the user wants addtional definitions, they click Add and other branches are added to the tree view, up to maximum of ten. \n\nI think I should be able to create a \"class\" that has a sub-UI (like a sub-form in Access) along with behavior code, that can be instantiated with each press of the Add button; each instantiation's settings can be set independently and is displayed in the main UI form )in a panel or frame) when selected in the tree view. For example, suppose the user Adds to make a total of three definitions: the tree view now has three sub-branches, each of which presents the same sub-UI with settings that can be set specific to the selected sub-branch. I'm sure it's possible but not sure how to do it.\n\nI know a comprehensive \"answer\" might be complicated and long, but I may just need some quick hints to get underway - don't be shy! Thanks in advance!\n    ", "Answer": "\r\nIf I understand correctly I think that what you're looking for is a ```\nUser Control```\n. This link contains more information: http://msdn.microsoft.com/en-us/library/c316f119%28VS.71%29.aspx\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Multi level Gradle projects with relative configuration\r\n                \r\nIs it possible to set up a project tree in gradle so each subtree builds independently?\n\nIn the example directory (project) structure:\n\n```\nA\n+  B1\n   +  C1\n   +  C2\n+  B2\n   +  C4\n   +  C5\n```\n\n\nYou should be able to build B1 by itself (will build C1 and C2) as well as A (which will build all 7 projects)\n\nProblem 1: A ignores B1 configuration\n\nA/B1/setting.gradle:\n\n```\ninclude \"C1\", \"C2\"\n```\n\n\nin A, executing \"gradle projects\" command will show B1 but not C1 or C2.\n\nProblem 2: Relative dependencies\n\nIf C1 depends on C2, the only way to specify this is absolute path. This means that it will work for either A or B1, but not for both:\n\n```\nproject(':B1:C2') // works for B1 but not for A\nor\nproject(':A:B1:C2') // works for A but not for B1\n```\n\n\nIs this directory structure possible, where I can build A, B1 and B2 separatelly?\n    ", "Answer": "\r\nAFAIK you can only have one settings.gradle in the root project and there are no ways of grouping hierarchical projects into subgroups.\n\nYou can have multiple levels in your settings.gradle though:\n\n```\ninclude \"b1\",\n        \"b1:c1\",\n        \"b1:c2\",\n        \"b2\",\n        \"b2:c4\",\n        \"b2:c5\"\n```\n\n\nThis will build all projects if you execute gradle in the root but it won't build just b1, c1, and c2 if you execute it in b1.\n\nI'm not really sure what you want to accomplish here, but maybe task dependencies can fix what you're after:\n\nb1/build.gradle:\n\n```\ntasks.jar.dependsOn += [\n    project(\":b1:c1\").tasks.jar,\n    project(\":b1:c2\").tasks.jar\n]\n```\n\n\nRunning the jar task:\n\n```\n$ gradle -p b1 jar\n:b1:compileJava UP-TO-DATE\n:b1:processResources UP-TO-DATE\n:b1:classes UP-TO-DATE\n:b1:c1:compileJava UP-TO-DATE\n:b1:c1:processResources UP-TO-DATE\n:b1:c1:classes UP-TO-DATE\n:b1:c1:jar\n:b1:c2:compileJava UP-TO-DATE\n:b1:c2:processResources UP-TO-DATE\n:b1:c2:classes UP-TO-DATE\n:b1:c2:jar\n:b1:jar\n\nBUILD SUCCESSFUL\n\nTotal time: 0.761 secs\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "multiple data lines for each person in my set\r\n                \r\nSo basically, I have a data set that looks similar to this:\n\nPerson|Class|Score\n\nDavid, Comp sci, A\nDavid, English, B\nDavid, Chemistry, A\nLaura, Chemistry, A\nHenry, English, D\nHenry, French, A\nHenry, Art, B\nClara, Comp Sci, B\nClara, English, A\n\nSo the idea here is that I put in my own set, for example,\nMe:\n  Chemistry, B\n    English, A\nComp Sci, B\n\nIf you look at the data set, you will see that my classes are most similar to David. I want my program to sort the names from most to least similar. Except in this case, David is NOT the most similar. It will actually be Clara. Here is the idea: Clara has two classes that are exactly the same as my classes. David has all the same classes, but his grades are only slightly off to mine. So, I won't worry about the math of getting to that, since the idea of whether a person's grade is more relevant or the number of classes is. \n\nSo here is my question: how would I organize something like this in python for machine learning? I would know what to do if there was one name for each line, but in this case a person can take multiple classes. These multiple occurrences are not independent events. The thing I have in mind is that I want the program to give weight to given students based on their similarity to me. For example, I could say that \"Because Clara has more similarity to me, when I order a pizza, her telling me she wants pepperoni is more likely to have me order pepperoni than anything that Henry suggests, since Henry doesn't have similar taste to me in anything. However, if she likes pepperoni but I absolutely hate pepperoni (or everyone else hates pepperoni), then I will completely ignore her request.\". So, I am adding a weighted \"score\" per se based on their similarity. \n\nI have two additional questions: How would I deal with a set of keywords for people? for example, for things learned in each class, I could say \"David, comp sci, A, (time complexity, binary trees, if statements)\". I would want to use this to find which class best matches these keywords. So, if I ask what has binary trees and time complexity, the program would spit out computer science based on everyone's keywords for it.\nThe other question is, what algorithm would work best? It seems to me that decision trees would work best in my case, but I am not sure.\n    ", "Answer": "\r\nHere is a basic implementation demonstrating what I said in my comment. I leave keywords, parsing results, and extending as an exercise to you, ask any questions you want and I will amend this post with any details. \n\nYou can do exactly the same with the keywords and if you'd like to preserve them or the classes, that is doable. The further usage of the results MAY make use of ML, but my intuition says there are still simpler methods there too.\n\nAlso, determining the exact value that classes should be and grades is another task. This can heavily influence the results. As you're deciding whether classes or grades are more important...This will heavily depend on usage case, you could even have \"bias slider\" to change it as you need. \n\nHere is a fairly robust scoring function:\n\n```\nscores[name] += (2*(2-bias)) - (bias * abs(data_point[1] - pivot_point[1]))```\n\n\n```\nimport numpy as np\n\npeople = \"\"\"David, Comp Sci, A\nDavid, English, B\nDavid, Chemistry, A\nLaura, Chemistry, A\nHenry, English, D\nHenry, French, A\nHenry, Art, B\nClara, Comp Sci, B\nClara, English, A\nOrbDeceptionist, Chemistry, B\nOrbDeceptionist, English, A\nOrbDeceptionist, Comp Sci, B\"\"\"\n\n\ndef get_names(dataset):\n    names = []\n\n    for line in dataset.split('\\n'):\n        name = line.split(',')[0]\n        if name not in names:\n            names.append(name)\n\n    return names\n\n\ngrade_table = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'F': 4}\ndef get_classes(dataset, person):\n    classes = []\n\n    for line in dataset.split('\\n'):\n        name, subject, grade = line.split(',')\n        if name == person:\n            classes.append((subject, grade_table[grade.strip(' ')]))\n\n    return classes\n\n\ndef most_similar(dataset, pivot, bias=0.3):\n    pivot_data = get_classes(dataset, pivot)\n\n    scores = {}\n\n    names = get_names(dataset)\n\n    for name in names:\n        person_data = get_classes(dataset, name)\n\n        for pivot_point in pivot_data:\n            for data_point in person_data:\n                if data_point[0] == pivot_point[0]:\n                    if name not in scores:\n                        scores[name] = 0\n\n                    scores[name] += (2*(2-bias)) - (bias * abs(data_point[1] - pivot_point[1]))\n\n    scores.pop(pivot)\n    # You don't want to round in your final version, this is just to make it cleaner to see for the example.\n    for k, v in scores.items():\n        scores[k] = round(v)\n\n    return scores\n\n\nprint('High bias favors grades, low bias favors classes.')\nfor b in np.arange(0.0, 1.1, 0.1):\n    print('bias:', b, \"|\", most_similar(people, \"OrbDeceptionist\", b))\n```\n\n\nResults: \n\n```\nHigh bias favors grades, low bias favors classes.\nbias: 0.0 | {'Henry': 4.0, 'Laura': 4.0, 'Clara': 8.0, 'David': 12.0}\nbias: 0.1 | {'Henry': 4.0, 'Laura': 4.0, 'Clara': 8.0, 'David': 11.0}\nbias: 0.2 | {'Henry': 3.0, 'Laura': 3.0, 'Clara': 7.0, 'David': 10.0}\nbias: 0.3 | {'Henry': 2.0, 'Laura': 3.0, 'Clara': 7.0, 'David': 9.0}\nbias: 0.4 | {'Henry': 2.0, 'Laura': 3.0, 'Clara': 6.0, 'David': 8.0}\nbias: 0.5 | {'Henry': 2.0, 'Laura': 2.0, 'Clara': 6.0, 'David': 8.0}\nbias: 0.6 | {'Henry': 1.0, 'Laura': 2.0, 'Clara': 6.0, 'David': 7.0}\nbias: 0.7 | {'Henry': 0.0, 'Laura': 2.0, 'Clara': 5.0, 'David': 6.0}\nbias: 0.8 | {'Henry': -0.0, 'Laura': 2.0, 'Clara': 5.0, 'David': 5.0}\nbias: 0.9 | {'Henry': -0.0, 'Laura': 1.0, 'Clara': 4.0, 'David': 4.0}\nbias: 1.0 | {'Henry': -1.0, 'Laura': 1.0, 'Clara': 4.0, 'David': 3.0}\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How do I set the accessible text for TreeView items when using HierarchicalDataTemplates and multiple item types?\r\n                \r\nI have an application with a ```\nTreeView```\n control that is built using a set of data types representing different levels in the hierarchy and an accompanying set of ```\nHierarchicalDataTemplate```\ns.  What I want to do now is set appropriate ```\nAutomationProperties.Name```\n values on the tree items.\n\nNormally, I would use ```\nTreeView.ItemContainerStyle```\n to bind the accessible name, but this is rather limited, as it requires I use a binding path that works for all types.\n\nIn this case, however, I would much rather be able to control the accessible name independently for each type.  For example, it may be useful to include ```\nId```\n in some layers, but not in others.\n\nI could probably live with using the displayed text, but while I can easily use a ```\nRelativeSource```\n binding in ```\nTreeView.ItemContainerStyle```\n to get at the ```\nTreeViewItem```\n, the ```\nPath```\n needed to ultimately reach the ```\nTextBlock.Text```\n value in the templated item from there eludes me.\n\nI have also tried using ```\nHierarchicalDataTemplate.ItemContainerStyle```\n, but that only applies to child items.  Even further, when I tried to define it on each template, only ```\nBazItem```\ns were properly set, even though I would have expected ```\nBarItem```\ns to work as well.\n\nI put together a minimal example to illustrate the issue.  The item types are as follows:\n\n```\npublic sealed class BazItem\n{\n    public BazItem(int id, string name)\n    {\n        Id = id;\n        Name = name ?? throw new ArgumentNullException(nameof(name));\n    }\n\n    public int Id { get; }\n    public string Name { get; }\n}\n\npublic sealed class BarItem\n{\n    public BarItem(int id, string display)\n    {\n        Id = id;\n        Display = display ?? throw new ArgumentNullException(nameof(display));\n        Bazs = new ObservableCollection<BazItem>();\n    }\n\n    public int Id { get; }\n    public string Display { get; }\n    public ObservableCollection<BazItem> Bazs { get; }\n}\n\npublic sealed class FooItem\n{\n    public FooItem(int id, string name)\n    {\n        Id = id;\n        Name = name ?? throw new ArgumentNullException(nameof(name));\n        Bars = new ObservableCollection<BarItem>();\n    }\n\n    public int Id { get; }\n    public string Name { get; }\n    public ObservableCollection<BarItem> Bars { get; }\n}\n```\n\n\nThe corresponding templates are as follows:\n\n```\n<HierarchicalDataTemplate DataType=\"{x:Type local:BazItem}\">\n    <TextBlock Text=\"{Binding Name, StringFormat='baz: {0}'}\"/>\n</HierarchicalDataTemplate>\n<HierarchicalDataTemplate DataType=\"{x:Type local:BarItem}\"\n                          ItemsSource=\"{Binding Bazs}\">\n    <TextBlock Text=\"{Binding Display, StringFormat='bar: {0}'}\"/>\n</HierarchicalDataTemplate>\n<HierarchicalDataTemplate DataType=\"{x:Type local:FooItem}\"\n                          ItemsSource=\"{Binding Bars}\">\n    <TextBlock Text=\"{Binding Name, StringFormat='foo: {0}'}\"/>\n</HierarchicalDataTemplate>\n```\n\n\nFinally, the tree view in the view is as follows:\n\n```\n<TreeView ItemsSource=\"{Binding Foos}\"/>\n```\n\n\nwhere Foos is an ```\nObservableCollection<FooItem>```\n property on the underlying view.\n    ", "Answer": "\r\nThe solution I came up with for now (pending a better answer) is to change the ```\nTreeView.ItemContainerStyle```\n to use a value converter against the tree item object rather than a property on the object:\n\nTreeView element:\n\n```\n<TreeView ItemsSource=\"{Binding ElementName=View, Path=Foos}\">\n    <TreeView.ItemContainerStyle>\n        <Style TargetType=\"{x:Type TreeViewItem}\">\n            <Setter Property=\"AutomationProperties.Name\" Value=\"{Binding Converter={StaticResource AccessibleConverter}}\"/>\n        </Style>\n    </TreeView.ItemContainerStyle>\n</TreeView>\n```\n\n\nConverter:\n\n```\n[ValueConversion(typeof(object), typeof(string), ParameterType = typeof(Type))]\npublic sealed class AccessibleTextConverter : IValueConverter\n{\n    public object Convert(object value, Type targetType, object parameter, CultureInfo culture)\n    {\n        switch (value)\n        {\n            case FooItem foo:\n                return $\"foo: {foo.Name}\";\n            case BarItem bar:\n                return $\"bar: {bar.Display}\";\n            case BazItem baz:\n                return $\"baz: {baz.Name}\";\n            default:\n                return Binding.DoNothing;\n        }\n    }\n\n    public object ConvertBack(object value, Type targetType, object parameter, CultureInfo culture)\n    {\n        throw new NotImplementedException();\n    }\n}\n```\n\n\nThis works, but it's less-than-ideal for several reasons:\n\n\nit duplicates the format strings (though I could pull them out into a shared resource location)\nthe value converter has to first convert ```\nobject```\n to the appropriate type before it can come up with the appropriate string format\nadding a new tree item type requires I touch both the templates as well as the value converter\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Calculating the probability of system failure in a distributed network\r\n                \r\nI am trying to build a mathematical model of the availability of a file in a distributed file-system. I posted this question at MathOverflow but this might as well be classified as a CS-question so I give it a shot here as well.\nThe system works like this: a node stores a file (encoed using erasure codes) at r*b remotes nodes, where r is the replication-factor and b is an integer constant. Erasure-coded files have the property that the file can be restored iff at least b of the remote nodes are available and return its part of the file.\nThe simplest approach to this is to assume that all remote nodes are independent of each other and have the same availability p. With these assumptions the availability of a file follows the Binomial distribution, i.e. \nUnfortunately these two assumptions can introduce a non-neligible error, as shown by this paper: http://deim.urv.cat/~lluis.pamies/uploads/Main/icpp09-paper.pdf.\nOne way to overcome the assumption that all nodes have the same availability is to calculate the probability of each possible combination of availaible/non-available node and take the sum of all these outcomes (which is sort of what they suggest in the paper above, just more formally than what I just described). You can see this approach as a binary tree with depth r*b and each leave is one possible combination of available/not-available nodes. The file's availability is the same thing as the probablity that you arrive at a leave with >=b available nodes. This approach is more correct but has a computational cost of . Also, it doesn't deal with the assumption of node independence.\nDo you guys have any ideas of a good approximation which introduces less error than the binomial distribution-aproximation but with better computational cost than ?\nYou can assume that the availability-data of each node is a set of tuples consisting of ```\n(measurement-date, node measuring, node being measured, succes/failure-bit)```\n. With this data you could for example calculate the correlation of the availability between the nodes and the availability variance.\n    ", "Answer": "\r\nFor large ```\nr```\n and ```\nb```\n you can use a method called Monte-Carlo integration, see e.g. Monte Carlo integration on Wikipedia (and/or chapter 3.1.2 of SICP) to compute the sum. For small ```\nr```\n and ```\nb```\n and significantly different node-failure probabilities ```\np[i]```\n the exact method is superior. The exact definition of small and large will depend on a couple of factors and is best tried out experimentally.\n\nSpecific sample code: This is a very basic sample code (in Python) to demonstrate how such a procedure could work:\n\n```\ndef montecarlo(p, rb, N):\n    \"\"\"Corresponds to the binomial coefficient formula.\"\"\"\n    import random\n    succ = 0\n\n    # Run N samples\n    for i in xrange(N):\n        # Generate a single test case\n        alivenum = 0\n        for j in xrange(rb):\n            if random.random()<p: alivenum += 1\n        # If the test case succeeds, increase succ\n        if alivenum >= b: succ += 1\n    # The final result is the number of successful cases/number of total cases\n    # (I.e., a probability between 0 and 1)\n    return float(succ)/N\n```\n\n\nThe function corresponds to the binomial test case and runs ```\nN```\n tests, checking if ```\nb```\n nodes out of ```\nr*b```\n nodes are alive with a probability of failure of ```\np```\n. A few experiments will convince you that you need values of ```\nN```\n in the range of thousands of samples before you can get any reasonable results, but in principle the complexity is ```\nO(N*r*b)```\n. The accuracy of the result scales as ```\nsqrt(N)```\n, i.e., to increase accuracy by a factor of two you need to increase ```\nN```\n by a factor of four. For sufficiently large ```\nr*b```\n this method will be clearly superior.\n\nExtension of the approximation: You obviously need to design the test case such, that it respects all the properties of the system. You have suggested a couple of extensions, some of which can be easily implemented while others can not. Let me give you a couple of suggestions:\n\n1) In the case of distinct but uncorrelated ```\np[i]```\n, the changes of the above code are minimal: In the function head you pass an array instead of a single float ```\np```\n and you replace the line ```\nif random.random()<p: alivenum += 1```\n by\n\n```\nif random.random()<p[j]: alivenum += 1\n```\n\n\n2) In the case of correlated ```\np[i]```\n you need additional information about the system. The situation I was referring to in my comment could be a network like this:\n\n```\nA--B--C\n   |  |\n   D  E\n   |\n   F--G--H\n      |\n      J\n```\n\n\nIn this case ```\nA```\n might be the \"root node\" and a failure of node ```\nD```\n could imply the automatic failure with 100% probability of nodes ```\nF```\n, ```\nG```\n, ```\nH```\n and ```\nJ```\n; while a failure of node ```\nF```\n would automatically bring down ```\nG```\n, ```\nH```\n and ```\nJ```\n etc. At least this was the case I was referring to in my comment (which is a plausible interpretation since you talk about a tree structure of probabilities in the original question). In such a situation you would need modify the code that ```\np```\n refers to a tree structure and ```\nfor j in ...```\n traverses the tree, skipping the lower branches from the current node as soon as a test fails. The resulting test is still whether ```\nalivenum >= b```\n as before, of course.\n\n3) This approach will fail if the network is a cyclic graph that cannot be represented by a tree structure. In such a case you need to first create graph nodes that are either dead or alive and then run a routing algorithm on the graph to count the number of unique, reachable nodes. This won't increase the time-complexity of the algorithm, but obviously the code complexity.\n\n4) Time dependence is a non-trivial, but possible modification if you know the m.t.b.f/r (mean-times-between-failures/repairs) since this can give you the probabilities ```\np```\n of either the tree-structure or the uncorrelated linear ```\np[i]```\n by a sum of exponentials. You will then have to run the MC-procedure at different times with the corresponding results for ```\np```\n.\n\n5) If you merely have the log files (as hinted in your last paragraph) it will require a substantial modification of the approach which is beyond what I can do on this board. The log-files would need to be sufficiently thorough to allow to reconstruct a model for the network graph (and thus the graph of ```\np```\n) as well as the individual values of all nodes of ```\np```\n. Otherwise, accuracy would be unreliable. These log-files would also need to be substantially longer than the time-scales of failures and repairs, an assumptions which may not be realistic in real-life networks.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Netbeans project to scripted build\r\n                \r\nI'm trying to convert a Netbeans 6.9.1 project into a scripted build (without netbeans). Of course, it fails (or I wouldn't be asking for help). \n\nIn the failure it says that the org.apache.commons.httpclient package does not exist. (Of course, it worked when we ran the build in Netbeans). \n\nNow I know exactly where the commons-httpclient.jar file is located in my project structure, but I can't seem to tell it to the compiler via the ant build files and the netbeans property files.\n\nPerhaps related to this is when I ran \"ant -v\" to build my software, it said, \n\nProperty lib.mystuff.classpath has not been set. This variable is important, I guess, because \n\nthe file nbproject/project.properties uses lib.mystuff.classpath in its definition of javac.classpath, which of course tells the Java compiler where to find the JARs. \n\nSo...when moving a Netbeans project to a netbeans-independent scripted build, how can the build script set these properties? Also, how can I ensure that the jar file gets included in the ant build?\n\nI appreciate any help I can get, as I am a Java newbie. \n\nUPDATE AFTER ACCEPTING ANSWER FROM vkraemer: \n\nThere are a few best practices for build scripts for production software:\n\n\nPut everything needed for a build under a single directory tree. (Netbeans = fail)\nPut everything in source code control.  (I did that)\nThe first line of the build script should clear all environment variables. \nThe next section of the build script should explicitly set all environment variables to values which are known to work.\nThe next part of the build should be able to execute using command-line programs such as javac, ant, cc, etc, and must not depend on firing up an IDE such as Eclipse or Netbeans. \n\n\nIt is a shame that Netbeans makes this hard. \n    ", "Answer": "\r\nI did a quick look in a Java Application project and found the following...\n\njavac.classpath = ${libs.MyStuff.classpath}\n\nlibs.MyStuff.classpath is defined in %HOME%/.netbeans/6.9.1/build.properties.\n\nYou may be able to get by doing the following...\n\nant -Dlibs.MyStuff.classpath=c:\\a\\b\\c.jar\n\nYou would need to do more if you have multiple jar files in the MyStuff library that you created in NetBeans.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Will non-linear regression algorithms perform better if trained with normally distributed target values?\r\n                \r\nAfter finding out about many transformations that can be applied on the target values(y column), of a data set, such as box-cox transformations I learned that linear regression models need to be trained with normally distributed target values in order to be efficient.(https://stats.stackexchange.com/questions/298/in-linear-regression-when-is-it-appropriate-to-use-the-log-of-an-independent-va)\n\nI'd like to know if the same applies for non-linear regression algorithms. For now I've seen people on kaggle use log transformation for mitigation of heteroskedasticity, by using xgboost, but they never mention if it is also being done for getting normally distributed target values.\n\nI've tried to do some research and I found in Andrew Ng's lecture notes(http://cs229.stanford.edu/notes/cs229-notes1.pdf) on page 11 that the least squares cost function, used by many algorithms linear and non-linear, is derived by assuming normal distribution of the error. I believe if the error should be normally distributed then the target values should be as well. \nIf this is true then all the regression algorithms using least squares cost function should work better with normally distributed target values. \n\nSince xgboost uses least squares cost function for node splitting(http://cilvr.cs.nyu.edu/diglib/lsml/lecture03-trees-boosting.pdf - slide 13)  then maybe this algorithm would work better if I transform the target values using box-cox transformations for training the model and then apply inverse box-cox transformations on the output in order to get the predicted values.\nWill this theoretically speaking give better results?\n    ", "Answer": "\r\nYour conjecture \"I believe if the error should be normally distributed then the target values should be as well.\" is totally wrong. So your question does not have any answer at all since it is not a valid question.\n\nThere are no assumptions on the target variable to be Normal at all.\n\nGetting the target variable transformed does not mean the errors are normally distributed. In fact, that may ruin normality. \n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to structure a more complex Angular 2 application?\r\n                \r\nI am currently doing some research about Angular 2 and it seems like a lot of stuff changes so i wanted to rebuild a very common use case for my projects which looks something like this in Angular 1 to get the basics. But i stumbled upon some general questions about how to structure an Angular 2 application.\n\nLet me give you an example how i solve this in Angular 1 right now.\n\n\nBasically it is not a single page application\nI just use directives to extend the DOM\nI do not need a routing\n\n```\n<html ng-app=my-app>\n\n  <head></head>\n  <body>\n\n    <my-autocomplete></my-autocomplete>\n\n    <!-- Some server side code -->\n\n    <my-navigation-menu></my-navigation-menu>\n\n    <!-- Some server side code -->\n\n    <my-main-app>\n\n        <my-filter facet=\"one\" />\n        <my-filter facet=\"two\" />\n        <my-filter facet=\"three\" />\n\n    </my-main-app>\n  </body>\n\n</html>\n```\n\n\n\nNow for the Angular 2 structure. \n\n```\n<head>\n    <base href=\"/elasticsearch_frontend/\">\n    <title>Angular 2 QuickStart</title>\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n    <link rel=\"stylesheet\" href=\"styles.css\">\n\n    <!-- 1. Load libraries -->\n    <!-- 2. Configure SystemJS -->\n    <script>\n        System.config({\n            packages: {\n                myapp: {\n                    format: 'register',\n                    defaultExtension: 'js'\n                }\n            }\n        });\n        System.import('myapp/main')\n                .then(null, console.error.bind(console));\n    </script>\n</head>\n\n<!-- 3. Display the application -->\n<body>\n\n<my-autocomplete></my-autocomplete>\n\n    <!-- Some server side code -->\n\n<my-main-app></my-app>\n```\n\n\nSo the problem is the following:\n\nIt seems like that everything must be in the root of the application. I am more used to the Angular 1 style, where i used to use the directives to html tree. Now in Angular 2 i used the application component as a container to initialize my application. \n\n\nSo how could i structure my components to achive a similar result in Angular 2?\nMight it be better to build two independent applications instead? One for the autocomplete and one for the main application, even if they share the same resources (currently via a service)\n\n\nI think that i do not need the template in the app.component.ts but if i remove it i will get this error: angular2.dev.js:23730 ORIGINAL EXCEPTION: Component 'AppComponent' must have either 'template' or 'templateUrl' set. Like said before, i just want to extend the DOM and initialize the directives in one place.\n\n\n\nmain.ts\n\n```\nimport {bootstrap}    from 'angular2/platform/browser';\nimport {ROUTER_PROVIDERS} from 'angular2/router';\n\nimport {AppComponent} from './app.component';\n\nbootstrap(AppComponent, [ROUTER_PROVIDERS]);\n```\n\n\napp.ts\n\n```\nimport {Component, OnInit} from 'angular2/core';\nimport {RouteConfig, ROUTER_DIRECTIVES} from 'angular2/router';\n\nimport {SearchService} from './search.service';\nimport {CatalogComponent} from './catalog.component';\nimport {AutocompleteComponent} from './autocomplete.component';\n\n@Component({\n    selector: 'my-app',\n\n\n    template: `\n          <h1>{{title}}</h1>\n    `,\n    directives: [AutocompleteComponent],\n    providers: [\n        SearchService\n    ]\n})\n\nexport class AppComponent implements OnInit {\n    public title = 'Elasticsearch Products Prototype';\n\n    public queryParams : String[] = [];\n\n\n    ngOnInit() {\n\n    }\n}\n```\n\n    ", "Answer": "\r\nMicronyks is right : Components annotations (@Component) need a template or templateUrl attribute whereas Directices annotations dont - so consider using directives if you don't need html to replace.\n\nAbout the structure, if you take a look at TourOfHeroes Google tutorial (https://angular.io/docs/ts/latest/tutorial/) you will find out that you need  :\n\n\nindex.html with JS scripts included and xx-app tag\nmain.ts file including bootstrap App component\napp.component.ts with template containing many xxx-xxx tags\n\n\nAnd for your folder structure you can have a folder for your components, services, templates,..\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Parallelizing gradle tasks like GNU Makefile\r\n                \r\nI followed the tutorial in https://guides.gradle.org/using-the-worker-api/ and got the example working. Summary: It's about parallelization of tasks in a gradle run, supported since version 4.0, and the gradle team obviously thinks they have a nice solution.\n\nThis is, in contrast, what a Makefile does (with the same paths, for comparison):\n\n```\nall: md5 sha256\n\nclean:\n    $(RM) -r build\n\nbuild/md5/%.md5: src/%\n    mkdir -p build/md5/\n    md5sum $< >$@\n    sleep 3\n\nbuild/sha256/%.sha256: src/%\n    mkdir -p build/sha256/\n    sha256sum $< >$@\n    sleep 3\n\nmd5: $(patsubst src/%,build/md5/%.md5,$(wildcard src/*))\nsha256: $(patsubst src/%,build/sha256/%.sha256,$(wildcard src/*))\n```\n\n\nAs you can see: i added also sha256 tasks (targets in Makefile \"language\"). The dependency tree for the all target looks like this:\n\n```\nall + md5    + build/md5/feynman.txt.md5\n    |        | build/md5/oppenheimer.txt.md5\n    |        \\ build/md5/einstein.txt.md5\n    \\ sha256 + build/sha256/feynman.txt.sha256\n             | build/sha256/oppenheimer.txt.sha256\n             \\ build/sha256/einstein.txt.sha256\n```\n\n\nAll targets in level 3 (the filename targets) are executed in parallel, when called with ```\nmake -j 6```\n or higher, the resulting time is 3 seconds (with the sleep)\n\nIn contrast, the extended build.gradle:\n\n```\ntask md5(type: CreateMD5) {\n    destinationDir = file(\"${buildDir}/md5\") \n    source file(\"src/\") \n}\n\ntask sha256(type: CreateMD5 /*enough for the example*/) {\n    destinationDir = file(\"${buildDir}/sha256\") \n    source file(\"src/\") \n}\n\ntask all(dependsOn: [md5, sha256])\n```\n\n\ndoesn't scale that well. It has two parallelizable tasks which in parallel process 3 files each because the tasks are designed to do that, but gradle is not smart enough to parallelize the two tasks md5 and sha256 even when they are completely independent. So the resulting time is 6 seconds (2*3)\n\nNow: for a more complex scenario, I need to chain even more different actions and parallelize them. for example 10 slightly different chains of dependent pack->upload->remote-build tasks which should all run in parallel until everything is up and then continue with non-parallel testing.\n\nIn GNU make, this is all no problem, but our developer team is Java only and they don't like the idea to use a 15* years old pure binary tool for something that looks like it's a job for gradle.\n\nIs there really no chance to set up that type of parallelization in gradle?\n    ", "Answer": "\r\nThis is default Worker API feature starting from Gradle 4.0:\n\n\n  Once all of the work for a task action has been submitted, it is safe to exit the task action. The work will be executed asynchronously and in parallel (up to the setting of max-workers). Of course, any tasks that are dependent on this task (and any subsequent task actions of this task) will not begin executing until all of the asynchronous work completes. However, other independent tasks that have no relationship to this task can begin executing immediately.\n\n\nTLDR:\nIndependent tasks that use Worker API to submit work asynchronously (make sure to not call ```\nworkerExecutor.wait()```\n in task action) will be executed in parallel automatically.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Combing generator results and writing result to stream\r\n                \r\nCurrently I can generate expression trees.\n\n```\nexpression_tree([_|N_s],N_s, [number(0)]).\nexpression_tree([_|N_s0],N_s1, [op(neg),[E1]]) :-\n    expression_tree(N_s0,N_s1, E1).\nexpression_tree([_|N_s0],N_s2, [op(add), [E1, E2]]) :-\n    expression_tree(N_s0,N_s1, E1),\n    expression_tree(N_s1,N_s2, E2).\n\ngenerate_expression(N_c, E) :-\n    length(N, N_c),\n    expression_tree(N,[], E).\n\n?- generate_expression(N,E).\nN = 1,\nE = [number(0)] ;\nN = 2,\nE = [op(neg), [[number(0)]]] ;\nN = 3,\nE = [op(neg), [[op(neg), [[number(0)]]]]] ;\nN = 3,\nE = [op(add), [[number(0)], [number(0)]]] ;\nN = 4,\nE = [op(neg), [[op(neg), [[op(neg), [[number(0)]]]]]]] ;\nN = 4,\nE = [op(neg), [[op(add), [[number(0)], [number(0)]]]]] ;\nN = 4,\nE = [op(add), [[number(0)], [op(neg), [[number(0)]]]]] ;\nN = 4,\nE = [op(add), [[op(neg), [[number(0)]]], [number(0)]]] ;\nN = 5,\nE = [op(neg), [[op(neg), [[op(neg), [[op(neg), [[number(0)]]]]]]]]]\n```\n\n\nwhere N is the number of nodes for the tree.\n\nI can also independently generate sequence numbers.\n\n```\nsequence_number(Sequence_number) :-\n    sequence_numbers(1, Sequence_number).\n\nsequence_numbers(I, I).\nsequence_numbers(I, K) :-\n    J is I + 1,\n    sequence_numbers(J, K).\n\n?- sequence_number(N).\nN = 1 ;\nN = 2 ;\nN = 3 ;\nN = 4 ;\nN = 5 ;\nN = 6 \n```\n\n\nI can also generate and output the expressions but not with the correct sequence numbers \n\n```\nprint_expression(Stream, Prefix, Suffix, Sequence_number, E) :-\n    write(Stream,Prefix),\n    format(Stream, '~|~`0t~d~7+', Sequence_number),\n    write(Stream,\", \"),\n    write(Stream,E),\n    write(Stream,Suffix),\n    nl(Stream).\n\nprint_expressions_a(Stream, Prefix, Suffix, Sequence_number, N) :-\n    generate_expression(N, E),\n    print_expression(Stream, Prefix, Suffix, Sequence_number, E).\n\nprint_expressions_a :-\n    Stream = user_output,\n    Prefix = '(',\n    Suffix = ')',\n    Sequence_number = 1,\n    N = 4,\n    print_expressions_a(Stream, Prefix, Suffix, Sequence_number, N).\n```\n\n\n\n\n```\n?- print_expressions_a.\n(0000001, [op(neg),[[op(neg),[[op(neg),[[number(0)]]]]]]])\ntrue ;\n(0000001, [op(neg),[[op(add),[[number(0)],[number(0)]]]]])\ntrue ;\n(0000001, [op(add),[[number(0)],[op(neg),[[number(0)]]]]])\ntrue ;\n(0000001, [op(add),[[op(neg),[[number(0)]]],[number(0)]]])\ntrue ;\nfalse.\n```\n\n\nNotice the sequence numbers are all ```\n0000001```\n.  \n\nWhich is generating choice-points, so I modified it using ```\nforall```\n\n\n```\nprint_expressions_b(Stream, Prefix, Suffix, Sequence_number, N) :-\n    forall(\n        generate_expression(N, E),\n        print_expression(Stream, Prefix, Suffix, Sequence_number, E)\n    ).\n\nprint_expressions_b :-\n    Stream = user_output,\n    Prefix = '(',\n    Suffix = ')',\n    Sequence_number = 1,\n    N = 4,\n    print_expressions_b(Stream, Prefix, Suffix, Sequence_number, N).\n\n?- print_expressions_b.\n(0000001, [op(neg),[[op(neg),[[op(neg),[[number(0)]]]]]]])\n(0000001, [op(neg),[[op(add),[[number(0)],[number(0)]]]]])\n(0000001, [op(add),[[number(0)],[op(neg),[[number(0)]]]]])\n(0000001, [op(add),[[op(neg),[[number(0)]]],[number(0)]]])\ntrue.\n```\n\n\nwhich is still wrong.\n\n\n\nThe output I seek is\n\n```\n(0000001, [op(neg),[[op(neg),[[op(neg),[[number(0)]]]]]]])\n(0000002, [op(neg),[[op(add),[[number(0)],[number(0)]]]]])\n(0000003, [op(add),[[number(0)],[op(neg),[[number(0)]]]]])\n(0000004, [op(add),[[op(neg),[[number(0)]]],[number(0)]]])\n```\n\n\nWhere each sequence number is unique and sequential starting from ```\n0```\n or ```\n1```\n and can be written to a file. For this example the stream is set to ```\nuser_output```\n to simplify the question.\n\nIf I add the sequence number generator into the mix \n\n```\nprint_expressions_c(Stream, Prefix, Suffix, N) :-\n    generate_expression(N, E),\n    sequence_number(Sequence_number),\n    print_expression(Stream, Prefix, Suffix, Sequence_number, E).\n\nprint_expressions_c :-\n    Stream = user_output,\n    Prefix = '(',\n    Suffix = ')',\n    N = 4,\n    print_expressions_c(Stream, Prefix, Suffix, N).\n\n?- print_expressions_c.\n(0000001, [op(neg),[[op(neg),[[op(neg),[[number(0)]]]]]]])\ntrue ;\n(0000002, [op(neg),[[op(neg),[[op(neg),[[number(0)]]]]]]])\ntrue ;\n(0000003, [op(neg),[[op(neg),[[op(neg),[[number(0)]]]]]]])\ntrue ;\n(0000004, [op(neg),[[op(neg),[[op(neg),[[number(0)]]]]]]])\ntrue ;\n(0000005, [op(neg),[[op(neg),[[op(neg),[[number(0)]]]]]]])\ntrue ;\n```\n\n\nthe sequence numbers are now correct, but new expressions are never generated because the sequence number generator is using a choice point to generate the next sequence number and so the predicate ```\nsequence_number```\n, does not backtrack to the ```\ngenerate_expression```\n predicate to get a new expression.\n\nSo, can I use two generators that rely on backtracking in succession? If so, how?\n\nSupplement\n\nThis is related to my earlier questions on tree generators.\nI am aware that this should be done with dcg, and that the data structure should be changed, but while I am trying to understand this, seeing it this way is easier to comprehend.  \n\nRelated SO Questions\n\n\nWhat are the uses of the fail predicate in Prolog?  \nHow to use backtrack to increment a variable infinitely in Prolog  \nAlgorithm improvement for enumerating binary trees  \nHow to enumerate combinations using DCGs with CLP(FD) and multiple constraints\n\n    ", "Answer": "\r\nRetracting backtracking\n\nTo summarize the question, you would like to:\n\n\ngenerate expressions using a generator that uses iterative deepening\nnumber each solution with consecutive integers.\n\n\nThus, the core problem you are facing is preserving information over backtracking.\n\nThis is of course impossible in pure Prolog: Doing so would destroy the most elementary properties we expect from relations, in particular our expectation that backtracking undoes everything that happened in the current branch of the computation.\n\nA pure solution, therefore, is to eliminate backtracking!\n\nI'm not joking: We will now change the entire search for solutions in such a way that each solution is found without backtracking, even though the program looks as if it used backtracking. In fact, the program will even stay the same, but we interpret it differently than plain Prolog would do it. This strategy allows us to carry a counter with us, and equip each solution we find with consecutive integers.\n\nIn essence, I am now implementing backtracking within Prolog, i.e., I am implementing backtracking without using Prolog's built-in mechanism for backtracking, so that I am free to extend it as I want. \n\nReifying backtracking\n\n\n  to reify = \"to make it a thing\" (from Latin: res, rei f. = matter, thing, affair)\n\n\nFirst, I will represent the whole program differently, so that it easier to reason about it. The representation I shall use avoids the defaulty representation for regular Prolog goals, and instead uses lists of goals. I will represent each clause as a fact of the form:\n\n\nhead_body(Head, [Goal1,Goal2,...,Goaln]).\n\n\nThis change is purely syntactical (even though it helps enormously for further processing within our programs), and can be easily automated:\n\n\nhead_body(expression_tree([_|N_s],N_s, [number(0)]), []).\nhead_body(expression_tree([_|N_s0],N_s1, [op(neg),[E1]]),\n          [expression_tree(N_s0,N_s1, E1)]).\nhead_body(expression_tree([_|N_s0],N_s2, [op(add), [E1, E2]]),\n          [expression_tree(N_s0,N_s1, E1),\n           expression_tree(N_s1,N_s2, E2)]).\n\n\nWe can interpret this program with a meta-interpreter like the following:\n\n\nmi([G-[]|_], G).\nmi([Gs0|Rest], G) :-\n        findall(G0-Body, (Gs0 = G0-[First|Others],\n                          head_body(First, Body0),\n                          append(Body0, Others, Body)), Nexts, Rest),\n        mi(Nexts, G).\n\n\nNote that backtracking no longer occurs in this interpreter in the search for solutions, except for collecting all matching clauses, and actually reporting any solutions, which is only part of the interface but not of the core logic.\n\nNote also that the ```\nappend/3```\n call can be eliminated by using list differences in the clause representation. I leave this as a very easy exercise.\n\nTo use this interpreter, we change our main predicate to read:\n\n\ngenerate_expression(N_c, E) :-\n        length(N, N_c),\n        mi([E-[expression_tree(N,[],E)]], E).\n\n\nSample query:\n\n\n?- generate_expression(N, E).\nN = 1,\nE = [number(0)] ;\nN = 2,\nE = [op(neg), [[number(0)]]] ;\nN = 3,\nE = [op(neg), [[op(neg), [[number(0)]]]]] ;\nN = 3,\nE = [op(add), [[number(0)], [number(0)]]] ;\nN = 4,\nE = [op(neg), [[op(neg), [[op(neg), [[number(0)]]]]]]] .\n\n\nThis is equivalent to what you already have, and so it does not help a lot currently. By the way, maybe it is now a good time to get rid of this \"have we got enough brackets yet\" notation, so that future solutions are a bit easier to read. Consider for example terms of the form ```\nop_arguments/2```\n to represent expressions, or better yet simply Prolog terms of the form ```\n(+)/2```\n etc.\n\nEnumerating solutions\n\nNow back to the main point: The key advantage of using a meta-interpreter is that it lets us change how plain Prolog would execute such programs.\n\nIn our case, now is the time to introduce a counter for solutions. Our first attempt could look like this:\n\n\nmi(Alts0, S0, S, G) :-\n        (   Alts0 = [G0-[]|Rest] ->\n            (   S #= S0,\n                G = G0\n            ;   S1 #= S0 + 1,\n                mi(Rest, S1, S, G)\n            )\n        ;   Alts0 = [Gs0|Rest],\n            findall(G0-Body, ( Gs0 = G0-[First|Others],\n                               head_body(First, Body0),\n                               append(Body0, Others, Body)), Alts, Rest),\n            mi(Alts, S0, S, G)\n        ).\n\n\nWith the invoking predicate looking like this:\n\n\ngenerate_expression(N_c, S, E) :-\n        length(N, N_c),\n        mi([E-[expression_tree(N,[],E)]], 0, S, E).\n\n\nThis almost solves the issue, but we still have the following problem:\n\n\n?- generate_expression(_, S, _).\nS = 0 ;\nS = 0 ;\nS = 0 ;\nS = 1 ;\nS = 0 ;\nS = 1 ;\nS = 2 ;\nS = 3 ;\nS = 0 ;\nS = 1 ;\nS = 2 ;\nS = 3 ;\nS = 4 ;\nS = 5 ;\nS = 6 ;\nS = 7 ;\nS = 8 ;\nS = 0 ;\nS = 1 .\n\n\nSo, solutions are enumerated, but there's still backtracking: The backtracking happens in ```\nlength/2```\n, and for each new length that is being tried, the counter is reset.\n\nFair from the start\n\nWe therefore now change the interpreter to implement a fair computation strategy right from the start. By fair, we mean that every solution that exists is eventually found.\n\nIterative deepening is one such strategy. I leave this as an exercise, and implement breadth-first search in this example. Obtaining breadth-first search is easy: We simply append new alternatives. In fact, since we are now about to implement fairness as a fundamental property of the interpreter, we can also simplify the program to read:\n\n\nhead_body(expression_tree([number(0)]), []).\nhead_body(expression_tree([op(neg), [E1]]),\n          [expression_tree(E1)]).\nhead_body(expression_tree([op(add), [E1, E2]]),\n          [expression_tree(E1),expression_tree(E2)]).\n\n\nA fair meta-interpreter, implementing breadth-first search and enumerating solutions:\n\n\nmi(Alts0, S0, S, G) :-\n        (   Alts0 = [G0-[]|Rest] ->\n            (   S #= S0,\n                G = G0\n            ;   S1 #= S0 + 1,\n                mi(Rest, S1, S, G)\n            )\n        ;   Alts0 = [Gs0|Rest],\n            findall(G0-Body, ( Gs0 = G0-[First|Others],\n                               head_body(First, Body0),\n                               append(Body0, Others, Body)), Alts1),\n            append(Rest, Alts1, Alts),\n            mi(Alts, S0, S, G)\n        ).\n\n\nOur main predicate:\n\n\ngenerate_expression(S, E) :-\n        mi([E-[expression_tree(E)]], 0, S, E).\n\n\nAnd here we go:\n\n\n?- generate_expression(S, E).\nS = 0,\nE = [number(0)] ;\nS = 1,\nE = [op(neg), [[number(0)]]] ;\nS = 2,\nE = [op(neg), [[op(neg), [[number(0)]]]]] ;\nS = 3,\nE = [op(add), [[number(0)], [number(0)]]] ;\nS = 4,\nE = [op(neg), [[op(neg), [[op(neg), [[...]]]]]]] ;\nS = 5,\nE = [op(neg), [[op(add), [[number(0)], [number(0)]]]]] ;\nS = 6,\nE = [op(add), [[number(0)], [op(neg), [[number(0)]]]]] ;\nS = 7,\nE = [op(add), [[op(neg), [[number(0)]]], [number(0)]]] .\n\n\nStay pure folks!\n\nUsing this pure approach to solve the issue gives us some hope to generalize this to other combinators, since the different concerns can be addressed in comparative isolation, and the original programs can stay the way they are.\n\nNote also that I let the toplevel do the printing. If necessary, I can always write these solutions anywhere I want using impure predicates, but first and foremost each solution is available as a predicate argument that I can actually reason about within Prolog.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Umbraco 7: Map property to page and check if is associated with current page\r\n                \r\nIn my Content section I have a property editor (Archetype) that allows to set content for the site independently from the content tree.\nI need to display only the sub categories from one category based on what page I'm currently on. What I have now is:\n\n```\n//get the content with id of 1123 from Content Section, type DynamicPublishedContent\nvar catItems = Umbraco.Content(1123).categoryItem; \n\nforeach (var item in catItems)\n{\n  foreach (var sub in item.GetValue<ArchetypeModel>(\"subCatItem\"))\n  {\n    <div class=\"tbl_dt\">\n        <p class=\"offerName\">@sub.GetValue(\"offerName\")</p>\n        <p class=\"departurePort\">@sub.GetValue(\"departurePort\")</p>\n    </div>\n }\n}\n```\n\n\nSee this reference for other details: Umbraco 7: Get fields from same property based on current page\n\nQ: How can I map the property to a content page and check if is associated with current page and display only the fields with mapped current page? Can this be done by adding a ```\ncontent picker```\n to it? If so how could I check if it is associated with current page?\n    ", "Answer": "\r\nFirst it is not good practice to reference content in code by their id. Rather use the document type alias which is guaranteed not to get deleted by a user.\n\nNow to check for the existence of a property on the current page all you need to do is\n\n```\n@if (CurrentPage.HasValue(\"subCatItem\"))\n{\n   string propertyStoredValue = CurrentPage.subCatItem.ToString();\n}\n```\n\n\nWhere \"subCatItem\" is the alias of the property you are checking for. The type of the property is not relevant in this case and bear in mind if the property is not mandatory and has not been given a value the above statement will evaluate to false even though the property exists on the document type (makes sense?)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Using a WiX Selection Tree control, when I select Feature 1, I want Feature 2 to be selected automatically\r\n                \r\nI have three features in a Selection Tree control.  I would like Feature 2 and 3 to be independently selected and installed but if Feature 1 is selected to be installed I want Feature 2 to be automatically selected since Feature 1 depends on it.  When my Selection Tree is displayed I see:\n\n```\n[-] All Features\n    [x] Feature 1 (requires Feature 2)\n    [x] Feature 2        \n    [x] Feature 3\n```\n\n\nWhere [-] represents the icon for \"Will be installed on local hard drive\"\nand [x] represents the icon for \"Entire feature will be unavailable\".\n\nWhen I select Feature 1 to be installed I see: \n\n```\n[-] All Features\n    [-] Feature 1 (requires Feature 2)\n    [x] Feature 2\n    [x] Feature 3\n```\n\n\nBut when I select Feature 1, I want Feature 2 to be selected automatically so it would look like this: \n\n```\n[-] All Features\n    [-] Feature 1 (requires Feature 2)\n    [-] Feature 2\n    [x] Feature 3\n```\n\n\nI don't want Feature 3 to be automatically selected since it is not required by Feature 1.  Is there a way to do this?  This seems like a simple problem but I could not find any documentation or examples on how to do this.  I have tried to use a condition within Feature2 like the following but the condition never gets tested since only Feature 1 was selected:\n\n```\n<Feature Id=\"ProductFeature\" Title=\"All Features\" Display=\"expand\" Level=\"1\">\n  <Feature Id=\"Feature1\" ConfigurableDirectory=\"APPLICATIONFOLDER\"\n           Title=\"Feature 1 (requires Feature 2)\" Level=\"2\">\n    <ComponentRef Id=\"file1.txt\" />\n  </Feature>\n  <Feature Id=\"Feature2\" ConfigurableDirectory=\"APPLICATIONFOLDER\"\n           Title=\"Feature 2\" Level=\"2\">\n    <ComponentRef Id=\"file2.txt\" />\n    <Condition Level=\"1\">MsiSelectionTreeSelectedFeature=\"Feature1\"</Condition>\n  </Feature>\n  <Feature Id=\"Feature3\" ConfigurableDirectory=\"APPLICATIONFOLDER\"\n           Title=\"Feature 3\" Level=\"2\">\n    <ComponentRef Id=\"file3.txt\" />\n  </Feature>\n</Feature>\n```\n\n\nIf only Feature 1 is selected, is there a way to \"tell it\" to set the Level attribute of Feature2 to 1 so that Feature 2 in the Selection Tree displays the icon showing it will be installed also?  If trying to set the Level attribute of Feature2 is not the right approach, is there another method I can use to accomplish the behavior I desire?\n\nHere is my full program if you want to try it:\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\">\n    <Product Id=\"41788c15-290e-426f-934e-e5b3bf875013\" Name=\"WixUI_FeatureTree\" \n           Language=\"1033\" Version=\"1.0.0.0\" Manufacturer=\"WixUI_FeatureTree\" \n           UpgradeCode=\"5f5d4f80-96f5-4060-a718-539b547d8a29\">\n        <Package InstallerVersion=\"200\" Compressed=\"yes\" />\n        <Media Id=\"1\" Cabinet=\"media1.cab\" EmbedCab=\"yes\" />\n        <?define FeatureTree=1?>\n    <UIRef Id=\"MyWixUI_FeatureTree\" />\n\n        <Directory Id=\"TARGETDIR\" Name=\"SourceDir\">\n            <Directory Id=\"ProgramFilesFolder\">\n                <Directory Id=\"APPLICATIONFOLDER\" Name=\"WixUI_FeatureTree\">\n                </Directory>\n            </Directory>\n        </Directory>\n\n        <DirectoryRef Id=\"APPLICATIONFOLDER\">\n      <Component Id=\"file1.txt\" Guid=\"FEBD6C0C-1BDF-413C-B7B1-A4E18AC7A6FA\">\n        <File Id=\"file1.txt\" Source=\"file1.txt\" KeyPath=\"yes\" Checksum=\"yes\"/>\n      </Component>\n      <Component Id=\"file2.txt\" Guid=\"FEBD6C0C-1BDF-413C-B7B1-A4E18AC7A6FB\">\n        <File Id=\"file2.txt\" Source=\"file2.txt\" KeyPath=\"yes\" Checksum=\"yes\"/>\n      </Component>\n      <Component Id=\"file3.txt\" Guid=\"FEBD6C0C-1BDF-413C-B7B1-A4E18AC7A6FC\">\n        <File Id=\"file3.txt\" Source=\"file3.txt\" KeyPath=\"yes\" Checksum=\"yes\"/>\n      </Component>\n        </DirectoryRef>\n\n    <Feature Id=\"ProductFeature\" Title=\"All Features\" Display=\"expand\" Level=\"1\">\n      <Feature Id=\"Feature1\" ConfigurableDirectory=\"APPLICATIONFOLDER\"\n               Title=\"Feature 1 (requires Feature 2)\" Level=\"2\">\n        <ComponentRef Id=\"file1.txt\" />\n      </Feature>\n      <Feature Id=\"Feature2\" ConfigurableDirectory=\"APPLICATIONFOLDER\"\n               Title=\"Feature 2\" Level=\"2\">\n        <ComponentRef Id=\"file2.txt\" />\n        <Condition Level=\"1\">MsiSelectionTreeSelectedFeature=\"Feature1\"</Condition>\n      </Feature>\n      <Feature Id=\"Feature3\" ConfigurableDirectory=\"APPLICATIONFOLDER\"\n               Title=\"Feature 3\" Level=\"2\">\n        <ComponentRef Id=\"file3.txt\" />\n      </Feature>\n    </Feature>\n\n  </Product>\n</Wix>\n```\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Best build process solution to manage build versions\r\n                \r\nI run a rather complex project with several independent applications. These use however a couple of shared components. So I have a source tree looking something like the below.\n\n\nMy Project \n\n\nApplication A\nShared1\nShared2 \nApplication B \nApplication C\n\n\n\nAll applications have their own MSBuild script that builds the project and all the shared resources it needs. I also run these builds on a CruiseControl controlled continuous integration build server. \n\nWhen the applications are deployed they are deployed on several servers to distribute load. This means that it’s extremely important to keep track of what build/revision is deployed on each of the different servers (we need to have the current version in the DLL version, for example “1.0.0.68”). \n\nIt’s equally important to be able to recreate a revision/build that been built to be able to roll back if something didn’t work out as intended (o yes, that happends ...). Today we’re using SourceSafe for source control but that possible to change if we could present good reasons for that (SS it’s actually working ok for us so far). \n\nAnother principle that we try to follow is that it’s only code that been build and tested by the integration server that we deploy further. \n\n\"CrusieControl Build Labels\" solution\n\nWe had several ideas on solving the above. The first was to have the continuous integration server build and locally deploy the project and test it (it does that now). As you probably know a successful build in CruiseControl generates a build label and I guess we somehow could use that to set the DLL version of our executables (so build label 35 would create a DLL like “1.0.0.35” )? The idea was also to use this build label to label the complete source tree. Then we probably could check out by that label and recreate the build later on. \n\nThe reason for labeling the complete tree is to include not only the actual application code (that’s in one place in the source tree) but also all the shared items (that’s in different places in the tree). So a successful build of “Application A” would label to whole tree with label “ApplicationA35” for example. \n\nThere might however be an issue when trying to recreate this build and setting the DLL version before deploying as we then don’t have access to the CruiseControl generated build label anymore. If all CrusieControl build labels were unique for all the projects we could use only the number for labeling but that’s not the case (both application A and B could at the same time be on build 35) so we have to include the application name in the label. Hence SourceSafe label “Application35”. How can I then recreate build 34 and set 1.0.0.34 to the DLL version numbers once we built build 35?\n\n\"Revision number\" solution\n\nSomeone told me that Subversion for example creates a revision number for the entire source tree on every check in – is this the case? Has SourceSafe something similar? If this is correct the idea is then to grab that revision number when getting latest and build on the CruiseControl server. The revision number could then be used to set the DLL version number (to for example “1.0.0.5678”). I guess we could then get this specific revision for the Subversion if needed and that then would include that application and all the shared items to be able to recreate a specific version from the past. Would that work and could this also be achived using SourceSafe?\n\nSummarize\n\nSo the two main requirements are:\n\n\nBe able to track build/revision number of the build and deployed DLL.\nBe able to rebuild a past revision/build, set the old build/revision number on the executables of that build (to comply with requirement 1).\n\n\nSo how would you solve this? What would be your preferred approach and how would you solve it (or do you have a totally different idea?)? **Pleased give detailed answers. **\n\nBonus question What are the difference between a revision number and a build number and when would one really need both?\n    ", "Answer": "\r\nYour scheme is sound and achievable in VSS (although I would suggest you consider an alternative, VSS is really an outdated product).\n\nFor your \"CI\" Build - you would do the Versioning take a look at MSBuild Community Tasks Project which has a \"Version\" tasks.  Typically you will have a \"Version.txt\" in your source tree and the MSBuild task will increment the \"Release\" number while the developers control the Major.Minor.Release.Revision numbers (that's how a client of mine wanted it).  You can use revision if you prefer.\n\nYou then would have a \"FileUpdate\" tasks to edit the AssemblyInfo.cs file with that version, and your EXE's and \"DLL's\" will have the desired version.\n\nFinally the VSSLabel task will label all your files appropriately.\n\nFor your \"Rebuild\" Build - you would modify your \"Get\" to get files from that Label, obviously not execute the \"Version\" task (as you are SELECTING a version to build) and then the FileUpdate tasks would use that version number.\n\nBonus question:\n\nThese are all \"how you want to use them\" - I would use build number for, well the build number, that is what I'd increment.  If you are using CI you'll have very many builds - the vast majority with no intention of ever deploying anywhere.\n\nThe major and minor are self evident - but revision I've always used for a \"Hotfix\" indicator.  I intend to have a \"1.3\" release - which would in reality be a product with say 1.3.1234.0 version.  While working on 1.4 - I find a bug - and need a hot fix as 1.3.2400.1. Then when 1.4 is ready - it would be say 1.4.3500.0\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Binding data in stackpanel\r\n                \r\nI use WPF and c#.\n\nI have an issue regarding binding and visibility. \nI have a tree which is bound to obsCol1. Then I have a form in a grid whose datacontext is set to `\n\n```\nDataContext=\"{Binding ElementName=tree, Path=SelectedItem}\">`\n```\n\n\nInside that form I have 3 identical subforms if you will. Each of the 3 subforms is a groupbox inside of which is a horizontal stack panel in which there is a label textbox label textbox button.\n\n```\n<GroupBox  Grid.Column=\"3\" Grid.Row=\"8\" Grid.ColumnSpan=\"3\">\n                    <GroupBox.Header>Reklama 1</GroupBox.Header>\n                                <StackPanel Name=\"Rek1\" DataContext=\"Reklame\" Orientation=\"Horizontal\">\n                                    <Label Grid.Column=\"3\"  Grid.Row=\"10\" HorizontalAlignment=\"Right\" VerticalAlignment=\"Top\">Datum post/zam</Label>\n                                    <xctk:DateTimePicker x:Name=\"dtReklama1\" \n                                 Grid.Row=\"10\" \n                                 Grid.Column=\"4\"                                     \n                                 Height=\"25\" \n                                 Margin=\"3\"\n                                 Padding=\"3\"\n                                 VerticalAlignment=\"Top\"\n                                 HorizontalAlignment=\"Left\"\n                                 Width=\"150\" Value=\"{Binding Path=Opr_brendiranje}\"/>                                      \n                                    <Label Grid.Column=\"3\"  Grid.Row=\"8\" HorizontalAlignment=\"Right\" VerticalAlignment=\"Top\">Dimenzija</Label>\n                                    <extToolkit:WatermarkTextBox x:Name=\"Reklama\" Grid.Row=\"8\"\n                     Grid.Column=\"4\"                         \n                     HorizontalAlignment=\"Left\"\n                     VerticalAlignment=\"Top\"\n                       Width=\"100\"\n                     Height=\"25\"\n                     Padding=\"3\" \n                     Margin=\"3\"\n                     AcceptsReturn=\"True\" \n                     Validation.ErrorTemplate=\"{StaticResource ValidationTemplate}\"\n                     Validation.Error=\"Validation_Error\">\n                                        <extToolkit:WatermarkTextBox.Watermark>\n                                            <TextBox Text=\"Reklama\" Margin=\"4,2,2,0\" FontWeight=\"Regular\" Foreground=\"Silver\" BorderThickness=\"0\"/>\n                                        </extToolkit:WatermarkTextBox.Watermark>\n                                        <extToolkit:WatermarkTextBox.Text>\n                                            <Binding Path=\"RekDimenzije\"  UpdateSourceTrigger=\"PropertyChanged\" NotifyOnValidationError=\"True\"/>\n                                        </extToolkit:WatermarkTextBox.Text>\n                                    </extToolkit:WatermarkTextBox>\n                                    <Button Grid.Column=\"5\" Grid.Row=\"9\" Height=\"20\" Width=\"15\" Click=\"Dodaj_Reklamu\"  VerticalAlignment=\"Top\" FontWeight=\"Bold\" Margin=\"5\" >+</Button>\n                                </StackPanel>\n\n                </GroupBox>\n```\n\n\nSo now I need to bind this but the issue is that these subforms use a different class from the form itself. They are an entity in and of itself. So I was wondering if there was any way to bind them independently somehow like itemsource the groupbox or the stack panel or soemthing. I tried using itemscontrol and binding to it but that did not work it would bind the itemsource but if the itemsource was empty the control would dissapear therefore not allowing the user to add it.\n\nAny help would be appreciated.\n\nUpdate:\n\nOk so I have a single usercontrol.\nOn the left side is a tree that uses a HierarchicalDataTemplate that is bound to 2 different classes one of which OrgSredstva is OrgClass with Sredstva class contained within.\n\n```\n<TreeView.ItemTemplate>\n            <HierarchicalDataTemplate ItemsSource=\"{Binding Path=Org_Sredstva}\">\n                <HierarchicalDataTemplate.ItemContainerStyle>\n                    <Style TargetType=\"{x:Type TreeViewItem}\">\n                        <Setter Property=\"Focusable\" Value=\"False\"/>\n                    </Style>\n                </HierarchicalDataTemplate.ItemContainerStyle>\n                <TextBlock Text=\"{Binding Path=Organizacije_Naziv}\"/>\n               <HierarchicalDataTemplate.ItemTemplate>                     \n                    <DataTemplate>\n                        <TextBlock Text=\"{Binding Path=Ossr_Naziv}\"/>\n                    </DataTemplate>\n                </HierarchicalDataTemplate.ItemTemplate>\n            </HierarchicalDataTemplate>\n        </TreeView.ItemTemplate>\n\n    </TreeView>\n```\n\n\nThis all works as complicated as it sounds the tree works fine.\n\nOn the right side is a grid that like i described above has datacontext set to whatever is selected in the tree. I need this so that when the selection changes in the tree the form changes with it. The issue is that neither of the classes the tree is bound to is the class the form should be bound to. So the grid can't find the data because the textbox bindings aren't in that observable collection but another one. The way I solved this is to bind every textbox.text property in codebehind so \n\n```\n   public void OdabranoDrvo()\n    {\n\n         OdabranaOrg = this.View.tree.SelectedItem as Organizacije;\n\n\n\n         if (OdabranaOrg != null)\n        {\n            string orgId = OdabranaOrg.Organizacije_Sifra;\n\n            IEnumerable<Opremljenost> odabranaOpr = from fn in _oprema\n\n                                                    where fn.Opr_org_sifra == orgId\n\n                                                    select fn;\n            var ob = new ObservableCollection<Opremljenost>(odabranaOpr);\n\n\n            if (ob.Count > 0)\n            {\n                foreach (Opremljenost opr in odabranaOpr)\n                {\n                    this.View.Povrsina.Text = opr.Opr_Povrsina.ToString();                      \n                    this.View.RadnoVrijeme.Text = opr.Opr_RadnoVrijeme;\n                    if (opr.Opr_Vlasnik == 1)\n                    {\n                        this.View.LutRad.IsChecked = true;\n                        this.View.ImeVlasnika.IsReadOnly = true;\n                    }\n                    else\n                    {\n                        this.View.LutRad.IsChecked = false;\n                        this.View.ImeVlasnika.IsReadOnly = false;\n                    }\n                    this.View.ImeVlasnika.Text = opr.Opr_ime_vlasnik;\n                    if (opr.Opr_brojilo == 1)\n                    {\n                        this.View.Brojilo.IsChecked = true;\n                    }\n                    else\n                    {\n                        this.View.Brojilo.IsChecked = false;\n                    }\n                    if (opr.Opr_ventilacija == 1)\n                    {\n                        this.View.Ventilacija.IsChecked = true;\n                    }\n                    else\n                    {\n                        this.View.Ventilacija.IsChecked = false;\n                    }\n\n                    this.View.dtBrendiranje.Value = opr.Opr_brendiranje;\n                    this.View.dtKrecenje.Value = opr.Opr_krecenje;\n                    this.View.Napomena.Text = opr.Opr_napomena;\n                    this.View.BrojAparata.Text = opr.Opr_broj_aparata.ToString();\n                    this.View.BrojRuleta.Text = opr.Opr_broj_ruleta.ToString();\n                    this.View.UkupanBrojKlima.Text = opr.Opr_uku_br_klima.ToString();\n                    this.View.BrojKlimaLutrija.Text = opr.Opr_br_kl_lut.ToString();\n                    this.View.UkupanBrojTv.Text = opr.Opr_uku_broj_tv.ToString();\n                    this.View.BrojTvLutrija.Text = opr.Opr_broj_tv_lut.ToString();\n                    this.View.BrojTvPartneri.Text = opr.Opr_broj_tv_partneri.ToString();\n                    this.View.StrujnaSnaga.Text = opr.Opr_struja_ang_snaga.ToString();\n                    _slikeOpr = Ap.GlavniRepository.UcitajSlikeZaOpremu(opr.Opr_Id);\n                    this.View.Thumbnails.ItemsSource = _slikeOpr;\n\n\n                    _reklame = Ap.GlavniRepository.UcitajReklameZaOpremu(opr.Opr_Id);\n                    int i = _reklame.Count();\n\n                    if (i == 2)\n                    {\n                        this.View.Rek2.Visibility = Visibility.Visible;\n                        this.View.Rek3.Visibility = Visibility.Collapsed;\n                    }\n                    else if (i == 3)\n                    {\n                        this.View.Rek2.Visibility = Visibility.Visible;\n                        this.View.Rek3.Visibility = Visibility.Visible;\n                    }\n                    else\n                    {\n                        this.View.Rek2.Visibility = Visibility.Collapsed;\n                        this.View.Rek3.Visibility = Visibility.Collapsed;\n                    }\n                    this.View.Reklame.DataContext = _reklame;\n\n\n                }\n\n            }\n            else\n            {\n                this.View.Povrsina.Text = \"0\";\n                this.View.RadnoVrijeme.Text = String.Empty;\n                this.View.LutRad.IsChecked=false;\n                this.View.ImeVlasnika.Text = String.Empty;\n                this.View.Brojilo.IsChecked = false;\n                this.View.Ventilacija.IsChecked = false;\n                this.View.dtBrendiranje.Value = DateTime.Now;\n                this.View.dtKrecenje.Value = DateTime.Now;\n                this.View.Napomena.Text = String.Empty;\n                this.View.BrojAparata.Text = \"0\";\n                this.View.BrojRuleta.Text = \"0\";\n                this.View.UkupanBrojKlima.Text = \"0\";\n                this.View.BrojKlimaLutrija.Text = \"0\";\n                this.View.UkupanBrojTv.Text = \"0\";\n                this.View.BrojTvLutrija.Text = \"0\";\n                this.View.BrojTvPartneri.Text = \"0\";\n                this.View.StrujnaSnaga.Text = \"0\";\n                this.View.Thumbnails.ItemsSource = null;\n                this.View.Rek2.Visibility = Visibility.Collapsed;\n                this.View.Rek3.Visibility=Visibility.Collapsed;\n            }\n        }\n    }\n```\n\n\nThe original question i resolved by creating a new grid inside my preexisting grid and just setting the data context for that inner grid to what I needed it to be. Now I find that all the bindings seem to work at least on reading from database, haven't tested inserting into database yet.\n\nI realise this is all very ugly but I couldn't figure out a way to actually bind it while it still working as it should...\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Is there a way to copy an existing library but being able to modify the new one?\r\n                \r\nI need to be able to create a new library from an existing one. For example, I would like to be able to copy Qt5::Widgets and create a library with an other name, but with every setting staying the same. Later, I would change some locations on the newly made library without changing the original library.\n\nAn example can help to understad:\n\nI have Qt5::Widgets and would like to make an exact copy of said library and call it ModifiedQt5Widgets. I want every property to be the same. Then, I would modify some properties such as ```\nIMPORTED_LOCATION_DEBUG```\n on this new library. I also want this new library to behave the same as Qt5::Widgets when I link it. This seems to be difficult since this is an imported library. Is there a function or a way to just do like ```\ncopy_existing_library(ModifiedQt5Widgets Qt5::Widgets)```\n?\n\nBasically, I want to make an alias library, but I want to be able to edit this new library.\n\nEdit\n\nMy use case is that I have 4 possible configurations: Debug, MinSizeRel, RelWithDebInfo, Release. This is the tree that I will have in my build folder:\n\n```\n├── bin\n|   ├── Debug\n|   ├── RelWithDebInfo\n|   ├── MinSizeRel\n|   └── Release\n```\n\n\nI have a bunch of external libraries that I link to. I need to be able to link to these libraries, and then copy all these shared libraries in the appropriate ```\nbin/[CONFIGURATION]```\n folder. Once that it compiled, I need my generated project in each folder to have all external dependencies to be in the same folder and be independent of the environment. \n\nAlso, this needs to work on Mac, Windows, and Linux. It seems that Windows may have issues with a solution based on using ```\nRPATH```\n. I also need a way to find the ```\ndll```\ns that match the ```\nlib```\ns that I link with.\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Simple algorithm but running out of memory\r\n                \r\n\n  Problem\n  \n  A sequence of positive rational numbers is defined as follows:\n  \n  An infinite full binary tree labeled by positive rational numbers is\n  defined by:\n  \n  \n  The label of the root is 1/1\n  The left child of label p/q is p/(p+q)\n  The right child of label p/q is (p+q)/q\n  \n  \n  The top of the tree is shown in the following figure: \n  \n  \n  \n  The sequence is defined by doing a level order (breadth first)\n  traversal of the tree (indicated by the light dashed line). So that:\n  \n  F(1)=1/1,F(2)=1/2,F(3)=2/1,F(4)=1/3,F(5)=3/2,F(6)=2/3,…\n  \n  Write a program which finds the value of n for which F(n) is p/q for\n  inputs p and q.\n  \n  Input\n  \n  The first line of input contains a single integer P, (1≤P≤1000), which\n  is the number of data sets that follow. Each data set should be\n  processed identically and independently. Each data set consists of a\n  single line of input. It contains the data set number, K, a single\n  space, the numerator, p, a forward slash (/) and the denominator, q,\n  of the desired fraction.\n  \n  Output\n  \n  For each data set there is a single line of output. It contains the\n  data set number, K, followed by a single space which is then followed\n  by the value of n for which F(n) is p/q. Inputs will be chosen so n\n  will fit in a 32-bit integer.\n\n\nSource to question\n\nMy approach\n\nI create the heap and planned to iterate over it until I find the element(s) in question, but I ran out of memory so I'm pretty sure I'm supposed to do it without creating the heap at all?\n\nCode\n\n```\npublic ARationalSequenceTwo() {\n\n    Kattio io = new Kattio(System.in, System.out);\n    StringBuilder sb = new StringBuilder(10000);\n    int iter = io.getInt();\n\n    // create heap\n    int parent;\n    Node[] heap = new Node[Integer.MAX_VALUE];\n    int counter = 1;\n    heap[0] = new Node(1, 1);\n    while (counter < Integer.MAX_VALUE) {\n        parent = (counter - 1) / 2;\n        // left node\n        heap[counter++] = new Node(heap[parent].numerator, heap[parent].numerator + heap[parent].denominator);\n        // right node\n        heap[counter++] = new Node(heap[parent].numerator + heap[parent].denominator, heap[parent].denominator);\n    }\n\n    // find Node\n    int dataSet;\n    String word;\n    int numerator;\n    int denominator;\n    for (int i = 0; i < iter; i++) {\n        dataSet = io.getInt();\n        word = io.getWord();\n        numerator = Integer.parseInt(word.split(\"/\")[0]);\n        denominator = Integer.parseInt(word.split(\"/\")[1]);\n        for (int j = 0; j < Integer.MAX_VALUE; j++) {\n\n            Node node = heap[j];\n            if (node.numerator == numerator && node.denominator == denominator) {\n                sb.append(dataSet).append(\" \").append(j).append(\"\\n\");\n            }\n        }\n    }\n    System.out.println(sb);\n    io.close();\n}\n```\n\n    ", "Answer": "\r\nlet's consider node n = a/b. If n is a left child of its parent, then n = p/(p+q), where the parent is p/q. I.e. \n\n```\np = a, \nb = p + q \n\np = a, \nq = b - a\n```\n\n\nIf n is a right child of its parent, then n = (p+q)/q:\n\n```\na = p + q\nb = q\n\np = a - b =\nq = b\n```\n\n\nso, given for example 3/5, is it a left child or a right child? If it was a left child, then it's parent would be 3/(5-3) = 3/2. For the right child, we would have (3-5)/5 = -2/5. As this would not be positive, clearly n is a left child. \n\nSo, generalizing:\n\ngiven a rational n, we can find the path to the root as follows:\n\nArrayList lefts = new ArrayList<>();\n\n```\nwhile (nNum != nDen) {\n  if (nNum < nDen) {\n    //it's a left child\n    nDen = nDen - nNum;\n    lefts.add(true);\n  } else {\n    nNum = nNum - nDen;\n    lefts.add(false);\n  }\n}\n```\n\n\nNow that we have the path in the array, how do we translate it in the final result? Let's observe that\n\n\nif the value given was 1/1, then the array is empty, and we should return 1\nEvery time we go from level n to level n+1, we add 2^n to the result. For example, going from level 0 to level 1 we add 1 (the root). going from level 1 to level 2 we add all two nodes of level 1, which are 2, etc.\n\n\nWe're left with the last piece, which is adding the nodes to the left of the last node we have, the one corresponding to the input rational, plus one. How many node are on the left? if you try to label each arc going left with 0 and each arc going right with 1, you'll notice that the path spells in binary the number of nodes in the last level. For example, 3/5 is the left child of 3/2. the array will be populated with false, true, false. in binary, 010. The final result is 2^0 + 2^1 + 2^2 + 010 + 1 = 1 + 2 + 4 + 2 + 1 = 10 \n\nFinally, note that sum(2^i) is 2^(i+1) - 1. so, we can finally write the code for the second part:\n\n```\nint s = (1 << lefts.size()) - 1) // 2^(i+1) - 1\nint k = 0\nfor (int i = lefts.size() - 1; i >= 0; i---) {\n  if (lefts.get(i)) { \n    k += 1 << i;\n  }  \n}\nreturn s + k + 1;\n```\n\n\nA full program taking in input num and den:\n\n```\nimport java.util.ArrayList;\npublic class Z {\n  public static int func(int num, int den) {\n    ArrayList<Boolean> lefts = new ArrayList<>();\n    while (num != den) {\n      if (num < den) {\n        //it's a left child\n        den = den - num;\n        lefts.add(true);\n      } else {\n        num = num - den;\n        lefts.add(false);\n      }\n    }\n    int s = (1 << lefts.size()) - 1; // 2^(i+1) - 1\n    int k = 0;\n    for (int i = lefts.size() - 1; i >= 0; i--) {\n      if (!lefts.get(i)) {\n        k += 1 << i;\n      }\n    }\n    return s + k + 1;\n  }\n\n  public static void main(String[] args) {\n    System.out.println(func(Integer.parseInt(args[0]),\n                Integer.parseInt(args[1])));\n  }\n}\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to access the graphic node of a treecell\r\n                \r\nThis screenshot\n\n\n\nshows a pretty simple implementation of a treeview where I used a custom treecell made up of a flowpane with 5 labels.  The flowpane extends to the edge of the treeview (highlighted unused flow pane space in red).\n\nWhat I want to be able to do is resize the labels to take up all available flow pane space.  Ideally each treecell(label in the flowpane) would be able to be independently resized.  I haven't been able to do this in the custom tree cell and/or cell factory because the width of the flowpane isn't known at creation time (at least I haven't been able to determine it). \n\nAs far as I have been able to determine the tree cells aren't directly available through the treeview.  I have attempted to save the cells in the cell factory at creation for use at a later time but there are 48 cells created just to show the 5 that are shown in the screenshot and I'm not sure which of those 48 represent those on the screen (presumably the last 5).\n\nSo I guess the easiest way to ask the question is, how can I access the flowpane of the tree cells (and by extension the labels)  so that I can calculate and set the label widths?\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "recursively dissect sql schema\r\n                \r\nI use DBeaver with postgresql. It has a feature that lists a tree view of a db's schemas, including information_schema, pg_catalog, and public. Then, within each schema, there are a set of headings: Tables, Views, Materialized Views, Indexes, Functions, Sequences, Data Types, Aggregate Functions. Within each of these headings there are other entities, and so on to several levels in depth.\nI would like to create that tree view independently of DBeaver, using tkinter. I can handle the tkinter part, but I haven't been able to divine the SQL statements that dissect schemas recursively down to leaf nodes. I've only found the topmost statement, which is:\n```\nselect schema_name from information_schema.schemata\n```\n\nBeyond that, I cannot find anything that enables me to display deeper structure. I have read all the so-called schema tutorials; they are focused only on user-created tables. I've also read the official postgresql docs on schemas; they read like a dictionary and have no tutorial value whatever.\nAny help, please.\n    ", "Answer": "\r\nYou find all required information (e. g. ```\nschemata```\n, ```\ntables```\n, ```\nviews```\n, ```\nsequences```\n, etc.) in the ```\ninformation_schema```\n schema, which you can inspect with DBeaver. The PostgreSQL information schema is documented at https://www.postgresql.org/docs/current/information-schema.html . Good luck!\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "BeagleBone Black: how to activate UART 4 or 5 to enable RS-485 communication\r\n                \r\nI want to enable RS-485 AND CANbus communications for my BBB using the comms cape 2.\nI used to setup my Beaglebone black thru the /boot/uEnv.txt by overwriting with EEProm as follows:\n```\n###Overide capes with eeprom\nuboot_overlay_addr0=/lib/firmware/BB-UART1-00A0.dtbo\nuboot_overlay_addr1=/lib/firmware/BB-UART2-00A0.dtbo\nuboot_overlay_addr2=/lib/firmware/BB-UART4-00A0.dtbo\nuboot_overlay_addr3=/lib/firmware/BB-UART5-00A0.dtbo\n```\n\nAnd then I use ttyS4 for RS-485 comms.\nThough it used to work on some BBBs, it's no longer the case on many others and many issues raise:\n\nIf I do that, the CANbus stops to work - probably messing the UART for the CANbus;\nIf I do not use CANbus, this settings does not seem to work anymore for the RS-485 itself - I guess something changed that depends on the linux version installed.\n\nLong story short, I'd like to find a modern way to 1) setup RS-485 comms and 2) setup CANbus comm so that they work simultaneously.\nAnd, possibly, how can I test RS-485 comms work, independent of my own software?\nWhat I found on the Web:\nThe official cape comms doc here https://github.com/beagleboard/capes/tree/master/beaglebone/Comms tells how to setup things as follows:\n```\nFor the RS485, you just need\nconfig-pin p9.11 uart\nconfig-pin p9.13 uart \n...and then use /dev/ttyS4\n\nFor the CAN, you just need\nconfig-pin p9.24 can\nconfig-pin p9.26 can\n```\n\nBut in my case, setting ```\nconfig-pin p9.11 uart```\n leads to the following error:\n```\nERROR: open() for /sys/devices/platform/ocp/ocp:P9_11_pinmux/state failed, No such file or directory\n```\n\nThis SO beaglebone black: no slots while enable uart tells how to setup UART5.\nThey say to disable video, which I did.\nAnd to:\n```\nconfig-pin P8_37 uart\nconfig-pin P8_38 uart\n```\n\nwhich works on my side, I mean no error was generated.\nAnd then I used ```\nttS5```\n in my own software, but I cannot see anything on the RS-485.\nAt this time I am a bit puzzled: for example, should I overwrite EEPROM or not? Should I stick with the disabling of video, sound, etc. Why config-pin for UART4 doesn't work? Does UART 5 correspond to ttyS5? And how to make sure the ttySX I use really work with the RS-485 comm?\nThanks in advance.\nAPPENDIX: my current ```\n/boot/uEnv.txt```\n\n```\n#Docs: http://elinux.org/Beagleboard:U-boot_partitioning_layout_2.0\n\nuname_r=4.19.94-ti-r42\n#uuid=\n#dtb=\n\n###U-Boot Overlays###\n###Documentation: http://elinux.org/Beagleboard:BeagleBoneBlack_Debian#U$\n###Master Enable\nenable_uboot_overlays=1\n###\n###Overide capes with eeprom\n#uboot_overlay_addr0=/lib/firmware/BB-UART1-00A0.dtbo\n#uboot_overlay_addr1=/lib/firmware/BB-UART2-00A0.dtbo\nuboot_overlay_addr2=/lib/firmware/BB-UART4-00A0.dtbo\nuboot_overlay_addr3=/lib/firmware/BB-UART5-00A0.dtbo\n###\n###Additional custom capes\n#uboot_overlay_addr4=/lib/firmware/<file4>.dtbo\n#uboot_overlay_addr5=/lib/firmware/<file5>.dtbo\n#uboot_overlay_addr6=/lib/firmware/<file6>.dtbo\n#uboot_overlay_addr7=/lib/firmware/<file7>.dtbo\n###\n###Custom Cape\n#dtb_overlay=/lib/firmware/<file8>.dtbo\n###\n###Disable auto loading of virtual capes (emmc/video/wireless/adc)\n#disable_uboot_overlay_emmc=1\ndisable_uboot_overlay_video=1\ndisable_uboot_overlay_audio=1\ndisable_uboot_overlay_wireless=1\n#disable_uboot_overlay_adc=1\n###\n###PRUSS OPTIONS\n###pru_rproc (4.14.x-ti kernel)\n#uboot_overlay_pru=/lib/firmware/AM335X-PRU-RPROC-4-14-TI-00A0.dtbo\n###pru_rproc (4.19.x-ti kernel)\nuboot_overlay_pru=/lib/firmware/AM335X-PRU-RPROC-4-19-TI-00A0.dtbo\n###pru_uio (4.14.x-ti, 4.19.x-ti & mainline/bone kernel)\n#uboot_overlay_pru=/lib/firmware/AM335X-PRU-UIO-00A0.dtbo\n###\n###Cape Universal Enable\nenable_uboot_cape_universal=1\n###\n###Debug: disable uboot autoload of Cape\n#disable_uboot_overlay_addr0=1\n#disable_uboot_overlay_addr1=1\n#disable_uboot_overlay_addr2=1\n#disable_uboot_overlay_addr3=1\n###\n###U-Boot fdt tweaks... (60000 = 384KB)\n#uboot_fdt_buffer=0x60000\n###U-Boot Overlays###\n\ncmdline=coherent_pool=1M net.ifnames=0 lpj=1990656 rng_core.default_qual$\n\n#In the event of edid real failures, uncomment this next line:\n#cmdline=coherent_pool=1M net.ifnames=0 lpj=1990656 rng_core.default_qua$\n\n##enable Generic eMMC Flasher:\n##make sure, these tools are installed: dosfstools rsync\n#cmdline=init=/opt/scripts/tools/eMMC/init-eMMC-flasher-v3.sh\n```\n\n    ", "Answer": "\r\nHere is my /boot/uEnv.txt file:\n```\n\n#Docs: http://elinux.org/Beagleboard:U-boot_partitioning_layout_2.0\n\nuname_r=4.19.94-ti-r71\n#uuid=\n#dtb=\n\n###U-Boot Overlays###\n###Documentation: http://elinux.org/Beagleboard:BeagleBoneBlack_Debian#U-Boot_Overlays\n###Master Enable\nenable_uboot_overlays=1\n###\n###Overide capes with eeprom\nuboot_overlay_addr0=BONE-SPI1_0.dtbo\nuboot_overlay_addr1=BONE-SPI0_0.dtbo\n#uboot_overlay_addr2=<file2>.dtbo\n#uboot_overlay_addr3=<file3>.dtbo\n\n```\n\nI did not apply the /lib/firmware sections in my uboot-overlays section(s).\nThis is ```\nls -l /dev/spidev*```\n\n```\n\ncrw------- 1 root root 153, 0 Feb 10 00:39 /dev/spidev1.0\ncrw------- 1 root root 153, 1 Feb 10 00:39 /dev/spidev2.0\n\n```\n\nI think not being root might be an issue for me.\nAnyway...the symlinks are used in source these days, I think, and there is also an up-to-date repo. from the BeagleBoard.org fellows/gals that help one to produce their .dts files into .dtb/o files. It is useful to me b/c I can then alter things or see what the people at beagleboard.org are doing w/ DT.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Axios interceptor in vue 2 JS using vuex\r\n                \r\nI store token after success login call in vuex store like this:\n\n```\naxios.post('/api/auth/doLogin.php', params, axiosConfig)\n    .then(res => {\n        console.log(res.data); // token\n        this.$store.commit('login', res.data);\n    })\n```\n\n\naxiosConfig is file where I only set baseURL ```\nexport default { baseURL: 'http://localhost/obiezaca/v2' }```\n and params is just data sent to backend.\n\nMy vuex file looks is:\n\n```\nimport Vue from 'vue';\nimport Vuex from 'vuex';\n\nVue.use(Vuex);\n\nexport const store = new Vuex.Store({\n    state: {\n        logged: false,\n        token: ''\n    },\n    mutations: {\n        login: (state, response) => {\n            state.logged = true;\n            state.token = response;\n            console.log('state updated');\n            console.log('state.logged flag is: '+state.logged);\n            console.log('state.token: '+state.token);\n        },\n        logout: (state) => {\n            state.logged = false;\n            state.token = '';\n        }\n    }\n});\n```\n\n\nIt is working correctly, I can re-render some of content in my SPA basing on ```\nv-if=\"this.$store.state.logged\"```\n for logged user. I'm able to access ```\nthis.$store.state.logged```\n from any component in my entire app.\n\nNow I want to add my token to every request which call my rest API backend. I've created basic axios http interceptor which looks like this:\n\n```\nimport axios from 'axios';\n\naxios.interceptors.request.use(function(config) {\n    const token = this.$store.state.token;\n    if(token) {\n        config.headers.Authorization = `Bearer ${token}`;\n    }\n    return config;\n}, function(err) {\n    return Promise.reject(err);\n});\n```\n\n\nNow I have 2 problems/questions about it.\n\n\nI know that it is available to use ```\nthis.$store.state.logged```\n or ```\nthis.$store.state.token```\n across every component but can I use it same way in single javascript file?\nWhere should I execute/start my interceptor javascript file? It is independent file which lays in my app main folder but I am not calling it anywhere, in angularJS which I was working before, I had to add ```\n$httpProvider.interceptors.push('authInterceptorService');```\n in config but I don't know how to do same thing in vue architecture. So where should I inject my interceptor?\n\n\nEDIT\n\nI followed GMaiolo tips I added \n\n```\nimport interceptor from './helpers/httpInterceptor.js';\ninterceptor();\n```\n\n\nto my main.js file and I refactor my interceptor to this:\n\n```\nimport axios from 'axios';\nimport store from '../store/store';\n\nexport default function execute() {\n    axios.interceptors.request.use(function(config) {\n        const token = this.$store.state.token;\n        if(token) {\n            config.headers.Authorization = `Bearer ${token}`;\n        }\n        return config;\n    }, function(err) {\n        return Promise.reject(err);\n    });\n}\n```\n\n\nResult of this changes is that every already existing backend calls ( GET ) which don't need token to work stopped working but it is logical because I didn't clarified to which request it should add token so it is trying to add it everywhere and in my interceptor something is still wrong and that is why every already exisitng request stopped working.\n\nWhen I try to do backend POST call in browser console I still get this error:\n\n\n  TypeError: Cannot read property '$store' of undefined\n\n\nAlthough I import store to my interceptor file. Any ideas? I can provide some more information if any needed.\n\nI additionally add screenshot of this main, store and interceptor tree structure so you can see that I'm importing fron correct path:\n\n\n    ", "Answer": "\r\n1.\nFirst of all I'd use a Vuex Module as this Login/Session behavior seems to be ideal for a ```\nSession```\n module. After that (which is totally optional) you can set up a Getter to avoid accessing the ```\nstate```\n itself from outside Vuex, you'd would end up with something like this:\n```\nstate: {\n  // bear in mind i'm not using a module here for the sake of simplicity\n  session: {\n    logged: false,\n    token: ''\n  } \n},\ngetters: {\n  // could use only this getter and use it for both token and logged\n  session: state => state.session,\n  // or could have both getters separated\n  logged: state => state.session.logged,\n  token: state => state.session.token\n},\nmutations: {\n  ...\n}\n```\n\nWith those getters set, you can get the values a bit easier from components. With either using ```\nthis.$store.getters.logged```\n (or the one you'd want to use) or using the ```\nmapGetters```\n helper from Vuex [for more info about this you can check the getters docs]:\n```\nimport { mapGetters } from 'vuex'\nexport default {\n  // ...\n  computed: {\n    ...mapGetters([\n      'logged',\n      'token'\n    ])\n  }\n}\n```\n\n2.\nI like to run Axios' interceptors along with Vue instantation in ```\nmain.js```\n creating, importing and executing an ```\ninterceptors.js```\n helper. I'd leave an example so you get an idea, but, then again, this is my own preference:\nmain.js\n```\nimport Vue from 'vue';\nimport store from 'Src/store';\nimport router from 'Src/router';\nimport App from 'Src/App';\n\n// importing the helper\nimport interceptorsSetup from 'Src/helpers/interceptors'\n\n// and running it somewhere here\ninterceptorsSetup()\n\n/* eslint-disable no-new */\nnew Vue({\n    el: '#app',\n    router,\n    store,\n    template: '<App/>',\n    components: { App }\n});\n```\n\ninterceptors.js\n```\nimport axios from 'axios';\nimport store from 'your/store/path/store'\n\nexport default function setup() {\n    axios.interceptors.request.use(function(config) {\n        const token = store.getters.token;\n        if(token) {\n            config.headers.Authorization = `Bearer ${token}`;\n        }\n        return config;\n    }, function(err) {\n        return Promise.reject(err);\n    });\n}\n```\n\nAnd there you'd end up having all the behavior cleanly encapsulated.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Compile multiple Kernel modules that share code\r\n                \r\nI whish to compile two Kernel modules (out of tree) that share a common library : module1.c uses functions from library.c and module2.c also uses functions from library.c. But, library.c implements a global variable \"my_variable\" that need to be shared between module1.c and module2.c.\n\nFor now, I have the following Makefile : \n\n```\n# List of files\nobj-m   += my_module1.o my_module2.o\n\nmy_module1-objs := library.o module1.o\nmy_module2-objs := library.o module2.o\n\nall:    \n    make -C $(KERNEL_DIR) M=$(PWD) modules\n```\n\n\n$(KERNEL_DIR) and $(PWD) are set before makefile is called.\n\nThat makefile makes the following output :\n\n```\nCC library.o\nCC module1.o\nLD my_module1.o\nCC library.o\nCC module2.o\nLD my_module2.o\nCC my_module1.mod.o\nLD my_module1.ko\nCC my_module2.mod.o\nLD my_module2.ko\n```\n\n\nlibrary.c is compiled twice, for each module that uses it. So there is two different \"my_variables\" objects that live independently, thing that I want to avoid.\n\nHow can I modify the Makefile to first, compile library.c => library.o then use the same library.o to compile each Kernel modules ?\n\nThanks a lot.\n    ", "Answer": "\r\nWithout seeing your code it is difficult to see what is going on exactly.\n\nBut from what I can understand you have two separate modules compiling (including the library). Since they are separate they will have their own copy of their variables.\n\nIf you want to share a variable you will need to use ```\nEXPORT_SYMBOL```\n in one module and then ```\nextern```\n it in the other - something like this\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "In npm/yarn workspaces, should packages consume src or dist\r\n                \r\nI want to use a monorepo for our frontend app. We want to divide some react UI components into a package folder under \"/packages/ui-components\" and leave the app in an \"/apps/app\" folder and then have the app consume ui-components by importing it (simplified setup). We don't plan to release these packages to individual npm repos anytime soon, but just have the final app running.\nI'm starting to worry a bit about how we can have the best workflow, and for some reason I cannot find this in my research:\nShould the app consume the src-files from packages or instead compile each package to the dist folder and import only these?\nWorkflow wise we would like working in different packages seamless, so if someone edits in a package we would like these changes to immediately show in the App.\nI see some pros and cons of using source-files compared to using a dist-output.\nPros of using src directly:\n\nBetter tree-shaking, as dependencies can be peer-dependencies and libraries that are used by multiple packages can be combined.\nSmaller final bundle size due to webpack having better access to original data like full dependency-tree and common functions etc.\nFaster development iterations with smaller projects as there's only one build and smart webpack could potentially only recompile a few changed files.\n\nPros of using dist:\n\nMore independent packages as they can contain their own build-pipeline.\nWill be easier to import as less peer-dependencies and special webpack-config is needed\nReady to be published as a public npm package\nPossibly faster build-time as only changed packages and main-app needs to recompile on changes (I assume webpack can do cache, so maybe this doesnt matter much)\n\nI'm sure I'm missing a lot of details; setting up the good development flow is quiet complicated these days and I would like to make it as simple to use as possible for my colleagues..\nTL;DR;\nShould packages in a mono-repo build to their dist for others to consume, or is it better to import directly from src.\n    ", "Answer": "\r\nIt is a matter of tradeoffs.\nIf you consume ```\ndist```\n of your packages, this means that in order to \"apply\" changes inside your package you need to build, then consume it in the ```\napp```\n.\nSome even suggest publishing the package to the registry (public or private), this allows you more loose coupling between the app and the packages.\nOn the other hand, working on the src has \"seem less\" like advantages, but will require your app setup to support it, since it will be the one that compile the package's code.\nPersonally, I'm using the second method, my apps are consuming from the ```\nsrc```\n, and it was not so trivial to configure to since most of the tools are ignoring code from ```\nnode_modules```\n by default (Like babel-loader, which will ignore transpilation of code inside ```\nnode_modules```\n).\nMost of my code was based on next-transpile-modules source code.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to debug: CUDA kernel fails when there are many threads?\r\n                \r\nI am using a Quadro K2000M card, CUDA capability 3.0, CUDA Driver 5.5, runtime 5.0, programming with Visual Studio 2010. My GPU algorithm runs many parallel breadth first searches (BFS) of a tree (constant). The threads are independed except reading from a constant array and the tree. In each thread there can be some malloc/free operations, following the BFS algorithm with queues (no recursion). There N threads; the number of tree leaf nodes is also N. I used 256 threads per block and (N+256-1)/256 blocks per grid.\n\nNow the problem is the program works for less N=100000 threads but fails for more than that. It also works in CPU or in GPU thread by thread. When N is large (e.g. >100000), the kernel crashes and then ```\ncudaMemcpy```\n from device to host also fails. I tried Nsight, but it is too slow. \n\nNow I set ```\ncudaDeviceSetLimit(cudaLimitMallocHeapSize, 268435456);```\n I also tried larger values, up to 1G; ```\ncudaDeviceSetLimit```\n succeeded but the problem remains.\n\nDoes anyone know some common reason for the above problem? Or any hints for further debugging? I tried to put some printf's, but there are tons of output. Moreover, once a thread crashes, all remaining printf's are discarded. Thus it is hard to identify the problem.\n    ", "Answer": "\r\n\"CUDA Driver 5.5, runtime 5.0\" -- that seems odd. \n\nYou might be running into a windows TDR event.  Based on your description, I would check that first.  If, as you increase the threads, the kernel begins to take more than about 2 seconds to execute, you may hit the windows timeout.\n\nYou should also add proper cuda error checking to your code, for all kernel calls and CUDA API calls.  A windows TDR event will be more easily evident based on the error codes you receive.  Or the error codes may steer you in another direction.\n\nFinally, I would run your code with ```\ncuda-memcheck```\n in both the passing and failing cases, looking for out-of-bounds accesses in the kernel or other issues.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to debug StealJS with IE 11 and Firefox 36?\r\n                \r\nI use the minor tag of StealJS to load my JS files and everything seems to work, but today I recognized that I'm simply unable to debug my code in IE 11 and Firefox 36. Until now I only used the new Opera based on Chrome/Blink, currently version 27, which works pretty well regarding debugging. But:\n\nFirefox's built in dev tools don't show my JS files at all. They only show steal.js and directly afterwards a greyed out line called \"evals\" with two additionals lines of two JS libs I use and export in stealconfig.js.\n\nFirefox's Firebug shows my files and I can set breakpoints, but there seems to be some errors, because if I set/unset the breakpoint there's a little animation shown which never finishes. If I reload the page the usual breakpoint icon, a red circle, is shown, so it looks like the breakpoint has been set successfully, but the code simply doesn't stop on the breakpoint. But it is run, because the functionality implemented at the break point is usable.\n\nIn IE 11 my JS files are shown in the \"dynamic scripts\" tree and I can set breakpoints as well, but everytime I reload the current page the icon for the breakpoint changes and gets some defect triangle with a warning sign, just like the breakpoint won't work anymore or such. And of course IE doesn't stop the code as well after I reload the page and if I open my JS file the breakpoint is not shown anymore, which at least works in Firefox's Firebug.\n\nNone of those problems happen in Opera/Chrome, I always see all my files, can set breakpoints and the code stops as expected. Additionally all browsers show individual requests for my JS file, nothing is bundled into one big one or such, it's all independent files during development.\n\nSo is StealJS and how it loads files simply incompatible with the other browsers? Do they need to add support for how Steal handles file loading? I used a former version of Steal with JavaScriptMVC and none of these problems occured with that version.\n    ", "Answer": "\r\nLooks like those are browser issues, so go and write bug reports.\n\nhttps://github.com/stealjs/steal/issues/419#issuecomment-99059303\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "rbenv: Surviving without gemsets\r\n                \r\nTL;DR\n\n\nDon't bother with gemsets; multiple versions of a gem may be installed concurrently.\nWhen necessary, specify which version to execute using ```\n$ gem-based-binary _version_ args```\n notation.\nUse ```\nbundle exec```\n when you have a Gemfile specifying the version.\n\n\n```\ngem install rails -v 3.2.13\nrails _3.2.13_ new Project2\ncd Project2\nbundle exec rails server\n```\n\n\n\n\nUPDATE: 2015-06-04\n\nI wrote this question three years ago.  Partly, it was based on a false assumption, and partly the situation has changed since then.  With appreciation to @indirect for his original answer, I want to call attention to @kelvin's newer (less upvoted) answer, summarized above.\n\nMy false assumption: Only a single version of a gem could be installed at a time, hence the need for gemsets to isolate the namespace.  Not true.  Multiple versions of a gem may be installed concurrently.  The most recent one will be used when invoked from a command line, unless you have a Gemfile specifying the version constraints and invoke the command via ```\nbundle exec```\n, or specify the version as its first argument.\n\nSee also How can I call an older version of a gem from the commandline? re: the underscore-version notation.\n\n\n\nOriginal question:\n\nI have multiple projects going on using different versions of Rails.  I have a workflow (described below) for creating projects using specific versions of rails, and keeping the projects isolated from each other.  I'd like to experiment with other workflows, in particular, using rbenv instead of RVM, but it's not clear how to do so.\n\nQUESTION:  What is the best current practice for creating multiple rails projects, each using a different version of rails, when making use of rbenv and bundler, as opposed to rbenv-gemset or rvm?\n\nUSE CASE:  I have two rails projects, called ProjectA and ProjectB.  ProjectA is developed using one version of rails (\"RailsA\"), whereas ProjectB uses a different version (\"RailsB\").  How do I manage having both versions installed?\n\nTHE GEMSETS APPROACH:  When I first started with Rails development, I used RVM.  In addition to supporting multiple, concurrent installations of ruby, RVM supports having multiple Named Gem Sets.  Each project has its own independent collection of gems (including rails itself) called a gemset:\n\n```\nrvm gemset create RailsA\nrvm gemset use RailsA\n# RailsA.  Note: My question is not version-specific.\ngem install rails --version 3.0\nrails new ProjectA\ncd ProjectA\nrvm --rvmrc use `rvm current`\nvi Gemfile\nbundle install\ncd ..\n## Now do the same for ProjectB\nrvm gemset create RailsB\nrvm gemset use RailsB\ngem install rails --version 3.2\nrails new ProjectB\ncd ProjectB\nrvm --rvmrc use `rvm current`\nvi Gemfile\nbundle install\n```\n\n\nNote: The very creation of the project folders should be done (IMHO) by a ```\nrails new```\n command using the desired version of rails, since the skeleton files change from version to version.  (Perhaps I should revisit this premise?)\n\nTHE BUNDLER APPROACH: I've been playing with using rbenv instead of RVM, but I don't understand the workflow as clearly.  In the README.md, Sam Stephenson writes that \"rbenv does not ... manage gemsets.  Bundler is a better way to manage application dependencies.\"  There is a plugin (rbenv-gemset) for getting the same results as rvm's gemsets, but Sam clearly favors using Bundler instead.  Unfortunately, he doesn't elaborate on what the workflow would look like.  Even the Bundler website doesn't explicitly connect all the dots of how to isolate one project from another.  Several blogs and gists come to the rescue, suggesting the following ```\n~/.bundle/config```\n file:\n\n```\n---\nBUNDLE_PATH: vendor/bundle\n```\n\n\n(BTW, I'm not sure what the \"---\" is about.  The docs make no mention of it and it doesn't seem to make a difference.)\n\nThis effectively gives each rails project its own gemset, storing the gems in ProjectX/vendor/bundle/.  In fact, rails itself will be (re-)installed there, making the project completely independent of the rest of my environment, once I run ```\nbundle install```\n.\n\nBut the elephant in the room is the chicken-and-egg problem of creating the rails project folder in the first place!!   In order to create the ProjectA folder using RailsA, I need to install rails (and its numerous dependencies) first.   But when I want to create ProjectB, I must then switch to using RailsB.  Without gemsets, I must do some serious upgrading/downgrading.  Not cool.\n\nA possible solution is simply not to worry about what version of rails I use to create the ProjectX folder.  If I then use rails 3.0 to create a 3.2 project, I could just manually create the app/assets tree.  But that just irks me.  Ain't there a better way?\n    ", "Answer": "\r\nMost people solve this by installing the rails gem first via ```\ngem install rails```\n. If you refuse to do that for some reason, you can opt out of the automatic bundling that Rails attempts to do for you. This will work completely regardless of your ruby management system.\n\n```\nmkdir myapp\ncd myapp\necho \"source :rubygems\" > Gemfile\necho \"gem 'rails', '3.2.2'\" >> Gemfile\nbundle install --path vendor/bundle\nbundle exec rails new . --skip-bundle\n```\n\n\nWhen prompted, type \"y\" to replace your Gemfile with the default Rails one (or not, as you prefer). Then, once it's done:\n\n```\nbundle install\n```\n\n\nYou're done, and you have boostrapped a new rails app with the version of your choice without installing the rails gem into rubygems.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Saving jpg in SQL from Access VBA\r\n                \r\nI'm trying to save a jpg file into SQL and display it in an Access FE. In SQL I have a table with a varbinary(max) column. In Access a form referencing the field which does not display the image but searching found that if I set something like ```\nImage1.PictureData = me.sqlImage```\n in the Form_Current() I can get it to display.\n\nNow the issue. If I insert the picture in T-SQL with something like this\n\n```\nUPDATE MyTableName\n\nSET SQLImage=(SELECT * FROM OPENROWSET(BULK N'test.jpg', SINGLE_BLOB) as x)\n\nWHERE IndexField='0123'\n```\n\n\nIt displays the image as desired. However, if I attempt to insert\\update the image from VBA with the following,\n\n```\n    Set dlgAdd = Application.FileDialog(msoFileDialogFilePicker)\n    With dlgAdd\n        .Filters.Clear\n        .Filters.Add \"Picture Files (*.jpg, * .jpeg)\", \"*.jpg;*.jpeg\"\n        .AllowMultiSelect = False\n        .Title = \"Select Picture\"\n\n        If .Show = True Then\n            '-- Open .Item For Binary As #1\n            Open .SelectedItems(1) For Binary As #1\n            '-- ReDim bytData(FileLen(.Item))\n            ReDim bytData(FileLen(.SelectedItems(1)) -1)\n        Else\n            Exit Sub\n        End If\n    End With\n\n    Get #1, , bytData\n    Close #1\n\n\n    Set DB = CurrentDb\n    strSQL = \"SELECT * FROM MyTableName WHERE IndexField='\" & Me.IndexField & \"'\"\n    Set RS = DB.OpenRecordset(strSQL, dbOpenDynaset, dbSeeChanges)\n    RS.OpenRecordset\n\n    RS.Edit\n    RS.Fields(\"SQLImage\").AppendChunk bytData\n    RS.Update\n    RS.Close\n```\n\n\nThen I get the lovely \"The bitmap you specified is not in a device-independent bitmap (.dib) format\" error attempting the ```\nImage1.PictureData```\n Searching more I found a reference to using a Web Browser Control to convert it to base64 which doesn't give me the error but only displays the small \"x\" box instead of the image so it still doesn't work.\n\nWhat am I doing wrong saving the jpg from Access VBA? It works fine if I insert the image from T-SQL but I want to have the users update the images from the FE.\n\nThanks in advance,\n\nEdit: Found article https://rtmccormick.com/2013/08/22/select-a-file-with-file-dialog-in-ms-access-with-vba/ and changed from ```\n.Item```\n to ```\n.SelectedItems(1)```\n. Left my original use commented for clarity. Based on comments checked size with a test integer and was showing 0 length after Open. Changed to ```\n.SelectedItems(1)```\n and now behaves correctly. Thanks to @Charles & @Erik A getting me to stop focusing on the tree. :)\n\nEdit2: I've included the test if file selected or canceled out if someone tries to copy\\paste since I haven't included everything (dims etc) but that part should have been there.\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Inspection of trees in a Quantile Random Forest Regression model\r\n                \r\nI am interested in training a random forest to learn some conditional quantile on some data {X, y} sampled independently from some distribution.\nThat is, for some $$\\alpha \\in (0, 1)$$, a mapping $$\\hat{q}{\\alpha}(x) \\in [0, 1]$$ such that for each $X$, $$argmin{\\hat{q}{\\alpha} P(y < \\hat{q}\\alpha(x)) > \\alpha$$.\nIs there any clear way to build a random forest effectively in python that could yield such a model?\nAdditionally, I have one added requirement that may be possible with the current libraries, though I am unsure. Requirement: I would like to select a subset of points, A, from my training set and select and exclude those trees that were trained with points in A from my random forest as I make predictions.\n    ", "Answer": "\r\nThere is a Python-based, scikit-learn compatible/compliant Quantile Regression Forest implementation that can be used to estimate conditional quantiles here: https://github.com/zillow/quantile-forest\nYour additional requirement of making predictions on training samples by excluding trees that included those samples during training is called out-of-bag (OOB) estimation, and can also be done with the above package.\nSetup should be as easy as:\n```\npip install quantile-forest\n```\n\nThen, here's an example of how to fit a quantile random forest model and use it to predict quantiles with OOB estimation for a subset (here the first 100 rows) of the training data:\n```\nimport numpy as np\nfrom quantile_forest import RandomForestQuantileRegressor\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\n\nX, y = datasets.fetch_california_housing(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\nqrf = RandomForestQuantileRegressor()\nqrf.fit(X_train, y_train)\n\n# Predict OOB quantiles for first 100 training samples.\ny_pred_oob = qrf.predict(\n    X_train[:100, :],\n    quantiles=[0.025, 0.5, 0.975],\n    oob_score=True,\n    indices=np.arange(100),\n)\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "PayUmoney iOS SDK multiple issues during uploading app on apple store with XCODE9.3(Objective-C)\r\n                \r\nErrors:\n\n\n  1.ITMS-90087 Unsupported Archtecture  PayUmoneyCoreSDK.framework containts unsupported architectures '[x86_64,i386]' also for\n  CitrusGraphics and PlugNPlay framework.\n  \n  2.ITMS-90209 Invalid Segment Alignment  CitrusGraphics does not have proper segment also for PlugNPlay and PayUmoneyCoreSDK framework.\n  \n  3.ITMS-90125 The Binary is invalid \"The incryption info in the LC_ENCRYPTION_INFO load command is either missing or invalid or the\n  binary is already encrypted.This binary does not seem to have been\n  built with Apple's linker\"\n  \n  Warnings:\n  1.ITMS-90080 PayUMoneyCoreSDK.framwork is not a position Independent Executable.Please ensure that your build setting are configured to\n  create PIE executables.\n\n\nI removed above framework from Embedded Binaries then uploaded to app store.Its uploaded successfully but app store rejected app because above libraries image not found issue and app crash initially.\n\nI took support from PayUmoney they suggested to again integrate iOS SDK.I did that but still issue is there.\n\nAnd someone please told why this is happening? Becasue last year  old iOS SDK worked fine.Once I integrated new update for XCODE 9 then issue will raise. I worked with objective-C and XCODE 9.3\n\nHere is updated iOS SDK link :https://github.com/payu-intrepos/PayUMoney-IOS-SDK/tree/master/PlugNPlay/Objective-C%20SampleApp \n\nI attached some snippet of issue.\n\nhttps://drive.google.com/file/d/1dV8Scc2K47o-V9lhVLSCl46o_cMxA6x0/view?usp=sharing\n\nhttps://drive.google.com/file/d/17P5ZCegveF2xdq73AEwuX0Wqwr6h68fP/view?usp=sharing\n\nhttps://drive.google.com/file/d/1xAB0WH1zLlqCRQxEbROVmRBP4TngkEzM/view?usp=sharing\n\nhttps://drive.google.com/file/d/10gPbOd9fwsMKj_RAqNRexcU6OUNFsgOn/view?usp=sharing\n\nhttps://drive.google.com/file/d/1KsP7QtvRoPVSCMNAAt9JGDmJEUBfDaH7/view?usp=sharing\n\nhttps://drive.google.com/file/d/1eXkCvGQU_7fnFJy136jV0S8YkI8Fpvqn/view?usp=sharing\n\nhttps://drive.google.com/file/d/1oU1TfIwpKQx_dx1eD2nFwmmiAPjKudsu/view?usp=sharing\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "PayUmoney iOS SDK multiple issues during uploading app on apple store with XCODE9.3(Objective-C)\r\n                \r\nErrors:\n\n\n  1.ITMS-90087 Unsupported Archtecture  PayUmoneyCoreSDK.framework containts unsupported architectures '[x86_64,i386]' also for\n  CitrusGraphics and PlugNPlay framework.\n  \n  2.ITMS-90209 Invalid Segment Alignment  CitrusGraphics does not have proper segment also for PlugNPlay and PayUmoneyCoreSDK framework.\n  \n  3.ITMS-90125 The Binary is invalid \"The incryption info in the LC_ENCRYPTION_INFO load command is either missing or invalid or the\n  binary is already encrypted.This binary does not seem to have been\n  built with Apple's linker\"\n  \n  Warnings:\n  1.ITMS-90080 PayUMoneyCoreSDK.framwork is not a position Independent Executable.Please ensure that your build setting are configured to\n  create PIE executables.\n\n\nI removed above framework from Embedded Binaries then uploaded to app store.Its uploaded successfully but app store rejected app because above libraries image not found issue and app crash initially.\n\nI took support from PayUmoney they suggested to again integrate iOS SDK.I did that but still issue is there.\n\nAnd someone please told why this is happening? Becasue last year  old iOS SDK worked fine.Once I integrated new update for XCODE 9 then issue will raise. I worked with objective-C and XCODE 9.3\n\nHere is updated iOS SDK link :https://github.com/payu-intrepos/PayUMoney-IOS-SDK/tree/master/PlugNPlay/Objective-C%20SampleApp \n\nI attached some snippet of issue.\n\nhttps://drive.google.com/file/d/1dV8Scc2K47o-V9lhVLSCl46o_cMxA6x0/view?usp=sharing\n\nhttps://drive.google.com/file/d/17P5ZCegveF2xdq73AEwuX0Wqwr6h68fP/view?usp=sharing\n\nhttps://drive.google.com/file/d/1xAB0WH1zLlqCRQxEbROVmRBP4TngkEzM/view?usp=sharing\n\nhttps://drive.google.com/file/d/10gPbOd9fwsMKj_RAqNRexcU6OUNFsgOn/view?usp=sharing\n\nhttps://drive.google.com/file/d/1KsP7QtvRoPVSCMNAAt9JGDmJEUBfDaH7/view?usp=sharing\n\nhttps://drive.google.com/file/d/1eXkCvGQU_7fnFJy136jV0S8YkI8Fpvqn/view?usp=sharing\n\nhttps://drive.google.com/file/d/1oU1TfIwpKQx_dx1eD2nFwmmiAPjKudsu/view?usp=sharing\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Selenium / Django gives Foreign Key error\r\n                \r\nI am trying to run functional tests using Selenium for a Django project. On both Firefox and Chrome I am getting a weird Foreign Key error when I try to test that a superuser can change a normal user's status to staff (I assume this is all verified via Django's internal testing, but thought it would be good practice to include it in my app's testing since my user scenarios depend on the functionality). It almost looks like Django doesn't like Selenium saving anything to the database? This one error trickles down to my other tests, too, so it seems like something breaks behind the scenes--like Selenium loses its database connection. Does anyone know why this happens?? I'm willing to dump the test in favor of assuming that the functionality works, but would love to fix this and use the test.\n\nOne possible symptom is that in Chrome, between between the outputs of \"checked the box\" and \"clicked the save button\", I get a broken pipe (does not happen in Firefox).\n\nIt seems to break around here, whenever Selenium clicks the 'save' button:\n\n```\n# Form looks properly rendered, now click the 'Staff status'\n# checkbox and submit it\nisStaffCheckbox = self.browser.find_element_by_id('id_is_staff')\nisStaffCheckbox.click()               \nprint 'checked the box'\n# Save the form\nsaveBtn = self.browser.find_element_by_css_selector('input[value=\"Save\"]')\nsaveBtn.click()\nprint 'clicked the save button'\n```\n\n\nThe error message I get is:\n\n```\nTraceback (most recent call last):\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/test/testcases.py\", line 268, in __call__\n    self._post_teardown()\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/test/testcases.py\", line 533, in _post_teardown\n    self._fixture_teardown()\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/test/testcases.py\", line 553, in _fixture_teardown\n    skip_validation=True, reset_sequences=False)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/core/management/__init__.py\", line 161, in call_command\n    return klass.execute(*args, **defaults)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/core/management/base.py\", line 255, in execute\n    output = self.handle(*args, **options)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/core/management/base.py\", line 385, in handle\n    return self.handle_noargs(**options)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/core/management/commands/flush.py\", line 82, in handle_noargs\n    emit_post_sync_signal(set(all_models), verbosity, interactive, db)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/core/management/sql.py\", line 195, in emit_post_sync_signal\n    interactive=interactive, db=db)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/dispatch/dispatcher.py\", line 170, in send\n    response = receiver(signal=self, sender=sender, **named)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/contrib/auth/management/__init__.py\", line 96, in create_permissions\n    auth_app.Permission.objects.using(db).bulk_create(perms)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/db/models/query.py\", line 444, in bulk_create\n    self._batched_insert(objs_without_pk, fields, batch_size)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/db/models/query.py\", line 902, in _batched_insert\n    using=self.db)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/db/models/manager.py\", line 215, in _insert\n    return insert_query(self.model, objs, fields, **kwargs)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/db/models/query.py\", line 1661, in insert_query\n    return query.get_compiler(using=using).execute_sql(return_id)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/db/models/sql/compiler.py\", line 937, in execute_sql\n    cursor.execute(sql, params)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/db/backends/mysql/base.py\", line 122, in execute\n    six.reraise(utils.IntegrityError, utils.IntegrityError(*tuple(e.args)), sys.exc_info()[2])\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/django/db/backends/mysql/base.py\", line 120, in execute\n    return self.cursor.execute(query, args)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/MySQL_python-1.2.4b4-py2.7-macosx-10.8-intel.egg/MySQLdb/cursors.py\", line 202, in execute\n    self.errorhandler(self, exc, value)\nFile \"~/virtual_environments/VideoSearch/lib/python2.7/site-packages/MySQL_python-1.2.4b4-py2.7-macosx-10.8-intel.egg/MySQLdb/connections.py\", line 36, in defaulterrorhandler\n    raise errorclass, errorvalue\nIntegrityError: (1452, 'Cannot add or update a child row: a foreign key constraint fails (`test_videos2002`.`auth_permission`, CONSTRAINT `content_type_id_refs_id_d043b34a` FOREIGN KEY (`content_type_id`) REFERENCES `django_content_type` (`id`))')\n```\n\n\n=====\nUpdated with code\n\n\nAlso note that test_admin_can_make_a_user_staff causes my other tests to Error out with the same error--but they are okay when I take out the \"save\" command from that test.\nI guess two things I really don't understand are: 1) Why this happens with the built-in Django admin view (thought it should just work), and 2) Why one test error cascades through to my other tests? I thought they were independent.\n\n\nThanks for looking at this!\n\nFrom my functional_tests.test.py (borrowed from https://github.com/lincolnloop/django-selenium-intro/tree/master/selenium_intro):\n\n```\nfrom django.test import LiveServerTestCase\n\nclass SeleniumTestCase(LiveServerTestCase):\n    \"\"\"\n    A base test case for selenium, providing hepler methods for generating\n    clients and logging in profiles.\n    \"\"\"\n\n    def open(self, url):\n        self.browser.get(\"%s%s\" % (self.live_server_url, url))\n```\n\n\nFrom my admin_django.py (set of test cases)\n\n```\nfrom functional_tests.test import SeleniumTestCase\n\nfrom selenium.webdriver.common.keys import Keys\nfrom django.core.urlresolvers import reverse\nfrom django.contrib.auth.models import User\nfrom django.test import LiveServerTestCase\nfrom django.conf import settings\nfrom selenium import webdriver\n\n\nclass AdminDjango(SeleniumTestCase):\n    def setUp(self):\n        User.objects.create_superuser(username='vcb',\n                                      password='rock5!',\n                                      email='me@name.edu')\n        User.objects.create_user(username='teaching',\n                                 password='assistant',\n                                 email='ta@name.edu')\n#        self.browser = webdriver.Chrome(settings.SELENIUM_WEBDRIVER)\n        self.browser = webdriver.Firefox()\n        self.browser.implicitly_wait(3)\n        self.browser.set_page_load_timeout(10)\n\n    def tearDown(self):\n        self.browser.quit()\n\n    def check_for_links(self, link_text):\n        \"\"\"\n        Helper function to check links on a page for certain text\n        \"\"\"\n        links = self.browser.find_elements_by_tag_name('a')\n        self.assertTrue(link_text, [link.text for link in links])\n\n    def admin_logs_in(self):\n        \"\"\"\n        Helper function that logs the admin user into the page\n        \"\"\"\n        username_field = self.browser.find_element_by_name('username')\n        username_field.send_keys('vcb')\n\n        password_field = self.browser.find_element_by_name('password')\n        password_field.send_keys('rock5!')\n        password_field.send_keys(Keys.RETURN)\n\n    def admin_log_in_complete(self):\n        \"\"\"\n        Includes navigation to the admin page\n        \"\"\"\n        self.open('/admin/')\n        self.admin_logs_in()\n\n    def test_admin_can_login(self):\n        \"\"\"\n        Admin user can log into the Django admin interface\n        \"\"\"\n        self.open('/admin/')\n        body = self.browser.find_element_by_tag_name('body')\n        self.assertIn('VCB Administration', body.text)\n\n        self.admin_logs_in()\n\n        # her username and password are accepted, and she is taken to\n        # the Site Administration page\n        body = self.browser.find_element_by_tag_name('body')\n        self.assertIn('Site administration', body.text)\n\n    def test_admin_page_renders_properly(self):\n        \"\"\"\n        The admin page should have at least two fields:\n         - Users\n         - Classes\n        Admins may have to add staff status to users, and they may have to\n        adjust the information for a class\n        \"\"\"\n        self.admin_log_in_complete()\n\n        self.check_for_links('Users')\n        self.check_for_links('Groups')\n        self.check_for_links('Classess')\n\n    def test_admin_can_make_a_user_staff(self):\n        \"\"\"\n        Admin users can add staff status to existing users\n        \"\"\"\n        self.admin_log_in_complete()\n        pageLinks = self.browser.find_elements_by_tag_name('a')\n\n        for link in pageLinks:\n            if link.text == 'Users':\n                userLink = link\n\n        userLink.click()\n\n        headers = self.browser.find_elements_by_tag_name('h1')\n        self.assertTrue('Select user to change', \n                [header.text for header in headers])\n\n        users =     self.browser.find_elements_by_xpath('//table[@id=\"result_list\"]/tbody/tr/th/a')\n\n        self.fail('Finish writing the test!')\n#        rowCount = 1\n#        for user in users:\n#            xpath = '//table[@id=\"result_list\"]/tbody/tr[' + str(rowCount) + ']/td[5]/img'\n#            # check first that this user is not a staff\n#            staffIcon = self.browser.find_element_by_xpath(xpath)\n#            isStaff = staffIcon.get_attribute('alt')\n#            \n#            if isStaff == 'false':\n#                user.click()\n#                userHeaders = self.browser.find_elements_by_tag_name('h1')\n#                self.assertTrue('Change user', \n#                        [userHeader.text for userHeader in userHeaders])\n#            \n#                # Are the right fields present in the user's form?\n#                formHeaders = self.browser.find_elements_by_tag_name('h2')\n#                self.assertTrue('Personal info', \n#                        [formHeader.text for formHeader in formHeaders])\n#                self.assertTrue('Permissions', \n#                        [formHeader.text for formHeader in formHeaders])\n#                self.assertTrue('Important dates', \n#                        [formHeader.text for formHeader in formHeaders])\n#            \n#                # Form looks properly rendered, now click the 'Staff status'\n#                # checkbox and submit it\n#                isStaffCheckbox = self.browser.find_element_by_id('id_is_staff')\n#                isStaffCheckbox.click()\n#                print 'checked the box'\n#                # Save the form\n#                saveBtn = self.browser.find_element_by_css_selector('input[value=\"Save\"]')\n#                saveBtn.click()\n#                print 'clicked the save button'\n#                # Returns you to the admin page\n#                messageBox = self.browser.find_element_by_class_name('info')\n#                self.assertIn('successfully', messageBox.text)\n#                \n#                # Check that staff status changed\n#                staffIcon = self.browser.find_element_by_xpath('//table[@id=\"result_list\"]/tbody/tr[' + str(rowCount) + ']/td[5]/img')\n#                isStaff = staffIcon.get_attribute('alt')\n#                self.assertTrue(isStaff)\n#                print 'should now be staff'\n#            rowCount += 1\n\n\n    def test_admin_can_change_a_class_obj_bank_id(self):\n        \"\"\"\n        Admin users can change a class's objective bank id\n        \"\"\"\n        self.fail('Finish writing the test!')\n\n    def test_logging_out_redirects_to_login_page(self):\n        \"\"\"\n        Logging out of the admin page should redirect to the main page\n        \"\"\"\n        self.admin_log_in_complete()\n        logOut = self.browser.find_element_by_link_text('Log out')\n        logOut.click()\n        body = self.browser.find_element_by_tag_name('body')\n        self.assertIn('VCB Administration', body.text)\n```\n\n    ", "Answer": "\r\nAs I mentioned in the comments, this seems to be a documented bug in Django. Here and here are the official bug reports. As reported in the second link, one workaround is to swap the order of ```\ndjango.contrib.auth```\n and ```\ndjango.contrib.contenttypes```\n in ```\nINSTALLED_APPS```\n, as such:\n\nWhat originally is this:\n\n```\nINSTALLED_APPS = (\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.sites',\n    'django.contrib.admin',\n    'testapp'\n)\n```\n\n\nShould become:\n\n```\nINSTALLED_APPS = (\n    'django.contrib.contenttypes',\n    'django.contrib.auth',\n    'django.contrib.sessions',\n    'django.contrib.sites',\n    'django.contrib.admin',\n    'testapp'\n)\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "CKEditor5 use model in custom Data Processor\r\n                \r\nI was playing with CKEDitor5, and I tried to create a custom Data Processor. I'd like to use the model in the ```\ntoData```\n conversion, but the method is called with the ```\nview/DocumentFragment```\n object. So my question is that how could I convert that into a ```\nmodel/DocumentFragment```\n object (or how to access the model from a data processor).\n\nUpdate (as it cannot fit into a comment):\nLet me try to better explain what exactly I try to do (or I already did so far) in a bit more detail. I figured out how to use access the model itself, but that seemed like a bad solution as you also pointed it out.\n\nSo basically I want to create a ```\nDataProcessor```\n to convert the editor data to BBCode, which sounds reasonable enough I guess. \n\nOn one hand, the ```\ntoView```\n method is simple, as the BBCode to HTML conversion can be assumed to be already implemented (in my case). And from HTML it seems to be trivial to load the editor data (by the same process used by the Markdown processor).\n\nOn the otherhand, it seems easier to convert to BBCode from the model data rather than the view. Mostly because the ```\nview/DocumentFragment```\n object and the rest of the view tree is pretty much just another representation of the DOM or HTML. I don't really care for whether bold is ```\n<b>```\n or ```\n<strong>```\n i just want to know whether the ```\ntext```\n node has the ```\nbold```\n attribute or not. \n\nBy using the model, I hope to work with the semantics rather than the representation used in HTML. It seems a bit pointless to basically map all HTML tags to their BBCode equvivalents (even if CKE5 does a good job of providing consistent HTML tags). So from my point of view, using the model just makes more sense. Converting from semantic representation to a \"data format\" is easier than to convert to a \"data format\" (view tree, DOM, HTML, morse code) and then create a \"representation map\" after that.\n\nFor a long time what blocked us from using RTEs or WYSIWYG editors were exactly the difficulty of converting from HTML to BBCode. Now CKE5 has model, which seems to be easy to convert to anything, as it is independent not just from the HTML format but the HTML displayed in the editor as well (this cannot be said about the view tree as it is exactly the HTML in the editor - at least it is not whatever contenteditable produces, but still not good enough).\n\nAlso: I just made a ```\nPlugin```\n that sets the ```\nDataProcessor```\n, as that was what the Markdown feature kind of does as well (in the docs somewhere). Is that a bad idea?\n\nThanks again for your answer.\n    ", "Answer": "\r\nRecently, a similar question was raised on CKE5 GitHub. The question is about getting JSON data as editor output, but topic raised by you is also partially covered.\n\n\n  (...) how to access the model from a data processor\n\n\nThere are certain problems and risks connected with operating straight on the model. This is not something that is recommended. It is explained in the linked post.\n\n\n  (...) my question is that how could I convert that into a ```\nmodel/DocumentFragment```\n\n\n\nThis is a better (less risky) approach than operating straight on the model. However, I have to ask - why do you want to convert from the model? Maybe there's a better solution to your problem?\n\nTo convert between view and model, one would have to use ```\nDataController#toView```\n and ```\nDataController#toModel```\n. ```\nDataController```\n instance is available at ```\nEditor#data```\n. To use it in a data processor, the data processor would need access to the editor instance.\n\nI'd suggest creating your own editor class, extending one of CKE5 editor classes. Then, in the new editor class constructor, overwrite data processor and also pass editor instance. Something like:\n\n```\nclass MyEditor extends ClassicEditor {\n  constructor() {\n    this.data.processor = new MyDataProcessor( this );\n  }\n}\n\nclass MyDataProcessor() {\n  constructor( editor ) {\n    this._editor = editor;\n  }\n\n  toData( viewDocumentFragment ) {\n    const modelDocumentFragment = this._editor.data.toModel( viewDocumentFragment );\n    // ...\n  }\n\n  toView( modelData ) {\n    // ...\n    this._editor.data.toView( ... );\n    // ...\n  }\n}\n```\n\n\nThese are just to show the direction, not working/tested samples.\n\nStill, I'd like to know why you insist on using the model rather than the view to generate editor output.\n\nBTW. If you go on and implement it like this, the whole process will be a bit silly :). First, you will get a model data, then convert it to view (in data processor), then the editor will take view data and convert it back to the model :). So maybe you will be also interested in overwriting ```\nEditor#setData```\n method so unnecessary conversions won't take place.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Asymptotically Fast Associative Array with Low Memory Requirements\r\n                \r\nOk, tries have been around for a while. A typical implementation should give you O(m) lookup, insert and delete operations independently of the size n of the data set, where m is the message length. However, this same implementation takes up 256 words per input byte, in the worst case.\n\nOther data structures, notably hashing, give you expected O(m) lookup, insertion and deletion, with some implementations even providing constant time lookup. Nevertheless, in the worst case the routines either do not halt or take O(nm) time.\n\nThe question is, is there a data structure that provides O(m) lookup, insertion and deletion time while keeping a memory footprint comparable to hashing or search trees?\n\nIt might be appropriate to say I am only interested in worst case behaviour, both in time and space-wise.\n    ", "Answer": "\r\nDid you try Patricia-(alias critbit- or Radix-) tries? I think they solve the worst-case space issue.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Memory leak when using json-data on a map\r\n                \r\nI've the following problem:\n\nI'm accessing foursquares Venue API and get a JSON string back. I parse this string with this json-framework. After that I'm saving the dictionaries and arrays for accessing further information about the venues (in special I'm using the explore API). So the venue information is saved deeply (for my experience) in the json-structure tree. And after getting the needed information (venue name & coordinates) I put a corresponding pin on a map with the same coordinates and with the venue's name as the pin's name.\n\nAnd exactly at the point where I want to set the pin's name, I get a memory leak. So something get's wrong here. If I don't set any title, all works fine. So the memory leak occurs only when I'm setting the name of the venue to the pin.\n\nHere is the corresponding code fragment:\n\n```\n- (void)connectionDidFinishLoading:(NSURLConnection *)connection\n{\n    //Parse JSON string\n    // Store incoming data into a string\n    NSString *jsonString = [[NSString alloc] initWithData:self.fetchedJSONData encoding:NSUTF8StringEncoding];\n    [self.fetchedJSONData setLength:0];\n\n    // Create a dictionary from the JSON string     \n    NSDictionary *results = [NSDictionary dictionaryWithDictionary:[jsonString JSONValue]];\n    [jsonString release];\n\n    NSDictionary *response = [NSDictionary dictionaryWithDictionary:[results objectForKey:@\"response\"]];\n\n    NSArray *groups = [NSArray arrayWithArray:[response objectForKey:@\"groups\"]];\n    NSDictionary *groupsDic = [groups lastObject];\n    NSArray *items = [NSArray arrayWithArray:[groupsDic objectForKey:@\"items\"]];\n\n   for (int i=0; i<[items count]; i++)\n   {\n        CLLocationCoordinate2D annotationCoord;\n        MKPointAnnotation *annotationPoint = [[MKPointAnnotation alloc] init];\n        NSDictionary* oneItemDoc = [NSDictionary dictionaryWithDictionary:[items objectAtIndex:i]]; \n        NSDictionary *singleVenue = [NSDictionary dictionaryWithDictionary:[oneItemDoc objectForKey:@\"venue\"]];             \n\n        /*\n         *          Leak here in the next two lines!\n         *\n         */\n\n        NSString *titleName = [[[singleVenue objectForKey:@\"name\"] copy] autorelease]; \n        annotationPoint.title = titleName;\n\n        NSDictionary *locationOfVenue = [NSDictionary dictionaryWithDictionary:[singleVenue objectForKey:@\"location\"]];\n\n        annotationCoord.latitude = [[locationOfVenue objectForKey:@\"lat\"] doubleValue];\n        annotationCoord.longitude = [[locationOfVenue objectForKey:@\"lng\"] doubleValue];               \n        annotationPoint.coordinate = annotationCoord;\n\n        [self.mapView addAnnotation:annotationPoint];\n        [self.annotationsArray addObject:annotationPoint];\n        [annotationPoint release];\n   }\n}\n```\n\n\nSo the leak occurs when I want to set the title for the annotationPoint.\n\nFor each venue fetched with JSON I get the following leak trace (blurred libraries are my own libraries):\n\n\n\nHas anybody a suggestion how to solve this problem? I tried many, many things. So the key issue seems to be how to \"hand over\" the ```\n[singleVenue objectForKey:@\"name\"]```\n correctly. I first tried to set it without a copy and an autorelease, but then I get a zombie object. So I don't know how to do this. I think the problem are not these two lines, but some lines above them. Am I right? I also have the suggestion, that my 3rd party json parser is forcing this problem (cf. leak trace).\n\nSo I hope someone can help me to fix this problem. Would be really great!\n\nUpdate: The problem seems to be independent of the corresponding JSON parser. I've testet my code with another parser, same problem there. So it has to do something with my code itself.\n\nI think I know what's the problem. So the leak occurs after closing the map. So after dealloc. So it might be, that I've missed something there. I have a mapview and I also release it in dealloc and set it to nil in viewDidUnload. I also release all the other Arrays etc. in dealloc. Is there something else (specific about the map and view) which I need to release? I think this might be the problem!\n\nUpdate: Solved the problem: I had to set all Foursquare pins' title and subtitle to nil in the dealloc method, because a value (accessed via a JSON parser) was retained by the map view somehow. Now all works fine!\n    ", "Answer": "\r\nSolved the problem: I had to set all Foursquare pins' title and subtitle to nil in the dealloc method, because a value (accessed via a JSON parser) was retained by the map view somehow. Now all works fine!\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Are any languages built upon uniquely represented data structures?\r\n                \r\nCopying immutable data is benign but wasteful of space. The reverse operation, sharing equal immutable data structures, can be used to reduce memory requirements and offer constant time equality, perfect hashing and dictionary lookup (e.g. for memoization). Maximal sharing can be achieved using techniques like hash consing and results in uniquely represented data structures. A related concept is history-independent data structures but their focus is security.\n\nI recently noticed whilst studying this benchmark that it is easy to adopt a unique representation and that it dramatically improves memory consumption and performance. Specifically, by referring to a symbolic expression as an integer index into a table that gives its constituent subexpressions and assigning the next consecutive integer when a never-before-seen expression is encountered. Furthermore, this representation is arguably more natural than the traditional (unshared) functional one when solving such problems in lower-level languages like C and C++. Symbolic, logic and dynamic programs (e.g. OCaml's Boyer benchmark) are well known to perform much better when hash consing is used to give their data structures unique representations so this result is not surprising or new.\n\nHowever, using hash consing from traditional languages is cumbersome which begs the question: do any programming languages automatically use unique representations for their primitive data structures?\n\nFor example, consider a mini-ML-like type system with integers, variables, tuples and unions. The construction of values of any type is easily hash consed using the technique I described above so all structurally-identical data will be maximally shared. Are there any programming languages that do this? If not, is there a show-stopping reason not to do this?\n\nSome background reading:\n\n\nUniquely Represented Data Structures for Computational Geometry\nConfluently persistents Sets and Maps\nB-Treaps: A Uniquely Represented Alternative to B-Trees\nPurely functional uniquely-represented deques\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "CMake add_subdirectory and recompiling\r\n                \r\nI've just migrated a somewhat large project from Visual Studio solutions to CMake and I've noticed a weird behavior.  I have something like the following structure:\n\n```\nproject/CMakeLists.txt\nproject/code/CMakeLists.txt\n\nproject/code/library-1/CMakeLists.txt\nproject/code/library-1/*.hpp\nproject/code/library-1/*.cpp\nproject/code/library-2/CMakeLists.txt\nproject/code/library-2/*.hpp\nproject/code/library-2/*.cpp\n...\nproject/code/library-n/CMakeLists.txt\nproject/code/library-n/*.hpp\nproject/code/library-n/*.cpp\n\nproject/demo/CMakeLists.txt\nproject/demo/demo-1/CMakeLists.txt\nproject/demo/demo-1/*.hpp\nproject/demo/demo-1/*.cpp\nproject/demo/demo-2/CMakeLists.txt\nproject/demo/demo-2/*.hpp\nproject/demo/demo-2/*.cpp\n...\nproject/demo/demo-n/CMakeLists.txt\nproject/demo/demo-n/*.hpp\nproject/demo/demo-n/*.cpp\n```\n\n\n\nThe root ```\nCMakeLists.txt```\n file configures the compilation flags, macro definitions, etc. and uses CMake's ```\nadd_subdirectory()```\n to include targets defined by the libraries and demo projects.\nThe ```\ncode```\n sub-folder contains a flat list of sub-folders with each containing source code for a static library (as well as its target defined in a ```\nCMakeLists.txt```\n file).\nThe ```\ndemo```\n sub-folder contains a flat list of sub-folders.  Each contains source code for an executable and associated ```\nCMakeLists.txt```\n file.\nEach library is a standalone component and builds independently from all other libraries and demo projects.\nEach demo program depends on one or more of the different libraries in the ```\ncode```\n sub-folder.\n\n\nThis setup is really nice.  If I want to change build options, I only need to modify the root ```\nCMakeLists.txt```\n and everything re-compiles with the new settings.  If I modify any source code anywhere in the tree, the appropriate libraries, if any, are recompiled and all dependent demo programs are also re-built.\n\nHowever, if I modify any ```\nCMakeLists.txt```\n file anywhere in the tree, the entire tree of libraries and programs is re-compiled without respect of dependencies.  To give an idea of what I mean, here a few parts of the CMake build scripts.\n\n\n\n```\nproject/demo/CMakeLists.txt```\n\n\n```\n# Resolve libraries built in `code` sub-folder.\nlink_directories(${LIBRARY_OUTPUT_PATH})\n\nset(demo-projects\n  demo-1\n  demo-2\n  ...\n  demo-n\n)\nforeach(demo-project ${demo-projects})\n  add_subdirectory(${demo-project})\nendforeach()\n```\n\n\n\n\n```\nproject/demo/demo-n/CMakeLists.txt```\n\n\n```\n# Find all source code in the same folder.\nfile(GLOB ${demo-project}_headers\n  ${CMAKE_CURRENT_SOURCE_DIR}/*.hpp\n)\nfile(GLOB ${demo-project}_sources\n  ${CMAKE_CURRENT_SOURCE_DIR}/*.cpp\n)\n\n# Select libraries to link with.\nset(${demo-project}_libraries\n  library-1\n  library-2\n  library-5\n)\n\n# Build the demo program.\nadd_executable(${demo-project}\n  ${${demo-project}_headers}\n  ${${demo-project}_sources}\n)\nif(${demo-project}_libraries)\n  target_link_libraries(${demo-project} ${${demo-project}_libraries})\nendif()\n\n# Manually register some dependencies on other targets.\nif(${demo-project}_dependencies)\n  add_dependencies(${demo-project} ${${demo-project}_dependencies})\nendif()\n```\n\n\n\n\nIf I happen to modify ```\nproject/demo/demo-n/CMakeLists.txt```\n to add an extra library, like this:\n\n```\nset(${demo-project}_libraries\n  library-1\n  library-2\n  library-5\n  library-6\n)\n```\n\n\nThen the entire source code for all libraries and demo programs in the project is re-compiled.  Why is this so?  Is there a better way to structure my scripts in order to avoid this?\n    ", "Answer": "\r\nThe first thing you want to do is figure out what changes.  You can use git to help you do that if you have it installed.\n\n\nRun cmake on your project with an out of source build\ncd to build directory\ncreate a git repo out of the build tree\ngit add .\ngit commit -m \"add build tree\"\nchange the cmakefile that causes the rebuild\nre-run cmake on the build tree\ncmake .\nrun git diff and see what changed.\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Set mat-table to use remaining space on screen with scrollbar\r\n                \r\nI have an application composed by this vertical structure:a navbar, a search section and table with the results.\nEach of these tree elements take up the space it needs without using fixed sizes. More over the search section has hidden sub-sections so it's size can change over time.\n\nWhat I'm trying to do is this: I would like these three sections to independently adjust their height to occupy all the space avaible. But since I can have a lot of results on the table this one needs to have, eventually, a vertical scrollbar. So the only scroolbar I want to see is in the table's results section.\n\nIf I set \n\n\n  overflow: auto\n\n\non the global CSS I see a global scrollbar if the table has too many results.\n\nHow can I force the table to use the remaining space on screen and show a scrollbar when it needs to? \n    ", "Answer": "\r\nYou can use CSS with Flexbox to make the table fill up the remaining screen space by setting the ```\nflex-grow```\n and ```\nflex-shrink```\n properties appropriately on your navbar, search, and table sections. Then use an absolutely positioned div with ```\noverflow: auto```\n to wrap your table.\n\nHTML:\n\n```\n<div id=\"container\">\n    <div id=\"navbar\"></div>\n    <div id=\"search\"></div>\n    <div id=\"table\">\n        <div id=\"table-container\">\n            <!-- Table goes here -->\n        </div>\n    </div>\n</div>\n```\n\n\nCSS:\n\n```\n#container {\n    height: 100vh;\n    display: flex;\n    flex-direction: column;\n    position: relative;\n}\n\n#navbar {\n    flex: 0 0 auto;\n    height: 70px;\n    width: 100%;\n}\n\n#search {\n    flex: 0 0 auto;\n    height: 50px;\n    width: 100%;\n}\n\n#table {\n    flex: 1 1 auto;\n    width: 100%;\n    position: relative;\n}\n\n#table-container {\n    position: absolute;\n    top: 0;\n    bottom: 0;\n    left: 0;\n    right: 0;\n    overflow: auto;\n}\n\n#table-container table {\n    width: 100%;\n}\n```\n\n\nAnd for bonus points, add ```\nposition: sticky```\n to pin the table header on scroll:\n\n```\n.mat-header-row th {\n    position: sticky;\n    top: 0;\n    background-color: white;\n}\n```\n\n\nStackblitz demo here: https://stackblitz.com/edit/angular-ykwfsy\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Nested and circular Module Federation bundles\r\n                \r\nI am running into what I think is multiple React modules initialize due to nested and circular federated modules. Wondering how to get around that, or is not not possible to have such scenario ?\nI have 2 apps. ```\nApp1```\n is the host app, but it also exposes ```\nComponent1```\n , which is used in ```\nApp2```\n.\nThe tree (overly simplified) looks like this: ```\nApp1```\n -> loads MF bundle dynamically from ```\nApp2```\n which in turn loads ```\nComponent1```\n from  MF bundle in ```\nApp1```\n\nWhen my ```\nComponent1```\n gets loaded, I see an error pointing to a potential duplicate ```\nReact```\n package on the page.\nError looks like below, and I ruled out the options 1 and 2 from React's error message:\n```\nUncaught Error: Invalid hook call. Hooks can only be called inside of the body of a function component. This could happen for one of the following reasons:\n1. You might have mismatching versions of React and the renderer (such as React DOM)\n2. You might be breaking the Rules of Hooks\n**3. You might have more than one copy of React in the same app**\nSee fb.me/react-invalid-hook-call for tips about how to debug and fix this problem.\n    at Object.throwInvalidHookError (VM13722 react-dom.development.js:16158)\n    at useEffect (VM13714 react.development.js:1631)\n```\n\nI have tested a simpler setup where ```\nApp2```\n runs independently and loads ```\nComponent1```\n from ```\nApp1```\n, that works no problem.\nApp1's webpack config has this setting:\n```\nnew webpack.container.ModuleFederationPlugin({\n            name: 'HostApp',\n            filename: `federatedEntry.js`,\n            exposes: {\n                Component1: './path/to/my/component',\n            },\n            remotes: {},\n            shared: {\n                react: {\n                    singleton: true,\n                    requiredVersion: deps.react,\n                },\n                'react-dom': {\n                    singleton: true,\n                    requiredVersion: deps['react-dom'],\n                },\n                'react-router-dom': {\n                    singleton: true,\n                    requiredVersion: deps['react-router-dom'],\n                },\n            },\n        })\n```\n\nApp2 webpack config looks similar:\n```\nnew ModuleFederationPlugin({\n            name: RemoteAppShell,\n            filename: remoteEntry.js,\n            exposes: {\n                Shell: './core/App',\n            },\n            shared: {\n                react: {\n                    import: 'react',\n                    shareKey: 'react',\n                    shareScope: 'default',\n                    singleton: true,\n                },\n                'react-dom': {\n                    singleton: true,\n                },\n                'react-router-dom': {\n                    singleton: true,\n                },\n            },\n        })\n```\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Recursive multiple relationships\r\n                \r\nI'm attempting to recursively perform alternate match statements with 2 specific relationships.\nFor example, Pets are owned by a Person.  Pets LIKE other people (not owner)  Those people have pets owned by them, who like other people etc.\n\n```\nmatch (n.Person {id.123})<-[r.OwnedBy]-(p.Pet)  Return n, r, p\nmatch (p.Pet {id.123})-[r.Likes]->(n.Person)  Return p, r, n\n```\n\n\nNotice the directional relationships involved - #1 is backwards, #2 is forwards.\n\nWhat I want to do is to, given a person(id),\n1. Display pets [OwnedBy] this person(id)\n2. Display people [Liked] by those pets\n3. Display pets [OwnedBy] the people in 2.\netc. recursively\n\nIndependently, these Match statements work.  together, they do not.\nI tried adding the 2nd match statement, using different variables, then it will go down 2 levels and stop.\n\nIn the real data set, there are dozens of nodes and relationships.  I'm trying to limit the display to a 'tree' view of only these 2 relationships/nodes.\n\nThanks!\n    ", "Answer": "\r\nHow about this?\n\n```\nmatch (n:Person {id:123})<-[:OwnedBy]-(p:Pet)-[:Likes]->(n2:Person)<-[:OwnedBy]-(p2:Pet)\nreturn n, collect(distinct p) as pets, collect(distinct n2) as peopleLiked, collect(distinct p2) as petsOfPeopleLiked\n```\n\n\nThough if you're only interested in the graph display, this should work:\n\n```\nmatch path = (n:Person {id:123})<-[:OwnedBy]-(p:Pet)-[:Likes]->(n2:Person)<-[:OwnedBy]-(p2:Pet)\nreturn path, n, p, n2, p2\n```\n\n\nYou can also utilize APOC Procedures. This can handle showing these paths, using only these two types of relationships:\n\n```\nmatch (n:Person {id:123})\ncall apoc.path.expandConfig(n, {relationshipFilter:'<OwnedBy|Likes>'}) yield path\nreturn path\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Fill Visible Area of Eclipse RCP Editor Without Scrolling\r\n                \r\nThis is a question about which general approach to take, so I haven't included any code.\n\nRequirement:\nI need to create a page within a multi-page editor that has two vertical sections in it.  The top section has a tree and the bottom section has a text field.  The tree and text field should fill their respective sections.  Each section should scroll independently and there should be a splitter in between.  When the editor is opened I want the visible area of the editor to be divided among the two sections based on some ratio I provide.  Then when the editor is resized, the two sections will adjust proportionally to maintain the ratio and fit the page.  This way there won't be scroll bars on the editor page itself, just the two sections.\n\nProposed Solution:\nMy idea was to add a ```\nSashForm```\n to the editor page and set the size of the ```\nSashForm```\n to be the same as the editor's visible area.  Then I'd add a resize listener to the editor page and adjust the size of the ```\nSashForm```\n so that it stays in sync with the page.  However, I can't find a way to get the editor's visible area.  So when I add the ```\nSashForm```\n it just makes each section big enough to fit its data and adds a scroll on the editor page itself.\n\nIs it possible to meet my requirement?\n    ", "Answer": "\r\nSuccess!  The key was to listen for resize events on the ```\nScrolledForm```\n.  I've only tested on Fedora but I'll take a look on Windows soon.  The only thing that bothers me is that the use of the buffer constants seems a little hacky.\n\n\n```\n/**\n * Form page that contains a sash form and a button.  The sash form is dynamically sized to ensure\n * that it always fills the available space on the page.\n */\npublic class SashFormDemoPage extends FormPage\n{\n    /** Horizontal buffer needed to ensure that content fits inside the page */\n    private static final int HORIZONTAL_BUFFER = 8;\n    /** Vertical buffer needed to ensure that content fits inside the page */\n    private static final int VERTICAL_BUFFER = 12;\n\n    /** Percentages of the sash form occupied by the tree and text box respectively */\n    private static final int[] SASH_FORM_WEIGHTS = new int[] {30, 70};\n\n\n    /**\n     * Constructor\n     * \n     * @param editor    parent editor\n     */\n    public SashFormDemoPage(ComponentEditor editor)\n    {\n        super(editor, \"sashFormDemoPage\", \"Demo\");\n    }\n\n\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected void createFormContent(IManagedForm managedForm)\n    {\n        // Set page title\n        ScrolledForm scrolledForm = managedForm.getForm();\n        scrolledForm.setText(\"SashForm Demo\");\n\n        // Set page layout and add a sash form\n        final Composite parent = scrolledForm.getBody();\n        parent.setLayout(new GridLayout());\n        final SashForm sashForm = new SashForm(parent, SWT.VERTICAL);\n\n        // Add a tree as the top row of the sash form and fill it with content\n        FormToolkit toolkit = managedForm.getToolkit();\n        int style = SWT.SINGLE | SWT.H_SCROLL | SWT.V_SCROLL | SWT.BORDER;\n        Tree tree = toolkit.createTree(sashForm, style);\n\n        for (int i = 0; i < 40; i++) {\n            TreeItem parentNode = new TreeItem(tree, SWT.NONE);\n            parentNode.setText(\"parent-\" + i);\n            for (int j = 0; j < 3; j++) {\n                TreeItem childNode = new TreeItem(parentNode, SWT.NONE);\n                childNode.setText(\"child-\" + i + \"-\" + j);\n            }\n        }\n\n        // Add a text box as the bottom row of the sash form and fill it with content\n        style = SWT.MULTI | SWT.V_SCROLL | SWT.WRAP | SWT.BORDER;\n        Text text = toolkit.createText(sashForm, null, style);\n\n        String message = \"\";\n        for (int i = 0; i < 100; i++) {\n            message += \"This is a test of the layout demo system.  This is only a test.  \";\n        }\n        text.setText(message);\n\n        // Add button below sash form\n        final Button button = toolkit.createButton(parent, \"Test\", SWT.NONE);\n\n        // Add resize listener to sash form's parent so that sash form always fills the page\n        parent.addControlListener(new ControlListener() {\n            @Override\n            public void controlMoved(ControlEvent e)\n            {\n                // Stub needed to implement ControlListener\n            }\n\n            @Override\n            public void controlResized(ControlEvent e)\n            {\n                GridData data = new GridData();\n                Point size = parent.getSize();\n                data.widthHint = size.x - HORIZONTAL_BUFFER;\n                data.heightHint = size.y - button.getSize().y - VERTICAL_BUFFER;\n                sashForm.setLayoutData(data);\n            }\n        });\n\n        // Set sash form's weights and pack its parent so that the initial layout is correct\n        sashForm.setWeights(SASH_FORM_WEIGHTS);\n        parent.pack();\n    }\n}\n```\n\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Is it wrong for a context (right click) menu be the only way a user can perform a certain task?\r\n                \r\nI'd like to know if it ever makes sense to provide some functionality in a piece of software that is only available to the user through a context (right click) menu. It seems that in most software I've worked with the right click menu is always used as a quick way to get to features that are otherwise available from other buttons or menus.\n\nBelow is a screen shot of the UI I'm developing. The tree view on the right shows the user's library of catalogs. Users can create new catalogs, or add and remove existing catalogs to and from their library. Catalogs in their library can then be opened or closed, or set to read-only.\n\n\n\nThe screen shot shows the context menu I've created for the browser. Some commands can be executed independently from any specific catalog (New, Add).  Yet the other commands must be applied to a specifically selected catalog (Close, Open, Remove, ReadOnly, Refresh, Clean UP, Rename).\n\nCurrently the \"Catalog\" menu at the top of the window looks identical to this context menu. Yet I think this may be confusing to the users as the tree view which shows the currently selected catalog may not always be visible. The user may have switched to the Search or Filters tab, or the left pane may be hidden entirely.  \n\nHowever, I'm hesitant to change the UI so that the commands that depends on a specifically selected catalog are only available through the context menu. \n    ", "Answer": "\r\nThe Windows User Experience Interaction Guidelines for Windows 7 and Windows Vista states (pg233):\n\n“Don’t make commands only available through context menus. Like shortcut keys, context menus are alternative means of performing commands and choosing options.” \n\nThe Apple Human Interface Guidelines states (pg189):\n\n“Always ensure that contextual menu items are also available as [pulldown] menu commands. A contextual menu is hidden by default and a user might not know it exists, so it should never be the only way to access a command.”\n\nIn your case, opening and closing the catalogue appears already available through the +/- buttons in the tree itself, so you’re already consistent with the Windows guidelines, if not the Apple guidelines. IMO, the only reason to put them on the context menu at all is if they're the default (double-click) action (which they're not right now). Rename may also already be available by directly selecting the name of a selected catalog, but you may want a pulldown menu item for that any way since that may be no more discoverable than the context menu. The rest of the commands probably belong on a pulldown menu in addition to the context menu.\n\nAs far as the Catalog pulldown menu being redundant with the Catalog context menu, you may want to consider organizing your pulldown menus by type of action, rather than class of object, in order to provide an alternative organization. As you’ve realized, context menus already organize commands by class of object. In addition to providing an alternative organization that some of you users may find more intuitive, this may simplify your menubar. For example, rather than a Catalog and Family menus, you can have a single Edit menu with Add, Delete, Rename, Copy, etc. where these commands apply to whatever is selected, whether it be a catalog, folder, or family. If they don't apply to the current selection, they're disabled, but if it makes any sense in your app, make them apply.\n\nBTW, what’s the difference between Add Catalog and New Catalog? \n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Chaining tasks with continuation and run parallel task afterward\r\n                \r\nThe work flow of the parallel tasks\n\n\n\nI am hoping to get help on the problem I am facing. So the problem is that I am running parallel tasks to search through folders for files. Each task entails identifying files and add it to a array of files. Next, wait until every task completes so that files are gathered up, then perform sorting on the results. Next, process the sorted file independently, by running one task per file to read through it to get a matching pattern back. The final stage is to aggregate all the results together in human readable format and display it in a user-friendly way.\n\nSo the question is that I want to chain the tasks in a proper way that does not blocks the UI thread. I would like to be able to cancel everything at any stage the program is at.\n\nTo sum it up:\n\nStage 1: Find files by searching through folders. Each task search recursively through a folder tree.\n\nStage 2: Sort all the files found and clean up duplicates\n\nStage 3: Start new tasks to process the files independently. Each task opens a file and search for matching pattern. \n\nStage 4: Aggregate result from every single file search into one giant result set and make it pretty for human to read.\n\n```\n     List<Task> myTasks = new List<Task>();\n\n// ==== stage 1 ======\n        for(int i = 0; i < 10; i++) {\n           string directoryName = directories[i];\n\n           Task t = new Task(() =>\n           {\n              FindFiles(directoryName);\n           });\n\n           myTasks.Add(t);\n            t.Start();\n        }\n\n// ==== stage 2 ====\n        Task sortTask = Task.Factory.ContinueWhenAll(myTasks.ToArray(), (t) =>\n        {\n           if(_fileResults.Count > 1) {\n              // sort the files and remove any duplicates\n           }\n        });\n\n        sortTask.Wait();\n\n// ==== stage 3 ====\n        Task tt = new Task(() =>\n        {\n             Parallel.For(0, _fileResults.Count, new ParallelOptions { MaxDegreeOfParallelism = Environment.ProcessorCount, CancellationToken = token, TaskScheduler = _taskScheduler },\n                    (i, loopstate) => {\n              // 1. open file\n              // 2. read file\n              // 3. read file line by line\n              }\n        }\n\n// == stage 4 === \n        tt.ContinueWith((t) =>\n        {\n           // 1. aggregate the file results into one giant result set\n           // 2. display the giant result set in human readable format\n        }, token, TaskContinuationOptions.OnlyOnRanToCompletion, TaskScheduler.FromCurrentSynchronizationContext());\n\n      tt.start();\n```\n\n    ", "Answer": "\r\nDon't synchronously wait for any of the tasks to finish.  If any of those operations need to take place after a previously created task, add that work as a continuation of that task instead.\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Recursive CTE - Updating nodes in SQL Server\r\n                \r\nI have some main tests. Each of these main tests consist on other tests. Each of these tests consists on other tests and so on. See below the trees as an example.\n\n```\n                 Main Test 1\n                     ID:1\n                  /    |    \\\n                 /     |     \\\n                +      o      +               \n              Test   Test   Test \n              ID:2   ID:3   ID:4\n             /    \\          / \\\n            /      \\        /   \\\n           +        o      +     o\n         Test     Test   Test   Test\n         ID:5     ID:6   ID:7   ID:8\n          |             /    \\\n          |            /      \\\n          o           o        o\n         Test       Test      Test\n         ID:12      ID:9      ID:10\n\n\n                 Main Test 2\n                     ID:2\n                  /        \\\n                 /          \\\n                +            +               \n              Test         Test \n              ID:3         ID:8\n            /   |   \\          \n           /    |    \\        \n          o     o     o      \n       Test   Test    Test   \n       ID:5   ID:10   ID:7   \n```\n\n\nSymbols:\n\n\n'o' are leafs \n'+' are parents \nMain Test 1 and Main Test 2 are main tests (root tests).\n\n\nWithin each main test, ids for tests are unique, but ids tests within a main test can be repeated for within another main tests as above trees show.\n\nI have an input table, let's say, \"INPUT\" with below columns:\n\n```\nID_MainTest | ID_TEST | PASSED\n```\n\n\nWith this input table we indicate which tests for each main test are passed.\n\nAlso we have another table that contains above trees representation into table, let's say table \"Trees\":\n\n```\nID_MainTest | ID_TEST | PARENT_ID_TEST\n```\n\n\nFinally we have another table, let's say table \"TESTS\", which contains all the tests which indicates the current result (PENDING,FAILED,PASSED) for each test:\n\n```\nID_MainTest | ID_TEST | RESULT\n```\n\n\nSo suppose tables content are:\n\nINPUT table (ID_MainTest and ID_Test are primary keys):\n\n```\nID_MainTest | ID_TEST | PASSED\n     1          4         1\n     1          5         1\n     1          6         1\n     1          2         1\n     1          3         1\n     2          3         1\n```\n\n\nTREES table (ID_MainTest and ID_Test are primary keys):       \n\n```\nID_MainTest | ID_TEST | PARENT_ID_TEST\n     1          2           NULL\n     1          3           NULL\n     1          4           NULL\n     1          5            2\n     1          6            2\n     1          7            4\n     1          8            4\n     1         12            5\n     1          9            7\n     1         10            7\n     2          3            NULL\n     2          8            NULL\n     2          5            3\n     2         10            3\n     2          7            3\n```\n\n\nTESTS table (ID_MainTest and ID_Test are primary keys): \n\n```\n ID_MainTest | ID_TEST |   RESULT\n     1          2           PENDING\n     1          3           FAILED\n     1          4           FAILED\n     1          5           PASSED\n     1          6           PENDING\n     1          7           PASSED\n     1          8           FAILED\n     1         12           PASSED\n     1          9           PASSED\n     1         10           PENDING\n     2          3           PENDING\n     2          8           FAILED\n     2          5           PASSED\n     2         10           PENDING\n     2          7           PENDING\n```\n\n\nThe functionality is the following:\n\n\nA test (those indicated in input table) will be switch to passed if and only if all its children figure as passed. If any of its children (or descendants) is failed, then parent will be set/switch to failed despite of indicated as passed in input table.\nIf test is indicated to be passed from input table, all its children (and descendants) will be set/switch to passed from the parent to the leafs when possible: Children (and descendants) may only be switch to passed if they figure as pending. If a child (or descendant) figures as failed it cannot be switch to passed (it keeps as failed). Also if a child (or descendant) already figures as passed it is not necessary to switch again to passed, it will be kept.\nParent indicated as passed in input table, can be switch to passed if\nall its descendants figure as passed (independently if this parent\nfigures as failed or pending in the tests table, this is an\nexception).\n\n\nSo taken into account the functionality and tables content above indicated I would like to obtain below result table with only the tests we have tried to switch to passed (successfully or not), switched to passed, or maintained to failed or passed, including those indicated in input table: \n\n(ID_MainTest and ID_Test are primary keys):\n\n```\n ID_MainTest | ID_TEST |   RESULT\n     1          2           PASSED\n     1          3           PASSED\n     1          4           FAILED\n     1          5           PASSED\n     1          6           PASSED\n     1          7           PASSED\n     1          8           FAILED\n     1         12           PASSED\n     1          9           PASSED\n     1         10           PASSED\n     2          3           PASSED\n     2          5           PASSED\n     2         10           PASSED\n     2          7           PASSED\n```\n\n\n\n\nI provide the initial tables below:\n\n```\nDECLARE @INPUT AS TABLE\n(\n    ID_MainTest int,\n    ID_TEST  int,\n    PASSED bit\n)\n\n\nINSERT INTO @INPUT VALUES\n(1, 4, 1),\n(1, 5, 1),\n(1, 6, 1),\n(1, 2, 1),\n(1, 3, 1),\n(2, 3, 1)\n\nDECLARE @TREES AS TABLE\n(\n    ID_MainTest int,\n    ID_TEST  int,\n    PARENT_ID_TEST int\n)\n\n\nINSERT INTO @TREES VALUES\n(1, 2, NULL),\n(1, 3, NULL),\n(1, 4, NULL),\n(1, 5, 2),\n(1, 6, 2),\n(1, 7, 4),\n(1, 8, 4),\n(1, 12, 5),\n(1, 9, 7),\n(1, 10, 7),\n(2, 3, NULL),\n(2, 8, NULL),\n(2, 5, 3),\n(2, 10, 3),\n(2, 7, 3)\n\nDECLARE @TESTS AS TABLE\n(\n    ID_MainTest int,\n    ID_TEST  int,\n    RESULT NVARCHAR(50)\n)\n\n\nINSERT INTO @TESTS VALUES\n(1, 2, 'PENDING'),\n(1, 3, 'FAILED'),\n(1, 4, 'FAILED'),\n(1, 5, 'PASSED'),\n(1, 6, 'PENDING'),\n(1, 7, 'PASSED'),\n(1, 8, 'FAILED'),\n(1, 12, 'PASSED'),\n(1, 9, 'PASSED'),\n(1, 10, 'PENDING'),\n(2, 3, 'PENDING'),\n(2, 8, 'FAILED'),\n(2, 5, 'PASSED'),\n(2, 10, 'PENDING'),\n(2, 7, 'PENDING')\n```\n\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Architecture for an isomorphic app using React.js and Flux\r\n                \r\nI'm looking for the best technology/architecture choices for my isomorphic app. \nHere are my constraints, due to what has already been developed, what we need and what we'd love:\n\n\nAll front-end in React.js, with layout(s), child components, etc.\nFlux architecture\nAs I said, server-side rendering (the current server is built on express.js, it can change but if we can keep it it would save some time)\nVery simple/flexible router, like react-router or even just a json route:component, I don't know\nEach component should be able to ask for the data it needs before render\nEach component should be able to have a specific context (set page title, insert specific css, set meta tags, etc.)\n\n\nTo be clear, we need to be able to add a page/feature on the app by simply saying in the router file \"This route needs to render this component, inside this layout\" and the component should be independent, asking \"ok, before everything, I need these data from the api, then, I need this css file, my title is 'title', ect.\".\n\nThe architecture we currently have is a mess, not maintainable, not scalable, not flexible enough:\n\nWith and Express.js router, on each route we set context information, make an api call and then render a jade file with specific css and js, in which we insert the jsx component. Here is an exemple:\n\nrouter.js\n\n```\nrouter.get('/profile', function(req, res, next) {\n    // make the api call\n    api.getProfile(function(err, profile) {\n        if (err) {\n            next(err);\n        }\n        // set props for the react component\n        var props = {\n            profile: profile\n        };\n        // render the react component\n        var ProfileEditor = React.createFactory(\n            require('path/to/components/profile.jsx')\n        );\n        var profileEditor = React.renderToString(\n            ProfileEditor(props)\n        );\n        // render the jade file\n        res.render('profile', {\n            props: safeStringify(props),\n            profile:profileEditor\n        });\n    });\n});\n```\n\n\nprofile.jade\n\n```\n// extend a layout\nextends ../layout   \n\n// ask for specific styles if need\nblock styles\n\n// insert the server side rendered component\nblock component\n    #profile \n        != profile\n\nblock scripts\n    // ask for specific scripts if needed\n    script(src=\"https://maps.googleapis.com/maps/api/js?key=key&libraries=places\")\n    // print props for the client side rendering\n    script(id=\"props\" type=\"application/json\")\n        |!{ props }\n    // set the react component\n    script(src=\"/bundles/profile.js\")\n```\n\n\nprofile.jsx\n\n```\nvar React = require(\"react\");\nvar store = require ('../stores/profile');\nvar actions = require ('../actions/profile');\n\nvar Profile = React.createClass({\n\n    // As usual\n\n    render: function(){\n        return(\n        <div>\n                // Profile component\n        </div>\n        )\n    }\n\n});\n\n// re-render client side using the same props from the script tag\nif (typeof window !== 'undefined') {\n    var ProfileFactory = React.createFactory(Profile);\n    var mountNode = document.getElementById(\"profile\");\n    var props = JSON.parse(document.getElementById(\"props\").innerHTML);\n    React.render(new ProfileFactory(props), mountNode);\n}\n\nmodule.exports = Profile;\n```\n\n\nOver the project grows, the less we are satisfied with that.\n\nThe solutions we've been trying to explore are :\n\n\nyeoman generator react-fullstack: https://github.com/kriasoft/react-starter-kit/tree/yeoman-generator > we find it very complicated and we didn't managed how to simply fetch data for each component. Although it's exactly what we need about context for each component. \nexpress.js + react-router: Client Routing (using react-router) and Server-Side Routing, http://putaindecode.fr/posts/js/reactjs-et-rendu-serverside/  > same problem with data, and we've not been able to set context. Also we are not so comfortable with the initial render server-side and then everything client side, at the opposite of what we currently have.\n\n\nWe feel like nothing is really adapted while we don't develop something really particular, just a platform to read/write data from an api.\n\nWhat would be the best, simple, flexible, limpid architecture for us regarding our constraints? What choices do we need to do?\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "How to close a Slidable from outside its widget tree?\r\n                \r\nI am using the package ```\nflutter_slidable```\n, which is amazing to get extra functionalities in list items. However, I still can't figure out how to control a ```\nSlidable```\n widget from outside its tree.\nSimple App:\nI have a ```\nListView```\n and each one of its items is wrapped with a ```\nSlidable```\n. These tiles are composed by a ```\nTextFormField```\n. I would like to be able to close a Slidable by tapping another tile. To be more precise, by tapping the TextFormField of another tile.\nThere are three tiles with Slidables attached to them.\nIn the following images, from left to right:\n\nI slide the second tile.\nI tap the ```\nTextFormField```\n of the third tile.\nThen, the ```\nSlidable```\n of the second tile should be closed.\n\n\nMain Page:\n```\nclass MyApp extends StatelessWidget {\n  const MyApp({Key? key}) : super(key: key);\n\n  @override\n  Widget build(BuildContext context) {\n    return MaterialApp(\n      home: Scaffold(\n        appBar: AppBar(\n            elevation: 0,\n            title: const Text('Slidable from outside'),\n        ),\n        body: SlidableAutoCloseBehavior(\n          closeWhenOpened: true,\n          closeWhenTapped: false,\n          child: ListView.builder(\n            itemCount: 3,\n            itemBuilder: (context, index) {\n              return const MyTile();\n            },\n          ),\n        ),\n      ),\n    );\n  }\n}\n```\n\nTile:\n```\nclass MyTile extends StatelessWidget {\n  const MyTile({Key? key}) : super(key: key);\n\n  @override\n  Widget build(BuildContext context) {\n    return Slidable(\n      closeOnScroll: false,\n      startActionPane: const ActionPane(\n        dragDismissible: false,\n        motion: ScrollMotion(),\n        children: [\n          SlidableAction(\n            backgroundColor: Color(0xFFe0e0e0),\n            icon: Icons.remove_circle_outline_outlined,\n            autoClose: false,\n            onPressed: null,\n          ),\n          SlidableAction(\n            backgroundColor: Color(0xFFe0e0e0),\n            icon: Icons.add_circle_outline_outlined,\n            autoClose: false,\n            onPressed: null,\n          ),\n        ],\n      ),\n      child: Container(\n        padding: const EdgeInsets.all(24),\n        child: TextFormField(\n          style: TextStyle(\n            fontSize: 18,\n            fontWeight: FontWeight.w600,\n            color: Colors.grey[800],\n          ),\n          decoration: const InputDecoration(\n            isDense: true,\n            border: InputBorder.none,\n            contentPadding: EdgeInsets.zero,\n          ),\n          initialValue: '25.000',\n          onTap: () {\n            //Some code that triggers the close action of another Slidable\n          },\n        ),\n      ),\n    );\n  }\n}\n```\n\nFrom what I understand, in old versions of this package you used a ```\nSlidableController```\n, but it has changed now. A recommended way is to wrap the list with a ```\nSlidableAutoCloseBehavior```\n, but it can't control each Slidable independently.\nThe parameter ```\ncloseWhenTapped```\n is the closest to a solution because if I set this to ```\ntrue```\n, it let me close the tile after tapping in another tile, but, I have to tap twice, hence the TextFormField is not selectable at first touch. So I set it to ```\nfalse```\n in order to let me select the TextFormField although without being able to close the Slidable automatically.\n    ", "Answer": "\r\nSlidableAutoCloseBehavior(\nchild: ListView(\nchildren: [\nSlidable(\ngroupTag: '0',\n),\nSlidable(\ngroupTag: '0',\n),\nSlidable(\ngroupTag: '1',\n),\n],\n),\n)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Trained GradientBoostedClassifier assigns zero importance to any feature\r\n                \r\nFirst some facts regarding the scenario:\ni try to predict some classes using 28 features (feature engineering completed) in scikit-learn. I had a huge dataset which i had to to split into 7 datasets depending on one specific feature that massively influenced the decision making process of models. \n\nFinally, i had X datasets and used GridSearch for each of those to find the best/good set of hyperparameters. For this, i used 4 models ( Decision Stump as Baseline, DecisionTree, RandomForest, GradientBoostedTrees). Afterwards, i wanted to analyze the best estimators to extract feature importances and make further specific feature engineering for each dataset independently. \n\nThe first 4 dataset feature importances seemed quite fine to me. However, starting from the 5th dataset, trained GBDT assigns zero feature importance to all features. The other classifiers behave as expected.\n\nFor some context, here is a concrete example:\n\nFeature importance of one dataset:\n\n\n\nModel accuracy:\n\n\n\nI searched on the internet for this and found only one relevant thread were the answers were, besides \"give more context please\" and \"maybe some errors?\", the fact that the trained classifier could have learned something trivial. However, i analyzed all trees of the GBDT and indeed, it seems no feature is used, every tree has one layer and looks like this\n\n```\ndigraph Tree {\nnode [shape=box];\n0 [label = friedman_mse = 0.135\n   samples = 106\n   values = 0.054\n];\n}\n```\n\n\nHas someone an explanation for this? many many thanks :)\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "how to quickly determine the winner of a simple shedding-card game?\r\n                \r\nA Naive Shedding Card Game\nGiven a simple version of a shedding type card game (which is actually a naive version of Dou Di Zhu(https://en.wikipedia.org/wiki/Dou_dizhu), the most popular game in china), how can we determine the winner (each player can have up to 20 cards) (is there exists a linear algorithm to solve the problem)?\nThe object of the game is to get rid of all cards on hand before the opponent. The players are called A and B. The card ranks are:\n3 < 4 < 5 < 6 < 7 < 8 < 9 < T < J < Q < k < A < 2 < r < R  (where T is 10, r, R is small and big joker)\nDefinition1:  Player who can discard any card compile with the Give-Out-Rule is called FirstDiscard player, while player who can only discard a card that has a higher rank then previous discarded card is called BeatDiscard player.\nA is the first player to discard a card, so A is always a FirstDiscard player at the beginning. If one choose not to discard a card (because he chooses not to discard or he can not find a valid card to discard), then another become FirstDiscard player.\nGive out Rule1: Each player can discard a single card at most, Even if you have multiple cards that is the same rank, you can only discard only one of them.\nExample1: B winner  4,4,5 < B: 3,4,4,8,T\n\nExplain: B is always the winner, because for any strategy A can possible choose to\nplay, B can always find a strategy to discard card that leads to winning of B.\nExample2: A winner 4,4,5,R > B: 3,4,4,8,T\n\nExplain: A is always the winner, because there exists a strategy A can choose to use that leads to winning of A regardless of strategies B choose to react.\n\nThe red and blue indicate the state(the cards left in hand) of A and\nB.\nThe polygon and box shape indicate the player is at FirstDiscard\nplayer state and BeatDiscard player state.\n\n\nA Relative Graph of tow card sets(A: 4,4,5,R > B: 3,4,4,8,T)\n\n\nThe Bp value of each card indicates how may opponent's card that this card can be used to beat.\n\nCards with the same Bp value form a block.\n\n\n\nThe research progress\nFor now, I can only use the game search tree methods to determine the winner, but the methods takes too long time to process. Give out Rule1 is Actually the first step of my research, the following research give out rule is:\nDefinition2: solo-card is defined as card with a specific rank whose count is one. while pair-card, trio-card, four-card are defined as card with a specific rank whose count is two, three, four.\nDefinition3: solo-card, pair-card, trio-card, four-card are also called independent-card\nGive out Rule2: Each player can only discard a kind of independent-card each time, if player is at BeatDiscard player state, he can only discard the same kind of independent-card of previous discarded cards with a higher rank.\nSplitCard is not allowed. (if you have a trio-card 555, you can not split the card to be a solo-card 5 and a pair-card 55)\nGive out Rule3: The same as Give out Rule2 except SplitCard is allowed.\nDefinition4: trio-card with a solo-card is called trio-solo-kicker-card, the rank is the same of trio-card.\nDefinition5: trio-card with a pair-card is called trio-pair-kicker-card, the rank is the same of trio-card.\nDefinition6: four-card with two solo-card is called four-2-solo-kicker-card, the rank is the same of four-card.\nDefinition7: four-card with two pair-card is called four-2-pair-kicker-card, the rank is the same of four-card.\nGive out Rule4: The same as Give out Rule3 and four additional card types (from Def4 ~ Def7) are allowed to discard.\nDefinition8: four-card is also called bomb-card, it can be used to beat all other card type and four-card with a lower rank (6666 can beat 33, 5555, 3331, 8888KJ)\nDefinition9: rocket-card is a combination of r and R, it can beat all other card type.\nGive out Rule5: The same as Give out Rule4 and tow additional card types (from Def8 ~ Def9) are allowed to discard.\nGive out Rule6: Player C is added as a teammate of B, he will discard card following B, either B or C discards all hand cards first will be winner of B and C.\nI believe there exists an linear algorithm for Give out Rule1 ~ Rule3, someone can provide such a method and related informations, or prove that the problem is exponential.\n    ", "Answer": "", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
{"Question": "Deriving from a base class whose instances reside in a fixed format (database, MMF)...how to be safe?\r\n                \r\n(Note: I'm looking for really any suggestions on the right search terms to read up on this category of issue.  \"Object-relational-mapping\" occurred to me as a place where I could find some good prior art...but I haven't seen anything quite fitting this scenario just yet.)\n\nI have a very generic ```\nclass Node```\n, which for the moment you can think of as being a bit like an element in a DOM tree.  This is not precisely what's going on--they're graph database objects in a memory mapped file.  But the analogy is fairly close for all practical purposes, so I'll stick to DOM terms for simplicity.\n\nThe \"tag\" embedded in the node implies a certain set of operations you should (ideally) be able to do with it.  Right now I'm using derived classes to do this.  So for instance, if you were trying to represent something like an HTML list:\n\n```\n<ul>\n   <li>Coffee</li>\n   <li>Tea</li>\n   <li>Milk</li>\n</ul>\n```\n\n\nThe underlying tree would be seven nodes:\n\n```\n+--UL                       // Node #1\n   +--LI                    // Node #2\n      +--String(Coffee)     // Node #3 (literal text)\n   +--LI                    // Node #4\n      +--String(Tea)        // Node #5 (literal text)\n   +--LI                    // Node #6\n      +--String(Milk)       // Node #7 (literal text)\n```\n\n\nSince ```\ngetString()```\n is already a primitive method on Nodes themselves, I'd probably only make ```\nclass UnorderedListNode : public Node```\n, ```\nclass ListItemNode : public Node```\n.\n\nContinuing this hypothetical, let's imagine I wanted to help the programmer use less general functions when they know more about the Node \"type\"/tag they have in their hands.  Perhaps I want to assist them with structural idioms on the tree, like adding a string item to an unordered list, or extracting things as a string.  (This is just an analogy so don't take the routines too seriously.)\n\n```\nclass UnorderedListNode : public Node {\nprivate:\n    // Any data members someone put here would be a mistake!\n\npublic:\n    static boost::optional<UnorderedListNode&> maybeCastFromNode(Node& node) {\n        if (node.tagString() == \"ul\") {\n            return reinterpret_cast<UnorderedListNode&>(node);\n        }\n        return boost::none;\n    }\n\n    // a const helper method\n    vector<string> getListAsStrings() const {\n        vector<string> result;\n        for (Node const* childNode : children()) {\n            result.push_back(childNode->children()[0]->getText());\n        }\n        return result;\n    }\n\n    // helper method requiring mutable object\n    void addStringToList(std::string listItemString) {\n        unique_ptr<Node> liNode (new Node (Tag (\"LI\"));\n        unique_ptr<Node> textNode (new Node (listItemString));\n        liNode->addChild(std::move(textNode));\n        addChild(std::move(liNode));\n    }\n};\n```\n\n\nAdding data members to these new derived classes is a bad idea.  The only way to really persist any information is to use the foundational routines of Node (for instance, the ```\naddChild```\n call above, or ```\ngetText```\n) to interact with the tree.  Thus the real inheritance model--to the extent one exists--is outside of the C++ type system.  What makes a ```\n<UL>```\n node \"maybeCast\" into an ```\nUnorderedListNode```\n has nothing to do with vtables/etc.\n\nC++ inheritance looks right sometimes, but feels wrong usually.  I feel like instead of inheritance I should have classes that exist independently of Node, and just collaborate with it somehow as \"accessor helpers\"...but I don't have a good grasp of what that would be like.\n    ", "Answer": "\r\nI am not sure I have understood completely what you intend to do but here are some suggestions you might find useful.\n\nYou are definitely on the right track with inheritance. All the UL nodes, LI nodes, ... etc. are Node-s. Perfect \"is_a\" relationship, you should derive these classes from the Node class. \n\n\n  let's imagine I wanted to help the programmer use less general functions when they know more about the Node \"type\"/tag they have in their hands\n\n\n...and this is what virtual functions are for. \n\nNow for the ```\nmaybeCastFromNode```\n method. That's downcasting. Why would you do that? Maybe for deserializing? If yes, then I'd recommend using ```\ndynamic_cast<UnorderedListNode *>```\n . Although most likely you won't need RTTI at all if the inheritance tree and the virtual methods are well-designed.\n\n\n  C++ inheritance looks right sometimes, but feels wrong usually.\n\n\nThis might not always be C++'s fault :-)\n    ", "Knowledge_point": "Independent Sets in Trees", "Tag": "算法分析"}
