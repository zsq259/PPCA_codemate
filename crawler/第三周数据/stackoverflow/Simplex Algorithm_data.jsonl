{"Question": "Simplex Algorithm - Worst Case\r\n                \r\nIts given that worst case time complexity of simplex algorithm is O(2^n). What is the worst case in simplex algorithm? To calculate time complexity I want to know about the worst case. \n    ", "Answer": "\r\nIn the worst case scenario, simplex needs to visit ```\n2^n```\n vertice points (Klee & Minty 1972), which could also be the same point being visited repeatedly if you consider degeneration. \n\nNonetheless, the simplex algorithm has polynomial average-case complexity under various probability distributions. By such principle, it was proven that slightly random pertubations (which bearely change the original data) to the input of simplex would cause the expected running time to become polynomial (Spielman and Teng - 2001).\n\nReferences:\n\n\nTopic at cstheory.stackexchange\nSimplex algorithm\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Simplex algorithm\r\n                \r\nI have to build Simplex Algorithm and its working but I want to allow user to input data, in method main I made few \"for\" loops where I put date into arrays, but that I put the same data in another arrays, (they have exactly the same data) I have no idea how to fix it.\n\nWhen I try to make just one arrays for one type of date, it's crash. \n\n[edit]\nYep, I update those Scanners (thanks guys)\nAnd right now I have this error:\n\n\n  \"Exception in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: 2\n  at simplex.Simplex$Modeler.(Simplex.java:224)\n  at simplex.Simplex.main(Simplex.java:196)\"\n\n\n```\npackage simplex;\n\nimport java.awt.List;\nimport java.util.ArrayList;\nimport java.util.Scanner;\n\npublic class Simplex {\n\n private double[][] macierz; // macierz\n private int LiczbaOgraniczen; // liczba ograniczen\n private int LiczbaX; // liczba zmiennych \"orginalnych\"\n private boolean MaxCzyMin;\n private static final boolean MAX = true;\n private static final boolean MIN = false;\n\n private int[] baza; // baza[i] = basic variable corresponding to row i\n\n public Simplex(double[][] macierz, int LiczbaOgraniczen, int numberOfOriginalVariable, boolean MaxCzyMin) {\n  this.MaxCzyMin = MaxCzyMin;\n  this.LiczbaOgraniczen = LiczbaOgraniczen;\n  this.LiczbaX = numberOfOriginalVariable;\n  this.macierz = macierz;\n\n  baza = new int[LiczbaOgraniczen];\n  for (int i = 0; i < LiczbaOgraniczen; i++)\n   baza[i] = LiczbaX + i;\n\n  Licz();\n\n }\n\n // Licz algorytm simples od startowych BFS\n private void Licz() {\n     while (true) {\n\n         DrukujInteracje();\n         int q = 0;\n         // znajdz kolumne q wchodzącą do bazy\n         if (MaxCzyMin) {\n             q = ZnajdzIndexPoz(); //jesli szukamy max\n         } else {\n             q = ZnajdzIndexNeg(); //jesli szukamy min\n         }\n\n         if (q == -1){\n             break; // optimum\n         }\n\n         // znajdz rzad p wychodzący z bazy\n         int p = minRatioRule(q);\n         if (p == -1){\n             throw new ArithmeticException(\"BLAD\");\n         }\n         //wiersz - kolumna\n         piwot(p, q);\n\n         // zaktualizuj baze\n         baza[p] = q;\n     }\n }\n\n // znajdowanie indexu niebazowej kolumny z najbardzoje pozytywnym kosztem\n private int ZnajdzIndexPoz() {\n     int q = 0;\n     for (int j = 1; j < LiczbaOgraniczen + LiczbaX; j++)\n         if (macierz[LiczbaOgraniczen][j] > macierz[LiczbaOgraniczen][q])\n             q = j;\n\n     if (macierz[LiczbaOgraniczen][q] <= 0){\n        return -1; // optimum \n     } else {\n        return q;\n     }\n }\n\n // znajdowanie indexu niebazowej kolumny z najbardziej negatywnym kosztem \n private int ZnajdzIndexNeg() {\n     int q = 0;\n     for (int j = 1; j < LiczbaOgraniczen + LiczbaX; j++)\n         if (macierz[LiczbaOgraniczen][j] < macierz[LiczbaOgraniczen][q])\n             q = j;\n\n     if (macierz[LiczbaOgraniczen][q] >= 0){\n         return -1; // optimum \n     } else {\n         return q;\n     }\n}\n\n // find row p using min ratio rule (-1 if no such row)\n private int minRatioRule(int q) {\n     int p = -1;\n     for (int i = 0; i < LiczbaOgraniczen; i++) {\n         if (macierz[i][q] <= 0)\n             continue;\n         else if (p == -1)\n             p = i;\n         else if ((macierz[i][LiczbaOgraniczen\n             + LiczbaX] / macierz[i][q]) < (macierz[p][LiczbaOgraniczen\n             + LiczbaX] / macierz[p][q]))\n             p = i;\n     }\n     return p;\n }\n\n //zastosowanie metody Gauss-Jordan, aby doprowadzic macierz do postaci bazowej\n private void piwot(int p, int q) {\n\n  for (int i = 0; i <= LiczbaOgraniczen; i++)\n   for (int j = 0; j <= LiczbaOgraniczen + LiczbaX; j++)\n    if (i != p && j != q)\n     macierz[i][j] -= macierz[p][j] * macierz[i][q] / macierz[p][q];\n\n  for (int i = 0; i <= LiczbaOgraniczen; i++)\n   if (i != p)\n    macierz[i][q] = 0.0;\n\n  for (int j = 0; j <= LiczbaOgraniczen + LiczbaX; j++)\n   if (j != q)\n    macierz[p][j] /= macierz[p][q];\n  macierz[p][q] = 1.0;\n }\n\n // Metoda zwraca wartosc funkcji celu\n public double WartoscFunkcjiCelu() {\n  return -macierz[LiczbaOgraniczen][LiczbaOgraniczen + LiczbaX];\n }\n\n // metoda zwaraca wartosc x-ow\n public double[] WyliczX() {\n  double[] x = new double[LiczbaX];\n  for (int i = 0; i < LiczbaOgraniczen; i++)\n  if (baza[i] < LiczbaX)\n    x[baza[i]] = macierz[i][LiczbaOgraniczen + LiczbaX];\n  return x;\n }\n\n // drukuj macierz => drukuj tabele \n public void DrukujInteracje() {\n  System.out.println(\"Liczba Ograniczen = \" + LiczbaOgraniczen);\n  System.out.println(\"Liczba zmiennych 'orginalnych' = \" + LiczbaX);\n  for (int i = 0; i <= LiczbaOgraniczen; i++) {\n   for (int j = 0; j <= LiczbaOgraniczen\n     + LiczbaX; j++) {\n    System.out.printf(\"%7.2f \", macierz[i][j]);\n   }\n   System.out.println();\n  }\n  System.out.println(\"Funkcja celu = \" + WartoscFunkcjiCelu());\n  for (int i = 0; i < LiczbaOgraniczen; i++)\n   if (baza[i] < LiczbaX)\n    System.out.println(\"x_\"\n      + baza[i]\n      + \" = \"\n      + macierz[i][LiczbaOgraniczen + LiczbaX]);\n  System.out.println();\n }\n\npublic static void main(String[] args) {\n        Scanner scan = new Scanner(System.in);\n        System.out.println(\"Podaj ilosc x\");\n        int iloscX = scan.nextInt();\n        double[] WspolczynnikiFunkcjiCelu = new double[iloscX + 1];\n    for(int ggg = 0; ggg < iloscX; ggg++){\n        System.out.println(\"Podaj x\" + ggg);\n        WspolczynnikiFunkcjiCelu[ggg]  =scan.nextDouble();\n}\n\n    System.out.println(\"Podaj ilosc ograniczen\");\n    int iloscOgraniczen = scan.nextInt();\n    double[][] LewaStronaOgraniczen = new double[iloscOgraniczen][iloscX];\n    double[] PrawaStronaOgraniczen = new double[iloscOgraniczen + 1];\n    Znaki[] OperatorOgraniczen = new Znaki [iloscOgraniczen + 1];\n\n    for(int ggh = 0;ggh <iloscOgraniczen; ggh++){\n        System.out.println(\"Podaj znak ograniczenia (lessThan - equal - greatherThan \");\n        OperatorOgraniczen[ggh]  = Znaki.valueOf(scan.next());\n\n        System.out.println(\"Podaj prawa strone ograniczenia\");\n        PrawaStronaOgraniczen[ggh] = scan.nextDouble();\n\n        for(int haha = 0; haha < iloscX; haha++){\n        System.out.println(\"Lewa strona: Podaj wspolczynnik przy x\" + haha);\n        LewaStronaOgraniczen[ggh][haha] =scan.nextDouble();\n    }\n    }\n\n\n  //double[] WspolczynnikiFunkcjiCelu = {Xsy[0], Xsy[1]};\n  // double[][] LewaStronaOgraniczen = {\n    //    { TablicaTablic[0][0], TablicaTablic[0][1] }, { TablicaTablic[1][0], TablicaTablic[1][1] }, { TablicaTablic[2][0], TablicaTablic[2][1] }, { TablicaTablic[3][0], TablicaTablic[3][1] } };\n  //Znaki[] OperatorOgraniczen = { TablicaOgraniczen[0], TablicaOgraniczen[1], TablicaOgraniczen[2], TablicaOgraniczen[3] };\n  //double[] PrawaStronaOgraniczen = {TablicaPrawejStrony[0],TablicaPrawejStrony[1],TablicaPrawejStrony[2],TablicaPrawejStrony[3]};\n\n\n  Modeler model = new Modeler(LewaStronaOgraniczen, PrawaStronaOgraniczen, OperatorOgraniczen, WspolczynnikiFunkcjiCelu);\n\n  Simplex simplex = new Simplex(model.getmacierz(),\n    model.getLiczbaOgraniczen(),\n    model.getLiczbaX(), MAX);\n  double[] x = simplex.WyliczX();\n  for (int i = 0; i < x.length; i++)\n   System.out.println(\"x[\" + i + \"] = \" + x[i]);\n  System.out.println(\"Rozwiazanie optymalne: \" + simplex.WartoscFunkcjiCelu());\n }\n\n //zbior mozliwych znakow ograniczajacych\n private enum Znaki {\n  lessThan, equal, greatherThan\n }\n\n public static class Modeler {\n  private double[][] a; // macierz\n  private int LiczbaOgraniczen; // Liczba Ograniczen \n  private int LiczbaX; // Liczba x w funkcji celu\n\n  public Modeler(double[][] LewaStronaOgraniczen,double[] PrawaStronaOgraniczen, Znaki[] OperatorOgraniczen, double[] WspolczynnikiFunkcjiCelu) {\n   LiczbaOgraniczen = PrawaStronaOgraniczen.length;\n   LiczbaX = WspolczynnikiFunkcjiCelu.length;\n   a = new double[LiczbaOgraniczen + 1][LiczbaX + LiczbaOgraniczen + 1];\n\n   for (int i = 0; i < LiczbaOgraniczen; i++) {\n    for (int j = 0; j < LiczbaX; j++) {\n     a[i][j] = LewaStronaOgraniczen[i][j];\n    }\n   }\n\n   for (int i = 0; i < LiczbaOgraniczen; i++)\n    a[i][LiczbaOgraniczen + LiczbaX] = PrawaStronaOgraniczen[i];\n\n   for (int i = 0; i < LiczbaOgraniczen; i++) {\n    int slack = 0;\n    switch (OperatorOgraniczen[i]) {\n    case greatherThan:\n     slack = -1;\n     break;\n    case lessThan:\n     slack = 1;\n     break;\n    default:\n    }\n    a[i][LiczbaX + i] = slack;\n   }\n\n   for (int j = 0; j < LiczbaX; j++)\n    a[LiczbaOgraniczen][j] = WspolczynnikiFunkcjiCelu[j];\n  }\n\n  public double[][] getmacierz() {\n   return a;\n  }\n\n  public int getLiczbaOgraniczen() {\n   return LiczbaOgraniczen;\n  }\n\n  public int getLiczbaX() {\n   return LiczbaX;\n  }\n }\n```\n\n\n} \n    ", "Answer": "\r\nwhy have you so many scanners? Try use only one. Declare and initialize it at the beginning main method.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "LP Simplex algorithm in C++ [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and  cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened,  visit the help center.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 13 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI need the robust C++ source code of the simplex algorithm (is a popular algorithm for numerical solution of the linear programming problem). \n\nPlease, no links to wikipedia. I need good source code in C++, using templates, clear user-friendly names and work very well. \n\nPreferably algorithm must check the unstable floating-point calculation.\n    ", "Answer": "\r\nThis one is a C++ library: http://soplex.zib.de. But the license has some restrictions regarding commercial use.\n\nThis one has a liberal license, but is in C: http://aldebaran.devinci.fr/~cagnol/promotion2007/cs302/gsl/multimin/simplex.c.html\nProbably you can write a thin wrapper.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "simplex algorithm - importance of basic solution? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs details or clarity. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Add details and clarify the problem by editing this post.\r\n                \r\n                    \r\n                        Closed 5 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nImportance of basic solution in simplex algorithm?\n    ", "Answer": "\r\nIf all variables (structural and logical) are non-negative (i.e. ```\nx>=0```\n and slacks ```\ns>=0```\n) then all non-basic variables are equal to zero. As they are fixed to zero we only have to solve for the ```\nm```\n basic variables. \n\nEssentially we have to solve \n\n```\nA x = b\n```\n\n\nUnfortunately this is a non-square system of equations (after adding slacks we always have more columns than rows). In LPs we can form a basic solution and partition this into\n\n```\nB x_B + N x_N = b\n```\n\n\nAfter setting ```\nx_N = 0```\n we have just a square system of linear equations with solution:\n\n```\nx_B = inv(B) b\n```\n\n\nThere is a fundamental theorem that says we can restrict the search to only basic solutions i.e. solutions that can be partitioned in basic and non-basic variables \n\n```\nx = [ x_B ]\n    [ x_N ]\n```\n\n\nwith ```\nx_B >= 0```\n and ```\nx_N = 0```\n.\n\nFor more info open a book about Linear Programming; a very good one is Vanderbei. \n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Simplex Algorithm: Initialize-Simplex\r\n                \r\nI am trying to figure out the simplex algorithm in the book \"Introduction to Algorithms, 3rd edition\". The procedure \"Initial-Simplex\" takes as input a standard form, and check if there is an initial basic feasible solution for the standard form. The pseudo code is as following:\n\n\nAt line 2, it checks if the minimum variable in array b is greater than or equal to 0. If not, it constructs a Laux and conduct a pivot to eliminate the negative variable within b. Then at line 9, it shows the basic solution is feasible for Laux.\nThe question is, what if originally in array b, there are more than one negative variables? For example the origin b is [-2, -1, 3, 1], then at line 1, we have b[k]=-2, so k=0. But after the execution of line 4 to line 9, there is still a negative variable -1 within b. In this case, we cannot say the basic solution is feasible for Laux. \nIn conclusion, there is no mechanism which checks whether all the variables in b are non-negative, and line 4 to line 9 is not within a loop. Does this algorithm assume that less than one negative variable is within b originally?\n    ", "Answer": "\r\nI checked the algorithm again, and I think I know the reason. For the following example, since -4 is the smallest variable in array b, after a pivot, it becomes 4. Even if there may be other negative variables in b originally, they cannot be smaller than -4, because -4 is the smallest. After we replace x0 with another variable, the bx0 value corresponding to x0 is 4, and we have |4| greater than or equal to any other |bi| in the array which bi < 0. So after a pivot, the new bi must be a non-negative number.\nFor the standard form\n\n```\nmaximize 2x1 - x2\nsubject to\n2x1-x2 <= -2\nx1 - 5x2 <= -4\nx1, x2 >= 0\n```\n\n\nThe slack form is\n\n```\nz = -x0\n2x1 - x2 - x0 <= -2\nx1 - 5x2 - x0 <= -4\nx1, x2, x0 >= 0\n```\n\n\nAnd after a pivot,\n\n```\nx0 = 4 + x1 - 5x2 + x4\nx3 = -2 - 2x1 -x2 + (4 + x1 - 5x2 + x4)\n```\n\n\nWe can see that -2 + 4 is greater than 0. There won't be any negative variables in b.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Speed up simplex algorithm\r\n                \r\nI am playing around with a great simplex algorithm I have found here: https://github.com/JWally/jsLPSolver/\n\nI have created a jsfiddle where I have set up a model and I solve the problem using the algorithm above. http://jsfiddle.net/Guill84/qds73u0f/\n\nThe model is basically a long array of variables and constraints. You can think of it as trying to find the cheapest means of transportation of passengers between different hubs (countries), where each country has a minimum demand for passengers, a maximum supply of passengers, and each connection has a price. I don't care where passengers go, I just want to find the cheapest way to distribute them. To achieve this I use the following minimising objective:\n\n```\nmodel = {\n        \"optimize\": \"cost\",\n            \"opType\": \"min\",\n            \"constraints\": { \\\\etc... \n```\n\n\nI am happy with the model and the answer provided by the algorithm ... but the latter takes a very long time to run (>15 seconds...) Is there any possible way I can speed up the calculation?\n\nKind regards and thank you.\nG.\n    ", "Answer": "\r\nIt sounds as though you have a minimum-cost flow problem. There's a reasonable-looking TopCoder tutorial on min-cost flow by Zealint, who covers the cycle-canceling algorithm that would be my first recommendation (assuming that there's no quick optimization that can be done for your LP solver). If that's still too slow, there's a whole literature out there.\n\nSince you're determined to solve this problem with an LP solver, my suggestion would be to write a simpler solver that is fast and greedy but suboptimal and use it as a starting point for the LP by expressing the LP in terms of difference from the starting point.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to calculate the efficiency of Simplex algorithm for diet\r\n                \r\nI'm trying to write a program to solve diet problem http://www.phpsimplex.com/en/diet_problem.htm\n\nusing SIMPLEX algorithms. My assignment require also to calculate the efficiency of the algorithms.\n\nI understood from wiki http://en.wikipedia.org/wiki/Simplex_algorithm that it's has exponential time in worst case. But it doesn't  show the exact big O notation, or how I could calculate that.\n\nIs there any advice how could I calculate the efficiency of Simplex algorithm for the above diet problem?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "What is complexity of simplex algorithm for binary integer programming?\r\n                \r\nWhat is complexity of simplex algorithm for binary integer programming problem? For worst case or average case?\n\nI'm solving assignment problem.\n\nReferences:\n\nhttps://en.wikipedia.org/wiki/Integer_programming\n\nhttps://en.wikipedia.org/wiki/Simplex_algorithm\n    ", "Answer": "\r\nSince it's for the assignment problem, that changes matters. In that case, as the wiki page notes, the constraint matrix is totally unimodular, which is exactly what you need to make your problem an instance of normal linear programming as well (that is, you can drop the integrality constraint, and the result will still be integral).\n\nSo, it can be solved in polynomial time. The Simplex algorithm doesn't guarantee that however.\n\nOf course there are also other polynomial time algorithms to solve the assignment problem.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "python network simplex algorithm for transportation problem?\r\n                \r\nAfter doing a lot of research I'm unable to find a network simplex algorithm for Python. This algorithm has been implemented in many other languages so there must be a python implementation I guess?\nI don't want to use PuLP as PuLP uses a standard LP formulization of this problem.\nHas someone dealt with this issue before?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to solve linear programming problem with simplex algorithm\r\n                \r\nI am solving the following problem of linear programming using the linprog function\n\n```\n%Objective Function\n     %X1    X2    X3    X4    X5    X6    X7    X8    X9    X10   X11   X12   X13   X14   X15   X16   X17   X18\nf = [0.669 0.654 0.503 0.683 0.670 0.673 0.749 0.655 0.660 0.583 1.243 0.639 2.024 2.156 1.672 0.473 0.139 0.687];\n\nA = [];   b = [];   %Sin restricciones de desigualdad\n\n%Restricciones de igualdad son:\n     %X1  X2    X3   X4   X5   X6   X7   X8   X9   X10  X11   X12  X13  X14  X15  X16  X17  X18\nAeq=[0.1 0.12 0.335 0.15 0.18 0.19 0.12 0.15 0.15 0.15   0   0.15 0.11  0   0.13  0     0  0.46; %Nitrogeno\n     0.3 0.24   0   0.03 0.05 0.04 0.27 0.03 0.24 0.15   0    0   0.52 0.52  0    0     0    0 ; %Fosforo\n     0.1 0.12   0   0.31 0.15 0.19 0.08 0.2  0.12 0.15  0.50  0    0   0.34 0.44  0     0    0 ; %Potasio\n      0    0    0    0    0    0    0    0    0    0     0   0.26  0    0    0    0    0.50  0 ; %Calcio\n      0    0    0    0   0.06  0    0    0    0    0     0    0    0    0    0   0.17   0    0]; %Magnesio\n\n\nbeq = [285.71 ; %Demanda nutricional de Nitrogeno (kg/ha)\n       305.33 ; %Demanda nutricional de Fosforo (kg/ha)\n          450 ; %Demanda nutricional de Potasio (kg/ha)\n       262.50 ; %Demanda nutricional de Calcio (kg/ha)\n        41.50]; %Demanda nutricional de Magnesio (kg/ha)\n\n%Limite inferior\nlb = zeros(18,1);   \n%Limite superior\nub = inf(18,1);        \n\nx = linprog(f, A, b, Aeq, beq, lb, ub, options)\n\nSolucion_optima = f*x\n```\n\n\nWhen I solve this is the result that throws me but does not show any results of the simplex table and I execute it with the following command\n\n```\noptions = optimoptions('linprog','Algorithm','dual-simplex');\n```\n\n\nSo I have the simplex algorithm\n\n```\niterM=100;\n\nIn=size(Aeq,1);\n\nXsol=[Aeq eye(In) beq\n    f zeros(1,In) 0];\n\nfor iter=1:1:iterM\n    fin=Xsol(end,1:end-1)<0;\n    if fin==0\n        break\n    end\n[a,c]=min(Xsol(end,:));\n\nXre=Xsol(:,end)./Xsol(:,c);\n\ni=Xre<=0;\n\nd=Xre;\nd(i)=inf;\n\n[beq,f]=min(d);\n\nXsol(f,1:end)=Xsol(f,1:end)/Xsol(f,c);\n\nfor i=1:1:size(Xsol,1)\n\n    if i~=f\n        Xsol(i,:)=Xsol(i,:)-(Xsol(i,c)*Xsol(f,:));\n    end\nend\n\nend\n\nfor i=1:1:size(f,2)\n    d=logical(Xsol(:,i));\n    X(i,1)=Xsol(d,end)\nend\n```\n\n\nWhen I run the Xsol function it does not show me the optimal solution nor the other values ​​that the simplex table should have\n    ", "Answer": "\r\nBased on the OP stating, \"I need the reduced costs, the dual solution and shadow prices.\"\n\n1) The dual solution is the shadow prices.  The shadow prices are the solution to the dual. \n\n2) The final simplex tableau is not the only way to obtain the stated objectives (though it would work). \n\nDual Solution (Shadow prices)\nYou can obtain the dual solution via ```\n[x,fval,exitflag,output,lambda] = linprog(___)```\n.  The ```\nlambda```\n is the dual solution; see MATLAB's documentation and examples for ```\nlinprog```\n (link).  The documentation calls these Lagrange multipliers.  \n\nReduced Costs\nThe reduced costs are obtainable with or without the dual solution.  If ```\nf```\n is the coefficients of the objective function (costs), then the reduced costs ```\n= f'- p'*A```\n when the LP is written in standard form ```\nA*x=b```\n. If someone else knows a better way to get the reduced costs from the output, please post.  I've tried to avoid the primal formula to spare pulling out the index of basic variables.    \n\nA clear reference on this:\nBertsimas, Dimistris, and Tsitsiklis, John N. 1997. Introduction to Linear Optimization, Athena Scientific & Dynamic Ideas, LLC, Belmont, MA. page 148\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Simplex algorithm in scipy package python\r\n                \r\nI am reading the documentation of the Simplex Algorithm provided in the Scipy package of python, but the example shown in the last at this documentation page is solving a minimization problem. Whereas I want to do a maximization. How would you alter the parameters in order to perform a maximization if we can do maximization using this package?\n    ", "Answer": "\r\nEvery maximization problem can be transformed into a minimization problem by multiplying the c-vector by -1: Say you have the 2-variable problem from the documentation, but want to maximize ```\nc=[-1,4]```\n\n\n```\nfrom scipy.optimize import linprog\nimport numpy\nc = numpy.array([-1, 4]) # your original c for maximization\nc *= -1 # negate the objective coefficients\nA = [[-3, 1], [1, 2]]\nb = [6, 4]\nx0_bnds = (None, None)\nx1_bnds = (-3, None)\nres = linprog(c, A, b, bounds=(x0_bnds, x1_bnds))\nprint(\"Objective = {}\".format(res.get('fun') * -1)) # don't forget to retransform your objective back!\n```\n\n\noutputs\n\n```\n>>> Objective = 11.4285714286\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Simplex algorithm stuck in loop\r\n                \r\nI'm trying to write a simplex algorithm in java for an assignment.\nMy code works for certain inputs, but quite often, the algorithm gets stuck in a cycle, recalculating from state A to state B, then back to state A. Into an infinite loop.\n\nAt first I thought it was a degeneracy problem. But I'm actually using Bland's rule, and further brainstorming and attempted debugging made me realize it's the negative coefficients in the constraint inequalities that are causing the cycling.\n\nSo I think I understand why the error is occurring. But I'm not sure how I should change my algorithm to fix the problem.\n\nHere's my entire code... \n\n```\npublic class Main {\n\n    // initialize tableau\n    static double tableau[][] = new double[101][201];\n    static int variable[] = new int[100];\n    static int nCount, mCount, totalColumnCount;\n\n    public static void main(String[] args) {\n        try {\n            // read from file\n            Scanner s = new Scanner(new File(\"c:\\\\hw6\\\\input.txt\"));\n\n            // for formatting double values to two decimal places\n            DecimalFormat oneDigit = new DecimalFormat(\"#,###0.00\");\n\n            // ----------------------------------------initialize tableau---------------------------------------------------\n            // read number of n(variables) and m(constraints)\n            nCount = s.nextInt();\n            mCount = s.nextInt();\n            totalColumnCount = nCount + mCount + 1;\n\n            // fill variable[] with arbitrarily large values\n            for (int j = 0; j < mCount; j++) {\n                variable[j] = 200;\n            }\n\n            // get coefficients for objective function and store into tableau\n            for (int j = 0; j < nCount; j++) {\n                tableau[mCount][j] = -s.nextInt();\n            }\n            for (int j = nCount; j < nCount + mCount; j++) {\n                tableau[mCount][j] = 0;\n            }\n            tableau[mCount][nCount + mCount] = 1; // value of MAX (P)\n            tableau[mCount][nCount + mCount + 1] = 0; // RHS (which should be 0)\n\n            // get coefficients of constraint inequalities\n            for (int j = 0; j < mCount; j++) {\n                for (int k = 0; k < nCount; k++) {\n                    tableau[j][k] = s.nextInt();\n                }\n                for (int k = nCount; k < nCount + mCount; k++) {\n                    if (k - nCount == j)\n                        tableau[j][k] = 1;\n                    else\n                        tableau[j][k] = 0;\n                }\n                // get the RHS\n                tableau[j][nCount + mCount + 1] = s.nextInt();\n            }\n\n            // store variables that each constraint refers to\n            for (int j = 0; j < mCount; j++) {\n                variable[j] = j + 1;\n            }\n            // ----------------------------------------initialize tableau---------------------------------------------------\n\n            // look for any negative values in the objective function\n            for (int j = 0; j <= totalColumnCount; j++) {\n                if (tableau[mCount][j] < 0) {\n                    Coordinate pivot = findPivot();\n                    pivotTo1(pivot);\n                    pivotColumnTo0(pivot);\n\n                    // for checking that this iteration of converting constraints has been calculated correctly\n                    for (int k = 0; k <= mCount; k++) {\n                        System.out.print(\"[ \");\n                        for (int l = 0; l <= totalColumnCount; l++) {\n                            System.out.print(oneDigit.format(tableau[k][l]) + \" \");\n                        }\n                        System.out.println(\" ]\");\n                    }\n                    System.out.println();\n\n                    // repeat looking for any negative values in the objective function\n                    j = 0;\n                    continue;\n                }\n            }\n            // get solutions\n            getSolution();\n\n        } catch (IOException e) {\n            System.out.println(e);\n        }\n    }\n\n    public static Coordinate findPivot() {\n        double currentMinColumn = Integer.MAX_VALUE;\n        double currentCalculation = Integer.MAX_VALUE;\n        int pivotColumn = 0;\n        int pivotRow = 0;\n\n        // find pivot column\n        for (int i = 0; i < totalColumnCount; i++) {\n            if (currentMinColumn > tableau[mCount][i]) {\n                currentMinColumn = tableau[mCount][i];\n                pivotColumn = i;\n            }\n        }\n\n        // find pivot\n        for (int i = 0; i < mCount; i++) {\n            if (currentCalculation > tableau[i][totalColumnCount] / tableau[i][pivotColumn]) {\n                currentCalculation = tableau[i][totalColumnCount] / tableau[i][pivotColumn];\n                pivotRow = i;\n            }\n        }\n\n        // return coordinate of pivot value\n        return new Coordinate(pivotRow, pivotColumn);\n    }\n\n    public static void pivotTo1(Coordinate pivot) {\n        double pivotValue = tableau[pivot.row()][pivot.column()];\n\n        // find factor to multiply to pivot's row to convert pivot to 1\n        double multFactor = 1.0 / pivotValue;\n\n        // convert the pivot's row\n        for (int i = 0; i <= totalColumnCount; i++) {\n            tableau[pivot.row()][i] *= multFactor;\n        }\n\n        // update variable for the constraint\n        variable[pivot.row()] = pivot.column();\n    }\n\n    public static void pivotColumnTo0(Coordinate pivot) {\n        double multFactor = 0;\n\n        // for all constraints\n        for (int i = 0; i < mCount + 1; i++) {\n            // skip constraint containing pivot\n            if (i == pivot.row())\n                continue;\n\n            // get multFactor of constraint\n            multFactor = -tableau[i][pivot.column()];\n\n            // update each constraint by making pivot column values become zero\n            for (int j = 0; j <= totalColumnCount; j++) {\n                tableau[i][j] = tableau[i][j] + (multFactor * tableau[pivot.row()][j]);\n            }\n        }\n    }\n\n    public static void getSolution() {\n        int solutionExists;\n\n        // for all variables\n        for (int i = 0; i < nCount; i++) {\n            solutionExists = 0;\n\n            // for all variables in the variable[] array\n            for (int j = 0; j < mCount; j++) {\n                // if the variable exists in the variable[] array print the value\n                if (i == variable[j]) {\n                    System.out.println(tableau[j][totalColumnCount]);\n                    solutionExists = 1;\n                    break;\n                }\n            }\n            // if it does not exist print 0\n            if (solutionExists == 0) {\n                System.out.println(0);\n            }\n        }\n    }\n}\n```\n\n\n(I would have liked to post only the relevant snippet of code so that you guys would have less of a hard time trying to decipher this, I thought that you guys would need the entire code anyway to find where my error is. I tried to put comments as specifically as possible.)\n\nI used this video as reference in understanding the simplex method: https://www.youtube.com/watch?v=gRgsT9BB5-8\n\nThe input.txt looks like this:\n\nThis one works\n\n```\n3 3         // number of variables (n), number of constraints (m)\n6 5 4       // objective function:      6x1 + 5x2 + 4x3\n2 1 1 180   // constraint 1:            2x1 + 1x2 + 1x3 <= 180\n1 3 2 300\n2 1 2 240\n```\n\n\nGiving the solution\n\n```\n48.0\n84.0\n0\n```\n\n\nThis one doesn't work\n\n```\n2 2\n2 5\n2 -1 4\n-1 2 9\n```\n\n\nAny help or advice will be greatly appreciated.\nThank you very much!\n    ", "Answer": "\r\nI had the exact same problem (expect for that I was programming with python. but the issue was the same). I found the solution in the answer in here.\nAs it states, when for example we have such table:\n\nwhen we choose x4 column because of the negative value (-1 in z row), then between s1, x1 and s3 rows, we could only choose s1 because the corresponding value for x4 column, can not be negative, since the RHS value can not become negative by later dividing.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Simplex Algorithm - why so complicated?\r\n                \r\nRecently I was introduced to the simplex algorithm for optimizing linear problems. I think I understand how it works, but I don't know, why it is that complicated.\n\n\nWhy do we have to use the pivot- row/column/element. If I see this correctly it is just a Gauss elimination which eliminates Elements in a specific order. Why does the order matter? Is it due to numerical noise? If everything is calculated precisely the ordering shouldn't be important, right?\nIn all examples I encountered so far (not too many to be fair) all slack variables are set to zero in the end. Why did we introduce them in the first place and didn't just rewrite all inequations  directly as equations?\n\n    ", "Answer": "\r\n\nPivoting is NOT Gaussian elimination. The tableau is likely to have about as many zeros after the pivot as before it. The order of pivoting is chosen to maintain the simplex constraint (always moving from one vertex of the feasible space to another), and to do so efficiently (by making maximum progress along the objective with each move).\nSlack variables are zero for constraints which bind the solution. It sounds like the problems you looked at didn't have any non-binding constraints.\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Alter Simplex Algorithm to Minimize on objective function NOT maximize [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI have created the following Simplex Algorithm that maximises on the objective function. I want the opposite to happen. In this example there are two variables and the algorithm must figure out what to multiply these two variables here (13.0 and 23.0) by in order to get the maximum possible result within the constraints set. I want the algorithm to figure out the lowest possible result instead.\n\nMy Code:\n\n```\nimport java.util.*;\n\n\npublic class Simplex\n{\nprivate static final double EPSILON = 1.0E-10;\nprivate double[][] tableaux;\nprivate int numOfConstraints;\nprivate int numOfVariables;\n\nprivate int[] basis;\n/**\n * Constructor for objects of class Simplex\n */\npublic Simplex()\n{\n\n\n    double[][] thisTableaux = {\n        {  5.0, 15.0 },\n        {  4.0,  4.0 },\n        { 35.0, 20.0 },\n    };\n\n    double[] constraints = { 480.0, 160.0, 1190.0 };\n\n    double[] variables = {  13.0,  23.0 };\n\n    numOfConstraints = constraints.length;\n    numOfVariables = variables.length;\n\n    tableaux = new double[numOfConstraints+1][numOfVariables+numOfConstraints+1];\n\n    //adds all elements from thisTableaux to tableaux\n    for(int i=0; i < numOfConstraints; i++)\n    {\n        for(int j=0; j < numOfVariables; j++)\n        {\n            tableaux[i][j] = thisTableaux[i][j];\n        }\n    } \n\n\n    //adds a slack variable for each variable there is and sets it to 1.0\n    for(int i=0; i < numOfConstraints; i++)\n    {\n        tableaux[i][numOfVariables+i] = 1.0;\n    }\n\n\n    //adds variables into the second [] of tableux\n    for(int j=0; j < numOfVariables; j++)\n    {\n        tableaux[numOfConstraints][j] = variables[j];\n    }\n\n\n\n    //adds constraints to first [] of tableaux\n    for(int k=0; k < numOfConstraints; k++)\n    {\n        tableaux[k][numOfConstraints+numOfVariables] = constraints[k];\n    }\n\n\n\n    basis = new int[numOfConstraints];\n\n    for(int i=0; i < numOfConstraints; i++)\n    {\n        basis[i] = numOfVariables + i;\n    }\n\n    //show();\n\n    //optimise();\n\n    //assert check(thisTableaux, constraints, variables);\n\n\n}\n\npublic void optimise() {\n    while(true) {\n\n        int q = findLowestNonBasicCol();\n\n        if(q == -1) {\n            break;\n        }\n\n        int p = getPivotRow(q);\n        if(p == -1) throw new ArithmeticException(\"Linear Program Unbounded\");\n\n        pivot(p, q);\n\n        basis[p] = q;\n    }\n\n}\n\npublic int findLowestNonBasicCol() {\n\n    for(int i=0; i < numOfConstraints + numOfVariables; i++)\n    {\n        if(tableaux[numOfConstraints][i] > 0) {\n\n\n            return i;\n        }\n    }\n\n    return -1;\n\n\n}\n\npublic int findIndexOfLowestNonBasicCol() {\n\n    int q = 0;\n    for(int i=1; i < numOfConstraints + numOfVariables; i++)\n    {\n        if(tableaux[numOfConstraints][i] > tableaux[numOfConstraints][q]) {\n            q = i;\n        }\n    }\n\n    if(tableaux[numOfConstraints][q] <= 0) {\n        return -1;\n    }\n\n    else {\n        return q;\n    }\n}\n\n/**\n * Finds row p which will be the pivot row using the minimum ratio rule.\n * -1 if there is no pivot row\n */\npublic int getPivotRow(int q) {\n\n    int p = -1;\n\n    for(int i=0; i < numOfConstraints; i++) {\n\n        if (tableaux[i][q] <=0) {\n            continue;\n        }\n\n        else if (p == -1) {\n            p = i;\n        }\n\n        else if((tableaux[i][numOfConstraints+numOfVariables] / tableaux[i][q] < tableaux[p][numOfConstraints+numOfVariables] / tableaux[p][q])) {\n            p = i;\n        }\n    }\n\n\n\n    return p;\n\n\n}\n\npublic void pivot(int p, int q) {\n\n    for(int i=0; i <= numOfConstraints; i++) {\n        for (int j=0; j <= numOfConstraints + numOfVariables; j++) {\n            if(i != p && j != q) {\n                tableaux[i][j] -= tableaux[p][j] * tableaux[i][q] / tableaux[p][q];\n            }\n        }\n    }\n\n    for(int i=0; i <= numOfConstraints; i++) {\n        if(i != p) {\n            tableaux[i][q] = 0.0;\n        }\n    }\n\n    for(int j=0; j <= numOfConstraints + numOfVariables; j++) {\n        if(j != q) {\n            tableaux[p][j] /= tableaux[p][q];\n        }\n    }\n\n    tableaux[p][q] = 1.0;\n\n    show();\n}\n\npublic double result() {\n    return -tableaux[numOfConstraints][numOfConstraints+numOfVariables];\n}\n\n\npublic double[] primal() {\n    double[] x = new double[numOfVariables];\n    for(int i=0; i < numOfConstraints; i++) {\n        if(basis[i] < numOfVariables) {\n            x[basis[i]] = tableaux[i][numOfConstraints+numOfVariables];\n        }\n    }\n\n    return x;\n}\n\npublic double[] dual() {\n    double[] y = new double[numOfConstraints];\n\n    for(int i=0; i < numOfConstraints; i++) {\n        y[i] = -tableaux[numOfConstraints][numOfVariables];\n    }\n\n    return y;\n}\n\npublic boolean isPrimalFeasible(double[][] thisTableaux, double[] constraints) {\n    double[] x = primal();\n\n    for(int j=0; j < x.length; j++) {\n        if(x[j] < 0.0) {\n            StdOut.println(\"x[\" + j + \"] = \" + x[j] + \" is negative\");\n            return false;\n        }\n    }\n\n    for(int i=0; i < numOfConstraints; i++) {\n        double sum = 0.0;\n\n        for(int j=0; j < numOfVariables; j++) {\n            sum += thisTableaux[i][j] * x[j];\n        }\n\n        if(sum > constraints[i] + EPSILON) {\n            StdOut.println(\"not primal feasible\");\n            StdOut.println(\"constraints[\" + i + \"] = \" + constraints[i] + \", sum = \" + sum);\n            return false;\n        }\n    }\n    return true;\n}\n\n\nprivate boolean isDualFeasible(double[][] thisTableaux, double[] variables) {\n\n    double[] y = dual();\n\n    for(int i=0; i < y.length; i++) {\n        if(y[i] < 0.0) {\n            StdOut.println(\"y[\" + i + \"] = \" + y[i] + \" is negative\");\n            return false;\n        }\n    }\n\n    for(int j=0; j < numOfVariables; j++) {\n        double sum = 0.0;\n\n        for(int i=0; i < numOfConstraints; i++) {\n            sum += thisTableaux[i][j] * y[i];\n        }\n\n        if(sum < variables[j] - EPSILON) {\n            StdOut.println(\"not dual feasible\");\n            StdOut.println(\"variables[\" + j + \"] = \" + variables[j] + \", sum = \" + sum);\n            return false;\n        }\n    }\n\n    return true;\n\n}\n\nprivate boolean isOptimal(double[] constraints, double[] variables) {\n\n    double[] x = primal();\n    double[] y = dual();\n    double value = result();\n\n    double value1 = 0.0;\n    for(int j=0; j < x.length; j++) {\n        value1 += variables[j] * x[j];\n    }\n\n    double value2 = 0.0;\n    for(int i=0; i < y.length; i++) {\n        value2 += y[i] * constraints[i];\n    }\n\n    if(Math.abs(value - value1) > EPSILON || Math.abs(value - value2) > EPSILON) {\n        StdOut.println(\"value = \" + value + \", cx = \" + value1 + \", yb = \" + value2);\n        return true;\n    }\n\n    return true;\n}\n\nprivate boolean check(double[][] thisTableaux, double[] constraints, double [] variables) {\n    return isPrimalFeasible(thisTableaux, constraints) && isDualFeasible(thisTableaux, variables) && isOptimal(constraints, variables);\n}\n\n\n}\n```\n\n\nIf you need any more info just ask. Any help appreciated thanks.\n    ", "Answer": "\r\nIf you want to minimize f(x), this is equivalent to maximizing -f(x), so if your posted code solves maximization problems correctly, you can use it to minimize any objective function f(x) simply by maximizing its additive inverse -f(x).\n\nNote that you do not change the constraints, only the objective function. \n\nFor example, minimizing f(x) = 3x + 5, x >= 1 is equivalent to maximizing -f(x) = -3x -5, x >= 1.  \n\nmin[f(x), x>=1] = f(1) = 8 = -(-8) = -[-f(1)] = -max[-f(x), x>=1].\n\nIn general, min[f(x)] = f(Xmin) = -[-f(Xmax)] = -max[-f(x)] and Xmin = Xmax.\n\nIn the above example, min[f(x)] = -max[-f(x)] = 8 and Xmin = Xmax = 1.\n\nIn the particular example you give, you would simply need to change the line\n\n```\ndouble[] variables = {  13.0,  23.0 };\n```\n\n\nto \n\n```\ndouble[] variables = {  -13.0,  -23.0 };\n```\n\n\nThe values of the variables returned should then be the same as for the minimum of the case where\n\n```\ndouble[] variables = {  13.0,  23.0 };\n```\n\n\nand multiplying the value of the objective function by -1 will give the minimum of the objective for the case where  \n\n```\ndouble[] variables = {  13.0,  23.0 };\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Are there Linear Programming libraries with the Simplex algorithm for Clojure?\r\n                \r\nThe Stigler Diet problem is a Linear Programming problem.  It takes a list of foods and their nutritional values and solves for an optimized selection and quantities that meet objectives and constraints.  Are there clojure libraries for Linear Programming - Simplex Algorithm, other than levand/prolin to work this?\n    ", "Answer": "\r\nActually there is a clojure library: prolin uses the Simplex implementation provided by Apache Commons Math. It's probably the most idiomatic api in clojure for linear programming. Current version in github uses org.apache.commons.math3 v3.2, however according to this JIRA entry the simplex implementation has significantly been improved in v3.3, so it may be worth upgrading (see prolin issue #1).\n\nAlso of interest is the Java Constraint Programming API (JSR 331). There's a clojure project using that API. Although its name hints towards constraint programming (CP), this blog post talks about using it for accessing linear programming (LP) solvers such as GLPK, lp_solve, gurobi, etc.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "simplex algorithm shifting origin in linear programming\r\n                \r\nI am reading linear programming using simplex algorithm in Algorithms book Sanjoy Das Gupta.\n\nI am having difficulty in understanding about origin is shifted and equations are changing. For example if origin is shifted from (0,0) to (0, 3). Here i can understand that if point is (x1, x2) in (0,0) origin, then the same point is (x1-0, x2-3) at new origin.  Here i am having confusion what is yi's pointing is it x1-0 = y1 and x2-3= y2. I am not getting how author got y1 - x1 and y2 - 3+ x1-x2 in below initial phase step ate end. Request to please explain.\n\n    ", "Answer": "\r\nSeems like a bad scan. I think that should read y1 = x1 and y2 = 3 + x1 − x2. The latter equation means that y2 is zero if and only if −x1 + x2 = 3 (i.e., constraint ③ is tight). Going between the two versions of the LP is just linear algebra.\n(TBH, I find this algebraic reasoning about the simplex method to be somewhat perplexing and prefer the geometric view of rolling a marble in a high-dimensional polytope.)\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Big Datasets for Simplex Algorithm (Linear Programming)\r\n                \r\nI need Big Datasets to test a parallel version of the simplex algorithm i am writing. The only Datasets i can find are in a Format called MPS but i cannot find a parser for MPS in Python or C.\n\nI would like them to directly contain the Matrix A and the vectors b and c if possible (in an easy to parse format).\n\nOr are there any easy to use parsers for MPS in C, Python, Java or Javascript?\n\nthanks!\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Numerical stability of Simplex Algorithm\r\n                \r\nEdit: Simplex the mathematical optimization algorithm, not to be confused with simplex noise or triangulation.\n\nI'm implementing my own linear programming solver and I would like to do so using 32bit floats. I know Simplex is very sensitive to the precision of the numbers because it performs lots of calculations and if too little precision is used, rounding errors may occur. But still, I would like to implement it using 32bit floats so I can make the instructions 4-wide, that is, so I can use SIMD to perform 4 calculations at a time. I'm aware that I could use doubles and make instructions 2-wide, but 4 is greater than 2 :)\n\nI have had problems with my floating point implementation where the solution was suboptimal or the problem was said to be unfeasible. This happens especially with mixed integer linear programs, which I solve with the branch and bound method.\n\nSo my question is: how can I prevent as much as possible having rounding errors resulting in unfeasible, unbounded or suboptimal solutions?\n\nI know one thing I can do is to scale the input values so that they are close to one (http://lpsolve.sourceforge.net/5.5/scaling.htm). Is there something else I can do?\n    ", "Answer": "\r\nYes, I tried to implement an algorithm for the Extended Knapsack problem using the Branch and bound method and Greedy Algorithm as a heuristic, is the exact analogue of the simplex running with a pivoting strategy that chooses the largest objective increase.\nI had problems with the numerical stabilities of the algorithm too.\nPersonally, I don't think there is an easy way to eliminate the issues if we keep using the floating-point, but there is a way to detect the instability during the branching process.\nI think, via experiment instead of rigorous maths on Stability Analysis, the majority of errors propagate through an integer solution that is extremely close to the constraints of the system.\nGiven any integer solution, we figure out the slack for that solution, and if the elements of the vector are extremely small, or on the magnitude of 1e-14 to 1e-15, then stop the branching and report instability.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "2D fiber alignment using the simplex algorithm\r\n                \r\nI have been writing some code for automatically aligning my fiber (whose X, Y, Z positions are controlled by a motor) to a light source. For this I have written my ```\naxis.move_to(pos)```\n method to move an axis to a position, and a ```\npm.meas_power()```\n method to measure optical power from my power meter.\nMy goal is to find the optimal (Y, Z) position (X is not needed at this stage) to maximise the optical power. Now, the search area is quite big compared to the light spot size, so a simple gradient search would not help if I start in an area where only noise is found, so what I do is randomly move across the search area, and move to a hill climbing algorithm as soon as I find a power higher than a certain threshold.\nProblem with this, is that it's quite inefficient. A first approach to optimisation would be to search for first light in a spiral rather than randomly, but computationally it does not really improve the number of steps.\nI have come across, instead, the simplex algorithm, which supposedly yields much better results than hill climbing. I found out that scipy has a ```\noptimize.linprog()```\n method which has a simplex algorithm, but it seems to me that this works for a 1D problem only.\nI tried to read the documentation and write my own code, but I know little about optimisation so I was having a hard time really understanding how that works.\nI was wondering whether you could help me write an algorithm given ```\n[ystart, zstart, yend, zend]```\n, i.e. the search area limits, and my two methods ```\naxis.move_to(pos)```\n and ```\npm.meas_power()```\n:\n```\nfrom labFunctions import PowerMeter, MotorAxis\n\npm = PowerMeter('pm_address')\nyaxis = MotorAxis('y_address')\nzaxis = MotorAxis('z_address')\n\nlimits = [ystart, zstart, yend, zend] # These can be formatted differently if needed\n```\n\n    ", "Answer": "\r\nUnfortunately, there are two very different Simplex methods:\n\nThe Nelder-Mead Simplex method for unconstrained non-linear problems. This method is referred to in the paper you linked to. https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html contains this method as ```\nNelder-Mead```\n.\nThe Simplex method for Linear Programming problems. ```\nlinprog```\n is about this method.\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to handle the special cases of simplex algorithm for linear programming\r\n                \r\nThis is a follow-up question to the SO question: Code a linear programming exercise by hand . I have a similar interest in implementing the simplex algorithm (linear programming) for pedagogical purposes. I understand that there are many improvements possible for a naive implementation of the simplex algorithm. But I am interested in developing a minimal complete simplex code.\n\nThe closest implementation I've found so far is in this answer due to @Pii to the above mentioned question in matlab, copied below for completeness. From the relatively short code, I can see how the basic logic of simplex involving pivoting is implemented (as pointed out in @RamNarasimhan's answer). But I don't know how to handle special cases of linear programming problems including:\n\n\ninfeasible problems, in which the feasible region is empty.\nunbounded problems, in which the objective function value is unconstrained from above (for a standard LP format: i.e. maximization problem)\n\n\nI suppose with these two cases handled, a simplex implementation will be complete in that it can handle any LP problems. \n\nMy question is how to modify the code to handle these two special cases.\n\nNote: I am not looking for complete code, just description of the specific logic to handle the above two corner cases. I've also looked at Looking for \"simple\" integer linear programming source code / pseudo code, and didn't find an answer.\n\n-- Code due to @Pii -- \n\n```\nfunction [x, fval] = mySimplex(fun, A, B, lb, up)\n\n%Examples paramters to show that the function actually works \n\n% sample set 1 (works for this data set)\n\n% fun = [8 10 7];\n% A = [1 3 2; 1 5 1];\n% B = [10; 8];\n% lb = [0; 0; 0];\n% ub = [inf; inf; inf];\n\n% sample set 2 (works for this data set)\n\nfun = [7 8 10];\nA = [2 3 2; 1 1 2];\nB = [1000; 800];\nlb = [0; 0; 0];\nub = [inf; inf; inf];\n\n\n% generate a new slack variable for every row of A \n\nnumSlackVars = size(A,1); % need a new slack variables for every row of A \n\n% Set up tableau to store algorithm data \ntableau = [A; -fun];\n\ntableau = [tableau, eye(numSlackVars + 1)];\n\nlastCol = [B;0];\n\ntableau = [tableau, lastCol];\n\n% for convienience sake, assign the following: \n\nnumRows = size(tableau,1);\nnumCols = size(tableau,2);\n\n% do simplex algorithm \n\n% step 0: find num of negative entries in bottom row of tableau \n\nnumNeg = 0; % the number of negative entries in bottom row\n\nfor i=1:numCols \n    if(tableau(numRows,i) < 0)\n        numNeg = numNeg + 1;\n    end\nend\n\n% Remark: the number of negatives is exactly the number of iterations\n% needed in the simplex algorithm \n\nfor iterations = 1:numNeg \n    % step 1: find minimum value in last row \n    minVal = 10000; % some big number \n    minCol = 1; % start by assuming min value is the first element \n    for i=1:numCols\n        if(tableau(numRows, i) < minVal)\n            minVal = tableau(size(tableau,1), i);\n            minCol = i; % update the index corresponding to the min element \n        end\n    end \n\n    % step 2: Find corresponding ratio vector in pivot column \n    vectorRatio = zeros(numRows -1, 1);\n    for i=1:(numRows-1) % the size of ratio vector is numCols - 1\n        vectorRatio(i, 1) = tableau(i, numCols) ./ tableau(i, minCol);\n    end \n\n    % step 3: Determine pivot element by finding minimum element in vector\n    % ratio\n\n    minVal = 10000; % some big number \n    minRatio = 1; % holds the element with the minimum ratio \n\n    for i=1:numRows-1\n        if(vectorRatio(i,1) < minVal)\n            minVal = vectorRatio(i,1);\n            minRatio = i;\n        end \n    end \n\n    % step 4: assign pivot element \n\n    pivotElement = tableau(minRatio, minCol);\n\n    % step 5: perform pivot operation on tableau around the pivot element \n\n    tableau(minRatio, :) = tableau(minRatio, :) * (1/pivotElement);\n\n    % step 6: perform pivot operation on rows (not including last row)\n\n    for i=1:size(vectorRatio,1)+1 % do last row last \n        if(i ~= minRatio) % skip over the minRatio'th element of the tableau \n            tableau(i, :) = -tableau(i, minCol) * tableau(minRatio, :) \n                            +  tableau(i,:);\n        end\n    end\nend \n\n% Now we can interpret the algo tableau \n\nnumVars = size(A,2); % the number of cols of A is the number of variables \n\nx = zeros(size(size(tableau,1), 1)); % for efficiency \n\n% Check for basicity \nfor col=1:numVars\n    count_zero = 0;\n    count_one = 0;\n    for row = 1:size(tableau,1)\n        if(tableau(row,col) < 1e-2)\n            count_zero = count_zero + 1;\n        elseif(tableau(row,col) - 1 < 1e-2)\n            count_one = count_one + 1;\n            stored_row = row; % store this column for later use \n        end\n    end\n    if(count_zero == (size(tableau,1) -1) && count_one == 1) % basic case\n        x(col,1) = tableau(stored_row, numCols);\n    else \n        x(col,1) = 0; % not basic case\n    end\nend\n\n% find function optimal value at optimal solution \nfval = x(1,1) * fun(1,1); % just needed for logic to work here \nfor i=2:numVars \n    fval = fval + x(i,1) * fun(1,i);\nend\n\n\nend\n```\n\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Is there an R function for applying Simplex algorithm from a given feasible starting point?\r\n                \r\nI would like to start Simplex algorithm from a feasible point apart from the origin.\n\nIs there any suitable function for this problem in R? I've tried the packages lpSolve and lpSolveAPI. \n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Why simplex algorithm works for solving Linear Programming\r\n                \r\nWe know that simplex is a very famous algorithm used to solve linear programming probleams, and I know how to use it, but what confused me is that why simplex always assumes that one of the vertices of the Polyhedron is the optimal solution ?\n    ", "Answer": "\r\nI think you can refer to the geometry, especially the analytic geometry. Simplex algorithm actually means that the optimal result always stay in the vertex instead of in the line or in the face, it's very intuitive.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Implementing simplex algorithm and getting \"matrix singular to machine precision\" error\r\n                \r\nI am implementing the (dual) simplex algorithm in Matlab/Octave.\n\nMy algorithm works just fine for a small test problem, but as soon as I try a bigger problem as afiro.mps (from http://www.netlib.org/lp/data/) I get the warning \"matrix singular to machine precision, rcond=0\" and octave throws an error (or does not terminate). The exact command is:\n\n```\nx = zeros(n,1);\nx(B) = A(:,B) \\ b; % Compute primal variables\ny = A(:,B)' \\ c(B); % Compute dual variables\n```\n\n\nThe problem is in standard form\n\n```\nmin c*x\ns.t. Ax=b\nx>=0\n```\n\n\nA is a m-x-n matrix and B is the index vector of the inactive constraints (base variables).\nAs I am doing a two phased simplex I choose 1:size(A,1) as an initial base for the dual simplex.\n\nThe problem is read from a mps file via a self coded reader. I expect the mps file is read correctly, as the glpk function solves the problem correctly, when it has A,b,c as input parameters.\n\nIs there some way to avoid the warning or do I have an error in my coding?\n    ", "Answer": "\r\nThe basis matrices of linear programming problems usually have very bad condition numbers. This is one the difficulties when implementing a stable simplex algorithm.\n\nYou should have a look at this paper that explains this phenomenon:\nOn the Factorization of Simplex Basis Matrices\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Algorithm for maximal hypervolume simplex\r\n                \r\nGiven a set of points in D-dimensional space. What is the optimal algorithm to find maximal possible D-simplex, all the vertexes of which is in the set? Algebraically it means that we have to find a subset of D + 1 points such, that determinant of D * D matrix, constructed from rows as deltas of coordinates each of first D points and last D + 1-st point, have greatest possible value (absolute value) on the set.\n\nI sure, that all D + 1 required points are vertexes of convex hull of given set of points, but I need the algorithm, which not used any convex hull algorithm, because simplex required for they, in turn, required for such algorithms as starting polytope.\n\nIf it is not possible to obtain the simplex in less than exponential time, then what is the algorithm, which gives adjustable ratio run-time/precision of approximation for approximate solving of the problem?\n    ", "Answer": "\r\nI can't think of an exact solution, but you could probably get a reasonable approximation with an iterative approach. Note than I'm assuming that ```\nN```\n is larger than ```\nD+1```\n here; if not then I have misunderstood the problem.\n\nFirst, use a greedy algorithm to construct an initial simplex; choose the first two vertices to be the two most distant points, the next one to maximise your size measure in two dimensions, the next to maximise it in three, and so on. This has polynomial complexity in ```\nN```\n and ```\nD```\n.\nOne you have the initial simplex you can switch to iterative improvement. For example, for a given vertex in the simplex you can iterate through the points not in it measuring the change in the size measure that would result if you swapped them. At the end you swap it with the one, if any, that gave the greatest increase. Doing this once for each vertex in the simplex is again polynomial in ```\nN```\n and ```\nD```\n.\nTo trade-off betwen run-time cost and how large the resulting simplex is, simply choose how many times you're willing to do this.\n\nNow this is a relatively crude local optimisation algorithm so cannot guarantee that it will find the maximal simplex. However, such approaches have been found to result in reasonably good approximations to the solution of problems like the travelling salesman problem, in the sense that whilst they're not optimal, they result in a distance that isn't too much greater than that of the actual solution in most cases.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to use the Nelder Meade Simplex algorithm in mathdotnet for function maximization\r\n                \r\nIn my C# program I have a dataset where each data point consists of:\n\na stimulus intensity (intensity) as x-coordinate\nthe percentage of correct response (percentageCorrect) to stimulus as y-coordinate\n\nWhen the intensity is low percentageCorrect is low. When the intensity is high the percentageCorrect is high. The function graph is an S-shaped curve as the percentageCorrect reaches an asymptote at low and high ends.\nI am trying to find the threshold intensity where percentageCorrect is half way between the asymtotes at either end (center of the S-shaped curve)\nI understand this to be a function maximization problem that can be solved by the Nelder Meade Simplex algorithm.\nI am trying to solve my problem using the Nelder Meade Simplex algorithm in mathdotnet and its IObjectiveFunction parameter.\nHowever, I am having trouble understanding the API of the NedlerMeadeSimplex class FindMinimum method and the IObjectiveFunction EvaluateAt method.\nI am new to numerical analysis that is pre-requisite for this question.\nSpecific questions are:\n\nFor the NedlerMeadeSimplex class FindMinimum method what are the initialGuess and initialPertubation parameters?\nFor the IObjectiveFunction EvaluateAt method, what is the point parameter? I vaguely understand that the point parameter is a datum in the dataset being minimized\nHow can I map my data set to this API and solve my problem?\n\nThanks for any guidance on this.\n    ", "Answer": "\r\nThe initial guess is a guess at the model parameters.\nI've always used the forms that don't require an entry of the initialPertubation parameter, so I can't help you there.\nThe objective function is what your are trying to minimize. For example, for a least squares fit, it would calculate the sum of squared areas at the point given in the argument. Something like this:\n```\nprivate double SumSqError(Vector<double> v)\n{\n    double err = 0;\n    for (int i = 0; i < 100; i++)\n    {\n        double y_val = v[0] + v[1] * Math.Exp(v[2] * x[i]);\n        err += Math.Pow(y_val - y[i], 2);\n    }\n    return err;\n}\n```\n\nYou don't have to supply the point. The algorithm does that over and over while searching for the minimum. Note that the subroutine as access to the vector x.\nHere is the code for a test program fitting a function to random data:\n```\nprivate void btnMinFit_Click(object sender, EventArgs e)\n{\n    Random RanGen = new Random();\n    x = new double[100];\n    y = new double[100];\n\n    // fit exponential expression with three parameters\n    double a = 5.0;\n    double b = 0.5;\n    double c = 0.05;\n    // create data set\n    for (int i = 0; i < 100; i++) x[i] = 10 + Convert.ToDouble(i) * 90.0 / 99.0; // values span 10 to 100\n    for (int i = 0; i < 100; i++)\n    {\n        double y_val = a + b * Math.Exp(c * x[i]);\n        y[i] = y_val + 0.1 * RanGen.NextDouble() * y_val;  // add error term scaled to y-value\n    }\n\n    // var fphv = new Func<double, double, double, double>((x, A, B) => A * x + B * x + A * B * x * x); extraneous test\n\n\n    var f1 = new Func<Vector<double>, double>(x => LogEval(x));\n    var obj = ObjectiveFunction.Value(f1);\n    var solver = new NelderMeadSimplex(1e-5, maximumIterations: 10000);\n    var initialGuess = new DenseVector(new[] { 3.0, 6.0, 0.6 });\n\n    var result = solver.FindMinimum(obj, initialGuess);\n\n\n    Console.WriteLine(result.MinimizingPoint.ToString());\n\n}\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to determine simplex time complexity (ie Max flow)\r\n                \r\nSimplex algorithm is said to have exponential worst case time complexity. Yet it is still often used in practice. How can you determine the average time complexity for a certain problem (being solved with simplex).\n\nFor example, what is the average time complexity of the maximum flow problem being solved with simplex algorithm. (Wiki has time complexity for all other algorithms)\n\nThank you for your time.\n    ", "Answer": "\r\nThe average case complexity is rather difficult to analyze and it depends on the distribution of your linear program. I believe that it was worked out to be polynomial time under some common distributions. I currently cannot find the paper though.\n\nEDIT: Yes, here are the sources:\n\nNocedal, J. and Wright, S. J. Numerical Optimization. New York: Springer-Verlag, 1999.\n\nForsgren, A.; Gill, P. E.; and Wright, M. H. \"Interior Methods for Nonlinear Optimization.\" SIAM Rev. 44, 525-597, 2002.\n\nI read it in the first book and apparently it was proven in a separate paper (Forsgren). You could find either in a university library.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Tiling Simplex Noise?\r\n                \r\nI've been interested (as a hobbyist) in pseudo-random noise generation, specifically the Perlin and Simplex algorithms. The advantage to Simplex is speed (especially at higher dimensions), but Perlin can be tiled relatively easily. I was wondering if anyone was aware of a tiling simplex algorithm? Fixed-dimension is fine, generic is better; pseudocode is fine, c/c++ is better.\n    ", "Answer": "\r\nJust tile your noise the same way you would in Perlin only do it after the skew. You can do this by modifying the part that gets the permutaions to do the mod 256 (or & 255, whatever you are using) after (instead of before) you add to offsets to the get the other corners from the base corner. This is the modified bit of code in HLSL:\n\n```\nuint3 iIdx0 = p0SI % 256;\nuint3 iIdx1 = (p0SI + pI1) % 256;\nuint3 iIdx2 = (p0SI + pI2) % 256;\nuint3 iIdx3 = (p0SI + 1.0f) % 256;\nuint iGI0 = gPerm[ iIdx0.x + gPerm[ iIdx0.y + gPerm[ iIdx0.z ] ] ] % 12;\nuint iGI1 = gPerm[ iIdx1.x + gPerm[ iIdx1.y + gPerm[ iIdx1.z ] ] ] % 12;\nuint iGI2 = gPerm[ iIdx2.x + gPerm[ iIdx2.y + gPerm[ iIdx2.z ] ] ] % 12;\nuint iGI3 = gPerm[ iIdx3.x + gPerm[ iIdx3.y + gPerm[ iIdx3.z ] ] ] % 12;\n```\n\n\np0SI is the corner 0 point and pI2 and PI2 are vectors to corner one and corner 2 calculated in the usual way. Note that in HLSL scalars promote to vectors automatically in mixed operatons so for instance 1.0f is actually (1.0,1.0,1.0). I just figured this tiling stuf out but apprently it works. If you need to shade a large planet or some shit but only have single precision on your card there are a few more steps. Hit me up. \n\nEdit: you know after thinking about it some more I don't think you have to change anything. I think it tiles autmatically at 256 units as implemented. \n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "What's the randomness quality of the Perlin/Simplex Noise algorithms?\r\n                \r\nWhat's the randomness quality of the Perlin Noise algorithm and Simplex Noise algorithm?\n\nWhich algorithm of the two has better randomness?\n\nCompared with standard pseudo-random generators, does it make sense to use Perlin/Simplex as random number generator?\n\nUpdate:\nI know what the Perlin/Simplex Noise is used for. I'm only curious of randomness properties.\n    ", "Answer": "\r\nPerlin noise and simplex noise are meant to generate useful noise, not to be completely random. These algorithms are generally used to create procedurally generated landscapes and the like. For example, it can generate terrain such as this (image from here):\n\n\n\nIn this image, the noise generates a 2D heightmap such as this (image from here):\n\n\n\nEach pixel's color represents a height. After producing a heightmap, a renderer is used to create terrain matching the \"heights\" (colors) of the image.\n\nTherefore, the results of the algorithm are not actually \"random\"; there are lots of easily discernible patterns, as you can see.\n\nSimplex supposedly looks a bit \"nicer\", which would imply less randomness, but its main purpose is that it produces similar noise but scales to higher dimensions better. That is, if one would produce 3D,4D,5D noise, simplex noise would outperform Perlin noise, and produce similar results.\n\nIf you want a general psuedo-random number generator, look at the Mersenne twister or other prngs. Be warned, wrt to cryptography, prngs can be full of caveats.\n\nUpdate:\n\n(response to OPs updated question)\n\nAs for the random properties of these noise functions, I know perlin noise uses a (very) poor man's prng as input, and does some smoothing/interpolation between neighboring \"random\" pixels. The input randomness is really just pseudorandom indexing into a precomputed random vector.\n\nThe index is computed using some simple integer operations, nothing too fancy. For example, the noise++ project uses precomputed \"randomVectors\" (see here) to obtain its source noise, and interpolates between different values from this vector. It generates a \"random\" index into this vector with some simple integer operations, adding a small amount of pseudorandomness. Here is a snippet:\n\n```\nint vIndex = (NOISE_X_FACTOR * ix + NOISE_Y_FACTOR * iy + NOISE_Z_FACTOR * iz + NOISE_SEED_FACTOR * seed) & 0xffffffff;\nvIndex ^= (vIndex >> NOISE_SHIFT);\nvIndex &= 0xff;\n\nconst Real xGradient = randomVectors3D[(vIndex<<2)];\n\n...\n```\n\n\nThe somewhat random noise is then smoothed over and in effect blended with neighboring pixels, producing the patterns.\n\nAfter producing the initial noise, perlin/simplex noise has the concept of octaves of noise; that is, reblending the noise into itself at different scales. This produces yet more patters. So the initial quality of the noise is probably only as good as the precomputed random arrays, plus the effect of the psuedorandom indexing. But after all that the perlin noise does to it, the apparent randomness decreases significantly (it actually spreads over a wider area I think).\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "linear programming with dual simplex in R\r\n                \r\nI have a linear programming problem that I'm trying to solve in ```\nR```\n. I have used ```\nlpSolve```\n package. lpSolve by default uses primal simplex algorithm to obtain solution. What if I want to change the algorithm to dual simplex ? The results vary widely between the two algorithms. Are there any other packages that would help to solve the problem below using dual simplex algorithm.\n\n```\nlibrary(\"lpSolve\")\n\nf.obj <- c(rep(1,12),rep(0,4))\nf.cons <- matrix(c(1,-1,0,0,0,0,0,0,0,0,0,0,1,-1,0,0,\n                   0,0,1,-1,0,0,0,0,0,0,0,0,1,0,-1,0,\n                   0,0,0,0,1,-1,0,0,0,0,0,0,1,0,0,-1,\n                   0,0,0,0,0,0,1,-1,0,0,0,0,0,1,-1,0,\n                   0,0,0,0,0,0,0,0,1,-1,0,0,0,1,0,-1,\n                   0,0,0,0,0,0,0,0,0,0,1,-1,0,0,1,-1),nrow=6,byrow=T)\n\nf.dir <- rep(\"=\",6)\n\nf.rhs <- c(-1.0986,1.6094,-1.0986,1.94591,1.3863,-1.7917)\n\ng <- lp (\"min\", f.obj, f.cons, f.dir, f.rhs,compute.sens=TRUE)\ng$solution\n```\n\n\nPrimal Simplex using lpSolve in ```\nR```\n is as follows:\n\n```\n0 0 0 0 0 0.91630 0.0 0.76209 0.47 0 0 0 1.60940 2.70800 0 1.79170\n```\n\n\nDual Simplex using Lingo software and SAS is as follows:\n\n```\n0 0.76214 0 0 1.23214 0 0 0 0.15415 0 0 0 0.8473 1.9459 0 1.7918\n```\n\n\nThe objective function is same for both the algorithms is ```\n2.14839```\n\n    ", "Answer": "\r\nWith ```\nlpSolveAPI```\n, you can finetune your solver:\n\n```\nlprec <- make.lp(0, ncol=16) \nset.objfn(lprec, obj=c(rep(1,12), rep(0,4)))\n\nadd.constraint(lprec, xt=c(1,-1,1,-1), indices=c(1, 2, 13, 14), type=\"=\", rhs=-1.0986)\nadd.constraint(lprec, xt=c(1,-1,1,-1), indices=c(3, 4, 13, 15), type=\"=\", rhs=1.6094)\nadd.constraint(lprec, xt=c(1,-1,1,-1), indices=c(5, 6, 13, 16), type=\"=\", rhs=-1.0986)\nadd.constraint(lprec, xt=c(1,-1,1,-1), indices=c(7, 8, 14, 15), type=\"=\", rhs=1.94591)\nadd.constraint(lprec, xt=c(1,-1,1,-1), indices=c(9, 10, 14, 16), type=\"=\", rhs=1.3863)\nadd.constraint(lprec, xt=c(1,-1,1,-1), indices=c(11, 12, 15, 16), type=\"=\", rhs=-1.7917)\n\nlp.control(lprec, simplextype=\"dual\", pivoting=\"dantzig\", verbose=\"detailed\")\nsolve(lprec)\nget.variables(lprec)\n#  [1] 0.00000 0.00000 0.76209 0.00000 0.00000 0.15421 0.00000 0.00000 1.23209\n# [10] 0.00000 0.00000 0.00000 0.84731 1.94591 0.00000 1.79170\n```\n\n\nSee ```\n?lp.control.options```\n for more details. However, I could not reproduce the solution given by LINGO/SAS.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Simplex algorithm in Excel without Solver\r\n                \r\nI am looking for an Excel table with formulas (no VBA, no Solver) that can solve LP problems:\n\nAx=b\n\n0<=x\n\ncx->min\n\nWith Solver and VBA, I can do it but I would like a solution which builds only on Excel Formulas. Or a proof that no such system consisting of formulas is possible. Efficiency is not critical.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "What is the difference between simplex method and network-simplex?\r\n                \r\nI am using the Network Simplex algorithm to solve a Maximum Flow Problem in directed graphs.\nIn order to compare the execution time for several routing algorithms, I need to use an implementation of the simplex method by George Dantzig.\nMy question is : Can the Simplex Method solve a maximum flow problem in a given directed graph?\nIs there any good documentation that explains the Simplex Method in graph theory?\n    ", "Answer": "\r\nThe Network Simplex Method is a highly specialized form of the general Simplex method: it can only solve network problems. \n\nOf course, the standard Simplex method for Linear Programming can also solve network problems, by just formulating the network problem as an LP problem. \n\nFor comparison, you may want to have a look at Cplex: it both has implementations for the (primal and dual) Simplex method for linear programming and a Network Simplex method.\n\nInterestingly, Gurobi does not have a network Simplex method. The thought behind this is that LP solvers have become so fast that specialized network solvers have lost some of their speed advantages.\n\nA good reference is: Ahuja, Magnanti and Orlin, Network Flows.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "The shadow price is different under different simple algorithm\r\n                \r\ni am using column generation algorithm to solve some problem,for example multi-commodity flow.I use gurobi .net api. When i try to get the shadow price of constraints, i found they are different with different simplex algorithms,such as primal simplex algorithm and dual simplex algorithm.In gurobi .net api, i set as follow:\n\n```\nGRBEnv env = new GRBEnv();\n    env.Set(GRB.IntParam.Method, GRB.METHOD_PRIMAL);//primal   \n    or env.Set(GRB.IntParam.Method, GRB.METHOD_DUAL);//DUAL\n```\n\n\nAnd also, with presolve and not presolve the result of shadow price will also be different，my setting are as follow:\n\n```\n env.Set(GRB.IntParam.Presolve, 0);//turn off presolve\n    env.set(GRB.IntParam.presolve,1);//with presolve\n```\n\n\nThe problem i am confusing are:\n\n\nin column generation algorithm,i should use which simplex algorithm,primal one or dual one?Should i turn off presolve or not?\ni test the two kind of algorithm respectively, i found the shadow prices in dual simplex algorithm without presolve are more reasonable. So ,i set the GRBEnv as dual simplex algorithm and turn off presolve,but during column generation iteration, usually in 3th iteration, the shadow prices will be the result of primal simplex algorithm.Because i write the continue lp model into *.lp file, reread the model and solve with two kind of algorithm,the result of primal one is  the same as the result of column generation iteration, so why during iteration,the dual simplex algorithm will turn to primal algorithm.\n\n\nAre there anybody can help me,thank you in advance.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to create a simplex algorithm table\r\n                \r\nI am trying to create a table that can have user input. I want to have a table with boxes instead of asking the user for a list of numbers, they can just input a lot of numbers into the table. Right now I have a list of variables and it is asking for user input for all of the variables.\nI want it to look a bit like this with some sort of way to input the numbers.\nhttps://i.stack.imgur.com/wNz4I.jpg\nHere is my code so far. It isn't very good. There is probably a much easier way to do it.\n```\nrow1X1=input(\"what is row1X1?: \")\n \nrow1X2=input(\"What is row1X2: \")\n \nrow1X3=input(\"what is row1X3?: \")\n \nrow1S1=input(\"What is row1S1: \")\n \nrow1S2=input(\"what is row1S2?: \")\n \nrow1Z=input(\"What is row1Z: \")\n \nrow1Equal=input(\"What is the equals: \")\n \n \n \nrow2X1=input(\"what is row2X1?: \")\n \nrow2X2=input(\"What is row2X2: \")\n \nrow2X3=input(\"what is row2X3?: \")\n \nrow2S1=input(\"What is row2S1: \")\n \nrow2S2=input(\"what is row2S2?: \")\n \nrow2Z=input(\"What is row2Z: \")\n \nrow2Equal=input(\"What is the equals: \")\n \n \nrow3X1=input(\"what is row3X1?: \")\n \nrow3X2=input(\"What is row3X2: \")\n \nrow3X3=input(\"what is row3X3?: \")\n \nrow3S1=input(\"What is row3S1: \")\n \nrow3S2=input(\"what is row3S2?: \")\n \nrow3Z=input(\"What is row3Z: \")\n \nrow3Equal=input(\"What is the equals: \")\n \n \n{\n \n \nprint(row1X1, row1X2, row1X3, row1S1, row1S2, row1Z, row1Equal)\n \nprint(row2X1, row2X2, row2X3, row2S1, row2S2, row2Z, row2Equal)\n \nprint(row3X1, row3X2, row3X3, row3S1, row3S2, row3Z, row3Equal)\n}\n```\n\nI eventually want to be able to input numbers and then have the program pivot the table based on the most negative number in the bottom row. I am not sure how to go about doing this, however.\n    ", "Answer": "\r\nWhat you've asked for here is a GUI.  In Python, that's done with tools like Tkinter or Qt or wxWidgets, but that's a huge problem.  Surely, for now, the best plan is you have your users enter their data in a text file with a simple text editor, then have your program read that file.  Then you can concentrate on the math.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Choosing the initial simplex in the Nelder-Mead optimization algorithm\r\n                \r\nWhat's the best way to initialize a simplex for use in a Nelder-Mead simplex search from a user's 'guess' vertex? \n    ", "Answer": "\r\nI'm not sure if there is a best way to choose the initial simplex in the Nelder-Mead method, but the following is what is done in common practice.\n\nThe construction of the initial simplex ```\nS```\n is obtained from generating ```\nn+1```\n vertices ```\nx0,..,xn```\n around what you call a user's \"guess\" vertex ```\nxin```\n in a ```\nN```\n dimensional space. The most frequent choice is \n\n```\nx0=xin \n```\n\n\nand the remaining ```\nn```\n vertices are then generated so that \n\n```\nxj=x0+hj*ej \n```\n\n\nwhere ```\nej```\n is the unit vector of the ```\nj```\n-th coordinate axis in ```\nR^n```\n and ```\nhj```\n is a step-size in the direction of ```\nej```\n. \n\n```\nhj = 0.05    if (x0)j is non-zero\nhj = 0.00025 if (x0)j=0\n```\n\n\nwith (x0)j the j-th component of x0. Note that this is the choice in Matlab's fminsearch routine, which is based on the Nelder-Mead scheme.\n\nYou can find some more information in\n\nF. Gao, L. Han, \"Implementing the Nelder-Mead simplex algorithm with adaptive parameters\", Comput. Optim. Appl., DOI 10.1007/s10589-010-9329-3\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Minimize Simplex method\r\n                \r\nI find topic about Simplex method here Alter Simplex Algorithm to Minimize on objective function NOT maximize\nBut answer didn`t help. When I change from \n\n```\ndouble[] variables = {  13.0,  23.0 };\n```\n\n\nto\n\n```\ndouble[] variables = { -13.0, -23.0 };\n```\n\n\nThe program dont calculate(no Exception), it print first step and that`s all.\nCould somebody help me with alter simplex method from maximize to minimize? \n\ncode:\n\nimport java.util.*;\n\n```\npublic class Simplex\n{\nprivate static final double EPSILON = 1.0E-10;\nprivate double[][] tableaux;\nprivate int numOfConstraints;\nprivate int numOfVariables;\n\nprivate int[] basis;\n/**\n * Constructor for objects of class Simplex\n */\npublic Simplex()\n{\n\n\n    double[][] thisTableaux = {\n        {  5.0, 15.0 },\n        {  4.0,  4.0 },\n        { 35.0, 20.0 },\n    };\n\n    double[] constraints = { 480.0, 160.0, 1190.0 };\n\n    double[] variables = {  -13.0,  -23.0 };\n\n    numOfConstraints = constraints.length;\n    numOfVariables = variables.length;\n\n    tableaux = new double[numOfConstraints+1][numOfVariables+numOfConstraints+1];\n\n    //adds all elements from thisTableaux to tableaux\n    for(int i=0; i < numOfConstraints; i++)\n    {\n        for(int j=0; j < numOfVariables; j++)\n        {\n            tableaux[i][j] = thisTableaux[i][j];\n        }\n    } \n\n\n    //adds a slack variable for each variable there is and sets it to 1.0\n    for(int i=0; i < numOfConstraints; i++)\n    {\n        tableaux[i][numOfVariables+i] = 1.0;\n    }\n\n\n    //adds variables into the second [] of tableux\n    for(int j=0; j < numOfVariables; j++)\n    {\n        tableaux[numOfConstraints][j] = variables[j];\n    }\n\n\n\n    //adds constraints to first [] of tableaux\n    for(int k=0; k < numOfConstraints; k++)\n    {\n        tableaux[k][numOfConstraints+numOfVariables] = constraints[k];\n    }\n\n\n\n    basis = new int[numOfConstraints];\n\n    for(int i=0; i < numOfConstraints; i++)\n    {\n        basis[i] = numOfVariables + i;\n    }\n\n    show();\n\n    optimise();\n\n    assert check(thisTableaux, constraints, variables);\n\n\n}\n\npublic void optimise() {\n    while(true) {\n\n        int q = findLowestNonBasicCol();\n\n        if(q == -1) {\n            break;\n        }\n\n        int p = getPivotRow(q);\n        if(p == -1) throw new ArithmeticException(\"Linear Program Unbounded\");\n\n        pivot(p, q);\n\n        basis[p] = q;\n    }\n\n}\n\npublic int findLowestNonBasicCol() {\n\n    for(int i=0; i < numOfConstraints + numOfVariables; i++)\n    {\n        if(tableaux[numOfConstraints][i] > 0) {\n\n\n            return i;\n        }\n    }\n\n    return -1;\n\n\n}\n\npublic int findIndexOfLowestNonBasicCol() {\n\n    int q = 0;\n    for(int i=1; i < numOfConstraints + numOfVariables; i++)\n    {\n        if(tableaux[numOfConstraints][i] > tableaux[numOfConstraints][q]) {\n            q = i;\n        }\n    }\n\n    if(tableaux[numOfConstraints][q] <= 0) {\n        return -1;\n    }\n\n    else {\n        return q;\n    }\n}\n\n/**\n * Finds row p which will be the pivot row using the minimum ratio rule.\n * -1 if there is no pivot row\n */\npublic int getPivotRow(int q) {\n\n    int p = -1;\n\n    for(int i=0; i < numOfConstraints; i++) {\n\n        if (tableaux[i][q] <=0) {\n            continue;\n        }\n\n        else if (p == -1) {\n            p = i;\n        }\n\n        else if((tableaux[i][numOfConstraints+numOfVariables] / tableaux[i][q] < tableaux[p][numOfConstraints+numOfVariables] / tableaux[p][q])) {\n            p = i;\n        }\n    }\n```\n\n    ", "Answer": "\r\nYou might want to look into the Dual Simplex Method (or Duality Theory). If the standard form of the primal problem is:\n\n```\nMaximize = 13*X1 + 23*X2;\n```\n\n\nwith constraints:\n\n```\n5*X1    +   15*X2   <= 480;\n4*X1    +   4*X2    <= 160;\n35*X1   +   20*X2   <= 1190;\nX1 >= 0;\nX2 >= 0;\n```\n\n\nThen the dual problem is:\n\n```\nMinimize = 480*Y1 + 160*Y2 + 1190*Y3;\n```\n\n\nwith constraints:\n\n```\n5*Y1    +   4*Y2    +   35*Y3   >= 13;\n15*Y1 +     4*Y2    +   20*Y3   >= 23;\nY1 >= 0;\nY2 >= 0;\nY3 >= 0;\n```\n\n\nI tested both of these problems in LINGO and get the same answer for both (Z = 800, X1 = 12, X2 = 28 -- Y1 = 1, Y2 = 2, Y3 = 0).\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Minimizing a very noisy 6-parameters function with simplex and a genetic algorithm - ¨Python language\r\n                \r\nI'm trying to minimize a loss function between empirical human data and simulated data from a 6-parameters cognitive model. The model is very noisy. Note that the model is programmed in PYTHON.\n\nThe standard method is to use a Simplex search. However, Simplex is very dependent on the initial guess, and the risk to capture a local minimum is high. So I have two questions:\n\n1) I'm wondering if a genetic algorithm could not be used to first search for an approximate position of the global minimum first, and use the result as a starting point for the simplex search. If it is a good idea, does someone know a good implementation of an appropriate genetic algorithm in python?\n\n2) Which reflection, expansion, and contraction constant should I use for the Simplex search?\n\nAny help would be highly appreciated. \n\nCheers,\nMat\n    ", "Answer": "\r\nSince your function is very noisy, have few dimensions and you are open to try evolutionary algorithm, I would recommend you to actually replace your Simplex optimization process by the Covariance Matrix Adaptation Evolution Strategy.\n\nThe algorithm is recognized by the black-box optimization community to be one of the most efficient for complex problem under 50 dimensions. It is described in details by its author  : here.\n\nThe author provides implementation of its algorithm in Python here. The evolutionary algorithms framework DEAP also provides a Python implementation of CMA-ES and different examples of application, which I find easier to use (disclaimer, I am one of the main developers of DEAP).\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "GJK algorithm creates simplex with two opposite points\r\n                \r\nI am making a physics engine, and I am using the GJK algorithm. Right now I have written it based off this blog post, and here is my code:\n```\nclass CollManager:\n    @staticmethod\n    def supportPoint(a, b, direction):\n        return a.supportPoint(direction) - \\\n            b.supportPoint(-direction)\n\n    @staticmethod\n    def nextSimplex(args):\n        length = len(args[0])\n        if length == 2:\n            return CollManager.lineSimplex(args)\n        if length == 3:\n            return CollManager.triSimplex(args)\n        if length == 4:\n            return CollManager.tetraSimplex(args)\n        return False\n    \n    @staticmethod\n    def lineSimplex(args):\n        a, b = args[0]\n        ab = b - a\n        ao = -a\n        if ab.dot(ao) > 0:\n            args[1] = ab.cross(ao).cross(ab)\n        else:\n            args[0] = [a]\n            args[1] = ao\n    \n    @staticmethod\n    def triSimplex(args):\n        a, b, c = args[0]\n        ab = b - a\n        ac = c - a\n        ao = -a\n        abc = ab.cross(ac)\n        if abc.cross(ac).dot(ao) > 0:\n            if ac.dot(ao) > 0:\n                args[0] = [a, c]\n                args[1] = ac.cross(ao).cross(ac)\n            else:\n                args[0] = [a, b]\n                return CollManager.lineSimplex(args)\n        elif ab.cross(abc).dot(ao) > 0:\n            args[0] = [a, b]\n            return CollManager.lineSimplex(args)\n        else:\n            if abc.dot(ao) > 0:\n                args[1] = abc\n            else:\n                args[0] = [a, c, b]\n                args[1] = -abc\n        return False\n    \n    @staticmethod\n    def tetraSimplex(args):\n        a, b, c, d = args[0]\n        ab = b - a\n        ac = c - a\n        ad = d - a\n        ao = -a\n        abc = ab.cross(ac)\n        acd = ac.cross(ad)\n        adb = ad.cross(ab)\n        if abc.dot(ao) > 0:\n            args[0] = [a, b, c]\n            return CollManager.triSimplex(args)\n        if acd.dot(ao) > 0:\n            args[0] = [a, c, d]\n            return CollManager.triSimplex(args)\n        if adb.dot(ao) > 0:\n            args[0] = [a, d, b]\n            return CollManager.triSimplex(args)\n        return True\n\n    @staticmethod\n    def gjk(a, b):\n        ab = a.pos - b.pos\n        c = Vector3(ab.z, ab.z, -ab.x - ab.y)\n        if c == Vector3.zero():\n            c = Vector3(-ab.y - ab.z, ab.x, ab.x)\n\n        support = CollManager.supportPoint(a, b, ab.cross(c))\n        points = [support]\n        direction = -support\n        while True:\n            support = CollManager.supportPoint(a, b, direction)\n            if support.dot(direction) <= 0:\n                return None\n            points.insert(0, support)\n            args = [points, direction]\n            if CollManager.nextSimplex(args):\n                return args[0]\n            points, direction = args\n```\n\nI have checked that the support point function works as intended, as I have worked out the maths behind it. What i did was I created two cubes, both of side length 2, with positions (0, 0, 0) and (1, 0, 0). The first direction that is calculated is ```\nVector3(0, 1, 0)```\n, so the first point on the simplex is ```\nVector3(1, -2, 0)```\n. The second point, looking in the other direction, is exactly the opposite, ```\nVector3(-1, 2, 0)```\n. This raises a problem, because the next direction that is created uses the cross product of the two, which gives ```\nVector3(0, 0, 0)```\n. Obviously no vector is in the same direction as this, so the line ```\nif support.dot(direction) <= 0:```\n fails.\nHowever, this happens when x is -1, 0 or 1, but not at -2 and 2.\nHow can I make sure the second point found on the simplex is not exactly opposite the first, thus making the check return early?\nMinimum reproducible example (uses exact same code):\n```\n# main.py\nfrom vector3 import Vector3\nimport math\n\nclass BoxCollider:\n    def __init__(self, position, side_length):\n        self.pos = position\n        self.side_length = side_length\n    \n    def supportPoint(self, direction):\n        maxDistance = -math.inf\n        min, max = self.pos - self.side_length // 2, self.pos + self.side_length // 2\n        for x in (min.x, max.x):\n            for y in (min.y, max.y):\n                for z in (min.z, max.z):\n                    distance = Vector3(x, y, z).dot(direction)\n                    if distance > maxDistance:\n                        maxDistance = distance\n                        maxVertex = Vector3(x, y, z)\n        return maxVertex\n\ndef supportPoint(a, b, direction):\n    return a.supportPoint(direction) - \\\n        b.supportPoint(-direction)\n\ndef nextSimplex(args):\n    length = len(args[0])\n    if length == 2:\n        return lineSimplex(args)\n    if length == 3:\n        return triSimplex(args)\n    if length == 4:\n        return tetraSimplex(args)\n    return False\n\ndef lineSimplex(args):\n    a, b = args[0]\n    ab = b - a\n    ao = -a\n    if ab.dot(ao) > 0:\n        args[1] = ab.cross(ao).cross(ab)\n    else:\n        args[0] = [a]\n        args[1] = ao\n\ndef triSimplex(args):\n    a, b, c = args[0]\n    ab = b - a\n    ac = c - a\n    ao = -a\n    abc = ab.cross(ac)\n    if abc.cross(ac).dot(ao) > 0:\n        if ac.dot(ao) > 0:\n            args[0] = [a, c]\n            args[1] = ac.cross(ao).cross(ac)\n        else:\n            args[0] = [a, b]\n            return lineSimplex(args)\n    elif ab.cross(abc).dot(ao) > 0:\n        args[0] = [a, b]\n        return lineSimplex(args)\n    else:\n        if abc.dot(ao) > 0:\n            args[1] = abc\n        else:\n            args[0] = [a, c, b]\n            args[1] = -abc\n    return False\n\ndef tetraSimplex(args):\n    a, b, c, d = args[0]\n    ab = b - a\n    ac = c - a\n    ad = d - a\n    ao = -a\n    abc = ab.cross(ac)\n    acd = ac.cross(ad)\n    adb = ad.cross(ab)\n    if abc.dot(ao) > 0:\n        args[0] = [a, b, c]\n        return triSimplex(args)\n    if acd.dot(ao) > 0:\n        args[0] = [a, c, d]\n        return triSimplex(args)\n    if adb.dot(ao) > 0:\n        args[0] = [a, d, b]\n        return triSimplex(args)\n    return True\n\ndef gjk(a, b):\n    ab = a.pos - b.pos\n    c = Vector3(ab.z, ab.z, -ab.x - ab.y)\n    if c == Vector3.zero():\n        c = Vector3(-ab.y - ab.z, ab.x, ab.x)\n\n    support = supportPoint(a, b, ab.cross(c))\n    points = [support]\n    direction = -support\n    while True:\n        support = supportPoint(a, b, direction)\n        if support.dot(direction) <= 0:\n            return None\n        points.insert(0, support)\n        args = [points, direction]\n        if nextSimplex(args):\n            return args[0]\n        points, direction = args\n\na = BoxCollider(Vector3(0, 0, 0), 2)\nb = BoxCollider(Vector3(1, 0, 0), 2)\nprint(gjk(a, b))\n```\n\nMy vector3.py file is much too long, here is an equivalent that also works: https://github.com/pyunity/pyunity/blob/07fed7871ace0c1b1b3cf8051d08d6677fe18209/pyunity/vector3.py\n    ", "Answer": "\r\nThe fix was to change ```\nab.cross(ao).cross(ab)```\n into just ```\nab / 2```\n, because that gives a vector from the midpoint of AB to the origin, and is much less expensive than two cross products.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Simplex noise vs Perlin noise\r\n                \r\nI would like to know why Perlin noise is still so popular today after Simplex came out. Simplex noise was made by Ken Perlin himself and it was suppose to take over his old algorithm which was slow for higher dimensions and with better quality (no visible artifacts).\n\nSimplex noise came out in 2001 and over those 10 years I've only seen people talk of Perlin noise when it comes to generating heightmaps for terrains, creating procedural textures, et cetera.\n\nCould anyone help me out, is there some downside of Simplex noise? I heard rumors that Perlin noise is faster when it comes to 1D and 2D noise, but I don't know if it's true or not.\n\nThanks!\n    ", "Answer": "\r\n\"If it ain't broke, don't fix it.\"\n\nSee if you can find anyone telling you why Simplex is better. \"It's faster and extends to multiple dimensions\" and \"simplex noise attempts to reduce the complexity of higher dimensional noise functions\" were what I found. Most of us work in 2 or 3 dimensions, maybe 4 if we're lucky enough to be doing something with time.\n\nI think its fair to say there is little enough real-time usage of Perlin that is too slow to handle, that for most purposes standard Perlin noise is sufficient. In pre-renderings (such as used in the movie industry) time isn't really important since renderings are slow anyway; and in real-time simulations, we have enough ways to reduce the scope of ongoing processing that it's unlikely you're going to be generating massive noise maps every few nano/milliseconds -- that's just basic real-time optimisation.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Desiring jagged results from simplex noise or another algorithm just as fast\r\n                \r\nI'm wanting to do some placement of objects like trees and the like based on noise for the terrain of a game/tech demo.\n\nI've used value noise previously and I believe I understand perlin noise well enough. Simplex noise, however, escapes me quite well (just a tad over my head at present).\n\nI have an implementation in C# of simplex noise, however, it's almost completely stolen from here. It works beautifully, but I just don't understand it well enough to modify it for my own purposes.\n\nIt is quite fast, but it also gives rather smooth results. I'm actually wanting something that is a little more jagged, like simple linear interpolation would give when I was doing value noise. My issue here is that due to the amount of calls I'd be doing for these object placements and using fractal Brownian motion, the speed of the algorithm becomes quite important.\n\nAny suggestions on how to get more 'jagged' results like linear interpolation gives with value noise using a faster algorithm than value noise is?\n    ", "Answer": "\r\nif you are using a complex noise function to do a simple task like the placement of trees, your using completely the wrong type of maths function. It is a very specific function which is great for making textures and 3d shapes and irregular curves. Placing treas on 2d certainly doesn't need irregular curves! Unless you want to place trees along in lines that are irregular and curved!\n\nunless you mean you want to place trees in areas of the noise which are a certain level, for example where the noise is larger than 0.98, which will give you nicely randomised zones that you can use as a central point saying some trees will be there. \n\nit will be a lot faster and a lot easier to vary, if you just use any normal noise function, just program your placement code around the noise function. I mean a predictable pseudo-random noise function which is the same every time you use it.\n\nuse integers 0 to 10 and 20 to 30, multiplied by your level number, to select 10 X and 10 Y points on the same pseudo-random noise curve. this will give you 10 random spots on your map from where to do stuff using almost no calculations.\n\nOnce you have the central point where trees will be, use another 10 random points from the function to say how many trees will be there, another 10 to say how far apart they will be, for the distribution around the tree seed quite exceptional. \n\nThe other option, if you want to change the curve http://webstaff.itn.liu.se/~stegu/simplexnoise/simplexnoise.pdf  is to read this paper and look at the polynomial function /whatever gradient function could be used in your code, looking the comments for the gradient function, commented out and do X equals Y, which should give you a straight interpolation curve.\n\nif you vote this answer up, I should have enough points in order to comment on this forum:]\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Weight Middle Range for use of scipy.optimize.linprog (Simplex algorithm)\r\n                \r\nThe basic problem is given these constraints (this is a simple example, my use case follows the same format but can introduce more variables):\n\n```\nx + y = C1\nC2 <= x <= C3\nC4 <= y <= C5\n```\n\n\n(where CX are constants, and x and y are variables), solve.\n\nEasy enough with ```\nscipy.optimize.linprog```\n. I'm able to get a technically correct result.\n\nExample. Using these specific constraints:\n\n```\nx + y = 50\n5 <= x <= 65\n10 <= y <= 40\n```\n\n\nWe get:\n\n```\n>>> res = scipy.optimize.linprog([1,1], bounds=([5, 65], [10, 40]), A_eq=[[1,1]], b_eq=[50]  )\n>>> res.x\narray([ 40.,  10.])\n```\n\n\nwhich is technically correct. Notice that the 2nd variable is at its minimum. But due to business reasons, we would prefer something more \"fair\" where each variable gets to go above its min if possible, something more along the lines of (but not necessarily the same as):\n\n```\narray([ 25.,  25.])\n```\n\n\nSo I've been thinking about weighting the midpoints. How can I use this ```\nscipy.optimize.linprog```\n api (or some other scipy optimization api) to modify the function being minimized such that it will give higher priorities to values closer to the midpoint of each variable range?\n    ", "Answer": "\r\nPlease see this answer as a draft to get an idea how to approach those kinds of problems. This is certainly not the best way to do it and certainly not the most effective algorithm for this kind of problem.\n\n\n\nThe problem here is, that you can probably not express your idea as a smooth linear target function. You need some kind of distance measurement, which probably has to be at least quadratic in case of smooth functions.\n\nThe following code adds the ```\nL2```\n of the ```\nx```\n vector norm as a penalty. This helps in this case, because the L2 norm is quadratic in its components and therefore prefers all components to be equally small over one larger and one smaller.\n\n```\nfrom scipy.optimize import fmin_slsqp\n\n# equality constraints as h(x) = 0\ndef h(x):\n    return x[0] + x[1] - 50\n\n# inequality constraints as g(x) >= 0\ndef g(x):\n    return [\n        x[0] - 5,\n        -x[0] + 65,\n        x[1] - 10,\n        -x[1] + 40,\n    ]\n\n# target functions\nf1 = lambda x: x[0] + x[1]\nf2 = lambda x: x[0] + x[1] + sum(x**2)\n```\n\n\n\n\nThe results:\n\n```\nx = fmin_slsqp(f1, (5,45), f_eqcons=h, f_ieqcons=g)\nprint(x)\n```\n\n\noutputs:\n\n```\nOptimization terminated successfully.    (Exit mode 0)\n            Current function value: 50.0\n            Iterations: 1\n            Function evaluations: 5\n            Gradient evaluations: 1\n[ 10.  40.]\n```\n\n\nAnd the penalized version:\n\n```\nx = fmin_slsqp(f2, (5,45), f_eqcons=h, f_ieqcons=g)\nprint(x)\n```\n\n\nprints\n\n```\nOptimization terminated successfully.    (Exit mode 0)\n            Current function value: 1300.0\n            Iterations: 3\n            Function evaluations: 12\n            Gradient evaluations: 3\n[ 25.  25.]\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Performance gain by implementing streamlined simplex\r\n                \r\nNOTE: I'm reposting here because of a comment on my original question in Computer Science StackExchange suggesting that maybe it was too implementation-based for that site.\n\n\n\nI have to solve linear transportation problems for a research project. Ideally, I should design an application that will recieve the problem data as an input and then show some results. The size of the problems are in the order of N=10.000 sources and N=10.000 destinations. Also, there are 2N=20.000 restrictions of equality, one for each source and one for each destination.\n\nI've been using Python's PuLP with the standard solver(COIN-OR) and with GLPK. As a general rule, the performance of COIN-OR is superior than that of GLPK, but even with COIN-OR the problems are taking too long to be solved. As far I as know, there's a streamlined version of the simplex algorithm for transportation problems, but I ignore the magnitude of the improvement in performance I should expect by using that streamlined version of simplex algorithm.\n\nSo, my first question is if those solvers identify the transportation problem structure of the problems I'm dealing with and act accordingly.\n\nIf the answer turns out to be no, then my second question is if I can exploit that particular structure of the transportation problems with a free solver that has a Python interface.\n\nAlso, will I note some improvement if I implement myself the streamlined version of the simplex algorithm? Or implementations must be too far from naive to really beat a well-established simplex solver like the ones I mentioned before?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "CPLEX quadratic simplex?\r\n                \r\nDoes anybody know which simplex-like algorithm CPLEX uses to solve quadratic programs. what is the so called Quadratic Simplex it is using?\n\nThank you in advance,\nMehdi\n    ", "Answer": "\r\nI'm not sure what CPLEX uses but the Simplex Method has been modified by Philip Wolfe to solve quadratic programming. In a nut shell, this is what it does:\n\nGiven a quadratic programming problem: QPP. p'x + 1/2x'Cx with constrains Ax = b\n\n\nC has to be symmetric positive definite (positive semi-definite might work as well)\ngenerate linear constraints using the Karush-Kuhn-Tucker conditions\nmodify the Simplex method in a way such that complementary slackness holds when choosing the pivot columns.\nproceed with the other usual Simplex method steps\n\n\nFor more detailed information, please take a look at this paper:\nhttp://pages.cs.wisc.edu/~brecht/cs838docs/wolfe-qp.pdf\n\nHope this helps.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Is there an algorithmic way to find the scaling factor for a given simplex noise dimension?\r\n                \r\nHere is one implementation in C# of the simplex noise algorithm\n\nYou'll notice that each noise function (2d, 3d, and 4d) scales the corner contributions to fit in the -1 to 1 range (this is the magic number on the return statements), which is reasonable. As far as I know these were figured out experimentally.\n\nThe problem is that I want to template this into an arbitrary number of dimensions, and this factor seems to be the one roadblock to doing that, so I'd like to find an algorithmic way of getting that scaling factor. I'm not familiar enough with the algorithm to see what factors contribute to the scale, but if I had to guess I'd think the permutations table at the top is a major one.\n\nDoes anyone have any ideas on this, perhaps just to say it isn't feasible?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Add Initial basic feasible solution for simplex using GLPK\r\n                \r\nI'd like to know if it is possible to introduce an initial basic feasible solution to the simplex in glpk, this in order to avoid de initialization phase of the algorithm and save computation time. I also want to know if glpk library uses the standard simplex or the revised simplex. Thanks.\n    ", "Answer": "\r\nYes, you can set a custom basis by using \nglp_set_col_stat(). You will have to set each column to be Basic (GLP_BS) or Non-basic (GLP_NL). You could also use the API glp_adv_basis method, though I don't think it lets you customize the basis.\n\nI recommend the very readable Section 2.6 in the LP Basis Construction Routines here.\n\nAnd yes, GLPK uses the Revised Simplex. I believe this is the default setting.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Can we assign a new propagator different from domain and bounds in GECODE solver for solving linear constraints?\r\n                \r\nLinear equations/inequations can be easily solved by simplex algorithm which is very fast. But for GECODE solver we only have two propagators : domain and bounds which solve the constraints that have different approach for solving linear problems and have time complexity near to NP Hard. \\n\nCan we modify the GECODE solver code to assign a new propagator that will use the simplex algorithm for solving linear constraints? Any idea?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Python – Simplex returning different values for the primal and the dual\r\n                \r\nI’m currently working on an implementation of the optimal transport problem using the simplex algorithm in Python, for the primal and the dual. However, I don't get the same values for the primal and the dual.\n\nI think the problem might come from the dual, because I have also solved the primal problem using Sinkhorn's algorithm, and it returned the same value as the simplex-based primal solution. \n\nHowever, I really can't find what is wrong and I am running out of ideas as to where the problem might come from. Here is my code, I hope it is clear !\n\nThank you for taking the time to read, and thank you in advance for any help that might come !!!\n\n```\nimport numpy as np\nfrom random import random\nimport scipy\nfrom scipy import optimize\n\n#descriptions of the primal (resp dual) problem line 42 (resp 48 and 50)\n\nn = 10 #number of points in distribution x_a\nm = 20 #number of points in distribution x_b\n\nx_a = [random() for i in range(n)] #n points chosen randomly between 0 and 1\nx_a.sort() #sorted list\nx_b = [2*random() for j in range(m)] #m points chosen randomly between 0 and 2\nx_b.sort()\n\na = [1/n for i in range(n)] #distribution vector for x_a (uniform)\nb = [1/m for i in range(m)] #distribution vector for x_b (uniform)\nB = a+b #concatenation of a and b\n\n#cost function (quadratic cost)\ndef cost(x,y) :\n    n = len(x)\n    p = len(y)\n    tab = [[0 for j in range(p)] for i in range(n)]\n    for i in range(n):\n        for j in range(p):\n            tab[i][j] = (x[i]-y[j])**2\n    return tab\n\n#definition of the matrix A\na0 = np.kron([1 for i in range(m)], np.eye(n, n))\na1 = np.kron(np.eye(m, m), [1 for i in range(n)])\nA = np.concatenate((a0,a1), axis = 0)\n\n#matrix of cost which we put columnwise into a 1D vector\ncost_matrix = cost(x_a,x_b)\ncost_column = []\nfor j in range(0,m):\n    for i in range(n):\n        cost_column += [cost_matrix[i][j]]\n\n#Primal problem : Minimize cost_column*p under the constraint A*p=B (p decision variable)\nproba = scipy.optimize.linprog(cost_column, A_ub=None, b_ub=None, A_eq=A, b_eq=B, bounds=None, method='simplex', callback=None, options=None, x0=None)\nobjective_result_primal = proba.fun\nprint(objective_result_primal)\n\nA_transpose = np.transpose(A)\n#Dual problem : Maximize B*h under the constraint A_transpose*h<=cost_column\nB2 = [-B[i] for i in range(m+n)]#we use the opposite of B to turn the maximization problem into a minimization one (so that we can use the simplex)\n#The dual problem becomes : Minimize B2*h under the constraint A_transpose*h<=cost_column\nproba = scipy.optimize.linprog(B2, A_ub=A_transpose, b_ub=cost_column, A_eq=None, b_eq=None, bounds=None, method='simplex', callback=None, options=None, x0=None)\nobjective_result_dual = - proba.fun\nprint(objective_result_dual)\n```\n\n    ", "Answer": "\r\nThe primal and dual for the (equality version of the) transportation problem look like:\n\n\n\nWhen using ```\nbounds=None```\n in the call to linprog, we tell the solver to use non-negative variables. This is correct for the primal, but not for the dual problem. For the dual problem you need to use ```\nbounds=(None,None)```\n which indicates the variables should be free. Now you should see that the optimal objective values for the primal and the dual problem are identical.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to give an initial simplex to Scipy.minimize?\r\n                \r\nI tried to enter an initial simplex to Nelder Mead but got an exception in python, that the shape is wrong. However, I don't know and can't figure out the shape, nor do I know where to look it up.\nWhen I want to use the scipy Nelder Mead algorithm, I want to have a very flexible initial simplex or also restart the optimization from a certain point without iterating the initial simplex again.\nHowever, I get an exception that the shape of my initial simplex is wrong:\n```\nValueError: `initial_simplex` should be an array of shape (N+1,N)\n```\n\nI could not find a good description or an example how to enter an initial simplex to the algorithm. Can someone provide a minimal example including the initial_simplex parameter?\n    ", "Answer": "\r\nafter testing I found a way it works.\nThis workinge xample takes a simplex into the algorithm which is then evaluated and from there the algorithm is started:\n```\nfrom math import pi, sin\nfrom random import uniform\n\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import minimize\n\n\ndef function(x, a, b, c):\n    return a * x ** 2 + b * x + c\n\n\ndef cost_function(guess):\n    y_test = [function(x_i, *guess) for x_i in x_range]\n    differences = [(y_i - data_i)**2 for y_i, data_i in zip(y_test, data)]\n    opt_plot.set_ydata(y_test)\n    plt.pause(1e-6)\n    cost = sum(differences) / len(differences)\n\n    print('cost', cost, 'guess', guess, end='\\n')\n    return cost\n\n\ndef get_initial_simplex(guess, delta_0=.2):\n    print('get simplex')\n    simplex = []\n    simplex.append([cost_function(guess), guess])\n    for i in range(len(guess)):\n        simplex_guess = guess.copy()\n        simplex_guess[i] += delta_0\n        cost = cost_function(simplex_guess)\n        simplex.append([cost, simplex_guess])\n\n    simplex = sorted(simplex, key=lambda x: x[0])\n    print('done')\n    return [elem[1] for elem in simplex]\n\n\n# create data\nx_range = [i / 100 for i in range(-100, 100)]\ndata = [3 * sin(x_i + pi / 2) + 2 for x_i in x_range]\n\n# plot the data:\nfig, ax = plt.subplots()\nax.plot(x_range, data)\nopt_plot, = ax.plot(x_range, [0 for _ in data])\nguess = [uniform(-1,1) for _ in range(3)]\n\n# start optimization of mse function\n\n\noptions ={\n    'initial_simplex': get_initial_simplex(guess)\n}\n\nresult = minimize(cost_function, guess, method='Nelder-Mead', options=options)\n\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Why do all Simplex Noise algorithms have a Permutation & Gradient table?\r\n                \r\nI've been trying to implement Simplex Noise for about a month now, and I do understand the idea of working with Simplices to reduce the amount of calculations needed and also safe power on the gradient side. Implementing this into any language though, seems like Mission Impossible. \n\nIn every, every, every, code I find, resource I read, everywhere, the code seems to be having a G and a P table. From some Googling and asking around I learnt they are a Permutation and a Gradients table. What do they do? Why do we need them? \n\nMy current thought is that the permutation table just contains random values so they don't have to be calculated at runtime. \n\nExamples:\n\n\nhttp://cabbynode.net/2012/06/10/perlin-simplex-noise-for-c-and-xna/\nhttp://www.6by9.net/simplex-noise-for-c-and-python/\nhttp://webstaff.itn.liu.se/~stegu/simplexnoise/simplexnoise.pdf\nhttp://www.csee.umbc.edu/~olano/s2002c36/ch02.pdf\n\n    ", "Answer": "\r\nEssentially yes, the P table is used to select a random gradient from the G table. However, the important thing is that it needs to be repeatable. That is, in the 3D case, for a given ```\n(i,j,k)```\n triple you need to be able to always produce the same \"random\" gradient. This is what makes the noise function coherent. So the whole point of the formula where it does a few lookups in the P table is that the result comes out looking random, but it's deterministic for a given input.\n\nIf you weren't concerned about performance, you could just as easily use ```\n(i,j,k)```\n to seed a pseudorandom number generator, and then use that to pick a gradient from the G table.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Nelder-Mead initial simplex size\r\n                \r\nI use Matlab's fminsearch function for finding the minimum with Nelder-Mead. fminsearch calculates the size of the initial simplex automatically. In my case, the initial simplex is too small, thus it performs not well.\n\nfminsearch uses a leg of length 5% of the size of each variable, with a value of 0.00025 for zero variables. However, I have read the following (source):\n\n\n  However, it can be a reasonable policy to set the points in such a way\n  that the simplex covers virtually the entire possible range. The\n  algorithm of Nelder-Mead will shrink automatically the simplex and\n  aproximate to the optimum. The practical advantage of this policy is\n  that you will obtain a better overall-knowledge of the\n  response-function.\n\n\nWhat leg length (percentage) do I have to choose to admit to this policy?\n\n\n  Please remember that the first simplex-opereation is añways a\n  reflection. If the starting simplex covers the whole permitted range\n  the reflection necessarily will give a point off limits. But\n  HillStormer allows to use linear constraints and can avoid this\n  problem.\n\n\nWhich linear constraints do I have to use to avoid this problem? I'm using fminsearchbnd and fminsearchcon which allows such constraints.\n\nLast but not least, I've read in Numerical Recipes that when the algorithm gets stuck at a local minima, it helps to reinitialize the simplex at the point where you get stuck. Of course, if fminsearch terminates I can rerun it with the new points as starting points. To what value should I set the initial simplex size in this case?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Print a table format of a numpy matrix\r\n                \r\nin one of my course projects I have written the simplex algorithm and recorded the output in a NumPy matrix as the following\n```\ntable =\n[[-1.00000000e+00  0.00000000e+00  0.00000000e+00  2.13333333e+00 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e-01 6.66666667e-02  3.86666667e+00  6.00000000e+00  4.50000000e+00 0.00000000e+00  0.00000000e+00  2.42766667e+03]\n [ 3.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00 1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00 0.00000000e+00  0.00000000e+00  4.00000000e+02]\n [ 1.00000000e+00  0.00000000e+00  1.00000000e+00 -8.00000000e+00 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00 0.00000000e+00  8.00000000e+00 -3.00000000e+00 -3.00000000e+00 0.00000000e+00  0.00000000e+00  8.00000000e+01]\n [ 5.00000000e+00  0.00000000e+00  0.00000000e+00 -5.33333333e-01 0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00 -6.66666667e-02  5.33333333e-01 -2.00000000e-01 -2.00000000e-01 0.00000000e+00  0.00000000e+00  1.33333333e+00]\n [ 0.00000000e+00  1.00000000e+00  0.00000000e+00  4.00000000e+00 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00 0.00000000e+00 -4.00000000e+00  2.00000000e+00  2.00000000e+00 0.00000000e+00  0.00000000e+00  1.60000000e+02]\n [ 4.00000000e+00  0.00000000e+00  0.00000000e+00  4.00000000e-01 0.00000000e+00  1.00000000e+00  0.00000000e+00 -1.00000000e-01 0.00000000e+00 -4.00000000e-01  2.00000000e-01  2.00000000e-01 0.00000000e+00  0.00000000e+00  1.10000000e+01]\n [ 1.10000000e+01  6.93889390e-18  0.00000000e+00  1.33333333e-01 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e-01 6.66666667e-02 -1.33333333e-01  0.00000000e+00  0.00000000e+00 1.00000000e+00  0.00000000e+00  8.76666667e+01]\n [ 1.20000000e+01  0.00000000e+00  0.00000000e+00  4.00000000e-01 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00 0.00000000e+00 -4.00000000e-01 -6.00000000e-01 -6.00000000e-01 0.00000000e+00  1.00000000e+00  1.60000000e+01]]\n```\n\nmy question is, how can I print this matrix in the following format (represent the simplex table)?\n\nThanks a lot in advance.\n    ", "Answer": "\r\nWhile not a perfect solution and certainly a bit of a mess to maintain, here is an approach that gets close to what you are looking for. Note: Being lazy , I only formatted the first 4 columns and the last column, but this should give you an idea as to how to proceed with the others.\n```\ndef format_array(ar):\n    shp = ar.shape \n    for r in range(shp[0]):\n        lst = ar[r]\n        print(f'{lst[0]:>6.0f} | {lst[1]:>12.6g} |  {lst[3]:>12.6g} | {lst[4]:>12.6g} | {lst[5]:<12.6g} ||{lst[14]:<12.6g}')\n        if r == 0:\n            print('='.rjust(80,'='))\n    \n```\n\nGiven your array, this is the result of the above:\n```\n    -1 |            0 |       2.13333 |            0 | 0            ||2427.67     \n================================================================================\n     3 |            0 |             0 |            1 | 0            ||400         \n     1 |            0 |            -8 |            0 | 0            ||80          \n     5 |            0 |     -0.533333 |            0 | 0            ||1.33333     \n     0 |            1 |             4 |            0 | 0            ||160         \n     4 |            0 |           0.4 |            0 | 1            ||11          \n    11 |  6.93889e-18 |      0.133333 |            0 | 0            ||87.6667     \n    12 |            0 |           0.4 |            0 | 0            ||16          \n```\n\n​\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Delphi mathematical optimisation techniques including simplex or genetic algorithms, etc\r\n                \r\nJust wondering whether anyone has recommendations for optimisation utilities for Delphi.\neg Simplex, Genetic algorithms etc...\n\nBasically I need to optimise my overarching model as a complete black box function, with input variables like tilt angle or array size, within pre-determined boundaries. Output is usually a smooth curve, and usually with no false summits.\n\nThe old NR Pascal stuff is looking a bit dated (no functions as variables etc).\n\nMany thanks, Brian\n    ", "Answer": "\r\nI found a program, written in Pascal, that simulates the Simplex method. It's a little old, but you may convert it into Delphi. You can find it \n\nhere\n\nI hope it's of some use to you.\n\nPS: If you have some cash to spend, try \n\nhere\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Linear programming algorithm\r\n                \r\nConsider the following algorithm for linear programming, minimizing [c,x] with A.x <= b.\n\n\n\n(1) Start with a feasible point x_0\n\n(2) Given a feasible point x_k, find the greatest alpha such that x_k - alpha.c is admissible (straighforward, look at the ratios of the components of A.x0 to A.c)\n\n(3) take the normal unit vector n to the hyperplane we just reached, pointing inwards. Project n on the plane [c,.] giving r = n - [n,c]/[c,c].c, then look for the greatest beta for which x_k - alpha.c + beta.r is admissible. Set x_{k+1} = x_k - alpha.c + 1/2*beta.r\n\nIf x_{k+1} is close enough to x_k within tolerance, return it, otherwise go to (2)\n\n\n\nThe basic idea is to follow the gradient until one hits a wall. Then, rather than following the shell of the simplex, like the simplex algorithm would do, the solution is kicked back inside the simplex, on a plane where the solutions are no worse, in the direction of the normal vector. The solution moves halfway between the starting point and the next constraint in this direction. It's no worse than before, but now it's more \"inside\" the simplex, where is has a shot at taking long leaps towards the optimum.\n\n\nThough the probability of hitting an intersection of more than one hyperplane is 0, if one gets close enough to multiple hyperplane within a certain tolerance, the average of the normals may be taken.\nThis can be generalized to any convex objective function by following geodesics on the levels of the function. For quadratic programming in particular, one rotates the solution towards the inside of the simplex.\n\n\n\n\nQuestions:\n\n\nDoes this algorithm have a name or fall within a category of linear-programming algorithms?\nDoes it have an obvious flaw that I'm overlooking?\n\n    ", "Answer": "\r\nI am pretty sure this doesn't work, unless I miss something: your algorithm will not start moving in most cases.\n\nAssume your variable ```\nx```\n is taken in ```\nR^n```\n.\n\nA polyhedron of the form ```\nAx <= b```\n is contained in a 'maximal' affine subspace ```\nP```\n of dimension ```\np <= n```\n, and usually ```\np```\n is much smaller than ```\nn```\n (you will have a lot of equality constraints, which can be implicit or explicit: you cannot assume that the expression of ```\nP```\n is simple to obtain from ```\nA```\n and ```\nb```\n).\n\nNow assume you can find an initial point ```\nx_0```\n (which is far from being obvious, btw) ; there is very little chance that the direction of the gradient ```\nc```\n is a feasible direction. You would need to consider the projection of the direction ```\nc```\n on ```\nP```\n, and this is very difficult to do in practice (how would you compute such projection?).\n\nThen, what you want in your step (3) is not the normal direction of the hyperplane you reached, but again its projection on ```\nP```\n (visualize the polyedron as a 2d polyedron embedded in a 3d space can help).\n\nThere is a very good reason why barrier functions are used in the interior point methods: it is very difficult to describe in practice the geometry of the high-dimension convex sets from the constraints (even simple ones like polyedrons), and things that \"seems obvious\" when you draw a picture on a piece of paper will not usually work when the dimension of the polyedron increases.\n\nOne last point is that your algorithm would not give the exact solution, whereas the simplex does in theory (and I read somewhere it can be done in practice by working with exact rational numbers).\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How fast is simplex method to solve tsp?\r\n                \r\nHow fast is simplex method compared with brute-force or any other algorithm to solve a ts problem?\n    ", "Answer": "\r\nYou can't model a TS problem with a \"pure\" LP problem (with continuous variables). You can use an integer-programming formulation, wich will use the simplex method at each node of a research tree (branch and bound or branch and cut method). It will work for small problems, but it is slow because the problem is hard: with one binary variable for each edge for instance, you need a lot of constraints to model the fact that the path is a cycle.\n\nBrute-force is intractable (the problem is exponential), do not even try it unless you have a very small problem. Use the MIP formulation, even for small problems.\n\nFor big problems, you should use some kind of heuristic (I think simulated annealing give good results on this one), or a \"smart\" modelization of you problem (column generation for instance) if you want an exact solution.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Why is the quality of my GLSL simplex noise so much worse then the one run on Java?\r\n                \r\nI've been working on an infinetly procedurally generated terrain using Simplex Noise. I've decided to improve its performance by transferring the Code for simplex noise to my compute shader. The problem was that the code I found for GLSL simplex noise performs worse then the code I found for Java simplex noise. Both of them work properly but the Java simplex noise produces terrain that looks way better and more interesting then the one in GLSL. Is there a way for me to improve the Simplex noise algorithm on my Compute shader or is it better to risk performance speed by using the Java Noise and get better results?\nCompute Shader Simplex noise Code\n```\n#version 430 core\n\nlayout  (local_size_x  =  10, local_size_y  =  10, local_size_z  =  10)  in;\n\nlayout(std430, binding=0) buffer Pos3D{\n    float Position3D[];\n};\nlayout(std430, binding=1) buffer Pos2D{\n    float Position2D[];\n};\n\nuniform float size;\n\n\nvec4 permute(vec4 x){return mod(((x*34.0)+1.0)*x, 289.0);}\nvec4 taylorInvSqrt(vec4 r){return 1.79284291400159 - 0.85373472095314 * r;}\n\nfloat snoise(vec3 v){ \n  const vec2  C = vec2(1.0/6.0, 1.0/3.0) ;\n  const vec4  D = vec4(0.0, 0.5, 1.0, 2.0);\n\n// First corner\n  vec3 i  = floor(v + dot(v, C.yyy) );\n  vec3 x0 =   v - i + dot(i, C.xxx) ;\n\n// Other corners\n  vec3 g = step(x0.yzx, x0.xyz);\n  vec3 l = 1.0 - g;\n  vec3 i1 = min( g.xyz, l.zxy );\n  vec3 i2 = max( g.xyz, l.zxy );\n\n  //  x0 = x0 - 0. + 0.0 * C \n  vec3 x1 = x0 - i1 + 1.0 * C.xxx;\n  vec3 x2 = x0 - i2 + 2.0 * C.xxx;\n  vec3 x3 = x0 - 1. + 3.0 * C.xxx;\n\n// Permutations\n  i = mod(i, 289.0 ); \n  vec4 p = permute( permute( permute( \n             i.z + vec4(0.0, i1.z, i2.z, 1.0 ))\n           + i.y + vec4(0.0, i1.y, i2.y, 1.0 )) \n           + i.x + vec4(0.0, i1.x, i2.x, 1.0 ));\n\n// Gradients\n// ( N*N points uniformly over a square, mapped onto an octahedron.)\n  float n_ = 1.0/7.0; // N=7\n  vec3  ns = n_ * D.wyz - D.xzx;\n\n  vec4 j = p - 49.0 * floor(p * ns.z *ns.z);  //  mod(p,N*N)\n\n  vec4 x_ = floor(j * ns.z);\n  vec4 y_ = floor(j - 7.0 * x_ );    // mod(j,N)\n\n  vec4 x = x_ *ns.x + ns.yyyy;\n  vec4 y = y_ *ns.x + ns.yyyy;\n  vec4 h = 1.0 - abs(x) - abs(y);\n\n  vec4 b0 = vec4( x.xy, y.xy );\n  vec4 b1 = vec4( x.zw, y.zw );\n\n  vec4 s0 = floor(b0)*2.0 + 1.0;\n  vec4 s1 = floor(b1)*2.0 + 1.0;\n  vec4 sh = -step(h, vec4(0.0));\n\n  vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy ;\n  vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww ;\n\n  vec3 p0 = vec3(a0.xy,h.x);\n  vec3 p1 = vec3(a0.zw,h.y);\n  vec3 p2 = vec3(a1.xy,h.z);\n  vec3 p3 = vec3(a1.zw,h.w);\n\n//Normalise gradients\n  vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));\n  p0 *= norm.x;\n  p1 *= norm.y;\n  p2 *= norm.z;\n  p3 *= norm.w;\n\n// Mix final noise value\n  vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);\n  m = m * m;\n  return 42.0 * dot( m*m, vec4( dot(p0,x0), dot(p1,x1), \n                                dot(p2,x2), dot(p3,x3) ) );\n}\n\nvec3 permute(vec3 x) { return mod(((x*34.0)+1.0)*x, 289.0); }\n\nfloat snoise(vec2 v){\n  const vec4 C = vec4(0.211324865405187, 0.366025403784439,\n           -0.577350269189626, 0.024390243902439);\n  vec2 i  = floor(v + dot(v, C.yy) );\n  vec2 x0 = v -   i + dot(i, C.xx);\n  vec2 i1;\n  i1 = (x0.x > x0.y) ? vec2(1.0, 0.0) : vec2(0.0, 1.0);\n  vec4 x12 = x0.xyxy + C.xxzz;\n  x12.xy -= i1;\n  i = mod(i, 289.0);\n  vec3 p = permute( permute( i.y + vec3(0.0, i1.y, 1.0 ))\n  + i.x + vec3(0.0, i1.x, 1.0 ));\n  vec3 m = max(0.5 - vec3(dot(x0,x0), dot(x12.xy,x12.xy),\n    dot(x12.zw,x12.zw)), 0.0);\n  m = m*m ;\n  m = m*m ;\n  vec3 x = 2.0 * fract(p * C.www) - 1.0;\n  vec3 h = abs(x) - 0.5;\n  vec3 ox = floor(x + 0.5);\n  vec3 a0 = x - ox;\n  m *= 1.79284291400159 - 0.85373472095314 * ( a0*a0 + h*h );\n  vec3 g;\n  g.x  = a0.x  * x0.x  + h.x  * x0.y;\n  g.yz = a0.yz * x12.xz + h.yz * x12.yw;\n  return 130.0 * dot(m, g);\n}\n\nfloat sumOctaves(int iterations, vec3 pos, double persistance, double scale, double low, double high){\n    double maxamp = 0;\n    double amp = 1;\n    double frequency = scale;\n    double noise = 0;\n    \n    for(int i = 0; i<iterations; i++){\n        noise += snoise(vec3(pos.x*frequency, pos.y*frequency, pos.z*frequency))*amp;\n        maxamp += amp;\n        amp *= persistance;\n        frequency *= 2;\n    }\n    \n    noise /= maxamp;\n    \n    noise = noise * (high - low) / 2 + (high + low) / 2;\n    return float(noise);\n}\nfloat sumOctaves(int iterations, vec2 pos, double persistance, double scale, double low, double high){\n    double maxamp = 0;\n    double amp = 1;\n    double frequency = scale;\n    double noise = 0;\n    \n    for(int i = 0; i<iterations; i++){\n        noise += snoise(vec2(pos.x*frequency, pos.y*frequency))*amp;\n        maxamp += amp;\n        amp *= persistance;\n        frequency *= 2;\n    }\n    \n    noise /= maxamp;\n    \n    noise = noise * (high - low) / 2 + (high + low) / 2;\n    return float(noise);\n}\n\nint getPosition(vec3 v){\n    return int(v.x+v.z*size+v.y*size*size);\n}\nint getPosition(vec2 v){\n    return int(v.x+v.y*size);\n}\nvoid main(){\n    if(gl_GlobalInvocationID.x < size && gl_GlobalInvocationID.y < size && gl_GlobalInvocationID.z < size){\n        Position3D[getPosition(gl_GlobalInvocationID)] = sumOctaves(4,gl_GlobalInvocationID,0.5,0.01,0,1);\n        Position2D[getPosition(gl_GlobalInvocationID.xz)] = sumOctaves(4,gl_GlobalInvocationID.xz,0.5,0.01,0,1);\n    }\n}\n```\n\nJava Simplex Noise Code\n```\npublic class SimplexNoise {  /[![enter image description here][1]][1]/ Simplex noise in 2D, 3D and 4D\n  private static Grad grad3[] = {new Grad(1,1,0),new Grad(-1,1,0),new Grad(1,-1,0),new Grad(-1,-1,0),\n                                 new Grad(1,0,1),new Grad(-1,0,1),new Grad(1,0,-1),new Grad(-1,0,-1),\n                                 new Grad(0,1,1),new Grad(0,-1,1),new Grad(0,1,-1),new Grad(0,-1,-1)};\n\n  private static Grad grad4[]= {new Grad(0,1,1,1),new Grad(0,1,1,-1),new Grad(0,1,-1,1),new Grad(0,1,-1,-1),\n                   new Grad(0,-1,1,1),new Grad(0,-1,1,-1),new Grad(0,-1,-1,1),new Grad(0,-1,-1,-1),\n                   new Grad(1,0,1,1),new Grad(1,0,1,-1),new Grad(1,0,-1,1),new Grad(1,0,-1,-1),\n                   new Grad(-1,0,1,1),new Grad(-1,0,1,-1),new Grad(-1,0,-1,1),new Grad(-1,0,-1,-1),\n                   new Grad(1,1,0,1),new Grad(1,1,0,-1),new Grad(1,-1,0,1),new Grad(1,-1,0,-1),\n                   new Grad(-1,1,0,1),new Grad(-1,1,0,-1),new Grad(-1,-1,0,1),new Grad(-1,-1,0,-1),\n                   new Grad(1,1,1,0),new Grad(1,1,-1,0),new Grad(1,-1,1,0),new Grad(1,-1,-1,0),\n                   new Grad(-1,1,1,0),new Grad(-1,1,-1,0),new Grad(-1,-1,1,0),new Grad(-1,-1,-1,0)};\n\n  private static short p[] = {151,160,137,91,90,15,\n  131,13,201,95,96,53,194,233,7,225,140,36,103,30,69,142,8,99,37,240,21,10,23,\n  190, 6,148,247,120,234,75,0,26,197,62,94,252,219,203,117,35,11,32,57,177,33,\n  88,237,149,56,87,174,20,125,136,171,168, 68,175,74,165,71,134,139,48,27,166,\n  77,146,158,231,83,111,229,122,60,211,133,230,220,105,92,41,55,46,245,40,244,\n  102,143,54, 65,25,63,161, 1,216,80,73,209,76,132,187,208, 89,18,169,200,196,\n  135,130,116,188,159,86,164,100,109,198,173,186, 3,64,52,217,226,250,124,123,\n  5,202,38,147,118,126,255,82,85,212,207,206,59,227,47,16,58,17,182,189,28,42,\n  223,183,170,213,119,248,152, 2,44,154,163, 70,221,153,101,155,167, 43,172,9,\n  129,22,39,253, 19,98,108,110,79,113,224,232,178,185, 112,104,218,246,97,228,\n  251,34,242,193,238,210,144,12,191,179,162,241, 81,51,145,235,249,14,239,107,\n  49,192,214, 31,181,199,106,157,184, 84,204,176,115,121,50,45,127, 4,150,254,\n  138,236,205,93,222,114,67,29,24,72,243,141,128,195,78,66,215,61,156,180};\n  // To remove the need for index wrapping, double the permutation table length\n  private static short perm[] = new short[512];\n  private static short permMod12[] = new short[512];\n  static {\n    for(int i=0; i<512; i++)\n    {\n      perm[i]=p[i & 255];\n      permMod12[i] = (short)(perm[i] % 12);\n    }\n  }\n\n  // Skewing and unskewing factors for 2, 3, and 4 dimensions\n  private static final double F2 = 0.5*(Math.sqrt(3.0)-1.0);\n  private static final double G2 = (3.0-Math.sqrt(3.0))/6.0;\n  private static final double F3 = 1.0/3.0;\n  private static final double G3 = 1.0/6.0;\n  private static final double F4 = (Math.sqrt(5.0)-1.0)/4.0;\n  private static final double G4 = (5.0-Math.sqrt(5.0))/20.0;\n\n  // This method is a *lot* faster than using (int)Math.floor(x)\n  private static int fastfloor(double x) {\n    int xi = (int)x;\n    return x<xi ? xi-1 : xi;\n  }\n\n  private static double dot(Grad g, double x, double y) {\n    return g.x*x + g.y*y; }\n\n  private static double dot(Grad g, double x, double y, double z) {\n    return g.x*x + g.y*y + g.z*z; }\n\n  private static double dot(Grad g, double x, double y, double z, double w) {\n    return g.x*x + g.y*y + g.z*z + g.w*w; }\n\n\n  // 2D simplex noise\n  public static double noise(double xin, double yin) {\n    double n0, n1, n2; // Noise contributions from the three corners\n    // Skew the input space to determine which simplex cell we're in\n    double s = (xin+yin)*F2; // Hairy factor for 2D\n    int i = fastfloor(xin+s);\n    int j = fastfloor(yin+s);\n    double t = (i+j)*G2;\n    double X0 = i-t; // Unskew the cell origin back to (x,y) space\n    double Y0 = j-t;\n    double x0 = xin-X0; // The x,y distances from the cell origin\n    double y0 = yin-Y0;\n    // For the 2D case, the simplex shape is an equilateral triangle.\n    // Determine which simplex we are in.\n    int i1, j1; // Offsets for second (middle) corner of simplex in (i,j) coords\n    if(x0>y0) {i1=1; j1=0;} // lower triangle, XY order: (0,0)->(1,0)->(1,1)\n    else {i1=0; j1=1;}      // upper triangle, YX order: (0,0)->(0,1)->(1,1)\n    // A step of (1,0) in (i,j) means a step of (1-c,-c) in (x,y), and\n    // a step of (0,1) in (i,j) means a step of (-c,1-c) in (x,y), where\n    // c = (3-sqrt(3))/6\n    double x1 = x0 - i1 + G2; // Offsets for middle corner in (x,y) unskewed coords\n    double y1 = y0 - j1 + G2;\n    double x2 = x0 - 1.0 + 2.0 * G2; // Offsets for last corner in (x,y) unskewed coords\n    double y2 = y0 - 1.0 + 2.0 * G2;\n    // Work out the hashed gradient indices of the three simplex corners\n    int ii = i & 255;\n    int jj = j & 255;\n    int gi0 = permMod12[ii+perm[jj]];\n    int gi1 = permMod12[ii+i1+perm[jj+j1]];\n    int gi2 = permMod12[ii+1+perm[jj+1]];\n    // Calculate the contribution from the three corners\n    double t0 = 0.5 - x0*x0-y0*y0;\n    if(t0<0) n0 = 0.0;\n    else {\n      t0 *= t0;\n      n0 = t0 * t0 * dot(grad3[gi0], x0, y0);  // (x,y) of grad3 used for 2D gradient\n    }\n    double t1 = 0.5 - x1*x1-y1*y1;\n    if(t1<0) n1 = 0.0;\n    else {\n      t1 *= t1;\n      n1 = t1 * t1 * dot(grad3[gi1], x1, y1);\n    }\n    double t2 = 0.5 - x2*x2-y2*y2;\n    if(t2<0) n2 = 0.0;\n    else {\n      t2 *= t2;\n      n2 = t2 * t2 * dot(grad3[gi2], x2, y2);\n    }\n    // Add contributions from each corner to get the final noise value.\n    // The result is scaled to return values in the interval [-1,1].\n    return 70.0 * (n0 + n1 + n2);\n  }\n\n\n  // 3D simplex noise\n  public static double noise(double xin, double yin, double zin) {\n    double n0, n1, n2, n3; // Noise contributions from the four corners\n    // Skew the input space to determine which simplex cell we're in\n    double s = (xin+yin+zin)*F3; // Very nice and simple skew factor for 3D\n    int i = fastfloor(xin+s);\n    int j = fastfloor(yin+s);\n    int k = fastfloor(zin+s);\n    double t = (i+j+k)*G3;\n    double X0 = i-t; // Unskew the cell origin back to (x,y,z) space\n    double Y0 = j-t;\n    double Z0 = k-t;\n    double x0 = xin-X0; // The x,y,z distances from the cell origin\n    double y0 = yin-Y0;\n    double z0 = zin-Z0;\n    // For the 3D case, the simplex shape is a slightly irregular tetrahedron.\n    // Determine which simplex we are in.\n    int i1, j1, k1; // Offsets for second corner of simplex in (i,j,k) coords\n    int i2, j2, k2; // Offsets for third corner of simplex in (i,j,k) coords\n    if(x0>=y0) {\n      if(y0>=z0)\n        { i1=1; j1=0; k1=0; i2=1; j2=1; k2=0; } // X Y Z order\n        else if(x0>=z0) { i1=1; j1=0; k1=0; i2=1; j2=0; k2=1; } // X Z Y order\n        else { i1=0; j1=0; k1=1; i2=1; j2=0; k2=1; } // Z X Y order\n      }\n    else { // x0<y0\n      if(y0<z0) { i1=0; j1=0; k1=1; i2=0; j2=1; k2=1; } // Z Y X order\n      else if(x0<z0) { i1=0; j1=1; k1=0; i2=0; j2=1; k2=1; } // Y Z X order\n      else { i1=0; j1=1; k1=0; i2=1; j2=1; k2=0; } // Y X Z order\n    }\n    // A step of (1,0,0) in (i,j,k) means a step of (1-c,-c,-c) in (x,y,z),\n    // a step of (0,1,0) in (i,j,k) means a step of (-c,1-c,-c) in (x,y,z), and\n    // a step of (0,0,1) in (i,j,k) means a step of (-c,-c,1-c) in (x,y,z), where\n    // c = 1/6.\n    double x1 = x0 - i1 + G3; // Offsets for second corner in (x,y,z) coords\n    double y1 = y0 - j1 + G3;\n    double z1 = z0 - k1 + G3;\n    double x2 = x0 - i2 + 2.0*G3; // Offsets for third corner in (x,y,z) coords\n    double y2 = y0 - j2 + 2.0*G3;\n    double z2 = z0 - k2 + 2.0*G3;\n    double x3 = x0 - 1.0 + 3.0*G3; // Offsets for last corner in (x,y,z) coords\n    double y3 = y0 - 1.0 + 3.0*G3;\n    double z3 = z0 - 1.0 + 3.0*G3;\n    // Work out the hashed gradient indices of the four simplex corners\n    int ii = i & 255;\n    int jj = j & 255;\n    int kk = k & 255;\n    int gi0 = permMod12[ii+perm[jj+perm[kk]]];\n    int gi1 = permMod12[ii+i1+perm[jj+j1+perm[kk+k1]]];\n    int gi2 = permMod12[ii+i2+perm[jj+j2+perm[kk+k2]]];\n    int gi3 = permMod12[ii+1+perm[jj+1+perm[kk+1]]];\n    // Calculate the contribution from the four corners\n    double t0 = 0.6 - x0*x0 - y0*y0 - z0*z0;\n    if(t0<0) n0 = 0.0;\n    else {\n      t0 *= t0;\n      n0 = t0 * t0 * dot(grad3[gi0], x0, y0, z0);\n    }\n    double t1 = 0.6 - x1*x1 - y1*y1 - z1*z1;\n    if(t1<0) n1 = 0.0;\n    else {\n      t1 *= t1;\n      n1 = t1 * t1 * dot(grad3[gi1], x1, y1, z1);\n    }\n    double t2 = 0.6 - x2*x2 - y2*y2 - z2*z2;\n    if(t2<0) n2 = 0.0;\n    else {\n      t2 *= t2;\n      n2 = t2 * t2 * dot(grad3[gi2], x2, y2, z2);\n    }\n    double t3 = 0.6 - x3*x3 - y3*y3 - z3*z3;\n    if(t3<0) n3 = 0.0;\n    else {\n      t3 *= t3;\n      n3 = t3 * t3 * dot(grad3[gi3], x3, y3, z3);\n    }\n    // Add contributions from each corner to get the final noise value.\n    return 32.0*(n0 + n1 + n2 + n3);\n  }\n\n\n  // 4D simplex noise, better simplex rank ordering method 2012-03-09\n  public static double noise(double x, double y, double z, double w) {\n\n    double n0, n1, n2, n3, n4; // Noise contributions from the five corners\n    // Skew the (x,y,z,w) space to determine which cell of 24 simplices we're in\n    double s = (x + y + z + w) * F4; // Factor for 4D skewing\n    int i = fastfloor(x + s);\n    int j = fastfloor(y + s);\n    int k = fastfloor(z + s);\n    int l = fastfloor(w + s);\n    double t = (i + j + k + l) * G4; // Factor for 4D unskewing\n    double X0 = i - t; // Unskew the cell origin back to (x,y,z,w) space\n    double Y0 = j - t;\n    double Z0 = k - t;\n    double W0 = l - t;\n    double x0 = x - X0;  // The x,y,z,w distances from the cell origin\n    double y0 = y - Y0;\n    double z0 = z - Z0;\n    double w0 = w - W0;\n    // For the 4D case, the simplex is a 4D shape I won't even try to describe.\n    // To find out which of the 24 possible simplices we're in, we need to\n    // determine the magnitude ordering of x0, y0, z0 and w0.\n    // Six pair-wise comparisons are performed between each possible pair\n    // of the four coordinates, and the results are used to rank the numbers.\n    int rankx = 0;\n    int ranky = 0;\n    int rankz = 0;\n    int rankw = 0;\n    if(x0 > y0) rankx++; else ranky++;\n    if(x0 > z0) rankx++; else rankz++;\n    if(x0 > w0) rankx++; else rankw++;\n    if(y0 > z0) ranky++; else rankz++;\n    if(y0 > w0) ranky++; else rankw++;\n    if(z0 > w0) rankz++; else rankw++;\n    int i1, j1, k1, l1; // The integer offsets for the second simplex corner\n    int i2, j2, k2, l2; // The integer offsets for the third simplex corner\n    int i3, j3, k3, l3; // The integer offsets for the fourth simplex corner\n    // [rankx, ranky, rankz, rankw] is a 4-vector with the numbers 0, 1, 2 and 3\n    // in some order. We use a thresholding to set the coordinates in turn.\n    // Rank 3 denotes the largest coordinate.\n    i1 = rankx >= 3 ? 1 : 0;\n    j1 = ranky >= 3 ? 1 : 0;\n    k1 = rankz >= 3 ? 1 : 0;\n    l1 = rankw >= 3 ? 1 : 0;\n    // Rank 2 denotes the second largest coordinate.\n    i2 = rankx >= 2 ? 1 : 0;\n    j2 = ranky >= 2 ? 1 : 0;\n    k2 = rankz >= 2 ? 1 : 0;\n    l2 = rankw >= 2 ? 1 : 0;\n    // Rank 1 denotes the second smallest coordinate.\n    i3 = rankx >= 1 ? 1 : 0;\n    j3 = ranky >= 1 ? 1 : 0;\n    k3 = rankz >= 1 ? 1 : 0;\n    l3 = rankw >= 1 ? 1 : 0;\n    // The fifth corner has all coordinate offsets = 1, so no need to compute that.\n    double x1 = x0 - i1 + G4; // Offsets for second corner in (x,y,z,w) coords\n    double y1 = y0 - j1 + G4;\n    double z1 = z0 - k1 + G4;\n    double w1 = w0 - l1 + G4;\n    double x2 = x0 - i2 + 2.0*G4; // Offsets for third corner in (x,y,z,w) coords\n    double y2 = y0 - j2 + 2.0*G4;\n    double z2 = z0 - k2 + 2.0*G4;\n    double w2 = w0 - l2 + 2.0*G4;\n    double x3 = x0 - i3 + 3.0*G4; // Offsets for fourth corner in (x,y,z,w) coords\n    double y3 = y0 - j3 + 3.0*G4;\n    double z3 = z0 - k3 + 3.0*G4;\n    double w3 = w0 - l3 + 3.0*G4;\n    double x4 = x0 - 1.0 + 4.0*G4; // Offsets for last corner in (x,y,z,w) coords\n    double y4 = y0 - 1.0 + 4.0*G4;\n    double z4 = z0 - 1.0 + 4.0*G4;\n    double w4 = w0 - 1.0 + 4.0*G4;\n    // Work out the hashed gradient indices of the five simplex corners\n    int ii = i & 255;\n    int jj = j & 255;\n    int kk = k & 255;\n    int ll = l & 255;\n    int gi0 = perm[ii+perm[jj+perm[kk+perm[ll]]]] % 32;\n    int gi1 = perm[ii+i1+perm[jj+j1+perm[kk+k1+perm[ll+l1]]]] % 32;\n    int gi2 = perm[ii+i2+perm[jj+j2+perm[kk+k2+perm[ll+l2]]]] % 32;\n    int gi3 = perm[ii+i3+perm[jj+j3+perm[kk+k3+perm[ll+l3]]]] % 32;\n    int gi4 = perm[ii+1+perm[jj+1+perm[kk+1+perm[ll+1]]]] % 32;\n    // Calculate the contribution from the five corners\n    double t0 = 0.6 - x0*x0 - y0*y0 - z0*z0 - w0*w0;\n    if(t0<0) n0 = 0.0;\n    else {\n      t0 *= t0;\n      n0 = t0 * t0 * dot(grad4[gi0], x0, y0, z0, w0);\n    }\n   double t1 = 0.6 - x1*x1 - y1*y1 - z1*z1 - w1*w1;\n    if(t1<0) n1 = 0.0;\n    else {\n      t1 *= t1;\n      n1 = t1 * t1 * dot(grad4[gi1], x1, y1, z1, w1);\n    }\n   double t2 = 0.6 - x2*x2 - y2*y2 - z2*z2 - w2*w2;\n    if(t2<0) n2 = 0.0;\n    else {\n      t2 *= t2;\n      n2 = t2 * t2 * dot(grad4[gi2], x2, y2, z2, w2);\n    }\n   double t3 = 0.6 - x3*x3 - y3*y3 - z3*z3 - w3*w3;\n    if(t3<0) n3 = 0.0;\n    else {\n      t3 *= t3;\n      n3 = t3 * t3 * dot(grad4[gi3], x3, y3, z3, w3);\n    }\n   double t4 = 0.6 - x4*x4 - y4*y4 - z4*z4 - w4*w4;\n    if(t4<0) n4 = 0.0;\n    else {\n      t4 *= t4;\n      n4 = t4 * t4 * dot(grad4[gi4], x4, y4, z4, w4);\n    }\n    // Sum up and scale the result to cover the range [-1,1]\n    return 27.0 * (n0 + n1 + n2 + n3 + n4);\n  }\n\n  // Inner class to speed upp gradient computations\n  // (In Java, array access is a lot slower than member access)\n  private static class Grad\n  {\n    double x, y, z, w;\n\n    Grad(double x, double y, double z)\n    {\n      this.x = x;\n      this.y = y;\n      this.z = z;\n    }\n\n    Grad(double x, double y, double z, double w)\n    {\n      this.x = x;\n      this.y = y;\n      this.z = z;\n      this.w = w;\n    }\n  }\n}\n```\n\nBoth code is rendered using the same octave, frequency and amplitude.\nJava Simplex Noise Render\n\nGLSL Simplex Noise Render\n\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Why does simplex noise seem to have *more* artifacts than classic Perlin noise?\r\n                \r\nI read Stefan Gustavson's excellent paper on simplex noise, in which I was promised that:\n\n\n  Simplex noise has no noticeable directional artifacts\n\n\nin contrast with \"classic\" Perlin noise. I excitedly implemented it to find out that the opposite appeared to be true. I do see artifacts in classic noise, but I see at least as many artifacts in simplex noise, aligned at 45 degrees to the main axes. They're especially noticeable when you map the noise to a step function.\n\nTo ensure it wasn't a problem with my implementation, I used someone else's JavaScript implementation. Compare some images:\n\n\nClassic noise vs simplex noise\nClassic noise step vs simplex noise step\n\n\nAnd here's a gallery with all of them. In that last image, look for borders that are aligned at 45 degrees from horizontal/vertical. They're all over the place. I can highlight some of them if need be, but they seem really obvious to me. (And again, I see them in the classic noise image as well.)\n\nEDIT: To be more quantitative, I sampled 1 million random points, and for each point I numerically computed the gradient of both classic and simplex noise, and took a histogram of the direction of the gradient projected onto the x-y plane. If there were no directional artifacts, the graph would be flat. But you can see that both classic and simplex noise spike every 45 degrees.\n\nIs this a problem with the simplex noise algorithm? Is it something that can be fixed? Or am I the only one who sees this as a problem?\n    ", "Answer": "\r\nI just read the paper, and I think I have an idea what might be causing the artifacts. The gradients for each vertex of the grid are pseudorandomly chosen from a rather small lookup table. As Gustavson states on page 3:\n\n\"A good choice for 2D and higher is to pick gradients of unit length but different directions. For 2D, 8 or 16 gradients distributed around the unit circle is a good choice.\"\n\nThis was the method used in classical Perlin noise, which is not what Perlin proposed for Simplex noise in his 2001 paper, page 14:\n\n\"Rather than using a table lookup scheme to compute the index of a pseudo-random gradient at each surrounding vertex, the new method uses a bit-manipulation scheme that uses only a very small number of hardware gates.\"\n\nHowever, Gustavson states on page 7:\n\n\"I will use a hybrid approach for clarity, using the gradient hash method from classic noise but the simplex grid and straight summation of noise contributions of simplex noise. That is actually a faster method in software.\"\n\nHis 2D implementation actually uses the 12 gradients from the 3D gradient table, discarding the z coordinate. In that scheme, the edge coordinates are used twice each, but the corners are used only once, which would seem to introduce a bias at 90-degree intervals. But that's not relevant in your case, because the implementation you're using only has 8 gradients, quite suggestive of a bias at 45-degree intervals. The likelihood of visible patterns emerging from such minimal variance seems pretty high. But it should be easy to adapt that algorithm for 16 gradients, using a mod 16 permutation table, which should help reduce the directional artifacts significantly.\n\nUltimately, though, I think there will always be some visible patterns in a single octave of any gradient noise function, simply because they're band-limited by design, as the narrow range of frequencies will tend to align perturbations to the grid. Being a triangular grid, Simplex noise will probably exhibit some bias at 60-degree intervals even if the gradients were truly random. Well, that's just conjecture, but the point is that these noise functions are really designed to be combined in different frequencies, which tends to break up any patterns you might see in a single octave.\n\nEDIT:\n\nAnother point I just realized, the corner gradients such as (1,1) are not of unit length, they are sqrt(2). The first quote makes it clear that the gradients should lie on the unit circle. This may be another source of bias. Interestingly, Gustavson uses these non-unit gradients too. \n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Simplex noise reference to array\r\n                \r\nEDIT: I have been adjusting the sliders on the Simplex noise constructor. I have used more softer floating point numbers and have seen reduced numbers of bars. Possible solution?\n\n```\n{ frequency: 0.001, amplitude: 0.010, persistence: 0.50, octaves: 10 }\n```\n\n\nI'm working with Simplex noise to generate better pseudo random noise. I'm trying to create a basic map generator and I was hoping to use the Simplex noise generated to relate to a predefined array of textures. I am using the algorithm as interpreted from joshforisha to select a Simplex number scaled to the length of the array.\n\nI've created a simplified version here. You might need to refresh the code a couple of times before you get it, but you should see repeating \"un-simplex\" style lines punctuating the Simplex noise. \n\nMy understanding of the situation is that the random number returned isn't being mapped the length of the array or it's skipping too many numbers, but I'm not sure.\n\nHere is how the noise selection is being obtained from the array. I have omitted references to other defined code to keep this example as brief as I can.\n\n```\nvar noiseGen = new FastSimplexNoise({\n    /** use simplex noise constructor **/\n    amplitude: 0.015,\n    frequency: 0.015,\n    octaves: 3,\n    max: text.length /** set reference to length of textures **/,\n    min: 0\n});\n\n/** iterate over canvas width **/\nfor (var i = 0; i < width; i++) {\n\n    /** iterate over canvas height **/\n    for (var j = 0; j < height; j++) {\n\n       /** create noise point **/\n       var n = noiseGen.in2D(i, j);\n\n       /** make noise a whole number for use as index look up **/   \n       var h = parseInt(n);\n\n       /** get texture from array **/\n       var t = text[h];\n\n       /** paint **/\n       ctx.fillStyle = t.hexidec;\n       ctx.fillRect(i * scale, j * scale, scale, scale);\n    }\n }\n```\n\n    ", "Answer": "\r\nAnswering my own question here. I believe that I had an issue with my noise algorithm. I have been tweaking how the squares are projected and distributed and it seems that this issue has been fixed. Thanks for anyone who set time aside to think about the issue.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Finding the point on a simplex closest to the origin using GJK's distance subalgorithm\r\n                \r\nI'm trying to implement the Gilbert–Johnson–Keerthi distance algorithm (GJK), but I'm having problems with the \"distance subalgorithm\", also known as \"Johnson's Algorithm\", which is used to determine the point on a simplex that is closest to the origin. I'm getting incorrect results but I can't find any bugs in my code, so the problem must be in my interpretation of the algorithm.\n\nIn Johnson’s Algorithm (as described in Gino van den Bergen's book Collision Detection in Interactive 3D Environments), the point on the affine hull of a simplex ```\nX = {yi : i ∈ Ix}```\n closest to the origin is given by:\n\n\n\nWhere the Δi^X values are determined recursively in order of increasing cardinality of X:\n\n\n\n... and Δ^X is given by:\n\n\n\nFor two dimensions, I find the closest point to the origin using:\n\n```\nPoint ClosestPointToOrigin(Simplex simplex)\n{\n    float dx = 0;\n    for (int i = 0; i < simplex.size(); ++i)\n        dx += dj(simplex, i);\n\n    Point closest_point(0,0);\n    for (int i = 0; i < simplex.size(); ++i)\n        closest_point += dj(simplex, i) / dx * simplex[i];\n\n    return closest_point;\n}\n```\n\n\nIn which the Δi values are determined by:\n\n```\nfloat dj(Simplex simplex, int j)\n{\n    if (j == 0)\n    {\n        return 1;\n    }\n    else\n    {\n        float d = 0;\n\n        for (int i = 0; i < j; ++i)\n            d += dj(simplex, i) * (simplex[0] - simplex[j]).dotProduct(simplex[i]);\n\n        return d;\n    }\n}\n```\n\n\nFor a simplex ```\nX = {y1, y2}```\n where ```\ny1 = (1,1)```\n, ```\ny2 = (1,-1)```\n, the above code returns ```\n(1.0, -0.333333)```\n, when the closest point is, in fact, ```\n(1, 0)```\n.\n\nI must be doing something wrong, but I can't figure out what that is.\n    ", "Answer": "\r\nYour error is the ```\ndj```\n function, maybe you have misunderstood the ```\ndxi```\n equation or you did not write what you want.\nI will try to explain myself, do not hesitate to comment if you do not understand something (I am writing pseudo python code but it should be easily understandable).\nAssume I have the following Simplex:\n```\nS  = Simplex({\n    1: Point (1, 1)  # y1\n    2: Point (1,-1)  # y2\n})\n```\n\nI can immediately compute 2 deltas values:\n\nThen, I can compute 2 others deltas values:\n\n\nHopefully by now you'll start to see your mistake: The Δ values are index based, so for each Simplex X of dimension n, you have n Δ values. One of your mistake was to assume that you can compute ΔX0 and ΔXi regardless of the content of X, which is false.\nNow the last Δ:\n\nNotice that:\n\nOnce you are here:\n\nHere is a code written in Python, if you do not understand it, I'll try to write one in a language you understand:\n```\nimport numpy\n\n\nclass Point(numpy.ndarray):\n    def __new__(cls, x, y):\n        return numpy.asarray([x, y]).astype(float).view(cls)\n\n    def __str__(self):\n        return repr(self)\n\n    def __repr__(self):\n        return \"Point ({}, {})\".format(self.x, self.y)\n\n    x = property(fget=lambda s: s[0])\n    y = property(fget=lambda s: s[1])\n\n\nclass Simplex(dict):\n    def __init__(self, points):\n        super(Simplex, self).__init__(enumerate(points))\n\n    def __str__(self):\n        return repr(self)\n\n    def __repr__(self):\n        return \"Simplex <\" + dict.__repr__(self) + \">\"\n\n\ndef closest_point(s):\n    dx = sum(dj(s, i) for i in range(len(s)))\n    return sum(dj(s, i) / dx * v for i, v in s.items())\n\n\ndef dj(s, j):\n    if len(s) == 0 or (len(s) == 1 and j not in s):\n        print(s, j)\n        raise ValueError()\n    if len(s) == 1:\n        return 1\n    ts = s.copy()\n    yj = s[j]\n    del ts[j]\n    return sum(\n        dj(ts, i) * (ts[list(ts.keys())[0]] - yj).dot(v) \n        for i, v in ts.items()\n    )\n\n\nS = Simplex([Point(1, 1), Point(1, -1)])\n\nprint(closest_point(S))\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How does scipy.optimize.fmin (Simplex) deal with parameters associated with different magnitudes?\r\n                \r\nI want to fit a 4-parameters (a,g,N and k) model to data by minimizing a chi-square loss function with a python implementation of the Simplex algorithm (scipy.optimize.fmin). \nPreliminary simulations suggest the following range for each parameter: a = [5, 50], g = [0.05, 1.5], N = [5, 200],and k = [0, 0.05].\n\nLooks like the scipy.optimize.fmin function treats the parameters as if they were all in the same range (presumably [0, 1]). Should I rescale them?  Below is my code:\n\n```\n#determine starting point (x0) for each parameter\na = np.random.uniform(5,50)\ng = np.random.uniform(0.05, 1.5)\nN = np.random.uniform(5, 200)\nk = np.random.uniform(0, 0.05)\nx0 = np.array ([a, g, N, k]) #initial guess for SIMPLEX\n\nxopt = fmin (chis, x0, maxiter=1000)#call Simplex \n```\n\n    ", "Answer": "\r\nImagine that you want to minimize the following bi-variate function\n\n```\ndef to_min1((x,y)):\n    return abs(1e-15 - x) + abs(1e15 - y)\n```\n\n\nEven if this example is not realistic, it highlights the main point. For sure, ```\nfmin```\n may not move in ```\nx```\n (if ```\nx0=0```\n), because it is already very close to zero.\n\nSo as to get objectives which have equal weights within the optimization program, one makes them in terms of variations rather than in terms of differentials (with arguments to numerators to avoid ```\nZeroDivisionError```\n):\n\n```\ndef to_min2((x,y)):\n    return abs(-1+x/1e-15) + abs(-1+y/1e15)\n```\n\n\nNote that this is an ```\nftol```\n concern, since, by doing so, one wants its iterative recomputation to be equally weighted over all arguments.\n\nWhat follows does not exactly answer to your question, but to the one:\nDoes scipy.optimize.fmin (Simplex) deal with parameters associated with different magnitudes? \n\nApparently no, since \n\n```\n>>> fmin(to_min1, (0,0))\nOptimization terminated successfully.\n         Current function value: 1000000000000000.000000\n         Iterations: 3\n         Function evaluations: 11\narray([ 0.,  0.])\n```\n\n\nwhile \n\n```\n>>> fmin(to_min2, (0,0))\nOptimization terminated successfully.\n         Current function value: 1.000000\n         Iterations: 118\n         Function evaluations: 213\narray([  1.00000000e-15,   8.98437500e-05])\n```\n\n\nFor sure the ```\nOptimization```\n did not ```\nterminate successfully.```\n, and it could be done by increasing ```\nfmin```\n's ```\nmaxiter```\n argument, etc... but the two cases are clearly not managed the same way.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to find the smallest N dimensional simplex from a set of points that contains a given point?\r\n                \r\nI've looked all over google and stack but haven't found an answer to this problem yet. I keep finding results relating to the simplex method or results for finding the smallest arbitrary simplex (i.e. the vertices are not constrained). Neither can I think of an analytical solution.\n\nGiven a set of N-dimensional points, M, and an arbitrary N-dimensional point, q, how do I find the smallest N-dimensional simplex, S, that contains q as an interior point if the vertices of S must be in M? I'm sure I could solve it with an optimization, but I'd like an analytical solution if possible. A deterministic algorithm would be ok, as well.\n\nI was originally using a K nearest neighbors approach, but then I realized it's possible that the N+1 nearest neighbors to q won't necessarily create a simplex that contains q.\n\nThanks in advance for any assistance provided.\n    ", "Answer": "\r\nI think you can do this is O(N^2) using an iterative process very similar to K-NN, but perhaps there is a more efficient way. This should return the minimum simplex in terms of the number of vertices. \n\nFor each coordinate i in q, we can iterate through all elements of M, comparing the  q_i and m_i. We will select the two points in M which give us the min positive difference and min negative difference. If we repeat this process for every coordinate, then we should have our min set S. \n\nAm I understanding the problem correctly?\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Simplex code in R\r\n                \r\nim trying to develop an algorithm that would take in a few x,y coordinates and then out put them in order of closest to furthest(from origin), I cant use the library for the simplex function, just need some help with the logic.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Replacing specific matrix element in numpy\r\n                \r\nI am trying to make a python code to complete the simplex algorithm for linear optimization (this is not for a class). I am using the numpy array. I want to replace the element in the (i,j) position with its reciprocal, how do I do this.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Linear Programming with Constraints\r\n                \r\nIs there any known algorithm to find a maximum when there is a constraint on the optimizing function. i.e. I am interested to find the maximum of \n\n\n  cTx \n\n\nunder the constraint \n\n\n  Ax <= b \n\n\nhowever I also request that \n\n\n  cTx <= α\n\n\nIt looks similar to the simplex algorithm but I have an additional constraint on the maximizing cost. \n    ", "Answer": "\r\nThe simplex algorithm can deal with any linear constraints and linear objective function. There is nothing special at all if some linear constraint constains the objective function. Any LP solver can do the trick! It might be handful though to add a new decision variable, equal to the objective function.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "C/C++ implementation of simplex method [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is seeking recommendations for books, tools, software libraries, and more. It does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     We don’t allow questions seeking recommendations for books, tools, software libraries, and more. You can edit the question so it can be answered with facts and citations.\r\n                \r\n                    \r\n                        Closed 7 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI am unable to find an implemenation of simplex method.I have a set of points and want to minimize theie distance so i only need the method simplex \nI have google before posting this question and could nt find anything that I could use\n    ", "Answer": "\r\n```\n/*\n  What: Simplex in C\n  AUTHOR: GPL(C) moshahmed/at/gmail.\n\n  What: Solves LP Problem with Simplex:\n    { maximize cx : Ax <= b, x >= 0 }.\n  Input: { m, n, Mat[m x n] }, where:\n    b = mat[1..m,0] .. column 0 is b >= 0, so x=0 is a basic feasible solution.\n    c = mat[0,1..n] .. row 0 is z to maximize, note c is negated in input.\n    A = mat[1..m,1..n] .. constraints.\n    x = [x1..xm] are the named variables in the problem.\n    Slack variables are in columns [m+1..m+n]\n\n  USAGE:\n    1. Problem can be specified before main function in source code:\n      c:\\> vim mosplex.c  \n      Tableau tab  = { m, n, {   // tableau size, row x columns.\n          {  0 , -c1, -c2,  },  // Max: z = c1 x1 + c2 x2,\n          { b1 , a11, a12,  },  //  b1 >= a11 x1 + a12 x2\n          { b2 , a21, a22,  },  //  b2 >= a21 x1 + a22 x2\n        }\n      };\n      c:\\> cl /W4 mosplex.c  ... compile this file.\n      c:\\> mosplex.exe problem.txt > solution.txt\n\n    2. OR Read the problem data from a file:\n      $ cat problem.txt\n            m n\n            0  -c1 -c2\n            b1 a11 a12\n            b2 a21 a11 \n      $ gcc -Wall -g mosplex.c  -o mosplex\n      $ mosplex problem.txt > solution.txt\n*/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <string.h>\n#include <assert.h>\n\n#define M 20\n#define N 20\n\nstatic const double epsilon   = 1.0e-8;\nint equal(double a, double b) { return fabs(a-b) < epsilon; }\n\ntypedef struct {\n  int m, n; // m=rows, n=columns, mat[m x n]\n  double mat[M][N];\n} Tableau;\n\nvoid nl(int k){ int j; for(j=0;j<k;j++) putchar('-'); putchar('\\n'); }\n\nvoid print_tableau(Tableau *tab, const char* mes) {\n  static int counter=0;\n  int i, j;\n  printf(\"\\n%d. Tableau %s:\\n\", ++counter, mes);\n  nl(70);\n\n  printf(\"%-6s%5s\", \"col:\", \"b[i]\");\n  for(j=1;j<tab->n; j++) { printf(\"    x%d,\", j); } printf(\"\\n\");\n\n  for(i=0;i<tab->m; i++) {\n    if (i==0) printf(\"max:\"); else\n    printf(\"b%d: \", i);\n    for(j=0;j<tab->n; j++) {\n      if (equal((int)tab->mat[i][j], tab->mat[i][j]))\n        printf(\" %6d\", (int)tab->mat[i][j]);\n      else\n        printf(\" %6.2lf\", tab->mat[i][j]);\n      }\n    printf(\"\\n\");\n  }\n  nl(70);\n}\n\n/* Example input file for read_tableau:\n     4 5\n      0   -0.5  -3 -1  -4 \n     40    1     1  1   1 \n     10   -2    -1  1   1 \n     10    0     1  0  -1  \n*/\nvoid read_tableau(Tableau *tab, const char * filename) {\n  int err, i, j;\n  FILE * fp;\n\n  fp  = fopen(filename, \"r\" );\n  if( !fp ) {\n    printf(\"Cannot read %s\\n\", filename); exit(1);\n  }\n  memset(tab, 0, sizeof(*tab));\n  err = fscanf(fp, \"%d %d\", &tab->m, &tab->n);\n  if (err == 0 || err == EOF) {\n    printf(\"Cannot read m or n\\n\"); exit(1);\n  }\n  for(i=0;i<tab->m; i++) {\n    for(j=0;j<tab->n; j++) {\n      err = fscanf(fp, \"%lf\", &tab->mat[i][j]);\n      if (err == 0 || err == EOF) {\n        printf(\"Cannot read A[%d][%d]\\n\", i, j); exit(1);\n      }\n    }\n  }\n  printf(\"Read tableau [%d rows x %d columns] from file '%s'.\\n\",\n    tab->m, tab->n, filename);\n  fclose(fp);\n}\n\nvoid pivot_on(Tableau *tab, int row, int col) {\n  int i, j;\n  double pivot;\n\n  pivot = tab->mat[row][col];\n  assert(pivot>0);\n  for(j=0;j<tab->n;j++)\n    tab->mat[row][j] /= pivot;\n  assert( equal(tab->mat[row][col], 1. ));\n\n  for(i=0; i<tab->m; i++) { // foreach remaining row i do\n    double multiplier = tab->mat[i][col];\n    if(i==row) continue;\n    for(j=0; j<tab->n; j++) { // r[i] = r[i] - z * r[row];\n      tab->mat[i][j] -= multiplier * tab->mat[row][j];\n    }\n  }\n}\n\n// Find pivot_col = most negative column in mat[0][1..n]\nint find_pivot_column(Tableau *tab) {\n  int j, pivot_col = 1;\n  double lowest = tab->mat[0][pivot_col];\n  for(j=1; j<tab->n; j++) {\n    if (tab->mat[0][j] < lowest) {\n      lowest = tab->mat[0][j];\n      pivot_col = j;\n    }\n  }\n  printf(\"Most negative column in row[0] is col %d = %g.\\n\", pivot_col, lowest);\n  if( lowest >= 0 ) {\n    return -1; // All positive columns in row[0], this is optimal.\n  }\n  return pivot_col;\n}\n\n// Find the pivot_row, with smallest positive ratio = col[0] / col[pivot]\nint find_pivot_row(Tableau *tab, int pivot_col) {\n  int i, pivot_row = 0;\n  double min_ratio = -1;\n  printf(\"Ratios A[row_i,0]/A[row_i,%d] = [\",pivot_col);\n  for(i=1;i<tab->m;i++){\n    double ratio = tab->mat[i][0] / tab->mat[i][pivot_col];\n    printf(\"%3.2lf, \", ratio);\n    if ( (ratio > 0  && ratio < min_ratio ) || min_ratio < 0 ) {\n      min_ratio = ratio;\n      pivot_row = i;\n    }\n  }\n  printf(\"].\\n\");\n  if (min_ratio == -1)\n    return -1; // Unbounded.\n  printf(\"Found pivot A[%d,%d], min positive ratio=%g in row=%d.\\n\",\n      pivot_row, pivot_col, min_ratio, pivot_row);\n  return pivot_row;\n}\n\nvoid add_slack_variables(Tableau *tab) {\n  int i, j;\n  for(i=1; i<tab->m; i++) {\n    for(j=1; j<tab->m; j++)\n      tab->mat[i][j + tab->n -1] = (i==j);\n  }\n  tab->n += tab->m -1;\n}\n\nvoid check_b_positive(Tableau *tab) {\n  int i;\n  for(i=1; i<tab->m; i++)\n    assert(tab->mat[i][0] >= 0);\n}\n\n// Given a column of identity matrix, find the row containing 1.\n// return -1, if the column as not from an identity matrix.\nint find_basis_variable(Tableau *tab, int col) {\n  int i, xi=-1;\n  for(i=1; i < tab->m; i++) {\n    if (equal( tab->mat[i][col],1) ) {\n      if (xi == -1)\n        xi=i;   // found first '1', save this row number.\n      else\n        return -1; // found second '1', not an identity matrix.\n\n    } else if (!equal( tab->mat[i][col],0) ) {\n      return -1; // not an identity matrix column.\n    }\n  }\n  return xi;\n}\n\nvoid print_optimal_vector(Tableau *tab, char *message) {\n  int j, xi;\n  printf(\"%s at \", message);\n  for(j=1;j<tab->n;j++) { // for each column.\n    xi = find_basis_variable(tab, j);\n    if (xi != -1)\n      printf(\"x%d=%3.2lf, \", j, tab->mat[xi][0] );\n    else\n      printf(\"x%d=0, \", j);\n  }\n  printf(\"\\n\");\n} \n\nvoid simplex(Tableau *tab) {\n  int loop=0;\n  add_slack_variables(tab);\n  check_b_positive(tab);\n  print_tableau(tab,\"Padded with slack variables\");\n  while( ++loop ) {\n    int pivot_col, pivot_row;\n\n    pivot_col = find_pivot_column(tab);\n    if( pivot_col < 0 ) {\n      printf(\"Found optimal value=A[0,0]=%3.2lf (no negatives in row 0).\\n\",\n        tab->mat[0][0]);\n      print_optimal_vector(tab, \"Optimal vector\");\n      break;\n    }\n    printf(\"Entering variable x%d to be made basic, so pivot_col=%d.\\n\",\n      pivot_col, pivot_col);\n\n    pivot_row = find_pivot_row(tab, pivot_col);\n    if (pivot_row < 0) {\n      printf(\"unbounded (no pivot_row).\\n\");\n      break;\n    }\n    printf(\"Leaving variable x%d, so pivot_row=%d\\n\", pivot_row, pivot_row);\n\n    pivot_on(tab, pivot_row, pivot_col);\n    print_tableau(tab,\"After pivoting\");\n    print_optimal_vector(tab, \"Basic feasible solution\");\n\n    if(loop > 20) {\n      printf(\"Too many iterations > %d.\\n\", loop);\n      break;\n    }\n  }\n}\n\nTableau tab  = { 4, 5, {                     // Size of tableau [4 rows x 5 columns ]\n    {  0.0 , -0.5 , -3.0 ,-1.0 , -4.0,   },  // Max: z = 0.5*x + 3*y + z + 4*w,\n    { 40.0 ,  1.0 ,  1.0 , 1.0 ,  1.0,   },  //    x + y + z + w <= 40 .. b1\n    { 10.0 , -2.0 , -1.0 , 1.0 ,  1.0,   },  //  -2x - y + z + w <= 10 .. b2\n    { 10.0 ,  0.0 ,  1.0 , 0.0 , -1.0,   },  //        y     - w <= 10 .. b3\n  }\n};\n\nint main(int argc, char *argv[]){\n  if (argc > 1) { // usage: cmd datafile\n    read_tableau(&tab, argv[1]);\n  }\n  print_tableau(&tab,\"Initial\");\n  simplex(&tab);\n  return 0;\n} \n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How do I check if a simplex contains the origin?\r\n                \r\nI am implementing the Gilbert-Johnson-Keerthi algorithm which computes whether two objects are intersecting (ie. colliding).\n\nThe entry point to my code is the ```\nhasCollided```\n function which takes two lists of points and returns ```\nTrue```\n if they are intersecting. I believe I have implemented the paper correctly - however, I still have to implement the ```\ncontains```\n function.\n\nThe ```\ncontains```\n function should determine whether a simplex contains the origin. I am unsure as to how to implement this. \n\nHow do I efficiently determine if a simplex (collection of points) contains the origin?\n\n\n\nThe following is my implementation:\n\n```\ntype Simplex = Set (Vector Double)\n\nhasCollided :: [Vector Double] -> [Vector Double] -> Bool\nhasCollided points1 points2 = gjk points1 points2 simplex (scale (-1) direction) p\n  where simplex   = insert p empty\n        p         = support points1 points2 direction\n        direction = fromList [1, 0, 0]\n\ngjk :: [Vector Double] -> [Vector Double] -> Simplex -> Vector Double -> Vector Double -> Bool\ngjk points1 points2 simplex direction lastAdded =\n  if p <.> direction < 0 then False\n  else\n    if contains simplex' (fromList [0, 0, 0]) direction p then True\n    else gjk points1 points2 simplex' direction' p\n  where p          = support points1 points2 direction\n        simplex'   = insert p simplex\n        direction' = cross ab $ cross ao ab\n        ab         = sub p lastAdded\n        ao         = sub origin3D lastAdded\n```\n\n\nThe helper functions are:\n\n```\ncontains :: Simplex -> Vector Double -> Vector Double -> Vector Double -> Bool\ncontains simplex point direction lastAdded = undefined\n\n\nsupport :: [Vector Double] -> [Vector Double] -> Vector Double -> Vector Double\nsupport points1 points2 direction = sub p1 p2\n  where p1 = getFarthestPoint points1 direction\n        p2 = getFarthestPoint points2 direction\n\ngetFarthestPoint :: [Vector Double] -> Vector Double -> Vector Double\ngetFarthestPoint points direction = points !! index\n  where index       = fromJust $ elemIndex (maximum dotproducts) dotproducts\n        dotproducts = map (direction <.>) points\n\norigin3D :: Vector Double\norigin3D = fromList [0, 0, 0]\n```\n\n    ", "Answer": "\r\nI'll take the non-clever, \"let's do some linear algebra to solve it\" approach.\n\nEvery point within a simplex is a convex combination of the points which define the simplex.  A convex combination is just a linear combination where the coefficients are all >= 0 and add up to 1.\n\n\"Does a simplex contain the origin\" is identical to asking if there is a convex combination of the simplex points that is equal to the zero vector.  Can we write this as a matrix expression?\n\nLet's say we're working with a simplex defined by four vectors, ```\nx1```\n through ```\nx4```\n.\n\nWe're going to form an arbitrary linear combination of those vectors, ```\ny = a1*x1 + a2*x2 + a3*x3 + a4*x4```\n.\n\nWe want to find ```\na1```\n through ```\na4```\n such that ```\ny```\n is the zero vector and ```\na1 + a2 + a3 + a4 = 1```\n.\n\nI'll show what the linear system would look like if the simplex is of points in a three-dimensional Euclidean space; let the vector ```\nxi```\n have components ```\nxi1```\n, ```\nxi2```\n, and ```\nxi3```\n.  \n\n```\n[ x11  x21  x31  x41 ] [ a1 ]   [ 0 ]\n[ x12  x22  x32  x42 ] [ a2 ] = [ 0 ]\n[ x13  x23  x33  x43 ] [ a3 ]   [ 0 ]\n[  1    1    1    1  ] [ a4 ]   [ 1 ]\n```\n\n\nThe first three rows of this linear system correspond to the constraint that ```\ny```\n must be zero, i.e., that we can get to the origin through some linear combination of ```\nx1```\n through ```\nx4```\n.  The last row corresponds to the constraint that the coefficients add up to 1 which is necessary but not sufficient for the linear combination to be a convex combination.  The constraint not expressed by the matrix equation is that ```\nai >= 0```\n.\n\nPick your favorite method for solving a linear system and apply it.  If the vectors making up your simplex are linearly independent, you won't find any solutions.  If the linear system has a solution or solutions and at least one solution has all the ```\nai >= 0```\n, then the simplex contains the origin.\n\nI don't have any ready description for an algorithm for that last step, determining if the solution set includes any points where all the coefficients are positive.  I suggest working a few examples out on paper- I expect you can find one.\n\nEDIT: determining if the solution set includes any points where all coefficients are positive is actually the same as determining whether the simplex defined by the intersection of the solution space with ```\nai >= 0```\n includes any points other than the origin.\n\nThat means this method of solution reduces the problem of\n\n\"Does the input simplex contain the origin?\"\n\nto\n\n\"Does another simplex (derived from the input simplex) contain any points other than the origin?\"\n\nI think it's a cute example of reducing a problem to another (hopefully easier) problem.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Program received Segmentation fault while debug in CLion\r\n                \r\nI have the challenge to implement simplex-method (or simplex algorithm). Simplex-method is a popular algorithm for linear programming which is based on rebuilding matrices. My program should return an optimal solution. I have a C++ project in Clion. It works correctly when I run the program, but during the debug I get a SIGSEGV Signal (Segmentation Fault) in one of the methods. It happens when I try to allocate memory for the matrix. Here is the part of code:   \n\n```\ndouble **newTable;\n    newTable = new double *[rows];\n    for (int i = 0; i < rows; ++i) {\n        for (int j = 0; j < cols; ++j) {\n            newTable[i] = new double [cols];\n        }\n    }\n```\n\n\nI free the memory at the end of the method using delete[], but it doesn’t work. \nI’ve already tried to run the program in another IDE (CodeBlocks), but it works properly too, and I have no idea why it happens and where the problem occurs. \n    ", "Answer": "\r\nNo need for this nested loop. You only need one loop to allocate memory for this jagged array:\n\n```\nint main() {\n    int rows = 5, cols = 10;\n    double **newTable;\n    newTable = new double *[rows];\n    for (int i = 0; i < rows; ++i) \n        newTable[i] = new double[cols];\n\n    for (int i = 0; i < rows; ++i)\n        delete newTable[i];\n    delete newTable;\n}\n```\n\n\nThe way your code is now it will leak memory, but that alone won't cause a segmentation fault. There might be a mistake with how you're freeing the memory, too.\n\n\n\nAlso, since this is C++, may I recommend using ```\nstd::vector```\n instead?\n\n```\n#include <vector>\nint main() {\n    std::vector<std::vector<double>> newTable(5, std::vector<double>(10));\n}\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "cannot import minimize in scipy\r\n                \r\nI am working with scipy trying to test out the Nelder-Mead simplex algorithm. I am exactly following the example code shown here: http://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html\n\nThis line causes an error:\n\n\n  from scipy.optimize import minimize\n\n\nIt says it cannot import name minimize. Am I importing something wrong? \n    ", "Answer": "\r\nYou need Scipy version 0.11.0, the first beta was released some time ago.\n\nIf you don't have it, you should read the tutorial for the version of scipy you have, for example:\nhttp://docs.scipy.org/doc/scipy-0.10.1/reference/tutorial/optimize.html\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Downhill Simplex on finite intervals\r\n                \r\nI've been reading up on Downhill Simplex (Nelder-Mead) optimization, but what I was missing were good proposals on what to do when the parameters / coordinates are bound to a fixed interval. What is the best way to handle the case that one parameter goes to the limit of the intervals, especially avoiding that it gets \"stuck\" there?\nLet's say I optimize a function of 10-20 parameters which are each limited to a finite interval, say, [0 ; 100]. What is the right course of action if the algorithm would push one or several of the parameters over the limits (<0 or >100)?\nThanks,\nMartin\nReading through multiple descriptions and publications on numerical optimization using downhill simplex\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Largest simplex in convex hull of points in n dimensions\r\n                \r\nGiven a convex hull C of a set of points in n dimensions, is there a known algorithm (apart from checking all possibilities) that finds the n+1 corner points of a simplex with the largest volume that is completely in C?\n\n(See this question for the same question about polygons/triangles.)\n    ", "Answer": "\r\nDoubtful, since the problem has a fixed parameter intractability result:\nhttps://doi.org/10.1016/j.ipl.2006.05.006\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Does choosing initial starting point for simplex construction influences the result of Nelder-Mead algorithm?\r\n                \r\nI was wondering how the choice of the initial vertex x0, and the step that is used to compute the others vertices, influence the final result given by the Nelder-Mead algorithm.\nIs this susceptible to produce a local optimum around the x0?\n    ", "Answer": "\r\nYes, the choice of starting point x0 influences the outcome of minimization (and this is not unique to Nelder-Mead method). Getting stuck in a local minimum is a very real possibility.\n\nIt's important to recognize that the method operates with a simplex (n+1 points in case of n variables). If the simplex is small compared to the size of landscape features, the trajectory will be gradient-like, approaching a nearest local minimum. If it's large, there will be a more global investigation of the function's landscape. \n\nFor example, SciPy implementation of this algorithm chooses the initial simplex as follows: the k-th vertex is x0 with its k-th coordinate increased by 5% (unless the coordinate is 0, in which case it's arbitrarily set to 0.00025). If you have a better idea of what region of parameters should be explored, try choosing ```\ninitial_simplex```\n yourself, so that its size is comparable to the size of the range being searched.  \n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Fix directional artifacts generated by Perlin noise with another algorithm\r\n                \r\nI saw recently that Simplex noise(3D and higher dimensions) is patented... A substitute for simplex noise exists to avoid(only a lawyer can tell) the patented parts, namely Opensimplex. But I am not a lawyer so I don't want to risk anything...\n\nBack to square one with the older noise algorithm, namely Perlin noise and it's directional artifacts.\n\nCan anyone think of an algorithm that eliminates or at least reduces the generated directional artifacts from Perlin noise in 3D?, i.e. I need an algorithm that corrects the final generated result from Perlin noise.\nIt doesn't matter if this algorithm is slow, because everything is only generated at startup!:)\n    ", "Answer": "\r\nSince multi-octave Perlin noise is generated by adding octaves of noise together, directional artifacts can be reduced by rotating each octave by a different (random) amount.\n\nYou can also add multiple noise planes (each rotated separately) together at each octave, but this will change the appearance of the noise.\n\nHere's an article by Ken Perlin about improving the appearance of Perlin noise.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Simple Simplex method\r\n                \r\nI wrote a program which is solving the Simplex Method but it works only on equations where the number of constraints is equal or less then the number of variables in the target function. If there is any other equation there is an OutOfBoundsException and I don't know how to solve this problem. If someone knows please tell me or share the link to the working algorithm.\n```\nprivate static int ROW;\n\nprivate static int COL;\n\nprivate static Scanner scanner = new Scanner(System.in);\n\nprivate static double[] calctemp(double[] temp, double[][] constLeft,\n        double[] targetFunc, int[] basic) {\n    double[] calcTemp = new double[temp.length];\n    for (int i = 0; i < COL; i++) {\n        calcTemp[i] = 0;\n        for (int j = 0; j < ROW; j++) {\n            calcTemp[i] += targetFunc[basic[j]] * constLeft[j][i];\n        }\n        calcTemp[i] -= targetFunc[i];\n    }\n    return calcTemp;\n}\n\nprivate static int minimum(double[] arr) {\n    double arrmin = arr[0];\n    int minPos = 0;\n    for (int i = 0; i < arr.length; i++) {\n        if (arr[i] < arrmin) {\n            arrmin = arr[i];\n            minPos = i;\n        }\n    }\n    return minPos;\n}\n\nprivate static void printFrame(double[] targetFunc) {\n    StringBuilder sb = new StringBuilder();\n    sb.append(\"Cj\\t\\t\\t\");\n    for (int i = 0; i < targetFunc.length; i++) {\n        sb.append(targetFunc[i] + \"\\t\");\n    }\n    sb.append(\"\\ncB\\txB\\tb\\t\");\n    for (int i = 0; i < targetFunc.length; i++) {\n        sb.append(\"a\" + (i + 1) + \"\\t\");\n    }\n    System.out.print(sb);\n}\n\nprivate static void printAll(double[] targetFunc, double[] constraintRight,\n        double[][] constraintLeft, int[] basic) {\n    printFrame(targetFunc);\n    StringBuilder sb = new StringBuilder();\n    for (int i = 0; i < ROW; i++) {\n        sb.append(\"\\n\" + targetFunc[basic[i]] + \"\\tx\" + (basic[i] + 1)\n                + \"\\t\" + constraintRight[i] + \"\\t\");\n        for (int j = 0; j < COL; j++) {\n            sb.append(constraintLeft[i][j] + \"\\t\");\n        }\n        sb.append(\"\\n\");\n    }\n    System.out.println(sb);\n}\n\npublic static void main(String[] args) {\n    double[] targetFunc = { 6, -5, 0, 0};\n    ROW = 2;\n    COL = 2 + ROW;\n    double[][] constraintsLeft = { { 2, 5, 1, 0 },\n            { 5, 2, 0, 1 }};\n    double[] constraintsRight = { 10, 10 };\n\n    double[] temp = new double[COL];\n\n    int tempMinPos;\n    double[] miniRatio = new double[ROW];\n    int miniRatioMinPos = 0;\n    double key;\n    int goOutCol = 0;\n    double z;\n    double[] x = new double[COL];\n    int[] basic = new int[ROW];\n    int[] nonBasic = new int[ROW];\n    boolean flag = false;\n\n    for (int i = 0; i < ROW; i++) {\n        basic[i] = (i + ROW);\n        nonBasic[i] = i;\n    }\n    System.out.println(\"------------Calculating------------\");\n    while (!flag) {\n        z = 0;\n        temp = calctemp(temp, constraintsLeft, targetFunc, basic);\n\n        tempMinPos = minimum(temp);\n        printAll(targetFunc, constraintsRight, constraintsLeft, basic);\n        System.out.print(\"Zj-Cj\\t\\t\\t\");\n        for (int i = 0; i < COL; i++) {\n            System.out.print(temp[i] + \"\\t\");\n        }\n        System.out\n                .println(\"\\n--------------------------------------------------\");\n        System.out.println(\"Basic variables : \");\n        for (int i = 0; i < ROW; i++) {\n            x[basic[i]] = constraintsRight[i];\n            x[nonBasic[i]] = 0;\n            System.out.println(\"x\" + (basic[i] + 1) + \" = \"\n                    + constraintsRight[i]);\n        }\n        for (int i = 0; i < ROW; i++) {\n            z = z + targetFunc[i] * x[i];\n        }\n        System.out.println(\"Max(z) = \" + z);\n\n        for (int i = 0; i < ROW; i++) {\n            if (constraintsLeft[i][tempMinPos] <= 0) {\n                miniRatio[i] = 999;\n                continue;\n            }\n            miniRatio[i] = constraintsRight[i]\n                    / constraintsLeft[i][tempMinPos];\n        }\n        miniRatioMinPos = minimum(miniRatio);\n\n        for (int i = 0; i < ROW; i++) {\n            if (miniRatioMinPos == i) {\n                goOutCol = basic[i];\n            }\n        }\n        System.out.println(\"Outgoing variable : x\" + (goOutCol + 1));\n        System.out.println(\"Incoming variable : x\" + (tempMinPos + 1));\n\n        basic[miniRatioMinPos] = tempMinPos;\n        nonBasic[tempMinPos] = goOutCol;\n\n        key = constraintsLeft[miniRatioMinPos][tempMinPos];\n        constraintsRight[miniRatioMinPos] /= key;\n        for (int i = 0; i < COL; i++) {\n            constraintsLeft[miniRatioMinPos][i] /= key;\n        }\n        for (int i = 0; i < ROW; i++) {\n            if (miniRatioMinPos == i) {\n                continue;\n            }\n            key = constraintsLeft[i][tempMinPos];\n            for (int j = 0; j < COL; j++) {\n                constraintsLeft[i][j] -= constraintsLeft[miniRatioMinPos][j]\n                        * key;\n            }\n            constraintsRight[i] -= constraintsRight[miniRatioMinPos] * key;\n        }\n\n        for (int i = 0; i < COL; i++) {\n            flag = true;\n            if (temp[i] < 0) {\n                flag = false;\n                break;\n            }\n        }\n    }\n}    \n```\n\nI entered some equation to solve. It's is solved right.\nTry to change on this\n```\n    double[] targetFunc = { 8, 2, 0, 0, 0};\n    \n    ROW = 3;\n    COL = 2 + ROW;\n    double[][] constraintsLeft = { { 1, -4, 1, 0, 0 },\n            { -4, 1, 0, 1, 0 },\n            { 1, 1, 0, 0, 1}};\n    double[] constraintsRight = { 4, 4, 6 };\n```\n\n    ", "Answer": "\r\nHere is my scala version. I tried it on degenerated case and I think it supports the \"Brand Rule\".\n\n```\nobject Simplex {\n\n    sealed trait Pivot {};\n    case class Next(row: Int, col: Int) extends Pivot;\n    object NoSolution extends Pivot;\n    object NoMore extends Pivot;\n\n\n    def minSuch[T,U](array: Array[T])(fn: (T,Int)=>Option[U])(implicit order: scala.math.Ordering[U]): Option[(Int, T, U)] = {\n        @scala.annotation.tailrec\n        def compute(idx: Int, res: Option[(Int, T, U)]): Option[(Int, T, U)] = if(idx>=array.length) res else (res, fn(array(idx), idx)) match {\n            case (r , None) => compute(idx+1,r)\n            case (r @ Some((_, _, u1)), Some(u2)) if order.lt(u1, u2) => compute(idx+1, r)\n            case (_ , Some(u)) => compute(idx+1, Some((idx, array(idx), u)))\n        }\n        return compute(0, Option.empty[(Int, T, U)])\n    }\n\n    def solve[T](A: Array[Array[T]], Y: Array[T], C: Array[T])(implicit frac:scala.math.Fractional[T], classtag: scala.reflect.ClassTag[T]) : Option[(T,Array[T])] = {\n        import scala.math.Fractional.Implicits._\n        import scala.math.Ordering.Implicits._\n\n        val N = (0 to  (C.length-1) by +1).toArray\n        val B = (1 to -(Y.length  ) by -1).toArray\n        val Z = C.map(-_)\n        var z = frac.zero\n\n        def pivot(): Pivot = minSuch(Z) { case (z,_) => \n            if( z<frac.zero ) Some(z) else None\n        }.map { case (col, _, _) => \n            minSuch(A) { case(cells,row) =>\n                if( cells(col)>frac.zero ) Some(Y(row)/cells(col)) else None\n            }.map { case (row, _, _) =>\n                new Next(row, col)\n            }.getOrElse(NoSolution)\n        }.getOrElse(NoMore)\n\n        @scala.annotation.tailrec\n        def resolve(): Option[(T, Array[T])] = pivot() match {\n            case NoSolution => None\n            case NoMore => {\n                Some((z, Y.zip(B).foldLeft(Array.fill(C.length)(frac.zero))( (result, yb)=> \n                    if( yb._2 >= 0 ) result.updated(yb._2, yb._1) else result\n                )))\n            }\n            case Next(row, col) => {\n                val coef = A(row)(col)\n                val tmp = B(row)\n                B(row) = N(col)\n                N(col) = tmp\n\n                Z(col) = -Z(col) / coef\n                z = z + Z(col) * Y(row)\n                for(c <- 0 to Z.length-1 if(c!=col)) Z(c) = Z(c) + A(row)(c) * Z(col)\n\n                Y(row) =  Y(row) / coef\n                for(r <- 0 to Y.length-1 if(r!=row)) Y(r) = Y(r) - A(r)(col) * Y(row)\n\n                A(row)(col) = frac.one / coef\n                for(c <- 0 to A(row).length-1 if(col!=c) ) A(row)(c)=A(row)(c)/coef\n                for(r <- 0 to A.length-1 if(row!=r); c <- 0 to A(r).length-1 if(col!=c)) A(r)(c)=A(r)(c) - A(r)(col) * A(row)(c)\n                for(r <- 0 to A.length-1 if(row!=r)) A(r)(col) = -A(r)(col) / coef\n\n                return resolve()\n            }\n        }\n\n        return resolve();\n    }\n\n}\n```\n\n\nThis use case works. I've tried with a cyclic one and it works too...\n\n```\n    Simplex.solve(\n        Array(\n            Array(Rational(1), Rational(1)),\n            Array(Rational(1), Rational(-2)),\n            Array(Rational(-1), Rational(4))\n        ),\n        Array(\n            Rational(2),\n            Rational(0),\n            Rational(1)\n        ),\n        Array(Rational(5), Rational(8))\n    ).foreach { result=>\n        println(result._1)\n        result._2.foreach(println)\n    }\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Algorithm for Cutting Patterns\r\n                \r\nLet's say I have a given length ```\nc```\n and I need to cut out several pieces of different lengths ```\na{i}```\n, where ```\ni```\n is the index of a specific piece. The length of every piece is smaller or equal to the length ```\nc```\n. I need to find all possible permutations of cutting patterns.\n\nDoes someone has a smart approach for such tasks or an algorithm to solve this?\n\nThe function could look something similar to this:\n\n```\nPattern[] getPatternList(double.. a, double c);\n```\n\n\nThe input is hence a list of different sizes and the total available space. My goal is to optimize/minimize the trim loss. \nI'll use the simplex algorithm for that but to create an linear programming model, I need a smart way to determine all the cutting patterns.\n    ", "Answer": "\r\n\nThere are exponentially many cutting-patterns in general. So it might not be feasible to construct them all (time and memory)\nIf you need to optimize some cutting based on some objective, enumerating all possible cuttings is a bad approach (like @harold mentioned)\n\n\nA bad analogy (which does not exactly apply here as your base-problem is np-hard):\nsolving 2-SAT is possible in polynomial-time\nenumerating all 2-SAT solutions is Sharp-P-complete (an efficient algorithm would imply P=NP, so there might be none!)\n\nA simple approach (to generate all valid cutting-patterns):\n\n\nGenerate all permutations if items = ordering of items (bounded by !n)\nPlace them one after another and stop if c is exceeded\n(It would be a good idea to do this incrementally; build one permutation after another)\nAssumption: each item can only be selected once\nAssumption: moving/shifting a cut within a free range does not generate a new solution. It it would: solution-space is possibly an uncountably infinite set\n\n\n\nedit\n\nCode\n\nHere is a more powerful approach handling the problem with the same assumptions as described above. It uses integer-programming to minimize the trim-loss, implemented in python with the use of cvxpy (and a commercial-solver; can be replaced by an open-source solver like cbc):\n\n```\nimport numpy as np\nfrom cvxpy import *\nnp.random.seed(1)\n\n# random problem\nSPACE = 25000\nN_ITEMS = 10000\nitems = np.random.randint(0, 10, size=N_ITEMS)\n\ndef minimize_loss(items, space):\n    N = items.shape[0]\n    X = Bool(N)\n    constraint = [sum_entries(mul_elemwise(items, X)) <= space]\n    objective = Minimize(space - sum_entries(mul_elemwise(items, X)))\n    problem = Problem(objective, constraint)\n    problem.solve(solver=GUROBI, verbose=True)\n\n    print('trim-loss: ', problem.value)\n    print('validated trim-loss: ', space - sum(np.dot(X.value.flatten(), items)))\n    print('# selected items: ', np.count_nonzero(np.round(X.value)))\n\nprint('items: ', items)\nprint('space: ', SPACE)\nminimize_loss(items, SPACE)\n```\n\n\nOutput\n\n```\nitems:  [5 8 9 ..., 5 3 5]\nspace:  25000\nParameter OutputFlag unchanged\n   Value: 1  Min: 0  Max: 1  Default: 1\nChanged value of parameter QCPDual to 1\n   Prev: 0  Min: 0  Max: 1  Default: 0\nOptimize a model with 1 rows, 10000 columns and 8987 nonzeros\nCoefficient statistics:\n  Matrix range    [1e+00, 9e+00]\n  Objective range [1e+00, 9e+00]\n  Bounds range    [1e+00, 1e+00]\n  RHS range       [2e+04, 2e+04]\nFound heuristic solution: objective -25000\nPresolve removed 1 rows and 10000 columns\nPresolve time: 0.01s\nPresolve: All rows and columns removed\n\nExplored 0 nodes (0 simplex iterations) in 0.01 seconds\nThread count was 1 (of 4 available processors)\n\nOptimal solution found (tolerance 1.00e-04)\nBest objective -2.500000000000e+04, best bound -2.500000000000e+04, gap 0.0%\ntrim-loss:  0.0\nvalidated trim-loss:  [[ 0.]]\n# selected items:  6516\n```\n\n\nedit v2\nAfter read your new comments, it is clear, that your model-description was incomplete/imprecise and nothing above tackles the problem you want to solve. It's a bit sad.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "SciPy Optimization algorithm\r\n                \r\nI need to solve an optimization task with Python.\nThe task is following:\n\n\n  Fabric produces  desks, chairs, bureau and cupboards. For producing this stuff two types of boards could be used. Fabric has 1500m. of first type and 1000m. of second. Fabric has 800 Employees. What should produce fabric and how much to receive a maximum profit?\n\n\nThe input values are following:\n\n```\n|              |           Products               |\n|              | Desk | Chair | Bureau | Cupboard |\n|--------------|------|-------|--------|----------|\n| Board 1 type | 5    | 1     | 9      | 12       |\n| Board 2 type | 2    | 3     | 4      | 1        |\n| Employees    | 3    | 2     | 5      | 10       |\n| Profit       | 12   | 5     | 15     | 10       |\n```\n\n\nUnfortunately I don't have an experience in solving optimization tasks so I don't even know where to start. What I did:\n\n\nI found sciPy optimization package which suppose to solve such type of problems.\nI have some vision about input and output for my function. The input should amount of each type of product and the output supposed to be the profit. But the choice of resources(boards, employees) might also be different. And this affects algorithm implementation.\n\n\nCould you please give me at least any direction where to go? Thank you!\n\nEDIT:\nBasically @Balzola is right. It's a simplex algorithm. The task might be solved by using SciPy.optimize.linprog solution which uses simplex under the hood.\n    ", "Answer": "\r\nTypical https://en.wikipedia.org/wiki/Simplex_algorithm\n\nLooks like scipy can do it:\nhttps://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#nelder-mead-simplex-algorithm-method-nelder-mead\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Simplex Method/Linear Programming Help\r\n                \r\nBefore programming an algorithm which implements the simplex method, I thought I'd solve an issue before the actual programming work begins.\n\nFor some reason, I can NEVER get the correct answer. I've understood the method, but the problem is with the row operations - where you try to get a column to have all 0 values except for the pivot element which has a value of '1'.\n\nTo do this, I play around with the rows by doing R1-R2, R2+5R1, etc. I always manage to get the pivot column to be 1 and the rest 0's, however my answers never match the correct ones. I've narrowed it down to a problem with the row operations - are there any rules related to this, or can I just play around with the rows as much as I like? Also, can I mix between older tableaux and the current one?\n\nThanks\n    ", "Answer": "\r\nIt sounds like you are adding and subtracting arbitrary combinations of rows to get zeros, like you would if you were transforming a matrix to row-reduced echelon form.  In the Simplex algorithm, you are only allowed to add a multiple of the pivot row from the other rows.\n\nYou should definitely not be using older tableaus in your solution.  Each iteration should only involve the current tableau.\n\nAre you implementing this for an educational project?  If not, there are many highly tuned libraries for solving linear programs.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Curve fit in python using simplex algorithm: Routine Stops even when chi^2 does not converge\r\n                \r\nI am trying to fit the data using a physical model. The code snippet is included here:\n\n```\nfrom scipy.optimize import fmin as simplex\n\ndef chi2(p1,x,y_r):\n    chisq = 0.0\n    for i in range (len(x)):\n        real_f=(np.abs(gamma(tret_m,alpha_m)[i])*(p1[0]*sin(p1[1]*x[i]+p1[2]))+ \\\n                p1[3]*np.abs((gamma(tret_m,alpha_m)[i]))**2\n        if (300>p1[3]>250 and 65>p1[0]>60):#constraining parameters\n            chisq += (real_f-y_r[i])**2\n        else:\n            chisq=1.0e15\n    return (chisq)\n\npopt = simplex(chi2, guess1, args=(x,obs),ftol=1.0e-6,maxiter=1000000, maxfun=1000000) \n```\n\n\nThe parameters produced at output are same as that provided as initial guesses (passed as guess1)! The output shows this (apart from list of parameters):\n\n```\n  Optimization terminated successfully.\n  Current function value: 1000000000000000.000000\n  Iterations: 19\n  Function evaluations: 170\n```\n\n\nAny clue through which I can make this function run till the function value converges?\n\nEDIT:\n1. gamma(tret,alpha) is a function I have defined elsewhere. I am passing tret_m and alpha_m as parameters to gamma (these parameters have been initialized with numerical values). gamma function returns an array of size 1X600.\n2. x is a 1X600 array extracted from a file.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How can I solve a system of non-linear equations in Python?\r\n                \r\nI've got a system of equations:\n\n```\nfor i [1, N]:\n\n        |A_i x (X - B_i)|\ny_i = ------------------------\n           |A_i|\n```\n\n\n```\nthe goal: find X such that it minimizes the target function:\nsum_{i in [1, N]} (y_i)^2 -> min\n\n```\n\n\nwhere ```\nA_i, X, B_i```\n are ```\n3x1```\n vectors, ```\n*```\n is a scalar multiplication, ```\n|v|```\n is euclidean norm of ```\nv```\n, and ```\nx```\n is a cross multiplication.\n\nHow can I use Python (scipy.optimize?) to solve this system of equations? I only solved ```\nAx = b```\n using ```\nnumpy.linalg.solve```\n previously, so I'm a bit confused.\n\nI'm thinking that I should use Nelder-Mead simplex algorithm, does it sound correct?\n    ", "Answer": "\r\nBasically I ended up with using the code from this SciPy documentation:\n\n```\nimport numpy as np\nfrom scipy.optimize import minimize\n\n# Target function\ndef rosen(x):\n    \"\"\"The Rosenbrock function\"\"\"\n    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nres = minimize(rosen, x0, method='nelder-mead',\n               options={'xtol': 1e-8, 'disp': True})\n\nprint(res.x)\n\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Implementation of M method Of Simplex For LP in Java\r\n                \r\nI have to solve LP problem in JAVA and have to keep track of iterations number to solve LP by simplex method . I have used MATLAB for this purpose . But matlab initially finds an suitable vertex and starts from that vertex . So the iterations number to solve LP by Simplex is not correct . \n\nHence I have started using Simplex.java . But it supports only solution of Lp problem for less than constraint . \n\nI have heard that \"greater than \" constraint can be handled by M method . Can you help me by providing implementation of M method in JAVA . ? \n\nI have to submit my thesis within 2 days . I have made an algorithm for my thesis . I have to check my algorithm by solving LP method by solving this problem and keep tracking no of iterations to solve LP problem .  \n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Comparision between vectors fails\r\n                \r\nI am implementing the simplex algorithm for an university course.\n\nThe code works well, but when I'm testing with the provided test problem I do not get the right result.\n\nOne line in the code compares two vectors ```\npMinC```\n and ```\nzeros(n,1)```\n where ```\nn```\n is the dimension of ```\npMinC```\n to decide whether the result is optimal.\n\nIn the second iteration I get the vector ```\npMinC = [ 0.00000 4.00000 3.50000 -33.00000 -3.00000 0.00000 0.00000]```\n which is obviously bigger than zero, but the algorithm terminates.\n\nThe code looks like this:\n\n```\nwhile(done == false)\n   % compute pMinC\n   if (sum(pMinC > zeros(n,1)))\n      % do stuff\n   else\n      done = true;\n   endif\nendwhile\n```\n\n\nWhy does the comparison work first and then fails the second time?\n    ", "Answer": "\r\nThe problem is you are comparing a n*1 vector with a 1*n vector. In this case octave broadcasts the variable (similar to matlabs ```\nbsxfun```\n) resulting in a matrix. The sum of a matrix is a vector.\n\nUse ```\nif any(pMinC>0)```\n to fix the problem. \n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Algorithm behind standard pulp solver\r\n                \r\nI'm currently working on an LP optimization problem with and looked into PuLP.\nI know that PuLPs default solver is: PULP-CBC-CMD. I solved a test problem with this and I'm wondering what kind of algorithm this solver actually uses... it doesnt seem to be a simplex as my problem got interpreted completely differently than a simplex interpretion would look like?\nAlso: Every other solver for PuLP has to be added to PuLP manually right?\nAlso: what solvers are you guys working with in python?\nThanks in advance!\n    ", "Answer": "\r\nCBC is based on simplex, yes. But, like most solvers, it combines simplex with many other algorithms such as branch-and-bound and cut-generation.\nIn particular, to solve linear programs it uses Clp: https://github.com/coin-or/Clp\nMore information on the CBC solver in their site: https://github.com/coin-or/Cbc\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "offsetting Simplex noise return values\r\n                \r\nI am planning on a project that uses the simplex noise algorithm to generate a map.\n\nI want to generate more terrain as you move and explore. I know that simplex generates its noise from a seed, and will generate the same map if a seed is re-used. I want to load the map chunk by chunk.\n\nMy question is this:\n\nWould it be possible pass offset parameters to a modified noise function, without iterating through values i already have? \n\nFor example receiving data for the (0,0)-(100,100) values and then from a separate call using the same seed receiving (0,100)-(100,200) values, without having to loop through the first 100x100 values.\n\nI haven't worked with noise that much before, and i am interested to know if this approach would be feasible?\n\nwhat other efficient methods would there be of generating similar results. and if this works would i be able to save the map data as the seeds used? minimizing IO functions?\n    ", "Answer": "\r\nSimplex Noise is a form of Value Noise. If you have a set seed, the mathematical calculation it performs to get the noise value is the same. This means that you only generate the noise value for a passed location. \n\nSo if you generate for 100,100; that is the only noise value you will get. You dont calculate 0-100, 0-100; unless you loop it.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Sample uniformly at random from an n-dimensional unit simplex\r\n                \r\nSampling uniformly at random from an n-dimensional unit simplex is the fancy way to say that you want n random numbers such that\n\n\nthey are all non-negative,\nthey sum to one, and\nevery possible vector of n non-negative numbers that sum to one are equally likely.\n\n\nIn the n=2 case you want to sample uniformly from the segment of the line x+y=1 (ie, y=1-x) that is in the positive quadrant.\nIn the n=3 case you're sampling from the triangle-shaped part of the plane x+y+z=1 that is in the positive octant of R3:\n\n\n\n(Image from http://en.wikipedia.org/wiki/Simplex.)\n\nNote that picking n uniform random numbers and then normalizing them so they sum to one does not work.  You end up with a bias towards less extreme numbers.\n\nSimilarly, picking n-1 uniform random numbers and then taking the nth to be one minus the sum of them also introduces bias.\n\nWikipedia gives two algorithms to do this correctly:  http://en.wikipedia.org/wiki/Simplex#Random_sampling\n(Though the second one currently claims to only be correct in practice, not in theory. I'm hoping to clean that up or clarify it when I understand this better. I initially stuck in a \"WARNING: such-and-such paper claims the following is wrong\" on that Wikipedia page and someone else turned it into the \"works only in practice\" caveat.)\n\nFinally, the question:\nWhat do you consider the best implementation of simplex sampling in Mathematica (preferably with empirical confirmation that it's correct)?\n\nRelated questions\n\n\nGenerating a probability distribution\njava random percentages\n\n    ", "Answer": "\r\nThis code can work:\n\n```\nsamples[n_] := Differences[Join[{0}, Sort[RandomReal[Range[0, 1], n - 1]], {1}]]\n```\n\n\nBasically you just choose ```\nn - 1```\n places on the interval ```\n[0,1]```\n to split it up then take the size of each of the pieces using ```\nDifferences```\n.\n\nA quick run of ```\nTiming```\n on this shows that it's a little faster than Janus's first answer.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How does PuLP linear programming solver work?\r\n                \r\nI am curious about the algorithm in the PuLP \nIs this LPsolver is using the simplex method?\n    ", "Answer": "\r\nPuLP provides a convenient frontend for a number of solvers. Some of these solvers may use simplex, others may not. You can specify the solver in order to better control this, but you'd need to look at the details for the individual solvers to figure out if any meet your criteria.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Will Z3 adaptively change strategy in solving linear real arithmetic constraints?\r\n                \r\nI have a huge set of linear real arithmetic constraints to solve, and I am incrementally feeding them to the solver. Z3 always seems to get stuck after a while. Is Z3 internally going to change its strategy in solving the constraints, such as moving away from the Simplex algorithm and try others, etc. Or do I have to explicitly instruct Z3 to do so? I am using Z3py.\n    ", "Answer": "\r\nWithout further details it's impossible to answer this question precisely. \n\nGenerally, with no logic being set and the default tactic being run or ```\n(check-sat)```\n being called without further options, Z3 will switch to a different solver the first time it sees a ```\npush```\n command; prior to that it can use a non-incremental solver. \n\nThe incremental solver comes with all the positives and negatives of incremental solvers, i.e., it may be faster initially, but it may not be able to exploit previously learned lemmas after some time, and it may simply remember too many irrelevant facts. Also, the heuristics may 'remember' information that doesn't apply at a later time, e.g., a 'good' variable ordering may change into a bad one after everything is popped and a different problem over the same variables is pushed. In the past, some users found it works better for them to use the incremental solver for some number of queries, but to start from scratch when it becomes too slow. \n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Creating first triangle in DeWall Algorithm (Delaunay Triangulation)\r\n                \r\nI am trying to understand a particular approach of the DeWall algorithm to perform a 2D/3D delaunay triangulation/tetrahedralization (DT). I am especially interested in the 3D case. Where other divide and conquer algorithms create partial DT and merge them together, the DeWall algorithm directly builds the DT along hierarchical cuts:\n\nHowever, I am stuck at the very beginning of constructing the first simplex.  In Cignoni 1997 - DeWall: A Fast Divide & Conquer Delaunay Triangulation Algorithm in Eᵈ the authors write\n\nMakeFirstSimplex selects the point p₁ ∈ P nearest to the plane α.\nIt then selects a second point p₂ such that p₂ is the nearest point to p₁ on the other side of α.\nThen, it searches the point p₃ such that the circum-circle around the 1-face (p₁, p₂) and the point p₃ has the minimum radius;\n(p₁ ; p₂; p₃) is therefore a 2-face of Σ.\nThe process continues until the required d-simplex is built.\n\nHowever, if I understand correctly this procedure should always lead to a simplex that does belong to the DT, but when I test this with different point sets, it seems to happen sometimes that an edge is picked which does not belong to the DT.\nI've tested this by connecting (green) each point (orange) to its left and right nearest neighbour. A DT made with the triangle program (gray) and the local left-right-splitting-plane (black) are also shown.\n \nIn the zoomed-in picture above, the green edges are picked by that prodedure, but one is not part the gray DT. So in a similar case where the plane α of the topmost point would be a bit right of the point and α would be a cut-plane of the DeWall algorithm, this would lead to a wrong simplex.\nIt is known, that the nearest neighbour graph is always part of a DT, but that does not help in our case since is not guaranteed that a cut-plane α always crosses one of these.\nIs there an explanation why this should work in the first place, some trick or an alternative construction to obtain the very first simplex at that constrained position?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Linear Program to solve NP-hard problems\r\n                \r\nI'm pretty new to the realm of LP, and this question has been bothering me for a long time. I know that Simplex algorithm takes exponential time in the worst case but practical on average, but Ellipsoid can solve LP with exponential number of constraints in polynomial time in the worst case. Then my question is, when you try to formulate NP-hard problems into LP, shouldn't Ellipsoid algorithm be able to solve them in poly-time? Do LP-programmable NP-hard problems always imply exponential number of variables and constraints?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How safe/mature is the simulated annealing algorithm given in Numerical Recipes?\r\n                \r\nThe authors of \"Numerical Recipes\" give in Ch. 10 an implementation of the simulated annealing algorithm that combines the \"classical\" simulated annealing with the Nelder-Mead downhill simplex method.\n\nWhat I really like about this algorithm is the way it converges to a classic downhill search as the annealing temperatures reaches 0. However, I have never found any other reference to this algorithm; is it a safe, mature variant of the simulated annealing algorithm (i.e. production-ready) or should it be considered as an experimental idea thrown into the book?\n    ", "Answer": "\r\nNope, not safe, guaranteed to give you herpes.\n\nAs someone who works professionally with AI and intelligent systems I can tell you that very few such algorithms are considered mature. By their nature advanced algorithms all tend to have an experimental aspect to them. For example, in simulated annealing you need to formulate a cooling schedule. How you do this is very problem-specific and will require you to experiment with and tune the algorithm. The NR code is a reasonable starting point for doing this.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "numpy/scipy analog of matlab's fminsearch\r\n                \r\nI am converting some Matlab code into python using numpy. Everything worked pretty smoothly but recently I encountered fminsearch function. \n\nSo, to cut it short: is there an easy way to make in python something like this:\n\n```\nbanana = @(x)100*(x(2)-x(1)^2)^2+(1-x(1))^2;\n[x,fval] = fminsearch(banana,[-1.2, 1])\n```\n\n\nwhich will return \n\n```\nx = 1.0000    1.0000\nfval = 8.1777e-010\n```\n\n\nUp till now I have not found anything that looks similar in numpy. The only thing that I found similar is scipy.optimize.fmin. Based on the definition it\n\n\n  Minimize a function using the downhill simplex algorithm.\n\n\nBut right now I can not find to write the above-mentioned Matlab code using this function\n    ", "Answer": "\r\nIt's just a straight-forward conversion from Matlab syntax to python syntax:\n\n```\nimport scipy.optimize\n\nbanana = lambda x: 100*(x[1]-x[0]**2)**2+(1-x[0])**2\nxopt = scipy.optimize.fmin(func=banana, x0=[-1.2,1])\n```\n\n\nwith output:\n\n```\nOptimization terminated successfully.\n         Current function value: 0.000000\n         Iterations: 85\n         Function evaluations: 159\narray([ 1.00002202,  1.00004222])\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "GJK algorithm gets stuck in a loop of different Voronoi Region cases\r\n                \r\nI'm currently trying to implement the simplified GJK algorithm presented in https://mollyrocket.com/849 into my C++ game.\n\nHowever, I'm experiencing strange behaviour in the second and third dimension: The algorithm sometimes (which is quite often when called multiple times a second) gets stuck in a loop of cases. As an example, the debug messages print the following to std::cout over and over again:\n\n```\n3ACxAB\n4AB\n3ABxAC\n4ABD\n4AD\n```\n\n\nIf you have a look at my code, you'll see that these lines represent the cases the algorithm allows. E.g. 3ACxAB means that the simplex currently is a triangle and that the origin is in the voronoi region of the face, in direction of the cross product AC x AB (which may be interpreted as \"above\" or \"below\" the triangle). The case 4AB means that the simplex is a tetrahedron and the origin is in the voronoi region of the edge AB.\n\nA always is the newly added point. In the code, A always is the greatest index of ```\nsimplex```\n. (^simplex[1]` if it's a line, 2 if a triangle and 3 in the case of a) tetrahedron.\n\nEven after days of searching for mistakes (I found some, but there still is one or more left), the algorithm won't work.\n\nDo you see any problem in the code? Because neither I nor two friends of mine do.\n\nPS: I didn't copy any of the calculations (e.g. cross products for the direction vector) from Casey's video. After watching it, I made up my mind myself, so here potential problems may lie, especially in the third dimension, where Casey intentionally didn't speak about.\n\n\n\nMy support function:\n\n```\n//hullA/B: convex hull of A resp. B; baseA/B: location of A/B\nVector3f gjkSupport(Vector3f direction,\n        std::vector<GLfloat> hullA, std::vector<GLfloat> baseA,\n        std::vector<GLfloat> hullB, std::vector<GLfloat> baseB) {\n    //Initialize\n    GLfloat maxDotP = -std::numeric_limits<GLfloat>::max();\n    Vector3f furthestPointA, furthestPointB;\n    //Get furthest point in given direction out of hullA by getting the maximum dot\n    //product of the direction vector and a hull vertex's position vector\n    for (GLuint i = 0; i < hullA.size(); i += 3) {\n        Vector3f current (hullA[i]+baseA[0], hullA[i+1]+baseA[1], hullA[i+2]+baseA[2]);\n        // * = dot product\n        GLfloat dotP = direction * current;\n        if (dotP > maxDotP) {\n            maxDotP = dotP;\n            furthestPointA = current;\n        }\n    }\n    maxDotP = -std::numeric_limits<GLfloat>::max();\n    //Get furthest point in negative of the given direction out of hullB\n    for (GLuint i = 0; i < hullB.size(); i += 3) {\n        Vector3f current (hullB[i]+baseB[0], hullB[i+1]+baseB[1], hullB[i+2]+baseB[2]);\n        GLfloat dotP = -direction * current;\n        if (dotP > maxDotP) {\n            maxDotP = dotP;\n            furthestPointB = current;\n        }\n    }\n    //Furthest Minkowski Difference point is difference of d*A[i]-(-d)*B[j]\n    return furthestPointA - furthestPointB;\n}\n```\n\n\nMy simplex function:\n\n```\nbool gjkSimplex(std::vector<Vector3f> &simplex, Vector3f &direction) {\n    GLuint simplexSize = simplex.size();\n    std::cout << simplexSize;\n    switch (simplexSize) {\n    //If the simplex is a line segment\n    case 2:\n        //Point is closest feature\n        if ((simplex[0]-simplex[1])*-simplex[1] < 0) {\n            std::cout << \"A\";\n            simplex = {simplex[1]};\n            //direction = A0\n            direction = -simplex[1];\n        //Line is closest feature\n        } else {\n            std::cout << \"AB\";\n            //direction = AB x (A0 x AB)\n            // ^ = cross product\n            direction = (simplex[0]-simplex[1]) ^ ((-simplex[1]) ^ (simplex[0]-simplex[1]));\n        }\n        break;\n    //If the simplex is a triangle\n    case 3:\n        //Point is closest feature\n        if ((simplex[0]-simplex[2])*(-simplex[2]) < 0 && (simplex[1]-simplex[2])*(-simplex[2]) < 0) {\n            std::cout << \"A\";\n            //direction = A0\n            direction = -simplex[2];\n            simplex = {simplex[1]};\n        //Line to second-latest point is closest feature\n        } else if ((((simplex[0]-simplex[2])^(simplex[1]-simplex[2]))^(simplex[1]-simplex[2]))*-simplex[2] > 0) {\n            std::cout << \"AB\";\n            //direction = AB x (A0 x AB)\n            direction = (simplex[1]-simplex[2]) ^ ((-simplex[2]) ^ (simplex[1]-simplex[2]));\n            simplex = {simplex[1], simplex[2]};\n        //Line to oldest point is closest feature\n        } else if (((simplex[0]-simplex[2])^((simplex[0]-simplex[2])^(simplex[1]-simplex[2])))*-simplex[2] > 0) {\n            std::cout << \"AC\";\n            //direction = AC x (A0 x AC)\n            direction = (simplex[0]-simplex[2]) ^ ((-simplex[2]) ^ (simplex[0]-simplex[2]));\n            simplex = {simplex[0], simplex[2]};\n        //Face is closest feature\n        } else {\n            //Origin is in direction AC x AB\n            if (((simplex[1]-simplex[2]) ^ (simplex[0]-simplex[2])) * (-simplex[2]) < 0) {\n                std::cout << \"ACxAB\";\n                //direction = AC x AB\n                direction = (simplex[0]-simplex[2]) ^ (simplex[1]-simplex[2]);\n            //origin is in direction AB x AC (other side of the face)\n            } else {\n                std::cout << \"ABxAC\";\n                //direction = AB x AC\n                direction = (simplex[1]-simplex[2]) ^ (simplex[0]-simplex[2]);\n                simplex = {simplex[1], simplex[0], simplex[2]};\n            }\n        }\n        break;\n    //If the simplex is a tetrahedron\n    case 4:\n        //Newest point is closest feature\n        if ((simplex[0]-simplex[3])*(-simplex[3]) < 0 && (simplex[1]-simplex[3])*(-simplex[3]) < 0 &&\n                (simplex[2]-simplex[3])*(-simplex[3]) < 0) {\n            std::cout << \"A\";\n            //direction = A0\n            direction = -simplex[3];\n            simplex = {simplex[3]};\n        //Edge between newest and second-newest point is closest feature\n        } else if ((((simplex[2]-simplex[3]) ^ ((simplex[1]-simplex[3]) ^ (simplex[2]-simplex[3]))) * (-simplex[2]) < 0) &&\n                ((((simplex[1]-simplex[3]) ^ (simplex[0]-simplex[3])) ^ (simplex[2]-simplex[3])) * (-simplex[2]) < 0)) {\n            std::cout << \"AB\";\n            //direction = AB x (A0 x AB)\n            direction = (simplex[2]-simplex[3]) ^ ((-simplex[3]) ^ (simplex[2]-simplex[3]));\n            simplex = {simplex[2], simplex[3]};\n        //Edge between newest and third-newest vertex is closest feature\n        } else if ((((simplex[1]-simplex[3]) ^ ((simplex[0]-simplex[3]) ^ (simplex[1]-simplex[3]))) * (-simplex[2]) < 0) &&\n                ((((simplex[0]-simplex[3]) ^ (simplex[2]-simplex[3])) ^ (simplex[1]-simplex[3])) * (-simplex[2]) < 0)) {\n            std::cout << \"AC\";\n            //direction = AC x (A0 x AC)\n            direction = (simplex[1]-simplex[3]) ^ ((-simplex[3]) ^ (simplex[1]-simplex[3]));\n            simplex = {simplex[1], simplex[3]};\n        //Edge between newest and oldest point is closest feature\n        } else if ((((simplex[0]-simplex[3]) ^ ((simplex[2]-simplex[3]) ^ (simplex[0]-simplex[3]))) * (-simplex[2]) < 0) &&\n                ((((simplex[2]-simplex[3]) ^ (simplex[1]-simplex[3])) ^ (simplex[0]-simplex[3])) * (-simplex[2]) < 0)) {\n            std::cout << \"AD\";\n            //direction = AD x (A0 x AD)\n            direction = (simplex[0]-simplex[3]) ^ ((-simplex[3]) ^ (simplex[0]-simplex[3]));\n            simplex = {simplex[0], simplex[3]};\n        //Face between the three newest points is closest feature\n        } else if (((simplex[1]-simplex[3]) ^ (simplex[2]-simplex[3])) * (-simplex[3]) > 0) {\n            std::cout << \"ABC\";\n            //direction = AC x AB (outer normal of face)\n            direction = (simplex[1]-simplex[3]) ^ (simplex[2]-simplex[3]);\n            simplex = {simplex[1], simplex[3], simplex[2]};\n        //Face between newest, second-newest and oldest point is closest feature\n        } else if (((simplex[2]-simplex[3]) ^ (simplex[0]-simplex[3])) * (-simplex[3]) > 0) {\n            std::cout << \"ABD\";\n            //direction = AB x AD\n            direction = (simplex[2]-simplex[3]) ^ (simplex[0]-simplex[3]);\n            simplex = {simplex[0], simplex[2], simplex[3]};\n        //Face between newest, second-oldest and oldest point is closest feature\n        } else if (((simplex[0]-simplex[3]) ^ (simplex[1]-simplex[3])) * (-simplex[3]) > 0) {\n            std::cout << \"ACD\";\n            //direction = AD x AC\n            direction = (simplex[0]-simplex[3]) ^ (simplex[1]-simplex[3]);\n            simplex = {simplex[0], simplex[3], simplex[1]};\n        //Origin is encased by simplex\n        } else {\n            //Collision detected\n            std::cout << \"ABCD\";\n            return true;\n        }\n        break;\n    default:\n        direction = {1,1,1};\n        simplex = {};\n        break;\n    }\n    std::cout << \"\\n\";\n    return false;\n};\n```\n\n\nGJK main loop:\n\n```\n//Narrow Phase collision function using GJK\nbool SolidObject::collidesWith(SolidObject *object) {\n    //Initialize by using an arbitrary direction\n    Vector3f direction (1,1,1);\n    std::vector<Vector3f> simplex;\n    Vector3f point = gjkSupport(direction,\n            this->meshes[0].getConvexHull(), this->base, object->meshes[0].getConvexHull(), object->base);\n    simplex = {point};\n    //Set direction to the negative of the resulting point\n    direction = -point;\n\n    bool originInSimplex = false;\n    while (!originInSimplex) {\n        //Get furthest point in new direction\n        point = gjkSupport(direction,\n                this->meshes[0].getConvexHull(), this->base, object->meshes[0].getConvexHull(), object->base);\n        //The furthest point in the negative direction is not in the opposing octant\n        //  => no collision\n        if (point*direction < 0) {\n            return false;\n        }\n        //Add point to the simplex\n        simplex.push_back(point);\n        //Update simplex and direction, and return whether the simplex contains the origin\n        originInSimplex = gjkSimplex(simplex, direction);\n    }\n    std::cout << \"\\n\";\n    return true;\n}\n```\n\n    ", "Answer": "\r\nIn the triangle case:\n\n```\n//Point is closest feature\nif ((simplex[0]-simplex[2])*(-simplex[2]) < 0 && (simplex[1]-simplex[2])*(-simplex[2]) < 0) {\n    std::cout << \"A\";\n    //direction = A0\n    direction = -simplex[2];\n    simplex = {simplex[1]};\n}\n```\n\n\nIt should be\n\n```\nsimplex = {simplex[2]};\n```\n\n\nIn the tetrahedron case:\n\nAll your edge checks perform the dot prodocut with```\nsimplex[2]```\n, but they should use the latest point ```\nsimplex[3]```\n.\n\nI think your first edge check uses the wrong face for the second condition, so instead of\n\n```\nif ((((simplex[2]-simplex[3]) ^ ((simplex[1]-simplex[3]) ^ (simplex[2]-simplex[3]))) * (-simplex[2]) < 0) &&\n        ((((simplex[1]-simplex[3]) ^ (simplex[0]-simplex[3])) ^ (simplex[2]-simplex[3])) * (-simplex[2]) < 0)) {\n    std::cout << \"AB\";\n    //direction = AB x (A0 x AB)\n    direction = (simplex[2]-simplex[3]) ^ ((-simplex[3]) ^ (simplex[2]-simplex[3]));\n    simplex = {simplex[2], simplex[3]};\n}\n```\n\n\nit should be\n\n```\nif ((((simplex[2]-simplex[3]) ^ ((simplex[1]-simplex[3]) ^ (simplex[2]-simplex[3]))) * (-simplex[3]) < 0) &&\n        ((((simplex[2]-simplex[3]) ^ (simplex[0]-simplex[3])) ^ (simplex[2]-simplex[3])) * (-simplex[3]) < 0)) {\n    std::cout << \"AB\";\n    //direction = AB x (A0 x AB)\n    direction = (simplex[2]-simplex[3]) ^ ((-simplex[3]) ^ (simplex[2]-simplex[3]));\n    simplex = {simplex[2], simplex[3]};\n}\n```\n\n\nthe same holds true for the second condition of the second edge check, where it should be:\n\n```\n((((simplex[1]-simplex[3]) ^ (simplex[2]-simplex[3])) ^ (simplex[1]-simplex[3])) * (-simplex[3]) < 0)\n```\n\n\nand the second condition of the third edge check:\n\n```\n((((simplex[0]-simplex[3]) ^ (simplex[1]-simplex[3])) ^ (simplex[0]-simplex[3])) * (-simplex[3]) < 0)\n```\n\n\nI also fixed the output simplexe of the triangle checks. The last point of the input simplex should be always the last point of the output simplex. Also, the ordering of the points should be consistent and match the calculated direction.\n\nHere is the complete fixed function:\n\n```\nbool gjkSimplex(std::vector<Vector3f> &simplex, Vector3f &direction) {\n    GLuint simplexSize = simplex.size();\n    std::cout << simplexSize;\n    switch (simplexSize) {\n    //If the simplex is a line segment\n    case 2:\n        //Point is closest feature\n        if ((simplex[0]-simplex[1])*-simplex[1] < 0) {\n            std::cout << \"A\";\n            //direction = A0\n            direction = -simplex[1];\n            simplex = {simplex[1]};\n        //Line is closest feature\n        } else {\n            std::cout << \"AB\";\n            //direction = AB x (A0 x AB)\n            // ^ = cross product\n            direction = (simplex[0]-simplex[1]) ^ ((-simplex[1]) ^ (simplex[0]-simplex[1]));\n        }\n        break;\n    //If the simplex is a triangle\n    case 3:\n        //Point is closest feature\n        if ((simplex[0]-simplex[2])*(-simplex[2]) < 0 && (simplex[1]-simplex[2])*(-simplex[2]) < 0) {\n            std::cout << \"A\";\n            //direction = A0\n            direction = -simplex[2];\n            simplex = {simplex[2]};\n        //Line to second-latest point is closest feature\n        } else if ((((simplex[0]-simplex[2])^(simplex[1]-simplex[2]))^(simplex[1]-simplex[2]))*-simplex[2] > 0) {\n            std::cout << \"AB\";\n            //direction = AB x (A0 x AB)\n            direction = (simplex[1]-simplex[2]) ^ ((-simplex[2]) ^ (simplex[1]-simplex[2]));\n            simplex = {simplex[1], simplex[2]};\n        //Line to oldest point is closest feature\n        } else if (((simplex[0]-simplex[2])^((simplex[0]-simplex[2])^(simplex[1]-simplex[2])))*-simplex[2] > 0) {\n            std::cout << \"AC\";\n            //direction = AC x (A0 x AC)\n            direction = (simplex[0]-simplex[2]) ^ ((-simplex[2]) ^ (simplex[0]-simplex[2]));\n            simplex = {simplex[0], simplex[2]};\n        //Face is closest feature\n        } else {\n            //Origin is in direction AC x AB\n            if (((simplex[1]-simplex[2]) ^ (simplex[0]-simplex[2])) * (-simplex[2]) < 0) {\n                std::cout << \"ACxAB\";\n                //direction = AC x AB\n                direction = (simplex[0]-simplex[2]) ^ (simplex[1]-simplex[2]);\n            //origin is in direction AB x AC (other side of the face)\n            } else {\n                std::cout << \"ABxAC\";\n                //direction = AB x AC\n                direction = (simplex[1]-simplex[2]) ^ (simplex[0]-simplex[2]);\n                simplex = {simplex[1], simplex[0], simplex[2]};\n            }\n        }\n        break;\n    //If the simplex is a tetrahedron\n    case 4:\n        //Newest point is closest feature\n        if ((simplex[0]-simplex[3])*(-simplex[3]) < 0 && (simplex[1]-simplex[3])*(-simplex[3]) < 0 &&\n                (simplex[2]-simplex[3])*(-simplex[3]) < 0) {\n            std::cout << \"A\";\n            //direction = A0\n            direction = -simplex[3];\n            simplex = {simplex[3]};\n        //Edge between newest and second-newest point is closest feature\n        } else if ((((simplex[2]-simplex[3]) ^ ((simplex[1]-simplex[3]) ^ (simplex[2]-simplex[3]))) * (-simplex[3]) < 0) &&\n                ((((simplex[2]-simplex[3]) ^ (simplex[0]-simplex[3])) ^ (simplex[2]-simplex[3])) * (-simplex[3]) < 0)) {\n            std::cout << \"AB\";\n            //direction = AB x (A0 x AB)\n            direction = (simplex[2]-simplex[3]) ^ ((-simplex[3]) ^ (simplex[2]-simplex[3]));\n            simplex = {simplex[2], simplex[3]};\n        //Edge between newest and third-newest vertex is closest feature\n        } else if ((((simplex[1]-simplex[3]) ^ ((simplex[0]-simplex[3]) ^ (simplex[1]-simplex[3]))) * (-simplex[3]) < 0) &&\n                ((((simplex[1]-simplex[3]) ^ (simplex[2]-simplex[3])) ^ (simplex[1]-simplex[3])) * (-simplex[3]) < 0)) {\n            std::cout << \"AC\";\n            //direction = AC x (A0 x AC)\n            direction = (simplex[1]-simplex[3]) ^ ((-simplex[3]) ^ (simplex[1]-simplex[3]));\n            simplex = {simplex[1], simplex[3]};\n        //Edge between newest and oldest point is closest feature\n        } else if ((((simplex[0]-simplex[3]) ^ ((simplex[2]-simplex[3]) ^ (simplex[0]-simplex[3]))) * (-simplex[3]) < 0) &&\n                ((((simplex[0]-simplex[3]) ^ (simplex[1]-simplex[3])) ^ (simplex[0]-simplex[3])) * (-simplex[3]) < 0)) {\n            std::cout << \"AD\";\n            //direction = AD x (A0 x AD)\n            direction = (simplex[0]-simplex[3]) ^ ((-simplex[3]) ^ (simplex[0]-simplex[3]));\n            simplex = {simplex[0], simplex[3]};\n        //Face between the three newest points is closest feature\n        } else if (((simplex[1]-simplex[3]) ^ (simplex[2]-simplex[3])) * (-simplex[3]) > 0) {\n            std::cout << \"ABC\";\n            //direction = AC x AB (outer normal of face)\n            direction = (simplex[1]-simplex[3]) ^ (simplex[2]-simplex[3]);\n            simplex = {simplex[1], simplex[2], simplex[3]};\n        //Face between newest, second-newest and oldest point is closest feature\n        } else if (((simplex[2]-simplex[3]) ^ (simplex[0]-simplex[3])) * (-simplex[3]) > 0) {\n            std::cout << \"ABD\";\n            //direction = AB x AD\n            direction = (simplex[2]-simplex[3]) ^ (simplex[0]-simplex[3]);\n            simplex = {simplex[2], simplex[0], simplex[3]};\n        //Face between newest, second-oldest and oldest point is closest feature\n        } else if (((simplex[0]-simplex[3]) ^ (simplex[1]-simplex[3])) * (-simplex[3]) > 0) {\n            std::cout << \"ACD\";\n            //direction = AD x AC\n            direction = (simplex[0]-simplex[3]) ^ (simplex[1]-simplex[3]);\n            simplex = {simplex[0], simplex[1], simplex[3]};\n        //Origin is encased by simplex\n        } else {\n            //Collision detected\n            std::cout << \"ABCD\";\n            return true;\n        }\n        break;\n    default:\n        direction = {1,1,1};\n        simplex = {};\n        break;\n    }\n    std::cout << \"\\n\";\n    return false;\n};\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Accessing the Nelder-Mead simplex at every iteration using scipy.optimize.minimize\r\n                \r\nSome background:\nI am using the Nelder-Mead simplex optimization algorithm from ```\nscipy.optimize.minimize```\n to do some hyperparameter optimization on a deep learning model. For an input x and a function f, ```\nminimize```\n is trying to optimize the function value f(x) by changing x. In my case, x are the hyperparameters of the model, f, which is making predictions for a constant set of training examples.\nBecause f is very large, and there are many training examples, each call f(x) takes about 10 minutes when the embarrassingly parallel problem of making predictions on all training examples is distributed among 20 rtx-2080 GPUs. So every step is expensive.\nFor one reason or another (crashing, running out of time on the GPUs) the script will stop in the middle of optimizing. It is therefore desirable for me to save the state of the optimization so I can continue it from where it left off. I am able to save the hyperparameter values x during every N.M. step, but this only goes so far. Even if you've recovered x (let's call the recovered version x'), the Nelder-Mead simplex is lost. If you restart optimization of f at x', ```\nminimize```\n has to rebuild the simplex by evaluating f(x' + p) N times, where p is some perturbation to one of the dimensions of x , and N is either dim(x) or dim(x) + 1. In my case, x is high dimensional (>20), so it takes ~3 hours just to recover the simplex.\nThe question:\nI need a way to access the simplex at every step in case of a crash. Others have suggested using a callback to solve the problem of recovering parameter and function values during optimization with ```\nscipy.optimize.minimize```\n (not necessarily with Nelder-Mead). However, in the documentation for ```\nminimize```\n it states the only version of ```\nminimize```\n that can return both the current parameter values (x) and an ```\nOptimizeResult```\n object (an object which could contain the simplex in the case of N.M.) via a callback is the \"trust_constr\" method. In other words, I'm pretty sure using a callback with the \"nelder_mead\" version only gives you access to x.\nThe best solution we've come up with is to edit the ```\n_minimize_neldermead```\n function within the ```\nminimize```\n source code to save the simplex values after each step. Is there a more elegant way of accomplishing this? Does ```\nminimize```\n already have this ability and we just can't find it?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Light generation algorithm for clouds on the iOS platform\r\n                \r\nI'd like to fill the background of my app with animated clouds. I did some research and stumbled upon the perlin noise algorithm which seems to be fitting. However even in the first test it was extremely expensive to generate a 512x512 (2D) cloud map. I tried simplex noise but it didn't fix it. \n\nAccording to http://freespace.virgin.net/hugo.elias/models/m_clouds.htm generating clouds is done by adding some perlin/simplex noise maps together. Impossible to do it on a iPhone in my app: I need fluid graphics (my optimistic expectation is 60 FPS on an A4).\n\nSo my question: Is there a lighter algorithm to generate animated clouds that does not make my frame rate drop too much?\n\nThanks in advance!\n\nPaul\n    ", "Answer": "\r\nUnless all you're doing is generating clouds you'll definitely want them precomputed. Perlin noise can make for nice 2d animations by traversing a set of 3d data, but you could just scroll a 2d image of some noise or a fractal like is generated by the diamond-square algorithm. Either way, you should probably precompute it.\n\nIf you want some more variation, I would experiment with putting a noise filter over the precomputed clouds.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How does Bowyer-Watson algorithm for Delaunay triangulation run in O(n^2) but runs over all the simplexes?\r\n                \r\nThe Bowyer-Watson algorithm for Delaunay triangulation is known to run in O(n^2) according to the authors, where n is the number of data points in R^d.\nIn addition, the algorithm (for example, as is written in Bowyer's paper, at stage 5 of the algorithm), runs over all the simplexes, (also runs over simplexes that will be later deleted).\nHow does it settle with the fact that there are O(n^{d/2}) simplexes in Delaunay triangulation?\nOne should expect from the algorithm to run in Omega(n^{d/2}), (and maybe even in a worse time complexity - since it runs over \"extra simplexes\").\nThanks!\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Does Integer Linear Programming give optimal solution?\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                Want to improve this post? Provide detailed answers to this question, including citations and an explanation of why your answer is correct. Answers without enough detail may be edited or deleted.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n\r\n\r\n    \r\n\r\nI am trying to implement a solution to a problem using Integer linear programming (ILP). As the problem is NP-hard , I am wondering if the solution provided by Simplex Method would be optimal ? Can anyone comment on the optimality of ILP using Simplex Method or point to some source. Is there any other algorithm that can provide optimal solution to the ILP problem? \n\nEDIT: I am looking for yes/no answer to the optimality of the solution obtained by any of the algorithms (Simplex Method, branch and bound and cutting planes) for ILP.\n    ", "Answer": "\r\nThe Simplex Method doesn't handle the constraint that you want integers. Simply rounding the result is not guaranteed to give an optimal solution.\n\nUsing the Simplex Method to solve an ILP problem does work if the constraint matrix is totally dual integral.\n\nSome algorithms that solve ILP (not constrained to totally dual integral constraint matrixes) are Branch and Bound, which is simple to implement and generally works well if the costs are reasonably uniform (very non-uniform costs make it try many attempts that look promising at first but turn out not to be), and Cutting Plane, which I honestly don't know much about but it's probably good because people are using it.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Passing SoPlex parameters to SCIP\r\n                \r\nI am using the SCIP solver in AMPL mode, with SoPlex as the LP solver. This is the pre-compiled version available at https://scipopt.org/index.php#download.\nI am solving mixed integer programs (MIPs) and would like to tell SoPlex to use the dual simplex algorithm for the LP subproblems. To do this, should I just specify ```\nlp/initalgorithm = d```\n and ```\nlp/resolvealgorithm = d```\n in scip.set? Or is there some way to send settings to the SoPlex subproblem solver, along the lines shown here?\n    ", "Answer": "\r\nSetting the parameters as you suggested is exactly correct. That guarantees that SoPlex will start with the dual simplex every time (which it would almost certainly also do by default).\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Analytic normals to a sphere displaced with Simplex Noise\r\n                \r\nI want to render a planet like sphere. The general idea is as follows:\n\n\nGenerate a bunch of unit length vertices which make up a sphere.\nWhile rendering the sphere the shader evaluates the 3D simplex noise at the point on the unit sphere.\nThe result is used as the \"height\" to displace the current vertex along its direction.\n\n\nUp to here everything is working like it should.\n\nNow I want to add lighting and therefore need normals to the surface.\n\nWhile implementing the lighting related parts I quickly added a method to estimate the normals of the terrain using partial derivatives in the fragment shader like this:\n\n```\nvec3 X = dFdx(ins.position);\nvec3 Y = dFdy(ins.position);\nvec3 normal = normalize(cross(X,Y));\n```\n\n\nwhere ```\nins.position```\n is the interpolated world position.\n\nWhile this works it does not look very good, because it essentially results in per-face normals.\n\n\n\nNow to the actual questions:\n\n\nCalculating per-vertex normals would result in smooth normals, unlike in the picture, correct?\nOne of the advantages of Simplex Noise over Perlin Noise is that is has a \"well-defined and continuous gradient everywhere that can be computed quite cheaply\" (to cite the excellent Simplex Noise demystified) and with the gradient one should be able to compute the normal, correct?\n\n\nIf the seconds question is a \"yes\" I have two problems:\n\n\nThe simplex noise algorithm was taken from a popular source, which sadly does not include the gradient calculation. I will post my attempt of adding it below, but I have no idea if it is correct.\nEven if I had the gradient I am stuck on deriving the normal from there.\n\n\nAny help is greatly appreciated!\n\nMy shot at the gradient implementation (replaced the last few lines of snoise):\n\n```\nfloat snoise(vec3 v, out vec3 grad)\n{\n    ......\n\n    // Mix final noise value\n    vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);\n    vec4 m2 = m * m;\n    vec4 m4 = m2 * m2;\n\n    vec4 pdotx = vec4(dot(p0,x0), dot(p1,x1), dot(p2,x2), dot(p3,x3));\n\n    vec4 temp = m2 * m * pdotx;\n    grad = -8.0 * (temp.x * x0 + temp.y * x1 + temp.z * x2 + temp.w * x3);\n    grad += m4.x * p0 + m4.y * p1 + m4.z * p2 + m4.w * p3;\n    grad *= 42.0;\n\n    return 42.0 * dot(m4, pdotx);\n}\n```\n\n\nUPDATE:\n\nThe part about calculating the surface normal from the gradient has been answered here:\nSurface normal to point on displaced sphere.\n\nThe remaining question now is how to implement the gradient calculation into the GLSL version of the 3D Simplex Noise, because my implementation seems to have issues.\n\nUPDATE 2:\n\nThe gradient calculation seems to be almost right, just the scaling seems to be off.\nInstead of multiplying by 42, dividing by 5 gives pretty good results, but that was found out by trial and error. A proper scaling factor would be nice.\n    ", "Answer": "\r\nAlright, turns out my problem was almost purely math related.\n\nIf anyone is interested:\nThe GLSL implementation of the gradient calculation posted in the question is totally correct.\nCalculating the normals directly from the gradient is possible as described here.\n\nAnd the result looks exactly like I wanted it to be, I am happy ;)\n\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Revised simplex method enters endless loop\r\n                \r\nI'm trying to implement a revised simplex method (RSM) algorithm using Python and numpy. I'm stuck with its either working on maximization only (correct on tiny matrices like 2x4, 5x5 etc and wrong on larger ones) or entering endless loop in most cases of minimization. The code below demonstrates my attempt to implement minimization:\n```\n    def __init__(self, A: np.ndarray, b: np.ndarray, c: np.ndarray):\n        base_size = A.shape[0]  # Number of basis vectors\n        I = np.eye(base_size)  # Identity matrix, an initial basis \n        self.extended_matrix = np.concatenate((A, I), axis=1)  # Extended matrix of the system\n        self.free_size = A.shape[1]  # Number of free vectors\n        self.b = b  # Right parts of the constraints\n        self.base_inv = I  # Initial inverse basis matrix\n        self.c = np.concatenate((c, np.zeros(base_size)))  # Objective function quotients including those related to the basis variables\n        self.c_i = [i for i, coeff in enumerate(self.c)]  # Indices for all variables\n        \n    @property\n    def c_f_indices(self):\n        \"\"\"\n        Indices of the free variables.\n        \"\"\"\n        return self.c_i[:self.free_size]\n    \n    @property\n    def c_T_B(self):\n        \"\"\"\n        Objective function quotients related to the basis variables.\n        \"\"\"\n        c_B_indices = self.c_i[self.free_size:]  # Basis variables indices.\n        return self.c[c_B_indices]\n    \n    @property\n    def c_T_f(self):\n        \"\"\"\n        Objective function quotients related to the free variables.\n        \"\"\"\n        return self.c[self.c_f_indices]\n        \n    @property\n    def free(self):\n        \"\"\"\n        Free vectors.\n        \"\"\"\n        return self.extended_matrix[:, self.c_f_indices]\n    \n    @property\n    def y_T(self):\n        \"\"\"\n        Lagrange multipliers.\n        \"\"\"\n        return self.c_T_B @ self.base_inv\n    \n    @property\n    def deltas(self):\n        \"\"\"\n        Net evaluations. \n        \"\"\"\n        return (self.y_T @ self.free) - self.c_T_f \n    \n\n\n    def _swap(self, exits: int, enters: int) -> None:\n        \"\"\"\n        In-/excluding respective vectors into/from the basis.\n        \"\"\"\n        self.c_i[enters], self.c_i[exits + self.free_size] = self.c_i[exits + self.free_size], self.c_i[enters]\n    \n    def optimize(self):\n        while any([delta > 0 for delta in self.deltas]): # < 0 in case of maximization\n            x_B = self.base_inv @ self.b  # Current basis variables\n            enters_base = np.argmax(self.deltas)  # Vector to enter the basis; argmin in case of maximization\n            \n            # Finding the vector to leave the basis:\n            alpha = self.base_inv @ self.free[:, enters_base]\n\n            try:\n                exits_base = np.argmin([b/a if a > 0 else np.inf for b, a in zip(x_B, alpha)])\n                assert alpha[exits_base] != 0\n            except (ValueError, AssertionError):\n                raise Exception(\"No solutions\")\n            \n            # Finding the E_r matrix, which current inverse basis will be left-multiplied with in order to achieve the new inverse basis:\n            zetas = [-alpha[j] / alpha[exits_base] if j != exits_base else 1/alpha[exits_base] for j, a_j in enumerate(alpha)]\n            E = np.eye(self.free.shape[0])\n            E[:, exits_base] = zetas\n            self.base_inv = E @ self.base_inv\n            \n            # In-/excluding respective vectors into/from the basis:\n            self._swap(exits_base, enters_base)\n            \n        return self.c_T_B @ self.base_inv @ self.b # Final objective function value\n```\n\nI've also tried to sort c_f_indices but still get endless loop. A similar RSM implementation also yields wrong results on larger matrices (like 16x8, for example) and works fine on tiny ones.\nWhere is the root of the problem?\n    ", "Answer": "\r\nAs already mentioned by Erwin Kalvelagen, the normal Dantzig pivot rule can lead to cycles and stalling, where there is no improvement in the objective value for long periods of time.\nIn general, this phenomena is known as degeneracy of the LP. Limited numerical accuracy and roundoffs errors can contribute to the degeneracy of an issue. This is why it is typically more prevalent in large LP's.\nThere's a few ways to combat this problem. As Erwin mentioned, pertubation is most often used. However, if you're doing this as a learning project, I would suggest using a solution where you use more refined pivoting rule such as Zadeh's Rule or Cunningham's Rule, where you simply keep a a table or variable to ensure you pick a different variable to enter the basis once you've cycled.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "excel solver (Simplex LP) binary constraints\r\n                \r\nI am solving an optimization problem.  the problem has binary constraints.  solver is (during iteration) setting those binary constraints to decimals between 0 and 1 (approximating a relaxed gradient search).  I wish to indicate to solver that it should just search over the discontinous values for 0..1.   \n\nIs there a way to do this?\n\nAlternatively, is there an algorithm in OpenSolver which does this, that mimics the simplex-lp, and provides a global optimum?\n\nthe cheap way to do it, is to right a for-loop, and iterate over the values.  I was wondering if there was a way to phrase it so that a nonlinear problem, becomes a linear problem.\n\nThanks.\n    ", "Answer": "\r\nThe GRG Nonlinear and Simplex LP methods both use the Branch & Bound method when faced with integer constraints. This method \"relaxes\" the integer requirement first, finds a solution, then fixes one of the constraints to an integer and finds a new solution. See the Solver on-line documentation.\n\nIt is a brute force search method and can take a considerable amount of time.\n\nThe Evolutionary method uses it's own algorithm for dealing with integer constraints and is typically much faster than the other two methods.\n\nYou ask about linearizing a non-linear problem - you would need to provide more specific information in order to answer that (e.g. What is your equation? How have you set up your solver problem? etc.)\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Triple integral of perlin/simplex noises\r\n                \r\nI'm wondering if it were possible to get the triple integral of a 3d noise function (for example perlin or simplex noises). I searched a little over the web but i haven't found any result.. if it were possible, we could calculate the sum of all f(x,y,z) (light/density/color/etc) in a given direction, given a start position (maybe even with infinite rendering distance). It could be cool.\n\nI tried to manage the perlin noise algorithm and I found the integral of lerp(int(u), int(u)+1, t)\nBut I can't figure out how to integrate hash function or f(lerp).. any idea or suggestion?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Solving linear simultaneous equations with 7 unknowns\r\n                \r\nI am trying to solve a system of 7 linear equations to complete a step involved in a \"Transhipment Simplex Algorithm\" problem. I have written the following code using the numpy library:\n```\nimport numpy as np \n\n# Coefficients matrix\nA = [[1,0,0,0,0,0,0], [1,0,0,0,0,0,1], [0,1,0,1,0,0,0], [0,1,0,0,1,0,0], [0,1,0,0,0,0,1], [0,0,1,0,0,1,0], [0,0,1,0,0,1,0]]\n\n# RHS matrix\nB = [0,120,100,40,10,60,100]\n\n# Solution matrix\nX = np.linalg.inv(A).dot(B)\nprint (X)\n```\n\nHowever, when I run this code I receive the following error:\n```\nlgerror_singular\n    raise LinAlgError(\"Singular matrix\")\nnumpy.linalg.LinAlgError: Singular matrix\n```\n\nI have tried to use the ```\nnp.linalg.solve(A,B)```\n method but this returns the same error.\nI have also tried defining the matrices like this ```\nB = np.array([0,120,100,40,10,60,100])```\n but this returns the following error:\n```\n    A = np.array([1,0,0,0,0,0,0], [1,0,0,0,0,0,1], [0,1,0,1,0,0,0], [0,1,0,0,1,0,0], [0,1,0,0,0,0,1], [0,0,1,0,0,1,0], [0,0,1,0,0,1,0])\nTypeError: array() takes from 1 to 2 positional arguments but 7 were given\n```\n\nI know I must be doing something wrong here, any help would be greatly appreciated!\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Implementing the Expanding Polytope Algorithm in 3D Space\r\n                \r\nI'm trying to implement the EPA algorithm in 3D space but I seem to have found a situation when the convex simplex can turn into a concave one.\n\nConsider this simplex:\n\n\n\nAnd because it's hard to see what's going on here it is animated:\n\n\n\nThe origin is the red, green and blue axis helper. The white sphere with no edges connected to it represents the point where I need to expand the polytope to next. The 5 yellow arrows are the normals of the faces that should be removed since they're in the same direction as the origin to the new point. Some faces don't look to be in the same direction but I've verified that they are as the dot products with the face normal and new point are:\n\n\n0.45396564417079877\n0.9473689548609279\n0.3346846050014339\n0.09982613239032267\n0.09982617482390854\n\n\nSo those two faces on the right side of the .gif are just barley in the same direction.\n\nOkay so the EPA algorithm says to remove those faces:\n\n\n\nThen construct new faces to the new point using the remaining edges from the faces we removed. But you can see now that the convex simplex has turned into a concave one:\n\n\n\nThis is obviously not right but I'm not sure where I went wrong. It feels to me like I've removed faces I shouldn't have but those faces are in the same direction as the new point.\n\nHere is my code:\n\n```\nvar EPA = function(aWorldVerts, bWorldVerts, simplex) {\n    var simplexFaces = [{a: 0, b: 1, c: 2},\n                        {a: 0, b: 1, c: 3},\n                        {a: 0, b: 2, c: 3},\n                        {a: 1, b: 2, c: 3}];\n\n    var ret = null;\n\n    while(true) {\n        var face = findClosestFace(simplex, simplexFaces);\n        var point = support(aWorldVerts, bWorldVerts, face.norm);\n        var dist = point.clone().dot(face.norm);\n\n        if(dist - face.dist < 0.00001) {\n            ret = {axis: face.norm, dist: dist};\n            break;\n        }\n\n        simplex.push(point);\n        reconstruct(simplex, simplexFaces, point);\n    }\n\n    return ret;\n}\n\nvar reconstruct = function(simplex, simplexFaces, extendPoint) {\n    //I do realize that this function can be done more efficietly\n    var removalFaces = [];\n    for(var i = 0; i < simplexFaces.length; i++) {\n        var face = simplexFaces[i];\n\n        var ab = simplex[face.b].clone().sub(simplex[face.a]);\n        var ac = simplex[face.c].clone().sub(simplex[face.a]);\n        var norm = ab.cross(ac).normalize();\n\n        var a0 = new THREE.Vector3().sub(simplex[face.a]);\n        if(a0.dot(norm) > 0)\n            norm.negate();\n\n        if(extendPoint.clone().dot(norm) > 0) {\n            removalFaces.push(i);\n        }\n    }\n\n    //get the edges that are not shared between the faces that should be removed\n    var edges = [];\n    for(var i = 0; i < removalFaces.length; i++) {\n        var face = simplexFaces[removalFaces[i]];\n        var edgeAB = {a: face.a, b: face.b};\n        var edgeAC = {a: face.a, b: face.c};\n        var edgeBC = {a: face.b, b: face.c};\n\n        var k = edgeInEdges(edges, edgeAB);\n        if(k != -1)\n            edges.splice(k, 1);\n        else\n            edges.push(edgeAB);\n\n        k = edgeInEdges(edges, edgeAC);\n        if(k != -1)\n            edges.splice(k, 1);\n        else\n            edges.push(edgeAC);\n\n        k = edgeInEdges(edges, edgeBC);\n        if(k != -1)\n            edges.splice(k, 1);\n        else\n            edges.push(edgeBC);\n    }\n\n    //remove the faces from the polytope\n    for(var i = removalFaces.length - 1; i >= 0; i--) {\n        simplexFaces.splice(removalFaces[i], 1);\n    }\n\n    //form new faces with the edges and new point\n    for(var i = 0; i < edges.length; i++) {\n        simplexFaces.push({a: edges[i].a, b: edges[i].b, c: simplex.length - 1});\n    }\n}\n\nvar edgeInEdges = function(edges, edge) {\n    for(var i = 0; i < edges.length; i++) {\n        if(edges[i].a == edge.a && edges[i].b == edge.b)\n            return i;\n    }\n\n    return -1;\n}\n\nvar findClosestFace = function(simplex, simplexFaces) {\n    var closest = {dist: Infinity};\n\n    for(var i = 0; i < simplexFaces.length; i++) {\n        var face = simplexFaces[i];\n\n        var ab = simplex[face.b].clone().sub(simplex[face.a]);\n        var ac = simplex[face.c].clone().sub(simplex[face.a]);\n        var norm = ab.cross(ac).normalize();\n\n        var a0 = new THREE.Vector3().sub(simplex[face.a]);\n        if(a0.dot(norm) > 0)\n            norm.negate();\n\n        var dist = simplex[face.a].clone().dot(norm);\n\n        if(dist < closest.dist) {\n            closest = {index: i, dist: dist, norm: norm, a: face.a, b: face.b, c: face.c};\n        }\n    }\n\n    return closest;\n}\n\nvar support = function(aVerts, bVerts, dir) {\n    a = getFurthestPointInDirection(aVerts, dir);\n    b = getFurthestPointInDirection(bVerts, dir.clone().negate());\n    return a.clone().sub(b);\n}\n\nvar getFurthestPointInDirection = function(verts, dir) {\n    var index = 0;\n    var maxDot = verts[index].clone().dot(dir.clone().normalize());\n\n    for(var i = 1; i < verts.length; i++) {\n        var dot = verts[i].clone().dot(dir.clone().normalize());\n\n        if(dot > maxDot) {\n            maxDot = dot;\n            index = i;\n        }\n    }\n\n    return verts[index];\n}\n```\n\n\nI know the support function works correctly as well as ```\nfindClosestFace()```\n and ```\nedgeInEdges()```\n. Also, it shouldn't matter but this is implemented using Three.js and Javascript. Maybe I'm just fundamentally misunderstanding how the algorithm works?\n\nWhat have I done wrong and how can I fix it?\n    ", "Answer": "\r\nMany hours of debugging later I've found my problem. The faces you want to remove before extending the polytope to the new point are not found by checking if the normal of the face is in the same direction as the origin to the new point. Many articles on this topic say you want to remove the faces that the new point can \"see\" which I took to mean the normals are in the same direction. This is not the case because you can very well have a face normal in the same direction as the origin to the new point however the face can't be \"seen\" by the point so removing it would be problematic which is what I was doing. You want to essentially imagine you're camera to be exactly where the new point is, look around and any face you can see should be removed.\n\nTo check if a given face can be \"seen\" by the new point you want to form a vector from a vertex of said face to the new point and check the dot product of that with the face normal. So I replaced ```\nif(extendPoint.clone().dot(norm) > 0)```\n with ```\nif(norm.clone().dot(extendPoint.clone().sub(simplex[face.a])) > 0)```\n in the ```\nreconstruct()```\n function and it now works.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Nelder Mead algorithm for constrained optimization?\r\n                \r\nI have read that Nelder Mead algorithm is working for unconstrained optimization. \nhttp://www.scholarpedia.org/article/Nelder-Mead_algorithm\nI think in Matlab Nelder Mead is used also for unconstrained optimization.\nHowever, I am a little bit confused, since I found a Java API for optimization \nhttp://www.ee.ucl.ac.uk/~mflanaga/java/Minimisation.html\n(Flanagan's Scientific Library)\nthat has a class that implements Nelder Mead simplex and allows for defining constraints and bounds.\nSo, is the version implemented in Flanagan's API a modified variation of the \"classical\" Nelder Mead algorithm? \n    ", "Answer": "\r\nIt looks like the API is implementing a simple \"soft\" constraint system, where constraints are transformed into penalty functions which severely penalize regions outside the constraints. It's a cheap-and-cheerful way of adding constraints to an unconstrained solver, but there'll be a tradeoff between optimality, convergence, and the degree to which the constraints are satisfied.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Looking for a template-based C++ library that solves linear programs\r\n                \r\nI'm looking for a LP (Linear Program) solver,  that uses Simplex algorithm or anything it likes. I have an additional request, that the solver will carry out all its compuations without any loss of precision !!\n\nSo if I can find a template-based C++ library, that let me define the underline type of the numerical variables it uses, I will let it use the boost's type cpp_ratinal, and thus all computations won't loss any precision due to rounding of floating-points.\n\nDoes such C++ library exists ?\n    ", "Answer": "\r\nBoth SoPlex and QSOpt have exact simplex solvers.  They will perform better than what you propose to do.  I should warn you, however, that SoPlex's exact simplex solver doesn't actually work; it's fairly straightforward to construct a feasible linear program with rational data on which SoPlex reports infeasibility.\n\nUsing exact arithmetic for the whole of the solving process is not a good idea.  You wind up having to row-reduce big matrices in exact arithmetic, and the exact numbers involved grow huge.  I believe GLPK's exact solver run simplex in rational arithmetic; you might play with it and see how much you like its performance.\n\nAmong interior-point solvers, SDPA-GMP is an interior-point method for a generalisation of linear programming that uses arbitrary-precision arithmetic.  You have to decide on the precision you want to use, but you might be able to use SDPA-GMP to get a very high-precision solution, then do some sort of high-precision crossover to get an exact optimal solution.  (I've never tried this since I've never wanted to solve an LP exactly.)  I would suspect the simplex-based solvers would run faster than an IPM in this case, too.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Scipy - find bases of column space of matrix\r\n                \r\nI'm trying to code up a simple Simplex algorithm, the first step of which is to find a basic feasible solution:\n\n\nChoose a set B of linearly independent columns of A\nSet all components of x corresponding to the columns not in B to zero.\nSolve the m resulting equations to determine the components of x. These are the basic variables.\n\n\nI know the solution will involve using ```\nscipy.linalg.svd```\n (or ```\nscipy.linalg.lu```\n) and some ```\nnumpy.argwhere```\n / ```\nnumpy.where```\n magic, but I'm not sure exactly how.\n\nDoes anyone have a pure-Numpy/Scipy implementation of finding a basis (step 1) or, even better, all of the above?\n\nExample:\n\n```\n>>> A\narray([[1, 1, 1, 1, 0, 0, 0],\n       [1, 0, 0, 0, 1, 0, 0],\n       [0, 0, 1, 0, 0, 1, 0],\n       [0, 3, 1, 0, 0, 0, 1]])\n\n>>> u, s, v = scipy.linalg.svd(A)\n>>> non_zero, = numpy.where(s > 1e-7)\n>>> rank = len(non_zero)\n>>> rank\n4\n>>> for basis in some_unknown_function(A):\n...     print(basis)\n{3, 4, 5, 6}\n{1, 4, 5, 6}\n```\n\n\nand so on.\n    ", "Answer": "\r\nA QR decomposition provides an orthogonal basis for the column space of A:\n\n```\nq,r = np.linalg.qr(A)\n```\n\n\nIf the rank of ```\nA```\n is ```\nn```\n, then the first ```\nn```\n columns of ```\nq```\n form a basis for the column space of ```\nA```\n.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Optimizing numerical array performance in Haskell\r\n                \r\nI'm working on a terrain generation algorithm for a MineCraft-like world. Currently, I'm using simplex noise based on the implementation in the paper 'Simplex Noise Demystified' [PDF], since simplex noise is supposed to be faster and to have fewer artifacts than Perlin noise. This looks fairly decent (see image), but so far it's also pretty slow.\n\n\n\nRunning the noise function 10 times (I need noise with different wavelengths for things like terrain height, temperature, tree location, etc.) with 3 octaves of noise for each block in a chunk (16x16x128 blocks), or about 1 million calls to the noise function in total, takes about 700-800 ms. This is at least an order of magnitude too slow for the purposes of generating terrain with any decent kind of speed, despite the fact that there are no obvious expensive operations in the algorithm (at least to me). Just floor, modulo, some array lookups and basic arithmetic. The algorithm (written in Haskell) is listed below. The SCC comments are for profiling. I've omitted the 2D noise functions, since they work the same way.\n\n```\ng3 :: (Floating a, RealFrac a) => a\ng3 = 1/6\n\n{-# INLINE int #-}\nint :: (Integral a, Num b) => a -> b\nint = fromIntegral\n\ngrad3 :: (Floating a, RealFrac a) => V.Vector (a,a,a)\ngrad3 = V.fromList $ [(1,1,0),(-1, 1,0),(1,-1, 0),(-1,-1, 0),\n                     (1,0,1),(-1, 0,1),(1, 0,-1),(-1, 0,-1),\n                     (0,1,1),( 0,-1,1),(0, 1,-1),( 0,-1,-1)]\n\n{-# INLINE dot3 #-}\ndot3 :: Num a => (a, a, a) -> a -> a -> a -> a\ndot3 (a,b,c) x y z = a * x + b * y + c * z\n\n{-# INLINE fastFloor #-}\nfastFloor :: RealFrac a => a -> Int\nfastFloor x = truncate (if x > 0 then x else x - 1)\n\n--Generate a random permutation for use in the noise functions\nperm :: Int -> Permutation\nperm seed = V.fromList . concat . replicate 2 . shuffle' [0..255] 256 $ mkStdGen seed\n\n--Generate 3D noise between -0.5 and 0.5\nsimplex3D :: (Floating a, RealFrac a) => Permutation -> a -> a -> a -> a\nsimplex3D p x y z = {-# SCC \"out\" #-} 16 * (n gi0 (x0,y0,z0) + n gi1 xyz1 + n gi2 xyz2 + n gi3 xyz3) where\n    (i,j,k) = {-# SCC \"ijk\" #-} (s x, s y, s z) where s a = fastFloor (a + (x + y + z) / 3)\n    (x0,y0,z0) = {-# SCC \"x0-z0\" #-} (x - int i + t, y - int j + t, z - int k + t) where t = int (i + j + k) * g3\n    (i1,j1,k1,i2,j2,k2) = {-# SCC \"i1-k2\" #-} if x0 >= y0\n        then if y0 >= z0 then (1,0,0,1,1,0) else\n             if x0 >= z0 then (1,0,0,1,0,1) else (0,0,1,1,0,1)\n        else if y0 <  z0 then (0,0,1,0,1,1) else\n             if x0 <  z0 then (0,1,0,0,1,1) else (0,1,0,1,1,0)\n    xyz1 = {-# SCC \"xyz1\" #-} (x0 - int i1 +   g3, y0 - int j1 +   g3, z0 - int k1 +   g3)\n    xyz2 = {-# SCC \"xyz2\" #-} (x0 - int i2 + 2*g3, y0 - int j2 + 2*g3, z0 - int k2 + 2*g3)\n    xyz3 = {-# SCC \"xyz3\" #-} (x0 - 1      + 3*g3, y0 - 1      + 3*g3, z0 - 1      + 3*g3)\n    (ii,jj,kk) = {-# SCC \"iijjkk\" #-} (i .&. 255, j .&. 255, k .&. 255)\n    gi0 = {-# SCC \"gi0\" #-} mod (p V.! (ii +      p V.! (jj +      p V.!  kk      ))) 12\n    gi1 = {-# SCC \"gi1\" #-} mod (p V.! (ii + i1 + p V.! (jj + j1 + p V.! (kk + k1)))) 12\n    gi2 = {-# SCC \"gi2\" #-} mod (p V.! (ii + i2 + p V.! (jj + j2 + p V.! (kk + k2)))) 12\n    gi3 = {-# SCC \"gi3\" #-} mod (p V.! (ii + 1  + p V.! (jj + 1  + p V.! (kk + 1 )))) 12\n    {-# INLINE n #-}\n    n gi (x',y',z') = {-# SCC \"n\" #-} (\\a -> if a < 0 then 0 else\n        a*a*a*a*dot3 (grad3 V.! gi) x' y' z') $ 0.6 - x'*x' - y'*y' - z'*z'\n\nharmonic :: (Num a, Fractional a) => Int -> (a -> a) -> a\nharmonic octaves noise = f octaves / (2 - 1 / int (2 ^ (octaves - 1))) where\n    f 0 = 0\n    f o = let r = int $ 2 ^ (o - 1) in noise r / r + f (o - 1)\n\n--Generate harmonic 3D noise between -0.5 and 0.5\nharmonicNoise3D :: (RealFrac a, Floating a) => Permutation -> Int -> a -> a -> a -> a -> a\nharmonicNoise3D p octaves l x y z = harmonic octaves\n    (\\f -> simplex3D p (x * f / l) (y * f / l) (z * f / l))\n```\n\n\nFor profiling, I used the following code,\n\n```\nq _ = let p = perm 0 in\n      sum [harmonicNoise3D p 3 l x y z :: Float | l <- [1..10], y <- [0..127], x <- [0..15], z <- [0..15]]\n\nmain = do start <- getCurrentTime\n          print $ q ()\n          end <- getCurrentTime\n          print $ diffUTCTime end start\n```\n\n\nwhich produces the following information:\n\n```\nCOST CENTRE                    MODULE               %time %alloc\n\nsimplex3D                      Main                  18.8   21.0\nn                              Main                  18.0   19.6\nout                            Main                  10.1    9.2\nharmonicNoise3D                Main                   9.8    4.5\nharmonic                       Main                   6.4    5.8\nint                            Main                   4.0    2.9\ngi3                            Main                   4.0    3.0\nxyz2                           Main                   3.5    5.9\ngi1                            Main                   3.4    3.4\ngi0                            Main                   3.4    2.7\nfastFloor                      Main                   3.2    0.6\nxyz1                           Main                   2.9    5.9\nijk                            Main                   2.7    3.5\ngi2                            Main                   2.7    3.3\nxyz3                           Main                   2.6    4.1\niijjkk                         Main                   1.6    2.5\ndot3                           Main                   1.6    0.7\n```\n\n\nTo compare, I also ported the algorithm to C#. Performance there was about 3 to 4 times faster, so I imagine I must be doing something wrong. But even then it's not nearly as fast as I would like. So my question is this: can anyone tell me if there are any ways to speed up my implementation and/or the algorithm in general or does anyone know of a different noise algorithm that has better performance characteristics but a similar look?\n\nUpdate:\n\nAfter following some of the suggestions offered below, the code now looks as follows:\n\n```\nmodule Noise ( Permutation, perm\n             , noise3D, simplex3D\n             ) where\n\nimport Data.Bits\nimport qualified Data.Vector.Unboxed as UV\nimport System.Random\nimport System.Random.Shuffle\n\ntype Permutation = UV.Vector Int\n\ng3 :: Double\ng3 = 1/6\n\n{-# INLINE int #-}\nint :: Int -> Double\nint = fromIntegral\n\ngrad3 :: UV.Vector (Double, Double, Double)\ngrad3 = UV.fromList $ [(1,1,0),(-1, 1,0),(1,-1, 0),(-1,-1, 0),\n                     (1,0,1),(-1, 0,1),(1, 0,-1),(-1, 0,-1),\n                     (0,1,1),( 0,-1,1),(0, 1,-1),( 0,-1,-1)]\n\n{-# INLINE dot3 #-}\ndot3 :: (Double, Double, Double) -> Double -> Double -> Double -> Double\ndot3 (a,b,c) x y z = a * x + b * y + c * z\n\n{-# INLINE fastFloor #-}\nfastFloor :: Double -> Int\nfastFloor x = truncate (if x > 0 then x else x - 1)\n\n--Generate a random permutation for use in the noise functions\nperm :: Int -> Permutation\nperm seed = UV.fromList . concat . replicate 2 . shuffle' [0..255] 256 $ mkStdGen seed\n\n--Generate 3D noise between -0.5 and 0.5\nnoise3D :: Permutation -> Double -> Double -> Double -> Double\nnoise3D p x y z = 16 * (n gi0 (x0,y0,z0) + n gi1 xyz1 + n gi2 xyz2 + n gi3 xyz3) where\n    (i,j,k) = (s x, s y, s z) where s a = fastFloor (a + (x + y + z) / 3)\n    (x0,y0,z0) = (x - int i + t, y - int j + t, z - int k + t) where t = int (i + j + k) * g3\n    (i1,j1,k1,i2,j2,k2) = if x0 >= y0\n        then if y0 >= z0 then (1,0,0,1,1,0) else\n             if x0 >= z0 then (1,0,0,1,0,1) else (0,0,1,1,0,1)\n        else if y0 <  z0 then (0,0,1,0,1,1) else\n             if x0 <  z0 then (0,1,0,0,1,1) else (0,1,0,1,1,0)\n    xyz1 = (x0 - int i1 +   g3, y0 - int j1 +   g3, z0 - int k1 +   g3)\n    xyz2 = (x0 - int i2 + 2*g3, y0 - int j2 + 2*g3, z0 - int k2 + 2*g3)\n    xyz3 = (x0 - 1      + 3*g3, y0 - 1      + 3*g3, z0 - 1      + 3*g3)\n    (ii,jj,kk) = (i .&. 255, j .&. 255, k .&. 255)\n    gi0 = rem (UV.unsafeIndex p (ii +      UV.unsafeIndex p (jj +      UV.unsafeIndex p  kk      ))) 12\n    gi1 = rem (UV.unsafeIndex p (ii + i1 + UV.unsafeIndex p (jj + j1 + UV.unsafeIndex p (kk + k1)))) 12\n    gi2 = rem (UV.unsafeIndex p (ii + i2 + UV.unsafeIndex p (jj + j2 + UV.unsafeIndex p (kk + k2)))) 12\n    gi3 = rem (UV.unsafeIndex p (ii + 1  + UV.unsafeIndex p (jj + 1  + UV.unsafeIndex p (kk + 1 )))) 12\n    {-# INLINE n #-}\n    n gi (x',y',z') = (\\a -> if a < 0 then 0 else\n        a*a*a*a*dot3 (UV.unsafeIndex grad3 gi) x' y' z') $ 0.6 - x'*x' - y'*y' - z'*z'\n\nharmonic :: Int -> (Double -> Double) -> Double\nharmonic octaves noise = f octaves / (2 - 1 / int (2 ^ (octaves - 1))) where\n    f 0 = 0\n    f o = let r = 2 ^^ (o - 1) in noise r / r + f (o - 1)\n\n--3D simplex noise\n--syntax: simplex3D permutation number_of_octaves wavelength x y z\nsimplex3D :: Permutation -> Int -> Double -> Double -> Double -> Double -> Double\nsimplex3D p octaves l x y z = harmonic octaves\n    (\\f -> noise3D p (x * f / l) (y * f / l) (z * f / l))\n```\n\n\nTogether with reducing my chunk size to 8x8x128, generating new terrain chunks now occurs at about 10-20 fps, which means moving around is now not nearly as problematic as before. Of course, any other performance improvements are still welcome.\n    ", "Answer": "\r\nThe thing that stands out initially is that your code is highly polymorphic. You should specialize your floating point type uniformly to ```\nDouble```\n, so GHC (and LLVM) have a chance of applying more aggressive optimizations.\n\nNote, for those trying to reproduce, this code imports:\n\n```\nimport qualified Data.Vector as V\nimport Data.Bits\nimport Data.Time.Clock\nimport System.Random\nimport System.Random.Shuffle\n\ntype Permutation = V.Vector Int\n```\n\n\n\n\nOk. There's lots of things you can try to improve this code.\n\nImprovements\n\nData representation\n\n\nSpecialize to a concrete floating point type, instead of polymorphic floating point functions\nReplace tuple ```\n(a,a,a)```\n with unboxed triple ```\nT !Double !Double !Double```\n\nSwitch from ```\nData.Array```\n to ```\nData.Array.Unboxed```\n for ```\nPermutations```\n\nReplace use of boxed array of triples with multidimensional unboxed array from ```\nrepa```\n package\n\n\nCompiler flags\n\n\nCompile with ```\n-O2 -fvia-C -optc-O3 -fexcess-precision -optc-march=native```\n (or equivalent with ```\n-fllvm```\n)\nIncrease spec constr threshold -- ```\n-fspec-constr-count=16```\n\n\n\nMore efficient library functions\n\n\nUse mersenne-random instead of StdGen to generate randoms\nReplace ```\nmod```\n with ```\nrem```\n\nReplace ```\nV.!```\n indexing with unchecked indexing ```\nVU.unsafeIndex```\n (after moving to ```\nData.Vector.Unboxed```\n\n\n\nRuntime settings\n\n\nIncrease the default allocation area: ```\n-A20M```\n or ```\n-H```\n\n\n\n\n\nAlso, check your algorithm is identical to the C# one, and you're using the same data structures.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Multiply 2 sparse matrices using cusp library\r\n                \r\nIm new to using cusp library for cuda. I'm trying to implement revised simplex algorithm for CUDA. For that I need to multiply 2 sparse matrices to update the base matrix.\n\nSo the question is - how can I multiply 2 sparse matrices(doesn't really matter in what format) using cusp library? Also is there a way to know how many nonzero elements is the result matrix going to contain(for memory allocation purposes)?\n\nI tried:\n\n```\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n#include <stdlib.h>\n#include <stdio.h>\n#include \"cusparse.h\"\n#include <cusp/version.h>\n#include <cusp/multiply.h>\n#include <cusp/array2d.h>\n#include <cusp/print.h>\n#include <cusp/coo_matrix.h>\n\nint main(void)\n{\n    cusp::coo_matrix<int,double,cusp::device_memory> A(2,2,2);\n\n    A.values[0] = 1;\n    A.row_indices[0] = 0;\n    A.column_indices[0]= 0;\n\n    A.values[1] = 1;\n    A.row_indices[1] = 1;\n    A.column_indices[1]= 1;\n\n    cusp::coo_matrix<int, double, cusp::device_memory> B(2,2,4);\n\n    B.values[0] = 1;\n    B.row_indices[0] = 0;\n    B.column_indices[0]= 0;\n\n    B.values[1] = 2;\n    B.row_indices[1] = 0;\n    B.column_indices[1]= 1;\n\n    B.values[2] = 3;\n    B.row_indices[2] = 1;\n    B.column_indices[2]= 0;\n\n    B.values[3] = 4;\n    B.row_indices[3] = 1;\n    B.column_indices[3]= 1;\n\n    cusp::print(A);\n    cusp::print(B);\n\n    cusp::coo_matrix<int,double, cusp::device_memory> C(2,2,4);\n\n    cusp::multiply(A,B,C);\n\n    cusp::print(C);\n\n}\n```\n\n\nAs cusp:multiply() was the only function for multiplication I found.\n\ncusp v.0.4\nCUDA v.5.5\n    ", "Answer": "\r\n\n  how can I multiply 2 sparse matrices(doesn't really matter in what format) using cusp library? \n\n\nYes, ```\ncusp::multiply```\n is the correct function for this.  Your code works correctly for me.\n\n\n  Also is there a way to know how many nonzero elements is the result matrix going to contain(for memory allocation purposes)?\n\n\nYou don't need to allocate it ahead of time.  Change your definition of the ```\nC```\n matrix to this:\n\n```\ncusp::coo_matrix<int,double, cusp::device_memory> C;\n```\n\n\nand your code still works correctly.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Worse is better. Is there an example?\r\n                \r\nIs there a widely-used algorithm that has time complexity worse than that of another known algorithm but it is a better choice in all practical situations (worse complexity but better otherwise)? \n\nAn acceptable answer might be in a form:\n\n\n  There are algorithms ```\nA```\n and ```\nB```\n that\n  have ```\nO(N**2)```\n and ```\nO(N)```\n time\n  complexity correspondingly, but ```\nB```\n\n  has such a big constant that it has no\n  advantages over ```\nA```\n for inputs less\n  then a number of atoms in the\n  Universe.\n\n\nExamples highlights from the answers:\n\n\nSimplex algorithm -- worst-case is exponential time  -- vs. known polynomial-time algorithms for convex optimization problems.\nA naive median of medians algorithm -- worst-case O(N**2) vs. known O(N) algorithm.\nBacktracking regex engines -- worst-case exponential vs. O(N) Thompson NFA -based engines.  \n\n\nAll these examples exploit worst-case vs. average scenarios.\n\nAre there examples that do not rely on the difference between the worst case vs. average case scenario?\n\n\n\nRelated:\n\n\nThe Rise of ``Worse is Better''. (For the purpose of this question the \"Worse is Better\" phrase is used in a narrower (namely -- algorithmic time-complexity) sense than in the article)\nPython's Design Philosophy:\n\n\n  The ABC group strived for perfection.\n  For example, they used tree-based data\n  structure algorithms that were proven\n  to be optimal for asymptotically large\n  collections (but were not so great for\n  small collections).\n\n\nThis example would be the answer if there were no computers capable of storing these large collections (in other words large is not large enough in this case).\nCoppersmith–Winograd algorithm for square matrix multiplication is a good example (it is the fastest (2008) but it is inferior to worse algorithms). Any others?\nFrom the wikipedia article: \"It is not used in practice because it only provides an advantage for matrices so large that they cannot be processed by modern hardware (Robinson 2005).\" \n\n    ", "Answer": "\r\nquick-sort has worst case time complexity of O(N^2) but it is usually considered better than other sorting algorithms which have O(N log n) time complexity in the worst case.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Alpha Shapes in 3D - Follow Up\r\n                \r\nProblem\n\nI am trying to implement Edelsbrunner's Algorithm for the alpha shape of a 3D point cloud in python as presented in this SO post. However, I'm having trouble plotting results. Half my sphere looks good, and the other half garbled.\nI suspect it may have something to do with the fact that I have negative coordinates, but I'm not sure.\n\nDefinitions\n\nI'm adding these so programmers can contribute without being bogged down by math. These are simplified definitions and not meant to be precise (Feel free to skip this part; for more, see see Introduction to Alpha Shapes and Discrete Differential Geometry):\n\nDelaunay triangulation: for a 2D point set, a tesselation of the points into triangles (i.e. \"triangulation\") where the circumscribed circle (i.e. \"circumcircle\") about every triangle contains no other points in the set. For 3D points, replace \"triangle\" with \"tetrahedron\" and \"circumcircle\" with \"circumsphere\".\n\nAffinely independent: a collection of points ```\np0, ..., pk```\n such that all vectors ```\nvi := pi-p0```\n are linearly independent (i.e. in 2D not collinear, in 3D not coplanar); also called \"points in general position\"\n\nk-simplex: the convex hull of k+1 affinely-independent points; we call the points its vertices.\n\n\n\n0-simplex = point (consists of 0+1 = 1 points)\n1-simplex = line (consists of 1+1 = 2 points)\n2-simplex = triangle (consists of 2+1 = 3 points)\n3-simplex = tetrahedron (consists of 3+1 = 4 points)\n\n\nface: any simplex whose vertices are a subset of the vertices of another simplex; i.e. \"a part of a simplex\"\n\n(geometric) simplicial complex: a collection of simplices where (1) the intersection of two simplices is a simplex, and (2) every face of a simplex is in the complex; i.e. \"a bunch of simplices\"\n\nalpha-exposed: a simplex within a point set where the circle (2D) or ball (3D) of radius alpha through its vertices doesn't contain any other point in the point set\n\nalpha shape: the boundary of all alpha-exposed simplices of a point set\n\n\nAlgorithm\n\nEdelsbrunner's Algorithm is as follows:\n\nGiven a point cloud ```\npts```\n:\n\nCompute the Delaunay triangulation ```\nDT```\n of the point cloud\nFind the alpha-complex: search all simplices in the Delaunay triangulation and    (a) if any ball around a simplex is empty and has\na radius less than ```\nalpha```\n (called the \"alpha test\"), then add it to the\nalpha complex\nThe boundary of the alpha complex is the alpha shape\n\n\nCode\n\n```\nfrom scipy.spatial import Delaunay\nimport numpy as np\nfrom collections import defaultdict\nfrom matplotlib import pyplot as plt\nimport pyvista as pv\n\nfig = plt.figure()\nax = plt.axes(projection=\"3d\")\n\nplotter = pv.Plotter()\n\ndef alpha_shape_3D(pos, alpha):\n    \"\"\"\n    Compute the alpha shape (concave hull) of a set of 3D points.\n    Parameters:\n        pos - np.array of shape (n,3) points.\n        alpha - alpha value.\n    return\n        outer surface vertex indices, edge indices, and triangle indices\n    \"\"\"\n\n    tetra = Delaunay(pos)\n    # Find radius of the circumsphere.\n    # By definition, radius of the sphere fitting inside the tetrahedral needs \n    # to be smaller than alpha value\n    # http://mathworld.wolfram.com/Circumsphere.html\n    tetrapos = np.take(pos,tetra.vertices,axis=0)\n    normsq = np.sum(tetrapos**2,axis=2)[:,:,None]\n    ones = np.ones((tetrapos.shape[0],tetrapos.shape[1],1))\n    a = np.linalg.det(np.concatenate((tetrapos,ones),axis=2))\n    Dx = np.linalg.det(np.concatenate((normsq,tetrapos[:,:,[1,2]],ones),axis=2))\n    Dy = -np.linalg.det(np.concatenate((normsq,tetrapos[:,:,[0,2]],ones),axis=2))\n    Dz = np.linalg.det(np.concatenate((normsq,tetrapos[:,:,[0,1]],ones),axis=2))\n    c = np.linalg.det(np.concatenate((normsq,tetrapos),axis=2))\n    r = np.sqrt(Dx**2+Dy**2+Dz**2-4*a*c)/(2*np.abs(a))\n\n    # Find tetrahedrals\n    tetras = tetra.vertices[r<alpha,:]\n    # triangles\n    TriComb = np.array([(0, 1, 2), (0, 1, 3), (0, 2, 3), (1, 2, 3)])\n    Triangles = tetras[:,TriComb].reshape(-1,3)\n    Triangles = np.sort(Triangles,axis=1)\n    # Remove triangles that occurs twice, because they are within shapes\n    TrianglesDict = defaultdict(int)\n    for tri in Triangles:TrianglesDict[tuple(tri)] += 1\n    Triangles=np.array([tri for tri in TrianglesDict if TrianglesDict[tri] ==1])\n    #edges\n    EdgeComb=np.array([(0, 1), (0, 2), (1, 2)])\n    Edges=Triangles[:,EdgeComb].reshape(-1,2)\n    Edges=np.sort(Edges,axis=1)\n    Edges=np.unique(Edges,axis=0)\n\n    Vertices = np.unique(Edges)\n    return Vertices,Edges,Triangles\n\ndef ptcloud_sphere():\n    r = 3\n    phi = np.linspace(0, np.pi, 18)\n    theta = np.linspace(0, 2 * np.pi, 36)\n\n    PHI, THETA = np.meshgrid(phi, theta)\n\n    x = r * np.sin(PHI) * np.cos(THETA)\n    y = r * np.sin(PHI) * np.sin(THETA)\n    z = r * np.cos(PHI)\n\n    ax.scatter(x, y, z)\n    plt.show()\n    \n    pts = np.stack((x.ravel(), y.ravel(), z.ravel()), axis=1)\n\n    return np.unique(pts, axis=0)\n\n\nif __name__ == \"__main__\":\n    pts = ptcloud_sphere()\n\n    verts, edges, faces = alpha_shape_3D(pts, alpha=10)\n\n    faces_conn_list = np.insert(faces, 0, 3, axis=1)\n    num_faces = faces.shape[0]\n\n    mesh = pv.PolyData(pts[verts], faces_conn_list, n_faces=num_faces)\n\n    plotter.add_mesh(mesh, reset_camera=True)\n    plotter.show()\n```\n\nOutput\nPoint Cloud:\n\nAlpha Shape:\n\nUpdate 09-SEP-2021\nPer @akaszynski, the problem does indeed appear to be a combination of unique and negative points. He fixed this issue with the following:\n```\npts = np.stack((x.ravel(), y.ravel(), z.ravel()), axis=1) + 10\n\nreturn np.unique(pts, axis=0) - 10\n```\n\n\nHowever, if someone could perform a deeper investigation to determine why this is the problem, that would help.\nUpdate 09-SEP-2021 #2\nPer @AndrasDeak, both ```\npyvista```\n and ```\nVTK```\n support the creation of 2d and 3d alpha shapes. The ```\npyvista```\n function ```\ndelaunay_3d```\n uses ```\nvtkDelaunay3D```\n under the hood, which accepts an ```\nalpha```\n parameter.\n(See vtkDelaunay3D docs)\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Implementing Simplex Method infinite loop\r\n                \r\nI am trying to implement a simplex algorithm following the rules I was given at my optimization course. The problem is\n\n```\nmin c'*x    s.t.\n    Ax = b\n    x >= 0\n```\n\n\nAll vectors are assumes to be columns, ```\n'```\n denotes the transpose. The algorithm should also return the solution to dual LP. The rules to follow are:\n\n\n\nHere, A_J denotes columns from A with indices in J and x_J, x_K denotes elements of vector x with indices in J or K respectively. Vector a_s is column s of matrix A.\n\nNow I do not understand how this algorithm takes care of condition ```\nx >= 0```\n, but I decided to give it a try and follow it step by step. I used Matlab for this and got the following code.\n\n```\nX = zeros(n, 1);\nY = zeros(m, 1);\n\n% i. Choose starting basis J and K = {1,2,...,n} \\ J\nJ = [4 5 6]  % for our problem\nK = setdiff(1:n, J)\n\n% this while is for goto\nwhile 1\n    % ii. Solve system A_J*\\bar{x}_J = b.\n    xbar = A(:,J) \\ b\n\n    % iii. Calculate value of criterion function with respect to current x_J.\n    fval = c(J)' * xbar\n\n    % iv. Calculate dual solution y from A_J^T*y = c_J.\n    y = A(:,J)' \\ c(J)\n\n    % v. Calculate \\bar{c}^T = c_K^T - u^T A_K. If \\bar{c}^T >= 0, we have\n    % found the optimal solution. If not, select the smallest s \\in K, such\n    % that c_s < 0. Variable x_s enters basis.\n    cbar = c(K)' - c(J)' * inv(A(:,J)) * A(:,K)\n    cbar = cbar'\n\n    tmp = findnegative(cbar)\n    if tmp == -1  % we have found the optimal solution since cbar >= 0\n        X(J) = xbar;\n        Y = y;\n        FVAL = fval;\n        return\n    end\n\n    s = findnegative(c, K)  %x_s enters basis\n\n    % vi. Solve system A_J*\\bar{a} = a_s. If \\bar{a} <= 0, then the problem is\n    % unbounded.\n    abar = A(:,J) \\ A(:,s)\n\n    if findpositive(abar) == -1  % we failed to find positive number\n        disp('The problem is unbounded.')\n        return;\n    end\n\n    % vii. Calculate v = \\bar{x}_J / \\bar{a} and find the smallest rho \\in J,\n    % such that v_rho > 0. Variable x_rho exits basis.\n    v = xbar ./ abar\n    rho = J(findpositive(v))\n\n    % viii. Update J and K and goto ii.\n    J = setdiff(J, rho)\n    J = union(J, s)\n    K = setdiff(K, s)\n    K = union(K, rho)\nend\n```\n\n\nFunctions ```\nfindpositive(x)```\n and ```\nfindnegative(x, S)```\n return the first index of positive or negative value in ```\nx```\n. ```\nS```\n is the set of indices, over which we look at. If ```\nS```\n is omitted, whole vector is checked. Semicolons are omitted for debugging purposes.\n\nThe problem I tested this code on is\n\n```\nc = [-3 -1 -3 zeros(1,3)];\nA = [2 1 1; 1 2 3; 2 2 1];\nA = [A eye(3)];\nb = [2; 5; 6];\n```\n\n\nThe reason for ```\nzeros(1,3)```\n and ```\neye(3)```\n is that the problem is inequalities and we need slack variables. I have set starting basis to ```\n[4 5 6]```\n because the notes say that starting basis should be set to slack variables.\n\nNow, what happens during execution is that on first run of ```\nwhile```\n, variable with index ```\n1```\n enters basis (in Matlab, indices go from 1 on) and ```\n4```\n exits it and that is reasonable. On the second run, ```\n2```\n enters the basis (since it is the smallest index such that ```\nc(idx) < 0```\n and ```\n1```\n leaves it. But now on the next iteration, ```\n1```\n enters basis again and I understand why it enters, because it is the smallest index, such that ```\nc(idx) < 0```\n. But here the looping starts. I assume that should not have happened, but following the rules I cannot see how to prevent this.\n\nI guess that there has to be something wrong with my interpretation of the notes but I just cannot see where I am wrong. I also remember that when we solved LP on the paper, we were updating our subjective function on each go, since when a variable entered basis, we removed it from the subjective function and expressed that variable in subj. function with the expression from one of the equalities, but I assume that is different algorithm.\n\nAny remarks or help will be highly appreciated.\n    ", "Answer": "\r\nThe problem has been solved. Turned out that the point 7 in the notes was wrong. Instead, point 7 should be\n\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Multivariate gradient descent for Python\r\n                \r\nI want to find the local maximum from a start vector (numpy array). For that I want to use the very simple gradient decent algorithm where I can set the maximum step size manually. Is there an implementation in scipy.optimize or somewhere else for Python-3? It needs to be multivariate optimisation unconstrained and it cannot be anything fancy like \"Nelder-Mead simplex algorithm\", \"BFGS\", \"conjugate gradient\", \"stochastic gradient descent\" or anything else. I need the algorithm to follow the gradient for each step - nothing more. I am able to provide the gradient of my function.\n\nObviously gradient descent is pretty easy to implement oneself. But with a canonical implementation I'd have one thing less to unit-test. It would seems strange that it needs to be implemented by oneself just because it is simple.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Zero multiplier for the value in objective function doesn't give the most feasible solution\r\n                \r\nI'm using Pulp to solve a linear program (also getting the same result with scipy). So something wrong with my linear program formulation, or I don't know some tricky details on how simplex algorithm works.\n\nHere is objective function for minimisation, notice that multiplier for ```\nx2```\n is ```\n0```\n, so I don't expect ```\nx1```\n or ```\nx2```\n to have any value except ```\n0```\n, because ```\nx3```\n doesn't have max constraint and ```\n-1 * x3```\n is able to provide more value for minimisation:\n\n\n\nSystem of linear equations:\n\n\n\nAs a solution I'm getting ```\nx2 = 20```\n even if its multiplier in objective function is ```\n0```\n.\n\n\n\nIf in objective function I set ```\n-2 * x3```\n, then it works just fine.\n    ", "Answer": "\r\nThe solution you've posted gives the objective = -380. Check ```\nx=[20,0,0,20,0,20,20,0]```\n, the objective function is -380 as well, which implies it's optimal too, hence, you have infinitely many solutions (it's easy to show that any convex combination of this two points is optimal, see any Linear Programming book). The problem is your PuLP solver stopped when it's encountered one optimal extreme point. If you are interested in getting all the optimal extreme points I would recommend you to use Cplex (it's not free but you might be eligible for IBM academic initiatives). Also, you can set a solution method to Dual Simlex in your PuLP solver to make it go in different direction and there is a chance you will get the other extreme point. \n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Choosing Barrier for VRP\r\n                \r\nI'm solving the VRP with Scip and want to choose the algorithm. In some of my instances, Scip solves the problem without the branch-and-bound tree in the root node; here I think cutting planes are executed. Cplex for example can choose prim Simplex or dual Simplex etc. to solve the Problem in this case.\nIs there a possibility in Scip too? I use the parameters lp/initalgorithm=b (barrier) and lp/resolvealgorithm=b to make sure, in the branch-and-bound tree only this algorithm is used. But when Scip solves the problem in the root node, these parameters change nothing.\nThanks for your help!\n    ", "Answer": "\r\nSo if I understand you correctly you want to always use barrier to solve the LP relaxations of your problem?\nYou need to make sure that the LP solver you are using supports this. If you use SoPlex as the LP solver in SCIP it does not have a barrier algorithm implemented and will fallback to solving with dual Simplex instead.\nThe LP solvers that support barrier are Cplex, Xpress, Gurobi, Mosek, and CLP\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Solving Negative coefficients in linear program\r\n                \r\nI am trying to solve a assignment problem using linear programming.\nI am using the simplex algorithm mentioned in CLRS.\n\nConsider the below example:\n```\n\n          --(1/1)--->|a|---(10/1)------>|d|----------->\n         |            |                  ^            |\n         |            |_(7/1)__          |            |\n        |s|            ________|_(12/1)__|           |t|\n         |            |        |_______               |\n         |            |                |              |\n         |            |                v              |\n          --(1/1)--->|b|---(10/1)---->|c|--(1/1)----->\n```\n\n\nVertex a and b are the persons.\n\nVertex c and d are the jobs.\n\nI have modeled it as a min cost max flow problem.\n\nSource S and Sink t has been added.\n\nAll the edge weights have been set to 1.\n\nEdge cost from source to vertex a and b is set to 1.\n\nEdge cost from d,c to sink is set to 1.\n\nThe (a/b) values in the edge represent (Cost/Flow Capacity) for that edge.\n\nI use W to represent edge cost and C for capacity.\n\n```\n\n    The linear program is:\n        Minimize,\n             Summation(W(uv).f(uv)) over all uv.\n\n```\n    Such that,\n         f(uv) >= 0 , for all (u,v) in E\n\n         f(uv) <= C(u,v) , C(u,v)=1 in this case, for all (u,v) in E\n\n         Flow conservation for each vertex except the source and the sink.\n         So Sum(f(uv)) = Sum(f(vu)), for all u,v\n\n         Flow demand of atleast 2, since we need to match 2 persons.\n         f(sa) + f(sb) = 2\n```\n\n\n```\n\n\n```\n\nThe Standard Form is:\n    Maximize,\n         -(Summation(W(uv).f(uv)) over all uv)\n\n```\n       Such that,\n         f(uv) >= 0 , for all (u,v) in E\n\n         f(uv) <= C(u,v) , C(u,v)=1 in this case, for all (u,v) in E\n\n         Flow conservation for each vertex except the source and the sink.\n         So Sum(f(uv)) = Sum(f(vu)), for all u,v\n\n         Demand:\n         f(sa) + f(sb) = 2\n```\n\n\n```\n\n\n```\n\nWhich reduces to \n   maximize (- { W(sa).f(sa) + W(sb).f(sb) + W(ad).f(ad) + W(ac).f(ac) + W(bd).f(bd) + W(bc).f(bc) + W(dt).f(dt) + W(ct).f(ct) } )\n```\n\n\nSubstituting x1 for sa, x2 for sb, x3 for ad, x4 for ac, x5 for bd, x6 for bc, x7 for dt, x8 for ct.\n\nFinally, we get something like this:\n```\n\n    Maximize\n        -x1-x2-10(x3)-7(x4)-12(x5)-7(x6)-x7-x8  (objective function)\n    Given that (constraints)\n      Capacity constraints:\n         x{1-8} <= 1\n      Flow conversations:\n         x1 = x3+x4 --> ( x1-x3-x4 <=0 & -x1+x3+x4 <= 0)\n         x2 = x6+x5 --> ( x2-x6-x5 <=0 & -x2+x6+x5 <= 0)\n         x7 = x3+x5 --> ( x7-x3-x5 <=0 & -x7+x3+x5 <= 0)\n         x8 = x4+x6 --> ( x8-x4-x6 <=0 & -x8+x4+x6 <= 0)\n      Demand:\n         x1 + x2 =2 --> ( x1+x2 <=2 && -x1-x2 <=2)\n```\n\n\nAccording to CLRS, \nThe first part of simplex is to obtain a initial slack form with a feasible solution using the INITIALISE-SIMPLEX method.\n\nThis method checks if there are any negative values on the right hand side of the inequalities in the constraints.\nIf not it returns the current setting as the initial slack form for the main algorithm to process.\n\nIn the main algorithm the first step is to choose a Non-basic variable whose coefficient is non-negative in the objective function.\n\nBut in this case, all the variables in the objective function have a negative coefficient(since we multiplied the initial obj function to convert minimization to maximization form).\n\nSo simplex will terminate with 0 as flow values for all the edges ?\n\nI fed the above problem to \"linear_solver in google OR-Tools library\".\nAnd it returns the correct result as 21 and x3 =1 & x4 =0 & x5 =0 & x6 =1\n\nSo i think my equations are right.\n\nCLRS doesn't handle this case, or am i missing something ?\n    ", "Answer": "\r\nActually, the problem with the above problem is that the \"Initialize-Simplex\" method would need to be more complicated in this case.  Since x_i = 0 (forall i) is not a feasible solution to the problem, you would need to do a \"phase-1\" operation to find an initial basic feasible solution to the problem.  (A solution that satisfies x1+x2 = 2).\nI suggest googling \"phase-1 simplex method\"  http://www.math.ubc.ca/~israel/m340/artif.pdf.\nI would not suggest CLRS as a good book for explaining all details of the simplex method.  An introductory Operations Research textbook like Hillier and Lieberman or Winston would be better.  Best of luck!\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Algorithm-finding-dedicated-sum-from-the-population-of-variables\r\n                \r\nI need a way of finding an exact value made of the sum of variables chosen from the population. The algorithm can find just the first solution or all. So we can have 10, 20, or 30 different numbers and we will sum some of them to get a desirable number. As an example we have a population of the below numbers: -2,-1,1,2,3,5,8,10 and we try to get 6 - this can be made of 8 and -2, 1 + 5 etc. I need at least 2 decimal places to consider as well for accuracy and ideally, the sum of variables will be exact to the asking value.\nThanks for any advice and help on this:)\nI build a model Using the simplex method in Excel but I need the solution in Python.\n    ", "Answer": "\r\nThis is the subset sum problem, which is an NP Complete problem.\nThere is a known pseudo-polynomial solution for it, if the numbers are integers. In your case, you need to consider numbers only to 2nd decimal point, so you could convert the problem into integers by multiplying by 1001, and then run the pseudo-polynomial algorithm.\nIt will works quite nicely and efficiently - if the range of numbers you have is quite small (Complexity is ```\nO(n*W)```\n, where ```\nW```\n is the sum of numbers in absolute value).\nAppendix:\nPseudo polynomial time solution is Dynamic Programming adaptation of the following recursive formula:\n```\nk is the desired number\nn is the total number of elements in list.\n\n// stop clause: Found a sum\nD(k, i) = true   | for all 0 <= i < n\n// Stop clause: failing attempt, cannot find sum in this branch.\nD(x, n) = false  | x != k\n// Recursive step, either take the current element or skip it.\nD(x, i) = D(x + arr[i], i+1) OR D(x, i+1)\n\nStart from D(0,0)\n```\n\nIf this is not the case, and the range of numbers is quite high, you might have to go with brute force solution, of checking all possible subsets. This solution is of course exponential, and processing it is in ```\nO(2^n)```\n .\n\n(1) Consider rounding if needed, but that's a simple preprocessing that doesn't affect the answer.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Better understanding of Simplex Noise\r\n                \r\nWell it's needless to say that I've recently found simplex noise. The algorithm for an absolute different amount of possibilities and so on which is great for creating textures, height maps and time-dependent graphics.\n\nI already have the function in the program and it works wonders, the problem is that as a \"mathematician\" I just can't stand not understanding thoroughly how the function works. \n\nBasically the only thing I don't really understand is if the \"skewed\" coordinates are the coordinates of the simplical or orthogonal grid. And also that if the inputs define which of these grids: the simplical or orthogonal.\n\nI'm certain I could figure the rest out but I just don't understand which grid belongs to which coordinates. Also any video, book, link that at least shows a visual step-by-step process would be very useful.\n\nNote:\n\nIf a questions or doubt arises please leave a comment. Thanks!!!\n    ", "Answer": "\r\nI know this is a year old almost, but in case someone has similar issues.\n\nThe coordinates begin as simplical and then are skewed to the orthogonal plane.  They are then skewed back. The math behind it can be a bit tricky. I had similar problems until I got this helpful reply from a redditor in /r/math.\n\nhttp://www.reddit.com/r/math/comments/279yzt/guidance_on_simplex_noise/\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Does z3 support rational arithmetic for its input constraints?\r\n                \r\nIn fact, does the SMT-LIB standard have a rational (not just real) sort? Going by its website, it does not.\nIf x is a rational and we have a constraint x^2 = 2, then we should get back ``unsatisfiable''. The closest I could get to encoding that constraint is the following:\n\n```\n;;(set-logic QF_NRA) ;; intentionally commented out  \n(declare-const x Real)  \n(assert (= (* x x) 2.0))  \n(check-sat)  \n(get-model)  \n```\n\n\nfor which z3 returns a solution, as there is a solution (irrational) in the reals. I do understand that z3 has its own rational library, which it uses, for instance, when solving QF_LRA constraints using an adaptation of the Simplex algorithm. On a related note, is there an SMT solver that supports rationals at the input level?\n    ", "Answer": "\r\nI'm sure it's possible to define a Rational sort using two integers as suggested by Nikolaj -- I would be interested to see that.  It might be easier to just use the Real sort, and any time you want a rational, assert that it's equal to the ratio of two Ints.  For example:\n\n```\n(set-option :pp.decimal true)\n(declare-const x Real)\n(declare-const p Int)\n(declare-const q Int)\n(assert (> q 0))\n(assert (= x (/ p q)))\n(assert (= x 0.5))\n(check-sat)\n(get-value (x p q)) \n```\n\n\nThis quickly comes back with\n\n```\nsat\n((x 0.5)\n (p 1)\n (q 2))\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Is there a well understood algorithm or solution model for this meeting scheduling scenario?\r\n                \r\nI  have a complex problem and I want to know if an existing and well understood solution model exists or applies, like the Traveling Salesman problem.\n\nInput:\n\n\nA calendar of N time events, defined by starting and finishing time, and place.\nThe capacity of each meeting place (maximum amount of people it can simultaneously hold)\nA set of pairs ```\n(Ai,Aj)```\n which indicates that attendant ```\nAi```\n wishes to meet with attendat ```\nAj```\n, and ```\nAj```\n accepted that invitation.\n\n\nOutput:\n\n\nFor each assistant ```\nA```\n, a cronogram of all the events he will attend. The main criteria is that each attendants should meet as many of the attendants who accepted his invites as possible, satisfying the space constraints.\n\n\nSo far, we thought of solving with backtracking (trying out all possible solutions), and using linear programming (i.e. defining a model and solving with the simplex algorithm)\n\nUpdate: If ```\nAi```\n already met ```\nAj```\n in some event, they don't need to meet anymore (they have already met).\n    ", "Answer": "\r\nYour problem is as hard as minimum maximal matching problem in interval graphs, w.l.o.g Assume capacity of rooms is ```\n2```\n means they can handle only one meeting in time. You can model your problem with Interval graphs, each interval (for each people) is one node. Also edges are if A_i & A_j has common time and also they want to see each other, set weight of edges to the amount of time they should see each other, . If you find the minimum maximal matching in this graph, you can find the solution for your restricted case. But notice that this graph is n-partite and also each part is interval graph.\n\nP.S: note that if the amount of time that people should be with each other is fixed this will be more easier than weighted one. \n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Handling box constraints in Nelder-Mead optimisation by distorting the parameter space\r\n                \r\nI have a question on a specific implementation of a Nelder-Mead algorithm (1) that handles box contraints in an unusual way. I cannot find in anything about it in any paper (25 papers), textbook (searched 4 of them) or the internet.\n\nI have a typical optimisation problem: ```\nmin f(x)```\n with a box constraint ```\n-0.25 <= x_i <= 250```\n\n\nThe expected approach would be using a penalty function and make sure that all instances of ```\nf(x)```\n are \"unattractive\" when x is out of bounds. \n\nThe algorithm works differently: the implementation in question does not touch ```\nf(x)```\n. Instead it distorts the parameter space using an inverse hyperbolic tangens ```\natanh(f)```\n. Now the simplex algorithm can freely operate in a space without bounds and pick just any point. Before it gets ```\nf(x)```\n in order to assess the solution at x the algorithm switches back into normal space.\n\nAt a first glance I found the idea ingenious. This way we avoid the disadvantages of penalty functions. But now I am having doubts. The distorted space affects termination behaviour. One termination criterion is the size of the simplex. By inflating the parameter space with ```\natanh(x)```\n we also inflate the simplex size. \n\nExperiments with the algorithm also show that it does not work as intended. I do not yet understand how this happens, but I do get results that are out of bounds. I can say that almost half of the returned local minima are out of bounds.\n\nAs an example, take a look at nmkb() optimising the rosenbrook function when we gradually change the width of the box constraint:\n\n```\nrosbkext <- function(x) {\n  # Extended Rosenbrock function\n  n <- length(x)\n  sum (100*(x[1:(n-1)]^2 - x[2:n])^2 + (x[1:(n-1)] - 1)^2)\n}\n\nnp <- 6 #12\nfor (box in c(2, 4, 12, 24, 32, 64, 128)) {\n  set.seed(123)\n  p0 <- rnorm(np)\n  p0[p0 > +2] <- +2 - 1E-8\n  p0[p0 < -2] <- -2 + 1E-8\n\n  ctrl <- list(maxfeval = 5E4, tol = 1E-8)\n  o <- nmkb(fn = rosbkext, par = p0, lower = -box, upper = +box, control = ctrl)\n  print(o$message)\n  cat(\"f(\", format(o$par, digits = 2), \") =\", format(o$value, digits=3), \"\\n\")\n}\n```\n\n\nThe output shows that it claims to converge but it does not in three cases. And it does that for bounds of (-2,2) and (-12,12). I might accept that but then it also fails at (-128, 128). I also tried the same with the unconstrained dfoptim::nmk(). No trouble there. It converges perfectly.\n\n```\n[1] \"Successful convergence\"\nf( -0.99  0.98  0.97  0.95  0.90  0.81 ) = 3.97 \n[1] \"Successful convergence\"\nf( 1 1 1 1 1 1 ) = 4.42e-09 \n[1] \"Successful convergence\"\nf( -0.99  0.98  0.97  0.95  0.90  0.81 ) = 3.97 \n[1] \"Successful convergence\"\nf( 1 1 1 1 1 1 ) = 1.3e-08 \n[1] \"Successful convergence\"\nf( 1 1 1 1 1 1 ) = 4.22e-09 \n[1] \"Successful convergence\"\nf( 1 1 1 1 1 1 ) = 8.22e-09 \n[1] \"Successful convergence\"\nf( -0.99  0.98  0.97  0.95  0.90  0.81 ) = 3.97 \n```\n\n\nWhy does the constrained algorithm have more trouble converging than the unconstrained one?\n\n\n\nFootnote (1):  I am referring to the Nelder-Mead implementation used in the optimx package in R. This package calls another package dfoptim with the nmkb-function.\n    ", "Answer": "\r\n(This question has nothing to do with ```\noptimx```\n, which is just a wrapper for R packages providing unconstrained optimization.)\n\nThe function in question is ```\nnmkb()```\n in the dfoptim package for gradient-free optimization routines. The approach to transform bounded regions into unbounded spaces is a common one and can be applied with many different transformation functions, sometimes depending on the kind of the boundary and/or the type of the objective function. It may also be applied, e.g., to transform unbounded integration domains into bounded ones.\n\nThe approach is problematic if the optimum lies at the boundary, because the optimal point will be sent to (nearly) infinity and cannot ultimately be reached. The routine will not converge or the solution be quite inaccurate.\n\nIf you think the algorithm is not working correctly, you should write to the authors of that package and -- that is important -- add one or two examples for what you think are bugs or incorrect solutions. Without explicit code examples no one here is able to help you.\n\n(1) Those transformations define bijective maps between bounded and unbounded regions and the theory behind this approach is obvious. You may read about possible transformations in books on multivariate calculus.\n\n(2) The approach with penalties outside the bounds has its own drawbacks, for instance the target function will not be smooth at the boundaries, and the BFGS method may not be appropriate anymore.\n\n(3) You could try the Hooke-Jeeves algorithm through function ```\nhjkb()```\n in the same dfoptim package. It will be slower, but uses a different approach for treating the boundaries, no transformations involved.\n\nEDIT (after discussion with Erwin Kalvelagen above)\n\nThere appear to be local minima (with some coordinates negative).\nIf you set the lower bounds to 0, ```\nnmkb()```\n will find the global minimum ```\n(1,1,1,1,1,1)```\n in any case.\nWatch out: starting values have to be feasible, that is all their coordinates greater 0.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Segmentation fault, when passing functions with array arguments to subroutine in Fortran\r\n                \r\nI am working on a project (which is due tomorrow :/) and encountered a problem when I tried to use a simplex algorithm on a function I wrote myself. It didn't work, and after now 5 hours of searching and experimenting, I found out the following:\n\nWhen I pass a function to a subroutine, this function can't have any array arguments. Is this true? Because in the code that I am supposed to use it evidently SHOULD work.\n\nI am using the ifort compiler. See below for a minimum example, which I basicaly took from http://malayamaarutham.blogspot.de/2006/02/passing-function-names-as-arguments-in.html\n\n```\n  ! Author : Kamaraju S Kusumanchi\n  ! Email  : kamaraju@gmail.com\n  ! Last edited : Sun Feb  5 2006\n  !\n  ! Sample program demonstrating the use of external attribute.        This program\n  ! shows how to pass function names as arguments in Fortran 90       programs.\n  !\n  ! Compilation and execution steps\n  ! $gfortran passing_functions.f90 -o passing_functions\n  ! $./passing_functions\n  !  beta =    5.500000\n  !  beta =    1.500000\n  !\n  ! I would appreciate any comments, feedback, criticism,       mistakes, errors etc.,\n  !   (however minor they are)\n  !\n  module dummy\n    implicit none\n  contains\n  !------------------------------------------------------------------------------\n  function func1(a)\n    implicit none\n    real :: a\n    real :: func1\n\n    func1 = a+5\n  end function func1\n  !------------------------------------------------------------------------------\n  function func2(b)\n    implicit none\n    real :: b(:)\n    real :: func2\n\n    func2 = b(1)\n  end function func2\n  !------------------------------------------------------------------------------\n  function func3(dyn_func, c)\n    implicit none\n    real :: c\n    real, external :: dyn_func\n    real :: func3\n\n    func3 = dyn_func(c)\n  end function func3\n  !------------------------------------------------------------------------------\n  function func4(dyn_func, c)\n    implicit none\n    real :: c(*)\n    real, external :: dyn_func\n    real :: func4\n\n    func4 = dyn_func(c)\n  end function func4\n  end module dummy\n  !------------------------------------------------------------------------------\n\n  program passing_functions\n    use dummy\n    implicit none\n\n    real :: alpha=0.5, beta\n    real :: gamma(2) = (/10,20/)\n\n    beta = func3(func1, alpha)\n    write(*,*) 'beta = ', beta\n    beta = func4(func2, gamma)\n    write(*,*) 'beta = ', beta\n  end program passing_functions\n```\n\n\nThis is the output:\n\n```\nzeus$ passing.out\n beta =    5.500000    \nforrtl: severe (174): SIGSEGV, segmentation fault occurred\nImage              PC                Routine            Line        Source             \npassing.out        0000000000402D44  Unknown               Unknown  Unknown\npassing.out        0000000000402C7C  Unknown               Unknown  Unknown\nlibc.so.6          00002AFF7915D23D  Unknown               Unknown  Unknown\npassing.out        0000000000402B79  Unknown               Unknown  Unknown\nzeus$ \n```\n\n    ", "Answer": "\r\nThe other answer could be used to solve your problem, but there are simpler ways without using pointers.\n\nThere is almost never a reason to use ```\nexternal```\n in modern Fortran.   In Fortran questions that I see on Stackoverflow it almost always leads people to a wrong approach.   Unless you are really sure, don't use ```\nexternal```\n.\n\nWhat you want to do is declare (i.e., describe) the function arguments in functions ```\nfunc3```\n and ```\nfunc4```\n with ```\ninterface```\n blocks.   Here is how to do it for ```\nfunc4```\n ... you should be able to figure out ```\nfunc3```\n:\n\n```\n function func4(dyn_func, c)\n    implicit none\n    real, dimension (:) :: c\n    interface\n       function dyn_func (x)\n          real :: dyn_func\n          real, dimension (:) :: x\n       end function dyn_func\n    end interface\n    real :: func4\n\n    func4 = dyn_func(c)\n  end function func4\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Does Numbapro support SIMD programming architecture\r\n                \r\nI am trying to solve an entropy problem on GPU using simplex optimisation. Because each iteration of simplex relies on the previous one I believe that there is no way that I can make my algorithm parallel. \n\nHowever having done some research on PyOpenCl and Numbapro, OpenCl offers a type of programming architecture called SIMD. I just wondered if Numbapro would offer the same? \n\nSo far I have tried jit, autojit & vectorize for some part of the code but there was no sign of performance improvement.  \n    ", "Answer": "\r\nYes, it does.\n\nPlease watch the video at https://developer.nvidia.com/how-to-cuda-python - it shows exactly what you are interested in.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "C# Xna Noise for terrain-generation\r\n                \r\nI struggle making my own map generator, generating 2d maps like in terraria. My problem is that the result of this looks very unnatural (the caves are mostly really big and round) while the open source simplex noise makes nice long and natural caves when i put it where in the first link the getSmoothNoise(x,y) is located.\n\nNow i have some questions:\n\n\nis it correct that the simplex noise is already interpolated but not smoothed?\ndoes the getSmoothNoise method only smooth the noise or is it also interpolating it?\nwhy is the perlin noise algorithm from the link faster than the simplex noise, when i blend multiple octaves of the noises together? I thought simplex is faster?\n\n\nWhat i actually want to do is creating many noises with the size of my map. Each ore/resoource would get its own noise then and in the end i would blend them all together.\n\n\ncan you imagine a better way to do this?\n\n    ", "Answer": "\r\nI'll just link you to what you really want, which is a c# port of the Accidental Noise Library:\n\nhttp://discordgames.com/?p=1954\n\nAccidental Noise:\n\nhttp://accidentalnoise.sourceforge.net/\n\nThis library will give you a much better way at creating maps that will lay ores in more specific areas.  \n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Gain/Persistence in Simplex Noise based on slope\r\n                \r\nI'm currently working on a terrain engine and I'm experimenting a little bit with noise. It's so fascinating to see what different structures, functions and pure imagination can create with just a few lines of code. Recently I saw this post: http://squall-digital.com/ProceduralGeneration.html, I was definitely intrigued by all of these techniques, but especially the first one caught my attention. The programmer made the gain (or persistence) of the noise to be proportional to the slope of the noise on that point. I'm currently trying to achieve this but I don't think I'm on the right track.\nI'm currently using simplex noise. I know the author of the article uses Perlin Noise and yes, I have seen how to calculate the derivative of Perlin Noise, but obviously this implementation wouldn't work because of the fundamental differences in how Perlin and Simplex noise are generated. I thus set out on my own way to try and approximate the slope of noise on a given position.\nI came up with the following \"algorithm\":\n\nCalculate neighboring points of noise [(x + 1, z),  (x - 1, z),  (x, z + 1),  (x, z - 1)].\nCalculate their respective noise value\nCalculate differenceX and differenceZ in noise values on the x-axis and the z-axis respectively\nCreate vectors from origin: (2, differenceX, 0) and (0, differenceZ, 2)\nScale to vectors of length 1\nAdd y-components of the resulting unit vectors\nuse this y-component as the \"slope\" approximated at the given point.\n\nNow I have implemented this in code (I added \"3D\" vectors for the purpose of ease of understanding)\n```\nprivate static float slope(OpenSimplex2F simplex, float x, float z, float noise) {\n    float[] neighbours = getStraightNeighbours(simplex, x, z);\n\n    float xSlope = (neighbours[1] - neighbours[0]) / (2.0f * x);\n    float zSlope = (neighbours[3] - neighbours[2]) / (2.0f * z);\n\n    float[] vecX = new float[] { 1, xSlope, 0 };\n    float[] vecZ = new float[] { 0, zSlope, 1 };\n\n    float scaleX = Maths.sqrt(1.0f + xSlope * xSlope);\n    float scaleZ = Maths.sqrt(1.0f + zSlope * zSlope);\n\n    for (int i = 0; i < 3; i++) {\n        vecX[i] /= scaleX;\n        vecZ[i] /= scaleZ;\n    }\n\n    float[] grad = new float[] {\n            vecX[0] + vecZ[0],\n            vecX[1] + vecZ[1],\n            vecX[2] + vecZ[2]\n    };\n\n    return grad[1];\n}\n```\n\nNow this gives me extremely underwhelming and rest assured, wrong results: Result\nIs there anyone that can explain me if this is a good technique to approximate the slope of if this is completely wrong. I'm not the biggest math genius so I was already happy I could figure this out and that it produced a result in the first place. If anyone has a resource linked to the derivative of simplex noise (which would be a life saver, obviously), it'd be really appreciated!\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Why does Scipy's Convex Hull algorithm find so many Simplices that share the same point?\r\n                \r\nI'm using Scipy's Convex Hull algorithm to find the surface area of a group of points. The points are each an atomic position in a crystal lattice, and together have the shape of a Truncated Octahedron.\nI would like to find out which surface planes are most common by calculating each simplexes normal. However, when I get simplex information for my array of points, many of the simplices seem to share the same point. This doesn't seem possible to me without Convex Hull incorrectly selecting the surface, or selecting the same surface multiple times.\nScipy notes that the simplices array contains the indices of the points which make up the simplical facets, so each simplex is defined by three indices from the points in the array. An example of a point being repeated in this array is below:\n```\n [...[14689 13913 14003]\n [14689   919   589]\n [14689  1830  1230]\n [14689    13    11]\n [14689   919   918]\n [14689 14086 13833]\n [14689  1230 13833]\n [14689    13   313]\n [14689   589   313]\n [14689  1223    42]\n [14689 13913 14086]\n [14689 14996 13617]\n [14689    20    11]\n [14689 14967 14828]\n [14689 13734 13617]\n [14689   992   918]\n [14689    20    42]\n [14689 14851 14967]\n [14689 14996 14828]\n [14689   992 13734]\n [14689  1223  1830]\n [14689 14675 14003]]\n```\n\nThe index 14689 is repeated 22 times. Does anyone understand why Scipy is doing this? Or know of any other software which could be better for getting detailed information about the Convex Hull of a group of points? Scipy's implementation is based on Qhull.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Natural language processing: finding semantic similarities with standard algorithms?\r\n                \r\nI want to ask if there exists some (collection of) standard algorithms (standard in the sense like the Simplex algorithm for linear optimization) which are scientifically accepted and practically \"good enough\" to sort and rate short (one to three sentences) questions with respect to their similarity. That means that I want some measure to tell that from the following three questions:\n\n\n\"Has the weight of Paul's dog increased over the last week?\" \n\"Is the dog heavier than before?\"\n\"Has Paul a dog named Lucifer?\"\n\n\nthe first two share the highest common semantic. I know that this is quite a hard problem and I think that any solution down the range towards simple comparison will also serve (failing on the given example, but oh well), my question is, what is current (open source) standard?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Example for SimplexSolver in Apache Commons Maths 3.6.1\r\n                \r\nI am new to linear optimization and currently trying to use the ```\nSimplexSolver.class```\n from ```\norg.apache.commons.math3.optim.linear```\n.\nSo I looked up some examples on how to use it, to understand it and also to recall what the  Simplex Algorithm exactly processes and how it works.\nBut unfortunately, I encountered some problems. For all the examples I was able to find, the class is used in that way:\n```\nPointValuePair s = new SimplexSolver().optimize(function, constraints, GoalType.MINIMIZE, false);\n```\n\nBut the parameters in the example don't fit with the current expectation of the function ```\noptimize```\n. Checking out the documentation was not very helpful for me, because it just says that I need one parameter of type ```\nOptimizationData```\n. Because ```\nOptimizationData```\n is just an interface, I don't really know which type to use.\nDoes anyone have an example of how to use the ```\noptimize```\n function properly?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Item assignment algorithm on python\r\n                \r\nI have a set of user preferences on different items. For example, let's say there are three items, and the user preferences are:\n```\n\nUser 1: Item A > Item B > Item C\nUser 2: Item B > Item A > Item C\nUser 3: Item A > Item C > Item B\n```\n\nThe real scenario has 25 users and 25 items, but the idea is the same. My goal here is to offer a best fitting solution, i.e. the one that offers a highest-ranking match for each user overall but not necessarily the maximum number of #1 preferences. Importantly, each item can only be assigned once.\nWhat algorithm could I use on Python to solve this? Thanks!\nI tried using Networkx simplex, but I got this error: networkx.exception.NetworkXUnfeasible: total node demand is not zero\n```\n`Sample preference:\n`User1 = ('User1', [20,24,17,22,7,6,5,11,25,8,1,9,23,12,2,19,21,15,16,14,13,4,18,10,3])`\n\n`# (name, index, limit)\nno_items=25\nC=[]\nfor i in range(1,no_items+1):\n    C.append(('s'+str(i),i,1))\n\n\"\"\" Helper \"\"\"\ndef get_cost(ranking, index):\n    return ranking.index(index)**2                        # quadratic penalty\n\n\"\"\" Min-cost flow graph \"\"\"\nG = nx.DiGraph()\n\n# Demands\nfor p in P:\n    G.add_node(p[0], demand=-1)\n    G.add_node('sink', demand=len(P))\n\n# layer 1\nfor p, c in itertools.product(P, C):\n    G.add_edge(p[0], c[0], weight=get_cost(p[1], c[1]))\n\n# layer 2\nfor c in C:\n    G.add_edge(c[0], 'sink', capacity=c[2])\n\nflowCost, flowDict = nx.network_simplex(G)\n#flowCost, flowDict = nx.capacity_scaling(G)\nprint('Cost: ', flowCost)\n\n\"\"\" SOLUTION \"\"\"\nfor p in P:\n    for c in C:\n        if flowDict[p[0]][c[0]]:\n            print(p[0], '->', c[0])`\n```\n\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "N-dimensional convex hull qhull algorithm optimality\r\n                \r\nWhy quick hull algorithm works with farthest point in outside set of facet instead of working with point, which gives maximum volume for simplex, resultant from the facet and the point?\n\nIf points are uniformly distributed in space (general case), then largest volume point potentially provide greater amount of cutoff points (which is not above the newly created facets) on each step. Note, that N-dimensional oriented volume proportional to simple determinant, but 1-dimensional signed distance additionally requires calculation of (N-1)-dimensional oriented volume (\"square\") for the facet, wich, in turn, imply determinant calculation of two non-square matrices dot-product.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "compute the tableau's nonbasic term in SCIP separator\r\n                \r\nIn traditional Simplex Algorithm notation, we have x at the current basis selection B as so:\nxB = AB-1b - AB-1ANxN. How can I compute the AB-1AN term inside a separator in SCIP, or at least iterate over its columns?\nI see three helpful methods: ```\ngetLPColsData```\n, ```\ngetLPRowsData```\n, ```\ngetLPBasisInd```\n. I'm just not sure exactly what data those methods represent, particularly the last one, with its negative row indexes. How do I use those to get the value I want?\nDo those methods return the same data no matter what LP algorithm is used? Or do I need to account for dual vs primal? How does the use of the \"revised\" algorithm play into my calculation?\nUpdate: I discovered the ```\ngetLPBInvARow```\n and ```\ngetLPBInvRow```\n. That seems to be much closer to what I'm after. I don't yet understand their results; they seem to include more/less dimensions than expected. I'm still looking for understanding at how to use them to get the rays away from the corner.\nUpdate 2: further code at https://github.com/scipopt/scip/issues/31\n    ", "Answer": "\r\nyou are correct that ```\ngetLPBInvRow```\n or ```\ngetLPBInvARow```\n are the methods you want. ```\ngetLPBInvARow```\n directly returns you a of the simplex tableau, but it is not more efficient to use than ```\ngetLPBInvRow```\n and doing the multiplication yourself since the LP solver needs to also compute the actual tableau first.\nI suggest you look into either ```\nsepa_gomory.c```\n or ```\nsepa_gmi.c```\n for examples of how to use these methods. How do they include less dimensions than expected? They both return sparse vectors.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to use index to derive pseudorandom gradient in 2D simplex noise\r\n                \r\nWhen using simplex noise one of it's main features is in the generation of gradients on-the-fly. This algorithm is described here. The problem is that even in the patent the gradient generation algorithm is only described in three dimensions (see below).\n\nThe specific new technique is as follows: The six bit index is split into (i) a lower three bit quantity, which is used to compute a magnitude of either zero or one for each of x,y and z, and (ii) an upper three bit quantity, which is used to determine an octant for the resulting gradient (positive or negative sign in each of x,y, and z).\n\nIf bit1bit0=0, then let (p,q,r)=(x,y,z). Otherwise, let (p,q,r) be a rotation of the order of (x,y,z) to (y,z,x) or (z,x,y), as bit1bit0=1 or 2, respectively, and set either q or r to zero as bit2=0 or 1, respectively.\n\n000 p = x q = y r = z\n001 p = y q = z r = 0\n010 p = z q = x r = 0\n011 p = x q = y r = 0\n100 p = x q = y r = z\n101 p = y q = 0 r = x\n110 p = z q = 0 r = y\n111 p = x q = 0 r = z\n\nThen you basically continue and flip the signs of the components of the generated gradient.\n\nThe problem is basically how does the above rotation algorithm translate to 2D?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "arc4random initialisation\r\n                \r\nI am using random number generation as part of a procedure for minimising a function (using the Nelder-Mead simplex algorithm) in objective-c (for iOS).  I have used ```\narc4random()```\n because it seems to be recommended everywhere on the grounds that a) it doesn't need to be seeded and b) it gives higher-quality random numbers than alternatives such as ```\nrand() and random()```\n. I generate doubles between 0 and 1 using \n\n```\n#define ARC4RANDOM_MAX      0x100000000\n-(double) Rnd{\nreturn (double)arc4random() / (double)ARC4RANDOM_MAX ; }\n```\n\n\nHowever, to test the procedure I need to generate repeatable sequences of random numbers, and I can't find any reference to a way to initialise ```\narc4random()```\n to do this.  Is it the case that ```\narc4random()```\n cannot be initialised to give a repeatable sequence?  If so, how can anyone implement an automated unit test when every test will result in a different answer? Do I need to use the \"lower quality\" random numbers from ```\nrandom()```\n?  Thanks for your help.\n    ", "Answer": "\r\nThe ```\narc4random```\n function gets random numbers from a pool over which it has no control. It has no mechanism to provide repeatability. For unit tests, you'll have to use something else.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How could I draw an Outlined Mesh like this?\r\n                \r\nSo I saw a blog about parsing OBJ files, but what really caught my eye was the object they were parsing (this question isn't about parsing OBJ files).\n\n\n\nI know the mesh was created using a 3D noise algorithm, probably simplex noise, but what I want to know is how I could make a similar line effect to that in LWJGL.\n\nI already have a 3D simplex noise algorithm, and some code that I thought would work but really doesn't do quite the same thing.\n\nThe pattern I notice about the mesh is there are rows of lines that start on the outside where the noise density is highest. Those lines then evolve based on the noise density in specific spots, so what I tried to do was make an algorithm to produce those lines and evolve them as well, but that didn't quite so work.\n\n```\nSimplexNoise noise = new SimplexNoise(23453) //Variable is the seed\nworldList = glGenLists(1);\nglNewList(worldList, GL_COMPILE); //Inefficient but gets the job done\n    float prevx = 0.0f;\n    float prevy = 0.0f;\n    float prevz = 0.0f;\n    for(int x=0;x<256;x++){\n        for(int y=0;y<256;y++){\n            for(int z=0;z<256;z++){\n                float xf = x/100;\n                float yf = y/100;\n                float zf = z/100;\n                density = noise.simplex(3,xf,yf,zf); //octaves,x,y,z\n                if(density>3){ //filter out some results\n                    drawLine(prevx,prevy,prevz,x+1,y*density,z*density);\n                    drawLine(prevx,prevy,prevz,x*density,y+1,z*density);\n                    drawLine(prevx,prevy,prevz,x*density,y*density,z+1);\n                }\n            }\n        }\n    }\nglEndList();\n```\n\n\nIt shouldn't be hard to realize that this doesn't produce anything near the same results. I do not know how to approach or exactly produce the same mesh shape or something similar, so can anyone help me?\n    ", "Answer": "\r\nI'm not familiar with LWJGL, but I think I may be able to point you in the right direction as far as the algorithm itself goes. You can plug Perlin/Simplex noise into a marching cubes algorithm and generate a triangle mesh from it. I used this technique to create this mesh:\n\n\n\nI believe you may be able to get the result you want by drawing the wireframe of the outputted mesh. After all, if you look closely, all of those lines make triangles. You can find more info about marching cubes here.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "glpsol tool split MIP and LP solutions\r\n                \r\nI am using glpsol to solve a rather big integer optimisation problem. The Simplex algorithm runs for about 30 mins on it, and after that ```\nglpsol```\n tries to find integer solution using MIP solver. \n\nQuestion: Can I split this into two steps using only the glpsol command tool, or should I use glpk API ?\n\nI have tried \"read\" and \"nomip\" option that according to the documentation is\n\n```\n-r filename, --read filename\n```\n\n\nto read the solution from the provided filename rather than to find it with the solver\n\nin this format:\n\n```\n glpsol --cpxlp WhiskasModel.lp --write WhiskasSolution.mip --nomip\n```\n\n\nand after that \n\n```\n glpsol --cpxlp WhiskasModel.lp --read WhiskasSolution.mip\n```\n\n\nbut I receive an error:\n\n```\n Reading MIP solution from `WhiskasModel.mip'...\n WhiskasModel.mip:33702: non-integer column valueUnable to read problem solution\n```\n\n\nand it is of course true because WhiskasModel.mip is an LP solution with nonint values.\n\nI find the ```\nglpsol toolkit```\n rather powerful and I want to play with some MIP options but on each step to wait 30 minutes is rather boring. Can I tell it, \"use this LP solution and start MIP\" ?\n    ", "Answer": "\r\nOne thing to try: write the LP basis to a plain text file, and then when re-starting, start with that LP solution as the basis.\n\nTry\n\n```\n  -w WhiskasBasis.txt\n```\n\n\nand when restarting to continue on as an IP, ask it to use that basis by adding the ```\nini```\n option.\n\n```\n--ini WhiskasBasis.txt \n```\n\n\nOther suggestions:\n\n\nI wouldn't use the command-line option if you are going to be doing this often. The GLPK API (for your language of choice) and with an IDE, will give you so much more flexibility and control. This link mentions several.\nIf you post your MIP model formulation with the objective and the constraints (maybe as a different question), you might get suggestions to speed things up. Sometimes there are relaxations and sub-problems that can help tremendously.\n\n\nHope that helps.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "threeJS procedural plane vertices not aligning\r\n                \r\nI'm using threeJS combined with a Simplex noise algorithm to generate a tile system of 50x50 planes. At the moment, I'm looping through x+y and adding each plane. I then use the Simplex noise algorithm to calculate the four vertices z position of the plane.\n\nI am using the current x/y as the top left vertice ([0]), and the rest you can see below in the function that generates the tiles initially:    \n\n```\n        PerlinSimplex.noiseDetail(4,0.5);\n\n        x=0;\n        y=0;\n\n        while (x<32) {\n            while (y<32) {\n                l=(x*tilesize)+(tilesize/2);\n                t=(y*tilesize)+(tilesize/2);\n                //fScl= .07;\n                fScl= 1;\n                xx=x*fScl;\n                yy=y*fScl;\n\n                tl=Math.floor((PerlinSimplex.noise(xx,yy))*100);\n                bl=Math.floor((PerlinSimplex.noise(xx,yy-1))*100);\n                br=Math.floor((PerlinSimplex.noise(xx+1,yy-1))*100);\n                tr=Math.floor((PerlinSimplex.noise(xx+1,yy))*100);\n\n                addTile(t,l,tl,tr,bl,br);\n                y++;\n            }\n            y=0;\n            x++;\n        }\n```\n\n\nOk so thats the loop, then the addTile function:\n\n```\n    function addTile(x,y,tl,tr,bl,br) {\n\n        var geo=new THREE.PlaneGeometry(tilesize, tilesize);\n        geo.dynamic = true;\n\n        geos.push(geo);\n\n        var plane = new THREE.Mesh(geo, col);\n        plane.overdraw = true;\n\n        plane.geometry.vertices[0].z=tl;\n        plane.geometry.vertices[1].z=tr;\n        plane.geometry.vertices[2].z=bl;\n        plane.geometry.vertices[3].z=br;\n\n\n        plane.geometry.computeFaceNormals();\n        plane.geometry.computeVertexNormals();    \n        plane.geometry.__dirtyNormals = true;\n\n        plane.position.x=x;\n        plane.position.y=y;\n        plane.position.z=0;\n\n        scene.add(plane);\n\n        planes.push(plane);\n\n        plane.geometry.verticesNeedUpdate = true;\n\n        // changes to the normals\n        plane.geometry.normalsNeedUpdate = true;\n\n    }\n```\n\n\n(Quick note, I realised I think I don't need to have a new geometry for each plane)\n\nOk and here is the result:\n\nhttps://i.stack.imgur.com/as7hb.jpg\n\nAs you can see, the vertices don't line up. I've tried quite a few things, but am totally stumped right now. I'm pretty sure I have the correct vertices being set as TL,TR, etc. Can you spot why the vertices aren't lining up?\n\nThankyou :)\nJack\n    ", "Answer": "\r\nOk, it turns out I was passing t and l into the function the wrong way around. Doh!\n\n:)\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Speed up gaussian elimination step with numpy\r\n                \r\nI'm currently working on implementing the Simplex algorithm and at the moment want to speed up the process.\n\nIn the gaussian elimination step I'm using\n\n```\n    # gausian elimination\n    rang = list(range(0,leaving_row))\n    rang.extend(range(leaving_row+1,self.matrix.shape[0]))\n\n    facs = -self.matrix[:, entering] / self.matrix[leaving_row, entering]\n    facs[leaving_row] = 0\n    for row in rang:\n        self.matrix[row] += facs[row] * self.matrix[leaving_row]\n\n    self.matrix[leaving_row] /= self.matrix[leaving_row, entering]\n```\n\n\nWhat it basically does is one gaussian step in way that the ```\nleaving_row```\n has a 1 at the end in the ```\nentering```\n column.\n\nIs there any way of speeding up the for loop? Any fancy way of using matrix multiplication here?\n\nThanks for any ideas in advance.\n\nMy matrix shape is:\n(1105, 2107)\n\nOne of these gaussian eliminations take about 0.009s on my laptop. I would like to be able to use my program on bigger instances therefore I would like to speed it up as much as possible. \n\nEdit\nI also tried to replace the loop by:\n\n```\nl_r = self.matrix[leaving_row]\nl_r_m = np.broadcast_to([l_r],self.matrix.shape)\nself.matrix += l_r_m*facs[:,np.newaxis]\n```\n\n\nThat seems to be a bit faster (around 0.007 instead of 0.009) but it also looks quite odd with this huge ```\nbroadcast_to```\n function.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Vector refilling is slower than creating a new one?\r\n                \r\nI was trying to implement an optimizer using Simplex Algorithm. The original codes online creates a new vector with 0 initial values in each iteration. I tried to create a common outside the loops, then use ```\nstd::fill```\n to reset the values in each iteration. I was surprised that the first one is faster than the second. To my view of point, the declaration, in any way, needs to ask for memory AND initialize the values, cannot be faster.\n\nCould anyone help to explain this? If this is true, is there any disadvantage of the first approach? Or can we improve it further?\n\nHere is the code.\n\nNew one:\n\n```\n    void Simplex(std::vector<double>& result, std::function<double(std::vector<double>)> func,\n        std::vector<double> init, std::vector<std::vector<double>> x = std::vector<std::vector<double>>(),\n        double EPS = 1E8 * std::numeric_limits<double>::epsilon(), int MAXIT = 1000000)\n    {\n        int N = init.size();                                //  Space Dimension\n        //  Coefficients for the new points.\n        const double a = 1.0;       //  a: Reflection\n        const double b = 1.0;       //  b: Expansion\n        const double g = 0.5;       //  g: Contraction\n        const double h = 0.5;       //  h: Multi-Contraction\n        std::vector<double> xcentroid_old(N, 0);    //  Old Simplex Centroid * (N + 1)\n        std::vector<double> xcentroid_new(N, 0);    //  New Simplex Centroid * (N + 1)\n        std::vector<double> vf(N + 1, 0);           //  Values at Simplex Vertexes       \n        int x1 = 0;                 //  Index of smallest vertex.\n        int xn = 0;                 //  Index of second greatest vertex.\n        int xnp1 = 0;               //  Index of greatest vertex.\n        int countIT = 0;                //  Iteration Count\n\n        //  If no initial simplex is specified, construct the trial simplex.\n        if (x.size() == 0)\n        {\n            std::vector<double> del(init);\n            //  del = init / 20\n            std::transform(del.begin(), del.end(), del.begin(),\n                std::bind2nd(std::divides<double>(), 20));\n            for (int i = 0; i < N; i++)\n            {\n                std::vector<double> tmp(init);\n                tmp[i] += del[i];\n                x.push_back(tmp);\n            }\n            x.push_back(init);\n\n            // Calculate the xcentriod.\n            std::transform(init.begin(), init.end(), xcentroid_old.begin(),\n                std::bind2nd(std::multiplies<double>(), N + 1));\n        }\n\n        std::vector<double> xg(N);\n        std::vector<double> xr(N);\n        std::vector<double> xe(N);\n        std::vector<double> xc(N);\n        //  Optimization starts.\n        for (countIT = 0; countIT < MAXIT; countIT++)\n        {\n            for (int i = 0; i < N + 1; i++)\n                vf[i] = func(x[i]);\n\n            // Find index of max, second max, min of vf.\n            x1 = 0; xn = 0; xnp1 = 0;\n            for (int i = 0; i < vf.size(); i++)\n            {\n                if (vf[i] < vf[x1])\n                    x1 = i;\n                if (vf[i] > vf[xnp1])\n                    xnp1 = i;\n            }\n            xn = x1;\n            for (int i = 0; i < vf.size(); i++)\n            {\n                if (vf[i] < vf[xnp1] && vf[i] > vf[xn])\n                    xn = i;\n            }\n\n            //  xg: Centroid of the N best vertexes.\n            std::fill(xg.begin(), xg.end(), 0);\n            for (int i = 0; i < x.size(); i++)\n            {\n                if (i != xnp1)\n                    std::transform(xg.begin(), xg.end(), x[i].begin(), xg.begin(), std::plus<double>());\n            }\n            std::transform(xg.begin(), xg.end(),\n                x[xnp1].begin(), xcentroid_new.begin(), std::plus<double>());\n            std::transform(xg.begin(), xg.end(), xg.begin(),\n                std::bind2nd(std::divides<double>(), N));\n\n            //  Termination condition: change (sum of absolute differences on all dimensions)\n            //  of simplex centroid is less than EPS.\n            double diff = 0;\n            for (int i = 0; i < N; i++)\n                diff += fabs(xcentroid_old[i] - xcentroid_new[i]);\n            if (diff / N < EPS)\n                break;\n            else\n                xcentroid_old.swap(xcentroid_new);\n\n            //  Reflection\n            std::fill(xr.begin(), xr.end(), 0);\n            for (int i = 0; i < N; i++)\n                xr[i] = xg[i] + a * (xg[i] - x[xnp1][i]);\n            double fxr = func(xr);\n            if (vf[x1] <= fxr && fxr <= vf[xn])\n                //  If f(x1) <= f(xr) <= f(xn), update xnp1 to xr.\n                std::copy(xr.begin(), xr.end(), x[xnp1].begin());\n            else if (fxr < vf[x1])\n            {\n                //  If f(xr) < f(x1), expansion.\n                std::fill(xe.begin(), xe.end(), 0);\n                for (int i = 0; i<N; i++)\n                    xe[i] = xr[i] + b * (xr[i] - xg[i]);\n                //  Update xnp1 to the better one of xr or xe.\n                if (func(xe) < fxr)\n                    std::copy(xe.begin(), xe.end(), x[xnp1].begin());\n                else\n                    std::copy(xr.begin(), xr.end(), x[xnp1].begin());\n            }\n            else if (fxr > vf[xn])\n            {\n                //  If f(xr) > f(xn), contraction.\n                std::fill(xc.begin(), xc.end(), 0);\n                for (int i = 0; i < N; i++)\n                    xc[i] = xg[i] + g * (x[xnp1][i] - xg[i]);\n                if (func(xc) < vf[xnp1])\n                    //  If f(xc) < f(xnp1), update xnp1 to xc.\n                    std::copy(xc.begin(), xc.end(), x[xnp1].begin());\n                else\n                {\n                    //  If f(xc) >= f(xnp1), multi-contraction.\n                    for (int i = 0; i < x.size(); i++)\n                    {\n                        if (i != x1)\n                        {\n                            for (int j = 0; j < N; j++)\n                                x[i][j] = x[x1][j] + h * (x[i][j] - x[x1][j]);\n                        }\n                    }\n                }\n            }\n        }\n\n        if (countIT == MAXIT)\n            throw std::invalid_argument(\"Iteration limit achieves, result may not be optimal.\");\n\n        result = x[x1];\n    }\n```\n\n\nOriginal one:\n\n```\n    void Simplex_Original(std::vector<double>& result, std::function<double(std::vector<double>)> func,\n        std::vector<double> init, std::vector<std::vector<double>> x = std::vector<std::vector<double>>(),\n        double EPS = 1E8 * std::numeric_limits<double>::epsilon(), int MAXIT = 1000000)\n    {\n        int N = init.size();                                //  Space Dimension\n        //  Coefficients for the new points.\n        const double a = 1.0;       //  a: Reflection\n        const double b = 1.0;       //  b: Expansion\n        const double g = 0.5;       //  g: Contraction\n        const double h = 0.5;       //  h: Multi-Contraction\n        std::vector<double> xcentroid_old(N, 0);    //  Old Simplex Centroid * (N + 1)\n        std::vector<double> xcentroid_new(N, 0);    //  New Simplex Centroid * (N + 1)\n        std::vector<double> vf(N + 1, 0);           //  Values at Simplex Vertexes       \n        int x1 = 0;                 //  Index of smallest vertex.\n        int xn = 0;                 //  Index of second greatest vertex.\n        int xnp1 = 0;               //  Index of greatest vertex.\n        int countIT = 0;                //  Iteration Count\n\n        //  If no initial simplex is specified, construct the trial simplex.\n        if (x.size() == 0)\n        {\n            std::vector<double> del(init);\n            //  del = init / 20\n            std::transform(del.begin(), del.end(), del.begin(),\n                std::bind2nd(std::divides<double>(), 20));\n            for (int i = 0; i < N; i++)\n            {\n                std::vector<double> tmp(init);\n                tmp[i] += del[i];\n                x.push_back(tmp);\n            }\n            x.push_back(init);\n\n            // Calculate the xcentriod.\n            std::transform(init.begin(), init.end(), xcentroid_old.begin(),\n                std::bind2nd(std::multiplies<double>(), N + 1));\n        }\n\n        //  Optimization starts.\n        for (countIT = 0; countIT < MAXIT; countIT++)\n        {\n            for (int i = 0; i < N + 1; i++)\n                vf[i] = func(x[i]);\n\n            // Find index of max, second max, min of vf.\n            x1 = 0; xn = 0; xnp1 = 0;\n            for (int i = 0; i < vf.size(); i++)\n            {\n                if (vf[i] < vf[x1])\n                    x1 = i;\n                if (vf[i] > vf[xnp1])\n                    xnp1 = i;\n            }\n            xn = x1;\n            for (int i = 0; i < vf.size(); i++)\n            {\n                if (vf[i] < vf[xnp1] && vf[i] > vf[xn])\n                    xn = i;\n            }\n\n            //  xg: Centroid of the N best vertexes.\n            std::vector<double> xg(N, 0);\n            for (int i = 0; i < x.size(); i++)\n            {\n                if (i != xnp1)\n                    std::transform(xg.begin(), xg.end(), x[i].begin(), xg.begin(), std::plus<double>());\n            }\n            std::transform(xg.begin(), xg.end(),\n                x[xnp1].begin(), xcentroid_new.begin(), std::plus<double>());\n            std::transform(xg.begin(), xg.end(), xg.begin(),\n                std::bind2nd(std::divides<double>(), N));\n\n            //  Termination condition: change (sum of absolute differences on all dimensions)\n            //  of simplex centroid is less than EPS.\n            double diff = 0;\n            for (int i = 0; i < N; i++)\n                diff += fabs(xcentroid_old[i] - xcentroid_new[i]);\n            if (diff / N < EPS)\n                break;\n            else\n                xcentroid_old.swap(xcentroid_new);\n\n            //  Reflection\n            std::vector<double> xr(N, 0);\n            for (int i = 0; i < N; i++)\n                xr[i] = xg[i] + a * (xg[i] - x[xnp1][i]);\n            double fxr = func(xr);\n            if (vf[x1] <= fxr && fxr <= vf[xn])\n                //  If f(x1) <= f(xr) <= f(xn), update xnp1 to xr.\n                std::copy(xr.begin(), xr.end(), x[xnp1].begin());\n            else if (fxr < vf[x1])\n            {\n                //  If f(xr) < f(x1), expansion.\n                std::vector<double> xe(N, 0);\n                for (int i = 0; i<N; i++)\n                    xe[i] = xr[i] + b * (xr[i] - xg[i]);\n                //  Update xnp1 to the better one of xr or xe.\n                if (func(xe) < fxr)\n                    std::copy(xe.begin(), xe.end(), x[xnp1].begin());\n                else\n                    std::copy(xr.begin(), xr.end(), x[xnp1].begin());\n            }\n            else if (fxr > vf[xn])\n            {\n                //  If f(xr) > f(xn), contraction.\n                std::vector<double> xc(N, 0);\n                for (int i = 0; i < N; i++)\n                    xc[i] = xg[i] + g * (x[xnp1][i] - xg[i]);\n                if (func(xc) < vf[xnp1])\n                    //  If f(xc) < f(xnp1), update xnp1 to xc.\n                    std::copy(xc.begin(), xc.end(), x[xnp1].begin());\n                else\n                {\n                    //  If f(xc) >= f(xnp1), multi-contraction.\n                    for (int i = 0; i < x.size(); i++)\n                    {\n                        if (i != x1)\n                        {\n                            for (int j = 0; j < N; j++)\n                                x[i][j] = x[x1][j] + h * (x[i][j] - x[x1][j]);\n                        }\n                    }\n                }\n            }\n        }\n\n        if (countIT == MAXIT)\n            throw std::invalid_argument(\"Iteration limit achieves, result may not be optimal.\");\n\n        result = x[x1];\n    }\n```\n\n\nTest function:\n\n```\ndouble func(vector<double> x)\n{\n    return (x[0] * x[0] + x[1] * x[1]) * (x[0] * x[0] + x[1] * x[1]) - (x[0] - 3 * x[1]) * (x[0] - 3 * x[1]);\n}\n\nvoid main()\n{\n    int m = 1000, n = 10;\n    double dz = 0.1 / m / n;\n    vector<double> init(2), result(2);\n\n    init[0] = 3;    init[1] = 3;\n    clock_t t1;\n    t1 = clock();\n    for (int i = 0; i < m; i++)\n    {\n        for (int j = 0; j < n; j++)\n        {\n            init[0] += dz;\n            Optimizer::Simplex_Original(result, func, init);\n        }\n    }\n    cout << \"Old:\" << '\\t' << float(clock() - t1) / CLOCKS_PER_SEC << endl;\n    cout << result[0] << '\\t' << result[1] << endl;\n\n    init[0] = 3;    init[1] = 3;\n    t1 = clock();\n    for (int i = 0; i < m; i++)\n    {\n        for (int j = 0; j < n; j++)\n        {\n            init[0] += dz;\n            Optimizer::Simplex(result, func, init);\n        }\n    }\n    cout << \"New:\" << '\\t' << float(clock() - t1) / CLOCKS_PER_SEC << endl;\n    cout << result[0] << '\\t' << result[1] << endl;\n}\n```\n\n\nI use VS 2013 with Release mode, O2 is turned on.\n\nFor the original one, 10000 repeats cost about 9s, but 13s for the new one.\n    ", "Answer": "\r\nI imagine the vector constructor, knowing that the memory is contiguous, will be able to better optimise setting its contents. It can probably just memset the whole area, or something similar, whereas std::fill does not know what type of container it is accessing, so must iterate over all the elements by incrementing the iterator for every one and writing every one individually...\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Library of optimzation algorithms in java\r\n                \r\nI'm looking for some library(open source will be perfect) that have realization of different optimizaion algorithms in java. Actually I need a dual simplex method. It will be good if it will be documented well.\n    ", "Answer": "\r\nTry http://code.google.com/p/net-fs/.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Issues with Simplex method for linear programming in Matlab (linprog funcion)\r\n                \r\nI am using the ```\nlinprog```\n function in Matlab to solve a set of large linear programming problems. I have 2601 decision variables, 51 inequality constraints, 71 equality constraints, and lower bounds of 0 for all variables. \n\nThe coefficients in the objective function and constraints vary in different problems. I am using the simplex method (when I try active-set and interior-point the program never stops running, as long as I have waited which was more than hours). \n\nThe simplex method converges for some of the problems very quickly, and for some of them (also very quickly) shows this message:\n\n\n  Exiting: The constraints are overly stringent; no feasible starting point found.\n\n\nHowever, even for the ones with that message, it still provides a solution which satisfy the constraints. Can I just ignore that message and use the solutions or the message is important and the solution is probably not optimum?\n\nUpdate: It turned out that the interior-point method solves some of them, but not the others. So in the code below, I used the interior-point method for the ones that work with it, and the simplex method with the rest.\n\nThese are my files and this is my code:\n\n```\nclc; clear;\n\n%distances\nt1 = readtable('t.xlsx', 'ReadVariableNames',false);\nti = table2array(t1);\nsz = size(ti);\ntiv = reshape(ti, [1,sz(1)*sz(2)]);\n\n%crude oil production and attraction\nA = readtable('A.xlsx', 'ReadVariableNames',false);\nAi = table2array(A);\nP = readtable('P.xlsx', 'ReadVariableNames',false);\nPi = table2array(P);\n\n%others\none1 = readtable('A Matrix.xlsx', 'ReadVariableNames',false);\none = table2array(one1);\ntwo1 = readtable('Aeq Matrix.xlsx', 'ReadVariableNames',false);\ntwo = table2array(two1);\nzero = zeros(sz(1), sz(1));\ninfin = inf(sz(1), sz(1));\nzerov = reshape(zero, [1,sz(1)*sz(2)]);\ninfinv = reshape(infin, [1,sz(1)*sz(2)]);\n\n%OF\nf = (tiv).^1;\n\n%linear program \n%x = linprog(f,A,b,Aeq,beq,lb,ub)\noptions1 = optimoptions('linprog','Algorithm','interior-point');\noptions2 = optimoptions('linprog','Algorithm','simplex');\nx1999 = vec2mat(linprog(f,one,Pi(1,1:end),two,Ai(1,1:end),zerov,infinv,zerov,options2),sz(1));\nx2000 = vec2mat(linprog(f,one,Pi(2,1:end),two,Ai(2,1:end),zerov,infinv,zerov,options1),sz(1));\nx2001 = vec2mat(linprog(f,one,Pi(3,1:end),two,Ai(3,1:end),zerov,infinv,zerov,options1),sz(1));\nx2002 = vec2mat(linprog(f,one,Pi(4,1:end),two,Ai(4,1:end),zerov,infinv,zerov,options1),sz(1));\nx2003 = vec2mat(linprog(f,one,Pi(5,1:end),two,Ai(5,1:end),zerov,infinv,zerov,options1),sz(1));\nx2004 = vec2mat(linprog(f,one,Pi(6,1:end),two,Ai(6,1:end),zerov,infinv,zerov,options1),sz(1));\nx2005 = vec2mat(linprog(f,one,Pi(7,1:end),two,Ai(7,1:end),zerov,infinv,zerov,options1),sz(1));\nx2006 = vec2mat(linprog(f,one,Pi(8,1:end),two,Ai(8,1:end),zerov,infinv,zerov,options1),sz(1));\nx2007 = vec2mat(linprog(f,one,Pi(9,1:end),two,Ai(9,1:end),zerov,infinv,zerov,options2),sz(1));\nx2008 = vec2mat(linprog(f,one,Pi(10,1:end),two,Ai(10,1:end),zerov,infinv,zerov,options2),sz(1));\nx2009 = vec2mat(linprog(f,one,Pi(11,1:end),two,Ai(11,1:end),zerov,infinv,zerov,options2),sz(1));\nx2010 = vec2mat(linprog(f,one,Pi(12,1:end),two,Ai(12,1:end),zerov,infinv,zerov,options2),sz(1));\nx2011 = vec2mat(linprog(f,one,Pi(13,1:end),two,Ai(13,1:end),zerov,infinv,zerov,options2),sz(1));\nx2012 = vec2mat(linprog(f,one,Pi(14,1:end),two,Ai(14,1:end),zerov,infinv,zerov,options1),sz(1));\nx2013 = vec2mat(linprog(f,one,Pi(15,1:end),two,Ai(15,1:end),zerov,infinv,zerov,options2),sz(1));\nx2014 = vec2mat(linprog(f,one,Pi(16,1:end),two,Ai(16,1:end),zerov,infinv,zerov,options2),sz(1));\nx2015 = vec2mat(linprog(f,one,Pi(17,1:end),two,Ai(17,1:end),zerov,infinv,zerov,options2),sz(1));\nx2016 = vec2mat(linprog(f,one,Pi(18,1:end),two,Ai(18,1:end),zerov,infinv,zerov,options1),sz(1));\n```\n\n    ", "Answer": "\r\nIn case somebody wants to know what the problem was, I found that for those programs with error, there was actually no feasible point and what the error said was correct. I found it out by running the same linear programs with a vector of zeros for the objective function's coefficients, and getting the same error (recommended method by Matlab's manual).\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Is there a way where I can optimize the output restricting the parameters in fmin from scipy.optimize\r\n                \r\nWhat I am doing: I modified the code from the zombie invasion system to demonstrate how it should be written and tried to optimize the least square error (defined as score function) with the fmin function.\n\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import odeint\nfrom scipy import integrate\nfrom scipy.optimize import fmin\n#=====================================================\n#Notice we must import the Model Definition\nfrom zombiewithdata import eq\n#=====================================================\n\n#1.Get Data\n#====================================================\nTd=np.array([0.5,1,1.5,2,2.2,3,3.5,4,4.5,5])#time\nZd=np.array([0,2,2,5,2,10,15,50,250,400])#zombie pop\n#====================================================\n\n#2.Set up Info for Model System\n#===================================================\n# model parameters\n#----------------------------------------------------\nP = 0       # birth rate\nd = 0.0001  # natural death percent (per day)\nB = 0.0095  # transmission percent  (per day)\nG = 0.0001  # resurect percent (per day)\nA = 0.0001  # destroy perecent (per day)\nrates=(P,d,B,G,A)\n\n# model initial conditions\n#---------------------------------------------------\nS0 = 500.               # initial population\nZ0 = 0                  # initial zombie population\nR0 = 0                  # initial death population\ny0 = [S0, Z0, R0]      # initial condition vector\n\n# model steps\n#---------------------------------------------------\nstart_time=0.0\nend_time=5.0\nintervals=1000\nmt=np.linspace(start_time,end_time,intervals)\n\n# model index to compare to data\n#----------------------------------------------------\nfindindex=lambda x:np.where(mt>=x)[0][0]\nmindex=map(findindex,Td)\n#=======================================================\n\n\n\n#3.Score Fit of System\n#=========================================================\ndef score(parms):\n    #a.Get Solution to system\n    F0,F1,F2,T=eq(parms,y0,start_time,end_time,intervals)\n    #b.Pick of Model Points to Compare\n    Zm=F1[mindex]\n    #c.Score Difference between model and data points\n    ss=lambda data,model:((data-model)**2).sum()\n    return ss(Zd,Zm)\n#========================================================\n\n\n#4.Optimize Fit\n#=======================================================\nfit_score=score(rates)\nansw=fmin(score,(rates),full_output=1,maxiter=1000000)\nbestrates=answ[0]\nbestscore=answ[1]\nP,d,B,G,A=answ[0]\nnewrates=(P,d,B,G,A)\n#=======================================================\n\n#5.Generate Solution to System\n#=======================================================\nF0,F1,F2,T=eq(newrates,y0,start_time,end_time,intervals)\nZm=F1[mindex]\nTm=T[mindex]\n#======================================================\n```\n\n\nNow in the #optimize fit section, is there any way I can get best possible values of bestrates when I restrict the values of \"rates\" like lb <= P, d, B, G, A <= ub where lb=lower bound and ub=upper bound and manage to get minimum of score in that restricted region? It need not be the most optimized value. fmin uses Nelder-Mead (simplex) algorithm. \n\nI am quite new to this, so any help in the right direction would be awesome. Feel free to ask any doubts regarding the code and I will answer to best of my knowledge. . Thank You.\n    ", "Answer": "\r\nI'm not sure why the original author of Adventures in Python : Fitting a Differential Equation System to Data jumps through hoops to get at the samples corresponding to the given data points, the procedure can be greatly simplified by passing to ```\neq```\n a time array instead of its construction parameters\n\n```\n#=======================================================\ndef eq(par,initial_cond,t):\n     #differential-eq-system----------------------\n     def funct(y,t):\n        Si, Zi, Ri=y\n        P,d,B,G,A=par\n        # the model equations (see Munz et al. 2009)\n        f0 = P - B*Si*Zi - d*Si\n        f1 = B*Si*Zi + G*Ri - A*Si*Zi\n        f2 = d*Si + A*Si*Zi - G*Ri\n        return [f0, f1, f2]\n     #integrate------------------------------------\n     ds = odeint(funct,initial_cond,t)\n     return ds.T\n#=======================================================\n```\n\n\nThis can then be called as \n\n```\nT = np.linspace(0, 5.0, 1000+1)\nS,Z,R=eq(rates,y0,T)\n```\n\n\nbut also in a way to produce only the values needed in the ```\nscore```\n function\n\n```\nTm=np.append([0],Td)\nSm,Zm,Rm=eq(rates,y0,Tm)\n```\n\n\nThis then simplifies the score function to\n\n```\ndef score(parms):\n    #a.Get Solution to system\n    Sm,Zm,Rm=eq(parms,y0,Tm)\n    #c.Score Difference between model and data points\n    ss=lambda data,model:((data-model)**2).sum()\n    return ss(Zd,Zm[1:])\n```\n\n\nNow if you want for example strongly reject negative parameters, then you could change the return value to\n\n```\n    return ss(Zd,Zm[1:]) + 1e6*sum(max(0,-x)**2 for x in parms)\n```\n\n\nwhich indeed renders all parameters positive (where previously in my notebook there was a negative first parameter).\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to represent a bus ride in linear programming?\r\n                \r\nHi I work as a programmer at a bus company and I need to implement a ride initialization request. I think it might be a linear programming problem but I'm not sure and I ask for some help :) \n\nA passenger sends my server a request to initialize a bus ride.\n\nThe request includes the different entities for the ride. For example a request might be :\n\n```\nRequest = [2 Adults, 3 Children, 1 Dog, 2 Bikes]\n```\n\n\nMy server knows what are the different tickets the passenger has. \nEach ticket has a cost (the price the passenger bought it with) and a list of entities it enables a ride for.  \n\nFor example, a passenger might possess :\n\n```\nTicket1- cost 10, enables [1 Adult, 1 Bike]\nTicket2- cost 20, enables [1 Child]\nTicket3- cost 10, enables [1 Adult, 1 Dog]\n```\n\n\nI would love some help designing an algorithm that finds the optimal collection of tickets to use for the ride (optimal being the cheapest combination), or return error if the ride isn't feasible.  \n\nI think this could be represented as a linear programming problem and then I can just use the simplex algorithm to find the optimal solution. But I'm not sure how to do it... please help me I'm not much of a math expert :/\n\nThank you!\n    ", "Answer": "\r\nHere is some R code that may be used as a template for your problem.\n\n```\nlibrary(lpSolveAPI)\n\nsolve_request <- function(request, available_tickets) {\n    lprec <- make.lp(0, ncol=3) # decision variables: how many tickets of type 1, 2 or 3 \n    set.type(lprec, columns=seq(1,3), type=\"integer\") # the decision variables are integers, there are no half tickets\n    set.objfn(lprec, obj=c(10, 20, 10)) # objective: minimize costs of tickets\n\n    # first type of constraints: no more tickets than available\n    add.constraint(lprec, xt=c(1,0,0), type=\"<=\", rhs=available_tickets[\"t1\"])\n    add.constraint(lprec, xt=c(0,1,0), type=\"<=\", rhs=available_tickets[\"t2\"])\n    add.constraint(lprec, xt=c(0,0,1), type=\"<=\", rhs=available_tickets[\"t3\"])\n\n    # second type of constraint: choosen ticket must meet request\n    add.constraint(lprec, xt=c(1,0,1), type=\">=\", rhs=request[\"adults\"])\n    add.constraint(lprec, xt=c(0,1,0), type=\">=\", rhs=request[\"children\"])\n    add.constraint(lprec, xt=c(0,0,1), type=\">=\", rhs=request[\"dogs\"])\n    add.constraint(lprec, xt=c(1,0,1), type=\">=\", rhs=request[\"bikes\"])\n\n    solve(lprec)\n    return(setNames(get.variables(lprec), c(\"t1\", \"t2\", \"t3\")))\n}\n\nsolve_request(request=c(adults=2, children=3, dogs=1, bikes=2), available_tickets=c(t1=10, t2=10, t3=10))\n```\n\n\nIt returns\n\n```\nt1 t2 t3 \n 1  3  1 \n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Matlab: linprog violates constraints\r\n                \r\nI have a linear programming optimization, with an equality constraint. (min f'*x such that Aeq *x = beq, x >= lb)\n\n```\nlinprog(f,[],[],Aeq,beq,lb,[],x0,options)\n```\n\n\nWhen i get the result, it should be valid that Aeq*x=beq, but it is violated in the output by:\n\n```\nnorm(Aeq*x-beq)=4.7919e-05\n```\n\n\nthe output variable gives\noutput.constrviolation=3.2781e-05\n\nI use the 'interior-point' algorithm, it seams there is no option to lower the tolerance to this violation (in the dual-simplex it can be done with TolCon)?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Generating tile noise maps \"on the fly\"\r\n                \r\nI’m interested in generating 3D height maps for a 2D game I am working on. I am using this to create land masses like in Minecraft or Dwarf Fortress.\nI've created 2D heightmaps before, but I used a very rudimentary algorithm that just interpolated between points of a fully random noise array to create a fixed size map. This doesn't tile however since if I try to add a new map next to it, it doesn't account for the height of the existing map.\nI have read about Perlin and Simplex noise, but I’m now confused on how to apply Perlin or Simplex noise to a 2D array of height values.\nAny help with this would be greatly appreciated. I have no idea what to do anymore. The term 'octaves' not on sheet music scares me.\n    ", "Answer": "\r\nExactly, you have to look for Perlin/Simplex noise. Think of it as a function f(x,y,...) (as many variable as you wish) that will output random-looking noise. The difference with pure noise is that it acts on gradients, so it will look more natural since it \"draws\" gradients instead of plain noise with high local variability. Simplex noise is pretty much the same as Perlin's but it divides space in simplexes instead of operating in n-dimensional grids like Perlin does. This alleviates computational cost and has some more benefits.\n\nIt might seem scary, but it's simple actually. You're scared about octaves, but they're pretty much the same as octaves in music: just higher (or lower) frequency noise mixed with the original output. Talking about sheet music, it's like playing C4 and C5 at the same time. It's still C but it has some flavor added (little spikes in the waveform.) Don't be afraid and keep researching, it's not that hard.\n\nRegarding tiling:\n\nIf you mean linear tiling (like Minecraft does) you just have to use the same seed for the noise algorithm. As soon as you approach your new boundaries, just generate the new chunk of data and it will tile perfectly (just like it does if you infinitely fill with noise.)\n\nIf you mean torus tiling (repeating tiles, think Pacman for instance) I found the best solution is to generate your noise tile and then interpolating near the borders as if it were tiled. The noise will deform to match sides and it will be completely tileable.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Java 2D Side-View Terrain Generation\r\n                \r\nI am trying to create a game with a Terraria like feel and I have browsed many threads/forums and can't seem to get anything working for myself. I've chosen the Simplex Noise algorithm to try and generate a side view game like Terraria but it's just a jumbled mess. I was wondering if someone could help me make a terrain generator using a Simplex Noise class I found online? I have blocks that are 32x32 that I want to spawn in for the terrain and then some I want at certain depths, etc. I'll post the code to the class below. I'm just starting with this random generation stuff and it is quite tricky for me.\n\n```\nimport java.util.Random;\n\npublic class SimplexNoise {\n\n    private static int grad3[][] = { {1,1,0},{-1,1,0},{1,-1,0},{-1,-1,0},\n                                    {1,0,1},{-1,0,1},{1,0,-1},{-1,0,-1},\n                                    {0,1,1},{0,-1,1},{0,1,-1},{0,-1,-1}};\n\n    private static int p[] = { 151,160,137,91,90,15,\n                            131,13,201,95,96,53,194,233,7,225,140,36,103,30,69,142,8,99,37,240,21,10,23,\n                            190, 6,148,247,120,234,75,0,26,197,62,94,252,219,203,117,35,11,32,57,177,33,\n                            88,237,149,56,87,174,20,125,136,171,168, 68,175,74,165,71,134,139,48,27,166,\n                            77,146,158,231,83,111,229,122,60,211,133,230,220,105,92,41,55,46,245,40,244,\n                            102,143,54, 65,25,63,161, 1,216,80,73,209,76,132,187,208, 89,18,169,200,196,\n                            135,130,116,188,159,86,164,100,109,198,173,186, 3,64,52,217,226,250,124,123,\n                            5,202,38,147,118,126,255,82,85,212,207,206,59,227,47,16,58,17,182,189,28,42,\n                            223,183,170,213,119,248,152, 2,44,154,163, 70,221,153,101,155,167, 43,172,9,\n                            129,22,39,253, 19,98,108,110,79,113,224,232,178,185, 112,104,218,246,97,228,\n                            251,34,242,193,238,210,144,12,191,179,162,241, 81,51,145,235,249,14,239,107,\n                            49,192,214, 31,181,199,106,157,184, 84,204,176,115,121,50,45,127, 4,150,254,\n                            138,236,205,93,222,114,67,29,24,72,243,141,128,195,78,66,215,61,156,180};\n\n    // To remove the need for index wrapping, double the permutation table length\n    private static int perm[] = new int[512];\n    static { \n        for(int i = 0; i < 512; i++) \n            perm[i] = p[i & 255]; \n    }\n\n    // This method is a *lot* faster than using (int)Math.floor(x)\n    private static int fastfloor(double x) {\n        return x > 0 ? (int)x : (int)x - 1;\n    }\n\n    private static double dot(int g[], double x, double y) {\n        return g[0] * x + g[1] * y; \n    }\n\n    // 2D simplex noise\n    public static double noise(double xin, double yin) {\n        double n0, n1, n2;\n\n        final double F2 = 0.5 * (Math.sqrt(3.0) - 1.0);\n        double s = (xin + yin) * F2;\n        int i = fastfloor(xin + s);\n        int j = fastfloor(yin + s);\n\n        final double G2 = (3.0 - Math.sqrt(3.0)) / 6.0;\n        double t = (i + j) * G2;\n        double X0 = i - t;\n        double Y0 = j - t;\n        double x0 = xin - X0;\n        double y0 = yin - Y0;\n\n        int i1, j1;\n        if (x0 > y0) {\n            i1=1; \n            j1=0;\n        } else {\n            i1 = 0;\n            j1 = 1;\n        }\n\n        double x1 = x0 - i1 + G2;\n        double y1 = y0 - j1 + G2;\n        double x2 = x0 - 1.0 + 2.0 * G2;\n        double y2 = y0 - 1.0 + 2.0 * G2;\n\n        int ii = i & 255;\n        int jj = j & 255;\n        int gi0 = perm[ii + perm[jj]] % 12;\n        int gi1 = perm[ii + i1 + perm[jj + j1]] % 12;\n        int gi2 = perm[ii + 1 + perm[jj + 1]] % 12;\n\n        double t0 = 0.5 - x0 * x0 - y0 * y0;\n        if(t0 < 0) \n            n0 = 0.0;\n        else {\n            t0 *= t0;\n            n0 = t0 * t0 * dot(grad3[gi0], x0, y0);\n        }\n\n        double t1 = 0.5 - x1 * x1 - y1 * y1;\n        if(t1 < 0) \n            n1 = 0.0;\n        else {\n            t1 *= t1;\n            n1 = t1 * t1 * dot(grad3[gi1], x1, y1);\n        }\n\n        double t2 = 0.5 - x2 * x2 - y2 * y2;\n        if(t2 < 0)\n            n2 = 0.0;\n        else {\n            t2 *= t2;\n            n2 = t2 * t2 * dot(grad3[gi2], x2, y2);\n        }\n\n        return 70.0 * (n0 + n1 + n2);\n    }\n\n    public static void genGrad(long seed) {\n        Random rnd = new Random(seed);\n        for(int i = 0; i < 255; i++)\n          p[i] = i;\n        for(int i = 0; i < 255; i++) {\n          int j = rnd.nextInt(255);\n          int nSwap = p[i];\n          p[i]  = p[j];\n          p[j]  = nSwap;\n        }\n\n        for(int i = 0; i < 512; i++) \n            perm[i] = p[i & 255];\n    }\n\n}\n```\n\n\nHere is the new code I'm using and it prints out all the blocks at the same location: \n\n```\nBlock[][] chunk = new Block[Chunk.CHUNK_WIDTH_BLOCKS][Chunk.CHUNK_HEIGHT_BLOCKS];\n    float[][] positions = new float[Chunk.CHUNK_WIDTH_BLOCKS][Chunk.CHUNK_HEIGHT_BLOCKS];\n    float frequency = 1.0f / (float) chunk.length; \n\n    for (int x = 0; x < chunk.length - 1; x++) \n    { \n        for (int y = 0; y < chunk[x].length - 1; y++) \n        { \n            positions[x][y] = SimplexNoise.Generate((float) x * frequency, (float) y * frequency);\n            g.drawRect(positions[x][0], positions[0][y], Block.BLOCK_WIDTH, Block.BLOCK_HEIGHT);\n        } \n    } \n\n    for (int x = 0; x < Chunk.CHUNK_WIDTH_BLOCKS; x++)\n    {\n        for (int y = 0; y < Chunk.CHUNK_HEIGHT_BLOCKS; y++)\n        {\n            if (positions[x][y] < 0f)\n                chunk[x][y] = new Block();\n            if (positions[x][y] >= -0f)\n                chunk[x][y] = new Block();\n        }\n    }\n```\n\n    ", "Answer": "\r\nI just found this LINK to explain how to use Perlin noise in 2d terrain generation like terraria. \n\nHere is the code for the noise class:\n\n```\npublic class Noise\n    {\n        /// <summary>\n        /// 1D simplex noise\n        /// </summary>\n        /// <param name=\"x\"></param>\n        /// <returns></returns>\n        public static float Generate(float x)\n        {\n            int i0 = FastFloor(x);\n            int i1 = i0 + 1;\n            float x0 = x - i0;\n            float x1 = x0 - 1.0f;\n            float n0, n1;\n            float t0 = 1.0f - x0 * x0;\n            t0 *= t0;\n            n0 = t0 * t0 * grad(perm[i0 & 0xff], x0);\n            float t1 = 1.0f - x1 * x1;\n            t1 *= t1;\n            n1 = t1 * t1 * grad(perm[i1 & 0xff], x1);\n            // The maximum value of this noise is 8*(3/4)^4 = 2.53125\n            // A factor of 0.395 scales to fit exactly within [-1,1]\n            return 0.395f * (n0 + n1);\n        }\n        /// <summary>\n        /// 2D simplex noise\n        /// </summary>\n        /// <param name=\"x\"></param>\n        /// <param name=\"y\"></param>\n        /// <returns></returns>\n        public static float Generate(float x, float y)\n        {\n            const float F2 = 0.366025403f; // F2 = 0.5*(sqrt(3.0)-1.0)\n            const float G2 = 0.211324865f; // G2 = (3.0-Math.sqrt(3.0))/6.0\n            float n0, n1, n2; // Noise contributions from the three corners\n            // Skew the input space to determine which simplex cell we're in\n            float s = (x + y) * F2; // Hairy factor for 2D\n            float xs = x + s;\n            float ys = y + s;\n            int i = FastFloor(xs);\n            int j = FastFloor(ys);\n            float t = (float)(i + j) * G2;\n            float X0 = i - t; // Unskew the cell origin back to (x,y) space\n            float Y0 = j - t;\n            float x0 = x - X0; // The x,y distances from the cell origin\n            float y0 = y - Y0;\n            // For the 2D case, the simplex shape is an equilateral triangle.\n            // Determine which simplex we are in.\n            int i1, j1; // Offsets for second (middle) corner of simplex in (i,j) coords\n            if (x0 > y0) { i1 = 1; j1 = 0; } // lower triangle, XY order: (0,0)->(1,0)->(1,1)\n            else { i1 = 0; j1 = 1; }      // upper triangle, YX order: (0,0)->(0,1)->(1,1)\n            // A step of (1,0) in (i,j) means a step of (1-c,-c) in (x,y), and\n            // a step of (0,1) in (i,j) means a step of (-c,1-c) in (x,y), where\n            // c = (3-sqrt(3))/6\n            float x1 = x0 - i1 + G2; // Offsets for middle corner in (x,y) unskewed coords\n            float y1 = y0 - j1 + G2;\n            float x2 = x0 - 1.0f + 2.0f * G2; // Offsets for last corner in (x,y) unskewed coords\n            float y2 = y0 - 1.0f + 2.0f * G2;\n            // Wrap the integer indices at 256, to avoid indexing perm[] out of bounds\n            int ii = i % 256;\n            int jj = j % 256;\n            // Calculate the contribution from the three corners\n            float t0 = 0.5f - x0 * x0 - y0 * y0;\n            if (t0 < 0.0f) n0 = 0.0f;\n            else\n            {\n                t0 *= t0;\n                n0 = t0 * t0 * grad(perm[ii + perm[jj]], x0, y0);\n            }\n            float t1 = 0.5f - x1 * x1 - y1 * y1;\n            if (t1 < 0.0f) n1 = 0.0f;\n            else\n            {\n                t1 *= t1;\n                n1 = t1 * t1 * grad(perm[ii + i1 + perm[jj + j1]], x1, y1);\n            }\n            float t2 = 0.5f - x2 * x2 - y2 * y2;\n            if (t2 < 0.0f) n2 = 0.0f;\n            else\n            {\n                t2 *= t2;\n                n2 = t2 * t2 * grad(perm[ii + 1 + perm[jj + 1]], x2, y2);\n            }\n            // Add contributions from each corner to get the final noise value.\n            // The result is scaled to return values in the interval [-1,1].\n            return 40.0f * (n0 + n1 + n2); // TODO: The scale factor is preliminary!\n        }\n\n        public static float Generate(float x, float y, float z)\n        {\n            // Simple skewing factors for the 3D case\n            const float F3 = 0.333333333f;\n            const float G3 = 0.166666667f;\n            float n0, n1, n2, n3; // Noise contributions from the four corners\n            // Skew the input space to determine which simplex cell we're in\n            float s = (x + y + z) * F3; // Very nice and simple skew factor for 3D\n            float xs = x + s;\n            float ys = y + s;\n            float zs = z + s;\n            int i = FastFloor(xs);\n            int j = FastFloor(ys);[attachment=11149:perlinBug.png]\n            int k = FastFloor(zs);\n            float t = (float)(i + j + k) * G3;\n            float X0 = i - t; // Unskew the cell origin back to (x,y,z) space\n            float Y0 = j - t;\n            float Z0 = k - t;\n            float x0 = x - X0; // The x,y,z distances from the cell origin\n            float y0 = y - Y0;\n            float z0 = z - Z0;\n            // For the 3D case, the simplex shape is a slightly irregular tetrahedron.\n            // Determine which simplex we are in.\n            int i1, j1, k1; // Offsets for second corner of simplex in (i,j,k) coords\n            int i2, j2, k2; // Offsets for third corner of simplex in (i,j,k) coords\n            /* This code would benefit from a backport from the GLSL version! */\n            if (x0 >= y0)\n            {\n                if (y0 >= z0)\n                { i1 = 1; j1 = 0; k1 = 0; i2 = 1; j2 = 1; k2 = 0; } // X Y Z order\n                else if (x0 >= z0) { i1 = 1; j1 = 0; k1 = 0; i2 = 1; j2 = 0; k2 = 1; } // X Z Y order\n                else { i1 = 0; j1 = 0; k1 = 1; i2 = 1; j2 = 0; k2 = 1; } // Z X Y order\n            }\n            else\n            { // x0<y0\n                if (y0 < z0) { i1 = 0; j1 = 0; k1 = 1; i2 = 0; j2 = 1; k2 = 1; } // Z Y X order\n                else if (x0 < z0) { i1 = 0; j1 = 1; k1 = 0; i2 = 0; j2 = 1; k2 = 1; } // Y Z X order\n                else { i1 = 0; j1 = 1; k1 = 0; i2 = 1; j2 = 1; k2 = 0; } // Y X Z order\n            }\n            // A step of (1,0,0) in (i,j,k) means a step of (1-c,-c,-c) in (x,y,z),\n            // a step of (0,1,0) in (i,j,k) means a step of (-c,1-c,-c) in (x,y,z), and\n            // a step of (0,0,1) in (i,j,k) means a step of (-c,-c,1-c) in (x,y,z), where\n            // c = 1/6.\n            float x1 = x0 - i1 + G3; // Offsets for second corner in (x,y,z) coords\n            float y1 = y0 - j1 + G3;\n            float z1 = z0 - k1 + G3;\n            float x2 = x0 - i2 + 2.0f * G3; // Offsets for third corner in (x,y,z) coords\n            float y2 = y0 - j2 + 2.0f * G3;\n            float z2 = z0 - k2 + 2.0f * G3;\n            float x3 = x0 - 1.0f + 3.0f * G3; // Offsets for last corner in (x,y,z) coords\n            float y3 = y0 - 1.0f + 3.0f * G3;\n            float z3 = z0 - 1.0f + 3.0f * G3;\n            // Wrap the integer indices at 256, to avoid indexing perm[] out of bounds\n            int ii = i % 256;\n            int jj = j % 256;\n            int kk = k % 256;\n            // Calculate the contribution from the four corners\n            float t0 = 0.6f - x0 * x0 - y0 * y0 - z0 * z0;\n            if (t0 < 0.0f) n0 = 0.0f;\n            else\n            {\n                t0 *= t0;\n                n0 = t0 * t0 * grad(perm[ii + perm[jj + perm[kk]]], x0, y0, z0);\n            }\n            float t1 = 0.6f - x1 * x1 - y1 * y1 - z1 * z1;\n            if (t1 < 0.0f) n1 = 0.0f;\n            else\n            {\n                t1 *= t1;\n                n1 = t1 * t1 * grad(perm[ii + i1 + perm[jj + j1 + perm[kk + k1]]], x1, y1, z1);\n            }\n            float t2 = 0.6f - x2 * x2 - y2 * y2 - z2 * z2;\n            if (t2 < 0.0f) n2 = 0.0f;\n            else\n            {\n                t2 *= t2;\n                n2 = t2 * t2 * grad(perm[ii + i2 + perm[jj + j2 + perm[kk + k2]]], x2, y2, z2);\n            }\n            float t3 = 0.6f - x3 * x3 - y3 * y3 - z3 * z3;\n            if (t3 < 0.0f) n3 = 0.0f;\n            else\n            {\n                t3 *= t3;\n                n3 = t3 * t3 * grad(perm[ii + 1 + perm[jj + 1 + perm[kk + 1]]], x3, y3, z3);\n            }\n            // Add contributions from each corner to get the final noise value.\n            // The result is scaled to stay just inside [-1,1]\n            return 32.0f * (n0 + n1 + n2 + n3); // TODO: The scale factor is preliminary!\n        }\n        private static byte[] perm = new byte[512] { 151,160,137,91,90,15,\n              131,13,201,95,96,53,194,233,7,225,140,36,103,30,69,142,8,99,37,240,21,10,23,\n              190, 6,148,247,120,234,75,0,26,197,62,94,252,219,203,117,35,11,32,57,177,33,\n              88,237,149,56,87,174,20,125,136,171,168, 68,175,74,165,71,134,139,48,27,166,\n              77,146,158,231,83,111,229,122,60,211,133,230,220,105,92,41,55,46,245,40,244,\n              102,143,54, 65,25,63,161, 1,216,80,73,209,76,132,187,208, 89,18,169,200,196,\n              135,130,116,188,159,86,164,100,109,198,173,186, 3,64,52,217,226,250,124,123,\n              5,202,38,147,118,126,255,82,85,212,207,206,59,227,47,16,58,17,182,189,28,42,\n              223,183,170,213,119,248,152, 2,44,154,163, 70,221,153,101,155,167, 43,172,9,\n              129,22,39,253, 19,98,108,110,79,113,224,232,178,185, 112,104,218,246,97,228,\n              251,34,242,193,238,210,144,12,191,179,162,241, 81,51,145,235,249,14,239,107,\n              49,192,214, 31,181,199,106,157,184, 84,204,176,115,121,50,45,127, 4,150,254,\n              138,236,205,93,222,114,67,29,24,72,243,141,128,195,78,66,215,61,156,180,\n              151,160,137,91,90,15,\n              131,13,201,95,96,53,194,233,7,225,140,36,103,30,69,142,8,99,37,240,21,10,23,\n              190, 6,148,247,120,234,75,0,26,197,62,94,252,219,203,117,35,11,32,57,177,33,\n              88,237,149,56,87,174,20,125,136,171,168, 68,175,74,165,71,134,139,48,27,166,\n              77,146,158,231,83,111,229,122,60,211,133,230,220,105,92,41,55,46,245,40,244,\n              102,143,54, 65,25,63,161, 1,216,80,73,209,76,132,187,208, 89,18,169,200,196,\n              135,130,116,188,159,86,164,100,109,198,173,186, 3,64,52,217,226,250,124,123,\n              5,202,38,147,118,126,255,82,85,212,207,206,59,227,47,16,58,17,182,189,28,42,\n              223,183,170,213,119,248,152, 2,44,154,163, 70,221,153,101,155,167, 43,172,9,\n              129,22,39,253, 19,98,108,110,79,113,224,232,178,185, 112,104,218,246,97,228,\n              251,34,242,193,238,210,144,12,191,179,162,241, 81,51,145,235,249,14,239,107,\n              49,192,214, 31,181,199,106,157,184, 84,204,176,115,121,50,45,127, 4,150,254,\n              138,236,205,93,222,114,67,29,24,72,243,141,128,195,78,66,215,61,156,180\n            };\n        private static int FastFloor(float x)\n        {\n            return (x > 0) ? ((int)x) : (((int)x) - 1);\n        }\n        private static float grad(int hash, float x)\n        {\n            int h = hash & 15;\n            float grad = 1.0f + (h & 7);   // Gradient value 1.0, 2.0, ..., 8.0\n            if ((h & 8) != 0) grad = -grad;      // Set a random sign for the gradient\n            return (grad * x);         // Multiply the gradient with the distance\n        }\n        private static float grad(int hash, float x, float y)\n        {\n            int h = hash & 7;     // Convert low 3 bits of hash code\n            float u = h < 4 ? x : y;  // into 8 simple gradient directions,\n            float v = h < 4 ? y : x;  // and compute the dot product with (x,y).\n            return ((h & 1) != 0 ? -u : u) + ((h & 2) != 0 ? -2.0f * v : 2.0f * v);\n        }\n        private static float grad(int hash, float x, float y, float z)\n        {\n            int h = hash & 15;   // Convert low 4 bits of hash code into 12 simple\n            float u = h < 8 ? x : y; // gradient directions, and compute dot product.\n            float v = h < 4 ? y : h == 12 || h == 14 ? x : z; // Fix repeats at h = 12 to 15\n            return ((h & 1) != 0 ? -u : u) + ((h & 2) != 0 ? -v : v);\n        }\n        private static float grad(int hash, float x, float y, float z, float t)\n        {\n            int h = hash & 31;    // Convert low 5 bits of hash code into 32 simple\n            float u = h < 24 ? x : y; // gradient directions, and compute dot product.\n            float v = h < 16 ? y : z;\n            float w = h < 8 ? z : t;\n            return ((h & 1) != 0 ? -u : u) + ((h & 2) != 0 ? -v : v) + ((h & 4) != 0 ? -w : w);\n }\n}\n```\n\n\nThe way that he uses it is like so:\n\n```\nprivate void CreatePerlinWorld()\n        {\n            world = new Tile[_maxWidth, _maxHeight];\n            diamond = new float[_maxWidth, _maxHeight];\n            for (int x = 0; x < world.GetLength(0) - 1; x++)\n            {\n                for (int y = 0; y < world.GetLength(1) - 1; y++)\n                {\n                    diamond[x,y] = Noise.Generate(x, y);\n                }\n            }\n        }\n        private void GeneratePerlinWorld()\n        {\n            for (int x = 0; x < _maxWidth; x++)\n            {\n                for (int y = 0; y < _maxHeight; y++)\n                {\n                    if (diamond[x, y] < 0f)\n                        world[x, y] = new Tile(TileType.None, TileCollision.Passable, ToolType.None);\n                    if (diamond[x, y] >= -0f)\n                        world[x, y] = new Tile(TileType.Dirt, TileCollision.Impassable, ToolType.Pickaxe);\n                }\n            }\n        }\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to get output from compute shader\r\n                \r\nI am working on a procedurally generated terrain simulator using the marching cubes algorithm and simplex noise. The problem with my current program is that it assigns a value to each vertex and generates triangles one at a time. After doing some research, I decided that using Compute Shaders(One for assigning values to each vertex using simplex noise, and one for creating the triangle mesh) will significantly increase the performance. I have a very basic idea as to how I want the shader to interact with my program but I have no clue how to make it.\n```\nUseNoiseComputeShader();//get output of ComputeShader.\noutput = noiseOutput;\n\nUseMeshComputeShader(output);//get output of ComputeShader.\nfloat[] vertices = outputMesh;\n\n//output vertices to VAO and draw\n```\n\nI have seen some people use Compute Shaders for similar projects online but they were using Unity and HLSL so I was wondering if it was at all possible using OpenGL and GLSL.\n    ", "Answer": "\r\nIn general a compute shader writes to an Image or Shader Storage Buffer Object.\nAn image can be read and written by image load and store:\n```\nlayout(rgba32f, binding = 1) readonly uniform image2D img_input;\nlayout(rgba32f, binding = 2) writeonly uniform image2D img_output;\n\nvoid main()\n{\n    ivec2 coord = ivec2(gl_GlobalInvocationID.xy);\n    vec4 color = imageLoad(img_input, coord);\n    imageStore(img_output, coord, color);\n}\n```\n\nTo a Shader Storage Buffer Object can be written by assignment or Atomic operations\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Procedural Maze Algorithm With Cells Determined Independently of Neighbors\r\n                \r\nI was thinking about maze algorithms recently (mostly because I'm working on a game, but I felt this is a more general question than game development related). In simple terms, I was wondering if there is a sort of maze algorithm that can generate (a possibly infinite number of) cells without any information specifically about the cell's neighbors. I imagine, if such a thing were possible, it would rely heavily upon noise functions such as Perlin or Simplex.\n\nEach cell has four walls, these are used when actually rendering the maze so that corridors and walls are not the same thickness.\n\nLet's say, for example, I'd like a cell at (32, 15) to generate its walls.\n\nI know of algorithms like Ellers (which requires a limited number of columns, but infinite rows) and the Virtual fractal Mazes algorithm (which needs to know previous cells in order to build upon them infinitely in both x and y directions).\n\nDoes anyone know of any algorithm I could look into for this specific request? If not, are there any algorithms that are good for chunk-based mazes that you know of?\n\n(Note: I did search around for a bit through StackOverflow to see if there were any questions with similar requests to mine, but I did not come across any. If you happen to know of one, a link would be greatly appreciated :D)\n\nThank you in advance.\n    ", "Answer": "\r\nSeeeeeecreeeets. My preeeeciooouss secretts. But yeah I can understand the frustration so I'll throw this one to you OP/SO. Feel free to update the PCG Wiki if you're not as lazy as me :3\n\nThere are actually many ways to do this. Some of the best techniques for procgen are:\n\n\nAsking what you really want.\nDesign backwards. Play in reverse. Result is forwards.\nLook at a random sampling of your target goal and try to see overall patterns.\n\n\nBut to get back to the question, there are two simple ways and they both start from asking what your really want. I'll give those first.\n\nThe first is to create 2 layers. Both are random noise. You connect the top and the bottom so they're fully connected. No isolated portions. This is asking what you really want which is connected-ness. And then guaranteeing it in a local clean-up step. (tbh I forget the function applied to layer 2 that guarantees connected-ness. I can't find the code atm.... But I remember it was a really simple local function... XOR, Curl, or something similar. Maybe you can figure it out before I fix this).\n\nThe second way is using the properties of your functions. As long as your random function is smooth enough you can take the gradient and assign a tile to it. The way you assign the tiles changes the maze structure but you can guarantee connectivity by clever selection of tiles for each gradient (b/c similar or opposite gradients are more likely to be near each other on a smooth gradient function). From here your smooth random can be any form of Perlin Noise, etc. Once again a asking what you want technique.\n\nFor backwards-reversed you unfortunately have an NP problem (I'm not sure if it's hard, complete, or whatever it's been a while since I've worked on this...). So while you could generate a random map of distances down a maze path. And then from there generate the actual obstacles... it's not really advisable. There's also a ton of consideration on different cases even for small mazes...\n\n```\n 012\n 123\n 234\n```\n\n\nIs simple. There's a column in the lower right corner of 0 and the middle 2 has an _| shaped wall.\n\n```\n042\n123\n234\n```\n\n\nThis one makes less sense. You still are required to have the same basic walls as before on all the non-changed squares... But you can't have that 4. It needs to be within 1 of at least a single neighbor. (I mean you could have a +3 cost for that square by having something like a conveyor belt or something, but then we're out of the maze problem) Okay so....\n\n```\n032\n123\n234\n```\n\n\nMakes more sense but the 2 in the corner is nonsense once again. Flipping that from a trough to a peak would give.\n\n```\n034\n123\n234\n```\n\n\nWhich makes sense. At any rate. If you can get to this point then looking at local neighbors will give you walls if it's +/-1 then no wall. Otherwise wall. Also note that you can break the rules for the distance map in a consistent way and make a maze just fine. (Like instead of allowing a column picking a wall and throwing it up. This is just loop splitting at this point and should be safe)\n\nFor random sampling as the final one that I'm going to look at... Certain maze generation algorithms in the limit take on some interesting properties either as an average configuration or after millions of steps. Some form Voronoi regions. Some form concentric circles with a randomly flipped wall to allow a connection between loops. Etc. The loop one is good example to work off of. Create a set of loops. Flip a random wall on each loop. One will delete a wall which will create access to the next loop. One will split a path and offer a dead-end and a continuation. For a random flip to be a failure there has to be an opening and a split made right next to each other (unless you allow diagonals then we're good). So make loops. Generate random noise per loop. Xor together. Replace local failures with a fixed path if no diagonals are allowed.\n\nSo how do we get random noise per loop? Or how do we get better loops than just squares? Just take a random function. Separate divergence and now you have a loop map. If you have the differential equations for the source random function you can pick one random per loop. A simpler way might be to generate concentric circular walls and pick a random point at each radius to flip. Then distort the final result. You have to be careful your distortion doesn't violate any of your path-connected-ness conditions at that point though.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "GLSL-ES Random grainy noise with FP16 limit\r\n                \r\nI am trying to write a compact and simple noise function with a strictly FP16 limit.\nThis is with what I came out so far, but I think somewhere on the operation the number gets too small for fract or sin, since in the GPU I must write this for these are within the FP16 limits. Any ideas on what am I doing wrong? BY the way, I cannot use a time variables, neither sample noise textures. The function I need to get right must be compact, small and self-sufficient, and produce a simple grainy noise effect.\nNote: The next algorithm works fine in any desktop GPU card, but fails completely on the \"MALI 400 MP\" GPU, since this one has a FP16 limitation on float values.\n\n```\nvec3 noise(vec3 color)\n{\n    float variation = length(color);\n    float dot_product = dot(variation, -0.577350269);\n    float sin_result = sin(dot_product) * 1.19245;\n    float random = fract(sin_result);\n    return color + vec3(random);\n}\n```\n\n\nIf any one can recommend any other random function for GLSL-ES but strictly with a FP16 limit, would also be great. I know about other random implementations such as simplex noise, but these are too large and slow for what I need to do. So Perlin and Simplex noise algorithms are not an option.\n    ", "Answer": "\r\nThese are the ones that I use but I don't know if either works in a FP16 limit:\n\n```\n// source: http://byteblacksmith.com/improvements-to-the-canonical-one-liner-glsl-rand-for-opengl-es-2-0/\nhighp float rand(vec2 co)\n{\n      highp float a = 12.9898;\n      highp float b = 78.233;\n      highp float c = 43758.5453;\n      highp float dt= dot(co.xy ,vec2(a,b));\n      highp float sn= mod(dt,3.14);\n      return fract(sin(sn) * c);\n}\n\n float rand2(vec2 co)\n{\n      return fract(sin(dot(co.xy,vec2(12.9898,78.233))) * 43758.5453);\n}\n```\n\n\nI didn't create either of these.  The link to the original author is above.  I actually use rand2 and didn't have the issue mentioned on that blog. To make a greyscale noise do something like:\n\n```\nfloat randColor = rand(v_position);\ngl_FragColor = vec4(randColor);\n```\n\n\nTo do a full color noise it would take 3 times longer and you'd do:\n\n```\ngl_FragColor = vec4(rand(v_position), rand(v_position), rand(v_position), 1.0);\n```\n\n\nTo add noise to whatever you're drawing you could:\n\n```\nfloat randColor = rand(v_position) * .1;  // to add 10% noise\ngl_FragColor = vec4(gl_FragColor.r + randColor, gl_FragColor.g + randColor, gl_FragColor.b + randColor, 1.0);\n```\n\n\nBy the way, this is slow.  On an iPhone5 this works fine with no major slowdown.  But on a 4S it dropped by fps down to 30.  If I removed adding the noise it raised it to 60.  So beware.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Sometimes entering an infinite loop in EPA algorithm when calculating contact normal and penetration depth\r\n                \r\nCurrently I'm in the middle of developing a 2D physics engine by scratch. And Everything worked well by far. It's object oriented, obviously, with Vectors, matrices and shape classes written from scratch by myself. Collision are not yet that organized, but before that I need to make sure it works. \n\nSo for educational purposes I decided to implement GJK algorithm for collision detection and EPA for calculating contact normal. The GJK part works fine. And from the simplex (Triangle since it's 2D) I calculate the closest edge and from there I followed the algorithm. But for some reason which I can't seem to find, in some instances only, the program enters an infinite loop, adding new Vertices to the vertices list, but when I print them they're all the same, And the difference that should be near 0 in EPA gives big results. such as 70.55. So I hope you'll be able to help. Thank you in advance.\n\n```\n    public class Collision\n    {\n\n    private Shape shape1;\n    private Shape shape2;\n    public List<Vector2> vertices;\n    private Vector2 direction;\n    private double TOLERENCE = 2;\n    public Vector2 contactNormal;\n    public double penetrationDepth;\n\n    private enum State\n    {\n        NO_INTERSECTION, FOUND_INTERSECTION, STILL_EVOLVING\n    }\n    private State result = State.STILL_EVOLVING;\n\n    public Collision(Shape shape1, Shape shape2)\n    {\n        this.shape1 = shape1;\n        this.shape2 = shape2;\n        vertices = new List<Vector2>();\n\n    }\n\n    public bool isColliding()\n    {\n        while (result == State.STILL_EVOLVING)\n        {\n            result = evolveSimplex();\n        }\n\n        if (result == State.FOUND_INTERSECTION)\n            findContactDetails();\n        return result == State.FOUND_INTERSECTION;\n    }\n\n    private State evolveSimplex()\n    {\n        if (vertices.Count == 0)\n        {\n            direction = shape1.position - shape2.position;\n        }\n\n        else if (vertices.Count == 1)\n        {\n            direction = -direction;\n        }\n        else if (vertices.Count == 2)\n        {\n            //ab is the vector from the 1st vertex to the second one\n            Vector2 ab = vertices[1] - vertices[0];\n            //a0 is the vector from the 1st vertex to the origin\n            Vector2 a0 = -vertices[0];\n            //Get the direction that is perpendicular to ab in the direction of the origin.\n            direction = ab.getPerpendicularUnitVectorTowards(a0);\n\n        }\n        else if (vertices.Count == 3)\n        {\n            //a,b and c are the three vertices\n            Vector2 a = vertices[0];\n            Vector2 b = vertices[1];\n            Vector2 c = vertices[2];\n\n            //lets find cb, ca and c0\n            Vector2 cb = b - c;\n            Vector2 ca = a - c;\n            Vector2 c0 = -c;\n\n            // let's find the perpendicular directions to cb and ca that are towards outside the simplex.\n            Vector2 cbPerp = cb.getPerpendicularUnitVectorTowards(c0);\n            Vector2 caPerp = ca.getPerpendicularUnitVectorTowards(c0);\n\n            if (cbPerp * c0 < 0)\n            {\n                vertices.Remove(a);\n                direction = cbPerp;\n            }\n            else if (caPerp * c0 < 0)\n            {\n                vertices.Remove(b);\n                direction = caPerp;\n            }\n            else\n            {\n                return State.FOUND_INTERSECTION;\n            }\n        }\n\n        return addSupport(direction) ? State.STILL_EVOLVING : State.NO_INTERSECTION;\n    }\n    private bool addSupport(Vector2 direction)\n    {\n        Vector2 support = shape1.getSupportPoint(direction) - shape2.getSupportPoint(-direction);\n        vertices.Add(support);\n        return direction * support > 0;\n    }\n\n    private void findContactDetails()\n    {\n        while (true)\n        {\n            Edge closestEdge = findClosestEdge(vertices);\n\n            Vector2 support = shape1.getSupportPoint(closestEdge.normal) - shape2.getSupportPoint(-closestEdge.normal);\n            double distance = support * closestEdge.normal;\n            Console.WriteLine(\"difference between the two = \" + (Math.Abs(distance - closestEdge.distance)) + \" and it's \" + (Math.Abs(distance - closestEdge.distance) < TOLERENCE));\n\n            if (Math.Abs(distance - closestEdge.distance) < TOLERENCE)\n            {\n                Console.WriteLine(\"Contact details found\");\n                contactNormal = closestEdge.normal;\n                penetrationDepth = distance;\n                break;\n\n            }\n\n            Console.WriteLine(\"That was not the closest edge. adding the support to the vertices at index \" + closestEdge.index);\n            vertices.Insert(closestEdge.index, support);\n            Console.WriteLine(\"The number of vertices now = \" + vertices.Count);\n\n            for (int i = 0; i < vertices.Count; i++)\n            {\n                Form1.dots.Add(vertices[i]);\n            }\n\n        }\n    }\n\n    private Edge findClosestEdge(List<Vector2> simplex)\n    {\n        Console.WriteLine(\"Finding closest edge\");\n        Edge closest = new Edge();\n        closest.distance = Double.PositiveInfinity;\n\n        for (int i = 0; i < simplex.Count; i++)\n        {\n            Console.WriteLine(\"i = \" + i);\n            int j = i + 1 == simplex.Count ? 0 : i + 1;\n\n            Vector2 a = simplex[i];\n            Vector2 b = simplex[j];\n\n            Vector2 edge = b - a;\n            Vector2 oa = a;\n\n            Vector2 normal = edge.getPerpendicularUnitVectorTowards(oa);\n            double d = Math.Abs(normal * oa);\n            Console.WriteLine(\"distance from origin to edge = \" + d);\n\n            if (d < closest.distance)\n            {\n                closest.distance = d;\n                closest.normal = normal;\n                closest.index = j;\n            }\n        }\n        Console.WriteLine(\"returing closest edge \" + closest.index + \" distance = \" + closest.distance);\n        return closest;\n    }\n}\n```\n\n\nAnd Heres the vector2 class.\n\n```\npublic class Vector2\n{\n    public double x;\n    public double y;\n    public static Vector2 zeroVector2 = new Vector2(0,0);\n\n    public Vector2(double x, double y)\n    {\n        this.x = x;\n        this.y = y;\n    }\n\n    public Vector2 add(Vector2 vector)\n    {\n        return new Vector2(x + vector.x, y + vector.y);\n    }\n    public Vector2 subtract(Vector2 vector)\n    {\n        return new Vector2(x - vector.x, y - vector.y);\n    }\n    public double dot(Vector2 vector)\n    {\n        return x * vector.x + y * vector.y;\n    }\n\n    public Vector2 multiply(double scalar)\n    {\n        return new Vector2(x*scalar, y*scalar);\n    }\n    public double getMagnitude()\n    {\n        return Math.Sqrt(Math.Pow(x, 2) + Math.Pow(y, 2));\n    }\n    public void negate()\n    {\n        x = -x;\n        y = -y;\n    }\n    public Vector2 negated()\n    {\n        return new Vector2(-x, -y);\n    }\n    public bool isZeroVector()\n    {\n        if (x == 0 && y == 0)\n            return true;\n        else return false;\n    }\n\n    public Vector2 normalized()\n    {\n        return this * (1 / getMagnitude());\n    }\n\n    public void normalize()\n    {\n        x *= (1 / getMagnitude());\n        y *= (1 / getMagnitude());\n    }\n\n\n    public static Vector2 operator -(Vector2 vector)\n    {\n        return vector.negated();\n    }\n\n    public static Vector2 operator +(Vector2 v1, Vector2 v2)\n    {\n        return v1.add(v2);\n    }\n    public static Vector2 operator -(Vector2 v1, Vector2 v2)\n    {\n        return v1.subtract(v2);\n    }\n    public static double operator *(Vector2 v1, Vector2 v2)\n    {\n        return v1.dot(v2);\n    }\n\n    public static Vector2 operator *(Vector2 v, double scalar)\n    {\n        return v.multiply(scalar);\n    }\n    public static Vector2 operator *(double scalar, Vector2 v)\n    {\n        return v.multiply(scalar);\n    }\n\n    public static bool operator ==(Vector2 v1, Vector2 v2)\n    {\n        if (v1.x == v2.x && v1.y == v2.y)\n            return true;\n        return false;\n    }\n    public static bool operator !=(Vector2 v1, Vector2 v2)\n    {\n        if (v1.x == v2.x && v1.y == v2.y)\n            return false;\n        return true;\n    }\n\n    public override string ToString()\n    {\n        return \"x = \" + x + \" , y = \" + y;\n    }\n\n    public Vector3 to3DVector()\n    {\n        return new Vector3(x, y, 0);\n    }\n\n    public Matrix toMatrix()\n    {\n        return new Matrix(new double[2,1]{{x}, {y}});\n    }\n\n    public Vector2 rotate(double degrees)\n    {\n        return (Matrix.getRotationMatrix(degrees) * this.toMatrix()).toVector2();\n    }\n\n    public static Vector2 toVector2(Point point)\n    {\n        return new Vector2(point.X, point.Y);\n    }\n\n    public Point toPoint()\n    {\n        return new Point((int)x,(int)y);\n    }\n\n    public Vector2 getPerpendicularUnitVectorTowards(Vector2 direction)\n    {\n        Vector2 perp =  new Vector2(-y, x) * (1 / getMagnitude());\n        Console.WriteLine(perp);\n        if (perp * direction < 0)\n            perp = -perp;\n        return perp;\n    }\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Random vectors uniformely distributed into convex n-polytope\r\n                \r\nHow to generate a vectors, uniformely distributed into convex polytope? I awared of the solution of reduced problem: uniform sampling on a unit simplex. Also I know how to split (even non-convex) polytope into the simplicial pieces (by means of Delaunay triangulation). Having such splitting I can simply work with particular simplicies, considering its hypervolumes as weights.\n\nBut how to deal with just a simplicies? I can't simply deform the unit simplex (internals of which consists of random points) to give the arbitrary simplex only using linear transformations. The uniformity of spatial distribution is violated in such case.\n\nI awared that Dirichlet distribution is connected to the problem. But I do not know the means of how to.\n\nI suspect that there is some functional (maybe linear?) dependency between parametres of Gamma-distributions of the components and dot products of radius-vectors of simplex vertices (Gramian matrix, just a supposition).\n\nEDIT:\n\nI want to specifically note, that only the rejection-step-less algorithms are interested. Or, another words, optimal in sense of minimum of amount of generated uniformely distributed \"source\" values.\n\nEDIT:\n\nFinally I found the solution.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How can I generate scipy.spatial.Delaunay object from an array of points and an array of edges\r\n                \r\nI would like to create a scipy.spatial.Delaunay object from an array of points: ```\nP = [[P1x,P1y],[P2x,P2y],...,[PNx,PNy]]```\n and the corresponding triangulation: ```\nT = [[T1a,T1b,T1c],[T2a,T2b,T2c],...,[TMa,TMb,TMc]]```\n\nA similar question has been asked here:\nHow to add simplices to a scipy Delaunay triangulation object .\nUnfortunately as xdze2 points out, for my case I do need it to be a valid Delaunay object so that I can use ```\nfind_simplex()```\n.\nIn matlab I can do the following:\n```\nTR = triangulation(double(T),double(P)); %generating the triangulation object\n[ID,B] = pointLocation(TR,X(:),Y(:)); %X and Y the coordinates of the points for which I want \n                                      %to find the simplex (ID) they lie in as well the \n                                      % barycentric coordinates in that simplex\n```\n\nCan I do something similar with scipy.spatial.Delaunay?\nCurrently I have written a bruteforce version that works, but it being brute force takes some time to complete: for the same number of queries, my algorithm needs about 180s compared to 18s for the matlab build in function (```\npointLocation```\n). I would like to see if I can get a speedup by using the ```\nfind_simplex()```\n method.\nThe bruteforce method I am using takes advantage of the barycentric transformation as described in the Delaunay doc.\nFor each simplex I compute the barycentric coordinates for each point and find the correct simplex by finding the simplex for which all the coordinates are positive.\n```\nfor num_simplex in range(T.shape[0]):\n    #compute barycentric coordinates for all points in P\n    b = transform_container[num_simplex,:2].dot(np.transpose(P-transform_container[num_simplex,2]))\n    coords = np.c_[np.transpose(b), 1 - b.sum(axis=0)]\n    # find negative coordinates\n    neg_vect = coords < 0\n    #find positions where ALL coords are positive\n    pos_vect = np.sum(neg_vect,axis=1) == 0\n   \n```\n\ntransform_container is the concatenation of the Delaunay object transform matrix for each simplex. This matrix has been generated by calling Delaunay on subsets of points. These subsets form a partition of the entire set of points P.\nMy issue is that I cannot call Delaunay on my entire set of points as there are specific nodes that are not connected. That is why I am working with subsets of points to artificially prevent some of the edges.\nThank you in advance for your help\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Why is wrapping coordinates not making my simplex noise tile seamlessly?\r\n                \r\nI've been trying to create a fake 3D texture that repeats in shadertoy (see here, use wasd to move, arrow keys to rotate) But as you can see, it doesn't tile. \n\nI generate the noise myself, and I've isolated the noise generation in this minimal example, however it does not generate seamlessly tileable noise seemingly no matter what I do. \n\nHere is the code:\n\n```\n//Common, you probably won't have to look here. \nvec2 modv(vec2 value, float modvalue){\n    return vec2(mod(value.x, modvalue), \n                mod(value.y, modvalue));\n}\nvec3 modv(vec3 value, float modvalue){\n    return vec3(mod(value.x, modvalue), \n                mod(value.y, modvalue),\n                mod(value.z, modvalue));\n}\nvec4 modv(vec4 value, float modvalue){\n    return vec4(mod(value.x, modvalue), \n                mod(value.y, modvalue),\n                mod(value.z, modvalue),\n                mod(value.w, modvalue));\n}\n\n//MATH CONSTANTS\nconst float pi  = 3.1415926535897932384626433832795;\nconst float tau = 6.2831853071795864769252867665590;\nconst float eta = 1.5707963267948966192313216916397;\nconst float SQRT3 = 1.7320508075688772935274463415059;\nconst float SQRT2 = 1.4142135623730950488016887242096;\nconst float LTE1 =  0.9999999999999999999999999999999;\nconst float inf = uintBitsToFloat(0x7F800000u);\n\n#define saturate(x) clamp(x,0.0,1.0)\n#define norm01(x) ((x + 1.0) / 2.0)\n\nvec2 pos3DTo2D(in vec3 pos, \n               const in int size_dim, \n               const in ivec2 z_size){\n    float size_dimf = float(size_dim);\n    pos = vec3(mod(pos.x, size_dimf), mod(pos.y, size_dimf),  mod(pos.z, size_dimf));\n    int z_dim_x = int(pos.z) % z_size.x;\n    int z_dim_y = int(pos.z) / z_size.x;\n    float x = pos.x + float(z_dim_x * size_dim);\n    float y = pos.y + float(z_dim_y * size_dim);\n    return vec2(x,y);\n}\n\nvec4 textureAs3D(const in sampler2D iChannel, \n                 in vec3 pos, \n                 const in int size_dim, \n                 const in ivec2 z_size,\n                 const in vec3 iResolution){\n    //only need whole, will do another texture read to make sure interpolated?\n\n    vec2 tex_pos = pos3DTo2D(pos, size_dim, z_size)/iResolution.xy;\n    vec4 base_vec4 = texture(iChannel, tex_pos);\n\n    vec2 tex_pos_z1 = pos3DTo2D(pos+vec3(0.0,0.0,1.0), size_dim, z_size.xy)/iResolution.xy;\n    vec4 base_vec4_z1 = texture(iChannel, tex_pos_z1);\n    //return base_vec4;\n    return mix(base_vec4, base_vec4_z1, fract(pos.z));\n}\n\nvec4 textureZ3D(const in sampler2D iChannel, \n                 in int y,\n                 in int z,\n                 in int offsetX,\n                 const in int size_dim, \n                 const in ivec2 z_size,\n                const in vec3 iResolution){\n    int tx = (z%z_size.x);\n    int ty = z/z_size.x;\n    int sx = offsetX + size_dim * tx;\n    int sy = y  + (ty *size_dim);\n    if(ty < z_size.y){\n        return texelFetch(iChannel, ivec2(sx, sy),0);\n    }else{\n        return vec4(0.0);\n    }\n    //return texelFetch(iChannel, ivec2(x, y - (ty *32)),0);\n}\n```\n\n\n\n\n```\n//Buffer B this is what you are going to have to look at. \n//noise\n\n//NOISE CONSTANTS\n// captured from https://en.wikipedia.org/wiki/SHA-2#Pseudocode\nconst uint CONST_A = 0xcc9e2d51u;\nconst uint CONST_B = 0x1b873593u;\nconst uint CONST_C = 0x85ebca6bu;\nconst uint CONST_D = 0xc2b2ae35u;\nconst uint CONST_E = 0xe6546b64u;\nconst uint CONST_F = 0x510e527fu;\nconst uint CONST_G = 0x923f82a4u;\nconst uint CONST_H = 0x14292967u;\n\nconst uint CONST_0 = 4294967291u;\nconst uint CONST_1 = 604807628u;\nconst uint CONST_2 = 2146583651u;\nconst uint CONST_3 = 1072842857u;\nconst uint CONST_4 = 1396182291u;\nconst uint CONST_5 = 2227730452u;\nconst uint CONST_6 = 3329325298u;\nconst uint CONST_7 = 3624381080u;\n\n\n\n\nuvec3 singleHash(uvec3 uval){\n    uval ^= uval >> 16;\n    uval.x *= CONST_A;\n    uval.y *= CONST_B;\n    uval.z *= CONST_C;\n    return uval;\n}\n\nuint combineHash(uint seed, uvec3 uval){\n    // can move this out to compile time if need be. \n    // with out multiplying by one of the randomizing constants\n    // will result in not very different results from seed to seed. \n    uint un = seed * CONST_5;\n    un ^= (uval.x^uval.y)* CONST_0;\n    un ^= (un >> 16);\n    un = (un^uval.z)*CONST_1;\n    un ^= (un >> 16);\n    return un;\n}\n\n/* \n//what the above hashes are based upon, seperate \n//out this mumurhash based coherent noise hash\nuint fullHash(uint seed, uvec3 uval){\n    uval ^= uval >> 16;\n    uval.x *= CONST_A;\n    uval.y *= CONST_B;\n    uval.z *= CONST_D;\n    uint un = seed * CONST_6;\n    un ^= (uval.x ^ uval.y) * CONST_0;\n    un ^= un >> 16;\n    un = (un^uval.z) * CONST_2;\n    un ^= un >> 16;\n    return un;\n}\n*/\n\nconst vec3 gradArray3d[8] = vec3[8](\n    vec3(1, 1, 1), vec3(1,-1, 1), vec3(-1, 1, 1), vec3(-1,-1, 1),\n    vec3(1, 1,-1), vec3(1,-1,-1), vec3(-1, 1,-1), vec3(-1,-1,-1)\n);\n\n\nvec3 getGradient3Old(uint uval){\n    vec3 grad = gradArray3d[uval & 7u];\n    return grad;\n}\n\n//source of some constants\n//https://github.com/Auburns/FastNoise/blob/master/FastNoise.cpp\nconst float SKEW3D = 1.0 / 3.0;\nconst float UNSKEW3D = 1.0 / 6.0;\nconst float FAR_CORNER_UNSKEW3D = -1.0 + 3.0*UNSKEW3D;\nconst float NORMALIZE_SCALE3D = 30.0;// * SQRT3;\nconst float DISTCONST_3D = 0.6;\n\nfloat simplexNoiseV(uint seed, in vec3 pos, in uint wrap){\n    pos = modv(pos, float(wrap));\n    float skew_factor = (pos.x + pos.y + pos.z)*SKEW3D;\n    vec3 fsimplex_corner0 = floor(pos + skew_factor);\n    ivec3 simplex_corner0 = ivec3(fsimplex_corner0);\n\n    float unskew_factor = (fsimplex_corner0.x + fsimplex_corner0.y + fsimplex_corner0.z) * UNSKEW3D;\n    vec3 pos0 = fsimplex_corner0 - unskew_factor;\n\n    //subpos's are positions with in grid cell. \n    vec3 subpos0 = pos - pos0;\n    //precomputed values used in determining hash, reduces redundant hash computation\n    //shows 10% -> 20% speed boost. \n    uvec3 wrapped_corner0 = uvec3(simplex_corner0);\n    uvec3 wrapped_corner1 = uvec3(simplex_corner0+1);\n    wrapped_corner0 = wrapped_corner0 % wrap;\n    wrapped_corner1 = wrapped_corner1 % wrap;\n\n    //uvec3 hashes_offset0 = singleHash(uvec3(simplex_corner0));\n    //uvec3 hashes_offset1 = singleHash(uvec3(simplex_corner0+1));\n    uvec3 hashes_offset0 = singleHash(wrapped_corner0);\n    uvec3 hashes_offset1 = singleHash(wrapped_corner1);\n    //near corner hash value\n    uint hashval0 = combineHash(seed, hashes_offset0);\n    //mid corner hash value\n    uint hashval1;\n\n    uint hashval2;\n    //far corner hash value\n    uint hashval3 = combineHash(seed, hashes_offset1);\n\n    ivec3 simplex_corner1;\n    ivec3 simplex_corner2;\n    if (subpos0.x >= subpos0.y)\n    {\n        if (subpos0.y >= subpos0.z)\n        {\n            hashval1 = combineHash(seed, uvec3(hashes_offset1.x, hashes_offset0.yz));\n            hashval2 = combineHash(seed, uvec3(hashes_offset1.xy, hashes_offset0.z));\n            simplex_corner1 = ivec3(1,0,0);\n            simplex_corner2 = ivec3(1,1,0);\n        }\n        else if (subpos0.x >= subpos0.z)\n        {\n            hashval1 = combineHash(seed, uvec3(hashes_offset1.x, hashes_offset0.yz));\n            hashval2 = combineHash(seed, uvec3(hashes_offset1.x, hashes_offset0.y, hashes_offset1.z));\n            simplex_corner1 = ivec3(1,0,0);\n            simplex_corner2 = ivec3(1,0,1);\n        }\n        else // subpos0.x < subpos0.z\n        {\n            hashval1 = combineHash(seed, uvec3(hashes_offset0.xy, hashes_offset1.z));\n            hashval2 = combineHash(seed, uvec3(hashes_offset1.x, hashes_offset0.y, hashes_offset1.z));\n            simplex_corner1 = ivec3(0,0,1);\n            simplex_corner2 = ivec3(1,0,1);\n        }\n    }\n    else // subpos0.x < subpos0.y\n    {\n        if (subpos0.y < subpos0.z)\n        {\n            hashval1 = combineHash(seed, uvec3(hashes_offset0.xy, hashes_offset1.z));\n            hashval2 = combineHash(seed, uvec3(hashes_offset0.x, hashes_offset1.yz));\n            simplex_corner1 = ivec3(0,0,1);\n            simplex_corner2 = ivec3(0,1,1);\n        }\n        else if (subpos0.x < subpos0.z)\n        {\n            hashval1 = combineHash(seed, uvec3(hashes_offset0.x, hashes_offset1.y, hashes_offset0.z));\n            hashval2 = combineHash(seed, uvec3(hashes_offset0.x, hashes_offset1.yz));\n            simplex_corner1 = ivec3(0,1,0);\n            simplex_corner2 = ivec3(0,1,1);\n        }\n        else // subpos0.x >= subpos0.z\n        {\n            hashval1 = combineHash(seed, uvec3(hashes_offset0.x, hashes_offset1.y, hashes_offset0.z));\n            hashval2 = combineHash(seed, uvec3(hashes_offset1.xy, hashes_offset0.z));\n            simplex_corner1 = ivec3(0,1,0);\n            simplex_corner2 = ivec3(1,1,0);\n        }\n    }\n\n    //we would do this if we didn't want to seperate the hash values. \n    //hashval0 = fullHash(seed, uvec3(simplex_corner0));\n    //hashval1 = fullHash(seed, uvec3(simplex_corner0+simplex_corner1));\n    //hashval2 = fullHash(seed, uvec3(simplex_corner0+simplex_corner2));\n    //hashval3 = fullHash(seed, uvec3(simplex_corner0+1));\n\n    vec3 subpos1 = subpos0 - vec3(simplex_corner1) + UNSKEW3D;\n    vec3 subpos2 = subpos0 - vec3(simplex_corner2) + 2.0*UNSKEW3D;\n    vec3 subpos3 = subpos0 + FAR_CORNER_UNSKEW3D;\n    float n0, n1, n2, n3;\n\n    //http://catlikecoding.com/unity/tutorials/simplex-noise/\n    //circle distance factor to make sure second derivative is continuous\n    // t variables represent (1 - x^2 + y^2 + ...)^3, a distance function with \n    // continous first and second derivatives that are zero when x is one. \n    float t0 = DISTCONST_3D - subpos0.x*subpos0.x - subpos0.y*subpos0.y - subpos0.z*subpos0.z;\n    //if t < 0, we get odd dips in continuity at the ends, so we just force it to zero\n    // to prevent it\n    if(t0 < 0.0){\n        n0 = 0.0;\n    }else{\n        float t0_pow2 = t0 * t0;\n        float t0_pow4 = t0_pow2 * t0_pow2;\n        vec3 grad = getGradient3Old(hashval0);\n        float product = dot(subpos0, grad);\n        n0 = t0_pow4 * product;\n    }\n    float t1 = DISTCONST_3D - subpos1.x*subpos1.x - subpos1.y*subpos1.y - subpos1.z*subpos1.z;\n    if(t1 < 0.0){\n        n1 = 0.0;\n    }else{\n        float t1_pow2 = t1 * t1;\n        float t1_pow4 = t1_pow2 * t1_pow2;\n        vec3 grad = getGradient3Old(hashval1);\n        float product = dot(subpos1, grad);\n        n1 = t1_pow4 * product;\n    }\n    float t2 = DISTCONST_3D - subpos2.x*subpos2.x - subpos2.y*subpos2.y - subpos2.z*subpos2.z;\n    if(t2 < 0.0){\n        n2 = 0.0;\n    }else{\n        float t2_pow2 = t2 * t2;\n        float t2_pow4 = t2_pow2*t2_pow2;\n        vec3 grad = getGradient3Old(hashval2);\n        float product = dot(subpos2, grad);\n        n2 = t2_pow4 * product;\n    }\n\n    float t3 = DISTCONST_3D - subpos3.x*subpos3.x - subpos3.y*subpos3.y - subpos3.z*subpos3.z;\n    if(t3 < 0.0){\n        n3 = 0.0;\n    }else{\n        float t3_pow2 = t3 * t3;\n        float t3_pow4 = t3_pow2*t3_pow2;\n        vec3 grad = getGradient3Old(hashval3);\n        float product = dot(subpos3, grad);\n        n3 = t3_pow4 * product;\n    }\n    return (n0 + n1 + n2 + n3);\n}\n\n//settings for fractal brownian motion noise\nstruct BrownianFractalSettings{\n    uint seed;\n    int octave_count;\n    float frequency;\n    float lacunarity;\n    float persistence;\n    float amplitude;\n};\n\nfloat accumulateSimplexNoiseV(in BrownianFractalSettings settings, vec3 pos, float wrap){\n    float accumulated_noise = 0.0;\n    wrap *= settings.frequency;\n    vec3 octave_pos = pos * settings.frequency;\n    for (int octave = 0; octave < settings.octave_count; octave++) {\n        octave_pos = modv(octave_pos, wrap);\n        float noise = simplexNoiseV(settings.seed, octave_pos, uint(wrap));\n        noise *= pow(settings.persistence, float(octave));\n        accumulated_noise += noise;\n        octave_pos *= settings.lacunarity;\n        wrap *= settings.lacunarity;\n    }\n    float scale = 2.0 - pow(settings.persistence, float(settings.octave_count - 1));\n    return (accumulated_noise/scale) * NORMALIZE_SCALE3D * settings.amplitude;\n}\n\nconst float FREQUENCY = 1.0/8.0;\nconst float WRAP = 32.0;\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    //set to zero in order to stop scrolling, scrolling shows the lack of tilability between\n    //wrapping. \n    const float use_sin_debug = 1.0;\n    vec3 origin = vec3(norm01(sin(iTime))*64.0*use_sin_debug,0.0,0.0);\n    vec3 color = vec3(0.0,0.0,0.0);\n    BrownianFractalSettings brn_settings = \n        BrownianFractalSettings(203u, 1, FREQUENCY, 2.0, 0.4, 1.0);\n    const int size_dim = 32;\n    ivec2 z_size = ivec2(8, 4);\n    ivec2 iFragCoord = ivec2(fragCoord.x, fragCoord.y);\n    int z_dim_x = iFragCoord.x / size_dim;\n    int z_dim_y = iFragCoord.y / size_dim;\n\n    if(z_dim_x < z_size.x && z_dim_y < z_size.y){\n        int ix = iFragCoord.x % size_dim;\n        int iy = iFragCoord.y % size_dim;\n        int iz = (z_dim_x) + ((z_dim_y)*z_size.x);\n        vec3 pos = vec3(ix,iy,iz) + origin; \n        float value = accumulateSimplexNoiseV(brn_settings, pos, WRAP);\n        color = vec3(norm01(value));\n    }else{\n        color = vec3(1.0,0.0,0.0);\n    }\n    fragColor = vec4(color,1.0);\n}\n```\n\n\n\n\n```\n//Image, used to finally display\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    const float fcm = 4.0;\n    //grabs a single 32x32 tile in order to test tileability, currently generates\n    //a whole array of images however. \n    vec2 fragCoordMod = vec2(mod(fragCoord.x, 32.0 * fcm), mod(fragCoord.y, 32.0 * fcm));\n    vec3 color = texture(iChannel2, fragCoordMod/(fcm*iResolution.xy)).xyz;\n    fragColor = vec4(color, 1.0);\n}\n```\n\n\nWhat I've tried position % wrap value, modifying wrap value by lacunarity, and after warp % wrap value, which are currently in use (look in ```\nsimplexNoiseV```\n for the core algorithm, ```\naccumulateSimplexNoiseV```\n for the octave summation). \n\nAccording to these answers it should be that simple (mod position used for hashing), however this clearly just doesn't work.  I'm not sure if it's partially because my hashing function is not Ken Perlin's, but it doesn't seem like that should make a difference. It does seem the skewing of coordinates should make this method not work at all, but apparently others have had success with this. \n\nHere's an example of it not tiling: \n\nWhy is wrapping coordinates not making my simplex noise tile seamlessly? \n\nUPDATE:\n\nI've still not fixed the issue, but it appears that tiling works appropriately along the simplicies, and not the grid seen here:\n\n\n\nDo I have to modify my modulus to account for the skewing? \n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Perlin Noise, Erlang and javascript\r\n                \r\nGiven the same seed to the a perlin/simplex noise generation algorithm, is it possible for the same noise map to be generated, in the two different programming languages?\n\nMy usecase: a procedurally generated multiplayer world - using javascript clients, with the erlang server generating the same noise map to manage world syncing and other server related things \n\nInstead of the server generating the noise map and having to transmit the generated values to the clients\n\nregards\n    ", "Answer": "\r\nOf course, if not out of the box then you can write your own PRNG function in both languages.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to calculate if 3D model is intersecting terrain surface LWJGL\r\n                \r\nI am currently working on a project using 3d simplex noise and the marching cubes algorithm in order to procedurally generated terrain. I am trying to implement collision detection between the player object and terrain mesh but I have no clue how to start. I have read some articles and posts about using JBullet and other libraries but they do not support complex meshes such as the ones generated by simplex noise. In order to simplify things for myself I decided to make it so that the player can only move in the direction I point meaning that I would only need to check if a singular point on the player is intersecting with the terrain. Are there any methods to implement such a process? (edit: I've already looked into barycentric coordinates but I have no idea how to implement into the game)\nCurrent Player Code\n```\npackage Entities;\n\nimport org.lwjgl.glfw.GLFW;\n\nimport Engine.Input;\nimport Maths.Vector3f;\nimport Models.TexturedModel;\n\npublic class Player extends Entity {\n    \n    public float xspeed = 0,zspeed = 0, yspeed = 0; \n    public Vector3f mousePos;\n    public float yrotation = 0, zrotation = 0;\n    public float maxYRotation = 75f;\n    \n    private double lastMousePosX = 600 , newMousePosX;\n    private double lastMousePosY = 500 , newMousePosY;\n    private float speed = 3;\n    \n    public Player(TexturedModel model, Vector3f position, float rotX, float rotY, float rotZ, float scale) {\n        super(model, position, rotX, rotY, rotZ, scale);\n    }\n    public void move(){\n        checkInput();\n        System.out.println(\"x =\"+this.position.x+\" y =\"+this.position.y+\" z =\"+this.position.z);\n        checkCollision();\n    }\n    public boolean checkCollision(){\n        if(terrain != null){\n            for(int i = 0; i<terrain.getVertices().length; i+=9){\n                Vector3f vertex1 = new Vector3f(terrain.getVertices()[i],terrain.getVertices()[i+1],terrain.getVertices()[i+2]);\n                Vector3f vertex2 = new Vector3f(terrain.getVertices()[i+3],terrain.getVertices()[i+4],terrain.getVertices()[i+5]);\n                Vector3f vertex3 = new Vector3f(terrain.getVertices()[i+6],terrain.getVertices()[i+7],terrain.getVertices()[i+8]);\n                \n                //Check if point p is interseting triangle (vertex1, vertex2, vertex3)\n                if(someCalculationFunction(position, vertex1, vertex2, vertex3){\n                    return true;\n                }\n            }\n        }\n        return false;\n    }\n\n    public void checkInput(){\n        newMousePosX = Input.getMouseX();\n        newMousePosY = Input.getMouseY();\n        \n        float dx = (float)(newMousePosX-lastMousePosX)*0.07f;\n        float dy = (float)(newMousePosY-lastMousePosY)*0.07f;\n        \n        if(!Input.isMouseDown(GLFW.GLFW_MOUSE_BUTTON_1)){\n\n            this.rotY -= dx/2;\n            this.rotX -= dy*0.8f;\n        \n        }\n        \n        if(Math.abs(rotX) > 50){\n            this.rotX = Math.abs(rotX)/rotX*50;\n        }\n        \n        if(this.rotY<0){\n            this.rotY = 360;\n        }\n        \n        float horizontalDistance = speed*(float)(Math.cos(Math.toRadians(rotX)));\n        float verticleDistance = speed*(float)(Math.sin(Math.toRadians(rotX)));\n\n        if(Input.isKeyDown(GLFW.GLFW_KEY_W)){\n            this.position.x += horizontalDistance*Math.sin(Math.toRadians(-rotY));\n            this.position.z -= horizontalDistance*Math.cos(Math.toRadians(-rotY));\n            this.position.y += verticleDistance;\n        }else if(Input.isKeyDown(GLFW.GLFW_KEY_S)){\n            this.position.x -= horizontalDistance*Math.sin(Math.toRadians(-rotY));\n            this.position.z += horizontalDistance*Math.cos(Math.toRadians(-rotY));\n            this.position.y -= verticleDistance;    \n        }\n        \n        lastMousePosX = newMousePosX;\n        lastMousePosY = newMousePosY;       \n        \n    }\n\n}\n```\n\n    ", "Answer": "\r\nI'm not positive if I understood the question right, but this answer will address the problem of ensuring the players height is that of the terrain that it is standing on\nWith barycentric coordinates you can calculate what the players height is supposed to be by using the heights of the three vertices that make up that triangle:\n```\npublic static float baryCentric(Vector3f p1, Vector3f p2, Vector3f p3, Vector2f pos) {\n    float det = (p2.z - p3.z) * (p1.x - p3.x) + (p3.x - p2.x) * (p1.z - p3.z);\n    float l1 = ((p2.z - p3.z) * (pos.x - p3.x) + (p3.x - p2.x) * (pos.y - p3.z)) / det;\n    float l2 = ((p3.z - p1.z) * (pos.x - p3.x) + (p1.x - p3.x) * (pos.y - p3.z)) / det;\n    float l3 = 1.0f - l1 - l2;\n    return l1 * p1.y + l2 * p2.y + l3 * p3.y;\n}\n```\n\nIn order to get these three points you can make a calculation using the world coordinates of your player:\n```\n    //Assuming the world is constructed of equal height and width sized triangles\n    float gridSquareSize = SIZE_OF_TERRAIN_MESH / NUM_TRIANGLES_PER_ROW;\n    float xCoord = worldX % gridSquareSize / gridSquareSize;\n    float zCoord = worldZ % gridSquareSize / gridSquareSize;\n```\n\nWith the xCoord and zCoord you can determine the 3 points that you need to use for your baryCentric calculation\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Optimization - Python and Scypi.minimize\r\n                \r\nI would like to find the position [X,Y,Z] of several elements in order to have the global center of gravity at a desired point.\n\nTo do so, I defined 2 classes:\n\n\nelements which store the element's mass and position\nplane which takes a list of element and can compute its center of gravity according to the set of element.\n\n\nI also defined an error function which compute the difference between the actual global center of gravity from the plane's set of elements and the desired center of gravity.\n\nTo minimize this function, I wanted to use the ```\nscypi.minimize```\n function with the Nelder-Mead Simplex algorithm. \n\nI put each element's coordinate into ```\nx0```\n and then pass ```\nx0```\n and the error function as parameter to minimize.\n\nI received this error which I don't understand.: \n\n```\nValueError: setting an array element with a sequence. \n```\n\n\nMoreover according to what I want to do, you may have a better idea to solve/fix my problem?\n\nhere is the code : \n\n```\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass plane(object):\n  def __init__(self, elts):\n    self.elements=elts\n    self.TotalMasse=self.calc_masse(self.elements) \n    self.cdg = self.calc_CDG()\n\n  def __getitem__(self):\n    return self.elements,self.TotalMasse\n\n  def calc_masse(self,elements):\n    Lm=[]\n    for el in elements:\n      Lm.append(el.masse)\n    return sum(Lm)\n\n  def calc_CDG(self):\n    Xcdg=0\n    Ycdg=0\n    Zcdg=0\n    for el in self.elements:\n      Xcdg+=el.masse*el.position[0]/self.TotalMasse\n      Ycdg+=el.masse*el.position[1]/self.TotalMasse\n      Zcdg+=el.masse*el.position[2]/self.TotalMasse\n    return [Xcdg,Ycdg,Zcdg]\n\nclass element(object):\n  def __init__(self, mass, pos):\n    self.masse=mass\n    self.position=pos\n\n  def __getitem__(self):\n    return self.masse, self.position\n\n\n\ndef calculErreurPosCDG(cdg):\n    global positionCDGconsigne\n    return [positionCDGconsigne[0]-cdg[0], positionCDGconsigne[1]-cdg[1],positionCDGconsigne[2]-cdg[2]]\n\nbattery = element(0.5,[0.5,1,1])\nmotor = element(0.2,[1,1,0])\nservoL = element(0.01,[-0.7,1,0])\nservoR = element(0.01,[0.7,1,0])\nreciever = element(0.01,[0.1,1,1])\n\nelements=[battery, motor, servoL, servoR, reciever]\n\npositionCDGconsigne=[1,1,1]\n\nplane1=plane(elements)\n\nx0=np.array([])\nfor el in elements:\n  x0= np.append(x0,[el.position])\n\nres=minimize(calculErreurPosCDG,x0,method='nelder-mead', options={'xtol':1e-8,'disp':True})\n```\n\n    ", "Answer": "\r\nYour target function returns a list, while ```\nminimize```\n expects a scalar. You need to set your problem first and specify what exactly do you mean by minimizing a vector-valued function. \n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Scipy Linear Programming returns False for success\r\n                \r\nI am working on a project about Transportation Network Analysis. My network contains data such as nodes, edges, free-flow travel times, capacity, etc. I need to find the volume of edges (links) by using the Frank-Wolf algorithm. I used scipy.optimize.linprog in my code; however, it returns False for success.\nThe first code is:\n```\nresult = optimize.linprog(c_0, A_eq=A, b_eq=b)  # min(c_0*x) such that: Ax=b\nprint(result)\nresult = np.reshape(result['x'], (k, n))\nxa = np.sum(result, axis=0)  # initial value of xa\nprint(xa)\n```\n\nThe output of the first code is:\n```\n     con: array([ 1.17458269e+04,  1.19588056e+03, -5.99940081e+00,  1.19488066e+03,\n        1.19388076e+03, -5.99940073e+00, -5.99940082e+00, -7.99920106e+00,\n       -5.99940082e+00,  9.71902933e+02,  9.95900537e+02, -5.99940081e+00,\n        1.13188696e+03,  8.89911122e+02,  8.51914917e+02, -5.99940084e+00,\n       -5.99940084e+00, -3.99960052e+00,  8.13918712e+02,  5.33946673e+02,\n        5.33946673e+02,  6.91930895e+02, -7.99920110e+00,  6.63933691e+02,\n        1.19688046e+03,  1.15548460e+04, -5.99940084e+00,  1.13488666e+03,\n        1.17388276e+03, -5.99940081e+00, -5.99940078e+00, -7.99920111e+00,\n       -5.99940078e+00,  9.91900936e+02,  1.01589854e+03, -5.99940087e+00,\n        8.11918912e+02,  8.49915117e+02,  8.41915916e+02, -5.99940082e+00,\n       -5.99940082e+00, -3.99960055e+00,  1.17388276e+03,  5.33946673e+02,\n        6.13938684e+02,  6.01939883e+02, -7.99920113e+00,  5.33946673e+02,\n       -2.99970041e+00, -3.99960055e+00, -5.99940082e+00, -4.99950069e+00,\n       -5.99940082e+00, -5.99940082e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00, -7.99920110e+00, -3.99960055e+00, -5.99940082e+00,\n       -7.99920110e+00, -9.99900137e+00, -7.99920110e+00, -5.99940082e+00,\n       -5.99940082e+00, -3.99960055e+00, -5.99940082e+00, -5.99940082e+00,\n       -5.99940082e+00, -7.99920110e+00, -7.99920110e+00, -5.99940082e+00,\n        1.19688046e+03,  1.13588656e+03, -5.99940075e+00,  1.10638950e+04,\n        1.19388076e+03, -5.99940078e+00, -5.99940081e+00, -7.99920113e+00,\n       -5.99940081e+00,  9.71902933e+02,  9.65903533e+02, -5.99940081e+00,\n        8.51914917e+02,  8.09919111e+02,  7.51924903e+02, -5.99940082e+00,\n       -5.99940085e+00, -3.99960056e+00,  7.23927699e+02,  5.53944676e+02,\n        5.73942679e+02,  5.31946873e+02, -7.99920109e+00,  7.23927699e+02,\n        1.19688046e+03,  1.17588256e+03, -5.99940085e+00,  1.19488066e+03,\n        1.13728642e+04, -5.99940079e+00, -5.99940091e+00, -7.99920121e+00,\n       -5.99940080e+00,  1.02189794e+03,  8.75912520e+02, -5.99940083e+00,\n        8.21917913e+02,  7.89921108e+02,  7.31926900e+02, -5.99940082e+00,\n       -5.99940079e+00, -3.99960055e+00,  6.53934690e+02,  7.23927699e+02,\n        7.33926701e+02,  8.41915916e+02, -7.99920111e+00,  5.33946673e+02,\n       -2.99970041e+00, -3.99960055e+00, -5.99940082e+00, -4.99950069e+00,\n       -5.99940082e+00, -5.99940082e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00, -7.99920110e+00, -3.99960055e+00, -5.99940082e+00,\n       -7.99920110e+00, -9.99900137e+00, -7.99920110e+00, -5.99940082e+00,\n       -5.99940082e+00, -3.99960055e+00, -5.99940082e+00, -5.99940082e+00,\n       -5.99940082e+00, -7.99920110e+00, -7.99920110e+00, -5.99940082e+00,\n       -2.99970041e+00, -3.99960055e+00, -5.99940082e+00, -4.99950069e+00,\n       -5.99940082e+00, -5.99940082e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00, -7.99920110e+00, -3.99960055e+00, -5.99940082e+00,\n       -7.99920110e+00, -9.99900137e+00, -7.99920110e+00, -5.99940082e+00,\n       -5.99940082e+00, -3.99960055e+00, -5.99940082e+00, -5.99940082e+00,\n       -5.99940082e+00, -7.99920110e+00, -7.99920110e+00, -5.99940082e+00,\n       -2.99970041e+00, -3.99960055e+00, -5.99940082e+00, -4.99950069e+00,\n       -5.99940082e+00, -5.99940082e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00, -7.99920110e+00, -3.99960055e+00, -5.99940082e+00,\n       -7.99920110e+00, -9.99900137e+00, -7.99920110e+00, -5.99940082e+00,\n       -5.99940082e+00, -3.99960055e+00, -5.99940082e+00, -5.99940082e+00,\n       -5.99940082e+00, -7.99920110e+00, -7.99920110e+00, -5.99940082e+00,\n       -2.99970041e+00, -3.99960055e+00, -5.99940082e+00, -4.99950069e+00,\n       -5.99940082e+00, -5.99940082e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00, -7.99920110e+00, -3.99960055e+00, -5.99940082e+00,\n       -7.99920110e+00, -9.99900137e+00, -7.99920110e+00, -5.99940082e+00,\n       -5.99940082e+00, -3.99960055e+00, -5.99940082e+00, -5.99940082e+00,\n       -5.99940082e+00, -7.99920110e+00, -7.99920110e+00, -5.99940082e+00,\n        9.76902434e+02,  9.95900537e+02, -5.99940080e+00,  9.74902634e+02,\n        1.02389774e+03, -5.99940083e+00, -5.99940084e+00, -7.99920109e+00,\n       -5.99940077e+00,  1.22707745e+04,  1.20587957e+03, -5.99940074e+00,\n        8.11918912e+02,  8.89911122e+02,  1.19188096e+03, -5.99940081e+00,\n       -5.99940082e+00, -3.99960054e+00,  1.05389474e+03,  8.53914717e+02,\n        8.13918712e+02,  8.71912920e+02, -7.99920105e+00,  5.33946673e+02,\n        9.96900437e+02,  1.01589854e+03, -5.99940085e+00,  9.64903632e+02,\n        8.73912720e+02, -5.99940082e+00, -5.99940080e+00, -7.99920109e+00,\n       -5.99940080e+00,  1.20187996e+03,  1.21647851e+04, -5.99940083e+00,\n        8.41915916e+02,  1.18988116e+03,  1.00189994e+03, -5.99940083e+00,\n       -5.99940081e+00, -3.99960055e+00,  8.53914717e+02,  6.63933691e+02,\n        5.43945675e+02,  9.91900936e+02, -7.99920107e+00,  9.43905730e+02,\n       -2.99970041e+00, -3.99960055e+00, -5.99940082e+00, -4.99950069e+00,\n       -5.99940082e+00, -5.99940082e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00, -7.99920110e+00, -3.99960055e+00, -5.99940082e+00,\n       -7.99920110e+00, -9.99900137e+00, -7.99920110e+00, -5.99940082e+00,\n       -5.99940082e+00, -3.99960055e+00, -5.99940082e+00, -5.99940082e+00,\n       -5.99940082e+00, -7.99920110e+00, -7.99920110e+00, -5.99940082e+00,\n        1.13688646e+03,  8.15918512e+02, -5.99940082e+00,  8.54914617e+02,\n        8.23917713e+02, -5.99940082e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00,  8.11918911e+02,  8.45915516e+02, -5.99940086e+00,\n        1.04109602e+04,  7.79922107e+02,  7.71922906e+02, -5.99940081e+00,\n       -5.99940082e+00, -3.99960055e+00,  6.13938684e+02,  5.33946673e+02,\n        5.53944676e+02,  6.01939883e+02, -7.99920111e+00,  1.19388076e+03,\n        8.96910423e+02,  8.55914517e+02, -5.99940082e+00,  8.14918612e+02,\n        7.93920709e+02, -5.99940082e+00, -5.99940083e+00, -7.99920109e+00,\n       -5.99940083e+00,  8.91910922e+02,  1.19588056e+03, -5.99940083e+00,\n        7.81921907e+02,  1.19888026e+04,  1.19188096e+03, -5.99940082e+00,\n       -5.99940083e+00, -3.99960055e+00,  1.02389774e+03,  8.53914717e+02,\n        7.83921708e+02,  8.11918911e+02, -7.99920111e+00,  1.02389774e+03,\n        8.56914418e+02,  8.45915516e+02, -5.99940082e+00,  7.54924604e+02,\n        7.33926701e+02, -5.99940083e+00, -5.99940083e+00, -7.99920112e+00,\n       -5.99940083e+00,  1.19188096e+03,  1.00589954e+03, -5.99940083e+00,\n        7.71922906e+02,  1.18988116e+03,  1.28107206e+04, -5.99940081e+00,\n       -5.99940085e+00, -3.99960055e+00,  1.19388076e+03,  1.14388576e+03,\n        1.03389674e+03,  1.19188096e+03, -7.99920110e+00,  8.23917713e+02,\n       -2.99970041e+00, -3.99960055e+00, -5.99940082e+00, -4.99950069e+00,\n       -5.99940082e+00, -5.99940082e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00, -7.99920110e+00, -3.99960055e+00, -5.99940082e+00,\n       -7.99920110e+00, -9.99900137e+00, -7.99920110e+00, -5.99940082e+00,\n       -5.99940082e+00, -3.99960055e+00, -5.99940082e+00, -5.99940082e+00,\n       -5.99940082e+00, -7.99920110e+00, -7.99920110e+00, -5.99940082e+00,\n       -2.99970041e+00, -3.99960055e+00, -5.99940082e+00, -4.99950069e+00,\n       -5.99940082e+00, -5.99940082e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00, -7.99920110e+00, -3.99960055e+00, -5.99940082e+00,\n       -7.99920110e+00, -9.99900137e+00, -7.99920110e+00, -5.99940082e+00,\n       -5.99940082e+00, -3.99960055e+00, -5.99940082e+00, -5.99940082e+00,\n       -5.99940082e+00, -7.99920110e+00, -7.99920110e+00, -5.99940082e+00,\n       -2.99970041e+00, -3.99960055e+00, -5.99940082e+00, -4.99950069e+00,\n       -5.99940082e+00, -5.99940082e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00, -7.99920110e+00, -3.99960055e+00, -5.99940082e+00,\n       -7.99920110e+00, -9.99900137e+00, -7.99920110e+00, -5.99940082e+00,\n       -5.99940082e+00, -3.99960055e+00, -5.99940082e+00, -5.99940082e+00,\n       -5.99940082e+00, -7.99920110e+00, -7.99920110e+00, -5.99940082e+00,\n        8.16918412e+02,  1.17588256e+03, -5.99940082e+00,  7.24927600e+02,\n        6.53934690e+02, -5.99940085e+00, -5.99940081e+00, -7.99920107e+00,\n       -5.99940082e+00,  1.05189494e+03,  8.55914517e+02, -5.99940083e+00,\n        6.11938884e+02,  1.01989814e+03,  1.19188096e+03, -5.99940082e+00,\n       -5.99940079e+00, -3.99960055e+00,  1.20927923e+04,  1.19388076e+03,\n        1.00389974e+03,  9.91900936e+02, -7.99920108e+00,  7.23927699e+02,\n        5.36946374e+02,  5.35946474e+02, -5.99940082e+00,  5.54944576e+02,\n        7.23927699e+02, -5.99940082e+00, -5.99940081e+00, -7.99920109e+00,\n       -5.99940082e+00,  8.51914917e+02,  6.65933491e+02, -5.99940082e+00,\n        5.31946873e+02,  8.49915117e+02,  1.14188596e+03, -5.99940082e+00,\n       -5.99940080e+00, -3.99960056e+00,  1.19388076e+03,  1.05929421e+04,\n        1.19388076e+03,  1.19188096e+03, -7.99920110e+00,  5.43945675e+02,\n        5.36946374e+02,  6.15938485e+02, -5.99940082e+00,  5.74942579e+02,\n        7.33926701e+02, -5.99940084e+00, -5.99940083e+00, -7.99920110e+00,\n       -5.99940082e+00,  8.11918911e+02,  5.45945475e+02, -5.99940081e+00,\n        5.51944876e+02,  7.79922107e+02,  1.03189694e+03, -5.99940080e+00,\n       -5.99940081e+00, -3.99960056e+00,  1.00389974e+03,  1.19388076e+03,\n        1.08429171e+04,  1.19188096e+03, -7.99920113e+00,  1.19388076e+03,\n        6.96930396e+02,  6.05939483e+02, -5.99940082e+00,  5.34946573e+02,\n        8.43915716e+02, -5.99940083e+00, -5.99940083e+00, -7.99920109e+00,\n       -5.99940083e+00,  8.71912920e+02,  9.95900537e+02, -5.99940083e+00,\n        6.01939883e+02,  8.09919111e+02,  1.19188096e+03, -5.99940081e+00,\n       -5.99940078e+00, -3.99960055e+00,  9.93900736e+02,  1.19388076e+03,\n        1.19388076e+03,  1.16308384e+04, -7.99920112e+00,  1.02389774e+03,\n       -2.99970041e+00, -3.99960055e+00, -5.99940082e+00, -4.99950069e+00,\n       -5.99940082e+00, -5.99940082e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00, -7.99920110e+00, -3.99960055e+00, -5.99940082e+00,\n       -7.99920110e+00, -9.99900137e+00, -7.99920110e+00, -5.99940082e+00,\n       -5.99940082e+00, -3.99960055e+00, -5.99940082e+00, -5.99940082e+00,\n       -5.99940082e+00, -7.99920110e+00, -7.99920110e+00, -5.99940082e+00,\n        6.66933392e+02,  5.35946474e+02, -5.99940082e+00,  7.24927600e+02,\n        5.33946673e+02, -5.99940081e+00, -5.99940082e+00, -7.99920110e+00,\n       -5.99940082e+00,  5.31946873e+02,  9.45905530e+02, -5.99940082e+00,\n        1.19188096e+03,  1.01989814e+03,  8.21917913e+02, -5.99940082e+00,\n       -5.99940086e+00, -3.99960055e+00,  7.23927699e+02,  5.43945675e+02,\n        1.19388076e+03,  1.02189794e+03, -7.99920107e+00,  1.05329480e+04])\n     fun: 4381.002675394279\n message: 'The algorithm terminated successfully and determined that the problem is infeasible.'\n     nit: 4\n   slack: array([], dtype=float64)\n  status: 2\n success: False\n       x: array([1.33630125, 1.33630125, 0.72363567, ..., 1.25494354, 1.2520338 ,\n       1.01759439])\n[25.2836661  25.2836661  23.87454089 23.85736666 22.92358045 25.21218089\n 23.77225208 23.82974501 25.39313184 23.82974501 24.83242583 24.49277083\n 25.37410372 22.90803073 23.68565375 24.81485143 22.88570538 24.25372542\n 24.45895798 24.68762057 22.92335758 23.92017804 24.27533126 23.11925871\n 24.58518598 25.23224542 24.60817148 23.14973545 24.26067157 24.60817148\n 24.59406271 24.6106668  23.6338265  23.75661862 24.24302036 24.72759441\n 24.39088079 23.6338265  24.60238281 24.71703015 23.86485208 24.78126498\n 23.29432843 23.86485208 24.04833536 25.12592644 24.26371588 23.24762732\n 24.39088079 24.33909973 23.87288055 24.01656751 24.04795658 23.70134198\n 24.30170872 24.30170872 24.23917449 24.64327592 24.07970166 24.34396678\n 24.67725583 25.12592644 24.32280263 23.60364009 24.23113127 24.21024173\n 24.40209124 24.3105531  23.75661862 23.63524614 24.42120405 24.17605304\n 24.42120405 24.36787799 24.23917449]\n```\n\nThe second code (added method:'simplex') is:\n```\nresult = optimize.linprog(c_0, A_eq=A, b_eq=b, method='simplex')  # min(c_0*x) such that: Ax=b\nprint(result)\nresult = np.reshape(result['x'], (k, n))\nxa = np.sum(result, axis=0)  # initial value of xa\nprint(xa)\n```\n\nThe output of the second code is:\n```\n     con: array([9.350e+03, 0.000e+00, 0.000e+00, 0.000e+00, 1.200e+03, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.000e+01, 0.000e+00,\n       2.400e+02, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 1.000e+01, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 1.036e+04, 0.000e+00, 0.000e+00, 4.000e+01, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.000e+01, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       1.000e+02, 0.000e+00, 0.000e+00, 4.200e+02, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 9.810e+03, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       3.000e+01, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 2.000e+02, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.020e+04, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 1.200e+02, 2.400e+02, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 2.000e+01, 0.000e+00, 0.000e+00, 5.000e+01, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 1.025e+04, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 5.200e+02, 5.400e+02, 0.000e+00, 0.000e+00,\n       0.000e+00, 2.000e+01, 0.000e+00, 9.000e+01, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.096e+04, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 1.300e+02, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.900e+02, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 3.000e+01, 0.000e+00,\n       9.630e+03, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 1.500e+02, 0.000e+00, 0.000e+00, 0.000e+00, 5.800e+02,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.000e+01, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 3.000e+02, 0.000e+00,\n       0.000e+00, 1.001e+04, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 4.000e+01, 7.900e+02, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 1.000e+01, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 9.970e+03, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 7.800e+02, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 3.600e+02, 0.000e+00, 7.000e+01, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       1.017e+04, 0.000e+00, 4.200e+02, 1.000e+03, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.700e+02, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 8.750e+03, 5.600e+02, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 8.000e+01, 0.000e+00, 0.000e+00, 1.600e+02, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 1.031e+04, 0.000e+00, 0.000e+00, 1.900e+02,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 4.000e+02, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.200e+02, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 2.100e+02, 1.041e+04, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n       6.700e+02, 5.400e+02, 0.000e+00, 7.300e+02, 5.400e+02, 0.000e+00,\n       0.000e+00, 0.000e+00, 0.000e+00, 5.400e+02, 9.500e+02, 0.000e+00,\n       1.200e+03, 1.030e+03, 8.300e+02, 0.000e+00, 0.000e+00, 0.000e+00,\n       7.300e+02, 5.500e+02, 1.200e+03, 1.030e+03, 0.000e+00, 1.054e+04])\n     fun: 202134.0\n message: \"Phase 1 of the simplex method failed to find a feasible solution. The pseudo-objective function evaluates to 1.6e+05 which exceeds the required tolerance of 1e-09 for a solution to be considered 'close enough' to zero to be a basic solution. Consider increasing the tolerance to be greater than 1.6e+05. If this tolerance is unacceptably  large the problem may be infeasible.\"\n     nit: 1000\n   slack: array([], dtype=float64)\n  status: 2\n success: False\n       x: array([1200.,    0.,    0., ...,    0.,    0.,    0.])\n[11740.     0.     0.     0.     0.     0.  1740.  9690.     0.     0.\n     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n     0.     0.     0.     0.     0.     0. 11940.     0.  1830.     0.\n     0.     0.     0.     0.     0.  7910.     0.     0.     0.     0.\n  5050.     0.     0.     0.     0.  7570.  2220.     0.     0.     0.\n     0.     0.     0.     0.     0.     0.  9650.  3550.     0.  7170.\n     0.     0.     0.     0.     0.     0.   120.     0.     0.     0.\n     0.     0.     0.     0.     0.]\n```\n\nI would appreciate any help in solving this problem.\n    ", "Answer": "\r\nIt was the incidence matrix that caused the problem.\nI should use this code:\n```\nincMatrixScipy = nx.incidence_matrix(Graph1, oriented=True)\nincMatrixNumPy = incMatrixScipy.todense()\n```\n\nInstead of this code:\n```\nincMatrixScipy = nx.incidence_matrix(Graph1)\nincMatrixNumPy = incMatrixScipy.todense()\n```\n\nI need to add oriented=True to receive the correct incidence matrix because my graph is directed.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "What are the equivalent functions of fmincon with 'trust-region-reflective' algorithm and fminsearchbnd in R?\r\n                \r\nI am trying to reproduce the following matlab functions in R. I need to find the closest approximations of fmincon and fminsearchbnd in R.\n```\nif license('test','optimization_toolbox')\n    % IF OPTIMIZATION TOOLBOX IS PRESENT, AN ANALYTICAL GRADIENT BASED\n    % MINIMIZATION APPROACH IS USED (trust-region-reflective)\n    if(exist('optimoptions', 'file'))\n      options = optimoptions('fmincon','Algorithm','trust-region-reflective','Display','off','GradObj','on','MaxIter',2000,...\n                           'MaxFunEvals',10000,'TolFun',1e-8,'TolX',1e-8);\n    else\n      options = optimset('Algorithm','trust-region-reflective','Display','off','GradObj','on','MaxIter',2000,...\n                           'MaxFunEvals',10000,'TolFun',1e-8,'TolX',1e-8);  \n    end\n    [xfit1,fval1] = fmincon(FUN_MIN_GRAD_PARAMETRIZED,x0,[],[],[],[],LB,UB,[],options);\n  end\n    % WE also USE A CONSTRAINED VERSION OF FREELY AVAILABLE fminsearch \n    % (THIS USES DERIFVATIVE FREE SIMPLEX ALGORITHM)\n    [xfit2,fval2] =  fminsearchbnd(FUN_MIN_GRAD_PARAMETRIZED,x0,LB,UB,optimset(...\n                     'MaxIter',2000,'MaxFunEvals',10000,'TolFun',1e-8,'TolX',1e-8)); \n```\n\nThe pracma package provides fmincon equivalence but with the  Squential\nQuadratic Programming (SQP) approach.\nAre there any equivalent functions of fmincon with trust-region-reflective algorithm and fminsearchbnd in R?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to use interior point method to get an extreme point with optimal objective value in large scale linear programming?\r\n                \r\nI need to solve a linear programming with few constraints but many variables:\n\n\n\nA is mxn. m is about 15, but n is more than 1 million. I used Matlab linprog with different algorithm(dual-simplex, interior-point, interior-point-legacy).Below are the time they spent.\n\n\nDual-simplex method takes almost a day. \nInterior-point method takes more than a day.\nInterior-point-legacy only takes within 5 miniutes.\n\n\nAs I know, interior point method is faster than simplex method in large scale linear programming. But the results 1 and 2 above are unexpected.\n\nDiscuss only dual-simplex method (1) and interior-point-legacy method (3). They get different answers. (1) gets an answer which has only 12 nonzero terms while (3) gets an answer with all terms nonzero. Two answers have the same objective value. \n\nThe answer of (1) is what I want (Only a few nonzero terms), but (1) is time-comsuming. The answer of (3) is an interior point, so all terms are nonzero. But almost 99% of the terms are very small (smaller than 0.001). That is not what I want. But (3) is fast.\n\nWhat I want is to let the answer of (3) goes to the extreme point. (Let the number of nonzero terms is at most the number of constraints.) I use some key words like 'large scale', 'interior point method', 'linear programming' to search on the Internet, but I have not found what I want yet. Is there any direction or suggestion?\n\nSorry, one thing I forgot to mention. My coefficients in A and b are all positive. And the coefficients in c are all \"-1\".\n    ", "Answer": "\r\nIn your case, the Sifting method is probably best suited:\n\n\nhttps://www.ibm.com/support/knowledgecenter/en/SS9UKU_12.7.0/com.ibm.cplex.zos.help/CPLEX/UsrMan/topics/cont_optim/simplex/10_sifting.html\nhttp://www.gurobi.com/documentation/7.5/refman/sifting.html#parameter:Sifting\n\n\nSifting iteratively solves subproblems containing only some of the variables and checks for optimality of the remaining ones. This can work because as you already suggested most of the variables in a basic solution would be zero.\n\nMost commercial solvers like CPLEX, or Gurobi would use this method automatically for your problem.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How would I modify a 3d cave systems so that it is does not remove as much material from the surface?\r\n                \r\nCurrently I am tackling a project involving 3d noise and the Marching Cubes algorithm to create a 3d procedurally generated world. I already have the code to create the above ground with mountains, cliffs, and overhangs using a mix of 2d and 3d simplex noise. In order to implement the cave system I simply used 3d simplex noise to carve out empty space underneath the main terrain mesh(Since I am using the marching cubes algorithm any vertex that is below the surfaceLevel variable is considered empty space). The main problem that I am having right now is that there are too many caves appearing above ground. One solution I came across here is to somehow make it so that the caves become narrower the closer it is to the surface. However, I have no idea how to implement this. Another solution I came across is from this video which was to create a noise mask(Again I have no idea how this works or how to implement it). How would I implement these methods or Is there a better way to make it so that the caves will not remove as much of the surface.\nCurrent Problem\n\nCurrent Code\n```\n        for(int y = 0; y<height+1; y++){\n            for(int x = x1; x<x1+width+1; x++){\n                for(int z = z1; z<z1+width+1; z++){ \n                    double noise3d = this.sumOctaves(4,x,y,z,0.5,0.01,0,1); // creates 3d terrain like caves and overhangs\n                    double noise2d = this.sumOctaves(4,x,z,0.5,0.01,0,1); // creates 2d terrain like mountains and hills (gives only height)\n                    double cave = this.sumOctaves(1,x,y,z,0.5,0.035,0,1); // creates 3d terrain like caves and overhangs\n                    double mask =  this.sumOctaves(1,x,z,0.1,0.0019,0,1); // creates a 2d mask to vary heights of regions, lower the scale more diversity in regions, higher the scale more mountains and canyons\n                    float curHeight = -y+height/3+(float)height*(float)(noise2d*(1-perlin3Dratio)+noise3d*perlin3Dratio)*(float)mask; // mixing them together with correct ratio of 3d and 2d data\n                    if(cave < surfaceLevel){//checks if the noise value is empty space\n                        curHeight = (float)cave;\n                    }\n                    terrainMap[x-x1][y][z-z1] = curHeight;\n                }\n            }\n        }\n```\n\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Angular4 error message shows code which differs from the code that's supposed to be serving\r\n                \r\nI'm writing an app to go into a website, which is intended to calculate simplex algorithms. At the moment I am attempting to create functionality whereby the user can enter the number of coefficients and constraints, name these whatever they wish, and have the app spawn the relevant number and type of UI elements relative to the user's input. Here's what appears to be the relevant portion of the code (app.component.ts):\n\n```\nimport { Component } from '@angular/core';\n\n[...]\n\nexport class UIComponent {\n  id: 1;\n  name: string;\n  value: number;\n  type: string;\n}\n\n//* Mock data */\nconst UICOMPONENTS: UIComponent[] = [\n  { id: 1, name: 'coefficient1', value: 4, type: '1dslide' },\n  { id: 2, name: 'constraint1', value: 2, type: '2dslide' },\n  { id: 3, name: 'min_max', value: 0, type: 'switch' },\n  { id: 4, name: 'profit', value: 100, type: 'num_output' }\n];\n\n[...]\n\nexport class AppComponent {\n  title = 'SimutronX';\n  uicomponents = UICOMPONENTS;\n  [...]\n}\n```\n\n\nThis produces an error on screen saying:\n\n```\nFailed to compile.\n\n/root/simutronx/simutron-app/src/app/app.component.ts (18,49): ',' expected.\n```\n\n\nWhich relates to this line: \n\n```\n{ id: 2, name: 'constraint1', value: 2, type: '2dslide' },\n```\n\n\nSpecifically the digit ```\n2```\n in ```\n2dslide```\n. The error message (it's extremely long so I won't reproduce it all) also includes:\n\n```\n./src/app/app.component.ts\nModule parse failed: /root/simutronx/simutron-app/node_modules/@ngtools/webpack/src/index.js!/root/simutronx/simutron-app/src/app/app.component.ts Unexpected token (22:85)\nYou may need an appropriate loader to handle this file type.\n| var UICOMPONENTS = [\n|     { id: 1, name: 'coefficient1', value: 4, type: '1dslide' },\n|     { id: 2, name: 'constraint1, value: 2, type: ', 2: dslide, ' },: { id: 3, name: 'min_max', value: 0, type: 'switch' }, },\n|     { id: 4, name: 'profit', value: 100, type: 'num_output' }\n| ];\n```\n\n\nWhich is particularly confusing since, as you can see, that's not how I wrote the code. What's going on here?\n    ", "Answer": "\r\nYou have an error in UIComponent type :\n\n```\nexport class UIComponent {\n  id: number; //HERE\n  name: string;\n  value: number;\n  type: string;\n}\n```\n\n\nHere a plunker :http://plnkr.co/edit/e6GrylSWznwbYD9VpK2C\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "collision prediction using minkowski sum\r\n                \r\nI want to use the minkowski sum to predict the exact point of collision between two convex shapes. By my understanding  the point where the velocity vector intersects with the minkowski sum is the amount I have to move my object along the vector so they just touch (I already know they will collide). Here's an example of what I mean (for simplicity reasons I just used rectangles):\n\n\n\nI mean I could just calculate the intersection with every line of the convex hull  and just use the closest but that seems horribly inefficient. My idea was to calculate the simplex closest to the vector but I have no idea how best to do it. I found a algorithm which calculates the smallest distance between to objects or to be more precise the smallest distance from the minkowski sum to the origin (http://www.codezealot.org/archives/153). One part of the algorithm tries to find the simplex closest to origin which is kinda what I want to do. I tried to change it to my needs but I wasn't successful. To me it sounds like there should be a very simple solution but I am not that good with vector math.\n\nI hope I could make my problem clear since my english is not so good :D\n    ", "Answer": "\r\nYou can transform the problem as follows:\n\n1) rotate the plane so that the velocity vector becomes horizontal\n\n2) consider the portions of the polygon outlines facing each other (these are two convex polylines); now you have to find the shortest horizontal distance between these two polylines\n\n3) through every vertex of one of the polylines, draw an horizontal line; this will parition the plane into a set of horizontal slices\n\n4) transform every slice using a shear transformation that brings the two vertices defining it onto the Y axis by horizontal moves; this transform preserves horizontal distances\n\n5) while the first polyline is transformed into a straight line (the Y axis), the other polyline is transformed into another polyline; find the vertex(es) closest to the Y axis. This gives you the length of the collision vector.\n\nAs a by-product, step 2) will tell you if the polygons do collide, if the ranges of Y values overlap.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to make and draw a Perlin Noise on a JPanel [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs to be more focused. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\r\n                \r\n                    \r\n                        Closed 6 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI want to make a application that draws a noise to a JPanel in Java. I came up with a really random noise, but i would like to draw a Perlin or Simplex Noise.\nHere is the code:  \n\n```\nimport java.awt.*;\nimport java.util.*;\nimport javax.swing.*;\n\npublic class Paint extends JPanel {\n\nprivate static boolean running = false;\nprivate static Paint paint = new Paint();\nprivate static Random random = new Random();\n\npublic static void main(String args[]) {\n    running = true;\n    JFrame f = new JFrame();\n    f.setSize(800, 800);\n    f.setResizable(running);\n    f.setUndecorated(running);\n    f.setLocationRelativeTo(null);\n    f.add(paint);\n    f.setVisible(running);\n\n    while(running) {\n        paint.repaint();\n    }\n}\n\npublic void paint(Graphics g) {\n    noise(g);\n}\n\nprivate void noise(Graphics g) {\n    for(int i = 0; i < 800; i=i+10) {\n        for(int j = 0; j < 800; j=j+10) {\n            g.setColor(new Color(random.nextInt(255),random.nextInt(255),random.nextInt(255)));\n            g.fillRect(j, i, 10, 10);\n        }\n    }\n    running = false;\n}\n\n}\n```\n\n\nSo how would I implant the Perlin Noise algorithm to this code, while not having to install external libraries.\nEDIT: I am not lazy, or something. I read my way through all possible Noise generations, I just don't completely understand how to immigrate the noise methods into the class.\n    ", "Answer": "\r\nYou are lucky, I recently did exactly this, heres my code:\n\n```\nBufferedImage tex;\nfloat[] interpol;\nint size;\nfloat[] noise;\nfloat[] workSet;\nfloat r1,g1,b1,r2,g2,b2;\nint octaves=4;\nint octaveOffset=2;\npublic void init(int size)\n{\n    this.size=size;\n    tex=new BufferedImage(size,size,BufferedImage.TYPE_INT_ARGB);\n    interpol=new float[size];\n    workSet=new float[size*size];\n    noise=new float[size*size];\n    float smult=(float) (Math.PI/size);\n    for(int i=0;i<size;i++)\n    {\n        interpol[i]=(1+(float) Math.cos(i*smult))/2;\n    }\n    r1=255;\n    g1=255;\n    b1=255;\n    r2=0;\n    g2=0;\n    b2=0;\n}\n\npublic void generate()\n{\n    Random r=new Random();\n    int[] pix=((DataBufferInt)(tex.getRaster().getDataBuffer())).getData();\n    int totalSize=size*size;\n    for(int i=0;i<totalSize;i++)\n    {\n        noise[i]=0.5f;\n    }\n    float[] randoms=new float[(size+1)*(size+1)];\n    int scale=size>>octaveOffset;\n    float max=0.50f;\n    for(int oct=0;oct<octaves;oct++)\n    {\n        int randsPerLine=size/scale+1;\n        int rands=randsPerLine*randsPerLine;\n        for(int i=0;i<rands;i++)\n        {\n            randoms[i]=max*(r.nextFloat()-0.5f);\n        }\n        for(int i=0;i<totalSize;i++)\n        {\n            int y=(i/size)/scale;\n            int suby=(i/size)%scale;\n            int x=(i%size)/scale;\n            int subx=(i%size)%scale;\n            float intp=interpol[subx*(size/scale)];\n            float colorA=randoms[y*randsPerLine+x]*intp+(1-intp)*randoms[y*randsPerLine+x+1];\n            float colorB=randoms[(1+y)*randsPerLine+x]*intp+(1-intp)*randoms[(1+y)*randsPerLine+x+1];\n            intp=interpol[suby*(size/scale)];\n            workSet[i]=colorA*intp+(1-intp)*colorB;\n        }\n\n        for(int i=0;i<totalSize;i++)\n        {\n            noise[i]+=workSet[i];\n        }\n        max/=2;\n        scale/=2;\n    }\n    for(int i=0;i<totalSize;i++)\n    {\n        int red=(int) (r1*noise[i]+r2*(1-noise[i]));\n        int g=(int) (g1*noise[i]+g2*(1-noise[i]));\n        int b=(int) (b1*noise[i]+b2*(1-noise[i]));\n        pix[i]=(255<<24)+(red<<16)+(g<<8)+b;\n    }\n}\n```\n\n\nTo draw it use ```\ng.drawImage(tex,[your coordinates],null)```\n.\nMy code generates a square image ```\nsize```\n x ```\nsize```\n with a noisy mixture between two colors, currently black and white, this can be changed by modifying ```\nr1, g1, b1, r2, g2, b2```\n. Play around with the ```\noctaves```\n and the ```\noctaveOffset```\n values to make the noise suit your needs.\nI only tested this code with ```\nsize```\n being a power of 2 and while merging with your code I found out that it only works if ```\npaint.init(1024)```\n and ```\npaint.generate()```\n are called right at the beginning of ```\nmain()```\n.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Expectation vs. direct numerical optimization of likelihood function for estimating high-dimensional Markov-Switching /HMM model\r\n                \r\nI am currently estimating a Markov-switching model with many parameters using direct optimization of the log likelihood function (through the forward-backward algorithm). I do the numerical optimization using matlab's genetic algorithm, since other approaches such as the (mostly gradient or simplex-based) algorithms in fmincon and fminsearchbnd were not very useful, given that likelihood function is not only of very high dimension but also shows many local maxima and is highly nonlinear. \nThe genetic algorithm seems to work very well. However, I am planning to further increase the dimension of the problem. I have read about an EM algorithm to estimate Markov-switching models. From what I understand this algorithm releases a sequence of increasing log-likelhood values. It thus seems suitable to estimate models with very many parameters. \n\nMy question is if the EM algorithm is suitable for my application involving many parameters (perhaps better suitable as the genetic algorithm). Speed is not the main limitation (the genetic algorithm is altready extremely slow) but I would need to have some certainty to end up close to the global optimum and not run into one of the many local optima. Do you have any experience or suggestions regarding this?\n    ", "Answer": "\r\nThe EM algorithm finds local optima, and does not guarantee that they are global optima. In fact, if you start it off with a HMM where one of the transition probabilities is zero, that probability will typically never change from zero, because those transitions will appear only with expectation zero in the expectation step, so those starting points have no hope of finding a global optimum which does not have that transition probability zero.\n\nThe standard workaround for this is to start it off from a variety of different random parameter settings, pick the highest local optima found, and hope for the best. You might be slightly reassured if a significant proportion of the runs converged to the same (or to equivalent) best local optimum found, on the not very reliable theory that anything better would be found from at least the same fraction of random starts, and so would have showed up by now.\n\nI haven't worked it out in detail, but the EM algorithm solves such a general set of problems that I expect that if it guaranteed to find the global optimum then it would be capable of finding the solution to NP-complete problems with unprecedented efficiency.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How can I improve the performance of my HTML5 2D canvas?\r\n                \r\nI've made a \"biome gridmap playground\" app which help to design biomes for a 2D grid map using simplex noise. The algorithm is roughly this: for each grid map tile, we look at the noises values (moisture and height) at this coordinate, determine the color of the tile and then render it on the canvas. It is very slow when there are hundreds of tiles. Also, rendering the canvas blocks the main thread and therefore the UI, which is very annoying. I think this could be solved by using Web Workers. However, it would not fix my main issue: canvas rendering seems to be slow. I'm wondering if using threejs could improve performances? Or maybe there is a smarter algorithm I could implement?\n    ", "Answer": "\r\nGPU State changes\nNice APP \"biome gridmap playground\" :)\nYou are wasting a lot of time changing GPU state by setting ```\nctx.fillStyle```\n for each tile.\nGPU State changes are a major source of slowdown for all apps that use the GPU (even native apps) Always go out of your way to avoid GPU state changes as they are evil.\nUse CPU\nRather than use the 2D API to fill tiles (```\ngridMap```\n) change the image pixels directly using the CPU.\nCreate the 2D API with option ```\ncanvas.getContext(\"2d\", {willReadFrequently: true})```\n this will disable the GPU for the 2D API (as we will not be using it)\nGet the pixels using ctx.getImageData. The data contains the raw pixel data.\nYou can then write directly to the image data buffer and avoid all state changes in the process.\nExample\nUsing drawRawMap as an example.\nDetails of ```\ndrawRawMap```\n\n\nFrom your git and using JS rather than TS.\nReplacing two functions ```\ndrawRawMap```\n and ```\nget2DCanvas```\n.\nCreates working canvas ```\nwCanvas```\n with tile size 1 to fill with B/W pixels\nGets ```\nimageData```\n and uses view of ```\nUint32Array```\n ```\nd32```\n to have single write per pixel.\nCreates a lookup table ```\npxLu```\n to convert raw 0 - 255 values to gray scale pixels\nDraws pixels and puts the new pixels back on the working canvas.\nGet on screen canvas and draws working canvas scaled by tile size onto it.\nAll done.\n\nThis will be an order of magnitude faster (at least) than the existing code.\nYou can do the same with other rendering calls. Draw to a working canvas pixels', use lookup table to get pixels colors. Use tile size 1 to avoid needing to set more than one pixel per tile, and scale by ```\ntilesize```\n when drawing the result to display canvas.\n```\n    // Assumes tileSize > 0 && width > 0 && height > 0\n    // Assumes rawMap rows and columns match height and width\n    // Assumes sizes rawMap.length === height && rawMap[0 to height - 1].length === width\n    drawRawMap(name, rawMap, width, height, tilesize) {\n        \n        // Next 4 lines best done only when needed (eg width or height change)\n        const wCanvas = Object.assign(document.createElement(\"canvas\"), {width, height});  // create working canvas\n        const wCtx = wCanvas.getContext(\"2d\", {willReadFrequently: true});    \n        const imgData = wCtx.getImageData(0, 0, width, height);    \n        const d32 = new Uint32Array(imgData.data.buffer); // get 32 bit int view of pixels\n\n        // Next 2 lines best done once\n        const pxLu = new Uint32Array(256);   // Lookup gray scale pixels\n        for (let i = 0; i < 255; i ++) { pxLu[i] = 0xFF000000 | (i << 16) | (i << 8) | i; } \n        \n        // draw rawMap into 32bit pixel view d32\n        var idx = 0;\n        for (const row of rawMap) {  // assumes rows\n            for (const val of row) {  // val for each column\n                d32[idx++] = pxLu[(val + 1) * 0.5 * 255 | 0]; // assumes val -1 to 1 convert to 0 -255, the | 0 forces integer\n            }\n        }\n        wCtx.putImageData(imgData, 0, 0);  // move pixels to work canvas\n        \n        // draw working canvas onto display canvas.\n        const ctx = this.get2DCanvas(name, width, height, tilesize);\n        if (!ctx) { return; /* Fatal error */ }\n        ctx.imageSmoothingEnabled = false;\n        ctx.drawImage(wCanvas, 0, 0, width * tilesize, height * tileSize);\n        ctx.imageSmoothingEnabled = true;\n    }\n\n\n    get2DCanvas(name, width, height, tilesize, gap = 0) {\n        const canvas = document.getElementById(name);\n        canvas.width = width * (tilesize + gap);\n        canvas.height = height * (tilesize + gap);\n        return canvas.getContext(\"2d\");\n    }\n\n```\n\nAvoid blocking code\nUse Workers\nYou can get improvement via workers but it will be complicated as moving data between offscreen canvases has many caveats.\nUse Generators\nUsing a generator function you can split the task into sections (eg per row). Using ```\nyield```\n to stop the generator functions' execution (without dumping its context) and let UI have a go.\nYou can display the result using a timer (eg ```\nrequestAnimationFrame```\n) as the data is created. The timer just calls ```\nnext()```\n on the generator to process the next section (row).\nIf the generator is less than 16ms per section (yield token) the user will experience zero lag.\nAn example of a generator to show progress to a solution.\nThis will prevent the task from blocking the UI and let the user see the progress to the solution (or wait till done to show result).\nNoise\nI did not look at the source of your simplex noise, the following is a fork of open simplex noise that has a good performance increase on the original.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Setting convergence criteria for scipy.optimize.fmin (and others)\r\n                \r\nI am working on an optimization task where cost function evaluations are very expensive, and some error can be tolerated.  I'm using some pre-packaged scipy methods from scipy.optimize to get started.  The first one I'm working with is fmin, which implements the nelder mead simplex algorithm.\n\nThis function has two convergence related parameters xtol and ftol, which (as I understand it) specifiy a convergence criteria where if x or f (the parameter set, and the cost respectively) change by less than xtol or ftol on an iteration, the function returns.\n\nHowever, since cost functions are so expensive for me, I want to also be able to specify a cost threshold where it will return immediately if it finds a point with less cost than the threshold.\n\nIs it possible to specify this threshold for scipy.optimize.fmin?\n\nBonus question:  I haven't looked in detail at many other methods, but it doesn't look like this threshold option exists for those either.  Is this typical for scipy optimization methods?  Would it be valuable for me to try to contribute this functionality?\n    ", "Answer": "\r\nIt is possible to stop the iteration for any criterion that can be expressed as a function of ```\nx```\n. The idea here is to hijack the ```\ncallback```\n method and use exceptions for flow control. Here are two solutions that exploit this idea:\n\n```\nfrom scipy.optimize import fmin_bfgs\nimport numpy as np\nf = lambda x: np.linalg.norm(x**2)\nx0 = np.random.rand(100)\n```\n\n\nSolution 1:\n\n```\nglobal result\n\nclass SmallEnoughException(Exception):\n    pass\n\ndef check_conv_criteria(xk):\n    global result\n    if np.linalg.norm(xk) < 0.1:\n        result = xk\n        raise SmallEnoughException()\n\ntry:\n    x, _, _ = fmin_bfgs(f, x0, callback=check_conv_criteria)\nexcept SmallEnoughException:\n    x = result\n```\n\n\nSolution 2:\n\n```\nclass StopOptimizingException(Exception):\n    pass\n\nclass CallbackCollector:\n\n    def __init__(self, f, thresh):\n        self._f  = f\n        self._thresh = thresh\n\n    def __call__(self, xk):\n        if self._f(xk) < self._thresh:\n            self.x_opt = xk\n            raise StopOptimizingException()\n\ntry:\n    cb = CallbackCollector(f, thresh=0.2)\n    x, _, _ = fmin_bfgs(f, x0, callback=cb)\nexcept StopOptimizingException:\n    x = cb.x_opt\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to get multiple different unsat cores or make the core smaller with z3 (QF_LRA)\r\n                \r\nAfter reading the previous questions Getting a \"good\" unsat core and getting new unsat core, I know that it is impossible to get multiple different unsat cores with z3 at present.\nDo you have some suggestions to make the unsat core smaller? I am using z3 c++ api to check the satisfiability of a constraints on linear real arithmetic. I found that when adding this line of code ```\np.set(\":auto-config\",false)```\n as suggested in Getting a \"good\" unsat core, the size of unsat core becomes smaller. \n\nAnother question is about the simplex-based algorithm of z3. I have used CPLEX to solve my application before using z3. CPLEX supports extracting the IIS (irreducible infeasible set) which is like unsat core in z3. We can set the solving algorithm to 'auto', 'primal', 'dual' in CPLEX. I found when switching the solving algorithm the IIS CPLEX gives may be different. Does z3 support setting different solving algorithms when the logic is set to QF_LRA? \n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Why do Perlin noise algorithms use lookup tables for random numbers\r\n                \r\nI have been researching noise algorithms for a library I wish to build, and have started with Perlin noise (more accurately Simplex noise, I want to work with arbitrary dimensions, or at least up to 6). Reading Simplex noise demystified, helped, but looking through the implementations at the end, i saw a big lookup table named ```\nperm```\n.\n\nIn the code example, it seems to be used to generate indexes into a set of gradients, but the method seems odd. I assume that the table is just there to provide 1) determinism, and 2) a speed boost.\n\nMy question is, does the ```\nperm```\n lookup table have any auxiliary meaning or purpose, or it there for the reasons above? Or another way, is there a specific reason that a pseudo-random number generator is not used, other than performance?\n    ", "Answer": "\r\nThis is a bytes array. The range is 0 to 255.\nYou may randomize it if you want. You will probably want to seed the random... etc.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Is there any way to improve performance of my procedural generation code?\r\n                \r\nI've been working on a project lately that creates procedurally generated terrain which uses 3d simplex noise as well as the Marching cubes algorithm. I am currently running it on my cpu which takes around 10-20 seconds to render a 200x200x200 terrain which isn't optimal if I want to make the world infinite. Is there any way to improve the speed which the terrain renders or is this the maximum speed I can achieve. (I've already tried using compute shaders but limitations with GLSL didn't allow me to pursue that idea.)\nTerrain Generation Code\n```\npackage Terrain;\n\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Random;\n\nimport Entities.Entity;\nimport Maths.Vector3f;\nimport Models.RawModel;\nimport Render.Loader;\n\n\npublic class Terrain {\n    private int width = 200, height = 2, interval = 8;\n    \n    private float x,y,z = 2f;\n    private int x1,y1,z1;\n    \n    private Loader loader;\n    \n    private List<Entity> cubes = new ArrayList<Entity>();\n    \n\n    private RawModel model;\n\n    private double perlin2DScale = 0.01, perlin3DScale = 0.01;//, maskScale = 0.00;\n    \n    private double perlin3Dratio = 0.8;// ratio of 3d noise to 2d;\n    \n    private double amp = 1; //height of mountains\n    \n    List<Vector3f> verticeArray = new ArrayList<Vector3f>();\n    float[][][] terrainMap = new float[width+1][height+1][width+1];\n    float[] SimplexMap3D = new float[(width+1)*(height+1)*(width+1)];\n    float[] SimplexMap2D = new float[(width+1)*(width+1)];\n\n    private float surfaceLevel = 1f;\n        \n    int seed;\n    \n    //SimplexComputeBuffer compute = new SimplexComputeBuffer();\n    public Terrain(float x, float z, Loader loader){\n        this.loader = loader; \n        this.x1 = (int) (x*width);\n        this.z1 = (int) (z*width);\n        this.x = x*width*interval;\n        this.z = z*width*interval;\n        Random rand = new Random();\n        seed = rand.nextInt(100000);\n        \n        loadMarchingTerrain();\n    }\n    public void changeAmp(double i){\n        x+=i;\n        System.out.println(\"amp =\"+amp);\n        verticeArray.clear();\n        loadMarchingTerrain();\n    }\n    public void changeSurface(double i){\n        surfaceLevel+=i;\n        System.out.println(\"surface =\"+surfaceLevel);\n        verticeArray.clear();\n        loadMarchingTerrain();\n    }\n    public void loadMarchingTerrain(){\n        for(int x = x1; x<x1+width+1; x++){\n            for(int y = y1; y<y1+height+1; y++){\n                for(int z = z1; z<z1+width+1; z++){ \n                    double noise3d = this.sumOctaves(4,x,y,z,0.5,perlin3DScale,0,1); // creates 3d terrain like caves and overhangs\n                    double noise2d = this.sumOctaves(4,x,z,0.5,perlin2DScale,0,1); // creates 2d terrain like mountains and hills (gives only height)\n                    //double mask =  this.sumOctaves(1,x,z,0.5,maskScale,0,1); // creates a 2d mask to vary heights of regions\n                    float curHeight = (float)height*(float)(noise2d*(1-perlin3Dratio)+noise3d*perlin3Dratio); // mixing them together with correct ratio of 3d and 2d data\n                    terrainMap[x-x1][y-y1][z-z1] = (float)-y+curHeight;\n                }\n            }\n        }\n        for(int x = 0; x<width; x++){\n            for(int y = 0; y<height; y++){\n                for(int z = 0; z<width; z++){\n                    marchCube(new Vector3f(x,y,z)); \n                }\n            }\n        }\n        float[] vertices = new float[verticeArray.size()*3];\n        int[] indice = new int[verticeArray.size()];\n        int vertexCount = 0;\n        for(Vector3f v : verticeArray){\n            vertices[vertexCount++] =v.x*interval;\n            vertices[vertexCount++] =v.y*interval;\n            vertices[vertexCount++] =v.z*interval;\n        }\n        for(int i = 0; i<indice.length; i++){\n            indice[i] = i;\n        }\n        model = loader.loadToVao(vertices, null, indice);\n    }\n    \n    public int configIndex(float[] cube){\n        int configIndex = 0;\n        for(int i = 0; i<8; i++){\n            if(cube[i] > surfaceLevel){\n                configIndex |= 1 << i;\n            }\n        }       \n        return configIndex;\n    }\n    \n    public float sampleTerrain(Vector3f point){\n        return terrainMap[(int) point.x][(int) point.y][(int) point.z];\n    }\n    \n    public Vector3f smoothPoint(Vector3f vert1, Vector3f vert2, int indice, float[] cube){\n        float sampleVert1 = cube[MarchingCubeTable.edges[indice][0]];\n        float sampleVert2 = cube[MarchingCubeTable.edges[indice][1]];\n        \n        float difference = sampleVert1-sampleVert2;\n        \n        if(difference == 0){\n            difference = surfaceLevel;\n        }else{\n            difference = (surfaceLevel-sampleVert1)/difference;\n        }\n        Vector3f a2 = vert1.subtract(vert2).scale(difference);\n        \n        Vector3f vertPos = vert1.add(a2);\n\n        return vertPos;\n    }\n    public void marchCube(Vector3f position){\n        //create cube\n        float[] cube = new float[8];\n        for(int i = 0; i<8; i++){       \n            Vector3f corner = position.add(MarchingCubeTable.cornerTable[i]);       \n            cube[i] = terrainMap[(int) corner.x][(int) corner.y][(int) corner.z];       \n        }\n        //search through index\n        int currentConfigIndex = configIndex(cube);     \n        if(currentConfigIndex == 0 || currentConfigIndex == 255){\n            return;\n        }       \n        //search through points\n        int edgeIndex = 0;\n        for(int j = 0; j<5; j++){\n            for(int i = 0; i<3; i++){\n                int indice = MarchingCubeTable.getIndex(currentConfigIndex)[edgeIndex];         \n                if(indice == -1){\n                    return;\n                }\n                Vector3f vert2 = position.add(MarchingCubeTable.cornerTable[MarchingCubeTable.edges[indice][0]]);\n                Vector3f vert1 = position.add(MarchingCubeTable.cornerTable[MarchingCubeTable.edges[indice][1]]);           \n                Vector3f vertPos = this.smoothPoint(vert1, vert2, indice, cube);                \n                verticeArray.add(vertPos);\n                edgeIndex++;\n            }\n        }\n    }\n    \n    /*\n     * Simplex Noise functions\n     */\n    public double sumOctaves(int iterations, double x, double y, double z, double persistance, double scale, double low, double high){\n        double maxamp = 0;\n        double amp = this.amp;\n        double frequency = scale;\n        double noise = 0;\n        \n        for(int i = 0; i<iterations; i++){\n            noise += SimplexNoise.noise((x)*frequency, (y)*frequency, (z)*frequency)*amp;\n            maxamp += amp;\n            amp *= persistance;\n            frequency *= 2;\n        }\n        \n        noise /= maxamp;\n        \n        noise = noise * (high - low) / 2 + (high + low) / 2;\n        return noise;\n    }\n    \n    public double sumOctaves(int iterations, int x, int y, double persistance, double scale, double low, double high){\n        double maxamp = 0;\n        double amp = this.amp;\n        double frequency = scale;\n        double noise = 0;\n        \n        for(int i = 0; i<iterations; i++){\n            noise += SimplexNoise.noise((x)*frequency, (y)*frequency)*amp;\n            maxamp += amp;\n            amp *= persistance;\n            frequency *= 2;\n        }\n        \n        noise /= maxamp;\n        \n        noise = noise * (high - low) / 2 + (high + low) / 2;\n        return noise;\n    }\n    \n    public List<Entity> getCubes(){\n        return cubes;\n    }\n    public float getX() {\n        return x;\n    }\n\n    public float getZ() {\n        return z;\n    }\n    \n    public float getY() {\n        return y;\n    }\n    public RawModel getRawModel(){\n        return model;\n    }\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to draw weighted convex hull in Matlab\r\n                \r\nSuppose I have a Matlab array ```\nPE```\n of size ```\nEx1```\n. The elements of ```\nPE```\n are between ```\n0```\n and ```\n1```\n and they sum up to one. \n\nTake another array ```\nPEY```\n of size ```\nExY```\n. The elements of ```\nPEY```\n are one or zero. Moreover, for each row, there exists at least a one. ```\nY=3```\n. \n\nFor example\n\n```\nclear\nE=4;\nY=3;\nPE=[1/2; 1/6; 1/6; 1/6];\nPEY=[1 0 0; 0 1 1; 1 1 1; 0 1 1]; \n```\n\n\nNow, consider the simplex with vertices ```\n(1,0,0)```\n, ```\n(0,1,0)```\n, and ```\n(0,0,1)```\n\n\n```\npatch([0 0 1],[0 1 0],[1 0 0],[0.8 0.8 0.8]);\naxis equal \naxis([0 1 0 1 0 1])\nview(120,30)\n```\n\n\nI want to draw a convex subset ```\nA```\n of such simplex. ```\nA```\n is constructed as follows. \n\nSTEP 1: We construct an ```\nEx1```\n cell array ```\nPEY_expanded```\n such that, for each ```\ne```\n-th row of ```\nPEY```\n that has more than a 1, we write down all admissible ```\n1xY```\n vectors containing just a 1 and stack them in ```\nPEY_expanded{e}```\n.\n\n```\nPEY_expanded=cell(E,1);\n\nfor e=1:E\n    if isequal(PEY(e,:),[1 1 1])\n       PEY_expanded{e}=[1 0 0; 0 1 0; 0 0 1]; \n    elseif isequal(PEY(e,:),[1 1 0])\n       PEY_expanded{e}=[1 0 0; 0 1 0];\n    elseif isequal(PEY(e,:),[1 0 1])\n       PEY_expanded{e}=[1 0 0; 0 0 1];\n    elseif isequal(PEY(e,:),[0 1 1])\n       PEY_expanded{e}=[0 1 0; 0 0 1];\n    else\n       PEY_expanded{e}=PEY(e,:);\n    end\nend\n```\n\n\nSTEP 2:  Take Cartesian product ```\nPEY_expanded{1} x PEY_expanded{2} x ... PEY_expanded{E}```\n and get ```\nPEY_cartesian```\n.\n\nNote: the code below is specific for ```\nE=4```\n and not general\n\n```\nsize_PEY_expanded=zeros(E,1);\nfor e=1:E\nsize_PEY_expanded(e)=size(PEY_expanded{e},1);\nend\n\n[a,b,c,d]=ndgrid(1: size_PEY_expanded(1),1: size_PEY_expanded(2),...\n                 1: size_PEY_expanded(3), 1: size_PEY_expanded(4));\n\nPEY_Cartesian= [PEY_expanded{1}(a,:),PEY_expanded{2}(b,:),...\n                PEY_expanded{3}(c,:), PEY_expanded{4}(d,:)];\n\nPEY_Cartesian_rearranged=cell(prod(size_PEY_expanded),1);\nfor i=1:prod(size_PEY_expanded)\n    PEY_Cartesian_rearranged{i}=[PEY_Cartesian(i,1:3); PEY_Cartesian(i,4:6);...\n                                 PEY_Cartesian(i,7:9);  PEY_Cartesian(i,10:end)];\nend\n\nPEY_Cartesian=PEY_Cartesian_rearranged;\n```\n\n\nSTEP 3: For each possible cell of ```\nPEY_Cartesian```\n, for ```\ny=1,...,Y```\n, weight ```\nPEY_Cartesian{i}(e,y)```\n by ```\nPE(e)```\n and then sum across ```\ne```\n. \n\n```\nPY=zeros(prod(size_PEY_expanded),Y);\nfor i=1:prod(size_PEY_expanded)\n    for y=1:Y\n        temp=0;\n        for e=1:E\n               temp=temp+PE(e)*PEY_Cartesian{i}(e,y);\n        end\n        PY(i,y)=temp;\n    end\nend\n```\n\n\nSTEP 4: Draw the region  ```\nA```\n that is the convex hull of the rows of ```\nPY```\n (black region in the picture)\n\n```\n%Need https://fr.mathworks.com/matlabcentral/fileexchange/37004-suite-of-functions-to-perform-uniform-sampling-of-a-sphere\nclose all\npatch([0 0 1],[0 1 0],[1 0 0],[0.8 0.8 0.8]);\naxis equal \naxis([0 1 0 1 0 1])\nview(120,30)\nhold on\nT = delaunayTriangulation(PY);\nK = convexHull(T);\npatch('Faces',K,'Vertices',T.Points,'FaceColor','k','edgecolor','k');\nhold on\n```\n\n\n\n\nQUESTION: \n\nThe algorithm above is unfeasible for large ```\nE```\n. In my actual case I have ```\nE=216```\n, for example. In particular, step 2 is unfeasible. \nCould you suggest an easier way to proceed? Given that ```\nA```\n is a convex region, maybe there is some shortcut I'm unable to see. \n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Plot triangles in real-time\r\n                \r\nI'm trying to implement an algorithm with python. I completed it but now I need some visualizing at runtime for tracking the value changes.\nIn a nutshell my algorithm creates different 3 points in every step. In 2D we can represent a triangle with this 3 point. So I need draw triangles which created in current step on loop to the coordinate system. My points are like: ```\n[2,4] x=2, y=4```\n. My triangle simplex values are like for a step: ```\n[[0.2, 4.2], [2.798, 2.7], [0.2, 1.2]]```\n\nI tried various libs and codes for this. I don't want to write useless codes that I tried. And also generally plot libraries(like ```\nmatplotlib```\n) draws shapes at the end of program as output. But I need to see them at the real-time. Do you have any advice or an example?\n    ", "Answer": "\r\nYou can call ```\npause()```\n after ```\ndraw()```\n like this:\n```\nplt.draw()\nplt.pause(0.1)\n```\n\nYou can also save it to a file if you need it for later:\n```\nplt.savefig(\"yourFile\")\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Infinte map generation in isometric game - Java LibGDX\r\n                \r\nI'm currently trying to learn game developing in Java with LibGDX and have a few questions regarding infinite map generation in an isometric type tile game. My current code in a Screen constructor looks like this.\n```\nfor (int col = MAP_WIDTH - 1; col >= 0; --col) {\n        for (int row = MAP_HEIGHT - 1; row >= 0; --row) {\n            int x = (col * TILE_WIDTH / 2) - (row * TILE_WIDTH / 2);\n            int y = (col * TILE_HEIGHT / 2) + (row * TILE_HEIGHT / 2);\n\n            float noise = OpenSimplex2.noise2_ImproveX(SEED, ((float) col) * scale, ((float) row * scale));\n            mainStage.addActor(new TileActor(x, y, col, row, getNameFromNoise(noise), mainStage));\n        }\n    }\n```\n\nThis adds and Actor in a set MAP_WIDTH and MAP_HEIGHT and changes the texture of that tile depending on a simplex noise algorithm. How would I best go about changing this to an infinite world? Should all the noise values be calculated beforehand and then the actors be loaded when the camera pans over their position? How would i best store this generated map? Thanks.\n    ", "Answer": "\r\nI don't think you need to store simplex values because its not a random function, you always get the same result for a given input, hence why one of the input parameters is usually time, to get change. Now admittedly I haven't used OpenSimplex2 I used another implementation but the whole point is that simplex noise is -coherent- so it cannot rely on randomness, which isn't coherent.\nSo I assume that you are using SEED to provide a different level every time you play and so assuming this could be called LEVEL_SEED.\nAnyway for an infinite world which you can reliably revisit areas without them changing, then you would need procedural generation for the area you are currently in, and given simplex noise is repeatable, then you can just change your function to iterate over the area you are currently in, and then map that area to the screen.\ni.e. you can iterate between\n```\nscreenCenterX - (screenWidth/2) to screenCenterX+ (screenWidth/2)\n```\n\nwith the inner iterator\n```\nscreenCenterY - (screenHeight/2) to screenCenterY+ (screenHeight/2)\n```\n\nI guess there are many ways but simplex noise is not a random function i.e. a different result every time, which means it does kind of lend itself to a procedural generation approach.\nYou might also want to look at this https://doc.mapeditor.org/en/stable/manual/using-infinite-maps/ which is a tile editor that allows dynamically super size map which is also pluggable into libGDX by which I mean its part of the libGDX framework.\nYou can alway ask on the Discord chat group here https://libgdx.com/community/ because I can imagine you'd get a quick answer as prob many opinions.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Is there a way to initialize the starting point of scipy.optimize.linprog?\r\n                \r\nI have a sequence of linear programs to solve. Each instance only differs from the previous one with the A, bounds, and costs being slightly different. Intuitively, the solutions from previous problems should help. How can I go about implementing that?\nscipy.optimize.linprog has an option ```\nx0```\n\n\nx0: 1-D array, optional\nStarting values of the independent variables, which will be refined by the optimization algorithm. For the revised simplex method, these must correspond with a basic feasible solution.\n\nwhich appears to do that, but doesn't seem to work if I just initialize the results from the previous optimization (```\nres.x```\n). It fails with the following error:\n```\n6 : Guess x0 cannot be converted to a basic feasible solution\n```\n\n    ", "Answer": "\r\nThe error basically means that ```\nres.x```\n from the problem you just solved does not satisfy the constraints of the problem you are trying to solve when passing in ```\nres.x```\n as ```\nx0```\n.\nWhy is that? The solution to a linear programming problem is always at one of the vertices of the feasible set, basically on the boundary of what is allowed by your constraints. If you next problem varies a bit from the one you solved, it is highly likely that the solution of the previous problem does not satisfy the constraints of the new one -- it was on the boundary and small changes to the problem moved the boundary a bit and made the previous point be outside. Without knowing the details of your optimization problem it is hard to recommend a sensible strategy here. For example, if you know that the point (0,...,0) is always feasible, you can scale all coordinates of ```\nres.x```\n down until you get into the feasible set.\nIt has been a while so I am not sure, but you can try ```\nmethod='interior-point'```\n as it may be more forgiving to ```\nx0```\n being outside the feasible set. Otherwise Google 'how to find a feasible solution for linear programming problem'\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "2-Dimensional Minimization without Derivatives and Ignoring certain Input Parameters on the go\r\n                \r\nI have a Function V which depends on two variables v1 and v2 and a parameter-Array p containing 15 Parameters. \nI want to Minimize my Function V regarding v1 and v2, but there is no closed expression for my Function, so I can't build and use the Derivatives. \n\nThe Problem is the following : For caluclating the Value of my Function I need the Eigenvalues of two 4x4 Matrices (which should be symmetric and real by concept, but sometimes the EigenSolver does not get real Eigenvalues). These Eigenvalues I calculate with the Eigen Package. The entries of the Matrices are given by v1,v2 and p.\n\nThere are certain Input Sets for which some of these Eigenvalues become negative. These are Input Sets which I want to ignore for my calculation as they will lead to an complex Function value and my Function is only allowed to have real values. \n\nIs there a way to include this? My first attempt was a Nelder-Mead-Simplex Algorithm using the GSL-Library and an way too high Output value for the Function if one of the Eigenvalues becomes negative, but this doesn't work. \n\nThanks for any suggestions.\n    ", "Answer": "\r\nFor the Nelder-Mead simplex, you could reject new points as vertices for the simplex, unless they have the desired properties.\n\nYour method to artificially increase the function value for forbidden points is also called penalty or barrier function. You might want to re-design your penalty function.\n\nAnother optimization method without derivatives is the Simulated Annealing method. Again, you could modify the method to avoid forbidden points.\n\nWhat do you mean by \"doesn't work\"? Does it take too long? Are the resulting function values too high?\n\nDepending on the function evaluation cost, it might be an approach to simply scan a 2D interval, evaluate all width x height function values and drill down in the tile with the lowest function values.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to create/post and delete/unpost constraints during search in Choco\r\n                \r\nI have got a project in Choco solver, but I have a question about the external effects during the search.\n\nI have got a planning graph with (let's say) BoolVars organised in layers and durations assigned to the layers, which mean that some action starts and some ends. The variable selection is static from the end of the plan to the start of the plan (the choice of the actions in layer is arbitrary). \n\nI am researching a solution that uses a simplex algorithm to help with assigning the durations, as between the start and the end of an action A we need to have a duration equal to N. There are some more constraints in between.\n\nThe additional constraints are created based on the instantiation of the BoolVars, however they are organized in an external matrix, so when an end action of the action A is added, in the effect an additional row is added to the matrix and current constraints are reformulated. On backtracking we would like to modify the matrix in the reverse way i.e. remove the row and unpost the constraints.\n\nIs there some way to realize this complex behavior in Choco?\n    ", "Answer": "\r\nDo you know in advance what constraint is triggered if a boolean is set to true?If yes, use reification (create the constraint at the beginning but associate them with boolvars instead of posting them). \n\nFor professional support on Choco Solver, you can contact https://www.cosling.com/\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Global random seed parameter in SCIP?\r\n                \r\nHow can I set a kind of global random seed on SCIP in order to obtain potentially different behaviors when solving a MIP? I'm looking for something like the ```\nSeed```\n parameter in Gurobi or the ```\nCPXPARAM_RandomSeed```\n parameter in CPLEX.\n\nLooking at the SCIP documentation, I see the following parameters but they make reference to particular plugins or aspects of the algorithm, and there does not seem to be a \"global\" random seed:\n\n\n```\nrandomization/permutationseed```\n (for permuting problem)\n```\nrandomization/lpseed```\n (for simplex)\n```\nbranching/random/seed```\n (for the random branching rule)\n```\nbranching/relpscost/startrandseed```\n (for the relpscost branching rule)\n```\nheuristics/alns/seed```\n (for bandit algorithms)\n```\nseparating/zerohalf/initseed```\n (for tie-breaking in cut selection)\n\n\nI do see the ```\nrandomization/randomseedshift```\n parameter that is described as \"global shift of all random seeds in the plugins and the LP random seed\". Could this parameter be used to achieve a global effect?\n\nThanks!\n    ", "Answer": "\r\nThe short answer is yes. The parameter ```\nrandomization/randomseedshift```\n affects all solver plugins that use randomization, and the LP. \n\nThe longer answer is that randomization of the solving process in SCIP can be achieved in three different basic ways:\n\n\nchanging the ```\nrandomization/randomseedshift```\n parameter, which affects the seed initialization of all plugins and the LP\nchanging the ```\nrandomization/lpseed```\n parameter for changing simplex randomization only\n```\nrandomization/permutationseed```\n for a permutation of the constraints and variables of the problems.\n\n\nThe permutation of the problem is the classic way of randomizing the solution process, however, it may obfuscate problem structure of the original input model.\n\nSCIP also provides access to the individual seeds such as ```\nheuristics/alns/seed```\n to modify only the behavior of a single plugin without affecting the rest.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Find best combination between many products and multiple sellers\r\n                \r\nLet's say i have a product A at 100$ with shipping cost at 3$ from supplier X, the same product at 102$ with shipping cost at 2.5$ from supplier Y and the same with different suppliers.\n\nNow let's say i have product B at 200$ with shipping cost at 1$ from supplier Z, the same product at 203$ with shipping cost at 2$ with supplier Y and the same with different suppliers.\n\nI want to order both A and B products and i want to calculate an optimal cost. For example, the input of my program will be multiple products and the output will be like\n example\n\nI am not familiar with simplex or any linear algorithms at all. How hard is to solve such a problem, can you give me any advice ?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Connect two procedurally generated landscape pieces\r\n                \r\nI'm working on a procedural generation of a continuous world.\nRecently I've been advised to use height map combinations to apply some constraints on my landscape.  \n\nThe next step is connecting two procedurally generated pieces to each other so that the transition would be smooth.\nMore accurately, it's all about generating the next piece based on the previous.\nI'm wondering what is the best way to do that (whether by combining height maps or in other way).\nIf I would have been using Diamond Square or Mid Displacement or any enclosing points based algorithm to generate the heights, \nI would think about assigning the first piece edge values to the second piece edge and use them as \"random\" values for these points. \nIn this way the transition would be smooth because all the rest of points in the second piece already take in account the edge points that are taken from the first piece.\nUnfortunately (or fortunately) I'm using a Simplex noise algorithm to generate the heights, and as you know is a gradient based algorithm.  \n\nSo what would you recommend?\n    ", "Answer": "\r\nYou can go similar way than in your previous question.\n\nIf you have your world divided by some grid and resulting in world ```\nchunks```\n, I'd make all chunks a bit bigger so they overlap their neighbors. Then you could modulate your heightmap by some rectangular gradient that goes to ```\n0```\n at the edges. Lastly, when you sum modulated values from all overlapping chunks you should get smooth transition between one height-map and another.\n\nYou'd still need to experiment with chunk scale factor and gradient data, to get the best transition and performance. Luckily, many of those operations can be done on GPU by simple rendering.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Calculating object rotation based on plane normal\r\n                \r\nI am currently working on procedurally generated terrain using simplex noise and the marching cubes algorithm. I've completed the process of creating a ground mesh which different entities like plants will lie on. However the models rendered will always point upwards instead of the direction which the trianglular face they lie on is pointing. This renders them into the ground which does not look good. I have already calculated the normals of each triangle so I am wondering how I would convert the normal of the triangular face to a 3D XYZ rotation for the model.\nThe image below shows my current problem:\nClipped plant models\n\n    ", "Answer": "\r\nJust take the cross product of up vector with plane normal. That will give you the rotation axis. Then take the dot product of the up vector with plane normal, that will give you the cosine of the rotation angle. So you have:\n```\nAxis = normalize(cross(up, normal))\n\nAngle = acos(dot(up, normal))\n```\n\nThen you can construct a quaternion or a rotation matrix from axis and angle.\nSee:\nhttps://en.m.wikipedia.org/wiki/Rodrigues%27_rotation_formula\nhttps://en.m.wikipedia.org/wiki/Rotation_matrix#Rotation_matrix_from_axis_and_angle\nhttps://www.euclideanspace.com/maths/geometry/rotations/conversions/angleToQuaternion/index.htm\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "3D Procedural generation of infinite caves\r\n                \r\nHow can you generate good looking caves? I have tried 3D simplex noise and 3D perlin noise, but neither give me any results. Depending on how I set it up, I get either slices or just random noise. My main problem is, that it seems all these noise generators are done for specific size (such as 4095x4095), but I need (relatively) infinite, thus I normalize the real coordinates (which are int) via ```\ncoord+(2^31)*(1.0/2^32)*4095```\n, but for 3D noise, it just makes the slices. If I do not do that, I get just random noise (even with just one octave). Which algorithm and how do you generate random caves in 3D?\n    ", "Answer": "\r\nYou can use perlin worms. (this might help)\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Pulling non zero values from excel\r\n                \r\ni have made this table in excel of items of food from a menu with their nutritional value. I've then got another table that has each item in one row and the quantity consumed of each item In the row below. I've then used the solver tool in excel to optimise the meal choices with set constraints on the amount of calories a meal can be as well as certain restrictions on the nutritional values that I have used.\n\nWhen I run the simplex algorithm through the solver tool what happens is the values in the table for quantity consumed changes to reflect what you should eat given the constraints. \n\nI want to make it flexible so that I can change the constraints and get different results but what I want is an easy way to show the choices made. Currently what I have is an index match on another tab to table and the values which I then apply a filter to and take off all the items with '0' for quantity consumed however this has to be done each time I run the solver. \n\nIs there any way to pull the non zeros and display what item these refer to without having to redo the filter every time ?\n    ", "Answer": "\r\nHere's a simple routine I use to look up something in a spreadsheet table and post the results on the same page (easily changed to post on another sheet). Hope this helps or heads you in the right direction. (Crude but effective)\n\n```\nPrivate Sub CommandButton3_Click()\n    'FIND A VALUE IN THE LIST AND POST RESULTS\n\nDim myName, myNumber, myComp\n\n  'Clear the results area\nWith Worksheets(\"SheetName\").Range(\"H2:J30\").ClearContents\nEnd With\nx = 2   'The row to start posting results to\ny = 0\n\n  'This is the range to search\nWith Worksheets(\"SheetName\").Range(\"A1:D300\")\n\n   Set found = .Find(What:=y, LookIn:=xlValues,  LookAt:=xlWhole)\n      If Not found Is Nothing Then\n        firstAddress = found.Address\n      Do\n\n        Set ws = Sheets(\"SheetName\")\n        myName = ws.Range(\"A\" & found.Row).Value  'Value in column A\n        myNumber = ws.Range(\"B\" & found.Row).Value 'Value in column B\n        myComp = ws.Range(\"C\" & found.Row).Value   'Value in column C \n\n               'I use a MsgBox at first for testing, then comment it out  when I know it's working \n               'MsgBox myName & \"   \" & myNumber & \"    \" & myComp\n\n                'Post the results to the desired area\n                ws.Range(\"H\" & x).Value = myName\n                ws.Range(\"I\" & x).Value = myNumber\n                ws.Range(\"J\" & x).Value = myComp\n            x = x + 1\n        Set found = .FindNext(found)\n        If found Is Nothing Then\n            GoTo DoneFinding\n        End If\n        Loop While Not found Is Nothing And found.Address <> firstAddress\n   End If\nDoneFinding:\nEnd With\nRange(\"A2\").Select\nEnd Sub\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Is there any documentation on the memory required by scipy.optimize.linprog or other python linear programming function\r\n                \r\nI have a problem with 288000 variables, 6 upper bound constraints, 24 equality constraints, and the parameters are bounded (all must be positive, half of them also have a maximum value).  I'm getting a MemoryError when I call scipy.optimize.linprog with an 8GB virtual machine. Is this expected? Is there any documentation on how much memory this function uses?\n\nI found this paper http://www.mit.edu/~mlubin/pipss.pdf \"Parallel distributed-memory simplex for large-scale stochastic LP problems\" Miles Lubin · J. A. Julian Hall · Cosmin G. Petra · Mihai Anitescu which surely has some clues. But if I'm setting up my problem wrong in the first place, a new algorithm won't help me.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "GJK collision detection implementation from 2D to 3D\r\n                \r\nI apologize for the length of this question and give a pre-emptive thanks for anyone who reads through this! \n\nSo i've spent the last few days going over the GJK algorithm. I understand the general concepts behind it, and understand the most of the nitty gritties of its implementation in 2D thanks to the wonderful article by William Bittle at http://www.codezealot.org/archives/88 . \n\nI've implemented his pseudo code (found at the end of the article) into my own c++ project, however i want to make a 3D implementation. My weakness comes into using the dot products to test the voronoi regions and the tripleProducts to get perpandicular lines. But im trying to read up more on that.\n\nMy problem comes down to the containsOrigin function. Im having trouble visualizing and accounting for the new voronoi regions that the z axis adds. I just can't seem to wrap my head around how to determine which regions contains the origin. I assume there is 4 I have to account for, each extending from the triangular planes that the comprise the 4 faces of the tetrahedron simplex. If the origin is not within any of those regions, then it is contained, and we have a collision.\n\nHow do i go about testing if it is contained in a particular voronoi region/ which triangular face is pointing in the direction of the origin? \n\nThe current 2D algorithm checks if a triangle is made, if not, then the simplex is a line and it finds the 3rd point. I assume the 3D algorithm with check if a tetrahedron is made, if not, then it will check for a triangle, if true then it will to find a 4th point to make a tetrahedron(how would i get this? using a normal in direction of origin?). If i trangle isnt made, it will find a 3rd point to make a triangle (do i still use triple product for this like in 2D?).\n\nAny suggestions, outlines, resources, code augmentations, comments are much appretiated.\n    ", "Answer": "\r\nDepending on what result you expect from the GJK algorithm you might want to look at this nice tutorial from Molly Rocket: https://mollyrocket.com/849\n\nBe aware though that his implementation only outputs intersection? yes/no. But it might be a nice start.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Why is each iteration in Nelder-Mead in scipy so slow?\r\n                \r\nI'm trying to minimize a function using Nelder-Mead as implemented in scipy.minimize(method='Nelder-Mead'). The function has about 30 inputs, but I have been optimizing sequentially (i.e. optimize over the first 5, keep remaining 25 fixed, then gradually increase number of variables to be minimized over). \n(I'm not using gradient-based since there is simulation noise in my objective function, making it non-smooth for too small step-sizes and gradients unreliable). \n\nHowever, the iterations are very slow. If I time the step of a single function evaluation, it takes about 60sec, but each iteration in the optimization is very slow, slower than 10 min at least. I'm using the callback function option to gauge the time taken. \n\nWhat does it do in each iteration? Does it actually take N^2 steps in the initial simplex? And what is done in each step of the algorithm? I know for a fact that it is different from the Matlab implementation, which only takes a single step per iteration (and sometimes a few more if it is shrinking or expanding the simplex). Or is it just a matter of when the callback function is called? \n\nBtw, I'm running this in a Jupyter notebook. But I have had it running for over 3 days with only 221 iterations completed and 20 variables to be optimized over; over 20min per iteration on avg. \n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to simulate mouse movement to procedurally generate beautiful galaxies in JS?\r\n                \r\nI'm working on a project that procedurally generates images of galaxies like this one: \n\n\n\nThis sample was \"hand drawn\" (by waving the cursor around). See this pen:\nhttps://codepen.io/OpherV/pen/JQBKVq?editors=0110\n\nI would like to procedurally generate these types of images, but rather than generate them at one go I'd like the generation be performed using a \"drawing\" process, that is, moving the drawing cursor in a pattern that achieves these visual structures. \n\n\n\nThe mouse-simulation code that I currently have is lifted directly from Louis Hoebregts' \"Simulating Mouse Movement\" article on CSS Tricks.\n\nThe principle function relies on Simplex noise:\n\n```\n    const s = 0.001 * (speed / 100);\n    const noiseX = (noise.simplex3(1, 0, a * s) + 1) / 2;\n    const noiseY = (noise.simplex3(11, 0, a * s) + 1) / 2;\n\n    random += randomness / 1000;\n    const randX = noise.simplex3(1, 0, random) * window.innerWidth * 0.1;\n    const randY = noise.simplex3(3, 0, random) * window.innerHeight * 0.1;\n    const x = noiseX * innerWidth + randX;\n    const y = noiseY * innerHeight + randY;\n\n    updateMouse(x, y);\n```\n\n\nHowever this type of noise won't create the visuals I'm aiming for. Breaking down the visual structure I have in mind, we have a center-weighted blob and elliptical \"arms\". To achieve the former, I think more \"drawing time\" should be performed near the center (which creates the bright blobs inside), with less often \"offshoots\" performing more elliptic motion to make the latter.\n\nI thought about somehow gradienting the Simplex noise so that it veers more towards the center, but I'm unsure how to go about doing that in 2d space. I'm also not certain how to proceed combining that with something that draws the \"arms\" of the galaxy.\n\nCan you suggest an algorithm to achieve this? \nThanks 🙏\n    ", "Answer": "\r\nIf you only want to generate images, you could look into generating a galaxy with some number of spiral arms using cos and sin, play around with the circle radius: \n\n```\nMath.cos(radians) * radius, Math.sin(radians) * radius```\n\n\nGet this to work first.\nYou probably want to draw something somewhat elliptical instead of a full circle.\nRandomly go more often in the center of the galaxy and close to the arms.\n\n\nStep 1: Randomly generate galaxy points\nStep 2: Blend colors (HTML5 canvas paint blending color tool)\nStep 3: if you want realtime performance use WebGL ...\n\n\nBonus: if you want to go full overkill you could even try to use realistic formulas:\nhttps://arxiv.org/pdf/0908.0892.pdf\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to get optimal cutoff values for two variables with linear programming\r\n                \r\nI am trying to use the simplex algorithm to determine the optimal values of two variables to target most appealing persons with a marketing campaign. The variables are individual treatment effects (as an output from a predictive model) and expenditures per person. Now I want to identify the optimal levels of these variables to maximize expenditures while securing that we only target the persons where the treatment has a high positive effect. I further have the constraint of targeting only 20% of people from the whole data. I believe that linear programming helps me achieve this.\n\nTo get the values for the objective function, I am simply using the mean values per variable and follow a maximization objective. I am however stuck with the constraint function as I don't know how to set it up given my requirement. Apparently, treatm_score + expenditures < [20% of observations] works conceptually, but from a programming view, I am mixing up values with quantities I think. It seems that I need at least one constraint to use linear programming to get the cutoff values (if I could get the cutoff values without the need for a constraint, I would also be happy). I am looking for making a statement such as \"As a product seller, I maximize my expected sales to z if I target people with an individual treatment effect of at least x and expenditures of at least y\".\n\nMy questions are: \n1) Can you help me determine the cutoff values? \n2) Is there maybe a better way to achieve the goal?\n\nLet's use the following code to generate the data\n\n```\ntreatm_score <- rnorm(1000, 0.1, 0.02)\nhist(treatm_score)\n\nisZero = rbinom(n=1000, size=1, prob=0.95)\nexpenditures = ifelse(isZero==1, 0, rlnorm(sum(isZero==0), meanlog=1, sdlog=2))\nhist(expenditures); table(expenditures)\nlength(expenditures[expenditures>0]) / length(expenditures) *100 # 5% of people with expenditures\n\nmean_treatm_score <- mean(treatm_score)\nmean_expenditures <- mean(expenditures)\n```\n\n\nWe see that the distributions of the variables are very different and only some persons actually spend money in the past (about 5% from the whole, which is realistic). \n\nIf I follow https://en.proft.me/2015/09/23/classical-simplex-method-and-calc-r/, I need to load the linprog package and tried the following (here is where I fail):\n\n```\ninstall.packages(\"linprog\"); library(\"linprog\")\n\nc = c(mean(treatm_score), mean(expenditures)) # objective function\nmax_quant = 0.2*length(expenditures) # constraint: only 20% of all observations\nb = c(max_quant)\nres = solveLP(c, b, maximum=TRUE) # does not work\n```\n\n\nYour help is very much appreciated!!\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "networkx network_simplex function overflow warning without floating numbers\r\n                \r\nI am trying to use the networkx ```\nnetwork_simplex()```\n function with a directed graph.\nIn the official documentation it says:\n\nThis algorithm is not guaranteed to work if edge weights or demands\nare floating point numbers (overflows and roundoff errors can cause\nproblems). As a workaround you can use integer numbers by multiplying\nthe relevant edge attributes by a convenient constant factor (eg 100).\n\nHowever, I am not using any float numbers on edge weights or demands, how can I fix this issue?\nHere is the code piece that I am trying to run:\n```\nflow_cost, flow_dict = nx.network_simplex(directed_graph)\n```\n\nAnd below you can find the directed_graph specifications. Am I wrong, while saying that my edge weights or demands are not floating numbers?\n\nPS: Here is the only question, I found relevant to this topic: python networkX network simplex\n    ", "Answer": "\r\nFor me the solution was:\nthe weights and the demand dictionary contained ```\nnumpy.int32```\n integers. I first changed them to ```\nnumpy.int64```\n integers, still got the same warning. Then finally, I changed them to native python integers, meaning ```\nint()```\n.\nIt fixed the issue.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "References or Standardization of \"Value Updating\" in Constraint Satisfaction\r\n                \r\nConstraint Satisfaction Problems (CSPs) are basically, you have a set of constraints with variables and the domains of values for the variables. Then given some configuration of the variables (assignment of variables to values in their domains), you check to see if the constraints are \"satisfied\". That is, you check to see that evaluating all of the constraints returns a Boolean \"true\".\n\nWhat I would like to do is sort of the reverse. Instead of this Boolean \"testing\" if the constraints are true, I would like to instead take the constraints and enforce them on the variables. That is, set the variables to whatever values they need to be in order to satisfy the constraints. An example of this would be like in a game, you say \"this box's right side is always to the left of its containing box's right side,\" or, box.right < container.right. Then the constraint solving engine (like Cassowary for the game example) would take the box and set its \"right\" property to whatever number value it resolved to. So instead of the constraint solver giving you a Boolean value \"yes the variable configuration satisfies the constraints\", it instead updates the variables' configuration with appropriate values, \"you have updated the variables\". I think Cassowary uses the Simplex Algorithm for solving its constraints.\n\nI am a bit confused because Wikipedia says:\n\n\n  constraint satisfaction is the process of finding a solution to a set of constraints that impose conditions that the variables must satisfy. A solution is therefore a set of values for the variables that satisfies all constraints—that is, a point in the feasible region.\n\n\nThat seems different than the constraint satisfaction problem, of which it says:\n\n\n  An evaluation is consistent if it does not violate any of the constraints.\n\n\nThat's why it seems CSPs are to return Boolean values, while in CS you can set the values. Not quite clear the distinction.\n\nAnyways, I am looking for general techniques on Constraint Solving, in the sense of setting variables like in the simplex algorithm. However, I would like to apply it to any situation, not just linear programming. Some standard and simple example constraints are:\n\n\nAll variables are different.\nbox.right < container.right\nThe sum of all variables < 10\nVariable a goes before variable b in evaluation.\netc.\n\n\nFor the first case, seeing if the constraints are satisfied (Boolean true) is pretty easy: iterate through the pairs of variables, and if any pair is not equal to each other, return false, otherwise return true after processing all variables.\n\nHowever, doing the equivalent of setting the variables doesn't seem possible at first glance: iterate through the pairs of variables, and if they are not equal, perhaps you set the first one to the second one. You might have to do some fixed point thing, processing some of them more than once. And then figuring out what value to set them to seems arbitrary how I just did it. Maybe instead you need some further (nested) constraints defining how set the values (e.g. \"set a to b if a > b, otherwise set b to a\"). The possibilities are customizable.\n\nIn addition, for simpler cases like box.right < container.right, it is even complicated. You could say at first that if box.right >= container.right then set box.right = container.right. But maybe actually you don't want that, but instead you want some iPhone-like physics \"bounce\" where it overextends and then bounces back with momentum. So again, the possibilities are large, and you should probably have additional constraints.\n\n\n  So my question is, similar to how for testing the constraints (for Boolean value) is standardized to CSP, I am wondering if there are any references or standardizations in terms of setting the values used by the constraints.\n\n\nThe only thing I have seen so far is that Cassowary simplex algorithm example which works well for an array of linear inequalities on real-numbered variables. I would like to see something that can handle the \"All variables are different\" case, and the other cases listed, as well as the standard CSP example problems like for scheduling, box packing, etc. I am not sure why I haven't encountered more on setting/updating constraint variables instead of the Boolean \"yes constraints are satisfied\" problem.\n\nThe only limits I have are that the constraints work on finite domains.\n\nIf it turns out there is no standardization at all and that every different constraint listed requires its own entire field of research, that would be good to know. Then I at least know what the situation is and why I haven't really seen much about it.\n    ", "Answer": "\r\nCSP is a research fields with many publications each year. I suggest you to read one of the books on the subject, like Rina Dechter's.\n\nFor standardized CSP languages, check MiniZinc on one hand, and XCSP3 on the other.\n\nThere are two main approaches to CSP solving: systematic and stochastic (also known as local search). I have worked on three different CSP solvers, one of them stochastic, but I understand systematic solvers better. \n\nThere are many different approaches to systematic solvers. It is possible to fill a whole book covering all the possible approaches, so I will explain only the two approaches I believe the most in:\n\n\n(G)AC3 which propagates constraints, until all global constraints (hyper-arcs) are consistent. \nReducing the problem to SAT, and letting the SAT solver do the hard work. There is a great algorithm that creates the CNF lazily, on demand when the solver is already working. In a sence, this is a hybrid SAT/CSP algorithm.\n\n\nTo get the AC3 approach going you need to maintain a domain for each variable. A domain is basically a set of possible assignments.\n\nFor example, consider the domains of ```\na```\n and ```\nb```\n: D(a)={1,2}, D(b)={0,1} and the constraint ```\na <= b```\n. The algorithm checks one constraint at a time, and when it reaches ```\na <= b```\n, it sees that a=2 is impossible, and also b=0 is impossible, so it removes them from the domains. The new domains are D'(a)={1}, D'(b)={1}.\n\nThis process is called domain propagation. Using a queue of \"dirty\" constraints, or \"dirty\" variables, the solver knows which constraint to propagate next. When the queue is empty, then all constraints (hyper arcs) are consistent (this is where the name AC3 comes from).\n\nWhen all arcs are consistent, then the solver picks a free variable (with more than one value in the domain), and restricts it to a single value. In SAT, this is called a decision It adds it to the queue and  propagates the constraints. If it gets to a conflict (a constraint can't be satisfied), it goes back and undos an earlier decision.\n\nThere are a lot of things going on here:\n\nFirst, how the domains are represented. Some solvers only hold a pair of bounds for each domain. Others, have a set of integers. My solver holds an interval set, or a bit vector.\n\nThen, how the solver knows to propagate a constraint? Some solvers such as SAT solvers, Minion, and HaifaCSP, use watches to avoid propagating irrelevant constraints. This has a significant performance impact on clauses.\n\nThen there is the issue of making decisions. Usually, it is good to choose a variable that has a small domain and high connectivity. There are many papers comparing many different strategies. I prefer a dynamic strategy that resembles the VSIDS of  SAT solvers. This strategy is auto-tuned according to conflicts. \n\nMaking decision on the value is also important. Many simply take the smallest value in the domain. Sometimes this can be suboptimal if there is a constraint that limits a sum from below. Another option is to randomly choose between max and min values. I tune it further, and use the last assigned value.\n\nAfter everything, there is the matter of backtracking. This is a whole can of worms. The problem with simple backtracking is that sometimes the cause for conflicts happened at the first decision, but it is detected only at the 100'th. The best thing is to analyze the conflict, and realize where the cause of the conflict is. SAT solvers have been doing this for decades. But CSP representation is not as trivial as CNF. So not many solvers could do it efficiently enough.\n\nThis is a nontrivial subject that can fill at least two university courses. Just the subject of conflict analysis can take half of a course.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Triangulate a set of points with a concave domain\r\n                \r\nSetup\n\nGiven some set of nodes within a convex hull, assume the domain contains one or more concave areas:\n\n\n\nwhere blue dots are points, and the black line illustrates the domain. Assume the points are held as a 2D array ```\npoints```\n of length ```\nn```\n, where ```\nn```\n is the number of point-pairs.\n\nLet us then triangulate the points, using something like the Delaunay method from scipy.spatial:\n\n\n\nAs you can see, one may experience the creation of triangles crossing through the domain.\n\nQuestion\n\nWhat is a good algorithmic approach to removing any triangles that span outside of the domain? Ideally but not necessarily, where the simplex edges still preserve the domain shape (i.e., no major gaps where triangles are removed).\n\n\n\nSince my question is seeming to continue to get a decent amount of activity, I wanted to follow up with the application that I'm currently using.\n\nAssuming that you have your boundary defined, you can use a ray casting algorithm to determine whether or not the polygon is inside the domain.\n\nTo do this:\n\n\nTake the centroid of each polygon as ```\nC_i = (x_i,y_i)```\n.\nThen, imagine a line ```\nL = [C_i,(+inf,y_i)]```\n: that is, a line that spans east past the end of your domain.\nFor each boundary segment ```\ns_i```\n in boundary ```\nS```\n, check for intersections with ```\nL```\n. If yes, add +1 to an internal counter ```\nintersection_count```\n; else, add nothing. \nAfter the count of all intersections between ```\nL```\n and ```\ns_i for i=1..N```\n are calculated:\n\n```\nif intersection_count % 2 == 0:\n    return True # triangle outside convex hull\nelse:\n    return False # triangle inside convex hull\n```\n\n\n\nIf your boundary is not explicitly defined, I find it helpful to 'map' the shape onto an boolean array and use a neighbor tracing algorithm to define it. Note that this approach assumes a solid domain and you will need to use a more complex algorithm for domains with 'holes' in them.\n    ", "Answer": "\r\nHere is some Python code that does what you want.\n\nFirst, building the alpha shape (see my previous answer):\n\n```\ndef alpha_shape(points, alpha, only_outer=True):\n    \"\"\"\n    Compute the alpha shape (concave hull) of a set of points.\n    :param points: np.array of shape (n,2) points.\n    :param alpha: alpha value.\n    :param only_outer: boolean value to specify if we keep only the outer border or also inner edges.\n    :return: set of (i,j) pairs representing edges of the alpha-shape. (i,j) are the indices in the points array.\n    \"\"\"\n    assert points.shape[0] > 3, \"Need at least four points\"\n\n    def add_edge(edges, i, j):\n        \"\"\"\n        Add a line between the i-th and j-th points,\n        if not in the list already\n        \"\"\"\n        if (i, j) in edges or (j, i) in edges:\n            # already added\n            assert (j, i) in edges, \"Can't go twice over same directed edge right?\"\n            if only_outer:\n                # if both neighboring triangles are in shape, it's not a boundary edge\n                edges.remove((j, i))\n            return\n        edges.add((i, j))\n\n    tri = Delaunay(points)\n    edges = set()\n    # Loop over triangles:\n    # ia, ib, ic = indices of corner points of the triangle\n    for ia, ib, ic in tri.vertices:\n        pa = points[ia]\n        pb = points[ib]\n        pc = points[ic]\n        # Computing radius of triangle circumcircle\n        # www.mathalino.com/reviewer/derivation-of-formulas/derivation-of-formula-for-radius-of-circumcircle\n        a = np.sqrt((pa[0] - pb[0]) ** 2 + (pa[1] - pb[1]) ** 2)\n        b = np.sqrt((pb[0] - pc[0]) ** 2 + (pb[1] - pc[1]) ** 2)\n        c = np.sqrt((pc[0] - pa[0]) ** 2 + (pc[1] - pa[1]) ** 2)\n        s = (a + b + c) / 2.0\n        area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n        circum_r = a * b * c / (4.0 * area)\n        if circum_r < alpha:\n            add_edge(edges, ia, ib)\n            add_edge(edges, ib, ic)\n            add_edge(edges, ic, ia)\n    return edges\n```\n\n\nTo compute the edges of the outer boundary of the alpha shape use the following example call:\n\n```\nedges = alpha_shape(points, alpha=alpha_value, only_outer=True)\n```\n\n\nNow, after the ```\nedges```\n of the outer boundary of the alpha-shape of ```\npoints```\n have been computed, the following function will determine whether a point ```\n(x,y)```\n is inside the outer boundary.\n\n```\ndef is_inside(x, y, points, edges, eps=1.0e-10):\n    intersection_counter = 0\n    for i, j in edges:\n        assert abs((points[i,1]-y)*(points[j,1]-y)) > eps, 'Need to handle these end cases separately'\n        y_in_edge_domain = ((points[i,1]-y)*(points[j,1]-y) < 0)\n        if y_in_edge_domain:\n            upper_ind, lower_ind = (i,j) if (points[i,1]-y) > 0 else (j,i)\n            upper_x = points[upper_ind, 0] \n            upper_y = points[upper_ind, 1]\n            lower_x = points[lower_ind, 0] \n            lower_y = points[lower_ind, 1]\n\n            # is_left_turn predicate is evaluated with: sign(cross_product(upper-lower, p-lower))\n            cross_prod = (upper_x - lower_x)*(y-lower_y) - (upper_y - lower_y)*(x-lower_x)\n            assert abs(cross_prod) > eps, 'Need to handle these end cases separately'\n            point_is_left_of_segment = (cross_prod > 0.0)\n            if point_is_left_of_segment:\n                intersection_counter = intersection_counter + 1\n    return (intersection_counter % 2) != 0\n```\n\n\n\n\nOn the input shown in the above figure (taken from my previous answer) the call ```\nis_inside(1.5, 0.0, points, edges)```\n will return ```\nTrue```\n, whereas ```\nis_inside(1.5, 3.0, points, edges)```\n will return ```\nFalse```\n.\n\nNote that the ```\nis_inside```\n function above does not handle degenerate cases. I added two assertions to detect such cases (you can define any epsilon value that fits your application). In many applications this is sufficient, but if not and you encounter these end cases, they need to be handled separately.\nSee, for example, here on robustness and precision issues when implementing geometric algorithms.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Identifying lakes in a bit mask in JavaScript\r\n                \r\nI have an algorithm that generates \"continents\" using simplex noise, so it'll generate a height map, and when a pixel/tile is above a certain level it'll be recognised as land, otherwise it's water. \n\nThe problem I have is sometimes land will surround a section that is below sea level. I would like to be able to identify those areas because they won't be sea, but rather land or a lake.\n\nSo the in following the 0's represent water and 1's represent land:\n\n```\n000000000\n001110100\n011111110\n011001110\n001101100\n001111000\n000000000\n```\n\n\nThe 3 0's in the middle would be identified as non-sea.\n\nI am familiar with the flood fill algorithm. So one way I could do it is to iterate through random points, use a flood fill if I find water, if it's over a certain size then it'll be the sea. Then once the sea has been recognised I can go through and identify non-sea bodies for water. \n\nThis seems inefficient as I will have to work with a larger area than what is loaded otherwise it'll falsely recognise areas as non-sea. \n\nIs there a better way?\n    ", "Answer": "\r\nYou mentioned you are already familiar with flood fill. Why not flood fill from the edge of the map to get the sea? Any body of water that doesn't floodfill from the edge would then be a lake.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Many to Many \"Generalized Assignment Ρroblem\"\r\n                \r\nI am having problems with a specific problem. I have to schedule 5 employees to work over 14 days. each employee can only work 9 out of 14 days and each day there must be 3 employees scheduled. The key part is that each employee has a given penalty for working on a certain day. So if they cannot work on that day its a penalty of 10 if they can work that and don't mind its a penalty of zero and lastly if they can but don't want to its a penalty of 5.\n\nI have a matrix of the penalty values for each employee for each day. I am trying find a way to write my contraints out.\n\nI had a thought of having Matrix A(penalty Matrix) and matrix B(schedule matrix) and matrix C where C(i,j) = A(i,j)*B(i,j). given this setup if A(i,j) is equal to 0 (the employee does not work) then the penalty will not be taken into account and vica versa.\n\nSo then I could say as my constraints:\n\nA(1,1) + A(1,m) + A(1,n) <= 9\n\nand\n\nA(1,1) + A(m,1) + A(n,1) = 3\n\nand I am Minimizing: C(1,1) + C(m,m) + C(n,n)\n\nMy problem in looking at it like this is trying to use this in an optimization algorithm. The simplex algorithm is supposed to be able to solve any LP problem but it can be the slowest. I am stuck and I am sure now that I am looking at this the wrong way. If anyone can give me a fresh set of eyes and possibly an explanation as to why I am looking at this the wrong way I would appreciate it.\n    ", "Answer": "\r\nI think you made a modelling mistake that makes your problem more difficult than it needs to be.\n\nWhy are you modelling \"able and willing,\" \"able but unwilling,\" and \"unable\" using a penalty function?  Don't you just want to minimise the number of times an employee is assigned a timeslot that the employee is able but unwilling to work?  (Without, of course, assigning any employees slots that they're unable to work?)\n\nIf you modify the problem like I proposed above, this can be modelled as a straight minimum-cost flow problem.  You have one set of nodes for the employees and one set of nodes for the time slots.  Connect an employee to a time slot with an edge of capacity 1 if the employee is able to work that time slot.  Give it a cost of 0 if the employee is willing to work then and a cost of 1 if the employee is unwilling to work then.  Add a source and a sink; the source should have an edge to each employee with capacity 9 (the number of days they can work) and zero cost, while each time slot should have an edge to the sink with capacity 3 and zero cost.\n\nIt's relatively straightforward to code up a min-cost flow solver from scratch.\n\nIf you want to forbid timeslots from being staffed by two or more unwilling employees, I think you're stuck modelling the problem as an integer program.  GLPK is a free linear and integer program solver.  It's not quite state-of-the-art, but it does work quite nicely on lots of problems.  I doubt it'll have trouble solving small-scale instances like yours.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Find exact solutions to Linear Program\r\n                \r\nI need to find an exact real solution to a linear program (where all inputs are integers). It is important that the solver also outputs the solutions as rational numbers, ideally without doing any intermediate steps with floating point numbers.\n\nGLPK can do exact arithmetic, but cannot display the solutions as rational numbers (i.e. I get 0.3333 for 1/3). I could probably attempt to guess which number is meant by that, but that seems very fragile.\n\nI was unable to find an LP solver that can do this kind of thing. Is there one? Performance is not a huge issue; my problems are very small. (I did look into using an SMT solver like Z3; they can solve these kinds of problems and provide exact rational solutions, but they resort to quantifier elimination instead of using a more apt algorithm for Linear Programs like Simplex)\n    ", "Answer": "\r\nSoPlex can use rational arithmetic to solve LPs exactly. Use it like this:\n\n```\nsoplex -X -Y -o0 -f0 problem.lp\n```\n\n\nOptions ```\nX```\n and ```\nY```\n will print the primal and dual solution in rational numbers, while ```\no0```\n and ```\nf0```\n set the optimality and feasibility tolerance to 0, hence solving the LP exactly.\n\nYou need GMP installed (or MPIR on Windows) to use the rational functionalities. One advantage over QSopt_exact is that SoPlex uses a hybrid technique combining the speed of double precision computation with the exact precision of rational arithmetic (iterative refinement).\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to find the optimal sum\r\n                \r\nImagine this set of values:\n\n```\n      A B C\nLINE1 2 1 1\nLINE2 1 4 1\nLINE3 3 1 3\nLINE4 6 5 4\n```\n\n\nI can choose one value per line from 1 to 3. If I choose a value from a specific column, I need to sum the value from line 4.\n\nExample:\n\n```\n2 (LINE1, COLUMN A)\n1 (LINE2, COLUMN A)\n3 (LINE3, COLUMN C)\n```\n\n\nSo, as I chose values from COLUMN A, I need to sum both of them with the value of LINE 4. Final result:\n\n```\n      A B C\nLINE1 2 - -\nLINE2 1 - -\nLINE3 - - 3\nLINE4 6 - 4 \n\n2 + 1 + 6 = 9\n3 + 4 = 7\nTOTAL: 16\n```\n\n\nThe fact is: I need to retrieve the smaller possible total from the combination. I chose the numbers in the example randomly, but my algorithm need to choose numbers that give me the smaller total.\n\nI think the optimal solution is to pick all numbers from COLUMN C (TOTAL: 9), but will be situations that I need to pick numbers from different columns.\n\nI think it is a optimization problem and I thought to use simplex but I don't know how to start the development.\n\nThank you!\n    ", "Answer": "\r\nThis is the solution I came up with using GLPK in GNU MathProg modeling language. Note: This is literally the first thing I ever wrote in MathProg, so feedback is very welcome.\n\nSpecifically I'm not sure if the way I linked x[] and s[] is efficient (I'm more used to SAT CNF encodings than to ILP).\n\nSave the code as ```\ntest.mod```\n and execute with ```\nglpsol --math test.mod```\n.\n\n```\nset A, dimen 3;\nset B, dimen 2;\n\nset I := setof{(i,j,v) in A} i;\nset J := setof{(i,j,v) in A} j;\n\nvar x{I, J}, binary;\nvar s{J}, binary;\n\ns.t. lines {i in I}:\n  sum{j in J} x[i, j] = 1;\n\ns.t. rows {j in J, i in I}:\n  x[i, j] <= s[j];\n\nminimize obj:\n  (sum{(i,j,v) in A} x[i, j]*v) + (sum{(j,v) in B} s[j]*v);\n\nsolve;\n\nprintf \"Result:\\n\";\nprintf {(i,j,v) in A : x[i, j] == 1} \" %3d %3d %5d\\n\", i, j, v;\nprintf {(j,v) in B : s[j] == 1} \" --- %3d %5d\\n\", j, v;\nprintf \" --- --- %5d\\n\", (sum{(i,j,v) in A} x[i, j]*v) + (sum{(j,v) in B} s[j]*v);\nprintf \"\\n\";\n\ndata;\n\nset A :=\n# Line 1\n  1 1 2\n  1 2 1\n  1 3 1\n# Line 2\n  2 1 1\n  2 2 4\n  2 3 1\n# Line 3\n  3 1 3\n  3 2 1\n  3 3 3;\n\nset B :=\n# Line 4\n  1 6\n  2 5\n  3 4;\n\nend;\n```\n\n\nThanks to Robert for suggesting GLPK and providing an outline for the solution in his answer.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Is there an efficient way to generate N random integers in a range that have a given sum or average?\r\n                \r\nIs there an efficient way to generate a random combination of N integers such that—\n\n\neach integer is in the interval [```\nmin```\n, ```\nmax```\n],\nthe integers have a sum of ```\nsum```\n,\nthe integers can appear in any order (e.g., random order), and\nthe combination is chosen uniformly at random from among all combinations that meet the other requirements?\n\n\nIs there a similar algorithm for random combinations in which the integers must appear in sorted order by their values (rather than in any order)?\n\n(Choosing an appropriate combination with a mean of ```\nmean```\n is a special case, if ```\nsum = N * mean```\n.  This problem is equivalent to generating a uniform random partition of ```\nsum```\n into N parts that are each in the interval [```\nmin```\n, ```\nmax```\n] and appear in any order or in sorted order by their values, as the case may be.)\n\nI am aware that this problem can be solved in the following way for combinations that appear in random order (EDIT [Apr. 27]: Algorithm modified.):\n\n\nIf ```\nN * max < sum```\n or ```\nN * min > sum```\n, there is no solution.\nIf ```\nN * max == sum```\n, there is only one solution, in which all ```\nN```\n numbers are equal to ```\nmax```\n.  If ```\nN * min == sum```\n, there is only one solution, in which all ```\nN```\n numbers are equal to ```\nmin```\n.\nUse the algorithm given in Smith and Tromble (\"Sampling from the Unit Simplex\", 2004) to generate N random non-negative integers with the sum ```\nsum - N * min```\n.\nAdd ```\nmin```\n to each number generated this way.\nIf any number is greater than ```\nmax```\n, go to step 3.\n\n\nHowever, this algorithm is slow if ```\nmax```\n is much less than ```\nsum```\n. For example, according to my tests (with an implementation of the special case above involving ```\nmean```\n), the algorithm rejects, on average—\n\n\nabout 1.6 samples if ```\nN = 7, min = 3, max = 10, sum = 42```\n, but\nabout 30.6 samples if ```\nN = 20, min = 3, max = 10, sum = 120```\n.\n\n\nIs there a way to modify this algorithm to be efficient for large N while still meeting the requirements above?\n\nEDIT:\n\nAs an alternative suggested in the comments, an efficient way of producing a valid random combination (that satisfies all but the last requirement) is:\n\n\nCalculate ```\nX```\n, the number of valid combinations possible given ```\nsum```\n, ```\nmin```\n, and ```\nmax```\n.\nChoose ```\nY```\n, a uniform random integer in ```\n[0, X)```\n.\nConvert (\"unrank\") ```\nY```\n to a valid combination.\n\n\nHowever, is there a formula for calculating the number of valid combinations (or permutations), and is there a way to convert an integer to a valid combination?  [EDIT (Apr. 28): Same for permutations rather than combinations].\n\nEDIT (Apr. 27):\n\nAfter reading Devroye's Non-Uniform Random Variate Generation (1986), I can confirm that this is a problem of generating a random partition.  Also, Exercise 2 (especially part E) on page 661 is relevant to this question.\n\nEDIT (Apr. 28):\n\nAs it turned out the algorithm I gave is uniform where the integers involved are given in random order, as opposed to sorted order by their values.  Since both problems are of general interest, I have modified this question to seek a canonical answer for both problems.\n\nThe following Ruby code can be used to verify potential solutions for uniformity (where ```\nalgorithm(...)```\n is the candidate algorithm):\n\n```\ncombos={}\npermus={}\nmn=0\nmx=6\nsum=12\nfor x in mn..mx\n  for y in mn..mx\n    for z in mn..mx\n      if x+y+z==sum\n        permus[[x,y,z]]=0\n      end\n      if x+y+z==sum and x<=y and y<=z\n        combos[[x,y,z]]=0\n      end\n    end\n  end\nend\n\n3000.times {|x|\n f=algorithm(3,sum,mn,mx)\n combos[f.sort]+=1\n permus[f]+=1\n}\np combos\np permus\n```\n\n\nEDIT (Apr. 29): Re-added Ruby code of current implementation.\n\nThe following code example is given in Ruby, but my question is independent of programming language:\n\n```\ndef posintwithsum(n, total)\n    raise if n <= 0 or total <=0\n    ls = [0]\n    ret = []\n    while ls.length < n\n      c = 1+rand(total-1)\n      found = false\n      for j in 1...ls.length\n        if ls[j] == c\n          found = true\n          break\n        end\n      end\n      if found == false;ls.push(c);end\n    end\n    ls.sort!\n    ls.push(total)\n    for i in 1...ls.length\n       ret.push(ls[i] - ls[i - 1])\n    end\n    return ret\nend\n\ndef integersWithSum(n, total)\n raise if n <= 0 or total <=0\n ret = posintwithsum(n, total + n)\n for i in 0...ret.length\n    ret[i] = ret[i] - 1\n end\n return ret\nend\n\n# Generate 100 valid samples\nmn=3\nmx=10\nsum=42\nn=7\n100.times {\n while true\n    pp=integersWithSum(n,sum-n*mn).map{|x| x+mn }\n    if !pp.find{|x| x>mx }\n      p pp; break # Output the sample and break\n    end\n end\n}\n\n```\n\n    ", "Answer": "\r\nHere's my solution in Java. It is fully functional and contains two generators: ```\nPermutationPartitionGenerator```\n for unsorted partitions and ```\nCombinationPartitionGenerator```\n for sorted partitions. Your generator also implemented in the class ```\nSmithTromblePartitionGenerator```\n for comparison. The class ```\nSequentialEnumerator```\n enumerates all possible partitions (unsorted or sorted, depending on the parameter) in sequential order. I have added thorough tests (including your test cases) for all of these generators.\nThe implementation is self-explainable for the most part. If you have any questions, I will answer them in couple of days.\n\n\n\n```\nimport java.util.Random;\nimport java.util.function.Supplier;\n\npublic abstract class PartitionGenerator implements Supplier<int[]>{\n    public static final Random rand = new Random();\n    protected final int numberCount;\n    protected final int min;\n    protected final int range;\n    protected final int sum; // shifted sum\n    protected final boolean sorted;\n\n    protected PartitionGenerator(int numberCount, int min, int max, int sum, boolean sorted) {\n        if (numberCount <= 0)\n            throw new IllegalArgumentException(\"Number count should be positive\");\n        this.numberCount = numberCount;\n        this.min = min;\n        range = max - min;\n        if (range < 0)\n            throw new IllegalArgumentException(\"min > max\");\n        sum -= numberCount * min;\n        if (sum < 0)\n            throw new IllegalArgumentException(\"Sum is too small\");\n        if (numberCount * range < sum)\n            throw new IllegalArgumentException(\"Sum is too large\");\n        this.sum = sum;\n        this.sorted = sorted;\n    }\n\n    // Whether this generator returns sorted arrays (i.e. combinations)\n    public final boolean isSorted() {\n        return sorted;\n    }\n\n    public interface GeneratorFactory {\n        PartitionGenerator create(int numberCount, int min, int max, int sum);\n    }\n}\n\nimport java.math.BigInteger;\n\n// Permutations with repetition (i.e. unsorted vectors) with given sum\npublic class PermutationPartitionGenerator extends PartitionGenerator {\n    private final double[][] distributionTable;\n\n    public PermutationPartitionGenerator(int numberCount, int min, int max, int sum) {\n        super(numberCount, min, max, sum, false);\n        distributionTable = calculateSolutionCountTable();\n    }\n\n    private double[][] calculateSolutionCountTable() {\n        double[][] table = new double[numberCount + 1][sum + 1];\n        BigInteger[] a = new BigInteger[sum + 1];\n        BigInteger[] b = new BigInteger[sum + 1];\n        for (int i = 1; i <= sum; i++)\n            a[i] = BigInteger.ZERO;\n        a[0] = BigInteger.ONE;\n        table[0][0] = 1.0;\n        for (int n = 1; n <= numberCount; n++) {\n            double[] t = table[n];\n            for (int s = 0; s <= sum; s++) {\n                BigInteger z = BigInteger.ZERO;\n                for (int i = Math.max(0, s - range); i <= s; i++)\n                    z = z.add(a[i]);\n                b[s] = z;\n                t[s] = z.doubleValue();\n            }\n            // swap a and b\n            BigInteger[] c = b;\n            b = a;\n            a = c;\n        }\n        return table;\n    }\n\n    @Override\n    public int[] get() {\n        int[] p = new int[numberCount];\n        int s = sum; // current sum\n        for (int i = numberCount - 1; i >= 0; i--) {\n            double t = rand.nextDouble() * distributionTable[i + 1][s];\n            double[] tableRow = distributionTable[i];\n            int oldSum = s;\n            // lowerBound is introduced only for safety, it shouldn't be crossed \n            int lowerBound = s - range;\n            if (lowerBound < 0)\n                lowerBound = 0;\n            s++;\n            do\n                t -= tableRow[--s];\n            // s can be equal to lowerBound here with t > 0 only due to imprecise subtraction\n            while (t > 0 && s > lowerBound);\n            p[i] = min + (oldSum - s);\n        }\n        assert s == 0;\n        return p;\n    }\n\n    public static final GeneratorFactory factory = (numberCount, min, max,sum) ->\n        new PermutationPartitionGenerator(numberCount, min, max, sum);\n}\n\nimport java.math.BigInteger;\n\n// Combinations with repetition (i.e. sorted vectors) with given sum \npublic class CombinationPartitionGenerator extends PartitionGenerator {\n    private final double[][][] distributionTable;\n\n    public CombinationPartitionGenerator(int numberCount, int min, int max, int sum) {\n        super(numberCount, min, max, sum, true);\n        distributionTable = calculateSolutionCountTable();\n    }\n\n    private double[][][] calculateSolutionCountTable() {\n        double[][][] table = new double[numberCount + 1][range + 1][sum + 1];\n        BigInteger[][] a = new BigInteger[range + 1][sum + 1];\n        BigInteger[][] b = new BigInteger[range + 1][sum + 1];\n        double[][] t = table[0];\n        for (int m = 0; m <= range; m++) {\n            a[m][0] = BigInteger.ONE;\n            t[m][0] = 1.0;\n            for (int s = 1; s <= sum; s++) {\n                a[m][s] = BigInteger.ZERO;\n                t[m][s] = 0.0;\n            }\n        }\n        for (int n = 1; n <= numberCount; n++) {\n            t = table[n];\n            for (int m = 0; m <= range; m++)\n                for (int s = 0; s <= sum; s++) {\n                    BigInteger z;\n                    if (m == 0)\n                        z = a[0][s];\n                    else {\n                        z = b[m - 1][s];\n                        if (m <= s)\n                            z = z.add(a[m][s - m]);\n                    }\n                    b[m][s] = z;\n                    t[m][s] = z.doubleValue();\n                }\n            // swap a and b\n            BigInteger[][] c = b;\n            b = a;\n            a = c;\n        }\n        return table;\n    }\n\n    @Override\n    public int[] get() {\n        int[] p = new int[numberCount];\n        int m = range; // current max\n        int s = sum; // current sum\n        for (int i = numberCount - 1; i >= 0; i--) {\n            double t = rand.nextDouble() * distributionTable[i + 1][m][s];\n            double[][] tableCut = distributionTable[i];\n            if (s < m)\n                m = s;\n            s -= m;\n            while (true) {\n                t -= tableCut[m][s];\n                // m can be 0 here with t > 0 only due to imprecise subtraction\n                if (t <= 0 || m == 0)\n                    break;\n                m--;\n                s++;\n            }\n            p[i] = min + m;\n        }\n        assert s == 0;\n        return p;\n    }\n\n    public static final GeneratorFactory factory = (numberCount, min, max, sum) ->\n        new CombinationPartitionGenerator(numberCount, min, max, sum);\n}\n\nimport java.util.*;\n\npublic class SmithTromblePartitionGenerator extends PartitionGenerator {\n    public SmithTromblePartitionGenerator(int numberCount, int min, int max, int sum) {\n        super(numberCount, min, max, sum, false);\n    }\n\n    @Override\n    public int[] get() {\n        List<Integer> ls = new ArrayList<>(numberCount + 1);\n        int[] ret = new int[numberCount];\n        int increasedSum = sum + numberCount;\n        while (true) {\n            ls.add(0);\n            while (ls.size() < numberCount) {\n                int c = 1 + rand.nextInt(increasedSum - 1);\n                if (!ls.contains(c))\n                    ls.add(c);\n            }\n            Collections.sort(ls);\n            ls.add(increasedSum);\n            boolean good = true;\n            for (int i = 0; i < numberCount; i++) {\n                int x = ls.get(i + 1) - ls.get(i) - 1;\n                if (x > range) {\n                    good = false;\n                    break;\n                }\n                ret[i] = x;\n            }\n            if (good) {\n                for (int i = 0; i < numberCount; i++)\n                    ret[i] += min;\n                return ret;\n            }\n            ls.clear();\n        }\n    }\n\n    public static final GeneratorFactory factory = (numberCount, min, max, sum) ->\n        new SmithTromblePartitionGenerator(numberCount, min, max, sum);\n}\n\nimport java.util.Arrays;\n\n// Enumerates all partitions with given parameters\npublic class SequentialEnumerator extends PartitionGenerator {\n    private final int max;\n    private final int[] p;\n    private boolean finished;\n\n    public SequentialEnumerator(int numberCount, int min, int max, int sum, boolean sorted) {\n        super(numberCount, min, max, sum, sorted);\n        this.max = max;\n        p = new int[numberCount];\n        startOver();\n    }\n\n    private void startOver() {\n        finished = false;\n        int unshiftedSum = sum + numberCount * min;\n        fillMinimal(0, Math.max(min, unshiftedSum - (numberCount - 1) * max), unshiftedSum);\n    }\n\n    private void fillMinimal(int beginIndex, int minValue, int fillSum) {\n        int fillRange = max - minValue;\n        if (fillRange == 0)\n            Arrays.fill(p, beginIndex, numberCount, max);\n        else {\n            int fillCount = numberCount - beginIndex;\n            fillSum -= fillCount * minValue;\n            int maxCount = fillSum / fillRange;\n            int maxStartIndex = numberCount - maxCount;\n            Arrays.fill(p, maxStartIndex, numberCount, max);\n            fillSum -= maxCount * fillRange;\n            Arrays.fill(p, beginIndex, maxStartIndex, minValue);\n            if (fillSum != 0)\n                p[maxStartIndex - 1] = minValue + fillSum;\n        }\n    }\n\n    @Override\n    public int[] get() { // returns null when there is no more partition, then starts over\n        if (finished) {\n            startOver();\n            return null;\n        }\n        int[] pCopy = p.clone();\n        if (numberCount > 1) {\n            int i = numberCount;\n            int s = p[--i];\n            while (i > 0) {\n                int x = p[--i];\n                if (x == max) {\n                    s += x;\n                    continue;\n                }\n                x++;\n                s--;\n                int minRest = sorted ? x : min;\n                if (s < minRest * (numberCount - i - 1)) {\n                    s += x;\n                    continue;\n                }\n                p[i++]++;\n                fillMinimal(i, minRest, s);\n                return pCopy;\n            }\n        }\n        finished = true;\n        return pCopy;\n    }\n\n    public static final GeneratorFactory permutationFactory = (numberCount, min, max, sum) ->\n        new SequentialEnumerator(numberCount, min, max, sum, false);\n    public static final GeneratorFactory combinationFactory = (numberCount, min, max, sum) ->\n        new SequentialEnumerator(numberCount, min, max, sum, true);\n}\n\nimport java.util.*;\nimport java.util.function.BiConsumer;\nimport PartitionGenerator.GeneratorFactory;\n\npublic class Test {\n    private final int numberCount;\n    private final int min;\n    private final int max;\n    private final int sum;\n    private final int repeatCount;\n    private final BiConsumer<PartitionGenerator, Test> procedure;\n\n    public Test(int numberCount, int min, int max, int sum, int repeatCount,\n            BiConsumer<PartitionGenerator, Test> procedure) {\n        this.numberCount = numberCount;\n        this.min = min;\n        this.max = max;\n        this.sum = sum;\n        this.repeatCount = repeatCount;\n        this.procedure = procedure;\n    }\n\n    @Override\n    public String toString() {\n        return String.format(\"=== %d numbers from [%d, %d] with sum %d, %d iterations ===\",\n                numberCount, min, max, sum, repeatCount);\n    }\n\n    private static class GeneratedVector {\n        final int[] v;\n\n        GeneratedVector(int[] vect) {\n            v = vect;\n        }\n\n        @Override\n        public int hashCode() {\n            return Arrays.hashCode(v);\n        }\n\n        @Override\n        public boolean equals(Object obj) {\n            if (this == obj)\n                return true;\n            return Arrays.equals(v, ((GeneratedVector)obj).v);\n        }\n\n        @Override\n        public String toString() {\n            return Arrays.toString(v);\n        }\n    }\n\n    private static final Comparator<Map.Entry<GeneratedVector, Integer>> lexicographical = (e1, e2) -> {\n        int[] v1 = e1.getKey().v;\n        int[] v2 = e2.getKey().v;\n        int len = v1.length;\n        int d = len - v2.length;\n        if (d != 0)\n            return d;\n        for (int i = 0; i < len; i++) {\n            d = v1[i] - v2[i];\n            if (d != 0)\n                return d;\n        }\n        return 0;\n    };\n\n    private static final Comparator<Map.Entry<GeneratedVector, Integer>> byCount =\n            Comparator.<Map.Entry<GeneratedVector, Integer>>comparingInt(Map.Entry::getValue)\n            .thenComparing(lexicographical);\n\n    public static int SHOW_MISSING_LIMIT = 10;\n\n    private static void checkMissingPartitions(Map<GeneratedVector, Integer> map, PartitionGenerator reference) {\n        int missingCount = 0;\n        while (true) {\n            int[] v = reference.get();\n            if (v == null)\n                break;\n            GeneratedVector gv = new GeneratedVector(v);\n            if (!map.containsKey(gv)) {\n                if (missingCount == 0)\n                    System.out.println(\" Missing:\");\n                if (++missingCount > SHOW_MISSING_LIMIT) {\n                    System.out.println(\"  . . .\");\n                    break;\n                }\n                System.out.println(gv);\n            }\n        }\n    }\n\n    public static final BiConsumer<PartitionGenerator, Test> distributionTest(boolean sortByCount) {\n        return (PartitionGenerator gen, Test test) -> {\n            System.out.print(\"\\n\" + getName(gen) + \"\\n\\n\");\n            Map<GeneratedVector, Integer> combos = new HashMap<>();\n            // There's no point of checking permus for sorted generators\n            // because they are the same as combos for them\n            Map<GeneratedVector, Integer> permus = gen.isSorted() ? null : new HashMap<>();\n            for (int i = 0; i < test.repeatCount; i++) {\n                int[] v = gen.get();\n                if (v == null && gen instanceof SequentialEnumerator)\n                    break;\n                if (permus != null) {\n                    permus.merge(new GeneratedVector(v), 1, Integer::sum);\n                    v = v.clone();\n                    Arrays.sort(v);\n                }\n                combos.merge(new GeneratedVector(v), 1, Integer::sum);\n            }\n            Set<Map.Entry<GeneratedVector, Integer>> sortedEntries = new TreeSet<>(\n                    sortByCount ? byCount : lexicographical);\n            System.out.println(\"Combos\" + (gen.isSorted() ? \":\" : \" (don't have to be uniform):\"));\n            sortedEntries.addAll(combos.entrySet());\n            for (Map.Entry<GeneratedVector, Integer> e : sortedEntries)\n                System.out.println(e);\n            checkMissingPartitions(combos, test.getGenerator(SequentialEnumerator.combinationFactory));\n            if (permus != null) {\n                System.out.println(\"\\nPermus:\");\n                sortedEntries.clear();\n                sortedEntries.addAll(permus.entrySet());\n                for (Map.Entry<GeneratedVector, Integer> e : sortedEntries)\n                    System.out.println(e);\n                checkMissingPartitions(permus, test.getGenerator(SequentialEnumerator.permutationFactory));\n            }\n        };\n    }\n\n    public static final BiConsumer<PartitionGenerator, Test> correctnessTest =\n        (PartitionGenerator gen, Test test) -> {\n        String genName = getName(gen);\n        for (int i = 0; i < test.repeatCount; i++) {\n            int[] v = gen.get();\n            if (v == null && gen instanceof SequentialEnumerator)\n                v = gen.get();\n            if (v.length != test.numberCount)\n                throw new RuntimeException(genName + \": array of wrong length\");\n            int s = 0;\n            if (gen.isSorted()) {\n                if (v[0] < test.min || v[v.length - 1] > test.max)\n                    throw new RuntimeException(genName + \": generated number is out of range\");\n                int prev = test.min;\n                for (int x : v) {\n                    if (x < prev)\n                        throw new RuntimeException(genName + \": unsorted array\");\n                    s += x;\n                    prev = x;\n                }\n            } else\n                for (int x : v) {\n                    if (x < test.min || x > test.max)\n                        throw new RuntimeException(genName + \": generated number is out of range\");\n                    s += x;\n                }\n            if (s != test.sum)\n                throw new RuntimeException(genName + \": wrong sum\");\n        }\n        System.out.format(\"%30s :   correctness test passed%n\", genName);\n    };\n\n    public static final BiConsumer<PartitionGenerator, Test> performanceTest =\n        (PartitionGenerator gen, Test test) -> {\n        long time = System.nanoTime();\n        for (int i = 0; i < test.repeatCount; i++)\n            gen.get();\n        time = System.nanoTime() - time;\n        System.out.format(\"%30s : %8.3f s %10.0f ns/test%n\", getName(gen), time * 1e-9, time * 1.0 / test.repeatCount);\n    };\n\n    public PartitionGenerator getGenerator(GeneratorFactory factory) {\n        return factory.create(numberCount, min, max, sum);\n    }\n\n    public static String getName(PartitionGenerator gen) {\n        String name = gen.getClass().getSimpleName();\n        if (gen instanceof SequentialEnumerator)\n            return (gen.isSorted() ? \"Sorted \" : \"Unsorted \") + name;\n        else\n            return name;\n    }\n\n    public static GeneratorFactory[] factories = { SmithTromblePartitionGenerator.factory,\n            PermutationPartitionGenerator.factory, CombinationPartitionGenerator.factory,\n            SequentialEnumerator.permutationFactory, SequentialEnumerator.combinationFactory };\n\n    public static void main(String[] args) {\n        Test[] tests = {\n                            new Test(3, 0, 3, 5, 3_000, distributionTest(false)),\n                            new Test(3, 0, 6, 12, 3_000, distributionTest(true)),\n                            new Test(50, -10, 20, 70, 2_000, correctnessTest),\n                            new Test(7, 3, 10, 42, 1_000_000, performanceTest),\n                            new Test(20, 3, 10, 120, 100_000, performanceTest)\n                       };\n        for (Test t : tests) {\n            System.out.println(t);\n            for (GeneratorFactory factory : factories) {\n                PartitionGenerator candidate = t.getGenerator(factory);\n                t.procedure.accept(candidate, t);\n            }\n            System.out.println();\n        }\n    }\n}\n```\n\n\nYou can try this on Ideone.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "feasible method is stucked in infinite loop [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs debugging details. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     Edit the question to include desired behavior, a specific problem or error, and the shortest code necessary to reproduce the problem. This will help others answer the question.\r\n                \r\n                    \r\n                        Closed 6 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI have run the following simplex method which is written in C++ .The code is as follows : \n\n```\n#include<bits/stdc++.h>\n#include<cstdio>\nusing namespace std;\n\n#define maxm 500\n#define maxn 500\ndouble inf = 1e100;\ndouble eps = 1e-13;\n\nint row,col;\ndouble A[maxm][maxn];\ndouble B[maxn];\n///////////////////////////////////////////////////////////////////////////////////////////\n// Simon Lo's\n// Simplex algorithm on augmented matrix a of dimension (m+1)x(n+1)\n// returns 1 if feasible, 0 if not feasible, -1 if unbounded\n// returns solution in b[] in original var order, max(f) in ret\n// form: maximize sum_j(a_mj*x_j)-a_mn s.t. sum_j(a_ij*x_j)<=a_in\n// in standard form.\n// To convert into standard form:\n// 1. if exists equality constraint, then replace by both >= and <=\n// 2. if variable x doesn't have nonnegativity constraint, then replace by\n// difference of 2 variables like x1-x2, where x1>=0, x2>=0\n// 3. for a>=b constraints, convert to -a<=-b\n// note: watch out for -0.0 in the solution, algorithm may cycle\n// eps = 1e-7 may give wrong answer, 1e-10 is better\n\n\n\nvoid pivot(int m, int n, double a[maxm][maxn], int B[maxm], int N[maxn], int r, int c) {\n        int i, j;\n        swap(N[c], B[r]);\n        a[r][c]=1/a[r][c];\n        for (j=0; j<=n; j++)if (j!=c) a[r][j]*=a[r][c];\n        for (i=0; i<=m; i++)if (i!=r) {\n                for (j=0; j<=n; j++)if (j!=c)\n                        a[i][j]-=a[i][c]*a[r][j];\n                a[i][c] = -a[i][c]*a[r][c];\n        }\n}\nint feasible(int m, int n, double a[maxm][maxn], int B[maxm], int N[maxn]) {\n        int r, c, i; double p, v;\n        while (1) {\n                for (p=inf, i=0; i<m; i++) if (a[i][n]<p) p=a[r=i][n];\n                if (p>-eps) return 1;\n                for (p=0, i=0; i<n; i++) if (a[r][i]<p) p=a[r][c=i];\n                if (p>-eps) return 0;\n                cout<<\"Sultan\"<<endl;\n                p = a[r][n]/a[r][c];\n                for (i=r+1; i<m; i++) if (a[i][c]>eps) {\n                        v = a[i][n]/a[i][c];\n                        if (v<p) r=i, p=v;\n                }\n                pivot(m, n, a, B, N, r, c);\n        }\n}\nint simplex(int m, int n, double a[maxm][maxn], double b[maxn], double& ret)\n {\n        int B[maxm], N[maxn], r, c, i; double p, v;\n        for (i=0; i<n; i++) N[i]=i;\n        for (i=0; i<m; i++) B[i]=n+i;\n        if (!feasible(m, n, a, B, N)) return 0;\n        while (1) {\n                for (p=0, i=0; i<n; i++) if (a[m][i]>p)\n                        p=a[m][c=i];\n                if (p<eps) {\n                        for (i=0; i<n; i++) if (N[i]<n)\n                                b[N[i]]=0;\n                        for (i=0; i<m; i++) if (B[i]<n)\n                                b[B[i]]=a[i][n];\n                        ret = -a[m][n];\n                        return 1;\n                }\n                for (p=inf, i=0; i<m; i++) if (a[i][c]>eps) {\n                        v = a[i][n]/a[i][c];\n                        if (v<p) p=v, r=i;\n                }\n                if (p==inf) return -1;\n                pivot(m, n, a, B, N, r, c);\n        }\n}\n//////////////////////////////////////////////////////////////////////////////////////////////\n\nvoid read_file()\n{\n    freopen(\"Dimen.txt\",\"r\",stdin);\n\n    scanf(\"%d\",&row);\n    scanf(\"%d\",&col);\n\n    row = 30 ;\n    col = 100;\n\n    cout << row << \" \"<<col<<endl;\n\n    freopen(\"A1.txt\",\"r\",stdin);\n    for(int i=0;i<row;i++)\n       for(int j=0;j<col;j++)\n         scanf(\"%lf\",&A[i][j]);\n    cout<\"Completed A\";\n\n    freopen(\"B1.txt\",\"r\",stdin);\n    for(int i=0;i<row;i++){\n       scanf(\"%lf\",&A[i][col]);\n    }\n    cout<\"Completed B\";\n\n    freopen(\"F1.txt\",\"r\",stdin);\n    for(int j=0;j<col;j++){\n        scanf(\"%lf\",&A[row][j]);\n        //B[i]=-B[i];\n    }\n    cout<\"Completed F\";\n\n\n}\n\nint main()\n{\n    read_file();\n    double value,opt=0;\n    int flag = simplex(row,col, A,B, value);\n    freopen(\"opt.txt\",\"r\",stdin);\n    scanf(\"%lf\",&opt);\n    if(flag != -1)\n    {\n        cout<<\"The result is \"<<(value+opt);\n    }\n    else\n    {\n        cout<<\"The result is infeasible\";\n    }\n\n    return 0;\n}\n```\n\n\nBut this code runs in infinite loop . The feasible method stucks in infinite loop . How can I solve this error ? Please help me . \n    ", "Answer": "\r\nLets start by fixing the unclear bits of the code:\n\n```\n#include<bits/stdc++.h>  \n```\n\n\nYou should not use any includes that starts with ```\nbits/```\n include the standard header that will include it.\n\n```\n#include<cstdio>\nusing namespace std;\n```\n\n\nUsing ```\nstd```\n is bad practice, it might confuse the compiler in large projects and select a function/template/whatever that you did not mean to.\n\n```\n#define maxm 500\n#define maxn 500\n```\n\n\nAs minimum change these to \n\n```\n#define maxm (500)\n#define maxn (500)\n```\n\n\nSo macro substitution doesn't get confused. Better use c++11 and use\n\n```\nconstexpr int maxm = 500; \nconstexpr int maxn = 500; \n\ndouble inf = 1e100;\ndouble eps = 1e-13;\n```\n\n\nThere are standard ways of finding the correct values for ```\ninf```\n and ```\neps```\n\n\n```\ndouble inf = std::numeric_limits<double>::max();\n```\n\n\nFrom you code I presume you really meant max double. \nFor ```\neps```\n I wonder if you need\n\n```\ndouble eps = std::numeric_limits<double>::epsilon();\n```\n\n\nor \n\n```\ndouble eps = std::numeric_limits<double>::round_error();\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Draw non-overlapping lines between objects\r\n                \r\nHere is a problem, I found and would be interested in\nfinding first steps to get further in thinking about\nsolutions:\ngiven a set of n objects (rectangles, circles and similar forms),\nthe task to solve is to draw lines to connect\nsome pairs of them (the result should be a kind of flowchart diagram).\nThe lines should not cross the objects and they should look as simple\nas possible (shortest pathes between the objects without crossing,\nas straight as possible (no sharp kinks/bends) in the lines.\nI guess this could be a combinatorial optimization poblem.\nDoes there perhaps exist a standard heuristics?\nI know, that the graphviz/dot language has some kind of heuristics\nfor problems like that, but I dont know, how they work.\nIs it a simplex-type optimization problem?\nWould it be promising to try reinforcement learning on this task?\nDoes there propably exist a good approximation algorithm, so one would not need to\nfind exact solutions for the optimal line pathes?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Dynamic Programming problems with an additional condition besides the value that must be calculated\r\n                \r\nSay I have a weighted graph where the weights represent distance (in miles). I am to find the shortest path from some vertex S to some vertex T. Further, say there is a monetary cost  associated with each vertex. Now, at the beginning I have $M (i.e. M dollars). My job is to find the shortest path without incurring any debt.\n\nMy Attempt:\n\nI use Dijkstra's algorithm, but my solution only works in some instances but not all. Does anyone know how to solve this so it works -- NO SIMPLEX, please, unless you implement it fully. A java working code is much appreciated. I already looked at the ```\nUpper-Intermediate```\n example on top-coders but I don't know how to implement their pseudo-code.\n\nI try many different code/approaches but all of them have too many bugs. My tries are too numerous to post and posting just one does not make much sense.\n    ", "Answer": "\r\nYou are right to say that Dijkstra's algorithm works only in some cases, because it picks just the edges that cost less, while you have to verify the existence of two conditions:\n\n\nthe total cost of the path in dollars is within the bugdet of ```\nM```\n dollars;\nthe number of miles is minimum.\n\n\nAn approach that is guranteed to be correct, but could be really slow to run is this. You make two steps:\n\n\nfind all the possible paths in terms of cost in dollars and put them into an array or a list;\nfor each path calculate the number of miles and pick the path or the paths that have the minimum number of miles.\n\n\nThe problem with this approach is that the list produced could be really big. So maybe there is a better way to solve this problem.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How does Constrained Nonlinear Optimization VI works? (Theory)\r\n                \r\nI am trying to get the theory behind LabVIEW's Constrained Nonlinear Optimization VI. There description provides how to use it but not which optimization algorithms works behind it.\nHere is an overview of the optimization algorithms but it simply states\n\n\n  Solves a general nonlinear optimization problem with nonlinear equality constraint and nonlinear inequality constraint bounds using a sequential quadratic programming method. \n\n\n\n\nI suspect that it is a wrapper for multiple algorithms depending on the inputs... I want to know if it uses a  Levenberg-Marquardt or a Downhill-Simplex or other theory. It is not even said if it is trust-region or line search and how the bounds are ensured (e.g. by reflection)... In other languages, the documentation often refers to a paper from which I can take the original theory. This is what I am looking for. Can anyone help (or do I have to contact the NI support)? Thx\n\n(using LabVIEW 2017 and 2018 32bit)\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Find the best combination from a given set of multiple sets\r\n                \r\nSay you have a shipment. It needs to go from point A to point B, point B to point C and finally point C to point D. You need it to get there in five days for the least amount of money possible. There are three possible shippers for each leg, each with their own different time and cost for each leg:\n\n```\nArray\n(\n    [leg0] => Array\n        (\n            [UPS] => Array\n                (\n                    [days] => 1\n                    [cost] => 5000\n                )\n\n            [FedEx] => Array\n                (\n                    [days] => 2\n                    [cost] => 3000\n                )\n\n            [Conway] => Array\n                (\n                    [days] => 5\n                    [cost] => 1000\n                )\n\n        )\n\n    [leg1] => Array\n        (\n            [UPS] => Array\n                (\n                    [days] => 1\n                    [cost] => 3000\n                )\n\n            [FedEx] => Array\n                (\n                    [days] => 2\n                    [cost] => 3000\n                )\n\n            [Conway] => Array\n                (\n                    [days] => 3\n                    [cost] => 1000\n                )\n\n        )\n\n    [leg2] => Array\n        (\n            [UPS] => Array\n                (\n                    [days] => 1\n                    [cost] => 4000\n                )\n\n            [FedEx] => Array\n                (\n                    [days] => 1\n                    [cost] => 3000\n                )\n\n            [Conway] => Array\n                (\n                    [days] => 2\n                    [cost] => 5000\n                )\n\n        )\n\n)\n```\n\n\nHow would you go about finding the best combination programmatically?\n\nMy best attempt so far (third or fourth algorithm) is:\n\n\nFind the longest shipper for each leg\nEliminate the most \"expensive\" one\nFind the cheapest shipper for each leg\nCalculate the total cost & days\nIf days are acceptable, finish, else, goto 1\n\n\nQuickly mocked-up in PHP (note that the test array below works swimmingly, but if you try it with the test array from above, it does not find the correct combination):\n\n```\n$shippers[\"leg1\"] = array(\n    \"UPS\"    => array(\"days\" => 1, \"cost\" => 4000),\n    \"Conway\" => array(\"days\" => 3, \"cost\" => 3200),\n    \"FedEx\"  => array(\"days\" => 8, \"cost\" => 1000)\n);\n\n$shippers[\"leg2\"] = array(\n    \"UPS\"    => array(\"days\" => 1, \"cost\" => 3500),\n    \"Conway\" => array(\"days\" => 2, \"cost\" => 2800),\n    \"FedEx\"  => array(\"days\" => 4, \"cost\" => 900)\n);\n\n$shippers[\"leg3\"] = array(\n    \"UPS\"    => array(\"days\" => 1, \"cost\" => 3500),\n    \"Conway\" => array(\"days\" => 2, \"cost\" => 2800),\n    \"FedEx\"  => array(\"days\" => 4, \"cost\" => 900)\n);    \n\n$times = 0;\n$totalDays = 9999999;\n\nprint \"<h1>Shippers to Choose From:</h1><pre>\";\nprint_r($shippers);\nprint \"</pre><br />\";\n\nwhile($totalDays > $maxDays && $times < 500){\n            $totalDays = 0;\n            $times++;\n            $worstShipper = null;\n            $longestShippers = null;\n            $cheapestShippers = null;\n\n            foreach($shippers as $legName => $leg){\n                //find longest shipment for each leg (in terms of days)\n                unset($longestShippers[$legName]);\n                $longestDays = null;        \n\n                if(count($leg) > 1){\n                    foreach($leg as $shipperName => $shipper){\n                        if(empty($longestDays) || $shipper[\"days\"] > $longestDays){\n                            $longestShippers[$legName][\"days\"] = $shipper[\"days\"];\n                            $longestShippers[$legName][\"cost\"] = $shipper[\"cost\"];\n                            $longestShippers[$legName][\"name\"] = $shipperName;\n                            $longestDays = $shipper[\"days\"];\n                        }\n                    }           \n                }\n            }\n\n            foreach($longestShippers as $leg => $shipper){\n                $shipper[\"totalCost\"] = $shipper[\"days\"] * $shipper[\"cost\"];\n\n                //print $shipper[\"totalCost\"] . \" &lt;?&gt; \" . $worstShipper[\"totalCost\"] . \";\";\n\n                if(empty($worstShipper) || $shipper[\"totalCost\"] > $worstShipper[\"totalCost\"]){\n                    $worstShipper = $shipper;\n                    $worstShipperLeg = $leg;\n                }\n            }\n\n            //print \"worst shipper is: shippers[$worstShipperLeg][{$worstShipper['name']}]\" . $shippers[$worstShipperLeg][$worstShipper[\"name\"]][\"days\"];\n            unset($shippers[$worstShipperLeg][$worstShipper[\"name\"]]);\n\n            print \"<h1>Next:</h1><pre>\";\n            print_r($shippers);\n            print \"</pre><br />\";\n\n            foreach($shippers as $legName => $leg){\n                //find cheapest shipment for each leg (in terms of cost)\n                unset($cheapestShippers[$legName]);\n                $lowestCost = null;\n\n                foreach($leg as $shipperName => $shipper){\n                    if(empty($lowestCost) || $shipper[\"cost\"] < $lowestCost){\n                        $cheapestShippers[$legName][\"days\"] = $shipper[\"days\"];\n                        $cheapestShippers[$legName][\"cost\"] = $shipper[\"cost\"];\n                        $cheapestShippers[$legName][\"name\"] = $shipperName;\n                        $lowestCost = $shipper[\"cost\"];\n                    }\n                }\n\n                //recalculate days and see if we are under max days...\n                $totalDays += $cheapestShippers[$legName]['days'];  \n            }\n            //print \"<h2>totalDays: $totalDays</h2>\";\n        }\n\n        print \"<h1>Chosen Shippers:</h1><pre>\";\n        print_r($cheapestShippers);\n        print \"</pre>\";\n```\n\n\nI think I may have to actually do some sort of thing where I literally make each combination one by one (with a series of loops) and add up the total \"score\" of each, and find the best one....\n\nEDIT:\nTo clarify, this isn't a \"homework\" assignment (I'm not in school). It is part of my current project at work.\n\nThe requirements (as always) have been constantly changing. If I were given the current constraints at the time I began working on this problem, I would be using some variant of the A* algorithm (or Dijkstra's or shortest path or simplex or something). But everything has been morphing and changing, and that brings me to where I'm at right now.\n\nSo I guess that means I need to forget about all the crap I've done to this point and just go with what I know I should go with, which is a path finding algorithm.\n    ", "Answer": "\r\nCould alter some of the shortest path algorithms, like Dijkstra's, to weight each path by cost but also keep track of time and stop going along a certain path if the time exceeds your threshold.  Should find the cheapest that gets you in under your threshold that way\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to color voronoi polygons defined by area (1/area)?\r\n                \r\nI have generated a Voronoi diagram and calculated the area and then 1/area (flux) of the polygons formed and found average flux. I now want to color code my polygons by flux (i want colorize only polygons with flux>average flux)\n\n```\n#Voronoi algorithm\n\nlist_ra=tbdata[cut3]['RA']\n\nlist_dec=tbdata[cut3]['DEC']\n\npoints=np.column_stack((list_ra, list_dec))\n\nvor=Voronoi(points)\n\n#print vor.vertices\n\n#print vor.regions\n\n#print vor.ridge_vertices\n#print vor.ridge_points\n\nprint len(vor.point_region)\n\nplt.plot(points[:, 0], points[:, 1], '.')\n\nplt.plot(vor.vertices[:, 0], vor.vertices[:, 1], '.', markersize=0.25)\n\nplt.xlim(150.02, 150.21); plt.ylim(2.26, 2.45)\n\nfor simplex in vor.ridge_vertices:\n\n     simplex = np.asarray(simplex)\n\n     if np.all(simplex >= 0):\n\n      plt.plot(vor.vertices[simplex, 0], vor.vertices[simplex, 1], 'k-')\n\ncenter = points.mean(axis=0)\n\nfor pointidx, simplex in zip(vor.ridge_points, vor.ridge_vertices):\n\n     simplex = np.asarray(simplex)\n\n     if np.any(simplex < 0):\n\n         i = simplex[simplex >= 0][0] # finite end Voronoi vertex\n\n         t = points[pointidx[1]] - points[pointidx[0]]  # tangent\n\n         t = t / np.linalg.norm(t)\n\n         n = np.array([-t[1], t[0]]) # normal\n\n         midpoint = points[pointidx].mean(axis=0)\n\n         far_point = vor.vertices[i] + np.sign(np.dot(midpoint - center, n)) * n * 100\n\n         plt.plot([vor.vertices[i,0], far_point[0]],\n\n                  [vor.vertices[i,1], far_point[1]], 'k--')\n\nplt.xlabel(r' RA/deg ',size=12)\n\nplt.ylabel(r' DEC/deg ',size=12)\n\nplt.savefig('Voronoi_10x10', dpi=300)\n\nplt.show()\n\n###############################################################################################\n#Polygon areas\n\ntotal=0\n\ntotals=[]\n\nfor i in range (len(vor.point_region)):\n\n    polygon_coordinates=[vor.vertices[y] for y in vor.regions[vor.point_region[i]]]\n\n    list_polygon_coordinates=np.asarray(polygon_coordinates)\n\n    r=list_polygon_coordinates[:, 0]\n\n    d=list_polygon_coordinates[:, 1]\n\n    def PolyArea(r,d): \n        return 0.5*np.abs(np.dot(r,np.roll(d,1))-np.dot(d,np.roll(r,1)))\n\n    total=PolyArea(r,d)\n\n    totals.append(total)\n\ntotaltotal=0\n\nfor i in range(len(vor.point_region)):\n\n    totaltotal+=totals[i]\n\nprint ('totaltotal', totaltotal)\n\naverage_area=totaltotal/1533\n\nprint ('average_area', average_area)\n\n################################################################################################\n#Flux distribution\n\narea=np.array(totals)\n\nprint ('area', area)\n\nflux=1/area\n\nprint ('flux', flux)\n\ntotaltotal_flux=0\n\nfor i in range(1533):\n\n    totaltotal_flux+=flux[i]\n\nprint ('totaltotal_flux', totaltotal_flux)\n\naverage_flux=totaltotal_flux/1533\n\nprint ('average_flux', average_flux)\n```\n\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "MLE for censored distributions of the exponential family\r\n                \r\nWith the scipy.stats package it is straightforward to fit a distribution to data, e.g. scipy.stats.expon.fit() can be used to fit data to an exponential distribution.\nHowever, I am trying to fit data to a censored/conditional distribution in the exponential family. In other words, using MLE, I am trying to find the maximum of\n,\nwhere  is a PDF of a distribution in the exponential family, and  is its corresponding CDF.\nMathematically, I have found that the log-likelihood function is convex in the parameter space , so my assumption was that it should be relatively straightforward to apply the scipy.optimize.minimize function. Notice in the above log-likelihood that by taking  we obtain the traditional/uncensored MLE problem.\nHowever, I find that even for simple distributions that e.g. the nelder-mead simplex algorithm does not always converge, or that it does converge but the estimated parameters are far off from the true ones. I have attached my code below. Notice that one can choose a distribution, and that the code is generic enough to fit the loc and scale parameters, as well as the optional shape parameters (for e.g. a Beta or Gamma distribution).\nMy question is: what am I doing wrong to obtain these bad estimates, or sometimes get convergence issues? I have tried a few algorithms but there is not one that easily works, to my surprise as the problem is convex. Are there smoothness issues, and that I need to find a way to use the Jacobian and Hessian in a generic way for this problem?\nAre there other methods to tackle this problem? Initially I thought to override fit() function in the scipy.stats.rv class to take care of the censoring with the CDF, but this seemed quite cumbersome. But since the problem is convex, I would guess that using the minimize function of scipy I should be able to easily get the results...\nComments and help are very welcome!\n```\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import expon, gamma, beta, norm\nfrom scipy.optimize import minimize\nfrom scipy.stats import rv_continuous as rv\n\n\ndef log_likelihood(func: rv, delays, max_delays=10**8, **func_pars)->float:\n    return np.sum(np.log(func.pdf(delays, **func_pars)+1) - np.log(func.cdf(max_delays, **func_pars)))\n\n\ndef minimize_log_likelihood(func: rv, delays, max_delays):\n\n    # Determine number of parameters to estimate (always 'loc', 'scale', sometimes shape parameters)\n    n_pars = 2 + func.numargs\n\n    # Initialize guess (loc, scale, [shapes])\n    x0 = np.ones(n_pars)\n\n    def wrapper(params, *args):\n        func = args[0]\n        delays = args[1]\n        max_delays = args[2]\n        loc, scale = params[0], params[1]\n\n        # Set 'loc' and 'scale' parameters\n        kwargs = {'loc': loc, 'scale': scale}\n\n        # Add shape parameters if existing to kwargs\n        if func.shapes is not None:\n            for i, s in enumerate(func.shapes.split(', ')):\n                kwargs[s] = params[2+i]\n        \n        return -log_likelihood(func=func, delays=delays, max_delays=max_delays, **kwargs)\n\n    # Find maximum of log-likelihood (thus minimum of minus log-likelihood; see wrapper function)\n    return minimize(wrapper, x0, args=(func, delays, max_delays), options={'disp': True}, \n                    method='nelder-mead', tol=1e-8)\n\n\n\n\n# Test code with by sampling from known distribution, and retrieve parameters\ndistribution = expon\ndist_pars = {'loc': 0, 'scale': 4}\nx = np.linspace(distribution.ppf(0.0001, **dist_pars), distribution.ppf(0.9999, **dist_pars), 1000)\n\nres = minimize_log_likelihood(distribution, x, 10**8)\nprint(res)\n\n```\n\n    ", "Answer": "\r\nI have found that the convergence is bad due to numerical inaccuracies. Best is to replace\n```\nnp.log(func.pdf(x, **func_kwargs))\n```\n\nwith\n```\nfunc.logpdf(x, **func_kwargs)\n```\n\nThis leads to correct estimation of the parameters. The same holds for the CDF. The documentation of scipy also indicates that the numerical accuracy of the latter performs better.\nThis all works nicely with the Exponential, Normal, Gamma, chi2 distributions. The Beta distribution still gives me issues, but I think this is again to some (other) numerical inaccuracies which I will analyse separately.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Generalized Load Balancing (GLB) using Linear Programming (LP)\r\n                \r\nIn one of my project - I have a scenario where I need to implement an algorithm capable of doing load balancing. Now, unlike the general load balancing problem present in CS theory (which is NP hard) - where the task is to allocate M loads in N servers (M >> N), such that the maximum load in any one server is minimized, the case that I am dealing with is a little more generic. In my case, the load balancing problem is more generic in the sense - it has more constraints in the form that - such and such job can only be assigned to such an such server (lets say for example job M_{i} has some special security requirements and hence can be allocated/executed only on secure server N_{j}.\n\nNow I looked at the Kleinberg/Tardos book and I found a section (11.7) on the more generic load balancing problem (load balancing with constraints) and I found that this problem is an exact match for the situation I am in. The Generic Load Balancing problem has been converted from IP to LP taking advantage of the fact that LP can result in fractional assignment of jobs to machines which has later been rounded off adding an additional O(MN) time to the process. This approximation solution has then been shown to be within a factor of 2 times from the minimum possible. \n\nCan someone point me to some C/Java/Python/MATLAB code where this algorithm has been implemented? As KL book hardly gives any examples or sample pseudo/actual code, it is hard to get the algorithm internalized completely sometimes. Also as for the linear programming part of the problem - what kind of an implementation is suitable for it - Simplex/Interior Point? How much difference will it make when complexity from this LP part is added to the problem (to the fractional re-assignment part)? Unfortunately, the KL book is not very thorough in these aspects.\n\nSome sample C/Java/Python/MATLAB code (or pointers to code) showing some real implementation of this complete algorithm would be greatly helpful.\n\nEdit: The original paper is \"David B. Shmoys, Éva Tardos: An approximation algorithm for the generalized assignment problem. Math. Program. 62: 461-474 (1993)\"   \n    ", "Answer": "\r\nOne way in which I did this was to load balance according to the current load on each machine. So if there are three machines A,B,C..... A has a load of 10, B had a load of 5 and C has a load of 2 then the next task (which lets say has a load of 3) should go to C(3+2 = 5 < all other combinations). In case of equality given that the task which starts first usually finishes first(at least most of the times) remove the oldest task from each machine and repeat the above process... Do this recursively\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Understanding CPLEX output\r\n                \r\nI am working on a problem using CPLEX and I am very unfamiliar with it. I know how the Simplex algorithm works, I know Branch&Bound, MIP problems etc, but only from a theory point of view. This is the first time I actually use CPLEX.\n\nI am using it in C, and I wrote the main file based A LOT on the example \"populate.c\" file that is given as an example in the CPLEX distribution.\n\nHere is the C code.\n\n```\n#include <ilcplex/cplex.h>\n\n/* Bring in the declarations for the string and character functions \n   and malloc */\n\n#include <ctype.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\n#define EPSZERO        1.0E-10\n#define BUFSIZE 16\n\n/* Include declarations for functions in this program */\n\nstatic void\n   free_and_null (char **ptr),\n   usage         (char *progname);\n\n\nint\nmain (int argc, char *argv[])\n{\n   /* Declare and allocate space for the variables and arrays where we will\n      store the optimization results including the status, objective value,\n      and variable values. */\n\n\n   int      solstat;\n   double   objval;\n   double   incobjval;\n   double   meanobjval;\n   double   *x     = NULL;\n   double   *incx  = NULL;\n   int      numsol;\n   int      numsolreplaced;\n   int      numdiff;\n\n   CPXENVptr     env = NULL;\n   CPXLPptr      lp = NULL;\n   int           status;\n   int           i, j;\n   int           cur_numcols;\n\n   /* Check the command line arguments */\n\n   if ( argc != 2 ) {\n      usage (argv[0]);\n      goto TERMINATE;\n   }\n\n   /* Initialize the CPLEX environment */\n\n   env = CPXopenCPLEX (&status);\n\n   /* If an error occurs, the status value indicates the reason for\n      failure.  A call to CPXgeterrorstring will produce the text of\n      the error message.  Note that CPXopenCPLEX produces no output,\n      so the only way to see the cause of the error is to use\n      CPXgeterrorstring.  For other CPLEX routines, the errors will\n      be seen if the CPX_PARAM_SCRIND indicator is set to CPX_ON.  */\n\n   if ( env == NULL ) {\n      char  errmsg[CPXMESSAGEBUFSIZE];\n      fprintf (stderr, \"Could not open CPLEX environment.\\n\");\n      CPXgeterrorstring (env, status, errmsg);\n      fprintf (stderr, \"%s\", errmsg);\n      goto TERMINATE;\n   }\n\n   /* Turn on output to the screen */\n\n   status = CPXsetintparam (env, CPX_PARAM_SCRIND, CPX_ON);\n   if ( status ) {\n      fprintf (stderr, \n               \"Failure to turn on screen indicator, error %d.\\n\", status);\n      goto TERMINATE;\n   }\n\n   /* Create the problem, using the filename as the problem name */\n\n   lp = CPXcreateprob (env, &status, argv[1]);\n\n   /* A returned pointer of NULL may mean that not enough memory\n      was available or there was some other problem.  In the case of \n      failure, an error message will have been written to the error \n      channel from inside CPLEX.  In this example, the setting of\n      the parameter CPX_PARAM_SCRIND causes the error message to\n      appear on stdout.  Note that most CPLEX routines return\n      an error code to indicate the reason for failure.   */\n\n   if ( lp == NULL ) {\n      fprintf (stderr, \"Failed to create LP.\\n\");\n      goto TERMINATE;\n   }\n\n   /* Now read the file, and copy the data into the created lp */\n\n   status = CPXreadcopyprob (env, lp, argv[1], NULL);\n   if ( status ) {\n      fprintf (stderr, \"Failed to read and copy the problem data.\\n\");\n      goto TERMINATE;\n   }\n\n   /* Set the solution pool relative gap parameter to obtain solutions\n      of objective value within 10% of the optimal */\n\n   status = CPXsetdblparam (env, CPX_PARAM_SOLNPOOLGAP, 0);\n   if ( status ) {\n      fprintf (stderr, \n               \"Failed to set the solution pool relative gap, error %d.\\n\", \n               status);\n      goto TERMINATE;\n   }//*/\n\n\n\n   /* Optimize the problem and obtain multiple solutions. */\n\n   status = CPXpopulate (env, lp);\n\n   if ( status ) {\n      fprintf (stderr, \"Failed to populate MIP.\\n\");\n      goto TERMINATE;\n   }\n\n   solstat = CPXgetstat (env, lp);\n   printf (\"Solution status: %d.\\n\", solstat);\n\n   status  = CPXgetobjval (env, lp, &incobjval);\n\n   if ( status ) {\n      fprintf (stderr,\n               \"Failed to obtain objective value for the incumbent.\\n\");\n      goto TERMINATE;\n   }\n\n   printf (\"Objective value of the incumbent: %.10g\\n\", incobjval);\n\n   /* The size of the problem should be obtained by asking CPLEX what\n      the actual size is. cur_numcols stores the current number \n      of columns. */\n\n   cur_numcols = CPXgetnumcols (env, lp);\n\n   /* Allocate space for solution */\n\n   incx = (double *) malloc (cur_numcols*sizeof(double));\n\n   if ( incx == NULL ) {\n      fprintf (stderr, \"No memory for solution values for the incumbent.\\n\");\n      goto TERMINATE;\n   }\n\n   status = CPXgetx (env, lp, incx, 0, cur_numcols-1);\n   if ( status ) {\n      fprintf (stderr, \"Failed to obtain the incumbent.\\n\");\n      goto TERMINATE;\n   }\n\n   /* Write out the incumbent */\n   char          **cur_colname = NULL;\n   char          *cur_colnamestore = NULL;\n   int           cur_colnamespace;\n   int           surplus;\n\n   status = CPXgetcolname (env, lp, NULL, NULL, 0, &surplus, 0,\n                           cur_numcols-1);\n\n   if (( status != CPXERR_NEGATIVE_SURPLUS ) &&\n       ( status != 0 )                         )  {\n      fprintf (stderr, \n               \"Could not determine amount of space for column names.\\n\");\n      goto TERMINATE;\n   }\n\n\n   cur_colnamespace = - surplus;\n   if ( cur_colnamespace > 0 ) {\n      cur_colname      = (char **) malloc (sizeof(char *)*cur_numcols);\n      cur_colnamestore = (char *)  malloc (cur_colnamespace);\n      if ( cur_colname      == NULL ||\n           cur_colnamestore == NULL   ) {\n         fprintf (stderr, \"Failed to get memory for column names.\\n\");\n         status = -1;\n         goto TERMINATE;\n      }\n      status = CPXgetcolname (env, lp, cur_colname, cur_colnamestore, \n                              cur_colnamespace, &surplus, 0, cur_numcols-1);\n  }\n\n   for (j = 0; j < cur_numcols; j++) {\n\n      printf (\"Incumbent: Column %s:  Value = %17.10g\\n\", cur_colname[j], incx[j]);\n   }\n   printf (\"\\n\");\n\n   /* Get the number of solutions in the solution pool */\n\n   numsol = CPXgetsolnpoolnumsolns (env, lp);   \n   printf (\"The solution pool contains %d solutions.\\n\", numsol);\n\n   /* Some solutions are deleted from the pool because of the solution\n      pool relative gap parameter */\n\n   numsolreplaced = CPXgetsolnpoolnumreplaced (env, lp);\n   printf (\n\"%d solutions were removed due to the solution pool relative gap parameter.\\n\",\n          numsolreplaced);\n\n   printf (\"In total, %d solutions were generated.\\n\",\n           numsol + numsolreplaced);\n\n   /* Get the average objective value of solutions in the solution\n      pool */\n\n   status = CPXgetsolnpoolmeanobjval (env, lp, &meanobjval);\n   printf (\"The average objective value of the solutions is %.10g.\\n\\n\",\n          meanobjval);\n\n   /* Write out the objective value of each solution and its\n      difference to the incumbent */\n\n   x = (double *) malloc (cur_numcols*sizeof(double));\n   if ( x == NULL ) {\n      fprintf (stderr, \"No memory for solution values.\\n\");\n      goto TERMINATE;\n   }\n\n   printf (\"Solution        Objective   Number of variables\\n\");\n   printf (\"                value       that differ compared to\\n\");\n   printf (\"                            the incumbent\\n\");\n\n\n   for (i = 0; i < numsol; i++) {\n      char namei[BUFSIZE];\n      int  surplus;\n\n      /* Write out objective value */\n\n      CPXgetsolnpoolsolnname (env, lp, namei, BUFSIZE, &surplus, i);\n      printf (\"%-15s \", namei); \n\n\n      status = CPXgetsolnpoolobjval (env, lp, i, &objval);\n      if ( status ) {\n         fprintf (stderr,\n                  \"Failed to obtain objective value for solution %d.\\n\", i);\n         goto TERMINATE;\n      }\n      printf (\"%.10g         \", objval);\n\n      status = CPXgetsolnpoolx (env, lp, i, x, 0, cur_numcols-1);\n      if ( status ) {\n         fprintf (stderr, \"Failed to obtain solution %d.\\n\", i);\n         goto TERMINATE;\n      }\n\n      /* Compute the number of variables that differ in the solution\n         and in the incumbent */\n\n      numdiff = 0;\n      for (j = 0; j < cur_numcols; j++) {\n         if ( fabs (x[j] - incx[j]) > EPSZERO )\n            numdiff++;\n      }      \n      printf (\"%d / %d\\n\", numdiff, cur_numcols);\n   }\n\n\nTERMINATE:\n\n   /* Free up the solution */\n\n   free_and_null ((char **) &incx);\n   free_and_null ((char **) &x);\n\n   /* Free up the problem as allocated by CPXcreateprob, if necessary */\n\n   if ( lp != NULL ) {\n      status = CPXfreeprob (env, &lp);\n      if ( status ) {\n         fprintf (stderr, \"CPXfreeprob failed, error code %d.\\n\", status);\n      }\n   }\n\n   /* Free up the CPLEX environment, if necessary */\n\n   if ( env != NULL ) {\n      status = CPXcloseCPLEX (&env);\n\n      /* Note that CPXcloseCPLEX produces no output,\n         so the only way to see the cause of the error is to use\n         CPXgeterrorstring.  For other CPLEX routines, the errors will\n         be seen if the CPX_PARAM_SCRIND indicator is set to CPX_ON. */\n\n      if ( status ) {\n         char  errmsg[CPXMESSAGEBUFSIZE];\n         fprintf (stderr, \"Could not close CPLEX environment.\\n\");\n         CPXgeterrorstring (env, status, errmsg);\n         fprintf (stderr, \"%s\", errmsg);\n      }\n   }\n\n   return (status);\n\n}  /* END main */\n\n\n/* This simple routine frees up the pointer *ptr, and sets *ptr to NULL */\n\nstatic void\nfree_and_null (char **ptr)\n{\n   if ( *ptr != NULL ) {\n      free (*ptr);\n      *ptr = NULL;\n   }\n} /* END free_and_null */ \n\n\nstatic void\nusage (char *progname)\n{\n   fprintf (stderr,\"Usage: %s filename\\n\", progname);\n   fprintf (stderr,\"   where filename is a file with extension \\n\");\n   fprintf (stderr,\"      MPS, SAV, or LP (lower case is allowed)\\n\");\n   fprintf (stderr,\"  This program uses the CPLEX MIP optimizer.\\n\");\n   fprintf (stderr,\" Exiting...\\n\");\n} /* END usage */\n```\n\n\nNow, I generate my LP files (which have Binary variables and indicator constraints, so it's not just an LP) and give it to CPLEX.\n\nCPLEX does not complain at all and solves very well. But, I literally have no clue what it is telling me. Here is an example output:\n\n```\nPopulate: phase I \nTried aggregator 2 times.\nAggregator did 14 substitutions.\nReduced MIP has 92 rows, 160 columns, and 414 nonzeros.\nReduced MIP has 24 binaries, 0 generals, 0 SOSs, and 90 indicators.\nProbing time =    0.00 sec.\nTried aggregator 1 time.\nPresolve time =    0.00 sec.\nProbing time =    0.00 sec.\nMIP emphasis: balance optimality and feasibility.\nMIP search method: dynamic search.\nParallel mode: deterministic, using up to 8 threads.\nRoot relaxation solution time =    0.00 sec.\n\n        Nodes                                         Cuts/\n   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap\n\n      0     0     unbounded                                          0         \n      0     2     unbounded                                          0         \nElapsed real time =   0.01 sec. (tree size =  0.01 MB, solutions = 0)\n*     3     4      integral     0        0.9091                     47     --- \n*     7     7      integral     0        0.9005                     93     --- \n*    12    10      integral     0        0.7397                    178     --- \n\nRoot node processing (before b&c):\n  Real time             =    0.00\nParallel b&c, 8 threads:\n  Real time             =    0.08\n  Sync time (average)   =    0.00\n  Wait time (average)   =    0.00\n                          -------\nTotal (root+branch&cut) =    0.08 sec.\n\nPopulate: phase II \nMIP emphasis: balance optimality and feasibility.\nMIP search method: dynamic search.\nParallel mode: deterministic, using up to 8 threads.\n\n        Nodes                                         Cuts/\n   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap\n\n    601   301        1.1727     0        0.7397        0.7397     5173    0.00%\nElapsed real time =   0.00 sec. (tree size =  0.05 MB, solutions = 1)\n\nRoot node processing (before b&c):\n  Real time             =    0.00\nParallel b&c, 8 threads:\n  Real time             =    0.01\n  Sync time (average)   =    0.00\n  Wait time (average)   =    0.00\n                          -------\nTotal (root+branch&cut) =    0.01 sec.\nSolution status: 130.\nObjective value of the incumbent: 0.7396943877\nIncumbent: Column v0:  Value =      0.7396943877\nIncumbent: Column i_1_0:  Value =      0.7396943877\nIncumbent: Column i_2_0:  Value =       1.479388775\n... More stuff here...\nIncumbent: Column b_23:  Value =                 0\nIncumbent: Column b_24:  Value =                 0\n\nThe solution pool contains 1 solutions.\n0 solutions were removed due to the solution pool relative gap parameter.\nIn total, 1 solutions were generated.\nThe average objective value of the solutions is 0.7396943877.\n\nSolution        Objective   Number of variables\n                value       that differ compared to\n                            the incumbent\np2              0.7396943877         0 / 84\n```\n\n\nI do understand that the incumbent values are the values of my variables/objective.\nBut I have a few questions about some of the output:\n\n-MIP emphasis: balance optimality and feasibility. Can I make it focus on optimality?\n\n-MIP search method: how can I change this?\n\n-Most importantly, what are Phase I and Phase II? In my bigger instances Phase I takes way more (e.g 700s) than Phase II (e.g 20s). What are these phases doing?  If I understood correctly, Phase I is looking for a feasable solution, and Phase II to optimize, but as you can see in the log, it reported a first solution in Phase I (namely line \"*     3     4      integral     0        0.9091                     47     ---\") but then continued in Phase I. So I must have understood this wrong...\n\n-Is there a book or some resource I can read from to answer any future questions by myself? All I found was a 130pages tutorial from IBM that drowns me into \"irrelevant\" things and I cannot find what I am after.\n\nThanks.\n    ", "Answer": "\r\n\nMIP emphasis: balance optimality and feasibility\n\nThis is related to Cplex parameter MipEmphasis. This option \"controls trade-offs between speed, feasibility, optimality, and moving bounds in MIP\". Usually it is ok to leave it at its default value. You can tell Cplex to put more emphasis on optimality, but this does not lead necessarily to faster solution times. For large complicated models this is a useful option to play with.\nMIP search method \n\nThis is related to Cplex parameter MipSearch. This option \"sets the search strategy for a mixed integer program (MIP)\". I hardly ever use this option, and I believe it can be best left at its default value.\nMost importantly, what are Phase I and Phase II?\n\nThis is related to the solution pool algorithm. (Not to the concept of phase 1 and phase 2 in linear programming). See the documentation of Populate. \n\n\nI usually leave most or even all options to their defaults unless there is a good reason to change them. Cplex is designed to do a good job with default settings.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Smoothly mapping a 2D uv point onto a 3D xyz sphere\r\n                \r\nI have been trying to procedurally generate a sphere's surface using simplex noise, and I figured that in order to get smooth, non-distorted noise I need to map each uv pixel to an xyz coordinate. I have tried a few different algorithms, with the following being my favourite:\n\n```\nfunction convert2d3d(r1, r2, x, y) {\n    let z = -1 + 2 * x / r1;\n    let phi = 2 * Math.PI * y / r1;\n    let theta = Math.asin(z);\n    return {\n        x: r2 * Math.cos(theta) * Math.cos(phi),\n        y: r2 * Math.cos(theta) * Math.sin(phi),\n        z: r2 * z,\n    }\n}\n```\n\n\nWhile the points generated look continuous, there is severe distortion around the texture seams, and where the texture is stretched the most:\n\n\n\nI am aware what I am trying to do is called UV mapping, yet I'm struggling to implement it correctly. Either I get severe distortion, or ugly seams. To render the sphere I am using Three.JS MeshPhongMaterial and for the noise I am using noisejs.\n    ", "Answer": "\r\nDo you want something like THIS?\nIn the gui at the top right under scene -> geometry select the sphere.\n\nNo need to mess with UVs :)\n\nVertex shader from the demo linked above:\n\n```\nvarying vec3 vPosition;\nvoid main() {\n  vPosition = normalize(position);\n  gl_Position = projectionMatrix * modelViewMatrix * vec4(position,1.0);\n}\n```\n\n\nFragment Shader from the demo linked above:\n\n```\nvarying vec3 vPosition;\nuniform float scale;\n\n//\n// Description : Array and textureless GLSL 2D/3D/4D simplex \n//               noise functions.\n//      Author : Ian McEwan, Ashima Arts.\n//  Maintainer : ijm\n//     Lastmod : 20110822 (ijm)\n//     License : Copyright (C) 2011 Ashima Arts. All rights reserved.\n//               Distributed under the MIT License. See LICENSE file.\n//               https://github.com/ashima/webgl-noise\n// \n\nvec3 mod289(vec3 x) {\n  return x - floor(x * (1.0 / 289.0)) * 289.0;\n}\n\nvec4 mod289(vec4 x) {\n  return x - floor(x * (1.0 / 289.0)) * 289.0;\n}\n\nvec4 permute(vec4 x) {\n     return mod289(((x*34.0)+1.0)*x);\n}\n\nvec4 taylorInvSqrt(vec4 r)\n{\n  return 1.79284291400159 - 0.85373472095314 * r;\n}\n\nfloat snoise(vec3 v)\n  { \n  const vec2  C = vec2(1.0/6.0, 1.0/3.0) ;\n  const vec4  D = vec4(0.0, 0.5, 1.0, 2.0);\n\n// First corner\n  vec3 i  = floor(v + dot(v, C.yyy) );\n  vec3 x0 =   v - i + dot(i, C.xxx) ;\n\n// Other corners\n  vec3 g = step(x0.yzx, x0.xyz);\n  vec3 l = 1.0 - g;\n  vec3 i1 = min( g.xyz, l.zxy );\n  vec3 i2 = max( g.xyz, l.zxy );\n\n  //   x0 = x0 - 0.0 + 0.0 * C.xxx;\n  //   x1 = x0 - i1  + 1.0 * C.xxx;\n  //   x2 = x0 - i2  + 2.0 * C.xxx;\n  //   x3 = x0 - 1.0 + 3.0 * C.xxx;\n  vec3 x1 = x0 - i1 + C.xxx;\n  vec3 x2 = x0 - i2 + C.yyy; // 2.0*C.x = 1/3 = C.y\n  vec3 x3 = x0 - D.yyy;      // -1.0+3.0*C.x = -0.5 = -D.y\n\n// Permutations\n  i = mod289(i); \n  vec4 p = permute( permute( permute( \n             i.z + vec4(0.0, i1.z, i2.z, 1.0 ))\n           + i.y + vec4(0.0, i1.y, i2.y, 1.0 )) \n           + i.x + vec4(0.0, i1.x, i2.x, 1.0 ));\n\n// Gradients: 7x7 points over a square, mapped onto an octahedron.\n// The ring size 17*17 = 289 is close to a multiple of 49 (49*6 = 294)\n  float n_ = 0.142857142857; // 1.0/7.0\n  vec3  ns = n_ * D.wyz - D.xzx;\n\n  vec4 j = p - 49.0 * floor(p * ns.z * ns.z);  //  mod(p,7*7)\n\n  vec4 x_ = floor(j * ns.z);\n  vec4 y_ = floor(j - 7.0 * x_ );    // mod(j,N)\n\n  vec4 x = x_ *ns.x + ns.yyyy;\n  vec4 y = y_ *ns.x + ns.yyyy;\n  vec4 h = 1.0 - abs(x) - abs(y);\n\n  vec4 b0 = vec4( x.xy, y.xy );\n  vec4 b1 = vec4( x.zw, y.zw );\n\n  //vec4 s0 = vec4(lessThan(b0,0.0))*2.0 - 1.0;\n  //vec4 s1 = vec4(lessThan(b1,0.0))*2.0 - 1.0;\n  vec4 s0 = floor(b0)*2.0 + 1.0;\n  vec4 s1 = floor(b1)*2.0 + 1.0;\n  vec4 sh = -step(h, vec4(0.0));\n\n  vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy ;\n  vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww ;\n\n  vec3 p0 = vec3(a0.xy,h.x);\n  vec3 p1 = vec3(a0.zw,h.y);\n  vec3 p2 = vec3(a1.xy,h.z);\n  vec3 p3 = vec3(a1.zw,h.w);\n\n//Normalise gradients\n  vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));\n  p0 *= norm.x;\n  p1 *= norm.y;\n  p2 *= norm.z;\n  p3 *= norm.w;\n\n// Mix final noise value\n  vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);\n  m = m * m;\n  return 42.0 * dot( m*m, vec4( dot(p0,x0), dot(p1,x1), \n                                dot(p2,x2), dot(p3,x3) ) );\n  }\n\nvoid main() {\n  float n = snoise(vPosition * scale);\n  gl_FragColor = vec4(1.0 * n, 1.0 * n, 1.0 * n, 1.0);\n}\n```\n\n\nThe above takes a ```\nscale```\n uniform of type float.\n\n```\nvar uniforms = {\n    scale: { type: \"f\", value: 10.0 }\n};\n```\n\n\nMore ShaderMaterial demos\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "\"Stitching\" multiple 2d Arrays\r\n                \r\nEDIT (rephrased question):\nHow would I use the provided smoothstep function to create a gradual transition between adjacent 2d arrays? Each array is the same size and contain values ranging between 0 and 1, having a smooth transition from edge to edge via simplex noise. As a result I'm wanting the difference between adjacent array values to be at maxiumum 0.04\n\n```\nfunction smoothstep (min, max, value) {\n    var x = Math.max(0, Math.min(1, (value-min)/(max-min)));\n    return x*x*(3 - 2*x);\n};\n```\n\n\n\n\nI have 6 2d arrays containing values between 0 and 1 to represent heights on the face of a sphere. To iterate through all values of the arrays i have this: \n\n```\nfor (var i = 0; i < cube.faces.length; i++) {\n    for (var x = 0; x < cube.faces[i].heightMap.length; x++) {\n        for (var z = 0; z < cube.faces[i].heightMap.length; z++) {\n            if (x == 0 || x == cube.faces[i].heightMap.length - 1 || z == 0 || z == cube.faces[i].heightMap.length - 1) {\n                switch (i) {\n                    case 0:\n                        if (x == 0) {\n                            //match left of face 1 to top of face 4\n                        } else if (z == 0) {\n                            //match top of face 1 to top of face 6\n                        } else if (z == cube.faces[i].heightMap.length - 1) {\n                            //match bottom of face 1 to top of face 5\n                        } else {\n                            //match right of face 1 to top of face 3\n                        }\n                        break;\n                    case 1:\n                        if (x == 0) {\n                            //match left of face 2 to bottom of face 3\n                        } else if (z == 0) {\n                            //match top of face 2 to bottom of face 6\n                        } else if (z == cube.faces[i].heightMap.length - 1) {\n                            //match bottom of face 2 to bottom of face 5\n                        } else {\n                            //match right of face 2 to bottom of face 4\n                        }\n                        break;\n                    case 2:\n                        if (x == 0) {\n                            //match left of face 3 to right of face 5\n                        } else if (z == 0) {\n                            //~~match top of face 3 to right of face 1~~\n                        } else if (z == cube.faces[i].heightMap.length - 1) {\n                            //~~match bottom of face 3 to left of face 2~~\n                        } else {\n                            //match right of face 3 to left of face 6\n                        }\n                        break;\n                    case 3:\n                        if (x == 0) {\n                            //match left of face 4 to right of face 6\n                        } else if (z == 0) {\n                            //~~match top of face 4 to left of face 1~~\n                        } else if (z == cube.faces[i].heightMap.length - 1) {\n                            //~~match bottom of face 4 to right of face 2~~\n                        } else {\n                            //match right of face 4 to left of face 5\n                        }\n                        break;\n                    case 4:\n                        break;\n                    case 5:\n                        break;\n                    default:\n                        break;\n                }\n            }\n        }\n    }\n}\n```\n\n\nHowever I'm having some trouble getting the faces to match up. Looking into this i have found a function called \"smoothstep\" which seems to be exactly what i need. i don't know how to implement it, i have yet to find an explanation that is useful to me.\n\n```\nfunction smoothstep(min, max, value) {\n    var x = Math.max(0, Math.min(1, (value - min) / (max - min)));\n    return x * x * (3 - 2 * x);\n};\n```\n\n\nThe following page is where i learned of this method, but i can not make sense of what is trying to be said. if anyone has the time could you explain how i may implement this into my situation? Link to related question\n    ", "Answer": "\r\nRE: Smoothstep, I recreated the function in Python's IDLE interpreter real quick so that I could plug values into it and get instant results, and as near as I can tell, all it does is stretch your min value to 0, your max value to 1, then normalizes the value parameter accordingly.\n\nFor example, if you provide parameters ```\n(0.2, 0.4, 0.3)```\n   0.3 is halfway between 0.2 and 0.4, so the function will normalize the value to approx 0.5\n\nAre you just trying to create a solid gradient of numbers with the 50 array rows/columns that intersect Edge A and Edge B? \n\nIf so, I don't know if smoothstep is the way to go.\n\nRegardless, for something like this, I would get physical and bust out a sheet of paper and draw out something like this with the array id in the middle and label the edges  (Assuming a dice face pattern in the example below):\n\n```\n        |--A--|\n        D  3  B\n        |--C--|\n\n        |--A--|\n        D  1  B\n        |--C--|\n\n|--A--| |--A--| |--A--|\nD  2  B D  4  B D  5  B\n|--C--| |--C--| |--C--|\n\n        |--A--|\n        D  6  B\n        |--C--|\n```\n\n\nThen fold it up in your mind (or cut it out and physically fold up the cube) to find the edge pairs and draw arrows indicating the direction inward into the face from the edge.   (I like to use N(orth), E(ast), S(outh), W(est) to visualize which direction to head from the edge.\n\nHeading direction:\n\n```\nN = Same columnID, Start at max RowID and decrement  (going north)\nE = Same rowID, Start at min ColumnID and increment  (going east)\nS = Same columnID, Start at min RowID and increment  (going south)\nW = Same rowID, Start at max ColumnID and decrement  (going west)\n```\n\n\nYou would end up with a list of something like  ```\nvar list = [1,B,W,, 5,A,S,], [4,B,W,, 5,D,E,]...etc...]```\n  (extra commas are intentional, representing a blank space in the list well fill in next)\n\nNow with that list built out you would grab the value, 25 rows or columns in from the edge in whatever direction you noted for each array, plug it into your list in the blank spaces and you'll have the absolute min and a max values for your gradient. e.g. ```\nvar list = [[1,B,W,0.3, 5,A,S,0.7],...etc...]```\n\n\nThen if it's a solid gradient, you'd just do some easy math ```\nstep_value = Math.abs(list[n][3] - list[n][7])/50```\n   then increment or decrement from your starting value for each edge, in the appropriate direction, depending on whether it's the min or the max.\n\nIf it's more complicated than a straight gradient between 2D array edges, I apologize, but will probably need a better visualization of what you're trying to do.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "What algorithms can I use to optimize in a high dimensional discrete space in Python?\r\n                \r\nI have a matrix D representing a grid of points in a high dimensional space. The number of rows is the number of datapoints, and the number of columns is the dimensionality of the space.\nI have a function f that can take a row of D and outputs a single float value. The function f would be smooth if it could be evaluated at points outside the grid. The function f may have multiple zeros.\nI want to find points (row instances) where the function f is close to zero. I do not want to evaluate the function at every row in D exhaustively, because there are too many rows.\nWhat algorithm and libraries do you recommend for this problem? I would prefer using existing Python libraries to simplify the implementation. I am also interested in finding multiple zeros.\nSo start with, I was thinking of using some type of simplex search, maybe running it multiple times from different starting locations (multi-start). I do not know of libraries that could work on the problem the way it is posed, though.\nThank you very much for your help\n    ", "Answer": "\r\nas you do not want to evaluate f too many time, your problem looks like a black-box function problem. To optimize such a function, there are many tools, like bayesian optimization, that will modelize the shape of your function using gaussian processes (look at \"kriging\" in wikipedia). If your function f values are 1-dimensional, I recommand you to use smt : https://github.com/SMTorg/SMT\nIf there are many objectives, I developped a tool : https://github.com/RobinGRAPIN/smoot. Look at the notebook tutorial to understand its functionment :)\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Matlab linprog yields an unbounded result to a bounded model\r\n                \r\n```\nclear\nA=[-1 0 -1 0; 0 -1 0 -1; 1 1 0 0; 0 0 1 1];\nb=[-50 -70 80 45];\nf=[0.5; 0.6; 0.4; 0.55];\noptions = optimoptions('linprog','Algorithm','dual-simplex');\n[x,fval,exitflag,output] = linprog(f,A,b,[],[],[],[],options);\n```\n\n\nCode shown above produces an unbounded result ```\nProblem is unbounded```\n where Lindo and Excel Solver find the optimal objective function value which is 62.5 \n    ", "Answer": "\r\nThat's correct behaviour taken into account what matlab's ```\nlinprog```\n is doing.\n\nThe reason for this observation is the following:\n\n\n```\nlinprog```\n assumes variables are free ((-inf,inf) if no bound is given) like in your case\n\n\nYour solution (observed with Lindo) is the one, where your solution-vector is constrained to be nonnegative.\n\nThis can be expressed through constraints or using bounds. The docs give the following example:\n\n```\nExample: To specify that all x-components are positive, lb = zeros(size(f))\n    # personal opinion: this should be called \"nonnegative\"   \n```\n\n\nI'm not a Matlab user but using my tools, i can verify that:\n\n\nthe problem without the nonnegativity-constraint / or bounds expressing the same is unbounded\nthe problem with the constraint / bounds has a solution of 62.5\n\n\nRemark: Many mathematical-programming frameworks / solvers assume that the solution-vector is nonnegative by default, which is different from what ```\nlinprog```\n is doing. The former is a consequence of the underlying algorithmic theory.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Matlab linprog yields an unbounded result to a bounded model\r\n                \r\n```\nclear\nA=[-1 0 -1 0; 0 -1 0 -1; 1 1 0 0; 0 0 1 1];\nb=[-50 -70 80 45];\nf=[0.5; 0.6; 0.4; 0.55];\noptions = optimoptions('linprog','Algorithm','dual-simplex');\n[x,fval,exitflag,output] = linprog(f,A,b,[],[],[],[],options);\n```\n\n\nCode shown above produces an unbounded result ```\nProblem is unbounded```\n where Lindo and Excel Solver find the optimal objective function value which is 62.5 \n    ", "Answer": "\r\nThat's correct behaviour taken into account what matlab's ```\nlinprog```\n is doing.\n\nThe reason for this observation is the following:\n\n\n```\nlinprog```\n assumes variables are free ((-inf,inf) if no bound is given) like in your case\n\n\nYour solution (observed with Lindo) is the one, where your solution-vector is constrained to be nonnegative.\n\nThis can be expressed through constraints or using bounds. The docs give the following example:\n\n```\nExample: To specify that all x-components are positive, lb = zeros(size(f))\n    # personal opinion: this should be called \"nonnegative\"   \n```\n\n\nI'm not a Matlab user but using my tools, i can verify that:\n\n\nthe problem without the nonnegativity-constraint / or bounds expressing the same is unbounded\nthe problem with the constraint / bounds has a solution of 62.5\n\n\nRemark: Many mathematical-programming frameworks / solvers assume that the solution-vector is nonnegative by default, which is different from what ```\nlinprog```\n is doing. The former is a consequence of the underlying algorithmic theory.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "In Ipython Qt Console sp.info doesn't print inside the console\r\n                \r\nI have installed IPython 1.1.0, in Ubuntu 12.04 from the source. \n\nSimilarly I have installed Numpy-1.8.0, Scipy-0.13.1, Matplotlib-1.3.1 from the source.\n\nWhen I use the Ipython Qt COnsole the command sp.info(optimize.fmin) doesn't print the output in console but it prints it in the terminal (pylab). Is there anyway that it can print it in console too.\n\n```\nimport numpy as np\nimport scipy as sp\nfrom scipy import optimize\nsp.info(optimize.fmin)\n```\n\n\nThe output is like this in pylab\n\n```\nfmin(func, x0, args=(), xtol=0.0001, ftol=0.0001, maxiter=None, maxfun=None,\nfull_output=0, disp=1, retall=0, callback=None)\nMinimize a function using the downhill simplex algorithm.\nParameters\n----------\nfunc : callable func(x,*args)\n```\n\n    ", "Answer": "\r\nYou can use IPython's ```\n?```\n syntax to get information about any object:\n\n```\noptimize.fmin?\n```\n\n\nThat will work in all IPython environments.\n\nHowever, ```\nscipy.info()```\n and ```\nnumpy.info()```\n both work in the Qt console when I try them, whether or not I start it in pylab mode. I'm not sure why they don't for you.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Finding optimal solution to multivariable function with non-negligible solution time?\r\n                \r\nSo I have this issue where I have to find the best distribution that, when passed through a function, matches a known surface. I have written a script that creates the distribution given some parameters and spits out a metric that compares the given surface to the known, but this script takes a non-negligible time, so I can't just run through a very large set of parameters to find the optimal set of parameters. I looked into the simplex method, and it seems to be the right path, but its not quite what I need, because I dont exactly have a set of linear equations, and dont know the constraints for the parameters, but rather one method that gives a single output (an thats all). Can anyone point me in the right direction to how to solve this problem? Thanks!\n\nTo quickly go over my process / problem again, I have a set of parameters (at this point 2 but will be expanded to more later) that defines a distribution. This distribution is used to create a surface, which is compared to a known surface, and an error metric is produced. I want to find the optimal set of parameters, but cannot run through an arbitrarily large number of parameters due to the time constraint. \n    ", "Answer": "\r\nOne situation consistent with what you have asked is a model in which you have a reasonably tractable probability distribution which generates an unknown value. This unknown value goes through a complex and not mathematically nice process and generates an observation. Your surface corresponds to the observed probability distribution on the observations. You would be happy finding the parameters that give a good least squares fit between the theoretical and real life surface distribution.\n\nOne approximation for the fitting process is that you compute a grid of values in the space output by the probability distribution. Each set of parameters gives you a probability for each point on this grid. The not nice process maps each grid point here to a nearest grid point in the space of the surface. The least squares fit is a quadratic in the probabilities calculated for the first grid, because the probabilities calculated for a grid point in the surface are the sums of the probabilities calculated for values in the first grid that map to something nearer to that point in the surface than any other point in the surface. This means that it has first (and even second) derivatives that you can calculate. If your probability distribution is nice enough you can use the chain rule to calculate derivatives for the least squares fit in the initial parameters. This means that you can use optimization methods to calculate the best fit parameters which require not just a means to calculate the function to be optimized but also its derivatives, and these are generally more efficient than optimization methods which require only function values, such as Nelder-Mead or Torczon Simplex. See e.g. http://commons.apache.org/proper/commons-math/apidocs/org/apache/commons/math4/optim/package-summary.html.\n\nAnother possible approach is via something called the EM Algorithm. Here EM stands for Expectation-Maximization. It can be used for finding maximum likelihood fits in cases where the problem would be easy if you could see some hidden state that you cannot actually see. In this case the output produced by the initial distribution might be such a hidden state. One starting point is http://www-prima.imag.fr/jlc/Courses/2002/ENSI2.RNRF/EM-tutorial.pdf.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Trying to find a good allocation algorithm for a rota\r\n                \r\nTrying to find an allocation problem for a rota of a construction site.\nAround 5 construction sites each with 2-4 people needed.\nAround 40 construction workers.\nRota must follows these rules:\n\nThere are multiple construction sites happening at the same time.\nEvery worker can work at every construction site.\nEvery worker has a set of Boolean qualifications. (e.g. canUseDigger, canUseDrill, ...)\nEach construction site has the need for different qualifications but these needs qualifications will never change.\nThe number of each workers at each site must be fulfilled.\nEven if a worker is not qualified for any of tasks they can still be put onto a site assuming that all other of the site's requirements are complete.\nWorkers have different availability and can only work 5 days a week at most.\n\nThere are few other rules, and could be asked to implement more rules.\nAll of this information is in a database.\nIf anyone has had experience in this area before and have a few algorithms that come to mind I would be very thankful to hear them.\nIf the solution involves AI in some kind that is also a big plus (but is not a necessity)\nLinks to similar problems with open source solutions would be useful as well.\nThanks for reading.\nWasn't really sure where to start with this one. I was thinking about maybe treating it as a linear programming problem and using Simplex. Wasn't sure if it possible to put into an adjacency matrix either and use something like Hungarian. Someone has recommended bipartite graphs to me.\n    ", "Answer": "\r\nA good way to start is to think of your problem as a collection of jobs which can be completed by assigning resources.\nA question that you will need to decide upon is how good a solution you are willing to accept.  The algorithms that guarantee the optimal solution are fiendishly complex and require enormous run times to complete for problems that are larger than half a dozen jobs.  However algorithms with reasonable run times that produce reasonable results ( ~ 90% of the theoretical optimum ) for large problems ( dozens of jobs ) can be found.\nI have some open source code at https://github.com/JamesBremner/schedule which can give you some ideas on how to solve a few of these kind of problems.\nThis input\n```\nr Alice canUseDrill\nr Bob canUseDigger\nr Chad canUseDrill\nr Derek canUseDigger\nr Eric canUseDrill\nr Fiona canUseDigger\nr George canUseDrill\nr Hal canUseDigger\nr gw1\nr gw2\nr gw3\nr gw4\nr gw5\nr gw6\nr gw7\nr gw8\nr gw9\nj A 4 canUseDrill canUseDigger\nj B 3 canUseDigger\nj C 2 canUseDrill\nj D 4 canUseDrill canUseDigger\nj E 2 canUseDigger\nj F 2 canUseDrill\n```\n\ngenerates this output\n\nNote that in my code every resource ( == worker ) has exactly one type ( == skill ). Your feature 3 ( Every worker has a set of Boolean qualifications ) implies that resources can have multiple types.  This is a significant additional complication, since the algorithm will have to make decisions about which job ( == site ) to assign a worker who has multiple skills in demand at multiple sites.\nPerhaps the best way to handle this is to rank the skills in order of decreasing demand and assign workers with high demand skills first.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Scipy: Linear programming with sparse matrices\r\n                \r\nI want to solve a linear program in python. The number of variables (I will call it N from now on) is very large (~50000) and in order to formulate the problem in the way ```\nscipy.optimize.linprog```\n requires it, I have to construct two N x N matrices (```\nA```\n and ```\nB```\n below). The LP can be written as\n\n```\nminimize: c.x\nsubject to:\n    A.x <= a\n    B.x  = b\n    x_i >= 0 for all i in {0, ..., n}\n```\n\n\nwhereby ```\n.```\n denotes the dot product and ```\na```\n, ```\nb```\n, and ```\nc```\n are vectors with length N.\n\nMy experience is that constructing such large matrices (```\nA```\n and ```\nB```\n have both approx. 50000x50000 = 25*10^8 entries) comes with some issues: If the hardware is not very strong, NumPy may refuse to construct such big matrices at all (see for example Very large matrices using Python and NumPy) and even if NumPy creates the matrix without problems, there is a huge performance issue. This is natural regarding the huge amount of data NumPy has to deal with. \n\nHowever, even though my linear program comes with N variables, the matrices I work with are very sparse. One of them has only entries in the very first row, the other one only in the first M rows, with M < N/2. Of course I would like to exploit this fact.\n\nAs far as I have read (e.g. Trying to solve a Scipy optimization problem using sparse matrices and failing), ```\nscipy.optimize.linprog```\n does not work with sparse matrices. Therefore, I have the following questions:\n\n\nIs it actually true that SciPy does not offer any possibility to solve a linear program with sparse matrices? (If not, how can I do it?)\nDo you know any alternative library that will solve the problem more effectively than SciPy with non-sparse matrices? (The library suggested in the thread above seems to be not flexible enough for my purposes - as far as I understand its documentation)\nCan it be expected that a new implementation of the simplex algorithm (using plain Python, no C) that exploits the sparsity of the matrices will be more efficient than SciPy with non-sparse matrices?\n\n    ", "Answer": "\r\nI would say forming a dense matrix (or two) to solve a large sparse LP is probably not the right thing to do. When solving a large sparse LP it is important to use a solver that has facilities to handle such problems and also to generate the model in a way that does not create explicitly any of these zero elements.\n\nWriting a stable, fast, sparse Simplex LP solver in Python as a replacement for the SciPy dense solver is not a trivial exercise. Moreover a solver written in pure Python may not perform as well.  \n\nFor the size you indicate, although not very, very large (may be large medium sized model would be a good classification) you may want to consider a commercial solver like Cplex, Gurobi or Mosek. These solvers are very fast and very reliable (they solve basically any LP problem you throw at them). They all have Python APIs. The solvers are free or very cheap for academics.\n\nIf you want to use an Open Source solver, you may want to look at the COIN CLP solver. It also has a Python interface. \n\nIf your model is more complex then you also may want to consider to use a Python modeling tool such as Pulp or Pyomo (Gurobi also has good modeling support in Python).\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Checking which triangles intersect a convex hull\r\n                \r\nI have a bunch of 2D triangles (i.e., in R2), as well as a 2D convex hull (represented as a set of linear constraints), and I need to check which of those triangles intersect the convex hull. What algorithms are there for doing this?\n\nAt a later stage, I might also need to generalize the problem to higher dimensions than 2D (i.e., out of a set of simplexes in Rd, check which of those intersect a convex hull in Rd), so if you know of an algorithm that can handle the general case that would also be nice.\n    ", "Answer": "\r\nYou can solve the 2D problem in two steps:\n\n\nconstruct the vertices of the convex hull;\nintersect the triangles and the hull, which are both convex polygons (https://www.bowdoin.edu/~ltoma/teaching/cs3250-CompGeom/spring17/Lectures/cg-convexintersection.pdf). The time for intersection will be O(N) for a hull of N vertices.\n\n\nIf you need to do this for many triangles, a possibility is to decompose the hull in two monotone chains along along an axis, say X, and find the overlap range of the hull and every triangle by dichotomic search. This will lower the time to O(Log N + K) where K is the average number of sides of the hull in X-overlap with the triangles.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Normalising parameter scale with fminsearch\r\n                \r\nI remember reading once in the Matlab documentation about an optimisation algorithm which allowed the user to specify the \"scale\" of variation expected for each parameter during the search (at least initially).\n\nI can't remember what this function is, but now I am using ```\nfminsearch```\n and there is no such option. In fact, I can't even specify parameter bounds, and the documentation states that it takes 5% of the initial guess as a default step (or 25e-5 if 0). Because this seems to be a relative choice to the initial guess, it makes me think that perhaps I should re-normalise my parameters to a suitable scale, in order to indirectly define a suitable step for my optimisation problem.\n\nFor example, if I have a parameter which value is on the order of 10e5 but that I would like steps on the order of 100, then I should \"divide it\" by 500 during optimisation (obviously I would then multiply it when computing the objective function). However this becomes trickier if a parameter range is centred around 0 for example; then I can rescale it and offset it.\n\nMy question is; is it effectively what people usually do when using the downhill-simplex method, and is there a \"standard\" or \"better\" way to do it?\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Connect points to plane/Draw Polygon\r\n                \r\nI'm currently working on a project where I want to draw different mathematical objects onto a 3D cube. It works as it should for Points and Lines given as a vector equation. Now I have a plane given as a parametric equation. This plane can be somewhere in the 3D space and may be visible on the screen, which is this 3D cube. The cube acts as an AABB.\n\nFirst thing I needed to know was whether the plane intersects with the cube. To do this I made lines who are identical to the edges of this cube and then doing 12 line/plane intersections, calculating whether the line is hit inside the line segment(edge) which is part of the AABB. Doing this I will get a set of Points defining the visible part of the plane in the cube which I have to draw.\n\nI now have up to 6 points A, B, C, D, E and F defining the polygon ABCDEF I would like to draw. To do this I want to split the polygon into triangles for example: ABC, ACD, ADE, AED. I would draw this triangles like described here. The problem I am currently facing is, that I (believe I) need to order the points to get correct triangles and then a correctly drawn polygon. I found out about convex hulls and found QuickHull which works in three dimensional space. There is just one problem with this algorithm: At the beginning I need to create a three dimensional simplex to have a starting point for the algorithm. But as all my points are in the same plane they simply form a two dimensional plane. Thus I think this algorithm won't work.\n\nMy question is now: How do I order these 3D points resulting in a polygon that should be a 2D convex hull of these points? And if this is a limitation: I need to do this in C.\n\nThanks for your help!\n    ", "Answer": "\r\nOne approach is to express the coordinates of the intersection points in the space of the plane, which is 2D, instead of the global 3D space. Depending on how exactly you computed these points, you may already have these (say (U, V)) coordinates. If not, compute two orthonormal vectors that belong to the plane and take the dot products with the (X, Y, Z) intersections. Then you can find the convex hull in 2D.\n\nThe 8 corners of the cube can be on either side of the plane, and have a + or - sign when the coordinates are plugged in the implicit equation of the plane (actually the W coordinate of the vertices). This forms a maximum of 2^8=256 configurations (of which not all are possible).\n\nFor efficiency, you can solve all these configurations once for all, and for every case list the intersections that form the polygon in the correct order. Then for a given case, compute the 8 sign bits, pack them in a byte and lookup the table of polygons.\n\n\n\nUpdate: direct face construction.\n\nAlternatively, you can proceed by tracking the intersection points from edge to edge.\n\nStart from an edge of the cube known to traverse the plane. This edge belongs to two faces. Choose one arbitrarily. Then the plane cuts this face in a triangle and a pentagon, or two quadrilaterals. Go to the other the intersection with an edge of the face. Take the other face bordered by this new edge. This face is cut in a triangle and a pentagon...\n\nContinuing this process, you will traverse a set of faces and corresponding segments that define the section polygon.\n\n\n\nIn the figure, you start from the intersection on edge HD, belonging to face DCGH. Then move to the edge GC, also in face CGFB. From there, move to edge FG, also in face EFGH. Move to edge EH, also in face ADHE. And you are back on edge HD.\n\nComplete discussion must take into account the case of the plane through one or more vertices of the cube. (But you can cheat by slightly translating the plane, constructing the intersection polygon and removing the tiny edges that may have been artificially created this way.)\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Procedural terrain programming in Unity 3D\r\n                \r\nI am trying to get along with procedural generation, I definitely not a pro in unity, however I was following this guide: click  and got some results. For now I have 2 problems, I have some basic idea how to resolve them, however I would like to hear some other opinions.\n\n(I have already posted this question on Unity answers, however I have got no response at all, if there is some missing information or it is impossible to explain in a few words, please let me know or give some advice how to find this information)\n\nThe main issue is : gaps between chunks:\n\n\n\nthey kinda disappear if I will zoom, however textures remain unfit and it is remarkable.\n\nThe second, as you can see I have a problem with red (I don't really know how to call it) marks on the ground. I have tried to use material from guide, but got same effect.\n\nBesides, Perlin Noise ( I know that I can use Diamond square or simplex) is pseudo-random algorithm, so it will return the same values for the same input parameters, so does it mean that my chunks will always be the same?\n\nMy code ( I am using LibNoise library from guide):\n\n```\n    void Awake()\n    {\n        var settings = new TerrainChunkSettings(129, 129, 100, 40, FlatTexture, SteepTexture, TerrainMaterial);\n        var noiseProvider = new NoiseProvider();\n        for (var i = 0; i < 4; i++)\n            for (var j = 0; j < 4; j++)\n                new TerrainChunk(settings, noiseProvider, i, j).CreateTerrain();\n    }\npublic class TerrainChunkSettings\n{\n    public int HeightmapResolution { get; private set; }\n\n    public int AlphamapResolution { get; private set; }\n\n    public int Length { get; private set; }\n\n    public int Height { get; private set; }\n\n    public Texture2D FlatTexture { get; private set; }\n\n    public Texture2D SteepTexture { get; private set; }\n\n    public Material TerrainMaterial { get; private set; }\n\n    public TerrainChunkSettings(int heightmapResolution, int alphamapResolution, int length, int height, Texture2D flatTexture, Texture2D steepTexture, Material terrainMaterial)\n    {\n        HeightmapResolution = heightmapResolution;\n        AlphamapResolution = alphamapResolution;\n        Length = length;\n        Height = height;\n        FlatTexture = flatTexture;\n        SteepTexture = steepTexture;\n        TerrainMaterial = terrainMaterial;\n    }\n}\n\npublic class TerrainChunk\n{\n    private Terrain Terrain { get; set; }\n\n    private TerrainChunkSettings Settings { get; set; }\n\n    private NoiseProvider NoiseProvider { get; set; }\n\n    public int X { get; private set; }\n\n    public int Z { get; private set; }\n\n    private TerrainData Data { get; set; }\n\n    private float[,] Heightmap { get; set; }\n    public TerrainChunk(TerrainChunkSettings settings, NoiseProvider noiseProvider, int x, int z)\n    {\n        X = x;\n        Z = z;\n        Settings = settings;\n        NoiseProvider = noiseProvider;\n    }\n\n    public void CreateTerrain()\n    {\n        var terrainData = new TerrainData();\n        terrainData.heightmapResolution = Settings.HeightmapResolution;\n        terrainData.alphamapResolution = Settings.AlphamapResolution;\n\n        var heightmap = GetHeightmap();\n        terrainData.SetHeights(0, 0, heightmap);\n        ApplyTextures(terrainData);\n        terrainData.size = new Vector3(Settings.Length, Settings.Height, Settings.Length);\n\n        var newTerrainGameObject = Terrain.CreateTerrainGameObject(terrainData);\n        newTerrainGameObject.transform.position = new Vector3(X * Settings.Length, 0, Z * Settings.Length);\n        Terrain = newTerrainGameObject.GetComponent<Terrain>();\n        Terrain.Flush();\n    }\n\n    private float[,] GetHeightmap()\n    {\n        var heightmap = new float[Settings.HeightmapResolution, Settings.HeightmapResolution];\n\n        for (var zRes = 0; zRes < Settings.HeightmapResolution; zRes++)\n        {\n            for (var xRes = 0; xRes < Settings.HeightmapResolution; xRes++)\n            {\n                var xCoordinate = X + (float)xRes / (Settings.HeightmapResolution - 1);\n                var zCoordinate = Z + (float)zRes / (Settings.HeightmapResolution - 1);\n\n                heightmap[zRes, xRes] = NoiseProvider.GetValue(xCoordinate, zCoordinate);\n            }\n        }\n\n        return heightmap;\n    }\n\n    private void ApplyTextures(TerrainData terrainData)\n    {\n        var flatSplat = new SplatPrototype();\n        var steepSplat = new SplatPrototype();\n\n        flatSplat.texture = Settings.FlatTexture;\n        steepSplat.texture = Settings.SteepTexture;\n\n        terrainData.splatPrototypes = new SplatPrototype[]\n        {\n            flatSplat,\n            steepSplat\n        };\n\n        terrainData.RefreshPrototypes();\n\n        var splatMap = new float[terrainData.alphamapResolution, terrainData.alphamapResolution, 2];\n\n        for (var zRes = 0; zRes < terrainData.alphamapHeight; zRes++)\n        {\n            for (var xRes = 0; xRes < terrainData.alphamapWidth; xRes++)\n            {\n                var normalizedX = (float)xRes / (terrainData.alphamapWidth - 1);\n                var normalizedZ = (float)zRes / (terrainData.alphamapHeight - 1);\n\n                var steepness = terrainData.GetSteepness(normalizedX, normalizedZ);\n                var steepnessNormalized = Mathf.Clamp(steepness / 1.5f, 0, 1f);\n\n                splatMap[zRes, xRes, 0] = 1f - steepnessNormalized;\n                splatMap[zRes, xRes, 1] = steepnessNormalized;\n            }\n        }\n\n        terrainData.SetAlphamaps(0, 0, splatMap);\n    }\n}\n\npublic interface INoiseProvider\n{\n    float GetValue(float x, float z);\n}\npublic class NoiseProvider : INoiseProvider\n{\n    private Perlin PerlinNoiseGenerator;\n\n    public NoiseProvider()\n    {\n        PerlinNoiseGenerator = new Perlin();\n    }\n\n    public float GetValue(float x, float z)\n    {\n        return (float)(PerlinNoiseGenerator.GetValue(x, 0, z) / 2f) + 0.5f;\n    }\n}\n```\n\n    ", "Answer": "\r\n1) The main issue is : gaps between chunks\n\nYou can stitch terrain together to ensures they get the same LOD with ```\nSetNeighbors(Terrain left, Terrain top, Terrain right, Terrain bottom);```\n\n\nFrom the documentation:\n\n\n  Lets you setup the connection between neighboring Terrains.\n  \n  This ensures LOD matches up on neighboring terrains. Note that it is\n  not enough to call this function on one Terrain, you need to set the\n  neighbors of each terrain.\n\n\n2) The second: red marks on the ground\n\nThis problem should come from the textures you are using in your terrain object.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "What is the best way for \"Polling\"?\r\n                \r\nThis question is related with Microcontroller programming but anyone may suggest a good algorithm to handle this situation.\n\nI have a one central console and set of remote sensors. The central console has a receiver and the each sensor has a transmitter operates on same frequency. So we can only implement Simplex communication. \n\nSince the transmitters work on same frequency we cannot have 2 sensors sending data to central console at the same time.\n\nNow I want to program the sensors to perform some \"polling\". The central console should get some idea about the existence of sensors (Whether the each sensor is responding or not)\n\nI can imagine several ways.\n\n\nUsing a same interval between the poll messages for each sensor and start the sensors randomly. So they will not transmit at the same time.\nUse of some round mechanism. Sensor 1 starts polling at 5 seconds the second at 10 seconds etc. More formal version of method 1.\n\n\nThe maximum data transfer rate is around 4800 bps so we need to consider that as well.\n\nCan some one imagine a good way to resolve this with less usage of communication links. Note that we can use different poll intervals for each sensors if necessary.\n    ", "Answer": "\r\nI presume what you describe is that the sensors and the central unit are connected to a bus that can deliver only one message at a time.\n\nA normal way to handle this is to have collision detection. This is e.g. how Ethernet operates as far as I know. You try to send a message; then attempt to detect collision. If you detect a collision, wait for a random amount (to break ties) and then re-transmit, of course with collision check again.\n\nIf you can't detect collisions, the different sensors could have polling intervals that are all distinct prime numbers. This would guarantee that every sensor would have dedicated slots for successful polling. Of course there would be still collisions, but they wouldn't need to be detected. Here example with primes 5, 7 and 11:\n\n```\n ----|----|----|----|----|----|----|----| (5)\n ------|------|------|------|------|----- (7)\n ----------|----------|----------|-:----- (11)\n                                   * COLLISION\n```\n\n\nNotable it doesn't matter if the sensor starts \"in phase\" or \"out of phase\".\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "linear programming explanation in algorithms by Sanjoy Dasgupta\r\n                \r\nI am reading simplex algorithm in text book titled Algorithms by Dasgupta-Papadimitriou-Vairani\n\n\n  On each iteration, simplex has two tasks:\n  1. Check whether the current vertex is optimal (and if so, halt).\n  2. Determine where to move next.\n  \n  As we will see, both tasks are easy if the vertex happens to be at the\n  origin. And if the vertex is elsewhere, we will transform the\n  coordinate system to move it to the origin!\n  \n  First let's see why the origin is so convenient. Suppose we have some\n  generic LP\n  \n  max c transpose *  x Ax <= b x >= 0\n  \n  where x is the vector of variables, x = (x1; : : : ; xn). Suppose the\n  origin is feasible. Then it is certainly a vertex, since it is the\n  unique point at which the n inequalities {x1>=0, ..., xn>=0 } are\n  tight.\n  \n  Now let's solve our two tasks. Task 1: \n  \n  The origin is optimal if and only if all ci <= 0\n  \n  If all ci <= 0, then considering the constraints x>=0, we can't hope\n  for a better objective value. Conversely, if some ci > 0, then the\n  origin is not optimal, since we can increase the objective function by\n  raising xi.\n  \n  Thus, for task 2, we can move by increasing some xi for which ci > 0.\n  How much can we increase it? Until we hit some other constraint. That\n  is, we release the tight constraint xi >= 0 and increase xi until some\n  other inequality, previously loose, now becomes tight. \n  \n  At that point, we again have exactly n tight inequalities, so we are\n  at a new vertex.\n  \n  For instance, suppose we're dealing with the following linear program.\n\n\n```\n> max 2x1 + 5x2 2x1 - x2 <= 4 ----> Eq  1\n x1 + 2x2 <= 9 ----> Eq  2\n> -x1 + x2 <= 3 -----> Eq  3\n x1 >= 0 -----------> Eq  4\n  x2 >= 0 -----------> Eq  5\n```\n\n\n\n  Simplex can be started at the origin, which is specied by constraints\n  4 and  5 . To move, we release the tight constraint x2 >= 0. As x2 is\n  gradually increased, the first constraint it runs into is -x1 + x2 <=\n  3, and thus it has to stop at x2 = 3, at which point this new\n  inequality is tight. The new vertex is thus given by Eq  3 and Eq \n  4.\n  \n  So we know what to do if we are at the origin. But what if our current\n  vertex u is elsewhere? The trick is to transform u into the origin, by\n  shifting the coordinate system from the usual (x1, ..., xn) to the\n  local view from u. These local coordinates consist of (appropriately\n  scaled) distances y1, ..., yn to the n hyperplanes (inequalities) that\n  define and enclose u:\n\n```\n               u\n              / \\\n             /   \\\n            /    /\\\n           /    /y1\\\n          /----x    \\\n            y2\n```\n\n  \n  Specifically, if one of these enclosing inequalities is ai * x <= bi,\n  then the distance from a point x to that particular \"wall\" is yi =\n  bi -  ai * x\n  \n  The n equations of this type, one per wall, define the yi's as linear\n  functions of the xi's, and this relationship can be inverted to\n  express the xi's as a linear function of the yi's. Thus we can rewrite\n  the entire LP in terms of the y's. This doesn't fundamentally change\n  it (for instance, the optimal value stays the same), but expresses it\n  in a different coordinate frame. The revised local LP has the\n  following three properties:\n  \n  The revised local LP has the following three properties:\n  1. It includes the inequalities y >= 0, which are simply the transformed versions of the inequalities defining u.\n  2. u itself is the origin in y-space.\n  3. The cost function becomes max cu + ~cT * y, where cu is the value of the objective function at u and ~c is a transformed cost vector.\n\n\nI am having difficulty in understanding trick in above statement mentioned below:\n\nThe trick is to transform u into the origin, by shifting the coordinate system from the\nusual (x1, ..., xn) to the local view from u. These local coordinates consist of (appropriately\nscaled) distances y1, ..., yn to the n hyperplanes (inequalities) that define and enclose u:\n\nWhat does author mean by shifting coordinate system to local view from \"u\" in above statement?\n\nWhat does local coordinates consist of distances to the n hyper planes mean?\n\nKindly explain\n\nThanks in advance for your time and help\n    ", "Answer": "\r\nThis is a geometric interpretation of multiplying with the inverse of the basis matrix.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "vector of n numbers around a specific number\r\n                \r\nI'm trying to do an algorithm in Matlab to try to calculate a received power in dBm of a logarithmic model of a wireless telecommunication system..\n\nMy algorithm calculate the received power for a number of distances in km that the user specified in the input and stores it in a vector\n\nvector_distances = { 1, 5, 10, 50, 75 }\nvector_Prx = { 131.5266  145.5060  151.5266  165.5060  169.0278 }\n\nThe thing is that I almost have everything that I need, but for graphics purposes I need to plot a graph in where on the x axys I have my vector of receiver power but on the y axys I want to show the same received power but with the most complete logarithmic model (the one that have also the noise - with Log-normal distribution on the formula - but for this thing in particular for every distance in my vector I need to choose 50 numbers with 0.5 distance between them (like a matrix) and then for every new point in the same distance calculate the logarithmic model to later plot in the same graph the two functions, one with the model with no noise (a straight line) and one with the noise.. like this picture\n\n!https://i.stack.imgur.com/GpIAN.jpg\n\nMy question is, is there a way to choose 50 numbers with 0.5 distance between them for an existing number?\n\nI know for example, if you have a vector\n\n```\nEDU>> m = zeros(1,5)\n\nm =\n\n     0     0     0     0     0\n\nEDU>> v = 5 %this is the starter distance%\n\nv =\n\n     5\n\nEDU>> m(1) = 5\n\nm =\n\n     5     0     0     0     0\n\n% I want to create a vector with 5 numbers with 0.5 distance between them %\nEDU>> for i=2:5\nm(i) = m(i-1) + 0.5\nend\nEDU>> m\n\nm =\n\n    5.0000    5.5000    6.0000    6.5000    7.0000\n```\n\n\nBut I have two problems, the firs one is, could this be more simplex? I am new on Matlab..and the other one, could I create a vector like this (with the initial number in the center)\n\n```\nEDU>> m\n\nm =\n\n   4.0000   4.5000   **5.0000**    5.5000   6.0000\n```\n\n\nSorry for my english, and thank you so much for helping me\n    ", "Answer": "\r\nIn MATLAB, if you want to create a vector from a number ```\nn```\n to a number ```\nm```\n, you use the format\n\n```\nA = 5:10;\n% A = [5,6,7,8,9,10]\n```\n\n\nYou can also specify the step of the vector by including a third argument between the other two, like so:\n\n```\nA = 5:0.5:10;\n% A = [5,5.5,6,6.5,7,7.5,8,8.5,9,9.5,10]\n```\n\n\nYou can also use this to count backwards:\n\n```\nA = 10:-1:5\n% A = [10,9,8,7,6,5] \n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Terrain Generation with Realistic Height Map\r\n                \r\nI am having troubles finding out the best way to add realism to a terrain generator. At this point I have a flood fill that works perfectly, however if I want to add any sort of realism I will need to add in height variables. I have seen the following methods attempted to make heightmaps:\n\n\nTectonic Plates https://experilous.com/1/blog/post/procedural-planet-generation\nSimplex/Perlin Noise\nDiamond-Square Algoritm\n\n\nRight now I am generating plates through my flood fill, but I am not sure where to go from there.\n\nI am not sure about using a noise function just due to the fact that I would need to generate biomes within a continent to make it look realistic (A continent with just mountains would be unrealistic). The diamond square algorithm probably isn't going to work for my needs because I would like to be flexible in sizing. \n\nWhat is my best option for generating a height map if I have square tiles to give some realism, not very resource intensive, and keep the code I have?\n\nHere is an image of the generation, and the generation code is in the Github project:\nhttps://github.com/Hunterb9101/TileWorkspace/blob/59fe1f28f019d7128c970772d1ef6bd30d63072c/Generation.png\n    ", "Answer": "\r\ntldr: I would use a perlin noise generation with some tacked on biomes. \n\nThis article/tutorial goes over code snippets and their implementation methods. Suggesting the best algorithm for your task depends entirely on your skill and end result goals. \n\nHowever a brief description of perlin noise and using it with realistic aims in mind...\n\n\n  As with most terrain generation, noise functions are your friend -\n  Perlin and/or simplex noise in particular. I've implemented some\n  planetary terrain generation algorithms and although they are in 2d,\n  the resulting height / \"texture\" map could be projected to a sphere\n  rather easily. I assume conversion to hex format is not an issue\n  either.\n  \n  My technique has been creating multiple noise layers, e.g. temperature\n  and humidity. Temperature is fused with a latitude coordinate, in\n  order to make the equator more hot and poles cold, while the noise\n  makes sure it's not a simple gradient. The final terrain type is\n  selected by rules like \"if hot and not humid then pick desert\". You\n  can see my JavaScript implementation of this here:\n  https://github.com/tapio/infiniverse/blob/master/js/universe/planet-aerial.js\n  \n  As for the water percentage, you can just adjust the water level\n  height as noise functions tend to have a constant average. Another\n  option is to apply an exponent filter (useful also when generating\n  clouds, see my implementation here).\n  \n  Another way to generate spherical terrain that came into mind (haven't\n  tested) is to use 3d noise and sample it from a surface of a sphere,\n  using the resulting value as the ground height at that point. You can\n  then weight that according to amount of water on planet and the\n  latitude coordinate.\n  \n  I'll end with a link to one practical implementation of 3d planetary\n  terrain generation:\n  http://libnoise.sourceforge.net/tutorials/tutorial8.html\n\n\nTo generate any random style of realistic terrain you are going to have to use noise of some kind. In past projects I myself have used the diamond square algorithm. However that was to simply generate heightmaps. \n\nFor some more light reading I would check out this article about realistic terrain techniques. \n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Matplotlib - Extract 2D contour of a 3D polygons plot\r\n                \r\nI have a 3D plot defined by a set of Poly3DCollection. Each polygon of the collection holds a list of 3D simplices (a simplex = 4 points) like the following.\n\n```\n[[[21096.4, 15902.1, 74.3],  \n  [21098.5, 15904.3, 54.7],\n  [21114.2, 15910.1, 63.0],\n  [21096.4, 15902.1, 74.3]],\n  ...\n [[21096.4, 15902.1, 74.3],\n  [21114.8, 15909.9, 91.3],\n  [21114.2, 15910.1, 63.0],\n  [21096.4, 15902.1, 74.3]]]\n```\n\n\nFrom theses collections, I plot a 3D mesh giving me this result\n\n\nI would like to determine the contour of this 3D mesh when projected on 2D for plotting it on a screen, in order to highlight it. \nIdeally it would give me something like\n\n\nIs there any way to achieve this ?\n\nTo achieve it I was thinking about something like \n\n\nGetting the 2D coordinates of my 3D points once projected on the visualization plane, by multiplying each point by a projection matrix that matplotlib must have internally for final rendering\nOR \ndirectly get the projected 2D coordinates from matplotlib internals, by I don't know if it is possible.\nApplying some kind of 2D contour detection algorithm to the 2D coordinates from step 1\nAdd the 2D contour found at step 2 to the existing 3D plot\n\n\nHowever I don't find any way to implement this contour detection from the interface exposed by my matplotlib Axes3D object.\n\nAs long as I can achieve plotting the 2D contour, it doesn't matter to me if I determine it directly on my original 3D dataset and the projection or from my matplotlib Axes3D object.\n    ", "Answer": "\r\nThis turned out to be much more complicated than I at first anticipated. The way I solved it was to first rotate the object into a frontal view (in terms of the ```\nAxes3D```\n ```\nelev```\n and ```\nazim```\n angles), projected it onto the y-z-plane, compute the 2D outline, re-add the third dimension and then rotating the now 3D outline back into the current view. \n\nThe rotation part can be accomplished with simple matrix operation, one only has to take care that the x, y, and z axes may be stretched and need to be un-stretched before rotation.\n\nThe projection part was a bit tricky, as I don't know of any clever way to find the outer points of such a large collection of points. I therefore solved it by calculating the projection of each simplex separately, compute their 2D convex hulls (using ```\nscipy```\n), convert them into ```\nshapely```\n polygons, and finally compute the union of all these polygons. I then added back the missing x-coordinate and rotated the entire thing back into the current view.\n\nBy default, ```\nAxes3D```\n objects use perspective, causes the actual outline of the object to not align perfectly with the computed projection. This can be avoided by using an orthogonal view (set with ```\nax.set_proj_type('ortho')```\n).\n\nFinally, once the image is rotated, the outline/projection needs to be updated. I therefore added the entire function to the event queue following this example.\n\nPlease ask if there are any further questions.\n\n```\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection, Line3DCollection\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nfrom shapely.geometry import Polygon\nfrom scipy.spatial import ConvexHull\n\nfrom scipy.spatial import Delaunay\n\n##the figure\nfig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n\n##generating some random points:\npoints = np.random.rand(50,3)\nxmin,xmax = 0,100\nymin,ymax = -10,10\nzmin,zmax = -20,20\npoints[:,1] = (points[:,1]*(ymax-ymin)+ymin) * np.sin(points[:,0]*np.pi)\npoints[:,2] = (points[:,2]*(zmax-zmin)+zmin) * np.sin(points[:,0]*np.pi)\npoints[:,0] *= 100\n\n\n##group them into simlices\ntri =  Delaunay(points)\nsimplex_coords = np.array([tri.points[simplex] for simplex in tri.simplices])\n\n##plotting the points\nax.scatter(points[:,0], points[:,1], points[:,2])\n\n##visualizing simplices\nline_coords = np.array(\n    [[c[i],c[j]] for c in simplex_coords for i in range(len(c)) for j in range(i+1,len(c))]\n)\nsimplex_lines = Line3DCollection(line_coords, colors='k', linewidths=1, zorder=10)\nax.add_collection3d(simplex_lines)    \n\n##adjusting plot\nax.set_xlim([xmin,xmax])\nax.set_xlabel('x')\nax.set_ylim([2*ymin,2*ymax])\nax.set_ylabel('y')\nax.set_zlim([2*zmin,2*zmax])\nax.set_zlabel('z')\n\n\ndef compute_2D_outline():\n    \"\"\"\n    Compute the outline of the 2D projection of the 3D mesh and display it as\n    a Poly3DCollection or a Line3DCollection.\n    \"\"\"\n\n    global collection\n    global lines\n    global elev\n    global azim\n\n    ##remove the previous projection (if it has been already created)\n    try:\n        collection.remove()\n        lines.remove()\n    except NameError as e:\n        pass\n\n\n    ##storing current axes orientation\n    elev = ax.elev\n    azim = ax.azim\n\n    ##convert angles\n    theta = -ax.elev*np.pi/180\n    phi = -ax.azim*np.pi/180\n\n    #the extend of each of the axes:\n    diff = lambda t: t[1]-t[0]\n    lx = diff(ax.get_xlim())\n    ly = diff(ax.get_ylim())\n    lz = diff(ax.get_zlim())\n\n    ##to compute the projection, we 'unstretch' the axes and rotate them\n    ##into the (elev=0, azmi=0) orientation\n    stretch = np.diag([1/lx,1/ly,1/lz])\n    rot_theta = np.array([\n        [np.cos(theta), 0, -np.sin(theta)],\n        [0, 1, 0],\n        [np.sin(theta), 0,  np.cos(theta)],\n    ])\n    rot_phi = np.array([\n        [np.cos(phi), -np.sin(phi), 0],\n        [np.sin(phi),  np.cos(phi), 0],\n        [0,0,1],\n    ])\n    rot_tot = np.dot(rot_theta,np.dot(rot_phi,stretch))\n\n    ##after computing the outline, we will have to reverse this operation:\n    bstretch = np.diag([lx,ly,lz])\n    brot_theta = np.array([\n        [ np.cos(theta), 0, np.sin(theta)],\n        [0, 1, 0],\n        [-np.sin(theta), 0, np.cos(theta)],\n    ])\n    brot_phi = np.array([\n        [ np.cos(phi),  np.sin(phi), 0],\n        [-np.sin(phi),  np.cos(phi), 0],\n        [0,0,1],\n    ])\n    brot_tot = np.dot(np.dot(bstretch,brot_phi),brot_theta)\n\n    ##To get the exact outline, we will have to compute the projection of each simplex\n    ##separately and compute the convex hull of the projection. We then use shapely to\n    ##compute the unity of all these convex hulls to get the projection (or shadow).\n    poly = None\n    for simplex in simplex_coords:\n        simplex2D = np.dot(rot_tot,simplex.T)[1:].T\n        hull = simplex2D[ConvexHull(simplex2D).vertices]\n        if poly is None:\n            poly = Polygon(hull)\n        else:\n            poly = poly.union(Polygon(hull))\n\n    ##the 2D points of the final projection have to be made 3D and transformed back\n    ##into the correct axes rotation\n    outer_points2D = np.array(poly.exterior.coords.xy)\n    outer_points3D = np.concatenate([[np.zeros(outer_points2D.shape[1])],outer_points2D])    \n    outer_points3D_orig = np.dot(brot_tot, outer_points3D)\n\n    ##adding the polygons\n    collection = Poly3DCollection(\n        [outer_points3D_orig.T], alpha=0.25, facecolor='b', zorder=-1\n    )\n    ax.add_collection3d(collection)\n\n    ##adding the lines\n    lines = Line3DCollection(\n        [outer_points3D_orig.T], alpha=0.5, colors='r', linewidths=5, zorder=5\n    )\n    ax.add_collection3d(lines)    \n\n\ndef on_move(event):\n    \"\"\"\n    For tracking rotations of the Axes3D object\n    \"\"\"\n\n    if event.inaxes == ax and (elev != ax.elev or azim != ax.azim):\n        compute_2D_outline()        \n    fig.canvas.draw_idle()\n\n##initial outline:\ncompute_2D_outline()\n\n##the entire thing will only work correctly with an orthogonal view\nax.set_proj_type('ortho')\n\n##saving ax.azim and ax.elev for on_move function\nazim = ax.azim\nelev = ax.elev\n\n##adding on_move to the event queue\nc1 = fig.canvas.mpl_connect('motion_notify_event', on_move)\n\nplt.show()\n```\n\n\nThe final result (with some generated random data) looks something like this:\n\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Graph partitioning optimization\r\n                \r\nThe problem\n\nI have a set of locations on a plane (actually they are pins in a KML file) and I want to partition this graph into subgraphs. Connectivity is pretty good - as with all real world road networks - so I assume that if two locations are close they have some kind of connection. The resulting set of subgraphs should adhere to these constraints:\n\n\nEvery node has to be covered by a subgraph\nEvery node should be in exactly 1 subgraph\nEvery node within a subgraph should be close to each other (L2 norm distances)\nEvery subgraph should contain at least 5 locations\nThe amount of subgraphs should be minimal\n\n\nRight now the amount of locations is no more than 100 so I thought about brute forcing through every possibility but this obviously won't scale well.\n\nI thought about using some k-Nearest-Neighbors algorithm (e.g. using QuickGraph) but I can't get my head around where to start and how to extend/shrink the subgraphs on the way. Maybe it's possible to map this problem to another problem that can easily be solved with some numerical procedure (e.g. Simplex) ...\n\nMaybe someone has experience in this kind of optimization problems and is willing to help me find a solution? I don't have access to Mathematica/Matlab or the like ... but sufficient .NET programming skills and hmm Excel :-)\n\nThanks a lot!\n    ", "Answer": "\r\nAs soon as there are multiple criteria that need to be appeased in the best possible way simultanously, it is usually starting to get difficult. \n\nA numerical solution could work as follows: You could define yourself a utility function, that maps partitionings of your locations to positive real values, describing how \"good\" a partition is by assigning it a \"rating\" (good could be high \"bad\" could be near zero).\n\nOnce you have such a function assigning partitions their according \"values\", you simply need to optimize it and then you hopefully obtain a good solution if you defined your utility function reasonably. Evolutionary algorithms are good at that task since your utility function is probably analytically too complex to solve due to its discrete nature.\n\nThe problem is then only how you assign \"values\" to partitions via this utility function. This is then your task. It can be done for example by weighing each criterion with a factor and summing the results up, or even more complex functions (least squares etc.). The factors you use in the definition of the utility function are tuning parameters and can be varied until the result seems to be good.\n\nSome CA software wold help a lot for testing if you can get your hands on one, bit I guess to obtain a black box solver for your partitioning problem, you need to implement the complete procedure yourself using a language of your choice.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Closest-points set on simplicial complex\r\n                \r\nGiven two (low-dimensional, probably 2D) simplicial complexes P and Q, is there an efficient algorithm for constructing P', the subset of P consisting of all points in P which are the closest point to some point q in Q?\n\nFor instance, if P and Q were non-degenerately intersecting line segments, P' would be their intersection; if they were non-intersecting, P' would be a point or a segment. If P was a line segment and Q a triangle, P' would be the projection of Q onto P. If P was a triangle and Q was a line intersecting P, P' would consist of several incident line segments, from the interior and/or exterior of the triangle.\n\nSome picture examples: (THE ONE WITH THE POINT INTERSECTION IS INCORRECT)\n\n\n\nIn general P' seems to consist of the projections of Q onto each face (of any dimensionality) of P, but that description includes a large number of faces which are dominated by higher-dimensional faces, and it's not clear to me how to deal with that efficiently.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Implementing Raycasting for pathfinding LWJGL\r\n                \r\nI am currently working on a project involving procedurally generated underwater terrain using 3d Simplex noise and the marching cubes algorithm. Right now I have made my character model as well as generated the terrain mesh. Since the project is based in the water, I wanted to add fish and other entities to make it more realistic. I have read the basic on boids and have already created the program for entities to interact in a 3d space. However the problem I have been stuck on is having the entities interacting with obstacles. The method used in this video is by casting rays in a sphere around the entity and detecting whether or not a ray is intersecting with the obstacle. My idea is to check each point according to an interval along each ray until I detect a point that is intersecting a triangular face. I already have the code to check whether or not a 3d point is on a triangular face so my question is would I have to loop through each point along each ray in order calculate whether it is intersecting a triangle or is there a better way for me to do it?\nExample code\n```\nfor(Ray ray : rayList){\n    for(float j = 0; j<raylength; j+= rayinterval){\n        if(this.checkCollision(ray.getPos(raylenth))){\n             break;\n        }else if(j == raylenth-1){\n             return ray.getAngles();\n        }\n    }\n}\n```\n\n```\n    public boolean checkCollision(Vector3f position){\n        if(terrain != null){\n            for(int i = 0; i<terrain.getVertices().length; i+=9){\n                Vector3f vertex1 = new Vector3f(terrain.getVertices()[i],terrain.getVertices()[i+1],terrain.getVertices()[i+2]);\n                Vector3f vertex2 = new Vector3f(terrain.getVertices()[i+3],terrain.getVertices()[i+4],terrain.getVertices()[i+5]);\n                Vector3f vertex3 = new Vector3f(terrain.getVertices()[i+6],terrain.getVertices()[i+7],terrain.getVertices()[i+8]);\n                \n                if(inTriangle(position, vertex1, vertex2, vertex3)){\n                    return true;\n                }\n            }\n        }\n        return false;\n    }\n    public UVList getUV(Vector3f a, Vector3f b, Vector3f c){\n\n        //First, calculate the unit normal vector (cross product).\n        Vector3f ba = b.subtract(a);\n        Vector3f ca = c.subtract(a);\n        Vector3f nn = ba.cross(ca);\n        float unitVector = (float) Math.sqrt(nn.x*nn.x+nn.y*nn.y+nn.z*nn.z);\n        Vector3f n = nn.divide(unitVector);\n\n        //Calculate the signed distance from origin (dot product).\n        float d = n.dot(a);\n\n        //Calculate the three possible divisors.\n        float div_xy = a.x*(c.y-b.y) + b.x*(a.y-c.y) + c.x*(b.y-a.y);\n        float div_xz = a.x*(c.z-b.z) + b.x*(a.z-c.z) + c.x*(b.z-a.z);\n        float div_yz = a.y*(c.z-b.z) + b.y*(a.z-c.z) + c.y*(b.z-a.z);\n        float abs_xy = Math.abs(div_xy);\n        float abs_xz = Math.abs(div_xz);\n        float abs_yz = Math.abs(div_yz);\n        Vector3f u,v;\n        float u0,v0;\n        if(abs_xy >= abs_xz && abs_xy >= abs_yz){\n            //d_xy has the largest absolute value; using xy plane\n            u = new Vector3f((a.y-c.y)/div_xy, (c.x-a.x)/div_xy, 0);\n            v = new Vector3f((b.y-a.y)/div_xy, (a.x-b.x)/div_xy, 0);\n            u0 = (a.x*c.y - a.y*c.x)/div_xy;\n            v0 = (a.y*b.x - a.x*b.y)/div_xy;\n        }else if( abs_xz >= abs_xy && abs_xz >= abs_yz){\n            //d_xz has the largest absolute value; using xz plane\n            u = new Vector3f((a.z-c.z)/div_xz, 0, (c.x-a.x)/div_xz);\n            v = new Vector3f((b.z-a.z)/div_xz, 0, (a.x-b.x)/div_xz);\n            u0 = (a.x*c.z - a.z*c.x)/div_xz;\n            v0 = (a.z*b.x - a.x*b.z)/div_xz;\n        }else{\n            //d_yz has the largest absolute value; using yz plane\n            u = new Vector3f(0, (a.z-c.z)/div_yz, (c.y-a.y)/div_yz);\n            v = new Vector3f(0, (b.z-a.z)/div_yz, (a.y-b.y)/div_yz);\n            u0 = (a.y*c.z - a.z*c.y)/div_yz;\n            v0 = (a.z*b.y - a.y*b.z)/div_yz;\n        }\n        return new UVList(u0,v0,u,v,d,n);\n    }\n    public class UVList{\n        Vector3f u,v,n;\n        float u0, v0,d;\n        public UVList(float u0, float v0, Vector3f u, Vector3f v,float d,Vector3f n){\n            this.u = u;\n            this.v = v;\n            this.u0 = u0;\n            this.v0 = v0;\n            this.d = d;\n            this.n = n;\n        }\n        public Vector3f getN(){\n            return n;\n        }\n        public Vector3f getU(){\n            return u;\n        }\n        public Vector3f getV(){\n            return v;\n        }\n        public float getU0(){\n            return u0;\n        }\n        public float getV0(){\n            return v0;\n        }\n        public float getD(){\n            return d;\n        }\n    }\n    public boolean inTriangle(Vector3f p, Vector3f v1, Vector3f v2, Vector3f v3){\n        float ellipse = 1.5f;\n        \n        UVList uv = getUV(v1,v2,v3);\n        \n        \n        if(Math.abs(p.dot(uv.getN())-uv.getD()) >= ellipse){\n            return false;\n        }\n        \n        float u = p.dot(uv.getU())+uv.getU0();\n        \n        float v = p.dot(uv.getV())+uv.getV0();\n\n        if(u < 0 || u > 1){\n            return false;\n        }\n        \n\n        if(v < 0 || v > 1){\n            return false;\n        }\n        \n        if(u+v > 1){\n            return false;\n        }\n        \n        return true;\n    }\n```\n\n2d diagram\n\nAnd here is the terrain I want the entities to detect:\nterrain\n\nI am fairly new to 3d engines and collision so my code might not be the best.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Why is Microsoft Solver Foundation not returning a solution?\r\n                \r\nI'm trying to solve my linear program with Microsoft Solver Foundation, but it doesn't return a solution. It doesn't give a clear message to what is wrong, so I'm not sure what is going on. I have checked the constraints and I believe they are coded correctly, but maybe the LP model is wrong on itself? I would be glad if you can take a look at it and see what's wrong :)\n```\n===Solver Foundation Service Report===\nDate: 15/10/2021 16:00:21\nVersion: Microsoft Solver Foundation 3.0.2.10889 Express Edition\nModel Name: DefaultModel\nCapabilities Applied: MILP\nSolve Time (ms): 51\nTotal Time (ms): 103\nSolve Completion Status: Unknown\nSolver Selected: Microsoft.SolverFoundation.Solvers.SimplexSolver\nDirectives:\nSimplex(TimeLimit = -1, MaximumGoalCount = -1, Arithmetic = Default, Pricing = Default, IterationLimit = -1, Algorithm = Default, Basis = Default, GetSensitivity = False)\nAlgorithm: Primal\nArithmetic: Exact\nVariables: 133 -> 133 + 40\nRows: 40 -> 40\nNonzeros: 522\nEliminated Slack Variables: 0\nBasis: Slack\nPivot Count: 0\nPhase 1 Pivots: 0 + 0\nPhase 2 Pivots: 0 + 0\nFactorings: 0 + 0\nDegenerate Pivots: 0 (0,00 %)\nBranches: 0\n```\n\nI'm making this for a practical assignment, so I prefer not to share my code. For information about the assignment: it's a machine assignment problem, where you have to plan two appointments for all patients. There are global parameters:\n\np1: the duration of the first appointment\np2: the duration of the second appointment\ng: the gap between the first and second appointment\n\nEach patient needs two appointments t1 and t2 that need to be planned. Each patient also has personal parameters:\n\ninterval I1=[r1, d1], the time interval in which the first appointment can be planned\nx: (personal) extra gap between the first and second appointment\nlength l, the length of the second time interval. I2=[t1 + p1 + g + x, t1 + p1 + g + x + l - 1]\n\n\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Optimization of horizontal lines\r\n                \r\nI have run into an optimization problem which I think is a combination of known problems, but I can't seem to find the right algorithms.\n\nThe problem concerns adding a certain number of horizontal lines across a space with obstacles, and minimizing the length of the lines. There are constraints on the number of lines, the spacing between them and the spacing between the lines and boundary of the space.\n\nedit\n An example of what the input and output could look like to calrify the problem:\n\ninput:\n\n\nThe number of lines that should be added (2 in the exaple below)\nThe minimal allowed value for the spacing shown in the picture\nThe minimal allowed value for the spacing from the lines to the edges of the  space\ngeometric data containing the edges and obstacles\n\n\nDesign parameters are the Y values of the start points\n\nOutput:\n\n\ncoordinates of the optimal lines\n\n\nIf a solution with normal lines can not be found that satisfy the constraints, a line can \"skip over\" an obstacle, but when that happens, an extra line which is longer than the  skipped distance needs to be added under or over the obstacle (see example).\n\n \n\nI have looked into turning the space into a grid and using path finding algorithms like A*. I have also looked at Linear programming algorithms such as the simplex method, but I don't really know how to represent the problem, especially the \"skipping\" part.\n\nAny help regarding how to represent the problem or pointers towards similar problems or useful algorithms would be greatly appreciated.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Diamond Square improper implementation\r\n                \r\nHello Stack Community,\n\nI thought long and hard about posting this seeing as I did not want to attract yet another \"duplicate\" thread. However I have run out of ideas and do not know of any forums or other stacks where I could post this to get some help.\n\nI wrote this application as a fun project in an attempt to generate some height-maps. However whenever I try to generate more than one height-map at a time all my duplicates appear as either black voids or if the MAP_SIZE variable is low enough white voids. (Example, 16 && 33 create white voids, 1025 creates black)\n\nMy output folder appears as follows: low value vrs higher value\n\n\n\n\n\nWhy is this? Is it simply a mathematical fluke that I am missing at 3:15 am?\nI wrote the printMap specifically for the function of checking the values of the map data and while they are within ranges that would designate them to be black/white. I see no reason for this to exist continuously after the first iteration.\n\nJust for fun I printed 44 more maps, and after the first one they all were black, MAP_SIZE was set at 1025. Feel free to check this out yourselves. \n\nI created my diamond square algorithm based off my readings from here: ```\nhttp://www.gameprogrammer.com/fractal.html#heightmaps```\n\n\nAnd my greyWriteImage from a older stack overflow thread about simplex noise maps. \n\nEDIT\nThanks to  I was able to solve my problem, turns out it was just a simple fact that for each new map you attempted to create using the populateMap function I forgot to reset avgOffset to 1. Essentially the problem was you were dividing the avgOffset continuously by 2 getting smaller and smaller results, which always which would always be cast a certain way.\n\nBelow I have included my completed source code for anyone who would like to work with my algorithm and output. Have fun. \n\n```\nimport java.awt.Color;\nimport java.awt.image.BufferedImage;\nimport java.io.File;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Random;\nimport javax.imageio.ImageIO;\nimport java.util.concurrent.ThreadLocalRandom;\n\npublic class generateHeightMap {\n\n    // https://stackoverflow.com/questions/43179809/diamond-square-improper-implementation\n\n    private static final Random RAND = new Random();\n    // Size of map to generate, must be a value of (2^n+1), ie. 33, 65, 129\n    // 257,1025 are fun values\n    private static final int MAP_SIZE = 1025;\n    // initial seed for corners of map\n    private static final double SEED = ThreadLocalRandom.current().nextInt(0, 1 + 1);\n    // average offset of data between points\n    private static double avgOffSetInit = 1;\n\n    private static final String PATH = \"C:\\\\Users\\\\bcm27\\\\Desktop\\\\grayScale_export\";\n    private static String fileName = \"\\\\grayscale_map00.PNG\";\n\n    public generateHeightMap(int howManyMaps) {\n        System.out.printf(\"Seed: %s\\nMap Size: %s\\nAverage Offset: %s\\n\", \n                SEED, MAP_SIZE, avgOffSetInit);\n        System.out.println(\"-------------------------------------------\");\n\n        for(int i = 1; i <= howManyMaps; i++){ // how many maps to generate\n\n            double[][] map = populateMap(new double[MAP_SIZE][MAP_SIZE]); \n            //printMap(map);         \n            generateHeightMap.greyWriteImage(map);\n            fileName = \"\\\\grayscale_map0\" + i + \".PNG\";\n\n            System.out.println(\"Output: \" + PATH + fileName);\n        }\n    } \n    /*************************************************************************************\n     * @param requires a 2d map array of 0-1 values, and a valid file path\n     * @post creates a image file saved to path + file_name\n     ************************************************************************************/\n    private static void greyWriteImage(double[][] data) {\n        BufferedImage image = \n                new BufferedImage(data.length, data[0].length, BufferedImage.TYPE_INT_RGB);\n\n        for (int y = 0; y < data[0].length; y++)\n        {\n            for (int x = 0; x < data.length; x++)\n            {// for each element in the data\n\n                if (data[x][y]>1){\n                    // tells the image whether its white\n                    data[x][y]=1;\n                }\n                if (data[x][y]<0){\n                    // tells the image whether its black\n                    data[x][y]=0;\n                }\n                Color col = // RBG colors\n                        new Color((float)data[x][y],\n                                (float)data[x][y],\n                                (float)data[x][y]); \n                // sets the image pixel color equal to the RGB value\n                image.setRGB(x, y, col.getRGB());\n            }\n        }\n\n        try {\n            // retrieve image\n            File outputfile = new File( PATH + fileName);\n            outputfile.createNewFile();\n            ImageIO.write(image, \"png\", outputfile);\n\n        } catch (IOException e) {\n            throw new RuntimeException(\"I didn't handle this very well. ERROR:\\n\" + e);\n        }\n    }\n\n    /****************************************************************************\n     * @param requires map double[MAPSIZE][MAPSIZE]\n     * @return returns populated map\n     * \n     * [1] Taking a square of four points, generate a random value at the square \n     *     midpoint, where the two diagonals meet. The midpoint value is calcul-\n     *     ated by averaging the four corner values, plus a random amount. This \n     *     gives you diamonds when you have multiple squares arranged in a grid.\n     *\n     * [2] Taking each diamond of four points, generate a random value at the \n     *     center of the diamond. Calculate the midpoint value by averaging the \n     *     corner values, plus a random amount generated in the same range as \n     *     used for the diamond step. This gives you squares again.\n     *     \n     *     '*' equals a new value\n     *     '=' equals a old value\n     *     \n     *     * - - - *     = - - - =   = - * - =   = - = - =   = * = * =\n     *     - - - - -     - - - - -   - - - - -   - * - * -   * = * = *       \n     *     - - - - -     - - * - -   * - = - *   = - = - =   = * = * =\n     *     - - - - -     - - - - -   - - - - -   - * - * -   * = * = *                \n     *     * - - - *     = - - - =   = - * - =   = - = - =   = * = * =\n     *         A             B           C           D           E\n     *         \n     *     A: Seed corners\n     *     B: Randomized center value\n     *     C: Diamond step\n     *     D: Repeated square step\n     *     E: Inner diamond step\n     *     \n     *     Rinse and repeat C->D->E until data map is filled\n     *         \n     ***************************************************************************/\n    private static double[][] populateMap(double[][] map) {     \n\n        // assures us we have a fresh map each time\n        double avgOffSet = avgOffSetInit;\n\n        // assigns the corners of the map values to SEED\n        map[0][0] =\n        map[0][MAP_SIZE-1] =\n        map[MAP_SIZE-1][0] = \n        map[MAP_SIZE-1][MAP_SIZE-1] = SEED;\n\n        // square and diamond loop start\n        for(int sideLength = MAP_SIZE-1; sideLength >= 2; sideLength /=2,avgOffSet/= 2.0) {\n\n            int halfSide = sideLength / 2;\n            double avgOfPoints; \n\n            /********************************************************************\n             *           [1]            SQUARE FRACTAL             [1]\n             *********************************************************************/\n            // loops through x & y values of the height map\n            for(int x = 0; x < MAP_SIZE-1; x += sideLength) {\n                for(int y = 0; y <MAP_SIZE-1; y += sideLength) {\n\n                    avgOfPoints = map[x][y] +                 //top left point\n                            map[x + sideLength][y] +            //top right point\n                            map[x][y + sideLength] +            //lower left point\n                            map[x + sideLength][y + sideLength];//lower right point\n\n                    // average of surrounding points\n                    avgOfPoints /= 4.0; \n\n                    // random value of 2*offset subtracted\n                    // by offset for range of +/- the average\n                    map[x+halfSide][y+halfSide] = avgOfPoints + \n                            (RAND.nextDouble()*2*avgOffSet) - avgOffSet;\n                }\n            }\n\n            /********************************************************************\n             *          [2]            DIAMOND FRACTAL           [2]\n             *********************************************************************/\n            for(int x=0; x < MAP_SIZE-1; x += halfSide) {\n                for(int y = (x + halfSide) % sideLength; y < MAP_SIZE-1;\n\n                        y += sideLength) {\n                    avgOfPoints = \n                            map[(x - halfSide + MAP_SIZE) % MAP_SIZE][y] +//left of center\n                            map[(x + halfSide) % MAP_SIZE][y] +           //right of center\n                            map[x][(y + halfSide) % MAP_SIZE] +           //below center\n                            map[x][(y - halfSide + MAP_SIZE) % MAP_SIZE]; //above center\n\n                    // average of surrounding values\n                    avgOfPoints /= 4.0; \n\n                    // in range of +/- offset\n                    avgOfPoints += (RAND.nextDouble()*2*avgOffSet) - avgOffSet; \n\n                    //update value for center of diamond\n                    map[x][y] = avgOfPoints;\n\n                    // comment out for non wrapping values\n                    if(x == 0)  map[MAP_SIZE-1][y] = avgOfPoints; \n                    if(y == 0)  map[x][MAP_SIZE-1] = avgOfPoints; \n\n                } // end y\n            } // end x\n        } // end of diamond\n        return map;\n    } // end of populateMap\n\n    /*************************************************************************************\n     * @param requires a 2d map array to print the values of at +/-0.00\n     ************************************************************************************/\n    @SuppressWarnings(\"unused\")\n    private static void printMap(double[][] map) {\n        System.out.println(\"---------------------------------------------\");     \n\n        for (int x = 0; x < map.length; x++) {\n            for (int y = 0; y < map[x].length; y++) {\n                System.out.printf(\"%+.2f \", map[x][y] );              \n            }\n            System.out.println(); \n        }       \n    }\n\n} // end of class\n```\n\n    ", "Answer": "\r\nIs it possible that ```\navgOffSet```\n must be initialized before creating each map (start of ```\npopulateMap```\n)?\n\nIt is being divided by 2 but never reset to 1. I suppose each map is independent, that is, does not depend on the previous one, so there is no reason to not reset the variable. But I do not know that algorithm and have no time to learn it... [:-|\n\n```\nprivate static double[][] populateMap(double[][] map) {\n\n    avgOffSet = 1;  // missing this one\n\n    map[0][0] = ...\n```\n\n\nif this is correct I would suggest that ```\navgOffset```\n should be a variable; eventually create a field ```\navgOffsetInitial```\n with the initial value (instead of the current field).\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Resource with schedules allocation problem\r\n                \r\nI have a similar task but with differences in bold:\n\nI have a set of J jobs that need to be completed. Jobs are organized into set of directed graphs. Each job can have one or more preceding (parent) jobs that have to be completed before it starts.\nAll jobs take different times to complete, but the time is known.\nI have a set of R human resources. Each resource has a schedule when it is available.\nSome jobs can be preempted once started. E.g. if a resource is not available at some specific hours then it can process the job after.\nA job may have a predefined amount of resources which can be changed. If algorithm can't find desired decision (all jobs couldn't be finished at some known date) then I can increase/decrease resource amount. The duration of a job changes proportionally with amount. E.g. J1 requires 1 human resource initially and estimated duration 1 hour. If I set 2 human resource then duration decreases to 0.5 hour.\nResources have parameters that match tasks. E.g. If J1 has constraints {A,B} then we can assign resource R1 with permissions {A,B} which satisfied these constraints. If there is no appropriate resource then I can assign any of available.\n\nMy goal: Assign as much appropriate resources as possible so the job would finish at the time. How to solve this via simplex method? How equations would look like? What will be a complexity? I can't get close without brute force permutation.\nI tried a greedy algorithm:\n\nI scheduled tasks from job start date without resource calendars considering only relations between tasks (I calculated order for each task in chain, where order 0 is the earliest predecessor). E.g. in chain J1 -> J2 -> J3, J3 must be done after finishing J1 and J2. J1.Order = 0, J2.Order = 1, J3.Order = 3.\nThen I sorted tasks by order and operations count. First goes the task with higher count of children. Then I sorted by count of required resources. And finally by initial duration.\nFor each order I take a task and assign resources with satisfied skills and can do the task, then earlier, then better considering their calendars and business into another job.\n\nThis doesn't take into account predefined job finish date. It's far from optimal and another approach is needed. The greedy algorithm with a proof of correctness would also be acceptable.\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Keep C++ Modularity without Passing Functions Between Classes [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs details or clarity. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Add details and clarify the problem by editing this post.\r\n                \r\n                    \r\n                        Closed 6 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI want to keep my code modular. At the moment I have my code set-up to pass functions from a child class to a parent class. However it does not compile at all. Now I want to get rid of the passing functions all together but keep the 'modular-ness'.\n\nUpdates: I added more information about what my code is doing. I still left out majority of what I am doing. Class Molecule is optimizing multiple instances of Class Rates. Class Rates is optimizing multiple values that are generated by a single function inside Rates. \n\n```\nClass Data_Analysis {\n    virtual double find_rms_A (vector<double>) = 0;\n    virtual double find_rms_B (vector<double>) = 0;\n    virtual double find_rms_C (vector<double>) = 0;\n    double E (double (Data_Analysis::*fxn(vector<double>)) {\n        // doing tons of stuff\n        (this->*fxn)(vec);\n        //Simplex is third party library that requires a function that \n        // takes vector<double> and outputs a double\n        //http://www.codeguru.com/cpp/article.php/c17505/Simplex-Optimization-Algorithm-and-Implemetation-in-C-Programming.htm\n        Simplex((this->*fxn)(vec)); \n    }\n};\n\nClass Molecule: Data_Analysis {\n    virtual double find_rms_A (vector<double> ) {\n        // using variables only declared in Molecule\n        double rms = 0.0\n        for ( int data_point_A = 0; data_point_A < num_data_point_A; data_point_A++) {\n            Rates r(data_point_A);\n            r.run_simulation_v1();\n            rms += r.return_rate();\n        }\n        return rms;\n    }\n\n    virtual double find_rms_B (vector<double>) {\n        // using variables only declared in Molecule\n        double rms = 0.0\n        for ( int data_point_B = 0; data_point_B < num_data_point_B; data_point_B++) {\n            //do stuff\n            rms += rate;\n        }\n        return rms;\n    }\n    void optimize_A () {\n        // set variables for type of optimization A\n        E(&Data_Analysis::find_rms_A);\n    }\n    void optimize_B () {\n        // // set variables for type of optimization B\n        E(&Data_Analysis::find_rms_B);\n    }\n};\n\nClass Rates: Data_Analysis {\n    virtual double find_rms_C (vector<double>) {\n        // using variables only declared in Rates\n        double rms = 0.0\n        for ( int data_point_C = 0; data_point_C < num_data_point_C; data_point_C++) {\n            // run simulation that is completely different than anything used in Molecule\n            rms += rate;\n        }\n        return rms;\n    }\n    void optimize_C () {\n        // set variables for type of optimization C\n        E(&Data_Analysis::find_rms_C);\n    }\n};\n```\n\n\nThings I have tried to make passing functions work:\n\nVirtual Function 1, Virtual Function 2, Virtual Function 3: \"cannot declare variable ‘r’ to be of abstract type ‘Child2’\"\n\nPointer Functions 1, Pointer Functions 2: \"cannot convert ‘double (Child1::)(std::vector)’ to ‘Parent::fxn {aka double ()(std::vector)}’ in initialization\" (The asterisks are making things italics.)\n\nSo, I want to re-organize my code to get around passing functions. But I have no idea how to do this without getting rid of 'function E' and repeating the code in functions A-D (aka destroying the modular-ness). Any tips/advice?\n    ", "Answer": "\r\nIf you are going to pass a function specific to a child, don't do it through virtual functions defined in ```\nParent```\n.  Kill the virtual functions, and pass the child-specific functions you want directly into E.  Use std::bind to wrap the ```\nChild1```\n or ```\nChild2```\n-ness, so that E doesn't care about the function other than its arguments.\n\n```\nclass Parent {\n    double E (std::function<double (vector<double>)> fn) {\n        // doing tons of stuff\n        fn(vec);\n    }\n};\n\nclass Child1: public Parent {\n    double A (vector<double>) {\n        // using variables only declared in Child1\n    }\n    double B (vector<double>) {\n        // using variables only declared in Child1\n    }\n    void F () {\n        E(std::bind(&Child1::A, this, std::placeholders::_1));\n        E(std::bind(&Child1::B, this, std::placeholders::_1));\n    }\n};\n```\n\n\nA design litmus test is: If it doesn't make sense to implement a virtual function in all of the child classes, it probably shouldn't be one...\n\nYou could also use a lambda for the call instead.\n\nAlso, are you sure you want to be passing a vector by value?  You probably want to pass by const reference instead.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Stretch noise value meanwhile keep it in range (math issue!)\r\n                \r\nI implemented a simplex noise algorithm (by KdotJPG: OpenSimplex2S) which works fine, but I'd like to add a \"function\" which can increase/decrease the contrast of the noise. The noise method returns a value between -1 and 1 but the overall result is quite homogeneous. It is not bad at all, but I need to get a different outcome now.\nSo basically I should \"pull\" the value of the noise toward the range edges.. this will result more contrasting noise (more distance between the smaller and bigger values). Of course this change must be consistent and proportionally scaled between -1 and 1 (or 0-1) to get natural result.\nActually this is pure mathematical issue, but I'm not good in math at all! I'd like to make it more understandable to give this picture of two graphs:\n\nSo, on these graph the Y axis is the noise value (-1 is bottom and +1 it the top) and X axis is the time passed. The left graph shows the original result of the noise generator, and the right is the stretched version what I need to get. As you can see on the right graph everything the same but their values stretched/pulled toward the edge (toward the min, max limit) but still in range.\nIs there any math formula or c# built in function to stretch the return value of the noise proportionally respect to the min, max values (-1/1 or 0/1)? If you need the code of the noise you can see it here OpenSimplex2S too, but this is irrelevant in my case, as I just wish to modify its return value. Thanks!\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to get different Centrality indexes of each node from a Neo4j Graph?\r\n                \r\nI am working on a great project on social network analysis. My objective is to get different centrality indexes for each node in a graph. I need to analyze the graph and derive some meaning full information from it. I am using Neo4J graph database(Community Edition 1.8.M06) for this project. And I am very new to Neo4J, just two weeks of experience.\n\nRight now my graph is a friendship graph, and so the only relationship I have in the graph is of Friendship, which is mutual. The graph is undirected, unweighted and simplex. Soon I'll be adding other relationships and objects into the graph, which will make it complex.\n\nI understand Neo4J has implementations for a range graph algorithms to measure Centrality and I got that information from this link. But I couldn't find any information or examples on how to use them for getting the centrality measures. I also understand these algorithms are not production ready.\n\nIs there anyone who have tried out something similar with Neo4J? Is it possible to do it just using Neo4J? If not can I use R programming language to get Centrality indexes from Neo4J? \n\nI'd tried  using R with igraph package to get centrality from an edge-list. I suppose I could use R to access Neo4J using the REST API.\n\nI had also found some examples on using the common Graph Algorithms for shortest path problems. But no direct examples for getting the Centrality indexes. Learning from an example seems to be a perfect idea.\n\nThanks,Deepu\n    ", "Answer": "\r\nThe centrality algos are not used as much as the shortest path ones, but you should be able to test them. The main characteristic with them is that they might get slower as your graph grows, since they need exhaustive traversals. How big is your graph?\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "valgrind finds implausible number of invalid writes and reads\r\n                \r\nNew to valgrind, I am trying to understand why valgrind finds a very large number of invalid writes and reads in one of my C programs. It starts by reporting an invalid write for a function call where the calling pointer to an array, and the array itself, have, I think, been assigned appropriate memory in main. More puzzlingly, it goes on to object to numerous lines in this function where declared doubles are is assigned values. \n\nMy C program refines (ie improves) against experimental data a model of the crossbridge cycle of muscle (the cycle of events where tiny protein motors repeatedly interact with filaments of another protein to produce force and movement). The program proceeds by simulated annealing based on the downhill simplex method, the required functions being taken from Numerical Recipes in C. \n\nEach model is defined by 19 parameters, x[1] to x[19]. Memory is allocated to this array in main by first declaring x as a pointer to a double, and then creating an array numbering from 1 to 19.\n\n```\ndouble *x;\nx=dvector(1,19);\n```\n\n\nThe 19 parameters are then assigned values, initially from guesses and later using an algorithm based on the previous history:\n\n```\nfor (j=1;j<=19;j++)\n{\n    x[j]=initial_guess;\n}\n```\n\n\nThe pointer to the x array is then passed to a function scoremodel which tests the mechanical properties of the model in several ways, each producing a score and a weighted average score y is passed back to main at line 629: \n\n```\ny=scoremodel(x);\n```\n\n\nwhere the declaration of scoremodel on line 932 of my program is\n\n```\ndouble scoremodel(double *x)\n```\n\n\n(I also tried \n\n```\ndouble scoremodel(double x[])\n```\n\n\nbut the results with valgrind were the same)\n\nMain then works out from the previous results and the downhill simplex/simulated annealing algorithms what new model should be tested next. \n\nWith the great help I received from Mark Setchell after my last post to Stack Overflow, I have now been able to compile my program with gcc-4.9 and the –fopenmp flag, so that I can run it with OpenMP on my MacPro operating with Yosemite OS x 10.10.5). It runs without crashing or hanging. The properties and scores for the majority of the successive models are perfectly sensible and taking these alone the program does refine the starting model appreciably. But weirdly, about one-fifth of the models have absurd properties and very poor scores. \n\nI invoked the current release of valgrind to detect memory errors in a shorter test version of my program called refinemadpmodelinc2 with the command\n\n```\n valgrind-3.12.0/bin/valgrind --leak-check=yes ${HOME}/bin  /refinemadpmodelinc2 inc2_49 model3 model4 0 0.9 20 ../../tls/kappaFHStrunc\n```\n\n\nValgrind reports that the first error in the program occurs at the line where I declare the function scoremodel. \n\n```\nInvalid write of size 8\n==33173==    at 0x100001F71: scoremodel (refinemadpmodelinc2.c:932)\n==33173==    by 0x100001D8A: main (refinemadpmodelinc2.c:629)\n==33173==  Address 0x1045029a8 is on thread 1's stack\n==33173==  in frame #0, created by scoremodel (refinemadpmodelinc2.c:932)\n```\n\n\nI take the invalid write of size 8 is caused by me trying to write a double or a pointer to unavailable memory since their sizes are both 8 bytes on my computer. But I don’t understand what is wrong with my function call.\n\nThe next hundred lines in the function, nearly all declaration of variables, are passed by valgrind but from line 1109 to line 1203 every non-blank line is considered to be an invalid write of size 8, despite most of these lines being just simple assignments eg \n\n```\nexppower=395.9;\n```\n\n\n(when exppower has already been declared as a double). My hunch is that although I have made an error in calling the function scoremodel and upsetting valgrind, these lines must surely be OK. Your help in educating me into the mysteries of valgrind would be greatly appreciated.\n    ", "Answer": "\r\nIt is unlikely that Valgrind is wrong in this case.\n\nOlder versions of \"Numerical Recipes\" use the Fortran convention for arrays going from 1 to size inclusive, allocating an extra, unused element in C and C++. The latest version of the book (third edition, C++ only) has done away with all of this 1-based array stuff (though it's still far from a shining example of how to write C++). However, this is still a pitfall if you mix Numerical Recipes and any form of more conventional C or C++ using 0-based arrays.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Gekko and Pulp results differs but both are valid, why?\r\n                \r\nI have this simple product mix linear program, Pulp and Gekko results differs a lot but results are both valid.\nI wonder why and how should I get exactly the same result using both solvers ?\nThere is a simple product mix example :\nLet's say ```\nx1```\n is the amount of car toy 1, and ```\nx2```\n the amount of car toy 2 ( -> Decision variables).\nCar toy 1 price is 2$, Car toy 2 price is 1 $ ( -> Objective function).\nConstraint 1 is a worktime limit expressed in hours, Constraint 2 is a parts inventory limit expressed in units.\nI want to know which cars to build to maximize my profit subject to both constraints.\n```\n# Import \nfrom gekko import GEKKO\n# Local server used\nm = GEKKO(remote=False) \n# Picking solver 1\nm.options.SOLVER = 1\n\n# Initialize variables\nx1 = m.Var(value=1,lb=0,ub=1000,integer=True)\nx2 = m.Var(value=1,lb=0,ub=1000,integer=True)\n\n# Constraints \nm.Equation(2 * x1 + 3 * x2 <= 800)\nm.Equation(2 * x1 + x2 <= 500)\n\n# Objective\nm.Maximize( 2 * x1 + 1 * x2) \n\n# Steady state optimization\nm.options.IMODE = 3 \n\n# Solve\nm.solve(disp=False) \n\n# Display results\nprint('Results')\nprint('x1: ' + str(x1.value))\nprint('x2: ' + str(x2.value))\nprint('Objective: ' + str(m.options.objfcnval))\n```\n\n```\nResults\nx1: [184.0]\nx2: [132.0]\nObjective: -500.0\n```\n\nAnd, next, this is my Python Pulp code. You will notice that Python Pulp only picks the ```\nx1```\n variable, while Gekko seems to balance between the ```\nx1```\n and the ```\nx2```\n variables, or seems to optimize the decision variables allocation( Don't know if it's true or not); both results are valid, and constraints are not exceeded:\n```\n# Import \nimport pulp \n\n# This is a maximization L.P \nmodel = pulp.LpProblem(\"Maximize\", pulp.LpMaximize)\n\n# Initialize variables  \nx1 = pulp.LpVariable('x1', lowBound=0, cat='Integer')\nx2 = pulp.LpVariable('x2', lowBound=0, cat='Integer')\n  \n# Objective\nmodel +=  2 * x1 + 1 * x2, \"Profit\"\n\n# Constraints \nmodel += 2 * x1 + 3 * x2 <= 800\nmodel += 2 * x1 + x2 <= 500\n\n# Solve\nmodel.solve()\n\n# Status\npulp.LpStatus[model.status]\n\n# Display results\n# Print our decision variable values\nprint (\"x1 = {}\".format(x1.varValue))\nprint (\"x2 = {}\".format(x2.varValue))\n  \n# Print our objective function value\nprint (pulp.value(model.objective))\n```\n\n```\nResults\nx1 = 250.0\nx2 = 0.0\n500.0\n```\n\nGekko tells me to build 184 \"car toy 1\" and 132 \"car toy 2\" to maximize my profit , but Pulp tells me to only build 250 \"car toy 1\" , and to ignore \"car toy 2\" to maximize my profit. In the second case, the factory could abandon the plan to build toy car 2 altogether and dismantle parts of the factory to save money ( So it's good), so the result has a lot of consequences.\nCan somebody please tell me if that is a normal behavior, and how should I get the same behavior on both solvers ?\nIs is due to a different simplex or interior point algorithm used by theses libraries?\n( Secondary question :\nI don't know why the Gekko objective result is negative ... )\n    ", "Answer": "\r\nThere are multiple potential solutions because the profit objective and constraint 2 are co-linear and the objective contour is along constraint 2.\n```\nm.Equation(2*x1 + 1*x2 <= 500)\nm.Maximize(2*x1 + 1*x2)\n```\n\n\nThis is apparent with a contour plot that shows the constraints (blue and red) and objective contours (green). The optimal solutions are along the blue line constraint (#2) until it intersects with the red line constraint (#1).\nGenerate a contour plot\n```\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Design variables at mesh points\nx = np.arange(-1.0, 401, 5)\ny = np.arange(-1.0, 501, 5)\nx1, x2 = np.meshgrid(x,y)\n\n# Equations and Constraints\nprofit = 2.0 * x1 + 1.0 * x2\nc1 = 2.0 * x1 + 3.0 * x2\nc2 = 2.0 * x1 + 1.0 * x2\n\n# Create a contour plot\nplt.figure()\n# Profit contours\nlines = np.linspace(100.0,800.0,4)\nCS = plt.contour(x1,x2,profit,lines,colors='g')\nplt.clabel(CS, inline=1, fontsize=10)\n# Car 1 <= 800\nCS = plt.contour(x1,x2,c1,[760.0, 780.0, 800.0],colors='r',linewidths=[0.5,0.5,4.0])\nplt.clabel(CS, inline=1, fontsize=10)\n# Car 2 < 500\nCS = plt.contour(x1, x2,c2,[460.0,480.0,500.0],colors='b',linewidths=[0.5,0.5,4.0])\nplt.clabel(CS, inline=1, fontsize=10)\n# 0 <= Car 1 <= 1000\nCS = plt.contour(x1, x2,x1 ,[0.0, 5.0, 10.0],colors='k',linewidths=[1.0,0.5,0.5])\nplt.clabel(CS, inline=1, fontsize=10)\n# 0 <= Car 2 <= 100\nCS = plt.contour(x1, x2,x2 ,[0.0, 5.0, 10.0],colors='k',linewidths=[4.0,0.5,0.5])\nplt.clabel(CS, inline=1, fontsize=10)\nplt.xlabel('Car 1 Units'); plt.ylabel('Car 2 Units'); plt.show()\n```\n\nTo make the solution unique, add a small penalty to one of the variables such as:\n```\nm.Minimize(1e-5*x2)\n```\n\nHere is the new Gekko script that returns the same solution as Pulp. Pulp is limited to Mixed Integer Linear Programming (MILP) problems while Gekko can solve Mixed Integer Nonlinear Programming (MINLP) problems with differential and algebraic constraints.\n```\nfrom gekko import GEKKO\nm = GEKKO(remote=False) \nm.options.SOLVER = 1\n\n# Initialize variables\nx1 = m.Var(value=1,lb=0,ub=1000,integer=True)\nx2 = m.Var(value=1,lb=0,ub=1000,integer=True)\n\n# Equations\nm.Equation(2 * x1 + 3 * x2 <= 800)\nm.Equation(2 * x1 + x2 <= 500)\n\n# Objective\nm.Maximize( 2 * x1 + 1 * x2) \nm.Minimize(1e-5*x2)\n\n# Steady state optimization\nm.options.IMODE = 3 \n\n# Solve\nm.solve(disp=False) \n\nprint('Results')\nprint('x1: ' + str(x1.value))\nprint('x2: ' + str(x2.value))\nprint('Objective: ' + str(-m.options.objfcnval))\n```\n\n```\nResults\nx1: [250.0]\nx2: [0.0]\nObjective: 500.0\n```\n\nResponse to Secondary question: Gekko always converts to a minimization problem with ```\n-max(obj) = min(obj)```\n. Gekko is designed to potentially have multiple objectives so all are converted to minimization. An example is maximize profit, minimize costs, and minimize environmental damage. These may all be in a single optimization problem.\nAdditional information is in the ME575 (Design Optimization) course with the Design Optimization Online Textbook.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to Create a Multidimenisonal PRNG?\r\n                \r\nI am working on a procedural terrain generator, but the 3d Map is constantly morphing and changing, calling for at least 4d noise (5d if I need to make it loop). I haven't found a good perlin/simplex noise library that will work in this many dimensions, so I thought this would be a good time to learn how those algorithms work. After starting to make my own \"perlin\" noise, I found a large problem. I need to get a psudo random value based on the nD coordinates of that point. So far I have found solutions online that use the dot product of a single point and a vector generated by the inputs, but those became very predictable very fast (I'm not sure why). I then tried a recursive approach (below), and this worked ok, but I got some weird behavior towards the edges. \nRecursive 3d randomness attempt:\n\n```\nfunction Rand(seed  = 123456, deg = 1){\n    let s = seed % 2147483647;\n    s = s < 1 ? s + 2147483647 : s;\n    while(deg > 0){\n        s = s * 16807 % 2147483647;\n        deg--;\n    }\n\n    return (s - 1) / 2147483646;\n}\nfunction DimRand(seed, args){\n    if(args.length < 2){\n        return Rand(seed, args[0]);\n    }else{\n        let zero = args[0];\n        args.shift();\n        return DimRand(Rand(seed, zero), args);\n    }\n}\nvar T = 1;\nvar c = document.getElementById('canvas').getContext('2d');\ndocument.getElementById('canvas').height = innerHeight;\ndocument.getElementById('canvas').width = innerWidth;\nc.width = innerWidth;\nc.height = innerHeight;\nvar size = 50;\nfunction display(){\n    for(let i = 0; i < 20; i ++){\n        for(let j = 0; j < 20; j ++){\n            var bright = DimRand(89,[i,j])*255\n            c.fillStyle = `rgb(${bright},${bright},${bright})`\n            c.fillRect(i*size, j*size, size, size);\n        }   \n    }\n    T++;\n}\n\n\nwindow.onmousedown=()=>{display();}\n\n```\n\n\nAnd here is the result: \n\n\nThe top row was always 1 (White), the 2d row and first column were all 0 (Black), and the 3d row was always very dark (less than ≈ 0.3)\n\nThis might just be a bug, or I might have to just deal with it, but I was wondering if there was a better approach. \n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "How to Create a Multidimenisonal PRNG?\r\n                \r\nI am working on a procedural terrain generator, but the 3d Map is constantly morphing and changing, calling for at least 4d noise (5d if I need to make it loop). I haven't found a good perlin/simplex noise library that will work in this many dimensions, so I thought this would be a good time to learn how those algorithms work. After starting to make my own \"perlin\" noise, I found a large problem. I need to get a psudo random value based on the nD coordinates of that point. So far I have found solutions online that use the dot product of a single point and a vector generated by the inputs, but those became very predictable very fast (I'm not sure why). I then tried a recursive approach (below), and this worked ok, but I got some weird behavior towards the edges. \nRecursive 3d randomness attempt:\n\n```\nfunction Rand(seed  = 123456, deg = 1){\n    let s = seed % 2147483647;\n    s = s < 1 ? s + 2147483647 : s;\n    while(deg > 0){\n        s = s * 16807 % 2147483647;\n        deg--;\n    }\n\n    return (s - 1) / 2147483646;\n}\nfunction DimRand(seed, args){\n    if(args.length < 2){\n        return Rand(seed, args[0]);\n    }else{\n        let zero = args[0];\n        args.shift();\n        return DimRand(Rand(seed, zero), args);\n    }\n}\nvar T = 1;\nvar c = document.getElementById('canvas').getContext('2d');\ndocument.getElementById('canvas').height = innerHeight;\ndocument.getElementById('canvas').width = innerWidth;\nc.width = innerWidth;\nc.height = innerHeight;\nvar size = 50;\nfunction display(){\n    for(let i = 0; i < 20; i ++){\n        for(let j = 0; j < 20; j ++){\n            var bright = DimRand(89,[i,j])*255\n            c.fillStyle = `rgb(${bright},${bright},${bright})`\n            c.fillRect(i*size, j*size, size, size);\n        }   \n    }\n    T++;\n}\n\n\nwindow.onmousedown=()=>{display();}\n\n```\n\n\nAnd here is the result: \n\n\nThe top row was always 1 (White), the 2d row and first column were all 0 (Black), and the 3d row was always very dark (less than ≈ 0.3)\n\nThis might just be a bug, or I might have to just deal with it, but I was wondering if there was a better approach. \n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Incrementally adding constraints to a linear programming instance\r\n                \r\nI would like to solve a linear programming problem incrementally, adding new constraints and solving it to optimality with dual simplex. Although it is done internally in the solvers, I can't find how to do it in the APIs of GLPK, Clp or LPsolve.\n\nI am solving an NP-complete problem with rectangle packing constraints. I use a custom branch-and-bound algorithm with a linear relaxation. Mixed integer programming is out of question: it adds far too many variables (n^2), is not tighter and generally makes bad branching decisions. I solve the problem by branching on the added constraints rather than on boolean variables.\n\nI currently have a hand-written solver, which only handles a limited subset of LP, and want to tighten the relaxation: I would like to use a true (open) LP solver. GLPK, for example, allows lazy constraints, but does not seem to allow branching, adding a different constraint to each problem and solving them without destroying the previous basis factorization.\n\nHow would you do it properly with any of these solvers?\n\nThanks\n\nEdit - Background:\n\nI solve a problem with hard runtime limits, which includes rectangle packing constraints. For any pair of rectangles, there are four disjunctive constraints i.e. R1 above/below/right/left of R2.\nModeling it with boolean variables (with big-M), is too slow (bad branching choices + slower relaxation even with custom branching + lots of redundancy between feasible solutions): I need to branch directly on the disjunctive constraints, which works well, but I now need to use a general-purpose LP solver rather than my custom flow solver.\n\ni.e. in the callback I want to \n\n\ngenerate new nodes without branching on integer variables\nwith a different new constraint for each node\n\n    ", "Answer": "", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Change output of random list shuffle slightly when changing seed slightly\r\n                \r\nProblem:\nI would like to randomly shuffle a list, but using a seed value ```\ns```\n so that, when changing ```\ns```\n only slightly, the shuffle's output also only changes slightly.\nDetails:\nI have a sorted list of elements, for example:\n```\n[0,1,3,5,7]\n```\n\nThis list should be shuffled multiple times, each time using a seed value ```\ns```\n. When two seed values ```\ns1```\n and ```\ns2 = s1 + d```\n lie close to each other, then the shuffled lists should also be \"similar\".\nBy \"similar\", I mean that elements in the new shuffled list are either the same as they were when using the original seed value ```\ns1```\n, or they are replaced only by values which are close to them in the original list (for example their direct neighbors in the original list).\nEdit: The output should still be deterministic, i.e. using the same seed ```\ns1```\n when shuffling the same input list should result in the same shuffled list.\nExample for the above list (note how adding the small value ```\nd```\n only perturbs the list slightly, i.e. many values stay the same and if they change, they are usually replaced by their neighbors in the original list. As the offset increases, the \"difference\" between the lists may increase further, and values beyond the neighbors may be selected as well):\n\n\n\n\nSeed:\nOutput:\n\n\n\n\n```\ns```\n\n```\n[5,0,1,7,3]```\n\n\n\n```\ns + d```\n\n```\n[5,0,3,7,1]```\n\n\n\n```\ns + 2d```\n\n```\n[7,0,3,5,1]```\n\n\n\n```\ns + 3d```\n\n```\n[7,0,1,3,5]```\n\n\n\n\n\nIs there an algorithm for this? Is there a common name for this problem (or other search terms I could use)?\nEdit2:\nThe output should also not depend on what the original seed was, i.e. if ```\ns = s3 + d = s4 - 0.5*d```\n then the shuffle result should be the same whether I shuffle using ```\ns```\n, ```\ns3 + d```\n or ```\ns4 - 0.5*d```\n as a seed. In other words, I only pass the final seed to the algorithm, not the original seed ```\ns3```\n or ```\ns4```\n. The reason is that I want to interpolate between the seeds and the result should be an \"interpolation\" between the list's permutations.\nIdeas I had thus far:\nI could use simplex/perlin noise to sample elements: I generate a number between 0 and 1 and then use it to choose the next element from the list (0 meaning I choose the first element, 1 meaning I choose the last). Since these noise types can be \"smooth\", adding d will change the random value only slightly, meaning it will usually select elements in proximity of the ones it picked before adding d. However, I have a very hard time choosing a \"good\" frequency for the noise (high frequencies will remove the smoothness I need, low frequencies will result in no change when adding d). Also, once the list shrinks as I pick elements, the effect of d will decrease, because the range 0 to 1 will be mapped to fewer elements - and I don't really know if this is a problem yet...?\n    ", "Answer": "\r\nGenerate and set aside a random shuffle ```\nR```\n of the list. Then, every time the generator is invoked with seed ```\ns```\n:\n\nLet ```\ns = s % factorial(N)```\n where ```\nN```\n is the length of the list (or just require that ```\ns```\n should be between 0 and N!-1).\nFind the factorial representation  of ```\ns```\n\nConvert the factorial representation to a permutation ```\np```\n\nApply ```\np```\n to ```\nR```\n and return the result.\n\nThe construction is such that the permutations ```\np(s)```\n and ```\np(s+1)```\n are adjacent in lexicographic order. The steps can be implemented efficiently.\nYou could use the same idea with other orderings of the set of permutations, which minimize changes even more, such as the Heap ordering or the Steinhaus-Johnson-Trotter ordering, but I don't know whether step 3. can be implemented efficiently in those cases.\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
{"Question": "Using fminsearch for parameter estimation\r\n                \r\nI am trying to find log Maximum likelihood estimation for Gaussian distribution, in order to estimate parameters.\nI know that Matlab has a built-in function that does this by fitting a Gaussian distribution, but I need to do this with logMLE in order to expand this method later for other distributions.\nSo here is the log-likelihood function for gaussian dist : \nGaussian Log MLE\n\nAnd I used this code to estimate the parameters for a set of variables (r) with fminsearch. but my search does not coverage and I don't fully understand where is the problem: \n\n```\nclear\nclc\nclose all\n%make random numbers with gaussian dist\nr=[2.39587291079469\n1.57478022109723\n-0.442284350603745\n4.39661178526569\n7.94034385633171\n7.52208574723178\n5.80673144943155\n-3.11338531920164\n6.64267230284774\n-2.02996003947964];\n% mu=2 sigma=3\n\n%introduce f\nf=@(x,r)-(sum((-0.5.*log(2*3.14.*(x(2))))-(((r-(x(2))).^2)./(2.*(x(1))))))\nfun = @(x)f(x,r);\n\n% starting point\nx0 = [0,0];\n [y,fval,exitflag,output] = fminsearch(fun,x0)\n\n\nf = \n    @(x,r)-(sum((-0.5.*log(2*3.14.*(x(2))))-(((r-(x(2))).^2)./(2.*(x(1))))))\n\n\nExiting: Maximum number of function evaluations has been exceeded\n         - increase MaxFunEvals option.\n         Current function value: 477814.233176 \ny = 1×2    \n1.0e+-3 *\n\n    0.2501   -0.0000\n\nfval = 4.7781e+05 + 1.5708e+01i\nexitflag = 0\noutput = \n    iterations: 183\n     funcCount: 400\n     algorithm: 'Nelder-Mead simplex direct search'\n       message: 'Exiting: Maximum number of function evaluations has been exceeded↵         - increase MaxFunEvals option.↵         Current function value: 477814.233176 ↵' \n```\n\n    ", "Answer": "\r\n\n  Rewrite f as follows:\n\n\n\n\n```\nfunction y = g(x, r)\n\n     n = length(r);\n\n     log_part = 0.5.*n.*log(x(2).^2);\n\n     sum_part = ((sum(r-x(1))).^2)./(2.*x(2).^2);\n\n     y = log_part + sum_part;\n\n end\n```\n\n\n\n  Use ```\nfmincon```\n instead of ```\nfminsearch```\n because standard deviation is\n  always a positif number.\n  \n  Set standard deviation lower bound to zero ```\n0```\n\n\n\n\n\nThe entire code is as follows:\n\n```\n%make random numbers with gaussian dist\nr=[2.39587291079469\n1.57478022109723\n-0.442284350603745\n4.39661178526569\n7.94034385633171\n7.52208574723178\n5.80673144943155\n-3.11338531920164\n6.64267230284774\n-2.02996003947964];\n% mu=2 sigma=3\n\nfun = @(x)g(x, r);\n% starting point\nx0 = [0,0];\n\n% borns \nlb = [-inf, 0];\nub = [inf, inf];\n[y, fval] = fmincon(fun,x0,[],[],[],[],lb,ub, []);\nfunction y = g(x, r)\n\n     n = length(r);\n\n     log_part = 0.5.*n.*log(x(2).^2);\n\n     sum_part = ((sum(r-x(1))).^2)./(2.*x(2).^2);\n\n     y = log_part + sum_part;\nend\n```\n\n\nSolution\n\n```\ny = [3.0693    0.0000]\n```\n\n\n\n\nFor better estimation use ```\nmle()```\n directly \n\nThe code is quiet simple:\n\n```\ny = mle(r,'distribution','normal')\n```\n\n\nSolution\n\n```\ny = [3.0693    3.8056]\n```\n\n    ", "Knowledge_point": "Simplex Algorithm", "Tag": "算法分析"}
