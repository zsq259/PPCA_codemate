{"Question": "Dynamic programming: matrix chain multiplication [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and  cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened,  visit the help center.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 11 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI am reading Introduction to Algorithms by Cormen etc on dynamic programming.\n\nHere is text snippet which gives some back ground\n\n\n  the problem of matrix-chain multiplication exhibits optimal\n  substructure. We observed that an optimal parenthesization of A1 A2 ... An that splits the product between Ak and Ak + 1 contains within it optimal solutions to the problems of parenthesizing A1 A2 ... A k and  Ak + 1 Ak + 2 . . . An.\n\n\nIn the book for Matrix-chain multiplication there are theta(n square) subproblems.\n\nMy question is how does author came up with there are n square sub problems?\nCan any one pls give example how we came with this?\n\nThanks!\n    ", "Answer": "\r\nEach subproblem involves solving the problem for a consecutive subsequence of matrices ```\nAi, Ai+1, ..., Aj-1, Aj```\n. This subsequence is characterized by the two indices ```\ni```\n and ```\nj```\n. Since there are ```\nn```\n possible choices for each, the number of subproblems is theta(n2). The exact number is ```\nn(n+1)/2```\n due to the constraint ```\ni <= j```\n.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Parenthesization Matrix Chain Multiplication\r\n                \r\nI want to test some parenthesizations for matrix chain multiplication. could anyone can share a free webs source where could i get parenthesization for my data. or any free available code for this in any language. So, that i may use the code to test parenthesization and could compare it with my newly developed technique.\n    ", "Answer": "\r\nI have found a code thanks all. If anyone else wants that is available at ```\nhttp://en.wikipedia.org/wiki/Matrix_chain_multiplication```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Time complexity of matrix chain multiplication\r\n                \r\nThis is a solved problem in \"Introduction to Algorithms\", by Cormen, et. al. \nCh. 15, Section 15.2: Matrix Chain Multiplication. Pg. 373.\n\nThe objective is to parenthesize the matrix chain product A1.A2.A3.....An such that there are minimum number of scalar multiplications. \nFor Ai.Ai+1....Ak.Ak+1.....Aj,\nMatrix Ai has dimension pi-1xpi\nThe author comes up with the recursion\n\n```\nm[i,j] = 0 if i=j\n       = min {m[i,k] + m[k+1] + pi-1.pk.pj}   where i goes from k to (j-1)   if i<j\n```\n\n\n(m[i,j] is the minimum number of scalar multiplications required for the product Ai....Aj)\n\nSo far I understood, but then the time complexity he says is O(n^3). \nWhen I look at the pseudo-code, there are 3 for loops, so its correct. But I don't understand this intuitively by looking at the recursion. \n\nCan anyone please help?\n    ", "Answer": "\r\nThe final solution is to calculate ```\nm[0,N]```\n. But all ```\nm[i,j]```\n values need to be calculated before ```\nm[0,N]```\n can be calculated. This makes it ```\nO(N^2)```\n.\n\nFrom the recursion formula you can see each ```\nm[i,j]```\n calculation needs ```\nO(N)```\n complexity.\n\nSo ```\nO(N^3)```\n for the complete solution.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix chain Multiplication Different Recursive definition\r\n                \r\nMatrix Chain Multiplication has a dynamic programming solution where a recursive definition is used which works like this :\n```\nProblem : multiply i to j \nSub-problem : multiply i to k + multiply k+1 to j + multiplication cost\n```\n\nand this looks straight forward to memoize, due the repeating ```\n(i,j)```\n sub-problems. But the following recursive definition which is bit different, I am facing difficulty memoizing it :\n```\nCan someone help memoizing this algo for matrix chain multiplication : \n\nP is sequence of orders of matrices.\nFor eg, A(2,3)*B(3,4)*C(4,5), then P = {2,3,4,5}, i.e. order of ith matrix is P[i-1]*P[i]\nalso assumed P is 0-indexed.\n\nHere I am multiplying adjacent matrices and recursing\n\nPseudocode :  \n\nchain_mul(P, n) {\n    if(n = 1)   return 0\n\n    min_cost = inf\n    for( i = 1 to n-1) {\n        cost = P[i-1]*P[i]*P[i+1] + chain_mul(P-{P[i]}, n-1);\n\n        if(cost < min_cost) min_cost = cost\n    }\n    return min_cost\n}\n```\n\nHere repeating sub-problem is structure of P, like I have shown below : \n    ", "Answer": "\r\nThis cannot be memoized efficiently, because the argument P, iterates over all the subsets of the initial set P, so the memory required would be O(2^n).\nThe algoritms that can be memoized call the function specifying sections of the matrix chain, each section is characterized by two numbers, start and end index. The number of segments will be something like ```\n(n * (n + 1) / 2)```\n, and it is easy to implement a data structure to store and retrieve the results indexed by two numbers (e.g a matrix).\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Chain Multiplication\r\n                \r\nOn the website geeksforgeeks I came across the task of matrix chain multiplication.\n\nThere is a recursive solution for that problem, but I am having trouble understanding the code. Actually, I am having trouble with a certain line of the code.\n\nFirst of all here is the code:\n\n```\n#include <stdio.h>\n#include <limits.h>\n\n//Matrix Ai has dimension p[i-1] x p[i] for i = 1...n\nint MatrixChainOrder(int p[], int i, int j)\n{\n    if(i == j)\n        return 0;\n    int k, min = INT_MAX, count;\n\n    for(k=i; k < j; k++) {\n        count = MatrixChainOrder(p,i,k) + MatrixChainOrder(p,k+1,j) + p[i-1]*p[k]*p[j];\n\n    if(count < min)\n        min = count;\n    }\n\n    return min;\n}\n\nint main() {\n\n    int arr[] = {1, 2, 3, 4, 3};\n    int n = sizeof(arr)/sizeof(arr[0]);\n\n    printf(\"Minimum number of multiplications is %d \", MatrixChainOrder(arr, 1, n-1));\n\n    getchar();\n    return 0;\n}\n```\n\n\nThe matrices are: A=1x2, B=2x3, C=3x4, D=4x3\n\nThe line, which is causing me some trouble is\n\n```\ncount = MatrixChainOrder(p,i,k) + MatrixChainOrder(p,k+1,j) + p[i-1]*p[k]*p[j];\n```\n\n\nAt the beginning of the for-loop, ```\ni = 1```\n and ```\nj = 4```\n. So, ```\np[i-1]*p[k]*p[j]```\n would evaluate to ```\np[0]*p[1]*p[4] = 1x2x3```\n, which is obviously wrong, because the matrix A can only multiplied with B. I ran the code and nothing seem to be happening here, because there was no result given back for ```\np[i-1]*p[k]*p[j]```\n and also the same issue for the case ```\ni = 2, j = 4```\n.\n\nMay anyone enlighten me? I would appreciate it, if you explain me the recursion in this code. I mean the way and how it works.\n    ", "Answer": "\r\nThe answer lies in what the recursion is doing.  Assuming that this represents multiplying ```\nABCD```\n, then the iteration of the loop with ```\ni=1, j=4, k=1```\n represents performing this calculation by ```\n(A)(BCD)```\n.  ```\nMatrixChainOrder(p,i,k)```\n computes the best way to calculate ```\n(A)```\n, a ```\n1x2```\n matrix, and ```\nMatrixChainOrder(p,k+1,j)```\n computes the best way to calculate ```\n(BCD)```\n, a ```\n2x3```\n matrix.  \n\nFinally, the term you are interested in ```\np[i-1]*p[k]*p[j]```\n is the number of scalar multiplications to perform the final multiplication of ```\n(A)```\n and ```\n(BCD)```\n.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Time complexity for this relation - matrix chain multiplication\r\n                \r\nI think an (inefficient) recursive procedure for Matrix chain multiplication problem can be this (based on recurrence relation given in Cormen):\n\n```\nMATRIX-CHAIN(i,j)\n    if i == j\n        return 0\n    if i < j\n        q = INF\n\n        for k = i to j-1\n            q = min (q, MATRIX-CHAIN(i,k) + MATRIX-CHAIN(k+1, j) + c)  \n            //c = cost of multiplying two sub-matrices.\n\n        return q\n```\n\n\nTime complexity for this will be:\n\n```\nT(n) = summation over k varying from i to j [T(k) + T(n-k)]```\n \n\nHere, n = number of matrices to be multiplied.\n\nWhat will be the value of T(n) and how?\n    ", "Answer": "\r\nThis is http://en.wikipedia.org/wiki/Catalan_number\n\nYou can view the recurrence relation as doing parenthesis. The wiki page describes in depth how to arrive to the formula.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix chained Multiplication in PHP [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question appears to be off-topic because it lacks sufficient information to diagnose the problem. Describe your problem in more detail or include a minimal example in the question itself.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI wrote Matrix Chained Multiplication algorithm in C about 3 years ago, and I just started learning PHP.\n\nhere is the algorithm in C:\n\n```\n#include<stdio.h>\n#include<limits.h>\n\n\nint MatrixChainOrder(int p[], int n)\n{\n\n\nint m[n][n];\n\nint i, j, k, L, q;\n\nfor (i = 1; i < n; i++)\n    m[i][i] = 0;\n\n// L is chain length.  \nfor (L=2; L<n; L++)   \n{\n    for (i=1; i<=n-L+1; i++)\n    {\n        j = i+L-1;\n        m[i][j] = INT_MAX;\n        for (k=i; k<=j-1; k++)\n        {\n            // q = cost/scalar multiplications\n            q = m[i][k] + m[k+1][j] + p[i-1]*p[k]*p[j];\n            if (q < m[i][j])\n                m[i][j] = q;\n        }\n    }\n}\n\nreturn m[1][n-1];\n}\n\nint main()\n{\nint arr[] = {1, 2, 3, 4};\nint size = sizeof(arr)/sizeof(arr[0]);\n\nprintf(\"Minimum number of multiplications is %d \",\n                   MatrixChainOrder(arr, size));\n\ngetchar();\nreturn 0;\n}\n```\n\n\nI'm new in php and I want to help me to convert this algorithm to php.\n\nThanks.\n    ", "Answer": "\r\n```\nPHP```\n syntax is based on ```\nC```\n and straightforward similar to the latter.\n\nCheck it out:\n\n```\nfunction MatrixChainOrder($p, $n) {\n    $m = array();\n    for ($i = 1; $i < $n; $i++)\n        $m[$i][$i] = 0;\n    // L is chain length.  \n    for ($L=2; $L < $n; $L++) {\n        for ($i=1; $i <= $n-$L+1; $i++)\n        {\n            $j = $i+$L-1;\n            $m[$i][$j] = PHP_INT_MAX;\n            for ($k=$i; $k <= $j-1; $k++)\n            {\n                // q = cost/scalar multiplications\n                $q = $m[$i][$k] + $m[$k+1][$j] + $p[$i-1]* $p[$k]* $p[$j];\n                if ($q < $m[$i][$j])\n                    $m[$i][$j] = $q;\n            }\n        }\n    }\n    return $m[1][$n-1];\n}\n\n$arr = array(1, 2, 3, 4);\n$size = count($arr);\n\nprintf(\"Minimum number of multiplications is %d \", MatrixChainOrder($arr, $size));\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Can anyone explain how can I print the order of the matrix after matrix chain multiplication?\r\n                \r\nI have to find the order of matrix formed after matrix chain multiplication. \nI have the following code to determine the minimum number of multiplications required to multiply all matrices:\n\n\r\n\r\n```\nll MatrixChainOrder(ll p[], ll n) {\r\n\tll m[n][n], i, j, k, L, q;\r\n\tfor(i = 1; i < n; i++) {\r\n\t\tm[i][i] = 0;\r\n\t}\r\n\tfor(L = 2; L < n; L++) {\r\n\t\tfor(i = 1; i < n - L + 1; i++) {\r\n\t\t\tj = i + L - 1;\r\n\t\t\tm[i][j] = INT_MAX;\r\n\t\t\tfor(k = i; k <= j - 1; k++) {\r\n\t\t\t\tq = m[i][k] + m[k+1][j] + p[i-1] * p[k] * p[j];\r\n\t\t\t\tif (q < m[i][j]) {\r\n\t\t\t\t\tm[i][j] = q;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn m[1][n-1];\r\n}```\n\r\n\r\n\r\n\n\nHow can I print the order of the matrix as well? Can anyone explain?\n    ", "Answer": "\r\nYou need to use another auxiliary matrix (```\ns```\n for example), with indices.\n\n```\nif (q < m[i][j]) {\n    m[i][j] = q;\n    s[i][j] = k;\n}\n```\n\n\nWith matrices ```\nm```\n and ```\ns```\n you can print recursively the best matrix parenthesization.\n\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix chain Multiplication error while varying the size of matrices\r\n                \r\nI am writing a matrix chain multiplication code.\nIn this first i am taking input from user the no of matrices and their dimensions\nthen its sequential product is calculated,then matrix chain order is calculated.\nAfter that the matrices are multiplied based on the matrix chain order.\nBut following error occurs while varying the matrix dimensions.\nfor ex:\ncomplete multiplication and program ran successfully for\n2 matrix of order 10*13 13*10\n3 matrices of order 2*3 3*2 2*2\n3 matrices of order 10*13 13*10 10*13\n7 matrices each of order 12*12\n\nmatrix couldn't do just last step of product by MCM order for \n5 matrices of order 12*4 4*16 16*9 9*12 12*15\n6 matrices of order 19*19 and 7th matrix 19*20\n15 matrices of order 12*12\n\nsequential wasn't done for \n6 matrices of order 3*3 3*4 4*11 11*13 13*7 7*12\n\n```\n    #include<stdio.h>\n    #include<conio.h>\n    #include<stdlib.h>\n    #include<time.h>\n    int n,count;\n    int **a;\n    double ***b,***bz;\n    struct stack\n    {\n         int *s;\n         int top;\n    };\n    struct stack st,ss;\n   void push(struct stack *stk,int item)\n   {\n         if(stk->top==(3*n-2)-1)\n         printf(\"stack overflow\");\n         stk->top++;\n         stk->s[stk->top]=item;\n   }\n   int pop(struct stack *stk)\n   {\n         stk->top--;\n         return(stk->s[(stk->top)+1]);\n   }\n   void init_stack(struct stack *stk)\n   {\n         stk->top=-1;\n         stk->s=(int *) malloc((3*n-2)*sizeof(int));\n   }\n\n   void print_opt_parens(int **s,int i,int j);    \n   void matrix_chain_order(int p[],int length)\n   {\n         int n=length-1;\n         int i,j,k,l,q,**mal,**sal;\n         mal=(int **) malloc((n)*sizeof(int *));\n         sal=(int **) malloc((n)*sizeof(int *));\n         for(i=0;i<=n;i++)\n                 mal[i]=(int *) malloc((n)*sizeof(int));\n         for(i=0;i<=n;i++)\n                 sal[i]=(int *) malloc(n*sizeof(int));\n         for(i=0;i<=n;i++)\n                 mal[i][i]=0;\n         for(l=2;l<=n;l++)\n         {\n                 for(i=1;i<=n-l+1;i++)\n                 {\n                       j=i+l-1;\n                       mal[i][j]=9999999;\n                       for(k=i;k<=j-1;k++)\n                       {\n                              q=mal[i][k]+mal[k+1][j]+p[i-1]*p[k]*p[j];\n                              if(q < mal[i][j])\n                              {\n                                    mal[i][j]=q;\n                                    sal[i][j]=k;\n                              }\n                       }        \n                 }\n          }\n          printf(\"\\n Optimal Number of Operations = %d\",mal[1][n]);\n          printf(\"\\nprinting optimal parenthesis : \\n\");\n          print_opt_parens(sal,1,n);\n          return;\n     }\n     void mul(int x,int y);\n     void print_opt_parens(int **s,int i,int j)\n     {    int x,y,zz;\n\n          if(i==j){\n          printf(\" A%d \",i);\n          push(&st,i);\n     } \n     else\n     {\n          printf(\" ( \");\n          push(&st,-1);\n          print_opt_parens(s,i,s[i][j]);\n      print_opt_parens(s,s[i][j]+1,j);\n      printf(\" ) \");\n      x=pop(&st);\n      y=pop(&st);\n    mul(x,y);\n    zz=pop(&st);\n    if(x<0&&y<0)\n                push(&st,(x+y));\n    else if(x>0&&y>0)\n                push(&st,-(x+y));\n             else        \n                push(&st,(x*y));     \n     }\n    }\n     void init_b(double ***b)\n      {\n         int i,j,k;\n           bz=(double ***) malloc((2*n)*sizeof(double **));\n           for(i=0;i<n;i++)\n                bz[i]=(double **) malloc(n*sizeof(double *));\n            for(i=0;i<n;i++)\n                 for(j=0;j<n;j++)\n                                 bz[i][j]=(double *) malloc(n*sizeof(double));\n           for(i=0;i<n;i++)\n                 for(j=0;j<n;j++)\n                                 for(k=0;k<n;k++)\n                           bz[i][j]k]=0.0;                                             \n                   count=-1;\n              }\n          void mul(int x,int y)\n          {\n              FILE *fp4,*fp5,*fp6;\n             double **z,**tx,**ty;\n             int m,l,i,j,k,mm,ll,kk,nn;\n              if(x<0)\n                 {\n             mm=pop(&ss);\n             nn=pop(&ss);\n             tx=(double **) malloc(nn*sizeof(double));\n             for(i=0;i<nn;i++)\n                              tx[i]=(double *) malloc(mm*sizeof(double));\n\n             for(i=0;i<nn;i++)\n                              for(j=0;j<mm;j++){\n                                               tx[i][j]=bz[count][i][j];\n                                               }\n             count--;\n              }\n               else\n              {           \n             mm=a[0][x-1];\n             nn=a[1][x-1];\n             tx=(double **) malloc(mm*sizeof(double));\n             for(i=0;i<mm;i++)\n                              tx[i]=(double *) malloc(nn*sizeof(double));\n             for(i=0;i<mm;i++)\n                              for(j=0;j<nn;j++){\n                                               tx[i][j]=b[x-1][i][j];\n                                               }\n             } \n              if(y<0) \n           {\n             kk=pop(&ss);\n             ll=pop(&ss);\n             ty=(double **) malloc(kk*sizeof(double));\n             for(i=0;i<kk;i++)\n                              ty[i]=(double *) malloc(ll*sizeof(double));\n\n             for(i=0;i<kk;i++)\n                              for(j=0;j<ll;j++){\n                                               ty[i][j]=bz[count][i][j];\n                                              }\n\n             count--;\n             }\n              else\n               {\n             kk=a[0][y-1];\n             ll=a[1][y-1];\n             ty=(double **) malloc(kk*sizeof(double));\n             for(i=0;i<kk;i++)\n                              ty[i]=(double *) malloc(ll*sizeof(double));\n             for(i=0;i<kk;i++)\n                              for(j=0;j<ll;j++){\n                                               ty[i][j]=b[y-1][i][j];\n\n                                               }\n\n                      }\n           count++;\n             bz[count]=(double **) realloc(bz[count],mm*sizeof(double *));\n             for(i=0;i<mm;i++)\n             bz[count][i]=(double *) realloc(bz[count][i],ll*sizeof(double));    \n\n            for(i=0;i<kk;i++)\n               {\n             for(j=0;j<nn;j++)\n             {                  \n                              bz[count][i][j]=0;\n                              for(k=0;k<mm;k++)\n                              {\n                                                bz[count][i][j]+=ty[i][k]*tx[k][j];\n                              }\n             }\n            }\n\n              fp6=fopen(\"g.txt\",\"w+\");\n\n           for(i=0;i<kk;i++)\n             {\n                  for(j=0;j<nn;j++)\n                  {\n\n                                   fprintf(fp6,\"%lf\\t\",bz[0][i][j]);\n                  }\n                  fprintf(fp6,\"\\n\");\n\n            }\n          push(&ss,nn);\n           push(&ss,kk);\n\n           }   \n\n         int main()\n         {\n              FILE *fp1,*fp2,*fp3;\n              int i,j,k,l,m,p,q;\n              double **c,**t;\n               int *pa;\n               time_t ts;\n             srand(time(&ts));\n            // getting no of matrcies\n            printf(\"\\n Enter the Number or matrices :\");\n             scanf(\"%d\",&n);\n               // allocation of space to store matrices of varying rows and columns\n             a=(int **) malloc(2*sizeof(int));\n            init_b(bz);\n           init_stack(&st);\n           init_stack(&ss);\n             for(i=0;i<2;i++)\n                a[i]=(int *) malloc(n*sizeof(int));\n\n              printf(\"\\n Enter the rows and columns \\n\");\n             for(j=0;j<n;j++)\n                 for(i=0;i<2;i++)\n                                scanf(\"%d\",&a[i][j]);\n\n            // verifying the multiplicability of the matrices\n           for(i=0;i<n-1;i++)\n                if(a[1][i]!=a[0][i+1])\n                {               \n\n                                printf(\"The matrices %d and %d cannot be multiplied\",i,i+1);\n                                getch();\n                                exit(0);\n                }\n          // actual matrix allocation                                       \nb=(double ***) malloc(n*sizeof(double **));\nfor(i=0;i<n;i++)\n                b[i]=(double **) malloc(a[0][i]*sizeof(double *));\nfor(i=0;i<n;i<i++)\n                  for(j=0;j<a[0][i];j++)\n                                        b[i][j]=(double *) malloc(a[1][i]*sizeof(double));\n// data entry\nfor(i=0;i<n;i++)\n                for(j=0;j<a[0][i];j++)\n                                      for(k=0;k<a[1][i];k++)\n                                                            b[i][j][k]=(double)rand()/(double)RAND_MAX;\n//file opening\nfp1=fopen(\"b.txt\",\"w\");\nfp2=fopen(\"c.txt\",\"w\");\n//print data\nfor(i=0;i<n;i++)\n{\n                for(j=0;j<a[0][i];j++)\n                {\n                                      for(k=0;k<a[1][i];k++){\n                                                            if(fp1!=NULL)\n                                                                         fprintf(fp1,\"%lf\\t\",b[i][j][k]);\n                                                            printf(\"%lf\\t\",b[i][j][k]);\n                                      }\n                                      printf(\"\\n\");\n                                      fprintf(fp1,\"\\n\");\n                }\n                printf(\"\\n\");\n                fprintf(fp1,\"\\n\");\n}\n\n// allocating space for temp, and result variable\nc=(double **) malloc(a[0][0]*sizeof(double));\nfor(i=0;i<a[0][0];i++)\n                c[i]=(double *) malloc(a[1][1]*sizeof(double));\nt=(double **) malloc(a[0][0]*sizeof(double));\nfor(i=0;i<a[0][0];i++)\n                t[i]=(double *) malloc(a[1][0]*sizeof(double));\n// assigning initial value of t\nfor(i=0;i<a[0][0];i++)\n                for(j=0;j<a[1][0];j++)\n                                      t[i][j]=(double)b[0][i][j];\n// sequential matrix multiplication      \nfor(i=1;i<n;i++)\n{\n                 c=(double **) realloc(c,a[0][0]*sizeof(double));\n                 for(m=0;m<a[0][0];m++)\n                 {\n                                       c[m]=(double *) realloc(c[m],a[1][i]*sizeof(double));}\n                for(j=0;j<a[0][0];j++)\n                {\n                                      for(k=0;k<a[1][i];k++)\n                                      {\n                                                            c[j][k]=0.0;\n                                                            for(l=0;l<a[0][i];l++)\n                                                            {                     \n                                                                                  c[j][k]+=(double)t[j][l]*(double)b[i][l][k];\n                                                            }\n                                      }\n                }\n                t=(double **) realloc(t, a[0][0]*sizeof(double));\n                for(m=0;m<a[0][i-1];m++)\n                                       t[m]=(double *) realloc(t[m],a[1][i]*sizeof(double));\n                for(m=0;m<a[0][0];m++)\n                                        for(p=0;p<a[1][i];p++)\n                                                              t[m][p]=c[m][p];\n}\nfree(c);\nfree(t);\n// print the result\nfor(i=0;i<a[0][0];i++)\n{\n                      for(j=0;j<a[1][n-1];j++){\n                                              if(fp2!=NULL)\n                                                           fprintf(fp2,\"%lf\\t\",c[i][j]); \n                                              printf(\"%lf\\t\",c[i][j]);\n                      }\n                      printf(\"\\n\");\n                      fprintf(fp2,\"\\n\");\n}\n// extract the no of rows and columns\npa=(int *) malloc((n+1)*sizeof(int));\npa[0]=a[0][0];\nfor(i=1;i<n+1;i++)\n                  pa[i]=a[1][i-1];\n//Matrix Chain OPerations and Order\nmatrix_chain_order(pa,n+1);\nfclose(fp1);\nfclose(fp2);         \ngetch();\nreturn 0;\n }                \n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Segmentation Fault during the execution of Matrix Chain Multiplication\r\n                \r\nSegmentation Fault during the execution of Matrix Chain Multiplication.\n\nI was writting the code for Matrix Chain Multiplication. I proceeded in the following way.\n\nMy program is getting some segmentation fault. I read the code again but I cannot get the issue.\n\nMy Logic.\nA is a 2D Matrix where A[i][j] is storing the value of the minimum number of multiplications required to multiply C_j to C_i.\nB is a 1D Matrix where B[i] stores the Rows of C_{i+1} and columns of C_i.\n\nInitially I assigned the value 0 to each element of the matrix A. The program is able to print the value of A and It also takes the inputs of B.\n\nBut it is unable to calculate the number of minimum operations required to multiply C_1 to C_n.\nCan you help me figure out the issue\n\n```\n#include<stdio.h>\n#include<stdlib.h>\n#include<time.h>\nint Optimal(int **A, int *B, int n);\nint main()\n{ \n     int n, **A,*B,i,m,j,k;\n     printf(\"\\n Enter the number of natrices to be multiplied :\");\n     scanf(\"%d\",&n);\n\n     A =(int **)malloc((n+1)*sizeof(int *));\n\n     { \n          for(i=0; i<=n; i++)\n          {        A[i] = (int *)malloc(n*sizeof(int));         \n                   for( j=0; j<=n; j++)\n                   { \n                            A[i][j]=0;\n                   }\n          }     \n\n     }\n    printf(\"\\n Array entered :\\n\");\n     for(i=1;i<=n;i++)\n     { \n          for(j=1; j<=n; j++)\n          {\n               printf(\"%d \", A[i][j]); \n\n          }\n          printf(\"\\n\");\n     }\n\n B =(int *)malloc((n+1)*sizeof(int));\nfor(i=0;i<=n;i++)\n{   printf(\"Input the Columns of Matrix %d and Rows of %d\",i,i+1);\n    scanf(\"%d\",&m);\n    B[i]=m;\n}\n\nOptimal(A,B,n);\nprintf(\"The Minimum Number of Calculations required is %d \",A[1][n]);\n\n\nreturn 0;\n}\n\nint Optimal(int **A, int *B, int n)\n{  \n     int m=50000,j,i,k;\n  for(i=1;i<=n;i++)\n         {\n             A[i+1][i]=B[i+1]*B[i]*B[i-1];\n         }\n  for(k=2;k<n;k++)\n    {    \n\n         for(i=k+1;i<=n;i++)\n         {\n\n              for(j=1;j<k;j++)\n              if(m<A[i+k][i+k-j]*A[i+k-j-1][i]+B[i+k]*B[i+k-j-1]*B[i])\n              {\n                   m=A[i+k][i+k-j]*A[i+k-j-1][i]+B[i+k]*B[i+k-j-1]*B[i];\n              }\n              A[i+k][i]=m;\n         }\n    }\n\nreturn 0;\n}\n```\n\n\nI expect the actual result to be Minimum Number of Multiplications required to multiply the matrices\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix-chain Multiplication and a bit different problems?\r\n                \r\nWe know Matrix-chain Multiplication Problem. My professor solve one close problem as:\n\n\n  We want to find an order of Matrix multiplication such that number of\n  elements in middle matrixes (calculated in all steps of production) is\n  minimized (we called it cost of production). We have\n  A_1*A_2*A_3*...* A_n and dimension A_i is on d_{i-1} and d_i. C_{ij} =\n  min cost of production A_i*...*A_j sub problems and C_{ii}=0.  he says\n  the relation for solving this problem is:\n\n\n```\nC_{ij}=min i<=k < j  max{C_{ik}, C_{k+1,j}, d_{i-1}*d_j}\n```\n\n\nI couldent get it, what is the idea behind  this relation? how can help me ? \n    ", "Answer": "\r\nLet's assume that we want to minimize ```\nC(i, j)```\n. What can we choose? We can choose the position of the last multiplication we will perform. When it is fixed, we have two independent subproblems(everything before the last multiplication and everything after it). So the equation ```\nC_{ij}=min i<=k < j  max{C_{ik}, C_{k+1,j}, d_{i-1}*d_j}```\n in plain English means: \n\n\nLet's choose the position of the last multiplication and denote it is ```\nk```\n. \nLet's solve two subproblems: one for ```\n(i, k)```\n and another one for ```\n(k + 1, j)```\n.\nFor a fixed ```\nk```\n, the answer is maximum of the results for these two subproblems and the size of the final matrix which we get after multiplying all matrices in ```\n(i, j)```\n range(namely, ```\nd_{i-1}*d_j```\n, and it does not depend on the order of multiplication).\nWe want to minimize the result, so we choose the smallest value among all valid ```\nk```\n.\n\n\nThat's it.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "A Matrix Chain Multiplication algorithm in Javascript\r\n                \r\nI am trying to adapt an established dynamic programming Matrix Chain Multiplication algorithm to compare Javascript's performance to other languages.\n\nThis is the Java version found on Wikipedia from which I am adapting to Javascript:\n\n```\nvoid matrixChainOrder(int[] p) {\n    int n = p.length - 1;\n    m = new int[n][n];\n    s = new int[n][n];\n\n    for (int L = 1; L < n; L++) {\n        for (int i = 0; i < n - L; i++) {\n            int j = i + L;\n            m[i][j] = Integer.MAX_VALUE;\n            for (int k = i; k < j; k++) {\n                int q = m[i][k] + m[k+1][j] + p[i]*p[k+1]*p[j+1];\n                if (q < m[i][j]) {\n                    m[i][j] = q;\n                    s[i][j] = k;\n                }\n            }\n        }\n    }\n}\n```\n\n\nBelow is the version I am adapting and it is the same as far as I can see, but the console logs the following error message: ```\nTypeError: m[(k + 1)] is undefined```\n\n\n\r\n\r\n```\nvar matrixChainOrder = function(p) {\r\n    var n = p.length - 1;\r\n    var m = [[,]];\r\n    var s = [[,]];\r\n    for (var L = 1; L < n; L++) {\r\n        for (var i = 0; i < n - L; i++) {\r\n            var j = i + L;\r\n            m[i][j] = Number.MAX_SAFE_INTEGER;\r\n            for (var k = i; k < j; k++) {\r\n                var q = m[i][k] + m[k+1][j] + p[i]*p[k+1]*p[j+1];\r\n                if (q < m[i][j]) {\r\n                    m[i][j] = q;\r\n                    s[i][j] = k;\r\n                }\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\nvar array = [15, 12, 16, 17, 19];\r\nvar d = new Date();\r\nvar start = d.getMilliseconds();\r\nmatrixChainOrder(array);\r\nvar end = d.getMilliseconds();\r\nconsole.log(end - start);```\n\r\n\r\n\r\n\n\nI don't understand why a TypeError is being thrown... hoping someone else can spot the problem and help me out.\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Memoized version of matrix chain multiplication\r\n                \r\nHere is program for memoized version matrix chain multiplication program from Introduction to Algorithms by cormen etc\n\n```\nMEMOIZED-MATRIX-CHAIN(p)\n\n1 n  length[p] - 1   \n2 for i = 1 to n\n3      do for j = i to n\n4             do m[i, j]  = infinity   \n5 return LOOKUP-CHAIN(p, 1, n)\n\nLOOKUP-CHAIN(p, i, j)\n\n1 if m[i,j] < infinity\n2    then return m[i, j]\n3 if i = j\n4    then m[i, j]  0\n5    else for k =  i to j - 1\n6             do q = LOOKUP-CHAIN(p, i, k) +\n                     LOOKUP-CHAIN(p, k + 1, j) +\n                     p(i - 1)* p(k) *p(j) \n7                if q < m[i, j]\n8                   then m[i, j] = q\n9 return m[i, j]\n```\n\n\nIt is mentioned in description as we can categorize the calls of LOOKUP-CHAIN into two types:\n\n\ncalls in which m[i,j] = infinity, so that lines 3-9 are executed.\ncalls in which m[i,j] is less than infinity, so that LOOKUP-CHAIN simply returns in line \n\n\nThere are n square calls of first type, one per table entry. All calls of the second type are made as recursive calls by calls of the first type.\nWhenever, a given call of LOOKUP-CHAIN makes recursive calls, it makes \"n\" of them. Therfore, there are n cube calls of the second type in all. Each call of\nthe second type takes O(1) time, and each call of the first type takes O(n) time plus the spent in recursive calls. There for total time is O(n cube).\n\nMy question is\n\n\nWhat does author mean by \"All calls of the second type are made as recursive calls by calls of the first type\" ?\nHow author came up with  \" given call of LOOKUP-CHAIN makes recursive calls, it makes \"n\" of them\" in above sentence?\n\n\nThanks!\n    ", "Answer": "\r\n\nI think they meant that if you consider the tree of recursive calls, the calls of the second type appear as leaves (no more recursion), while the calls of the first type are the inner nodes of the tree.  So yes, the second type is called by the first type.\nThe ```\nfor```\n loop on line 5 of ```\nLOOKUP-CHAIN```\n performs at most n iterations (because 1≤i≤j≤n) so it can make up to 2n=O(n) recursive calls.\n\n\nMaybe it is easier to understand the complexity of this recursive algorithm if you picture it as a tree:\n\n\nThe inner node corresponds to \"type 2\", there cannot be more than n² of them (because of the memoization), and they each perform O(n) operations\nThe leaves correspond to \"type 1\".  Because there are at most n² inner nodes with at most 2n children, so you cannot have more than 2n³ leaves and each of these performs θ(1) operations\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Why are we using three loops in Matrix Chain Multiplication?\r\n                \r\nI am studying Dynamic programming. I was stuck at this question Matrix Chain Multiplication. I understand the need of three loops. But how to come up with these arrangements like j = i+L-1 and test condition for i. \nThere are some other DP questions with similar solutions and I have noticed that these loops are used to fill upper Triangle Matrix only. I want to know why we write loops like this ?\n\n```\nfor (int L=2; L<n; L++){\n    for (int i=1; i<n-L+1; i++)\n    {\n        int j = i+L-1; // Why ?\n        m[i][j] = INT_MAX;\n        for (int k=i; k<=j-1; k++)\n        {\n            int q = m[i][k] + m[k+1][j] + p[i-1]*p[k]*p[j];\n            if (q < m[i][j])\n            {\n                m[i][j] = q;\n            bracket[i][j] = k;\n            }\n        }\n    }\n}\n```\n\n    ", "Answer": "\r\nL is the length of Chain.\ni is for row number.\nj is for column number.\nk is the intermediate multiplication.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "In Matrix-chain multiplication, access to 2D arrays(parameter) error\r\n                \r\nI have difficulties in accessing 2D array. I pass the ```\nint** s```\n(s is 2D dimension) as parameter. And I tried to reuse the element of it with index below form(```\ns[sp][jc]```\n, I also tried ```\n*(*(s+sp)+jc))```\n, and this makes error(there's no error code but only shut down program). What is the problem? Or if I can't use 2D array as parameter, than how can I print the sequence of parenteses and matrix of matrix-chain multiplication --> like this: ```\n((a(bc))((de)f))```\n. \n\n```\nvoid printParenthesis(int sp, int ep, int jc, int** s) {\n   printf(\"Debug\\n\");\n\n   if(sp==ep) {\n      printf(\"( %d \", sp);\n      return;\n   }\n   else {\n      printParenthesis(sp, jc, s[sp][jc], s);\n      printParenthesis(jc+1, ep, s[jc+1][ep], s);\n      printf(\") \");\n   }\n}\nint main() {\n    ...\n    int s[matNum-1][matNum]\n    ...\n    printParenthesis(0, matNum, jc, (int**)s);\n```\n\n    ", "Answer": "\r\nC does not deal actually with 2D-arrays the way you expect it. It does it the C-way.\n\nLet's observe ```\n*(*(s+sp)+jc))```\n first. ```\n(s+sq)```\n is of type ```\nint*```\n, not ```\nint**```\n. That said, you immediately know what causes the crash. The expression dereferences an ```\nint*```\n twice, which is not realistic to work properly.\n\nTo correct your code, you have to change definition of the array's parameter to\n\n```\nvoid printParenthesis(int sp, int ep, int jc, int (*s)[SIZE_S])\n```\n\n\nsuch that your 2D-array has fixed size length.\n\nIn other words you are passing an array of ```\nSIZE_S```\n pointers to ```\nint```\n.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How do you compute the run time for the naive solution for Matrix Chain Multiplication?\r\n                \r\nI'm working on Matrix Chain Multiplication. And the naive solution is equivalent to the Catalan number of the problem.\n\nThis is what it says in the solution. That the naive solution ends up working out to be O(2^n) by reducing the parenthesizing problem to a binary tree. Then computing all the binary trees for a given input.\n\nI just don't understand how you go from parenthesizing a matrix chain multiplication to a binary tree. I would have never figured that out myself.\n    ", "Answer": "\r\nAnswering my own question. The binary expression tree isn't a new concept. We are working with binary operations and thereby recall that we can convert the parenthesizing to a binary expression tree. Then ask ourselves, how many binary expression trees exist?\n\nIt might be intresting to do run time analysis on a problem where it's K-ary expression tree.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Giving infinite as result when using matrix chain multiplication to find the efficient cost\r\n                \r\nI am trying to understand Matrix Chain Multiplication. Particularly the problem ```\nGiven a sequence of matrices, find the most efficient way to multiply these matrices together.```\n\nI tried the following but it prints some infinite value for the result. What is it that I am doing incorrectly?\n\r\n\r\n```\nconst p = [1, 2, 3, 4, 3];\n\nfunction mcm(m, i, j) {\n if (i >= j) return 0;\n else {\n    let ans = Number.MAX_VALUE;\n    let temp;\n    for (let k = i; k < j - 1; k++) {\n       temp = mcm(m, i, k) + mcm(m, k + 1, j) + m[i - 1] * m[k] * m[j];\n       if (ans > temp) ans = temp;\n    }\n    return ans;\n }\n}\n\nconsole.log(mcm(p, 1, p.length - 1));```\n\r\n\r\n\r\n\n    ", "Answer": "\r\nThe error is in the end-condition for your ```\nfor```\n loop:\n```\nfor (let k = i; k < j - 1; k++) {\n```\n\nIt should be:\n```\nfor (let k = i; k < j; k++) {\n```\n\nThe reason is that ```\nj```\n is included in the range to inspect, and so ```\nk```\n should go up to and including ```\nj-1```\n.\nYou are getting near Infinity because there are cases in your code where the loop performs no iterations at all (when ```\nj-i==1```\n) and then the function will return ```\nNumber.MAX_VALUE```\n, which explains the output you get.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Chain Multiplication Dynamic Programming\r\n                \r\nAssume that multiplying a matrix G1 of dimension p×q with another matrix G2 of dimension q×r requires pqr scalar multiplications. Computing the product of n matrices G1G2G3 ….. Gn can be done by parenthesizing in different ways. Define GiGi+1 as an explicitly computed pair for a given paranthesization if they are directly multiplied. For example, in the matrix multiplication chain G1G2G3G4G5G6 using parenthesization (G1(G2G3))(G4(G5G6)), G2G3 and G5G6 are only explicitly computed pairs.\n\nConsider a matrix multiplication chain F1F2F3F4F5, where matrices F1,F2,F3,F4 and F5 are of dimensions 2×25,25×3,3×16,16×1 and 1×1000, respectively. In the parenthesization of F1F2F3F4F5 that minimizes the total number of scalar multiplications, the explicitly computed pairs is/are\n\nF1F2 and F3F4 only\n\nF2F3 only\n\nF3F4 only\n\nF2F3 and F4F5 only\n\n=======================================================================\n\nMy approach - I want to solve this under one minute, but the only way I know is that to use Bottom up Dynamic Approach by making a table and the other thing I can conclude is we should multiply with F5 at last because it has 1000 in it's dimension.So, please how to develop fast intuition for this kind of question!\n\n======================================================================\n\nCorrect answer is F3F4\n    ", "Answer": "\r\nThe most important thing to note is the dimension 1×1000. You better watch out for it if you want to minimize the multiplications. OK, now we do know what we are looking for is basically multiply a small number with 1000.\n\nCarefully examining if we go with F4F5, we would be multiplying 16x1x1000. But computing F3F4 first , the result matrix has dimension 3x1. So going with F3F4 we are able to get small numbers like 3,1 . So , no way im going with F4F5.\n\nBy similar logic I would not go with F2F3 and loose the smaller 3 and get bigger 25 and 16 to be later used with 1000.\n\nOK, for F1F2, you can quickly find that (F1F2)(F3F4) is not better than\n(F1(F2(F3F4))) . So the answer is F3F4\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Calculating matrix chain mutlipication with Catalan numbers\r\n                \r\nI studied Matrix Chain Multiplication problem and I understand what the algorithm does. Lately, I came across Catalan numbers, which came in handy when solving the parenthesization problem. The problem appeared to me very similar to Matrix Chain Multiplication. In fact, in CLRS they mention the Catalan numbers in the Matrix Chain Multiplication chapter.\n\nI am curious can you solve Matrix Chain Multiplication with Catalan numbers algorithm? My thoughts are: no, you can't solve because Catalan numbers describe number of ways to parenthesize matrices, whereas the original Matrix Chain problem asks a different question -- specific way to arrange parenthesis that would give the smallest cost. \n\nAre my thoughts correct?\n    ", "Answer": "\r\nMatrix Chain Multiplication and Parenthesization Problem are equilvaent form of one another. One can be reduced into another.\n\nThe Chain Matrix Multiplication Problem\n\nGiven a sequence of ```\nn```\n matrices ```\nA1, A2, ... An```\n, and their dimensions ```\np0, p1, p2, ..., pn```\n, where where ```\ni = 1, 2, ..., n```\n, matrix ```\nAi```\n has dimension ```\npi − 1 × pi```\n, determine the order of multiplication that minimizes the the number of scalar multiplications.\n\nEquivalent form: Parenthesization Problem\n\nGiven ```\nn```\n matrices, ```\nA1, A2, ... An```\n, where for ```\n1 ≤ i ≤ n```\n, ```\nAi```\n is a ```\npi − 1 × pi```\n, matrix, parenthesize the product ```\nA1, A2, ... An```\n so as to minimize the total cost, assuming that the cost of multiplying an ```\npi − 1× pi```\n matrix by a ```\npi × pi + 1```\n matrix using the naive algorithm is ```\npi − 1× pi × pi + 1```\n\n\nWhen you try to write the recurrent relation of above problem, it turns out to be same as that of catalan numbers. Hence catalan number can be used to solve matrix chain multiplication problem.\n\nMatrix-chain Multiplication Problem\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Can there be more than one answer for matrix chain multiplication?\r\n                \r\nI'm studying for an Algorithms exam, and one of my problems is to find the optimal matrix chain multiplication for the following:\n\nA1: 5x7\n\nA2: 7x10\n\nA3: 10x7\n\nA4: 7x5\n\nI ended up with the solution ((A1*A2)A3)A4), which sums to 875 operations. The correct answer is marked as (A1(A2(A3*A4)), which also sums to 875. Are both answers correct, or is there some other thing here that I'm missing?\n    ", "Answer": "\r\nThere can be multiple optimal answers as can be seen from your example. You can also consider the trivial case with a set of matrices that all have the same dimensions (every sequence has the same cost).\n\nYou may want to note that the sequence of dimensions in your example is palindromic, so are the two possible optimal solutions. \n\nThere are no other criteria you can use without looking at the values of the matrices to optimize this further. Using the values of the matrices, one may think of improvements that can be done to minimize the time to get the final results (for example, use the order that gets to the 0 matrix fastest).\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "memoized matrix chain multiplication in Java\r\n                \r\nI feel like I'm really close with this implementation of a memoized matrix chain algorithm in Java, but I'm getting an array out of bounds error on line 45 and 53. These, for some reason, really seem to mess me up. Maybe there's something I'm continually messing up with, but I dunno, obviously. Can anyone help me out?\n\n```\npublic class Lab2 {\n//fields\nstatic int p[];\nstatic int m[][];\nfinal static int INFINITY = 999999999;\n\npublic Lab2() {\n    // \n}\npublic static void main(String[] args) {\nLab2 lab2 = new Lab2();\n\nLab2.m = new int[7][7];\n\nLab2.p = new int[7];\nLab2.p[0] = 20;\nLab2.p[1] = 8;\nLab2.p[2] = 4;\nLab2.p[3] = 25;\nLab2.p[4] = 30;\nLab2.p[5] = 5;\nLab2.p[6] = 10;\n\n\nint n = Lab2.p.length-1;\n\n//initialize m array to infinity\nfor (int i = 1; i <= n; i++){\n    for (int j = i; j <= n; j++){\n        Lab2.m[i][j]= INFINITY;\n    }\n}\nlab2.lookUpChain(m, p, 1, n);\n\nfor (int i = 0; i < 8; i++){\n    for (int j = 0; j < 8; j++){\n        System.out.println(m[i][j]);\n    }\n}\n\n}\n//\npublic int lookUpChain(int m[][], int p[], int i, int j ){\nif (m[i][j]<INFINITY){\n    return m[i][j];\n}\nif (i == j){\n    m[i][j] = 0;\n}\nelse{\n    for (int k = i; k <= j; i++){\n        int q = (lookUpChain(m,p,i,k)) + (lookUpChain(m,p,k+1,j)) +     (p[i]*p[k]*p[j]);\n        if (q < m[i][j]){\n            m[i][j] = q;\n        }\n    }\n}\nreturn m[i][j];\n\n}\n}\n```\n\n    ", "Answer": "\r\n\n  else{\n      for (int k = i; k <= j; i++)\n\n\nChange to:\n\n```\nelse{\nfor (int k = i; k <= j; k++) // change i to k\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How is Matrix Chain Multiplication a special case of shortest path in DAG?\r\n                \r\nCan DP algorithm for Matrix Chain Multiplication be modeled as shortest path in DAG? I read somewhere that every DP problem is a walk on an implicit DAG but I am unable to visualize those problems in which a transition leads to more than one state ( or sub-state ).\n\nOne more example where I fail to visulize the same is UVA 10003. A DP solution of the above is discussed here: Cutting a stick such that cost is minimized.\n    ", "Answer": "\r\nImagine that there is a directed edge between two states if we can go from the first state to the second one(of course, a state can consist of several parameters). There are no cycles in this graph, so it is DAG. So visualizing a DAG itself is not hard(you can just write down all states and edges between them). But is not necessary can modeled as a shortest path search. For example, in a problem about cutting a rope the value for a state is a sum of values for two other states, so it is not even a path. Anyway, it might impractical to visualize a solution if the number of parameters is very big. And there is no need to do any visualization to solve a problem and prove the correctness of your solution.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "I think the Java Matrix Chain Multiplication algorithm on Wikipedia is incorrect\r\n                \r\nI am nearly certain the Java implementation of ```\nmatrixChainOrder```\n on the Wikipedia page, Matrix Chain Multiplication, is incorrect. I would change it but I am not a well qualified Mathmematician and am not comfortable making the change without first vetting my observation. I guess what I'm asking is - am I correct in this assertion? k should instead be k + 1 because this version is written in zero based indexes unlike the pseudocode version first introduced on the same page.\n\n```\nprotected int[][]m;\nprotected int[][]s;\npublic void matrixChainOrder(int[] p) {\n    int n = p.length - 1;\n    m = new int[n][n];\n    s = new int[n][n];\n\n    for (int ii = 1; ii < n; ii++) {\n        for (int i = 0; i < n - ii; i++) {\n            int j = i + ii;\n            m[i][j] = Integer.MAX_VALUE;\n            for (int k = i; k < j; k++) {\n                int q = m[i][k] + m[k+1][j] + p[i]*p[k+1]*p[j+1];\n                if (q < m[i][j]) {\n                    m[i][j] = q;\n                    s[i][j] = k + 1; // <-- this is the necessary change \n                }\n            }\n        }\n    }\n}\n```\n\n\nedit\n\nI'm near answering my own question, but here's an example that explains the problem created by shifting the algorithm into a zero-based index:\n\nGiven the array = [3,2,4,3,2], these are cost tables generated by the above:\n\n```\nm:\n0   24  42  48  \n0   0   24  36  \n0   0   0   24  \n0   0   0   0   \n\ns:\n0   0   0   0   \n0   0   1   2   \n0   0   0   2   \n0   0   0   0   \n```\n\n\nBy not adding 1 to k (because of zero index shift), you get the wrong places for matrix chaining. You can't parenthesize the matrices at 0 for starters. The correct output for s should be:\n\n```\ns:\n0   1   1   1   \n0   0   2   3   \n0   0   0   3   \n0   0   0   0\n```\n\n\ns[0][3] = 1 means split ABCD at A(BCD)\ns[1][3] = 3 means split A(BCD) at A((BC)D)\n\nThat's it - an optimal cost calculation.\n    ", "Answer": "\r\nNo, the implementation is correct as it is. Changing ```\ns[i][j] = k;```\n to ```\ns[i][j] = k + 1;```\n would break the program.\n\nYou can test this by copying the code into a file called MatrixOrderOptimization.java and adding a ```\nmain```\n function like this one:\n\n```\npublic static void main(String[] args) {\n  MatrixOrderOptimization moo = new MatrixOrderOptimization();\n  moo.matrixChainOrder(new int[]{ 3, 2, 4, 3, 2 });\n  moo.printOptimalParenthesizations();\n}\n```\n\n\nTry compiling and running the program with and without your proposed change. You'll see that making the proposed change results in invalid index values.\n\nWhy is this? Well, the solution value ```\ns[i][j]```\n is defined as the \"index that achieved optimal cost\". That's what it's called in the pseudocode and that's how the Java implementation treats it.\n\nYou point out that in the pseudocode, indices start from 1 and that in the Java implementation, they start from 0. However, the meaning of ```\ns[i][j]```\n in both cases is the index that achieved optimal cost.\n\nIf you modify the indices by adding one, you're throwing off the rest of the program. Think about it this way: instead of changing ```\ns[i][j] = k;```\n to ```\ns[i][j] = k + 1;```\n, change the array accesses in ```\nprintOptimalParenthesizations```\n. In each line where the code refers to ```\ns[i][j]```\n, change that to ```\ns[i][j]+1```\n.\n\nIn other words, replace\n\n```\nprintOptimalParenthesizations(s, i, s[i][j], inAResult);\nprintOptimalParenthesizations(s, s[i][j] + 1, j, inAResult);\n```\n\n\nwith\n\n```\nprintOptimalParenthesizations(s, i, s[i][j]+1, inAResult);\nprintOptimalParenthesizations(s, s[i][j]+1 + 1, j, inAResult);\n```\n\n\nThe effect of these changes is exactly the same as your proposed change. Here we're adding one to the optimal index when we pull it out of the array, whereas you propose adding one to the optimal index when you stick it into the array.\n\nIn both cases, the value becomes incorrect and the program crashes. That's because the meaning of ```\ns[i][j]```\n is not the optimal index plus one. It's simply the optimal index.\n\nThe Java program expects ```\ns```\n to contain optimal indices as it understands optimal indices, meaning that they start from zero. If you alter these values by adding one, you violate the meaning of the indices and break the program.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix chain Multiplication in prolog\r\n                \r\nI have the following solution to matrix multiplication problem.\n\n```\nmatMul([X], os(0, X)).\nmatMul(L, os(A, m(a, d(D1, D2)))) :-\n     append([L1|L1s], [L2|L2s], L),\n     matMul([L1|L1s], os(A1, m(_, d(D1, C1)))),\n     matMul([L2|L2s], os(A2, m(_, d(_, D2)))),\n     A is A1 + A2 + (D1 * C1 * D2).\n```\n\n\nThis program gives me all the possible solutions. \n\n```\n?- matMul([m(a,d(5,4)), m(a,d(4,6)), m(a,d(6,2)), m(a,d(2,7))], A).\nA = os(392, m(a, d(5, 7))) ;\nA = os(244, m(a, d(5, 7))) ;\nA = os(414, m(a, d(5, 7))) ;\n**A = os(158, m(a, d(5, 7))) ;**\nA = os(250, m(a, d(5, 7))) ;\nfalse.\n```\n\n\nAs we can see, one of them is optimal one. \nWhat I would like to do is modify this one to get just one solution the optimal one.\n\nIf anyone can provide any pointer/suggestion to achieve it, that would be really helpful.\n\nThanks.\n    ", "Answer": "\r\nThe quick way to do this would be to use ```\nsetof/3```\n since it sorts in ascending order:\n\n```\noptimum_solution(Matrix, A) :-\n    setof(os(X,M), matMul(Matrix, os(X,M)), S),\n    S = [A|_].   % Select the first element, which has lowest X\n```\n\n\n```\nsetof/3```\n will use a standard ordering of terms when doing the sort.\n\nThen query it as:\n\n```\n| ?- optimum_solution([m(a,d(5,4)), m(a,d(4,6)), m(a,d(6,2)), m(a,d(2,7))], A).\n\nA = os(158,m(a,d(5,7)))\n\nyes\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "mtrix chain multiplication print the sequence of the mattrices\r\n                \r\nI have written code for matrix chain multiplication in dynamic programming in c++.\nthere is an error in the recursive call for printing the correct parenthesization of the matrices. I am taking input from text file and giving output on a text file. please help..\n\n```\n#include <iostream>\n#include <fstream>\n#include <limits.h>\nusing namespace std;\nint * MatrixChainOrder(int p[], int n)\n{\n    static   int m[100][100];\n    static int s[100][100];\n    int j, q;\n    int min = INT_MAX;\n    for (int i = 1; i <= n; i++)\n        m[i][i] = 0;\n\n    for (int L = 2; L <= n; L++) {\n        for (int i = 1; i <= n - L + 1; i++) {\n            j = i + L - 1;\n            m[i][j] = min;\n            for (int k = i; k <= j - 1; k++) {\n                q = m[i][k] + m[k + 1][j] + p[i - 1] * p[k] * p[j];\n                if (q < m[i][j]) {\n                    m[i][j] = q;\n                    s[i][j] = k;\n                }\n            }\n        }\n    }\n    return (*s);\n}\n\nvoid Print(int *s, int i, int j)\n{\n    ofstream outfile(\"output.text\");\n\n    if (i == j)\n    {\n        outfile << \"a1\";\n    }\n    else\n        outfile << \"(\";\n    {\n        Print(*s, i, s[i][j]);\n        Print(*s, s[i][j] + 1, j);\n        outfile << \")\";\n    }\n    outfile.close();\n}\n\nint main()\n{\n    int arr[100];\n    int num, i = 0;\n    ifstream infile(\"input.text\");\n    while (infile)\n    {\n        infile >> num;\n        arr[i] = num;\n        i++;\n    }\n    i = i - 1;\n    infile.close();\n    Print(MatrixChainOrder(arr, i - 1), 0, i - 1);\n    return 0;\n}\n```\n\n    ", "Answer": "\r\nIn C++ it is better to use ```\nstd::vector```\n for arrays. Aside from that, you can't mix pointers and arrays like that because the compiler loses track of array size.\n\nFor example this doesn't work:\n\n```\nint x[10][20];\nvoid foo(int *ptr)\n{\n    //the numbers 10 and 20 have not been passed through\n}\n```\n\n\nBut you can change it to\n\n```\nint x[10][20];\nvoid foo(int arr[10][20])\n{\n    //the numbers 10 and 20 are available\n}\n```\n\n\n```\nMatrixChainOrder```\n is supposed to return a number, according to this link\n\n```\nint MatrixChainOrder(int s[100][100], int p[], int n)\n{\n    int m[100][100];\n    for (int i = 0; i < 100; i++) m[i][i] = 0;\n    for (int i = 0; i < 100; i++) s[i][i] = 0;\n    int q = 0;\n    for (int L = 2; L <= n; L++) {\n        for (int i = 1; i <= n - L + 1; i++) {\n            int j = i + L - 1;\n            m[i][j] = INT_MAX;\n            for (int k = i; k <= j - 1; k++) {\n                q = m[i][k] + m[k + 1][j] + p[i - 1] * p[k] * p[j];\n                if (q < m[i][j]) {\n                    m[i][j] = q;\n                    s[i][j] = k;\n                }\n            }\n        }\n    }\n    return q;\n}\n\nint main()\n{\n    int arr[] = { 40, 20, 30, 10, 30 };\n    int array_size = sizeof(arr) / sizeof(int);\n    int n = array_size - 1;\n    int s[100][100];\n    int minimum = MatrixChainOrder(s, arr, n);\n    printf(\"{ 40, 20, 30, 10, 30 } should result in 26000 : %d\\n\", minimum);\n    return 0;\n}\n```\n\n\nLikewise you can change your ```\nPrint```\n function\n\n```\nvoid Print(int s[100][100], int i, int j)\n{\n    if (i < 0 || i >= 100 || j < 0 || j >= 100)\n    {\n        cout << \"array bound error\\n\";\n    }\n    //safely access s[i][j] ...\n}\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Improving space complexity in matrix chain multiplication\r\n                \r\nI want to know whether there is any way to improve space complexity of Dynamic Programming solution of matrix multiplication problem from O(N^2) to something better?\n    ", "Answer": "\r\nHere is a solution with space compexity O(n)\n\n```\n#include <iostream>\n\nusing namespace std;\n\nint min_cost(int a[], int n) {\n    int* b = new int(n);\n\n    b[1] = 0;\n    b[2] = a[0]*a[1]*a[2];\n\n    for (int j = 3; j < n; j++) {\n        b[j] = min( b[j-1] + a[0]*a[j-1]*a[j], b[j-2] + a[j-1]*a[j-2]*a[j] + a[0]*a[j-2]*a[j]);\n    }\n\n    return b[n-1];\n}\n\nint main() {\n    int arr[] = {10, 20, 30};\n    int size = sizeof(arr)/sizeof(arr[0]);\n\n    printf(\"Minimum number of multiplications is %d \", min_cost(arr, size));\n\n   return 0;\n}\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix chain multiplication algorithm\r\n                \r\nI am reading Thoman Cormen's \"Introduction to Algorithms\" and I have problems understanding the algorithm written below.\n\n```\n        Matrix-Chain-Order(p)\n        1 n ← length[p] − 1\n        2 for i ← 1 to n\n        3     do m[i, i] ← 0\n        4     for l ← 2 to n                     //l is the chain length.\n        5         do for i ← 1 to n − l + 1      // what is this?\n        6                do j ← i + l − 1        // what is this?\n        7                   m[i, j] ← ∞\n        8                   for k ← i to j − 1\n        9                       do q ← m[i, k] + m[k + 1, j] + pi−1pkpj\n       10                          if q < m[i, j]\n       11                            then m[i, j] ← q\n       12                                s[i, j] ← k\n       13 return m and s\n```\n\n\nNow, I know how the algorithm works. I know how to proceed in constructing the table and all that. In other words I know what happens up to line 4 and I also know what 9 to 13 is about.\nI have problems understanding the subtleties of the \"for\" loops though. Lines 4 to 8 are difficult to understand. In line 5 why does i go up to n-l+1 and why is j in line 6 set to i+l-1. In line 7  ,m[i, j] is initialized  for the comparison in line 10 but then again line 8 is a mystery.\n    ", "Answer": "\r\nI was just going through the algorithm definition on wikipedia and it's pretty comprehensive there. I'll try to explain you how I understood the solution. \n\nThe crux of the problem is we are basically trying to 'parenthesise' i.e. prioritize how we chain our matrices so that they are multiplied most efficiently and it's reflected in this line of code:\n\n```\nq = m[i,k] + m[k+1,j] + p[i-1]*p[k]*p[j];\n```\n\n\nTo understand the above stand, first let's establish that ```\ni```\n and ```\nj```\n are fixed here i.e. we are trying to compute m[i,j] or the most efficient way to multiply matrices ```\nA[i..j]```\n and ```\nk```\n is the variable.\n\nSo at a very high level if ```\ni=1```\n and ```\nj=3```\n and the matrices are :\n\n```\n(A*B)*C //We are trying to establish where the outer most parenthesis should be\n```\n\n\nWe don't know where it should be, hence we try all possibilities and pick the combination where ```\nm[i,j]```\n is minimized. So we try:\n\n```\ni=1 and j=3\nA*(B*C) //k=1\n(A*B)*C //k=2\n```\n\n\nSo clearly ```\nk```\n should vary from ```\ni```\n to ```\nj-1```\n which is reflected in the loop as we try all possible combinations and take the most efficient one. So for any ```\nk```\n we'll have two partitions: ```\nA[i..k]```\n and ```\nA[k+1...j]```\n\n\nSo the cost of multiplication of A[i..j] for this partition of ```\nk```\n is:\n\n```\n m[i,k]  //Minimum cost of multiplication of A[i..k]\n\n m[k+1,j] //Minimum cost of multiplication of A[k+1..j]\n\n p[i-1]*p[k]*p[j]; //Final cost of multiplying the two partitions i.e. A[i..k] and A[k+1..j], where p contains the dimensions of the matrices.\n```\n\n\n\n  A is a 10 × 30 matrix, B is a 30 × 5 matrix, and C is a 5 × 60 matrix. Then,\n  p[] = [10,30,5,60] i.e. Matrix Ai has dimension p[i-1] x p[i] for i = 1..n\n\n\nThis is what dynamic programming is all about. So we try all combinations of ```\nk```\n and calculate ```\nm[i,j]```\n but for that we also need to calculate ```\nm[i,k]```\n and ```\nm[k+1,j]```\n i.e. we break our problem down into smaller sub problems where the concept of chain length comes in.\n\nSo for all the matrices ```\nA[i..n]```\n we calculate the most efficient way of multiplying a smaller chain of matrices of length ```\nl```\n.\n\nThe smallest value of ```\nl```\n is obviously 2 and the largest is ```\nn```\n which is what we would get after we solve the smaller sub problems like I explained.\n\nLet's come to the piece of code you are having trouble understanding:\n\n```\n for l ← 2 to n                     //l is the chain length.\n  do for i ← 1 to n − l + 1      \n  do j ← i + l − 1        \n  m[i, j] ← ∞\n```\n\n\nNow let's again consider a smaller example of 4 matrices ```\nH,I,J,K```\n and you are looking at first chain lengths of 2. So when traversing the array of matrices.\n\n```\n A[1..4] = H,I,J,K //where A[1] = H and A[4] = K\n For l = 2\n Our loop should go from i=1 to i=3, as for every i we are looking at the chain of length 2.\n\n So when i = 1, we would compute\n m[1,2] i.e. minimum cost to multiply chain (H,I)\n\n and when i = 3, we would compute\n m[3,4] i.e. minimum cost to multiply chain (J,K)\n```\n\n\nWhen chain length is 3, we would have:\n\n```\n  For i=1, j=3\n  m[i,j] -> m[1,3] i.e. minimum cost to multiply chain (H,I,J)\n\n  For i=2, j=4\n  m[i,j] -> m[2,4] i.e. minimum cost to multiply chain (I,J,K)\n```\n\n\nHence when we define ```\ni```\n to not exceed ```\nn-l+1```\n and ```\nj=i+l-1```\n, we are making sure we are covering all the elements of the array and not exceeding the boundary condition i.e. the size of the array which is ```\nn```\n and ```\nj```\n defines the end of the chain starting from ```\ni```\n with length ```\nl```\n.\n\nSo the problem comes down to calculating ```\nm[i,j]```\n for some ```\ni```\n and ```\nj```\n which as I explained earlier is solved by taking a partition ```\nk```\n and trying out all possible values of ```\nk```\n and then re-defining ```\nm[i,j]```\n as the minimum value which is why it is initialized as ```\n∞```\n.\n\nI hope my answer wasn't too long and it gives you clarity as to how the algorithm flows and helps you appreciate the sheer vastness of dynamic programming. \n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How does BLAS incorporate matrix chain multiplication optimisation\r\n                \r\nBLAS (basic linear algebra subprograms) provide many other programming languages, like Matlab, which I use, with fast routines to do things like matrix multiplication.\n\nHowever, when multiplying multiple matrices together, there is an optimal order to \"bracket\" the matrices. Taken from the wikipedia article:\n\n\n  For example, suppose A is a 10 × 30 matrix, B is a 30 × 5 matrix, and\n  C is a 5 × 60 matrix. Then,\n  \n  (AB)C = (10×30×5) + (10×5×60) = 1500 + 3000 = 4500 operations \n  \n  A(BC) = (30×5×60) + (10×30×60) = 9000 + 18000 = 27000 operations.\n\n\nThe article goes on to discuss ways you solve for the optimal order of this multiplication. My question is, are any of these optimisation procedures utilised in BLAS? If not, can I get better speed if I explicitly define the order of matrix multiplications in programs like Matlab with appropriate use of brackets?\n    ", "Answer": "\r\nA canonical definition of BLAS can be found here and doesn't include a call with multiple matrices. So I don't expect any implementation which follows that definition provides the chaining optimisation you mention. It is hard to give a definitive answer, because BLAS has been done to death in the past 30 years, so there are many implementations out there and who knows, maybe some bored PhD student decided to do it at some point :)\n\nThat being said, there are implementations that are similar but not compatible with BLAS like Eigen which use features like Expression templates (...) to intelligently remove temporaries and enable lazy evaluation, when that is appropriate. This is something promising, but whether it applies to matrix chaining I don't really know. I suspect not, judging by the fact that its not included in their benchmark.\n\nThe bottom line is that the most reliable way to find out, is to just try it out yourself. You can check quite easily for your language/implementation of choice: just try out the example you have in your question but preferably with larger sizes, e.g. all dimensions times 100.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Are numpy matrix chain multiplication optimized?\r\n                \r\nI used to use the ```\nmatmul```\n (```\n@```\n) operator all the time in ```\nnumpy```\n, but I recently found the function numpy.linalg.multi_dot, according to the docs\n\nuses optimal parenthesization of the matrices. Depending on the shapes of the matrices, this can speed up the multiplication a lot.\n\nso given that ```\nmatmul```\n is a binary operator, I'm assuming it does not perform optimal parenthesization. Is this true? also, would it be possible to implement optimal parenthesization on a binary operator in python?\n    ", "Answer": "\r\nIt's probably possible to write an array type that does optimal parenthesize of matrix multiplication. You could write an array that defers the actual multiplication process, returning a proxy object instead of an array containing the results. Only when some non-multiplication operation is attempted on the array, would the proxy do the actual multiplication (using optimal parenthesization). The tedious thing would be setting up the proxy behavior for the custom type, so that you can do the deferred multiplication before any other operation.\nFor example, here's a class that wraps around an array and queues up matrix multiplications, but only performs them when an indexing or slicing operation is attempted:\n```\nclass DeferredMultiplicationArray:\n    def __init__(self, *arrays):\n        self.arrays = arrays\n\n    def __matmul__(self, rhs):\n        return DeferredMultiplicationArray(*self.arrays, rhs)\n\n    def __getitem__(self, index):\n        if len(self.arrays) > 1:\n            self.arrays = [numpy.linalg.multi_dot(self.arrays)]\n        return self.arrays[0][index]\n```\n\nThis doesn't support lots of other operations that real numpy arrays do, so it's not a full solution, but it demonstrates the general idea of deferring the multiplication until the results are needed, so that you can queue up any further matrix multiplications you get. Here's how it would operate:\n```\n>>> a = np.array([[1, 2, 3], [2, 3, 4]])\n>>> b = np.array([[3,4, 5, 6], [3, 2, 1, 0], [4, 5, 6, 7]])\n>>> c = [[1], [2], [3], [4]]\n>>> d = [[1,2,3,4,5,6]]\n>>> a @ b @ c @ d        # normal numpy matrix multiplication\narray([[ 250,  500,  750, 1000, 1250, 1500],\n       [ 370,  740, 1110, 1480, 1850, 2220]])\n\n>>> A = DeferredMultiplicationArray(a) @ b @ c @ d\n>>> A.arrays             # no multiplication has been done yet\n(array([[1, 2, 3],\n        [2, 3, 4]]),\n array([[3, 4, 5, 6],\n        [3, 2, 1, 0],\n        [4, 5, 6, 7]]),\n [[1], [2], [3], [4]],\n [[1, 2, 3, 4, 5, 6]])\n\n>>> A[:]         # slice the array to make our class do the actual multiplication\narray([[ 250,  500,  750, 1000, 1250, 1500],\n       [ 370,  740, 1110, 1480, 1850, 2220]])\n\n>>> A.arrays     # the result is now saved, not the inputs any more\n[array([[ 250,  500,  750, 1000, 1250, 1500],\n        [ 370,  740, 1110, 1480, 1850, 2220]])]\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Chain Matrix Multiplication : Multiply Algorithm not working\r\n                \r\nI have implemented a chain matrix multiplication. Although I get correct chain order, but while doing actual multiplication, the given multiply algorithm is not working properly. My Java Code:-\n\n```\npackage algopackage;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class ChainMatrixMultiplication {\n\n    static int s[][];\n\n    static int x[][];\n\n    static int y[][];\n\n    public ChainMatrixMultiplication() {\n    }\n\n    static void chainMatrixMultiplication(int[] p) {\n        boolean isFirst = false;\n        int n = p.length-1;\n        int m[][] = new int[n][n];\n        s = new int[n][n];\n        for (int c = 0; c < n; c++) \n            m[c][c] = 0; \n        for (int counter = 1; counter < n; counter++) {\n            for (int i = 0;i < n; i++) {\n                isFirst = false;\n                int j = i + counter;\n                for (int k = i; k < j && j < n; k++) {\n                    int result = m[i][k] + m[k+1][j] + p[i] * p[k+1] * p[j+1];\n                    if (!isFirst) {\n                        m[i][j] = result;\n                        s[i][j] = k;\n                        isFirst = true;\n                    } else if (m[i][j] > result) {\n                        m[i][j] = result;\n                        s[i][j] = k;\n                    }\n                }\n            }\n        }\n    }\n\n    static int[][] matrixMultiply(List<Matrix> matrices, int s[][], int i ,int j) {\n        if (i ==j) return matrices.get(i).getMatrix();\n         else {\n             int k = s[i][j];\n             x = matrixMultiply(matrices, s, i, k);\n             y = matrixMultiply(matrices, s, k+1, j);\n             return mult(x,y);\n        }\n    }\n\n    static int[][] mult(int[][] x, int[][] y) {\n        int [][] result = new int[x.length][y[0].length];\n\n        /* Loop through each and get product, then sum up and store the value */\n        for (int i = 0; i < x.length; i++) { \n            for (int j = 0; j < y[0].length; j++) { \n                for (int k = 0; k < x[0].length; k++) { \n                    result[i][j] += x[i][k] * y[k][j];\n                }\n            }\n        }\n\n        return result;\n    }\n\n    public static void main(String[] args) {\n        int p[] = {5,4,6,2};\n        List<Matrix> matrices = new ArrayList<Matrix>();\n        Matrix m1 = new Matrix(5,4);\n        int arr[] = {1,2,40,2,3,29,10,21,11,120,23,90,24,12,11,1,11,45,23,21};\n        m1.addElementsToMatrix(5, 4, arr);\n        Matrix m2 = new Matrix(4,6);\n        int arr1[] = {1,1,1,2,3,12,12,3,10,12,12,29,22,11,22,11,11,11,13,1,2,12,4,2};\n        m2.addElementsToMatrix(4, 6, arr1);\n        Matrix m3 = new Matrix(6,2);\n        int arr2[] = {1,1,12,3,22,11,13,1,2,12,12,12};\n        m3.addElementsToMatrix(6, 2, arr2);\n        matrices.add(m1);\n        matrices.add(m2);\n        matrices.add(m3);\n        chainMatrixMultiplication(p);\n        matrixMultiply(matrices,s,0,2);\n    }\n\n}\n\nclass Matrix {\n\n       private final int[][] matrix;\n\n       public Matrix(int rows, int cols) {\n            this.matrix = new int[rows][cols];\n       }\n\n       public void addElementsToMatrix(int rows, int cols, int[] arr) {\n           int counter = 0;\n           for (int i = 0; i < rows; i++) {\n               for (int j = 0; j < cols; j++) {\n                   matrix[i][j] = arr[counter++];\n               }\n           }\n\n       }\n\n       public int[][] getMatrix() {\n           return matrix;\n       }\n}\n```\n\n\nIn the above code matrixMultiply() function is throwing exception. Exception is caused as matrices are not being multiplied as expected. As recursion is not behaving as expected. I am missing something in this code. Any help will be appreciated.Thanks!\n    ", "Answer": "\r\nI'm not sure of the correctness of your code, but looking at the matrix multiplication output when you multiply matrix of dimension a*b and c*d after you multiply, you get a matrix of dimension a*d there by changing\n\n```\nfor (int k = 0; k < x[0].length; k++) { \n```\n\n\nto \n\n```\nfor (int k = 0; k < y[0].length; k++) { \n```\n\n\nshould resolve the problem.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Possible Combination of Parentheses in a Matrix Chain Application\r\n                \r\nI have studied matrix chain multiplication, wherein given a sequence of matrices, the goal is to find the most efficient way to multiply matrices. The problem is not actually to perform the multiplications, but merely to decide the sequence of the matrix multiplications involved. That is the reason why I am tasked to make a program that outputs all possible combinations of matrices in a matrix multiplication  given n as the number of matrices as an input. For example\n\n```\n n == 1     (A)\n\n n == 2     (AB)\n\n n == 3     (AB)C ,  A(BC)\n\n n== 4      ((AB)C)D,   (A(BC))D, A((BC)D), A(B(CD)), (AB)(CD)\n```\n\n\nMy intial code was below, called by \n\n```\n possible_groupings(4) #4 matrices\n\ndef possible_groupings(n):\n    print(\"Possible Groupings : \")\n    total  = 0\n    if(n==1):\n        print('A')\n        total = total + 1\n    elif(n==2):\n       print('(AB)')\n       total = total + 1\n    else:\n       a = 2\n       while(a <= n-1):\n           b = 0\n           while((b+a) <= (n )):\n               c = b\n\n               d = 0\n               substr = ''\n               while (d < c):                    \n                   substr = substr + chr(65 + d)                    \n                   d = d + 1\n\n               if substr != '':\n                   if len(substr) == 1:\n                      print( substr, end = '')\n                   else:\n                      print('(' + substr + ')', end = '')\n\n            print('(', end = '')\n            while (c < (b +a)):                    \n                print(chr(65 + c), end = '');\n                c = c + 1\n            print(')', end = '')\n\n            e = b+a\n\n            substr = ''\n            while (e < n):\n                substr = substr + chr(65 + e) \n                e = e + 1\n            if substr != '':\n                if len(substr) == 1:\n                    print( substr, end = '')\n                else:\n                    print('(' + substr + ')', end = '')\n            print('')\n\n            total = total + 1\n\n            b = b + 1\n        a = a + 1\nprint('Total : ' + str(total))\n```\n\n\nThe output of the code above when my inout is 4 matrices is:\n\n```\n(AB)(CD)\nA(BC)D\n(AB)(CD)\n(ABC)D\nA(BCD)\n```\n\n\nHow can I revise my code. The number of matrices must be in the range 1-26. My head now is aching. Please help.\n    ", "Answer": "\r\nHere is a recursive scheme that works back-to-front.\n\nIt is implemented as a generator, ```\npart```\n, that starts with the last multiplication. This last multiplication must be between two factors the left of which is a product over the first j (variable ```\ncut```\n in the code below) matrices (\"left block\") and the right of which is a product over the remaining matrices (\"right block\"). j can be anything between 1 and N-1 where N is the number of matrices in the chain.\n\nTherefore, to enumerate all groupings we must loop over j. For each j we must combine each grouping of the left block with each grouping of the right block. To enumerate the groupings of the blocks we use ```\npart```\n itself, i.e. recursion.\n\n```\ndef part(names, top=True):\n    lr = ('', '') if top else '()'\n    if len(names) <= 1:\n        yield names\n    elif len(names)==2:\n        yield names.join(lr)\n    else:\n        for cut in range(1, len(names)):\n            for left in part(names[:cut], False):\n                for right in part(names[cut:], False):\n                    yield (left+right).join(lr)\n```\n\n\nThe same logic can be used for the minimizer. This can utilize memoization as provided by ```\nfunctools.lru_cache```\n:\n\n```\nfrom functools import lru_cache\nfrom string import ascii_uppercase\n\n@lru_cache(None)\ndef _min_no_mult(dims):\n    if len(dims) == 2:\n        return 0, 'x'\n    elif len(dims)==3:\n        return dims[0]*dims[1]*dims[2], 'xx'.join('()')\n    cuts = ((cut, *_min_no_mult(dims[:cut+1]), *_min_no_mult(dims[cut:]))\n            for cut in range(1, len(dims)-1))\n    return min((mnl + mnr + dims[0]*dims[-1]*dims[cut], (nml+nmr).join('()'))\n                for cut, mnl, nml, mnr, nmr in cuts)\n\ndef min_no_mult(dims, names=None):\n    mn, argmn = _min_no_mult(tuple(dims))\n    names = iter(ascii_uppercase if names is None else names)\n    argmn = argmn[1:-1] if len(dims) > 2 else argmn\n    argmn = ''.join(next(names) if a=='x' else a for a in argmn)\n    return mn, argmn\n```\n\n\nDemo:\n\n```\n>>> for i, j in enumerate(part(ascii_uppercase[:6])):\n...     print(i, j)\n... \n0 A(B(C(D(EF))))\n1 A(B(C((DE)F)))\n2 A(B((CD)(EF)))\n3 A(B((C(DE))F))\n4 A(B(((CD)E)F))\n\n...\n\n38 ((A((BC)D))E)F\n39 (((AB)(CD))E)F\n40 (((A(BC))D)E)F\n41 ((((AB)C)D)E)F\n```\n\n\nThanks to memoization, the minimizer can easily handle large numbers of dimensions:\n\n```\n>>> import numpy as np\n>>> dims = np.clip(np.arange(-1, 26), 1, None)\n>>> np.random.shuffle(dims)\n>>> dims\narray([ 5, 25,  1,  4, 14, 24,  7, 15,  2, 12, 11,  9, 18,  8, 19, 13, 23,\n       17,  1, 22, 21,  1, 16,  6,  3, 20, 10])\n\n>>> min_no_mult(dims)\n(3383, '(AB)((((((((((CD)E)F)G)H)(I(J(K(L(M(N(O(P(QR))))))))))((ST)U))((VW)X))Y)Z)')\n```\n\n\nWe can query some basic cache statistics:\n\n```\n>>> _min_no_mult.cache_info()\nCacheInfo(hits=5450, misses=351, maxsize=None, currsize=351)\n```\n\n\nThis may look unimpressive but keep in mind that each hit cuts an entire subtree.\n\nIndeed, we can once more recycle the recurrence scheme and count the number of bracketings:\n\n```\n@lru_cache(None)\ndef count(n):\n    if n <= 2:\n        return 1\n    else:\n        return sum(count(cut) * count(n-cut) for cut in range(1, n))\n```\n\n\nFor 26 matrices there are quite a few ways of parenthesizing them:\n\n```\n>>> print(f\"{count(26):,d}\")\n4,861,946,401,452\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "java matrix chain multiplication array index out of bound exception\r\n                \r\n```\nTrying to do chain matrix multiplication but the code throws an out of bound exception at 2 places, please help me eliminate it.\nThe exception occurs at 2 places\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: 7\n    at Recursive.Recursive_Matrix(Recursive.java:27)\n    at Recursive.main(Recursive.java:15).\n```\n\n\nThe problem using the following recursion by repeatedly calling itself as follows:\n\n```\n mij =  0, if   i = j else it is\n\n        min   ( mik + mk+1 j + ri-1 * rk * rj )    if  i < j\n             i ≤ k < j\n```\n\n\nI think its related to MAX value being 99999.Or, it would be due to some other comparisons. \n\n```\n class Recursive{\n\n\n    public static int SIZE = 7;\n    public static int MAX = 99999;\n\n    static int M[][] = new int[SIZE][SIZE];\n    static int i, k, q, j;\n    static int P[] = new int []  { 25,10,15,5,30,10,15};\n\n\n    public static void main(String[] args)\n    {\n\n        Recursive_Matrix( 1, SIZE);\n        Print_M();\n\n       return;\n    }\n\n    static int Recursive_Matrix(int i, int j) \n    {\n        if( i == j )\n            return 0;\n        else\n        {\n            M[i][j] = MAX;\n            for(k = i; k <= j-1; k++)\n            {\n                q =  Recursive_Matrix(i, k) + Recursive_Matrix( k+1, j) +  ( P[i-1] * P[k] * P[j] );\n                if( q < M[i][j])\n                    M[i][j] = q;\n            }\n        }\n        return M[i][j]; \n    }\n```\n\n\n//this function is simply used to print the elements of the matrix\n//the diagonal elements are all 0, and the other elements are computed from the above recursive function.\n        static void Print_M()\n        {\n            for(int x = 1; x<= SIZE; x++)\n            {\n                for(int y = 1; y <= SIZE; y++)\n                {\n                    System.out.println(M[x][y]+\"  \");\n                }\n                System.out.println(\"\\n\");\n            }\n        }\n        }\n    ", "Answer": "\r\nJust have a look at your first call ```\nRecursive_Matrix( 1, SIZE);```\n. Now ```\nj=7```\n and later ```\n...M[j]...```\n and  ```\n...P[j]...```\n which is out of bound as indexes start with ```\n0```\n. Use your debugger and step through the code!\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Why does this code for chain matrix multiplication return a segmentation fault?\r\n                \r\nI was writing a program to execute chain matrix multiplication for number of rows and columns being random numbers greater than 1000. The program performs chain matrix multiplication for 10 matrices all having dimensions greater than 1000. These dimensions are assigned dynamically using srand(). Using OpenMP, the program is running on 4 threads\nHowever, whenever I run it its getting compiled but upon execution, it returns the error, 'Segmentation fault (core dumped)'\nHow do I fix this?\nThis is the code\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <limits.h>\n#include <omp.h>\n\nvoid matrix_chain_multiply(int *p, int n, int num_threads) {\n    // Allocate memory for matrix chain and auxiliary arrays\n    int **m = (int **)calloc(n, sizeof(int *));\n    int **s = (int **)calloc(n, sizeof(int *));\n    if (m == NULL || s == NULL) {\n        printf(\"Error: memory allocation failed\\n\");\n        exit(1);\n    }\n    for (int i = 0; i < n; i++) {\n        m[i] = (int *)calloc(n, sizeof(int));\n        s[i] = (int *)calloc(n, sizeof(int));\n        if (m[i] == NULL || s[i] == NULL) {\n            printf(\"Error: memory allocation failed\\n\");\n            exit(1);\n        }\n    }\n\n    // Set the number of threads\n    omp_set_num_threads(num_threads);\n\n    // Compute the matrix chain product using dynamic programming\n    for (int l = 2; l <= n; l++) {\n        #pragma omp parallel for schedule(dynamic)\n        for (int i = 1; i <= n - l + 1; i++) {\n            int j = i + l - 1;\n            m[i][j] = INT_MAX;\n            for (int k = i; k <= j - 1; k++) {\n                int q = m[i][k] + m[k+1][j] + p[(i-1)*2] * p[k*2+1] * p[j*2+1];\n                if (q < m[i][j]) {\n                    m[i][j] = q;\n                    s[i][j] = k;\n                }\n            }\n        }\n    }\n\n    // Free memory\n    for (int i = 0; i < n; i++) {\n        free(m[i]);\n        free(s[i]);\n    }\n    free(m);\n    free(s);\n}\n\nint main() {\n    int n = 10; // number of matrices\n    int num_threads = 4; // number of threads to use\n    int *p = (int *)malloc(sizeof(int) * (n+1) * 2);\n    if (p == NULL) {\n        printf(\"Error: memory allocation failed\\n\");\n        exit(1);\n    }\n    srand(time(NULL));\n    for (int i = 0; i < n; i++) {\n        p[i*2] = rand() % 1001 + 1000; // rows\n        p[i*2+1] = rand() % 1001 + 1000; // columns\n    }\n\n    double start_time = omp_get_wtime();\n    matrix_chain_multiply(p, n, num_threads);\n    double end_time = omp_get_wtime();\n    double time = end_time - start_time;\n    printf(\"Time: %f\\n\", time);\n\n    // Free memory\n    free(p);\n\n    return 0;\n}\n\n```\n\n    ", "Answer": "\r\n\nOut of bounds access to your array ```\nm```\n where ```\nk == 9```\n as ```\nm```\n is a ```\nn```\nx```\nn```\n array with ```\nn = 10```\n:\n\n```\nint q = m[i][k] + m[k+1][j] + p[(i-1)*2] * p[k*2+1] * p[j*2+1];\n```\n\nso maybe the loop should be ```\nfor (int k = i; k < j - 1; k++)```\n?\n\nSigned integer overflow:\n\n```\n$ gcc -g3 -fsanitize=undefined 1.c\n$ ./a.out\n1.c:34:57: runtime error: signed integer overflow: 3572439 * 1615 cannot be represented in type 'int'\nSegmentation fault\n```\n\nwhere the line in question is:\n```\nint q = m[i][k] + m[k+1][j] + p[(i-1)*2] * p[k*2+1] * p[j*2+1];\n```\n\nUse smaller numbers or bigger type (for example long).  If you change all your sizeof to use variables rather types then this is easier.  For example:\n```\n    long *p = malloc((n+1) * 2 * sizeof *p);\n```\n\n\nWith ```\nn = 10```\n you allocate 22 elements with the line above but later initialize 20 of them:\n\n```\n    for (int i = 0; i < n; i++) {\n        p[i*2] = rand() % 1001 + 1000; // rows\n        p[i*2+1] = rand() % 1001 + 1000; // columns\n    }\n```\n\n\n```\nmatrix_chain_multiple()```\n doesn't make much sense to me.  You pass in the input matrix ```\np```\n calculate ```\nm```\n and ```\ns```\n which you then free.\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "All Possible Groupings in a Matrix Chain Application\r\n                \r\nI have studied matrix chain multiplication, wherein given a sequence of matrices, the goal is to find the most efficient way to multiply matrices. The problem is not actually to perform the multiplications, but merely to decide the sequence of the matrix multiplications involved. \n\nSo say for example. Given 2 matrices A and B, I can have one possible matrix combination which is ```\n(AB)```\n and when my matrices are 3: ```\nA, B, C,```\n I can have two possible combinations: ```\n(AB)C```\n and ```\nA (BC)```\n. I want to implement a code given the number of matrices will output all possible matrix combinations in Python. \n\nThe code below is not right because given n = 3 matrices it outputs 5 combinations, when in fact it should be 2 only. The code below is printing all combinations of balanced parentheses.\n\n```\n def printParenthesis(str, n): \n     if(n > 0): \n         _printParenthesis(str, 0,  \n                      n, 0, 0,0); \n     return; \n\n def _printParenthesis(str, pos, n,  \n                  open, close, count): \n\n     if(close == n): \n         for i in str: \n             print(i, end = \"\"); \n         print(); \n         return; \n     else: \n         if(open > close): \n             str[pos] = '}'; \n             _printParenthesis(str, pos + 1, n,  \n                          open, close + 1, count); \n         if(open < n): \n             str[pos] = '{' + chr(65+count); \n            _printParenthesis(str, pos + 1, n,  \n                          open + 1, close, count+1); \n\n# Driver Code \nn = 3;  //Number of matrices\nstr = [\"\"] * 2 * n; \nprintParenthesis(str, n); \n```\n\n\nHow will I modify my code above to fit my problem? Please help .\n    ", "Answer": "\r\nSee below link , I cannot comment on this low points, so pls bear\nhttps://www.google.co.in/amp/s/www.geeksforgeeks.org/matrix-chain-multiplication-dp-8/amp/\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Assigning result of chain matrix multiplication to a variable in Maxima\r\n                \r\nI'm trying to assign the result of a chain matrix multiplication in Maxima to a new variable. I'm not sure as a new user why line %o6 isn't the same as the previous and fully evaluate the chain. Also why when I enter the new variable name \"B\" I simply have \"B\" returned back to me and not ([32, 32], [32, 32]). Basic questions I know but I've searched the documentation for a number of hours, and tutorials, and the syntax that I'm supposed to use here to get what I guess I was expecting as output, is still unclear to me.\n\n\n    ", "Answer": "\r\nI can't tell for sure, but it appears that the problem is that ```\nB : A.A.A```\n is entered holding the shift key for at least one of the spaces, and Shift+Space is interpreted as non-breaking space instead of ordinary space. This appears to be a known bug or at least a serious misfeature in wxMaxima; see: https://github.com/wxMaxima-developers/wxmaxima/issues/1031\n\n(I say misfeature because Shift+Space --> non-breaking space is documented in the wxMaxima documentation, but it seems like a classic example of \"bad affordance\"; it is all too easy to do the wrong thing without knowing it. Anyway this is just my opinion.)\n\nI built wxMaxima from current source code and it appears that Shift+Space is now not interpreted as non-breaking space in code, so ```\nB : A.A.A```\n should have the expected effect even if shift key is held while typing space. The current version is 19.07.0-DevelopmentSnapshot. I poked through the commit log a bit, but I can't figure out which commit changed the behavior of Shift+Space, so it's possible that the problem is not fixed and it is just fortuitous that I am not encountering it.\n\nThere are two workarounds, if one doesn't want to hazard an upgrade. (1) Omit spaces. (2) Be careful to only type space without shift.\n\nHope this is helpful in some way.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication subproblem graph vertex degree\r\n                \r\nI am studying dynamic programming and in chapter 15.2 of the Cormen's Introduction to Algorithms one reads:\n\n\n  For matrix-chain multiplication, if we were to draw the subproblem graph, it would have ```\nO(n^2)```\n vertices and each vertex would have degree at most ```\nn - 1```\n, giving a total of ```\nO(n^3)```\n vertices and edges.\n\n\nand when I draw a graph of ```\nn = 4```\n, I get:\n\n\n\nBut, vertex ```\nM[1, 4]```\n has degree 6 > 4 - 1. What I misunderstood?\n    ", "Answer": "\r\nSolving a subproblem should give you a solution to the main problem, though possibly not the best one. So, a subproblem here is the computation of two products, not one. For the product ```\nA1 A2 A3 A4```\n with ```\nn=4```\n we have three, i.e. ```\nn-1```\n, subproblems: (```\nA1```\n, ```\nA2 A3 A4```\n), (```\nA1 A2```\n, ```\nA3 A4```\n) and (```\nA1 A2 A3```\n, ```\nA4```\n).\n\nEdit. The book also reads:\n\n\n  Thus, we can build an optimal solution to an instance of the matrix-chain multiplication problem by splitting the problem into two subproblems (optimally parenthesizing ```\nAi ... Ak```\n and ```\nAk+1 ... Aj```\n), ...\n\n\nSo, the subproblem is a computation of a single product, not two. It seems that either the book has inconsistency in the definition of a subproblem, or ```\nn-1```\n bound is not correct, and should be ```\n2(n-1)```\n.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How to do Matrix Chain Multiplication (MCM) with Java threads?\r\n                \r\nI want to do MCM with threads of Java.\nHow can I achieve it?\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Chain Multiplication using Dynamic Programming in C++ Program Crashes?\r\n                \r\nI have written following C++ program to implement to implement MCM using Dynamic Programming. But the following program crashes. What is wrong in my code ?\n\n```\n#include<iostream>\n#include<cstdlib>\n#define SZ 10\nusing namespace std;\n\nint table[SZ][SZ];\nint P[] = {2,3,3,5};\n\nint MCM(int i, int j)\n{\n    if(i==j) return 0;\n\n    else\n    {\n        int min = INT_MAX;\n\n        for(int k=i;k<=j;k++)\n        {\n            if(table[i][k]==0)\n                table[i][k] = MCM(i,k);\n            if(table[k+1][j]==0)\n                table[k+1][j] = MCM(k+1,j);\n            int sum = table[i][k] + table[k+1][j] + P[i-1]*P[j]*P[k];\n            if(sum<min)\n                min = sum;  \n        }\n        return min;\n    }\n}\n\nint main()\n{\n    int size = sizeof(P)/sizeof(P[0]);\n    printf(\"Minimum number of mutiplications is %d\",MCM(0,size-1));\n    return 0;\n}\n```\n\n    ", "Answer": "\r\nYour code is going to infinite loop. Besides you have made some mistakes:\n\n\nYou have never assigned the optimum value in the table (when you find minimum sum, you are not storing it). Hence every time you are checking for table[i][j] == 0, it's true\nk in your loop can be equal to j and you are using k+1, this is a mistake\n\n\nAnyway I think the right version of your code should be something like this:\n\n```\n#include<iostream>\n#include<cstdlib>\n#define SZ 10\nusing namespace std;\n\nint table[SZ][SZ];\nint P[] = {1,2,3,4};\n\nint MCM(int i, int j)\n{\n    if(i==j) return 0;\n\n    else\n    {\n        int min = INT_MAX;\n\n        for(int k=i;k<j;k++)\n        {\n            if(table[i][k]==0)\n                table[i][k] = MCM(i,k);\n            if(table[k+1][j]==0)\n                table[k+1][j] = MCM(k+1,j);\n            int sum = table[i][k] + table[k+1][j] + P[i]*P[j]*P[k];\n            if(sum<min)\n                min = sum;\n       }\n       table[i][j] = min;\n       return min;\n   }\n```\n\n\n}\n\n```\nint main()\n{\n    int size = sizeof(P)/sizeof(P[0]);\n    printf(\"Minimum number of mutiplications is %d\",MCM(0,size-1));\n    return 0;\n}\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "OpenMP Performance Issues with Matrix Multiplication\r\n                \r\nI am  having issues with the performance using OpenMp. I am trying to test the results of a single threaded program not using OpenMP and an app using OpenMP. By looking at results online that are comparing matrix chain multiplication programs the openMP implementation is 2 to 3 times as fast, but my implementation is the same speed for both apps. Is the way I am implementing openMP incorrect? Any pointers on openMP and how to correctly implement it? Any help is much appreciated. Thanks in advance.\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n\nint main( int argc , char *argv[] ) \n{\n   srand(time(0));\n   if ( argc != 2 )\n   {\n      printf(\"Usage: %s <size of nxn matrices>\\n\", argv[0]);\n      return 1; \n   }\n\n   int n = atoi( argv[1] );\n   int a, b;\n   double A[n][n], B[n][n], C[n][n];\n   FILE *fp;\n   fp = fopen(\"/home/mkj0002/CPE631/Homework2/ArrayTry/matrixResults\", \"w+\"); //For the LeCASA machine\n\n   for(a = 0; a < n; a++)\n   {\n       for(b = 0; b < n; b++)\n       {\n          A[a][b] = ((double)rand()/(double)RAND_MAX);  //Number between 0 and 1\n          A[a][b] = (double)rand();         //Number between 0 and RAND_MAX\n          B[a][b] = ((double)rand()/(double)RAND_MAX);  //Number between 0 and 1\n          B[a][b] = (double)rand();         //Number between 0 and RAND_MAX\n          C[a][b] = 0.0;\n       }\n    }\n\n    #pragma omp parallel shared(A,B,C)\n    {\n        int i,j,k;\n        #pragma omp for schedule(guided,n)\n        for(i = 0; i < n; ++i)\n        {\n            for(j = 0; j < n; ++j)\n            {\n                double sum = 0;\n                for(k = 0; k < n; ++k)\n                {\n                    sum += A[i][k] * B[k][j];\n                }\n\n                C[i][j] = sum;\n                fprintf(fp,\"0.4lf\",C[i][j]);\n            }\n        }\n    }\n\n    if(fp)\n    {\n        fclose(fp);\n    }\n    fp = NULL;\n\n    return 0;\n}                  \n```\n\n    ", "Answer": "\r\n(1) Don't perform I/O inside your parallel region. You'll see instantaneous speedup when you move that out and write many ```\nC```\n variables simultaneously to file.\n\n(2) After you've done the above, you should then change your scheduling to ```\nstatic```\n because each loop will be doing the exact same amount of computations and there's no longer a need to incur the overhead from fancy scheduling.\n\n(3) Furthermore, to better utilize caching, you should swap your ```\nj```\n and ```\nk```\n loops. To see this, imagine accessing just your ```\nB```\n variable in your current loops.\n\n```\nfor(j = 0; j < n; ++j)\n{\n    for(k = 0; k < n; ++k)\n    {\n        B[k][j] += 5.0;\n    }\n}\n```\n\n\nYou can see how this accesses B as if it was stored in Fortran's column-major format. More info can be found here. A better alternative is:\n\n```\nfor(k = 0; k < n; ++k)\n{\n    for(j = 0; j < n; ++j)\n    {\n        B[k][j] += 5.0;\n    }\n}\n```\n\n\nComing back to your example though, we still have to deal with the ```\nsum```\n variable. An easy suggestion would be storing the row of current ```\nsum```\ns you're computing and then saving them all once you're done with your current loop. \n\nCombining all 3 steps, we get something like:\n\n```\n#pragma omp parallel shared(A,B,C)\n{\n    int i,j,k;\n    double sum[n]; // one for each j\n\n    #pragma omp for schedule(static)\n    for(i = 0; i < n; ++i)\n    {\n        for(j = 0; j < n; ++j)\n            sum[j] = 0;\n\n        for(k = 0; k < n; ++k)\n        {\n            for(j = 0; j < n; ++j)\n            {\n                sum[j] += A[i][k] * B[k][j];\n            }\n        }\n\n        for(j = 0; j < n; ++j)\n            C[i][j] = sum[j];\n    }\n}\n\n// perform I/O here using contiguous blocks of C variable\n```\n\n\nHope that helps.\n\nEDIT: As per @Zboson's suggestion, it would be even easier to simply remove ```\nsum[j]```\n entirely and replace it with ```\nC[i][j]```\n throughout the program.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Explanation for chained Matrix Multiplication using DP?\r\n                \r\nI could not understand the optimised chained Matrix multiplication(using DP) code example given in my algorithm's book.\n\n```\nint MatrixChainOrder(int p[], int n)\n{\n\n    /* For simplicity of the program, one extra row and one extra column are\n       allocated in m[][].  0th row and 0th column of m[][] are not used */\n    int m[n][n];\n\n    int i, j, k, L, q;\n\n    /* m[i,j] = Minimum number of scalar multiplications needed to compute\n       the matrix A[i]A[i+1]...A[j] = A[i..j] where dimention of A[i] is\n       p[i-1] x p[i] */\n\n    // cost is zero when multiplying one matrix.\n    for (i = 1; i < n; i++)\n        m[i][i] = 0;\n\n    // L is chain length.  \n    for (L=2; L<n; L++)   \n    {\n        for (i=1; i<=n-L+1; i++)\n        {\n            j = i+L-1;\n            m[i][j] = INT_MAX;\n            for (k=i; k<=j-1; k++)\n            {\n                // q = cost/scalar multiplications\n                q = m[i][k] + m[k+1][j] + p[i-1]*p[k]*p[j];\n                if (q < m[i][j])\n                    m[i][j] = q;\n            }\n        }\n    }\n\n    return m[1][n-1];\n}\n```\n\n\nWhy does the first loop starts from 2 ? \nWhy is j set to i+L-1 and i to n-L+1 ?\n\nI understood the recurrence relation, but could not understand why loops are set like this ?\n\nEDIT:\n\nWhat is the way to get the parenthesis order after DP ?\n    ", "Answer": "\r\nIn bottom up, that is DP we try to solve the smallest possible case first(we solve each smallest case). Now when we look at the recurrence (m[i,j] represents cost to parenthise from i , j..)\n\n\n\nWe can see that the smallest possible solution(which will be needed by any other larger sub problem) is of a smaller length than that we need to solve... For P(n) .We need all the costs of parenthising the expression with length lessser than n. This leads us to solve the problem lengthwise... (Note l in the outer loop represents length of the segment whose cost we are trying to optimise)\n\nNow first we solve all the sub problems of length 1 i.e. 0 always (No multiplication required)...\n\nNow your question L=2 -> L=n\nwe are varying length from 2 to n just to solve the sub problems in order...\n\ni is the starting point of all the sub intervals such that they can be the begining of an interval of length l..\n\nNaturally j represents the  end of sub interval -> i+l-1 is the end of sub interval (just because we know the starting point and length we can figure out the end of subinterval)\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Is this a redundant allocation of memory space in a multi dimensional array?\r\n                \r\nFrom the Matrix Chain Multiplication page on Wikipedia, there is this fragment of Java code:\n\n```\npublic void matrixChainOrder(int[] p) {\n    int n = p.length - 1;\n    m = new int[n][n];\n    s = new int[n][n];\n    for (int i = 0; i < n; i++) {\n        m[i] = new int[n];\n        m[i][i] = 0;\n        s[i] = new int[n];\n    }\n    ...\n```\n\n\nIsn't ```\nm = new int[n][n];```\n already allocating memory space of size ```\nn```\n in both its dimensions so this step in the loop ```\nm[i] = new int[n];```\n is actually redundant because all it does is reallocate the second dimension again?\n    ", "Answer": "\r\nYes, it is. \n\n```\nm[i] = new int[n];```\n is absolutely superfluous. And it seems that this line is heritage from ```\nc```\n-style psedocode, where such initilization was nessecary. \n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Dynamic programing mcm\r\n                \r\nI am stuck with an assignment problem\nArgue and prove that matrix chain multiplication exhibit optimal substructure property. I understand the concept but I am not getting how to prove it on paper.Any help will be great relief.\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Does the TensorFlows XLA compiler optimise matrix chains as a part of its graph optimisation?\r\n                \r\nA matrix chain is a chain of matrix matrix product. I consider the following matrix chain:\n\nABC;  where A and B are of size 3000x3000 and C is of size 3000x600\n\nThere are two ways to evaluate the above expression which significantly differ in performance:\n\nVariant 1: (AB)C : 6.48e10 FLOPs\n\n\nVariant 2: A(BC) : 2.16e10 FLOPs\n\nThe cost of a matrix matrix multiplication AB, where A is of size mxn and B is of size nxk, is 2xmxnxk. Using this formula, I obtained the performance in terms of FLOPs for the variants mentioned above.\nIf the parenthesizations are not explicitly specified, my TensorFlow build (version 2.8 with Eager mode disabled) choses only the variant 1 (left to right parenthesization), whose execution time is almost three times as that of variant 2. Although I could optimize this and parenthesise manually by explicitly computing the FLOPs of matrix multiplication, I'm curious if this could be done automatically by the Grappler graph optimiser used by TensorFlow? Are there any other graph optimisers that could automatically choose the best parenthesization?\nSample Script to observe performance effect of different parenthesizations\n```\n\nimport tensorflow as tf\nimport os\nimport time\n\nclass bcolors:\n    WARNING = '\\033[93m'\n    ENDC = '\\033[0m'\n\n\n#Check if MKL is enabled\nimport tensorflow.python.framework as tff\nprint(bcolors.WARNING + \"MKL Enabled : \", tff.test_util.IsMklEnabled(), bcolors.ENDC)\n\n\n#Set threads\ntf.config.threading.set_inter_op_parallelism_threads(1)\ntf.config.threading.set_intra_op_parallelism_threads(1)\ntf.config.run_functions_eagerly(False)\n\n#Problem size\nn = 3000\nreps = 10\nDTYPE = tf.float32\n\n\n@tf.function\ndef mc_non_optimized(A,B,C):\n    # Default Parenthesization (Variant 1)\n    start =  tf.timestamp()\n    with tf.control_dependencies([start]):\n        ret = A@B@C\n    with tf.control_dependencies([ret]):\n        end =  tf.timestamp()\n        tf.print(\"Non Optimized : \", end-start)\n    \n    return ret\n\n@tf.function\ndef mc_optimized(A,B,C):\n    #Optimized parenthesization (Variant 2)\n    start =  tf.timestamp()\n    with tf.control_dependencies([start]):\n        # I do not want to manually find the optimum parethesization every time\n        ret = A@(B@C)\n    with tf.control_dependencies([ret]):\n        end =  tf.timestamp()\n        tf.print(\"Optimized : \", end-start)\n\n    \n    return ret\n\n\nA = tf.random.normal([n, n], dtype=DTYPE)\nB = tf.random.normal([n, n], dtype=DTYPE)\nC = tf.random.normal([n, int(n/5)], dtype=DTYPE)\n\n\nfor i in range(reps):\n   ret = mc_non_optimized(A,B,C)\n   ret = mc_optimized(A,B,C)\n   tf.print(\"\\n\")\n\n```\n\nThe execution times with TensorFlow 2.8 (CPU) built with Intel MKL and Python 3.9.7 run on a Mac book pro 2018 Big sur\n\nVariant 1 (default parenthesization): 0.65s\nVariant 2 (Optimized parethesization) : 0.2s\n\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "What would be the time complexity and space complexity of brute force approach of matrix chain multiplication?\r\n                \r\nI know the time complexity and space complexity of ```\nmatrix chain multiplication```\n using dynamic programming would be O(n^3) and O(n^2).\nBut I want to know the time as well as space complexity of the brute force approach for this problem which can be implemented with below code.\n```\ndef MatrixChainOrder(p, i, j):\n \n    if i == j:\n        return 0\n \n    _min = sys.maxsize\n \n    for k in range(i, j):\n \n        count = (MatrixChainOrder(p, i, k)\n                 + MatrixChainOrder(p, k + 1, j)\n                 + p[i-1] * p[k] * p[j])\n \n        if count < _min:\n            _min = count\n \n    # Return minimum count\n    return _min\n\n#arr = [1, 2, 3, 4, 3]\n#n = len(arr)\n# p is array name\n# i=1\n#j= n-1\n```\n\nPlease elaborate...\n    ", "Answer": "\r\nThe stack depth is linear, hence so is the space usage.\nAs for time, we get a recurrence\n```\nT(1) = 1\nT(n) = sum_{k=1}^{n-1} (T(k) + T(n-k)) = 2 sum_{k=1}^{n-1} T(k).\n```\n\nWe can verify that the solution is\n```\nT(1) = 1\nT(n) = 2 (3^(n-1))\n```\n\nso the running time is Θ(3n).\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication for loop of n number of months\r\n                \r\nI have a matrix multiplication problem in a chain format. \nI only have a input Matrix A, will save Matrix B <- Matrix A. \nNeed to multiply in the below fashion\n\n```\nA * B = C\nB * C = D\nC * D = E\nD * E = F\n```\n\n\nthis chain of multiplication taken places till 18 months. \ni have tried the below code: but not able to select which loop i should go for. \n\nMatrix A:  \n\n```\n2   3\n4   2\n```\n\n\nCode:\n\n```\na = matrix( c(2, 3, 4, 2), nrow=2, ncol=2, byrow = TRUE) \na\n\nb <- a\nb\n\nc = b %*% a\nc\n\nd <- c %*% b\nd\n\ne <- d %*% c\ne\n```\n\n\ni am doing this multiplication manually till, i want to do it in chain loop fashion for 18 times. \n\nExpected output: \n\n\n  a\n\n\n```\n      [,1] [,2]\n[1,]    2    3\n[2,]    4    2\n```\n\n\n\n  b\n\n\n```\n      [,1] [,2]\n[1,]    2    3\n[2,]    4    2\n```\n\n\n\n  c = b %*% a\n  \n  c\n\n\n```\n      [,1] [,2]\n[1,]   16   12\n[2,]   16   16\n```\n\n\n\n  d <- c %*% b\n  \n  d\n\n\n```\n     [,1] [,2]\n[1,]   80   72\n[2,]   96   80\n```\n\n\n\n  e <- d %*% c\n  \n  e\n\n\n```\n     [,1] [,2]\n[1,] 2432 2112\n[2,] 2816 2432\n```\n\n\nso this should be repeated for 18 times. Please help. Thanks in Advance. \n    ", "Answer": "\r\nThe multiplication results in ```\nInf```\n from 12th loop onward as the value become too large to be stored in R.\n\nFollowing code will store the value in list matmull. Its first 2 elements are original value A and B. from 3rd element onward it has results of multiplications in the loop\n\n```\nA <- matrix(c(2L, 4L, 3L, 2L), 2, 2)\nmatmull <- rep(list(A), 20)\nfor(i in 1:18){\n matmull[[i+2]] <- matmull[[i]]%*%matmull[[i+1]]\n}\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Chain Matrix Multiplication Schedule Cost\r\n                \r\nIf I have the matrices M0, M1, M2, M3 with the dimensions 10×1, 1×2, 2×1, 1×10 respectively.\nI am getting the same cost for two different cases, is this possible or am I doing something wrong?\nM03 = (M0x(M1xM2)xM3) = 112\n\nM03 = ((M0xM1)xM2)xM3 = 112\n    ", "Answer": "\r\nThe cost to multiply two matrices ```\ni x j```\n and ```\nj x k```\n is ```\ni * j * k```\n.\nFor your first example, the cost is 2 + 10 + 100 = 112.\nFor your second example the cost is (10 * 1 * 2) + (10 * 2 * 1) + (10 * 1 * 10), or 20 + 20 + 100 = 140.\nIt's possible that depending on the dimensions, the order would not matter. In this case it does.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "dynamic array C doesn't work for all inputs\r\n                \r\nI'm trying to do matrix chain multiplication and I need to take input from a file in C\n\nIt works fine for one test case while for other run fails\n\ntestcase #1 (this works fine)\n\n```\n3 5\n5 7\n7 9\n9 6\n6 7\n7 9\n```\n\n\ntestcase #2 (this gives matrix.exe stopped working)\n\n```\n30 35\n35 15\n15 5\n5 10\n10 20\n20 25\n```\n\n\nNOTE: In testcases consecutive numbers are rows and columns of matrices\n\nThis is the code I'm using\n\n```\nint *p,i=0;\nchar str[3],*extra;\nFILE * file;\nfile = fopen(\"D:/Dump/testcases/matrix.txt\", \"r\");\nif (file) {\n    while (fscanf(file, \"%s\", str)!=EOF){\n        switch(i){\n            case 0:     p=(int *)malloc(sizeof(int));\n                        *(p)=atoi(str);\n                        break;\n            default:    *(p+i)=(int)malloc(sizeof(int));\n                        *(p+i)=atoi(str);\n                        break;\n        }\n        i++;\n    }\n}\n```\n\n    ", "Answer": "\r\nSo many problems and misconceptions; it is hard to provide useful advice.\n\nAs I understand it, you are meant to be reading the dimensions of a series of matrices with two numbers per line of input, and the second number in line N should be the same as the first number in line N+1.  You don't know until you reach EOF how many lines of input there will be.  Generally, the numbers should all be one or two digits (not longer).  The actual data for the arrays is stored elsewhere, or generated — it is not handled in this code.\n\nYour code is:\n\n```\nint *p,i=0;\nchar str[3],*extra;\nFILE * file;\nfile = fopen(\"D:/Dump/testcases/matrix.txt\", \"r\");\nif (file) {\n    while (fscanf(file, \"%s\", str)!=EOF){\n        switch(i){\n            case 0:     p=(int *)malloc(sizeof(int));\n                        *(p)=atoi(str);\n                        break;\n            default:    *(p+i)=(int)malloc(sizeof(int));\n                        *(p+i)=atoi(str);\n                        break;\n        }\n        i++;\n    }\n}\n```\n\n\n\nThe file opening is OK; you don't show the close, but that's a minor issue.\nYou don't limit the size of the string that is read; you could use ```\n%2s```\n to ensure you do not overflow the (rather short) string you use.\nYou don't check that ```\nfscanf()```\n actually read 1 item.  With a character string, that's OK.  If you were reading integers directly, that would not be OK.  You could get 0 integers converted, which is neither EOF nor 1.  You should be using ```\nwhile (fscanf(file, \"%2s\", str) == 1)```\n.\nThere's no very obvious reason not to have ```\nfscanf()```\n do the conversion for you.\nOTOH, you cannot force ```\nfscanf()```\n to require two numbers (only) on a single line either; it will be happy to have all the numbers on a single line, or each number on a line on its own with 2 blank lines between each line containing numbers.\nThe ```\nswitch```\n is a bit odd.  The ```\ndefault```\n clause should probably be using ```\nrealloc()```\n rather than ```\nmalloc()```\n, and the cast in the ```\ndefault```\n is seriously problematic.  The memory allocation scheme as a whole is very flawed, which you knew because you asked the question.  You could just about rescue it by writing:\n\n```\ndefault:\n    p = (int *)realloc(p, (i+1) * sizeof(int));\n    p[i] = atoi(str);  /* Or *(p+i) if you prefer */\n    break;\n```\n\n\n\nOverall, I think you need to think in terms of reading a line at a time (```\nfgets()```\n), then parsing the lines with ```\nsscanf()```\n.  You should probably think in terms of allocating the array two integers at a time.\n\n```\nint  *p = 0;\nint   i = 0;\nFILE *file = fopen(\"D:/Dump/testcases/matrix.txt\", \"r\");\n\nif (file != 0)\n{\n    char buffer[4096];\n    while (fgets(buffer, sizeof(buffer), file) != 0)\n    {\n        int d1, d2;\n        char c;\n        if (sscanf(buffer, \"%d%d%c\", &d1, &d2, &c) != 3 || c != '\\n')\n        {\n            fprintf(stderr, \"Badly formatted line: %s\", buffer);\n            break;\n        }\n        void *space;\n        if (i == 0)\n            space = malloc(2 * (i + 1) * sizeof(int));\n        else\n            space = realloc(p, 2 * (i + 1) * sizeof(int));\n        if (space == 0)\n        {\n            fprintf(stderr, \"Memory allocation failed (%d bytes)\\n\", 2 * (i + 1) * sizeof(int));\n            break;\n        }\n        p = (int *)space;\n        p[2*i + 0] = d1;\n        p[2*i + 1] = d2;\n        i++;\n    }\n    fclose(file);\n}\n\n/* i is the number of lines read (sets of matrix dimensions) */\n/* p is the pointer to 2*i array dimensions */\n/* ...Use i and p... */\nfree(p);\n```\n\n\nThe code does not check that the second dimension on one line is the same as the first dimension on the next line.  It does not check for positive integers of 1 or 2 digits (basically, 1..99); it allows bigger values, zeroes and negative values.  (The test ```\nc == '\\n'```\n ensures that there's a newline after the second number; no trailing blanks etc allowed.)\n\nGiven that ```\np```\n is (now) initialized to 0 (a null pointer), you could do without the ```\nmalloc()```\n and simply use ```\nrealloc()```\n unconditionally.  Most people prefer not to do that, but it avoids repetition.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Huge deegree of markov chain matrix\r\n                \r\nwe met with interesting problem of R. We wanted to find 100 degree of any given markov chain matrix. \nThe problem is that after some time matrix suddenly goes to zero. We think that is causation of approximately of matrix multiplication. \nDo you have any ideas how to fix it? \n\n```\na <- c(0.2, 0, 0.7, 0.1) \nb <- c(0.5, 0.2, 0.2, 0.1)\nc <- c(0, 0.3, 0.7, 0)\nd <- c(0.1, 0.8, 0, 0.1)\nmat <- matrix(c(a,b,c,d), ncol=4, byrow=TRUE)\nz <- mat\nfor(i in 1:100)\n{\n  print(i)\n  z <-  z%*%z\n  print(z)\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Exception java.lang.OutOfMemoryError: Java heap space occurs in recursion\r\n                \r\nI'm using IntelliJ as an editor.\nThese are my vmoptions:\n\n```\n-Xms1024m\n\n-Xmx4096m\n\n-XX:MaxPermSize=700m\n\n-XX:ReservedCodeCacheSize=480m\n\n-XX:SoftRefLRUPolicyMSPerMB=50\n```\n\n\nIs there anything else I can change in the settings to make it work for me? \n\nMy algorithm tries to calculate the Matrix Chain Multiplication Problem via Branch&Bound and in this part(code below) I'm performing deapth-search/creating successors etc. I assume this recursion triggers the heap problem.\n\n```\n public  static  SimpleMCPNode createTree(SimpleMCPNode currentNode) {\n//other statements \n.\n.\n.\n.\nfor (int i = 0; i < currentNode.matrices.size() - 1; i++) {\n        List<MatrixInfo> adaptedList = new ArrayList(currentNode.matrices);\n        currentNode.successors.add(createTree(currentNode.createSuccessor(adaptedList, i)));\n    }\n//other statements\n.\n.\n```\n\n\nDepending on the input it can grow exponentially...\n    ", "Answer": "\r\nYou do not have to initialize a new arraylist each time.\n\nPlease use :\n\n```\nArrayList<MatrixInfo> adaptedList = new ArrayList<MatrixInfo>();\nfor(int i=0; i< 10; i++){\n  currentNode.successors.add(createTree(currentNode.createSuccessor(adaptedList,i)));\n  adaptedList.clear() \n}\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Why c++ program generating different output for the same input? [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has an answer here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        C++ mixing printf and cout [duplicate]\r\n                            \r\n                                (1 answer)\r\n                            \r\n                    \r\n                Closed 3 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI am implementing matrix chain multiplication program in c++. I am using ```\nONLINE_JUDGE```\n flag to write output to the file. When i run the program it does not produce correct output in file, but it is producing correct output in console. \n\nMy Program:\n\n```\n#include<bits/stdc++.h>\nusing namespace std;\nint main(){\n    #ifndef ONLINE_JUDGE \n        // For getting input from input.txt file \n        freopen(\"C:\\\\Users\\\\Rahul kumar\\\\desktop\\\\Algorithm\\\\input.txt\", \"r\", stdin); \n        // Printing the Output to output.txt file \n        freopen(\"C:\\\\Users\\\\Rahul kumar\\\\desktop\\\\Algorithm\\\\output.txt\", \"w\", stdout); \n    #endif \n\n    // dimension of four matrices\n    vector<pair<int,int>>matrices;\n    matrices.push_back(make_pair(5,4));\n    matrices.push_back(make_pair(4,6));\n    matrices.push_back(make_pair(6,2));\n    matrices.push_back(make_pair(2,7));\n\n    vector<int>p; // algorithm helper data\n    int last; // column of last matrix. \n\n    for(auto matrix:matrices){\n        p.push_back(matrix.first);\n        last=matrix.second;\n    }    \n    p.push_back(last);  // add last matrix. \n    int numberOfMatrix=matrices.size();\n\n    int dp[numberOfMatrix][numberOfMatrix];\n    for(int i=0;i<numberOfMatrix;i++){\n        for(int j=0;j<numberOfMatrix;j++){\n            dp[i][j]=0;\n        }\n    }\n\n\n    for(int i=0;i<numberOfMatrix;i++){\n        for(int j=0;j<numberOfMatrix;j++){\n            if(i==j){\n                dp[i][j]=0;\n            }else if(j==i+1){\n                dp[i][j]=p[i]*p[i+1]*p[i+2];\n            }else{\n                int best=5000;\n                for(int k=i;k<j;k++){\n                    printf(\"dp[%d][%d]=%d, dp[%d][%d]=%d, p[%d]=%d, p[%d]=%d, p[%d]=%d\\n\",i,k,dp[i][k],k+1,j,dp[k+1][j],i,p[i],k+1,p[k+1],j+1,p[j+1]);\n                    best=min(best,dp[i][k]+dp[k+1][j]+p[i]*p[k+1]*p[j+1]);\n                    cout<<\"I: \"<<i<<\" J:  \"<<j<<\" Best: \"<<best<<endl;\n                }\n                dp[i][j]=best;\n            }\n        }\n    }\n\n    for(int i=0;i<numberOfMatrix;i++){\n        for(int j=0;j<numberOfMatrix;j++){\n            cout<<dp[i][j]<<\"   \";\n        }\n        cout<<endl;\n    }\n\n    return 0;\n}\n```\n\n\nOUTPUT in ```\noutput.txt```\n file:\n\n```\nI: 0 J:  2 Best: 40\nI: 0 J:  2 Best: 40\nI: 0 J:  3 Best: 140\nI: 0 J:  3 Best: 140\nI: 0 J:  3 Best: 110\nI: 1 J:  3 Best: 168\nI: 1 J:  3 Best: 104\n0   120   40   110   \n5000   0   48   104   \n5000   5000   0   84   \n5000   5000   5000   0   \ndp[0][0]=0, dp[1][2]=0, p[0]=5, p[1]=4, p[3]=2\ndp[0][1]=120, dp[2][2]=0, p[0]=5, p[2]=6, p[3]=2\ndp[0][0]=0, dp[1][3]=0, p[0]=5, p[1]=4, p[4]=7\ndp[0][1]=120, dp[2][3]=0, p[0]=5, p[2]=6, p[4]=7\ndp[0][2]=40, dp[3][3]=0, p[0]=5, p[3]=2, p[4]=7\ndp[1][1]=0, dp[2][3]=0, p[1]=4, p[2]=6, p[4]=7\ndp[1][2]=48, dp[3][3]=0, p[1]=4, p[3]=2, p[4]=7\n\n```\n\n\nNot expected output. \n When i comment this code\n\n```\n#ifndef ONLINE_JUDGE \n        // For getting input from input.txt file \n        freopen(\"C:\\\\Users\\\\Rahul kumar\\\\desktop\\\\Algorithm\\\\input.txt\", \"r\", stdin); \n        // Printing the Output to output.txt file \n        freopen(\"C:\\\\Users\\\\Rahul kumar\\\\desktop\\\\Algorithm\\\\output.txt\", \"w\", stdout); \n    #endif \n```\n\n\nand run the program then the output on the console is..\n\n```\ndp[0][0]=0, dp[1][2]=0, p[0]=5, p[1]=4, p[3]=2\nI: 0 J:  2 Best: 40\ndp[0][1]=120, dp[2][2]=0, p[0]=5, p[2]=6, p[3]=2\nI: 0 J:  2 Best: 40\ndp[0][0]=0, dp[1][3]=0, p[0]=5, p[1]=4, p[4]=7\nI: 0 J:  3 Best: 140\ndp[0][1]=120, dp[2][3]=0, p[0]=5, p[2]=6, p[4]=7\nI: 0 J:  3 Best: 140\ndp[0][2]=40, dp[3][3]=0, p[0]=5, p[3]=2, p[4]=7\nI: 0 J:  3 Best: 110\ndp[1][1]=0, dp[2][3]=0, p[1]=4, p[2]=6, p[4]=7\nI: 1 J:  3 Best: 168\ndp[1][2]=48, dp[3][3]=0, p[1]=4, p[3]=2, p[4]=7\nI: 1 J:  3 Best: 104\n0   120   40   110\n5000   0   48   104\n5000   5000   0   84\n5000   5000   5000   0\nI: 1 J:  3 Best: 104\n0   120   40   110\n5000   0   48   104\n5000   5000   0   84\n5000   5000   5000   0\n```\n\n\nThis output is expected, but different form output of the file. This happens many times with me. I am running this program on vs code. \n    ", "Answer": "\r\nInclude it in your program ```\nstd::ios::sync_with_stdio(true);```\n on the top of every statement. It also happened with me. Including this, in your program, ```\ncout```\n and ```\nprintf```\n will become thread-safe. Make sure the argument must be true.  \n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Minimize array elements by multiplying adjacent elements only if the product is less than equal to k\r\n                \r\nI recently came across this question in an online assessment.\n```\narr = [2,6,2,4] \nk = 15\n```\n\nThe array elements need to be minimized by multiplying two adjacent elements only and only if their product is less than ```\nk```\n.\nExample:\n```\n(2,6,2,4)\n(2*6,2*4) --> since 12 and 8 are less than k which is 15\n(12,8)\n```\n\nThe following pattern could have also been followed:\n```\n(2,6,2,4)\n(2,6*2,4) \n(2,12,4) --> no . of  elements is 3 which is more than 2 thus non-optimal.\n```\n\nI have been stuck on this problem for days.\nI tried walking it through the Matrix Chain Multiplication problem, but I am unable to make any headway. The main difference is that in the MCM problem all matrices CAN BE multiplied with each other. There is no case where 2 matrices cannot be multiplied.\nAny hints ?\n    ", "Answer": "\r\nAs the values of the array are strictly positive, you can use a greedy algorithm: keep multiplying values until a next multiplication would be ```\nk```\n or more. When that happens, start a new chunk and reset the product to the current array value. This way we put the chunk boundaries as far to the right as possible. We can see that if we would move one chunk boundary more to the left, this would never decrease the number of chunks needed.\nHere is an implementation of this greedy algorithm in (simple) JavaScript:\n\r\n\r\n```\nfunction solve(arr, k) {\n    if (arr.length == 0) return 0; // Boundary case\n    \n    let product = 1;\n    let count = 1;\n    \n    for (let i = 0; i < arr.length; i++) {\n        product = product * arr[i];\n        if (product >= k) { // Start a new chunk\n            product = arr[i];\n            count++;\n        }\n    }\n    return count;\n}\n\n// Example run\nconst arr = [2,6,2,4]; \nconst k = 15;\nconst result = solve(arr, k);\nconsole.log(\"Number of chunks\", result);```\n\r\n\r\n\r\n\nIf we would allow 0 as possible array value, and ```\nk```\n is strictly positive, then the occurrence of a zero would lead to the result 1: all values can be multiplied to one product which is 0.\nThis algorithm would no longer work correctly if negative array values would be allowed.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Why does a large local array crash my program, but a global one doesn't? [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        Segmentation fault on large array sizes\r\n                            \r\n                                (7 answers)\r\n                            \r\n                    \r\n                Closed 3 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nProgram with large global array:\n\n```\nint ar[2000000];\n\nint main()\n{\n}\n```\n\n\nProgram with large local array:\n\n```\nint main()\n{\n    int ar[2000000];\n}\n```\n\n\nWhen I declare an array with large size in the main function, the program crashes with \"SIGSEGV (Segmentation fault)\".\n\nHowever, when I declare it as global, everything works fine. Why is that?\n    ", "Answer": "\r\nDeclaring the array globally causes the compiler to include the space for the array in the data section of the compiled binary.  In this case you have increased the binary size by 8 MB (2000000 * 4 bytes per int).  However, this does mean that the memory is available at all times and does not need to be allocated on the stack or heap.\n\nEDIT: @Blue Moon rightly points out that an uninitialized array will most likely be allocated in the ```\nbss```\n data segment and may, in fact, take up no additional disk space. An initialized array will be allocated statically.\n\nWhen you declare an array that large in your program you have probably exceeded the stack size of the program (and ironically caused a stack overflow).\n\nA better way to allocate a large array dynamically is to use a pointer and allocate the memory on the heap like this:\n\n```\nusing namespace std;\nint main() {\n  int *ar;\n  ar = malloc(2000000 * sizeof(int));\n\n  if (ar != null) {\n    // Do something \n    free(ar);\n  }\n\n  return 0;\n}\n```\n\n\nA good tutorial on the Memory Layout of C Programs can be found here.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Markov Chain does not converge\r\n                \r\ni am trying to model car urban mobility by using Markov chains. I am trying to figure out why my Markov Chain model will not converge to a steady state distribution, assuming that it follows the assumptions of aperiodocity, ergodicity etc. I tried to implement it through python and matrix multiplication using numpy. Below you can see the initial state matrix (A0) and the transition matrix (T). I would appreciate any help.\nEdit:\nBelow there is a sample of my python code\n```\n#Transition matrix\nT = np.array([[0.772,0.044,0.001,0.026,0.026,0.001],\n             [0.114,0.760,0.183,0.026,0.022,0.007],\n             [0.001,0.112,0.447,0.055,0.056,0.008],\n             [0.057,0.028,0.157,0.473,0.022,0.001],\n             [0.055,0.042,0.184,0.394,0.556,0.072],\n             [0.001,0.014,0.026,0.028,0.318,0.911]]).reshape(6,6)\n\n\n#Initial state matrix\nA1 = np.array([0.086,0.180,0.086,0.078,0.219,0.350]).reshape(6,1)\n\nforw = A1\n\nfin = []\n\ni=0\n\nwhile i<10000:\n            \n    foo = np.dot(T,forw)\n        \n    fin.append(foo)\n    \n    forw = foo\n    \n    i+=1\n```\n\n\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "matrix expression calculation\r\n                \r\nCould anybody, please, point me on the algorithm of how matrix multiplication can be done (Identifying the order of multiplying). I tried really different way which I could design, but nothing works as expected, unfortunately :( For example I have one of the following matrix chains to multiply:  \n\n```\n((((0(((((((((((((((1 2)3)4)5)6)7)8)9)10)11)12)13)14)15)16))17)18)19 \n\n((((((((((((0 1)2)3)4)5)6)7)8)9)10)(11(12(13(14(15(16(1718))))))))19\n\n(((((0 1)(2(((3 4)(5 6))(((7 8)(9(10 11)))((((12 13)14)15)16)))))17)18)19  \n\n(((((((0 1)2)3)4)5)(6(7(8(9(10(11(12 13))))))))(((((14 15)16)17)18)19)  \n```\n\n\nCan somebody share a universal algorithm for all the cases?  \n\nNOTE:\n1.I need multiplication only.\n2.Matrices have different dimension, so they are not square. (Naturally, Matrices' dimensions agree)\n3.Maybe this topic can be helpful, but I really have no idea how it can be applied here.\n\nThanks in advance to everybody who is trying to help!\n    ", "Answer": "\r\nWhat you are looking for is called \"Matrix chain multiplication\".  http://en.wikipedia.org/wiki/Matrix_chain_multiplication\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Understanding Markov Chains in terms of Matrix Multiplication\r\n                \r\nIn a lecture on YouTube, a professor said Markov Chains could be simplified to ```\nStart(S) * Transition Matrix(Q)^State#```\n\n\nI'm trying to replicate this using numpy.\n\n```\nimport numpy as np\nS = np.zeros(shape=(1,2))\nQ = np.zeros(shape=(2,2))\n\n#starting state\nS[0] = [.2,.8]\n\n#transition matrix\nQ[0] = [.9, .1]\nQ[1] = [.7, .3]\n```\n\n\nIf I do ```\nprint S.dot(Q).dot(Q)```\n, it gives me ```\n[[0.848  0.152]]```\n which appears to be the correct answer (two steps into the future). \n\nHowever, this doesn't exactly seem the same as ```\nSQ^x```\n, so I tried ```\nprint S.dot(np.power(Q,2))```\n, but that gives me ```\n[[0.554  0.074]]```\n. Where am I going wrong, or what don't I understand here?\n    ", "Answer": "\r\nThe expressions ```\nS.dot(Q).dot(Q)```\n and ```\nS.dot(np.power(Q,2))```\n are not the same thing. The first is the behaviour you desire, while ```\nS.dot(np.power(Q,2))```\n raises each element in ```\nQ```\n to the second power. Documentation here.\n\nFor a more compact notation than repeatedly chaining ```\n.dot(Q)```\n, use:\n\n```\nS.dot(np.linalg.matrix_power(Q,n))\n```\n\n\nwhere ```\nn```\n is the desired power.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "PySpark Block Matrix multiplication fails with OOM\r\n                \r\nI'm trying to do a matrix multiplication chain of size 67584*67584 using Pyspark but it constantly runs out of memory or OOM error.Here are the details:\nInput is matlab file(.mat file) which has the matrix in a single file. I load the file using scipy loadmat, split the file into multiple files of block size (1024*1024) and store them back in .mat format.\nNow mapper loads each file using filelist and create a rdd of blocks.\n\n```\nfilelist = sc.textFile(BLOCKS_DIR + 'filelist.txt',minPartitions=200)\nblocks_rdd = filelist.map(MapperLoadBlocksFromMatFile).cache()\n```\n\n\nMapperLoadBlocksFromMatFile is a function as below:\n\n```\n def MapperLoadBlocksFromMatFile(filename):\n         data = loadmat(filename)\n         G = data['G']\n         id = data['block_id'].flatten()\n         n = G.shape[0]\n         if(not(isinstance(G,sparse.csc_matrix))):\n                 sub_matrix = Matrices.dense(n, n, G.transpose().flatten())\n         else:\n                 sub_matrix = Matrices.dense(n,n,np.array(G.todense()).transpose().flatten())\n     return ((id[0], id[1]), sub_matrix)\n```\n\n\nNow once i have this rdd, i create a BlockMatrix from it. and Do a matrix multiplication with it.\n\n```\nadjacency_mat = BlockMatrix(blocks_rdd, block_size, block_size, adj_mat.shape[0], adj_mat.shape[1])\n```\n\n\nI'm using the multiply method from BlockMatrix implementation and it runs out of memory every single time.\n\n```\nResult = adjacency_mat.multiply(adjacency_mat)\n```\n\n\nBelow are the cluster configuration details:\n\n```\n50 nodes of 64gb Memory and 20 cores processors.\nworker-> 60gb and 16 cores\nexecutors-> 15gb and 4 cores each\ndriver.memory -> 60gb and maxResultSize->10gb\n```\n\n\ni even tried with rdd.compress. Inspite of having enough memory and cores, i run out of memory every time. Every time a different node runs out of memory and i don't have an option of using visualVM in the cluster . What am i doing wrong? Is the way blockmatrix is created wrong? Or am i not accounting for enough memory? \nOOM Error Stacktrace\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Recursive version of Java function is slower than iterative on first call, but faster after. Why is this?\r\n                \r\nFor an assignment I'm currently trying to measure the performance (space/time) difference between an iterative solution to the matrix chain problem and a recursive one. \n\nThe gist of the problem and the solution I'm using for the iterative version can be found here: http://www.geeksforgeeks.org/dynamic-programming-set-8-matrix-chain-multiplication/\n\nI'm running a given input through both functions 10 times, measuring the space and time performance of each function. The very interesting thing is that while the recursive solution runs much slower than the iterative solution on the first call it's performance is much better on successive calls it is much faster. The functions are not making use of any class-global variables other than one for counting memory usage. Why is this occurring? Is it something the compiler is doing or am I missing something obvious? \n\nNote: I know my way of measuring memory is wrong, planning on changing it.\n\nMain: Initializes Array and passes it to run functions\n\n```\n    public static void main(String[] args) {\n\n    int s[] = new int[] {30,35,15,5,10,100,25,56,78,55,23};\n    runFunctions(s, 15);\n\n}\n```\n\n\nrunFunctions: Runs both functions 2 * n times, measuring space and time and printing results at the end\n\n```\nprivate static void runFunctions(int[]arr , int n){\n    final Runtime rt = Runtime.getRuntime();\n\n    long iterativeTime[] = new long [n],\n         iterativeSpace[] = new long [n],\n         recursiveSpace[] = new long [n],\n         recursiveTime[] = new long [n];\n\n    long startTime, stopTime, elapsedTime, res1, res2;\n\n    for (int i = 0; i <n; i++){\n\n        System.out.println(\"Measuring Running Time\");\n\n        //measure running time of iterative\n        startTime = System.nanoTime();\n        res1 = solveIterative(arr, false);\n        stopTime = System.nanoTime();\n        elapsedTime = stopTime - startTime;\n        iterativeTime[i] = elapsedTime;\n\n        //measure running time of recursive\n        startTime = System.nanoTime();\n        res2 = solveRecursive(arr, false);\n        stopTime = System.nanoTime();\n        elapsedTime = stopTime - startTime;\n        recursiveTime[i] = elapsedTime;\n\n        System.out.println(\"Measuring Space\");\n\n        //measure space usage of iterative\n        rt.gc();\n        res1 = solveIterative(arr, true);\n        iterativeSpace[i] = memoryUsage;\n\n        //measure space usage of recursive\n        rt.gc();\n        res2 = solveRecursive(arr, true);\n        recursiveSpace[i] = memoryUsage;\n        rt.gc();\n\n        if (res1 != res2){\n            System.out.println(\"Error! Results do not match! Iterative Result: \" + res1 + \" Recursive Result: \" + res2);\n        }\n    }\n\n    System.out.println(\"Time Iterative: \" + Arrays.toString(iterativeTime));\n    System.out.println(\"Time Recursive: \" + Arrays.toString(recursiveTime));\n    System.out.println(\"Space Iterative: \" + Arrays.toString(iterativeSpace));\n    System.out.println(\"Space Recursive: \" + Arrays.toString(recursiveSpace));\n}\n```\n\n\nsolveRecursive: bootstrap for doRecursion\n\n```\nprivate static int solveRecursive(int[] s, boolean measureMemory){\n\n    memoryUsage = 0;\n    maxMemory = 0;\n\n    int n = s.length - 1;\n    int[][]  m = new int[n][n];\n    int result;\n\n    if (measureMemory){\n        memoryUsage += MemoryUtil.deepMemoryUsageOf(n);\n        memoryUsage += MemoryUtil.deepMemoryUsageOf(s);\n        memoryUsage += MemoryUtil.deepMemoryUsageOf(m);\n        result = doRecursion(0, n - 1, m,  s);\n        memoryUsage += MemoryUtil.deepMemoryUsageOf(result);\n        System.out.println(\"Memory Used: \" + memoryUsage);\n    }\n    else\n    {\n        result = doRecursion(0, n - 1, m,  s);\n    }\n    return result;\n}\n```\n\n\ndoRecursion: solves the function recursively\n\n```\nprivate static int doRecursion(int i, int j, int[][] m, int s[]){\n\n    if (m[i][j] != 0){\n        return m[i][j];\n    }\n    if (i == j){\n        return 0;\n    }\n    else\n    {\n        m[i][j] = Integer.MAX_VALUE / 3;\n        for (int k = i; k <= j - 1; k++){\n            int q = doRecursion(i, k, m, s) + doRecursion(k + 1, j, m, s) + (s[i] * s[k + 1] * s[j + 1]);\n            if (q < m[i][j]){\n                m[i][j] = q;\n            }\n        }\n    }\n    return m[i][j];\n}\n```\n\n\nsolveIterative: Solves the problem iteratively\n\n```\nprivate static int solveIterative(int[] s, boolean measureMemory) {\n    memoryUsage = 0;\n    maxMemory = 0;\n    int n = s.length - 1;\n    int i = 0, j = 0, k= 0, v = 0;\n    int[][]  m = new int[n][n];\n    for (int len = 2; len <= n; len++) {\n        for (i = 0; i + len <= n; i++) {\n            j = i + len - 1;\n            m[i][j] = Integer.MAX_VALUE;\n            for (k = i; k < j; k++) {\n                v = m[i][k] + m[k + 1][j] + s[i] * s[k + 1] * s[j + 1];\n                if (m[i][j] > v) {\n                    m[i][j] = v;\n                }\n            }\n        }\n    }\n\n    if (measureMemory){\n        memoryUsage += MemoryUtil.deepMemoryUsageOf(n);\n        memoryUsage += MemoryUtil.deepMemoryUsageOf(m);\n        memoryUsage += MemoryUtil.deepMemoryUsageOf(i);\n        memoryUsage += MemoryUtil.deepMemoryUsageOf(j);\n        memoryUsage += MemoryUtil.deepMemoryUsageOf(k);\n        memoryUsage += MemoryUtil.deepMemoryUsageOf(v);\n        memoryUsage += MemoryUtil.deepMemoryUsageOf(s);\n\n        System.out.println(\"Memory Used: \" + memoryUsage);\n    }\n\n    return m[0][n - 1];\n}\n```\n\n\nOutput:\n\n```\nTime Iterative: [35605, 12039, 20492, 17674, 17674, 12295, 11782, 19467, 16906, 18442, 21004, 19980, 18955, 12039, 13832]\nTime Recursive: [79918, 4611, 8453, 6916, 6660, 6660, 4354, 6916, 18699, 7428, 13576, 5635, 4867, 3330, 3586]\nSpace Iterative: [760, 760, 760, 760, 760, 760, 760, 760, 760, 760, 760, 760, 760, 760, 760]\nSpace Recursive: [712, 712, 712, 712, 712, 712, 712, 712, 712, 712, 712, 712, 712, 712, 712]\n```\n\n    ", "Answer": "\r\nThe problem is that your test runs too short. JIT has not enough time to optimize the methods well enough.\n\nTry repeating the test at least 200 times (instead of 15) and you'll see the difference.\n\nNote that JIT compilation does not happen just once. Methods can be recompiled several times as JVM collects more runtime statistics. You've hit the situation where ```\nsolveRecursive```\n survived more levels of optimization than ```\nsolveIterative```\n.\n\n\n\nIn this answer I've described how JIT decides to compile a method. Basically there are two main compilation triggers: the method invocation threshold and the backedge threshold (i.e. loop iteration counter).\n\nNote that those two methods have different compilation triggers:\n\n\n```\nsolveRecursive```\n does more calls => it is compiled when invocation threshold is reached;\n```\nsolveIterative```\n runs more loops => it is compiled when backedge threshold is reached.\n\n\nThese thresholds are not equal, and it happens that on a short distance ```\nsolveRecursive```\n is compiled earlier. But as soon as ```\nsolveIterative```\n is optimized, it starts to perform even better.\n\nThere is also a trick to make ```\nsolveIterative```\n compiled earlier: move the innermost loop ```\nfor (k = i; k < j; k++)```\n to a separate method. Yes, it may sound strange, but JIT is better in compiling several small methods instead of compiling one big method. Smaller methods are easier to understand and to optimize not only for humans, but also for computers :)\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Numpy - Matrix multiplication to return ndarray, not sum\r\n                \r\nAll, I have an application that requires returning a numpy ndarray, rather than a simple sum, when multiplying two matrices; e.g.:\n\n```\nimport numpy as np\nx = np.array([[1, 1, 0], [0, 1, 1]])\ny = np.array([[1, 0, 0, 1], [1, 0, 1, 0], [0, 0, 0, 0]])\nw = x @ y\n>>> array([[2, 0, 1, 1],\n           [1, 0, 1, 0]])\n```\n\n\nHowever, the requirement is to return an ndarray (in this case..):\n\n```\narray([[[1,1,0], [0,0,0], [0,1,0], [1,0,0]],\n       [[0,1,0], [0,0,0], [0,1,0], [0,0,0]]])\n```\n\n\nNote that the matrix multiplication operation may be repeated; the output will be used as the left-side matrix of ndarrays for the next matrix multiplication operation, which would yield a higher-order ndarray after the second matrix multiplication operation, etc..\n\nAny way to achieve this? I've looked at overloading ```\n__add__```\n, and ```\n__radd__```\n by subclassing np.ndarray as discussed here, but mostly got dimension incompatibility errors. \n\nIdeas? \n\nUpdate:\n\nAddressing @Divakar's answer E.g., for chained operation, adding \n\n```\nz = np.array([[1, 1, 0], [0, 0, 0], [1, 0, 0], [0, 1, 0]])\ns1 = x[...,None] * y\ns2 = s1[...,None] * z\n```\n\n\nresults in an undesired output. \n\nI suspect the issue starts with s1, which in the case above returns s1.shape = (2,3,4). It should be (2,4,3) since [2x3][3x4] = [2x4], but we're not really summing here, just return an array of length 3. \n\nSimilarly, s2.shape should be (2,3,4,3), which [incidentally] it is, but with undesired output (it's not 'wrong', just not what we're looking for). \nTo elaborate, s1*z should be [2x4][4x3] = [2x3] matrix. Each element of the matrix is itself an ndarray, of [4x3] since we have 4 rows in z to multiply the elements in s1, and each element in s1 is itself 3 elements long (again, we're not arithmetically adding elements, but return ndarrays with the extended dimension being the row count in the R-matrix of the operation.\n\nUltimately, the desired output would be:\n\n```\ns2 = array([[[[1, 1, 0],\n              [0, 0, 0],\n              [0, 1, 0],\n              [0, 0, 0]],\n\n              [[1, 1, 0],\n               [0, 0, 0],\n               [0, 0, 0],\n               [1, 0, 0]],\n\n              [[0, 0, 0],\n               [0, 0, 0],\n               [0, 0, 0],\n               [0, 0, 0]]],\n\n\n             [[[0, 1, 0],\n               [0, 0, 0],\n               [0, 1, 0],\n               [0, 0, 0]],\n\n              [[0, 1, 0],\n               [0, 0, 0],\n               [0, 0, 0],\n               [0, 0, 0]],\n\n              [[0, 0, 0],\n               [0, 0, 0],\n               [0, 0, 0],\n               [0, 0, 0]]]])\n```\n\n    ", "Answer": "\r\nExtend them to ```\n3D```\n and leverage ```\nbroadcasting```\n -\n\n```\nx[:,None] * y.T\n```\n\n\nOr with ```\nnp.einsum```\n -\n\n```\nnp.einsum('ij,jk->ikj',x,y)\n```\n\n\n\n\nGoing by ```\nOP's comment```\n and the quote from the question :\n\n\n  ... matrix multiplication operation may be repeated; the output will\n  be used as the left-side matrix of ndarrays for the next matrix\n  multiplication operation, which would yield a higher-order ndarray\n  after the second matrix multiplication operation, etc..\n\n\nIt seems, we need to do something along these lines -\n\n```\ns1 = x[...,None] * y\ns2 = s1[...,None] * z # and so on.\n```\n\n\nThough, the order of the axes would be different in this case, but it seems to be the simplest way to extend the solution to a generic number of incoming ```\n2D```\n arrays.\n\nFollowing the edits in the question, seems like you are placing the incoming arrays from the first axis onwards for element-wise multiplication. So, if I got that right, you can swap axes to get the correct order, like so -\n\n```\ns1c = (x[...,None] * y).swapaxes(1,-1)\ns2c = (s1c.swapaxes(1,-1)[...,None] * z).swapaxes(1,-1) # and so on.\n```\n\n\nIf you are only interested in the final output, swap axes only at the final stage and skip those in the intermediate ones.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How can I use numpy.einsum for matrix-vector multiplication of an unknown number of operands?\r\n                \r\nI want to efficiently perform a chain of matrix-vector multiplication in Python and the ```\nnumpy.einsum```\n function seems to be the best choice. However, I do NOT know the number of matrix operands N in the chain a priori and so there is no simple way to write the ```\nsubscripts```\n string to pass to ```\neinsum```\n.\nTo be more clear, let's consider the simple case with N=3 matrices A, B, and C and the initial vector v. The ```\nnumpy.einsum```\n call would be the following:\n```\nresult = numpy.einsum('ij,jk,kl,l', A, B, C, v)\n```\n\nHow can I generalize this operation to an arbitrary N? A possibility would be to programmatically create the ```\nsubscripts```\n string but ```\nnumpy.einsum```\n only supports 52 different labels (26 letters lower and upper case) and this represents a limitation in my case since I don't know a priori the number of operands.\nIs there maybe a way to do this as efficiently as possible by using another approach based on a different ```\nnumpy```\n function?\n    ", "Answer": "\r\nHere are two recursive solutions, one based on \"atomic induction\" aka doing one einsum for each matrix multiplication:\n```\nA, B, C, D = (np.random.rand(10,10),) * 4\n\ndef recursive_matrix_multiply(*args):\n    if len(args) == 1:\n        return args[0]\n    return recursive_matrix_multiply( np.einsum('ij,jk' if args[1].ndim == 2 else 'ij,j', *args[:2]), *args[2:])\n\nnp.testing.assert_almost_equal( recursive_matrix_multiply(A, B, C, D), np.einsum('ij,jk,kl,lm', A, B, C, D))\nnp.testing.assert_almost_equal( recursive_matrix_multiply(A, B, C, D[:,0]), np.einsum('ij,jk,kl,l', A, B, C, D[:,0]))\n```\n\nand here is a solution based on \"block induction\" doing an einsum per largest block doable at one. Note that I started with ```\nstring.ascii_letters```\n to use all 52 letters in the function vocab but I was running into errors, so I had to reduce it to ```\n11```\n, ```\n15```\n did work but was slow.\n```\nfrom string import ascii_letters, ascii_lowercase\nfrom itertools import pairwise\nfrom functools import reduce\n\nletters = ascii_lowercase[:11]\n\ndef build_multiply_einsten_string(length, ends_with_vector):\n    ein_string = ','.join( ''.join(pair) for pair in pairwise(ascii_lowercase[:length+1]))\n    return ein_string if not ends_with_vector else ein_string[:-1]\n\ndef recursive_matrix_multiply(*args):\n    if len(args) == 1:\n        return args[0]\n    batch = args[:len(letters)-1]\n    tail = args[len(letters)-1:]\n    return recursive_matrix_multiply( np.einsum(build_multiply_einsten_string(len(batch), batch[-1].ndim == 1 ), *batch), *tail)\n\n# testing ending on a matrix\nargs = [np.random.rand(5,5) for _ in range(60)]\nnp.testing.assert_allclose( recursive_matrix_multiply(*args), reduce(np.matmul, args))\n\n# testing ending on a vector\nargs[-1] = args[-1][:,0]\nnp.testing.assert_allclose( recursive_matrix_multiply(*args), reduce(np.matmul, args))\n```\n\nNote that they catter for both scenarios:\n\npure 2d matrix multiplication\nchain of dot products ending on a vector\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Multiplying a matrix by itself in C++ [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        Why are these numbers not equal?\r\n                            \r\n                                (6 answers)\r\n                            \r\n                    \r\n                    \r\n                        Is floating point math broken?\r\n                            \r\n                                (33 answers)\r\n                            \r\n                    \r\n                Closed 2 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI am trying to simulate Markov chain transitions by multiplying a 2x2 matrix (the transition matrix) by a 2x1 matrix in C++, and then taking that output as a 2x1 matrix and then using it again in a multiplication, repeated again up to a set number of times.\n```\n#include <iostream>\n\nusing namespace std;\n\nint main(void){\n\n// initialize variables\nfloat trMat1,trMat2,trMat3,trMat4,iniA,iniB;\nint cycle;\n\n// initialize transition matrix\ntrMat1 = 0.883; // top left\ntrMat2 = 0.259; // top right\ntrMat3 = 0.117; // bottom left\ntrMat4 = 0.741; // bottom right\n\n    cout << \"Enter the product preference for A: \";\n    cin >> iniA;\n\n    cout << \"Enter the product preference for B: \";\n    cin >> iniB;\n\n    if(iniA + iniB != 1){\n        cout << \"ERROR: Probabilities do not add to 1. Terminating\" << endl;\n        return 0;\n    }\n\n    cout << \"Enter number of cycles to simulate: \";\n    cin >> cycle;\n\n    cout << \"Simulating... \" << endl;\n\n    // matrix multiplication starts\n    for(int z = 0; z < cycle; z++){\n        iniA = trMat1 * iniA + trMat2 * iniB;\n        iniB = trMat3 * iniA + trMat4 * iniB;\n    }\n    \n    cout << \"A (end): \";\n    cout << iniA << endl;\n\n    cout << \"B (end): \";\n    cout << iniB << endl;\n```\n\n}\nSince these are probabilities, iniA and iniB are meant to add to exactly 1, but they never do (always a little over or under 1 but never exactly). Could this be due to a rounding error or perhaps something else? Thank you.\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "R Markovchain package - fitting the markov chain based on the states sequence matrix\r\n                \r\nI was trying to use the R markovchain package.\n\nI have a question regarding the markovchainFit function and the sequence matrix.\n\nBy default the markovchainFit function is run with the sequence of states as the parameter.\nThen it is said in the documentation that this function changes that sequence into the sequence matrix, which can be retrieved using the createSequenceMatrix function.\n\nMy question is - can the markovchainFit be somehow run with the sequence matrix as the parameter (or at least with the vecotr of multiple data sequences)?\n\nI'm asking because in my model I have multiple absorbing states.\nThat means an example sequence may be short as it will end with the absorbing state.\nI have multiple sequences in my dataset and I'm able to create a sequence matrix based on them.\nNevertheless I don't have one long sequence which can be used as the parameter for the markovchainFit (as each sequence is absorbed after couple of states).\n\n\n\nTerminology in my question is based on the following documentation:\nCRAN Introduction to markovchain package\n\nIn the weather example in that article a simple scenario is introduced.\nThere are 3 states (sunny,cloudy,rain) and the transition matrix is given as in input:\n\n```\n       sunny cloudy rain\nsunny  0.7   0.20   0.10\ncloudy 0.3   0.40   0.30\nrain   0.2   0.45   0.35\n```\n\n\nBased on that matrix a markov chain object is built:\n\n```\nR> weatherMatrix <- matrix(data = c(0.70, 0.2, 0.1,\n+                                   0.3, 0.4, 0.3,\n+                                   0.2, 0.45, 0.35), byrow = byRow, nrow = 3,\n+ dimnames = list(weatherStates, weatherStates))\nR> mcWeather <- new(\"markovchain\", states = weatherStates, byrow = byRow,\n+ transitionMatrix = weatherMatrix, name = \"Weather\")\n```\n\n\nThen a sequence of data is generated from the markov chain - in order to demonstrate how to fit the model back from that sample:\n\n```\nR> weathersOfDays <- rmarkovchain(n = 365, object = mcWeather, t0 = \"sunny\")\n```\n\n\nThen a new Markov chain is fitted based on the data:\n\n```\nR> weatherFittedLAPLACE <- markovchainFit(data = weathersOfDays,\n+                                    method = \"laplace\", laplacian = 0.01,\n+                                    name = \"Weather LAPLACE\")\nR> weatherFittedLAPLACE$estimate\n```\n\n\nThe estimated results are given below, to show how the data is close to the original transition matrix:\n\n```\n       cloudy    rain       sunny\ncloudy 0.3944786 0.32110428 0.2844171\nrain   0.4050361 0.37972922 0.2152347\nsunny  0.1932057 0.07958871 0.7272056\n```\n\n\nIt is said that the fitting is based on the 'sequence matrix', which can be retrieved as follows:\n\n```\nR> createSequenceMatrix(stringchar = weathersOfDays)\n\n       cloudy rain sunny\ncloudy 43     35   31\nrain   32     30   17\nsunny  34     14   128\n```\n\n\nMy problem is that I have the data in form of multiple sequences as there are many absorbing states and the chains are relatively short.\n\nI would like to feed them and have the model fitted, however the package allows for a single sequence of the data being fed. Alternatively, I can construct the sequence matrix as shown above ad feed it to the model, but I don't see a function in the package, that could handle it.\n\nLong story short - I have multiple short data sequences, based on which I want a markov chain model to be fitted.\n    ", "Answer": "\r\nThere is an example that answer your request, at least partially. The holson 'data.frame' is actually a matrix where rows are life trajectories and columns time sequences and by running \n\n```\nsingleMc<-markovchainFit(data=holson[,2:12],name=\"holson\")\n```\n\n\na transition matrix is fit. This requires the sequence length to be even. In your example, i suppose you could have uneven length maybe if you stop recording the sequence when an absorbing state is reached. So you have to repeat the last state for that row until the max length of the life history is reached\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Dynamic programming: maximize value of arithmetic expression using parenthesis\r\n                \r\nThis is an interview question asked to me sometime back:\n\nSuppose you are given an expression E= x1 y1 x2 y2....yn-1 xn.\nWhere Xi belong to natural number and Yi belongs to { +,*}\nyou need to parenthesize such that it maximize the value of E ?\n\nI was able to think in the direction of Dynamic Programming and could related it to matrix chain multiplication problem, but was stuck on deriving the exact recursive relation for this one.\nMoreover, follow-up questions just complicated the situation for me:\n\nLet's change Yi to { +,-,*,/}, then how to maximize E? Now add %\noperator in that set..then how to maximize E?\n\nAn explanation on to how to approach and build a solution for this would be great.\n    ", "Answer": "\r\nI think the same relation to the matrix multiplication algorithm will work.\n\nThe function we are trying to compute is\n\n```\nF(i,j) = maximum number that can be computed using Xi ... Xj\n```\n\n\nThe base case is when we have a single number:\n\n```\nF(i,i) = Xi\n```\n\n\nAnd the recursive case is for operations between two subexpressions wrapped in parenthesis:\n\n```\nF(i,j) = for k = i,j-1, maximize\n    F(i,k) Yk F(k+1, j)\n```\n\n\nI think greedly maximizing the numbers should work because for multiplication and addition over positive numbers, we want both the operands to be as big as possible.\n\nIf we allow division, then we will want the second operand to be as small as possible to maximize the result. In that case, instead of just computing ```\nF```\n, you will also need to compute a similar ```\nG```\n that minimizes the value over the interval.\n\nIf we allow subtraction, then we will need to account for positive vs negative numbersd. If you keep track of largets positive, smallest positive, largest negative and smallest negative I think you should be able to get any values you need. Perhaps there is an alternative that requires less computation though.\n\nI didn't stop to think about the implications of ```\n%```\n. For starters, how does it behave with the non-integer results from ```\n/```\n?\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Multiples transformations matrix on SVG, get cursor point\r\n                \r\nThis question is probably more related to math than svg itself. \n\nInside a main svg, got multiples transformed svg, (from different events), by a viewBox attribute.\n\nInside those svg, others elements are grouped in a ```\ng```\n, modified using matrix transformations.\n\nHow to obtain the points on the elements transformed from the mouse pointer.\n\nThe goal could be to draw a point or obtain the related point, as a graph chart.\n\n\r\n\r\n```\nlet point = document.getElementById(\"main\").createSVGPoint();\r\n\r\n// The mouse cursor points\r\npoint.x = 180\r\npoint.y = 63\r\nmouse = point.matrixTransform(sub.getCTM())\r\n\r\n// console.log(mouse)\r\n// Output \r\n//  \"x\": 611.75439453125,\r\n//  \"y\": 68.71578979492188\r\n\r\n\r\n// Testing:\r\ncircle.setAttribute(\"cx\", 611.75439453125)\r\ncircle.setAttribute(\"cy\", 68.71578979492188)\r\n// Not working```\n\r\n```\n<!-- Parent svg -->\r\n<!-- Not preserving aspect ratios -->\r\n<svg id=\"main\" viewBox=\"0 0 300 400\">\r\n\r\n  <!-- Includes others svg, transformed with a viewBox -->\r\n  <!-- Not preserving aspect ratios -->\r\n  <svg id=\"group1\" viewBox=\"7 54 10 570\">\r\n       \r\n      <!-- Group element modified with a matrix -->\r\n      <!-- Using css to define the matrix behave identicaly -->\r\n      <!-- All elements in this group are transformed by this matrix -->\r\n      <g id=\"sub\" transform=\"matrix(4.5,0,0,0.84,-140,99)\">\r\n        \r\n        <!-- Exemple element in group -->\r\n        <polyline points=\"4 65.94338623003772 5 78 6 50.10565885410098 7 40.95007190251531 8 53.698867220021675 9 49.43265131064406 10 44.36112722960851 11 56.329540580770356 12 49.785452985846554 13 44.10803037565898 14 40.537830814642945 15 41.84933269419995 16 38.33857254585345 17 43.590332265307744 18 49.16421525342487 19 49.49017332290519 20 42.51658803643061 21 46.943865580139814 22 36.27544970608283 23 38.070136488634255 24 43.46186643792423 25 42.20788657062835 26 48.37424628503659 27 25.58210762671243 28 23.927391073996347 29 22.349370537628886 30 30.592274894669004 31 21.97356005752208 32 24.960869894290738 33 23.221787723591348 34 17.41781668642936 35 2 36 19.335217095138404 37 39.60405681560149 38 38.49579937936788 39 32.47132729520408 40 25.016474506143126 41 27.037414536922626 42 27.541690844412955 43 20.37253071624997 44 9.872846078159213 45 17.79362716653617 46 13.107500567651172 47 24.955117693064494 48 24.247596942250766 49 19.728284178923616 50 11.341574791230315 51 8.248807931982782 52 10.697328253903962 \" ></polyline>\r\n   \r\n        <!-- This circle should be at the cursor -->\r\n        <circle id=\"circle\" cx=\"50\" cy=\"50\" r=\"50\"fill=\"blue\">\r\n\r\n      </g>\r\n      \r\n  </svg>\r\n\r\n   <!-- Rectangles symbolizing the mouse cursor -->\r\n   <rect width=\"1000\" height=\"1\" x=\"0\" y=\"63\" ></rect>\r\n   <rect width=\"1\" height=\"500\" x=\"180\" y=\"0\"></rect>\r\n   \r\n</svg>```\n\r\n\r\n\r\n\n\nSvg has numerous bindings related to transformations, we can retrieve the transformation matrix of each elements with getCTM() and getBBox(), and use matrixTransform.\n\nThis works for one level of transformation?\n\nHow to chain multiples matrix transformations?\n    ", "Answer": "\r\nIf you want the point relative to the transformed area, then it should get reflected as the offsetX and offsetY properties of their corresponding MouseEvents.\n\nHowever, there seems to be a bug in Webkit / Blink browsers with this regard, so this actually only works in Firefox (and maybe IE?)...\n\n\r\n\r\n```\nconst poly = document.querySelector('polyline');\r\npoly.addEventListener('mousemove', evt => {\r\n  circle.setAttribute(\"cx\", evt.offsetX + 2.5);\r\n  circle.setAttribute(\"cy\", evt.offsetY + 2.5);\r\n});```\n\r\n```\n<!-- Parent svg -->\r\n<!-- Not preserving aspect ratios -->\r\n<svg id=\"main\" viewBox=\"0 0 300 400\">\r\n\r\n  <!-- Includes others svg, transformed with a viewBox -->\r\n  <!-- Not preserving aspect ratios -->\r\n  <svg id=\"group1\" viewBox=\"7 54 10 570\">\r\n       \r\n      <!-- Group element modified with a matrix -->\r\n      <!-- Using css to define the matrix behave identicaly -->\r\n      <!-- All elements in this group are transformed by this matrix -->\r\n      <g id=\"sub\" transform=\"matrix(4.5,0,0,0.84,-140,99)\">\r\n        \r\n        <!-- Exemple element in group -->\r\n        <polyline points=\"4 65.94338623003772 5 78 6 50.10565885410098 7 40.95007190251531 8 53.698867220021675 9 49.43265131064406 10 44.36112722960851 11 56.329540580770356 12 49.785452985846554 13 44.10803037565898 14 40.537830814642945 15 41.84933269419995 16 38.33857254585345 17 43.590332265307744 18 49.16421525342487 19 49.49017332290519 20 42.51658803643061 21 46.943865580139814 22 36.27544970608283 23 38.070136488634255 24 43.46186643792423 25 42.20788657062835 26 48.37424628503659 27 25.58210762671243 28 23.927391073996347 29 22.349370537628886 30 30.592274894669004 31 21.97356005752208 32 24.960869894290738 33 23.221787723591348 34 17.41781668642936 35 2 36 19.335217095138404 37 39.60405681560149 38 38.49579937936788 39 32.47132729520408 40 25.016474506143126 41 27.037414536922626 42 27.541690844412955 43 20.37253071624997 44 9.872846078159213 45 17.79362716653617 46 13.107500567651172 47 24.955117693064494 48 24.247596942250766 49 19.728284178923616 50 11.341574791230315 51 8.248807931982782 52 10.697328253903962 \" ></polyline>\r\n   \r\n        <!-- This circle should be at the cursor -->\r\n        <circle id=\"circle\" cx=\"5\" cy=\"5\" r=\"5\" fill=\"blue\" pointer-events=\"none\">\r\n\r\n      </g>\r\n      \r\n  </svg>\r\n\r\n   <!-- Rectangles symbolizing the mouse cursor -->\r\n   <rect width=\"1000\" height=\"1\" x=\"0\" y=\"63\" ></rect>\r\n   <rect width=\"1\" height=\"500\" x=\"180\" y=\"0\"></rect>\r\n   \r\n</svg>```\n\r\n\r\n\r\n\n\nIf you wish to transform arbitrary values, then you use the technique described in this Answer which consists in dispatching such a MouseEvent on your element:\n\n\r\n\r\n```\nconst point = {x:180, y:63};\r\nconst poly = document.querySelector('polyline');\r\npoly.addEventListener('mousemove', evt => {\r\n  point.x = evt.offsetX;\r\n  point.y = evt.offsetY;\r\n}, {once: true});\r\nconst evt = new MouseEvent('mousemove', {\r\n  clientX: point.x, \r\n  clientY: point.y\r\n});\r\npoly.dispatchEvent(evt);\r\nconsole.log(point);\r\ncircle.setAttribute(\"cx\",  point.x);\r\ncircle.setAttribute(\"cy\", point.y);```\n\r\n```\n<!-- Parent svg -->\r\n<!-- Not preserving aspect ratios -->\r\n<svg id=\"main\" viewBox=\"0 0 300 400\">\r\n\r\n  <!-- Includes others svg, transformed with a viewBox -->\r\n  <!-- Not preserving aspect ratios -->\r\n  <svg id=\"group1\" viewBox=\"7 54 10 570\">\r\n       \r\n      <!-- Group element modified with a matrix -->\r\n      <!-- Using css to define the matrix behave identicaly -->\r\n      <!-- All elements in this group are transformed by this matrix -->\r\n      <g id=\"sub\" transform=\"matrix(4.5,0,0,0.84,-140,99)\">\r\n        \r\n        <!-- Exemple element in group -->\r\n        <polyline points=\"4 65.94338623003772 5 78 6 50.10565885410098 7 40.95007190251531 8 53.698867220021675 9 49.43265131064406 10 44.36112722960851 11 56.329540580770356 12 49.785452985846554 13 44.10803037565898 14 40.537830814642945 15 41.84933269419995 16 38.33857254585345 17 43.590332265307744 18 49.16421525342487 19 49.49017332290519 20 42.51658803643061 21 46.943865580139814 22 36.27544970608283 23 38.070136488634255 24 43.46186643792423 25 42.20788657062835 26 48.37424628503659 27 25.58210762671243 28 23.927391073996347 29 22.349370537628886 30 30.592274894669004 31 21.97356005752208 32 24.960869894290738 33 23.221787723591348 34 17.41781668642936 35 2 36 19.335217095138404 37 39.60405681560149 38 38.49579937936788 39 32.47132729520408 40 25.016474506143126 41 27.037414536922626 42 27.541690844412955 43 20.37253071624997 44 9.872846078159213 45 17.79362716653617 46 13.107500567651172 47 24.955117693064494 48 24.247596942250766 49 19.728284178923616 50 11.341574791230315 51 8.248807931982782 52 10.697328253903962 \" ></polyline>\r\n   \r\n        <!-- This circle should be at the cursor -->\r\n        <circle id=\"circle\" cx=\"5\" cy=\"5\" r=\"5\" fill=\"blue\" pointer-events=\"none\">\r\n\r\n      </g>\r\n      \r\n  </svg>\r\n\r\n   <!-- Rectangles symbolizing the mouse cursor -->\r\n   <rect width=\"1000\" height=\"1\" x=\"0\" y=\"63\" ></rect>\r\n   <rect width=\"1\" height=\"500\" x=\"180\" y=\"0\"></rect>\r\n   \r\n</svg>```\n\r\n\r\n\r\n\n\nNote that WebKit / Blink do set it correctly on HTML elements as demonstrated in this Q/A...\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Max Product of a string that requires K multiplication operators to be inserted\r\n                \r\nMaximum Product.\nThe input to the problem is a string Z = z1,z2.....zn where each zi is any number between 1...9 and an integer k where 0 <= k < n.\nAn example string is Z = 8473817, which is of length n = 7. We want to insert k multiplication operators X into the string so that the mathematical result of the expression\nis the largest possible. There are n - 1 possible locations for the operators,\nnamely, after the ith character where i = 1,....., n - 1.\nFor example, for input Z = 21322 and k = 2, then one possible way to insert the X operators\nis: 2 X 1 X 322 = 644, another possibility is 21 X 3 X 22 = 1386.\nDesign a dynamic programming to output the maximum product\nobtainable from inserting exactly k multiplication operators X into the string.\nYou can assume that all the multiplication operations in your algorithm take\nO(1) time.\nI am approaching this using the Matrix Chain Multiplication method where you compute smaller subproblem along the upper diagonal.\nThis works when K=1 i.e. one multiplication operator is inserted.\nIn the picture below, I have used 8473817 as an example and shown that 8473 X 817 yields the highest product.\nHow do I scale this solution for K > 1 and K < N.\n\nUpdate: adding a pseudo code.\nlet A(i,j) store the max product for the strings A(i...j) 1 < i < j < n\n```\nfor i = 1 -> n:\n   A(i,i) = Z(i) \n\nfor s = 1 -> n-1:\n    for i = 1 -> n-s:\n        j = i + s\n        A(i,j) = 0\n        for l = i -> j-1:\n          A(i,j) = max (A(i,j), A(i,l) * A(l+1,j)\nreturn A(1,n)\n```\n\nThe above code works when k = 1. How do I scale this up when k > 1 and less than n\nUpdate\nBased on @trincot solution, I revamped the soln to not use memoization\nSub problem Defn\nLet T(i) store the start offset where inserting the X operator in Z yields max value for i : 1 < i < k.\nPseudo code\n```\n`\n    T(0) = 0\n    for i = 1 -> k:\n      max = 0\n    for j = T(i-1) + 1 -> n:\n          result = Z[1..j] * Z[j+1..n]\n          if result > max\n           max = result\n           T(i) = j\n  \n     val = 1\n    for i = 1 -> k:\n          val = val * Z[T(i-1)+1...T(i)]\n    val = val * Z[T(k)+1..n]\n```\n\n    ", "Answer": "\r\nYour pseudo code is a dynamic programming solution where you use memoization for every possible slice of ```\nz```\n (2 dimensions, starting and ending offset). However, you would only need to memoize the best result for any suffix of ```\nz```\n, so you would only need one (starting) offset. A second dimension in your memoization would then be used for the value of ```\nk```\n (the number of remaining multiplications).\nSo you would still need a 2-dimensional table for memoization, but one index would be for ```\nk```\n and the other for an offset in ```\nz```\n.\nHere is an implementation in JavaScript:\n\r\n\r\n```\nfunction solve(z, k) {\n    // Initialise a kxl array (where l is the length of z), filled with zeroes.\n    const memo = Array.from({length: k + 1}, () => Array(z.length + 1).fill(0));\n    \n    function recur(z, k) {\n        if (k == 0) return z;\n        let result = memo[k][z.length];\n        if (result == 0) {\n            for (let i = 1; i <= z.length - k; i++) {\n                result = Math.max(result, +z.slice(0, i) * recur(z.slice(i), k - 1));\n            }\n            memo[k][z.length] = result;\n        }\n        return result;       \n    }\n    return recur(z, k);\n}\n\n// A few example runs:\nconsole.log(solve('8473817', 1));  // 6922441\nconsole.log(solve('21322', 2));    // 1368\nconsole.log(solve('191111', 2));   // 10101```\n\r\n\r\n\r\n\nBottom up\nThe same can be done in an iterative algorithm -- bottom-up instead of top-down. Here we can save one dimension of the memoization array, as the same array can be re-used for the next value of ```\nk```\n as it increases from 0 to its final value:\n\r\n\r\n```\nfunction solve(z, k) {\n    const memo = Array(z.length);\n    // Initialise for k=0:\n    //    the best product in a suffix is the suffix itself\n    for (let i = 0; i < z.length; i++) {\n        memo[i] = +z.slice(i);\n    }\n    for (let kk = 1; kk <= k; kk++) {\n        for (let i = 0; i < z.length - kk; i++) {\n            // find best position for multiplication\n            let result = 0;\n            for (let j = i + 1; j < z.length - kk + 1; j++) {\n                result = Math.max(result, +z.slice(i, j) * memo[j]);\n            }\n            memo[i] = result;\n        }\n    }\n    return memo[0];\n}\n\n// A few example runs:\nconsole.log(solve('8473817', 1));  // 6922441\nconsole.log(solve('21322', 2));    // 1368\nconsole.log(solve('191111', 2));   // 10101```\n\r\n\r\n\r\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Finding stationary distribution of a markov process given a transition probability matrix\r\n                \r\nThere has been two threads related to this issue on Stack Overflow: \n\n\nHow can I obtain stationary distribution of a Markov Chain given a transition probability matrix describes what a transition probability matrix is, and demonstrate how a stationary distribution is reached by taking powers of this matrix;\nHow to find when a matrix converges with a loop uses an R loop to determine when the matrix power converges.\n\n\nThe above is straightforward, but very expensive. If we have a transition matrix of order ```\nn```\n, then at each iteration we compute a matrix-matrix multiplication at costs ```\nO(n ^ 3)```\n.\n\nIs there a more efficient way to do this? One thing that occurs to me is to use Eigen decomposition. A Markov matrix is known to:\n\n\nbe diagonalizable in complex domain: ```\nA = E * D * E^{-1}```\n;\nhave a real Eigen value of 1, and other (complex) Eigen values with length smaller than 1.\n\n\nThe stationary distribution is the Eigen vector associated with the Eigen value of 1, i.e., the first Eigen vector.\n\nWell, the theory is nice, but I can't get it work. Taking the matrix ```\nP```\n in the first linked question:\n\n```\nP <- structure(c(0, 0.1, 0, 0, 0, 0, 0, 0.1, 0.2, 0, 0, 0, 0, 0, 0.2, \n0.3, 0, 0, 0.5, 0.4, 0.3, 0.5, 0.4, 0, 0, 0, 0, 0, 0.6, 0.4, \n0.5, 0.4, 0.3, 0.2, 0, 0.6), .Dim = c(6L, 6L))\n```\n\n\nIf I do:\n\n```\nRe(eigen(P)$vectors[, 1])\n# [1] 0.4082483 0.4082483 0.4082483 0.4082483 0.4082483 0.4082483\n```\n\n\nWhat's going on? According to previous questions, the stationary distribution is:\n\n```\n# [1] 0.002590673 0.025906737 0.116580322 0.310880848 0.272020713 0.272020708\n```\n\n    ", "Answer": "\r\nWell, to use Eigen decomposition, we need to work with ```\nt(P)```\n. \n\nThe definition of a transition probability matrix differs between probability / statistics and linear algebra. In statistics all rows of ```\nP```\n sum to 1, while in linear algebra, all columns of ```\nP```\n sum to 1. So instead of ```\neigen(P)```\n, we need ```\neigen(t(P))```\n:\n\n```\ne <- Re(eigen(t(P))$vectors[, 1])\ne / sum(e)\n# [1] 0.002590673 0.025906737 0.116580322 0.310880848 0.272020713 0.272020708\n```\n\n\nAs we can see, we've only used the first Eigen vector, i.e., the Eigen vector of the largest Eigen value. Therefore, there is no need to compute all Eigen values / vectors using ```\neigen```\n. The power method can be used to find an Eigen vector of the largest Eigen value. Let's implement this in R:\n\n```\nstydis1 <- function (A) {\n  n <- dim(A)[1L]\n  ## checking\n  if (any(.rowSums(A, n, n) != 1)) \n    stop (\" 'A' is not a Markov matrix\")\n  ## implement power method\n  e <- runif (n)\n  oldnorm <- sqrt(c(crossprod(e)))\n  repeat {\n    e <- crossprod(A, e)\n    newnorm <- sqrt(c(crossprod(e)))\n    if (abs(newnorm / oldnorm - 1) < 1e-8) break\n    e <- e / newnorm\n    oldnorm <- newnorm\n    }\n  ## rescale `e` so that it sums up to 1\n  c(e / sum(e))\n  }\n\nstydis1 (P)\n# [1] 0.002590673 0.025906737 0.116580322 0.310880848 0.272020713 0.272020708\n```\n\n\nAnd the result is correct.\n\n\n\nIn fact, we don't have to exploit Eigen decomposition. We can adjust the method used in your second linked question. Over there, we took matrix power which is expensive as you commented; but why not re-cast it into a matrix-vector multiplication?\n\n```\nstydis2 <- function (A) {\n  n <- dim(A)[1L]\n  ## checking\n  if (any(.rowSums(A, n, n) != 1)) \n    stop (\" 'A' is not a Markov matrix\")\n  ## direct computation\n  b <- A[1, ]\n  oldnorm <- sqrt(c(crossprod(b)))\n  repeat {\n    b <- crossprod(A, b)\n    newnorm <- sqrt(c(crossprod(b)))\n    if (abs(newnorm / oldnorm - 1) < 1e-8) break\n    oldnorm <- newnorm\n    }\n  ## return stationary distribution\n  c(b)\n  }\n\nstydis2 (P)\n# [1] 0.002590673 0.025906737 0.116580322 0.310880848 0.272020713 0.272020708\n```\n\n\nWe start from an arbitrary initial distribution, say ```\nA[1, ]```\n, and iteratively apply transition matrix until the distribution converges. Again, the result is correct.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Reconstruct a string from n continuous substrings of fixed length\r\n                \r\nI have as input a list of n+2 continuous substrings of length 3.\nMy goal is to find out whether there exists a string of length n such that all its continuous substrings of length 2 are exactly the input list that I have been given.\nHow can I efficiently solve this problem (e.g. for strings of length 4000)?\nI have tried out a DP approach similiar to the one used for matrix chain multiplication but it didn't work.\nNow I am thinking that I could convert this problem into a graph where the substrings are the vertices and two vertices (substrings of length 3) are connected by an edge if the substrings can be joined into a substring of length 4 (e.g. abc and bcd are connected as they can be joined into abcd). Would trying to find a Eulerian path in this graph solve my problem? Or am I completely wrong about all this?\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Matrix class C++\r\n                \r\nhey there i'm a student in computer science ,\nwe are asked to build a generic matrix using the vector class  and we are not allowed to use \"new\" and \"delete\" at all.\nI don't know how to start it properly we can use these libraries:\n\ncassert\n\nvector\n\ncstdlib\n\ncmath\n\nI searched all over the Internet but didn't found a class that uses the vector as the matrix (index of matrix is mat[i*cols+j]) and doesn't use new and delete function or allocate memory:\n\nexamples of what we are supposed to check:(int google test)\n\n\"Matrix.hpp\"\n\n```\ntemplate < class T ><class T> class Matrix {\n    private:\n        int rows;\n        int cols;\n        vector< T > mat;\n\n    public:\n        Matrix(int row, int col,const T& mat2):rows(row),cols(col) {\n            mat.resize(rows*cols);\n            //?\n        };\n\n        Matrix(int row, int col);\n        virtual ~Matrix();\n        Matrix(const Matrix< T >& rhs);\n        Matrix< T > transpose();\n        Matrix< T >& operator=(const Matrix< T >& rhs);\n        bool operator==(const Matrix< T >& rhs)const;\n        const int getRowNum() const;\n        const int getColNum() const;\n        Matrix< T >& operator+(const Matrix< T >& rhs);\n};\n```\n\n\n\"gtest/gtest.h\"\n\n```\nMatrix<int> mat1(1, 1, std::vector<int>(1,2));\n\nEXPECT_EQ(1, mat1.getRowNum());\nEXPECT_EQ(1, mat1.getColNum());\n\nint t= 0;\nEXPECT_TRUE(mat1.hasTrace(t));\nEXPECT_TRUE(mat1.isSquareMatrix());\n\nMatrix<int> transpose_mat= mat1;\nEXPECT_EQ(transpose_mat, mat1.transpose());\n\nMatrix<int> mat2(1, 1, std::vector<int>(1,3));\nMatrix<int> add_mat(1, 1, std::vector<int> (1,5));\nEXPECT_EQ(add_mat, mat1+mat2);\n\nMatrix<int> multi_mat(1, 1, std::vector<int>(1,6));\nEXPECT_EQ(multi_mat, mat1*mat2);\n\nMatrix<int> scalar_multi_mat(1, 1, std::vector<int>(1,4));\nEXPECT_EQ(scalar_multi_mat, mat1*2);\n```\n\n\nThis is what we are supposed to do:\n\nMatrix interface: You must define and implement the generic class file Matrix.hpp Matrix. The matrix will be generic and limbs will not necessarily integers but generic type numbers. For the purpose of due diligence, you Squirrels are entitled to assume that operators will have the necessary exercise as being above. Also you can assume the Squirrels be used in relation to the rest of the matrix are such that the order of the atomic steps of connecting or twice) a long chain of calculations (does not matter. For example (a + b) + c == a + (b + c) the exercise or functions that you can use the default language is given), all generically, of course (:\n\n\nConstructor without parameters. The builder builds a matrix of 1x1 With organ is conducted T where T is the type that is stored in the matrix.\nThe constructor gets the number of rows, number of columns and the vector with the values ​​of the matrix filling) saw the driver call this constructor does not realize, the department should be structured so that default is good enough\n(Constructor Copy) copy constructor (a different matrix receiver) does not realize, the department should be structured so that default is good enough \n(The assignment operator) do not realize, the department must be built so that default is good enough\nPlus (+) operator to connect matrices. \nMultiplication (*) operator matrix multiplication. Matrix of the object it does the function is left matrix multiplication.\n(Swap function matrix) transpose \n(Aqaba function) HasTrace (reference to the organ recipient generic type and a task which the value of the trace (if any) of the matrix and returns a Boolean value: true if a square matrix, and another false case put the value additive identity organ received about .reference\nThe four functions above) connection, transpose and HasTrace double (not from the object it was applied function. In addition, you can add more public functions or Privacy desired, according to what you think is useful to the department.\n\n\nIf someone can help me, I will be grateful! \n    ", "Answer": "\r\nYou can start by considering that an ```\nNxM```\n matrix can be represented as a vector with ```\nM*N```\n elements.  Operations such as addition and subtraction become simply equivalent to vector addition and subtraction.\n\nMore general operations, though will require a simple transformation to convert a matrix index ```\n[a, b]```\n into a vector index ```\n[c]```\n.\n\nGiven a matrix index ```\n[a, b]```\n you can find the corresponding vector element by using:\n\n```\nc = a*N + b\n```\n\n\nSimilarly, converting from a vector index ```\n[c]```\n to the matrix index ```\n[a, b]```\n by:\n\n```\na = c / N\nb = c % N\n```\n\n\nHere the ```\n/```\n and ```\n%```\n are integer division and modulus.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Guaranteed Detection of Temporary->Named Points\r\n                \r\nSuppose you write a matrix class with some operations:\n\n```\nclass matrix\n{\npublic:\n    double operator()(size_t i, size_t j) const;\n    ...\n};\n\nmatrix operator*(const matrix &lhs, const matrix &rhs);\n...\n```\n\n\nIt makes sense to defer the evaluation of some matrix expressions: m0 * m1 * m2 * m3 * m4 (which is a series of four ```\noperator*```\n calls) can benefit from using the dynamic-programming matrix chain multiplication algorithm; the very common m0 * m1t has a very efficient ```\ndgemm```\n implementation, and so forth.\n\nIt consequently pays to defer the actual computation until when it's needed. This changes the above to:\n\n```\nclass matrix\n{\nprivate:\n    /*\n    * Pointer to an abstract base class - either an actual matrix, \n    *    or an expression tree. */\n    std::shared_ptr<matrix_imp> m_imp;\n\npublic:\n    // Forces compaction - \n    double operator()(size_t i, size_t j) const;\n    ...\n};\n\n/* Lazy; creates a matrix with an expression tree using the\n*    internals of lhs and rhs. */\nmatrix operator*(const matrix &lhs, const matrix &rhs);\n...\n```\n\n\nEach matrix holds a pointer to a base class object that can range from a real matrix to a complicated expression tree. Each operation tries to form a matrix using the laziest change to the internal implementation. Some operations have no choice but to actually evaluate things, compact the expression tree, and set the internal implementation to an actual matrix.\n\n\n\nThe problem was that, in practice, this caused huge memory overhead in very common cases. Let's say you read from a file a long-and-narrow matrix x = xp X q, p >> q, store xt x in a variable, and discard x. With lazy evaluation, the memory is pq >> qq. Load these in a loop, and it's a serious problem. (Of course, compaction can be forced after each load by the client code calling ```\noperator()```\n, but requiring this without algorithmic justification is ugly and error prone.)\n\nInitially, I thought that the move ctor was a good point for automatic compaction - it's exactly the point where a temporary becomes a named object, and it's named objects that cause increasing memory consumption, so \n\n```\nmatrix(matrix &&other); // <- Force compaction only here\n```\n\n\nwould appear to solve everything, e.g.,\n\n```\nauto res = // <- temp becoming named\n    a * // temp\n    b * // temp\n    c + // temp\n    2 * // temp\n    d;\n```\n\n\nbut can it be counted on? E.g., consider\n\n```\nmatrix load_xtx(const string &f_name)\n{\n    matrix x = ...\n    return x.t() * x; \n}\n\nauto xtx = load_xtx(\"foo.hdf5\"); // (*)\n```\n\n\nis the compiler forbidden to do in ```\n(*)```\n something similar to what it does with the NRVO, namely just to construct it in place? Even if not, might a compiler optimize away things in other cases?\n    ", "Answer": "\r\nSince the \"internal pointer\" method cannot give all the flexibility needed for the deferred evaluation, the typical solution used by C++ numerical libraries is to define specialized classes implementing lazy evaluation mechanisms. The old SO question Lazy evaluation in C++ and its best answers show the basics of such design and some sample code.\n\nAlthough I am not an expert, I think good examples of this architecture are the numerical libraries Eigen (here some details about its implementation) and Blitz++, which heavily relies on templates (I did not find on the web updated documentation illustrating its internals, but this article describes some part of its engine and also provides a broader overview of the \"expression template\" technique).\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "%^% operator in R\r\n                \r\nin order to perform markov chain forecast, i've been encountered to %^% operator. Previously we know that %*% operator would return multiplication for each element within the matrix, but when doing with %^% what should it return.\nthe following condition as below:\n```\nra <- matrix(c(.66, .23, .11, .46, .31, .23, .20, .31, .49), \n             nrow = 3, byrow = T) %>%\n  as.data.frame()\nColumnNames  <- c(\"No Rain\", \"Light Rain\", \"Heavy Rain\")\nRowNames <- c(\"No Rain\", \"Light Rain\", \"Heavy Rain\")\ncolnames(ra) <- ColumnNames\nrownames(ra) <- RowNames\n      \n        No Rain Light Rain Heavy Rain\n    No Rain       0.66       0.23       0.11\n    Light Rain    0.46       0.31       0.23\n    Heavy Rain    0.20       0.31       0.49\n```\n\nto perform predict the second day, perhaps we first should,\n```\nra2 <- ra %^% 2\n```\n\n    ", "Answer": "\r\nYou are probably referring to an overloaded operator.\n\nFor instance, consider I can have an overloaded operator '%^%' defined as:\n\n```\n'%^%' <- function(x,y) x+y\n\n a <- matrix(c(1,2,3,4),2,2)\n\n b <- matrix(c(1,2,3,4),2,2)\n```\n\n\nThen applying the operator on the matrices a and b will add them according to my operator definition.\n\n```\na %^% b \n    [,1] [,2]\n[1,]    2    6\n[2,]    4    8\n```\n\n\nAlso to know what the R operator  means in your context, %^%\nYou can see the custom operator definition this way:\n\n```\n`%^%`\nfunction(x,y) x+y\n```\n\n\nMore over, the custom operator can be used like a function call with function name being ```\n%^%```\n in this case , which is same as operand1 %^% operand2\n\n```\n   `%^%`(a,b)\n     [,1] [,2]\n[1,]    2    6\n[2,]    4    8\n```\n\n\nSo in your case, its a custom operator whose definition is required, before you can use it(implementation can come from a libray as well).\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Einsum slower than explicit Numpy implementation for n-mode tensor-matrix product\r\n                \r\nI'm trying to implement the n-mode tensor-matrix product (as defined by Kolda and Bader: https://www.sandia.gov/~tgkolda/pubs/pubfiles/SAND2007-6702.pdf) efficiently in Python using Numpy. The operation effectively gets down to (for matrix U, tensor X and axis/mode k):\n\n\nExtract all vectors along axis k from X by collapsing all other axes.\nMultiply these vectors on the left by U using standard matrix multiplication.\nInsert the vectors again into the output tensor using the same shape, apart from X.shape[k], which is now equal to U.shape[0] (initially, X.shape[k] must be equal to U.shape[1], as a result of the matrix multiplication).\n\n\nI've been using an explicit implementation for a while which performs all these steps separately:\n\n\nTranspose the tensor to bring axis k to the front (in my full code I added an exception in case k == X.ndim - 1, in which case it's faster to leave it there and transpose all future operations, or at least in my application, but that's not relevant here).\nReshape the tensor to collapse all other axes.\nCalculate the matrix multiplication.\nReshape the tensor to reconstruct all other axes.\nTranspose the tensor back into the original order.\n\n\nI would think this implementation creates a lot of unnecessary (big) arrays, so once I discovered np.einsum I thought this would speed things up considerably. However using the code below I got worse results:\n\n```\nimport numpy as np\nfrom time import time\n\ndef mode_k_product(U, X, mode):\n    transposition_order = list(range(X.ndim))\n    transposition_order[mode] = 0\n    transposition_order[0] = mode\n    Y = np.transpose(X, transposition_order)\n    transposed_ranks = list(Y.shape)\n    Y = np.reshape(Y, (Y.shape[0], -1))\n    Y = U @ Y\n    transposed_ranks[0] = Y.shape[0]\n    Y = np.reshape(Y, transposed_ranks)\n    Y = np.transpose(Y, transposition_order)\n    return Y\n\ndef einsum_product(U, X, mode):\n    axes1 = list(range(X.ndim))\n    axes1[mode] = X.ndim + 1\n    axes2 = list(range(X.ndim))\n    axes2[mode] = X.ndim\n    return np.einsum(U, [X.ndim, X.ndim + 1], X, axes1, axes2, optimize=True)\n\ndef test_correctness():\n    A = np.random.rand(3, 4, 5)\n    for i in range(3):\n        B = np.random.rand(6, A.shape[i])\n        X = mode_k_product(B, A, i)\n        Y = einsum_product(B, A, i)\n        print(np.allclose(X, Y))\n\ndef test_time(method, amount):\n    U = np.random.rand(256, 512)\n    X = np.random.rand(512, 512, 256)\n    start = time()\n    for i in range(amount):\n        method(U, X, 1)\n    return (time() - start)/amount\n\ndef test_times():\n    print(\"Explicit:\", test_time(mode_k_product, 10))\n    print(\"Einsum:\", test_time(einsum_product, 10))\n\ntest_correctness()\ntest_times()\n```\n\n\nTimings for me:\n\nExplicit: 3.9450525522232054\n\nEinsum: 15.873924326896667\n\nIs this normal or am I doing something wrong? I know there are circumstances where storing intermediate results can decrease complexity (e.g. chained matrix multiplication), however in this case I can't think of any calculations that are being repeated. Is matrix multiplication so optimized that it removes the benefits of not transposing (which technically has a lower complexity)?\n    ", "Answer": "\r\nI'm more familiar with the subscripts style of using ```\neinsum```\n, so worked out these equivalences:\n\n```\nIn [194]: np.allclose(np.einsum('ij,jkl->ikl',B0,A), einsum_product(B0,A,0))          \nOut[194]: True\nIn [195]: np.allclose(np.einsum('ij,kjl->kil',B1,A), einsum_product(B1,A,1))          \nOut[195]: True\nIn [196]: np.allclose(np.einsum('ij,klj->kli',B2,A), einsum_product(B2,A,2))          \nOut[196]: True\n```\n\n\nWith a ```\nmode```\n parameter, your approach in ```\neinsum_product```\n may be best.  But the equivalences help me visualize the calculation better, and may help others.\n\nTimings should basically be the same.  There's an extra setup time in ```\neinsum_product```\n that should disappear in larger dimensions.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How to optimize this product of three matrices in C++ for x86?\r\n                \r\nI have a key algorithm in which most of its runtime is spent on calculating a dense matrix product:\n\n```\nA*A'*Y, where: A is an m-by-n matrix, \n               A' is its conjugate transpose,\n               Y is an m-by-k matrix\n\nTypical characteristics:\n    - k is much smaller than both m or n (k is typically < 10)\n    - m in the range [500, 2000]\n    - n in the range [100, 1000]\n```\n\n\nBased on these dimensions, according to the lessons of the matrix chain multiplication problem, it's clear that it's optimal in a number-of-operations sense to structure the computation as ```\nA*(A'*Y)```\n. My current implementation does that, and the performance boost from just forcing that associativity to the expression is noticeable.\n\nMy application is written in C++ for the x86_64 platform. I'm using the Eigen linear algebra library, with Intel's Math Kernel Library as a backend. Eigen is able to use IMKL's BLAS interface to perform the multiplication, and the boost from moving to Eigen's native SSE2 implementation to Intel's optimized, AVX-based implementation on my Sandy Bridge machine is also significant. \n\nHowever, the expression ```\nA * (A.adjoint() * Y)```\n (written in Eigen parlance) gets decomposed into two general matrix-matrix products (calls to the ```\nxGEMM```\n BLAS routine), with a temporary matrix created in between. I'm wondering if, by going to a specialized implementation for evaluating the entire expression at once, I can arrive at an implementation that is faster than the generic one that I have now. A couple observations that lead me to believe this are:\n\n\nUsing the typical dimensions described above, the input matrix ```\nA```\n usually won't fit in cache. Therefore, the specific memory access pattern used to calculate the three-matrix product would be key. Obviously, avoiding the creation of a temporary matrix for the partial product would also be advantageous.\n```\nA```\n and its conjugate transpose obviously have a very related structure that could possibly be exploited to improve the memory access pattern for the overall expression.\n\n\nAre there any standard techniques for implementing this sort of expression in a cache-friendly way? Most optimization techniques that I've found for matrix multiplication are for the standard ```\nA*B```\n case, not larger expressions. I'm comfortable with the micro-optimization aspects of the problem, such as translating into the appropriate SIMD instruction sets, but I'm looking for any references out there for breaking this structure down in the most memory-friendly manner possible.\n\nEdit: Based on the responses that have come in thus far, I think I was a bit unclear above. The fact that I'm using C++/Eigen is really just an implementation detail from my perspective on this problem. Eigen does a great job of implementing expression templates, but evaluating this type of problem as a simple expression just isn't supported (only products of 2 general dense matrices are).\n\nAt a higher level than how the expressions would be evaluated by a compiler, I'm looking for a more efficient mathematical breakdown of the composite multiplication operation, with a bent toward avoiding unneeded redundant memory accesses due to the common structure of ```\nA```\n and its conjugate transpose. The result would likely be difficult to implement efficiently in pure Eigen, so I would likely just implement it in a specialized routine with SIMD intrinsics.\n    ", "Answer": "\r\nThis is not a full answer (yet - and I'm not sure it will become one).\n\nLet's think of the math first a little. Since matrix multiplication is associative we can either do \n(A*A')Y or A(A'*Y).\n\nFloating point operations for (A*A')*Y\n\n```\n2*m*n*m + 2*m*m*k //the twos come from addition and multiplication\n```\n\n\nFloating point operations for A*(A'*Y)\n\n```\n2*m*n*k + 2*m*n*k = 4*m*n*k\n```\n\n\nSince k is much smaller than m and n it's clear why the second case is much faster.\n\nBut by symmetry we could in principle reduce the number of calculations for A*A' by two (though this might not be easy to do with SIMD) so we could reduce the number of floating point operations  of (A*A')*Y to\n\n```\nm*n*m + 2*m*m*k.\n```\n\n\nWe know that both m and n are larger than k.  Let's choose a new variable for m and n called ```\nz```\n and find out where case one and two are equal:\n\n```\nz*z*z + 2*z*z*k = 4*z*z*k  //now simplify\nz = 2*k.\n```\n\n\nSo as long as m and n are both more than twice k the second case will have less floating point operations.  In your case m and n are both more than 100 and k less than 10 so case two uses far fewer floating point operations.\n\nIn terms of efficient code.  If the code is optimized for efficient use of the cache (as MKL and Eigen are) then large dense matrix multiplication is computation bound and not memory bound so you don't have to worry about the cache.  MKL is faster than Eigen since MKL uses AVX (and maybe fma3 now?).  \n\nI don't think you will be able to do this more efficiently than you're already doing using the second case and MKL (through Eigen).  Enable OpenMP to get maximum FLOPS.\n\nYou should calculate the efficiency by comparing FLOPS to the peak FLOPS of you processor.  Assuming you have a Sandy Bridge/Ivy Bridge processor.  The peak SP FLOPS is\n\n```\nfrequency * number of physical cores * 8 (8-wide AVX SP) * 2 (addition + multiplication)\n```\n\n\nFor double precession divide by two.  If you have Haswell and MKL uses FMA then double the peak FLOPS.  To get the frequency right you have to use the turbo boost values for all cores (it's lower than for a single core).  You can look this up if you have not overclocked your system or use CPU-Z on Windows or Powertop on Linux if you have an overclocked system.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Constructing Eigen expression templates with Boost.Proto\r\n                \r\nI'd like to use Boost.Proto to transform an embedded domain-specific language into a series of matrix operations implemented with the Eigen library. Since efficiency is important, I want proto to generate Eigen expression templates and avoid premature evaluation.\n\nI've implemented a simple grammar that can generate matrix multiplication expressions. The code below compiles without warnings (on g++ 4.8.0 and Intel C++ 2013.3, with Boost 1.54.0 and Eigen 3.1.3) and works as long as my expression only has a single multiplication operation. As soon as I add more multiplications to the chain, it crashes. Valgrind tells me that this is because one of the Eigen::GeneralProduct expression template temporaries gets destroyed before the evaluation is completed.\n\nI don't understand why this happens, or what I can do to prevent it. All help is appreciated!\n\n```\n#include <iostream>\n\n#include <boost/fusion/container.hpp>\n#include <boost/mpl/int.hpp>\n#include <boost/mpl/void.hpp>\n#include <boost/proto/proto.hpp>\n#include <boost/ref.hpp>\n#include <boost/type_traits/remove_const.hpp>\n#include <boost/type_traits/remove_reference.hpp>\n#include <boost/utility.hpp>\n\n#include <Eigen/Dense>\n\nnamespace fusion = boost::fusion;\nnamespace mpl = boost::mpl;\nnamespace proto = boost::proto;\n\ntypedef Eigen::Matrix<float, Eigen::Dynamic, Eigen::Dynamic> matrix;\n\n// Placeholders\n\nconst proto::terminal<mpl::int_<0> >::type I1 = {{}};\nconst proto::terminal<mpl::int_<1> >::type I2 = {{}};\nconst proto::terminal<mpl::int_<2> >::type I3 = {{}};\n\n// Grammar\n\ntemplate<class Rule, class Callable = proto::callable>\nstruct External :\n    proto::when<Rule, proto::external_transform> {};\n\nstruct matmul_transform : proto::callable {\n    template<class Sig> struct result;\n\n    template<class This, class MatrixExpr1, class MatrixExpr2>\n    struct result<This(MatrixExpr1, MatrixExpr2)> {\n            typedef typename Eigen::ProductReturnType<\n                    typename boost::remove_const<typename boost::remove_reference<MatrixExpr1>::type>::type,\n                    typename boost::remove_const<typename boost::remove_reference<MatrixExpr2>::type>::type>::Type\n                    type;\n    };\n\n    template<class MatrixExpr1, class MatrixExpr2>\n    typename result<matmul_transform(MatrixExpr1, MatrixExpr2)>::type\n    operator()(const MatrixExpr1 &a, const MatrixExpr2 &b) const {\n            return a * b;\n    }\n};\n\n\nstruct MatmulGrammar;\n\nstruct InputPlaceholder : proto::terminal<proto::_> {};\n\nstruct MatrixMultiplication :\n    proto::multiplies<MatmulGrammar, MatmulGrammar> {};\n\nstruct MatmulGrammar : proto::or_<\n    External<InputPlaceholder>,\n    External<MatrixMultiplication> > {};\n\nstruct matmul_transforms : proto::external_transforms<\n    proto::when<MatrixMultiplication, matmul_transform(MatmulGrammar(proto::_left), MatmulGrammar(proto::_right))>,\n    proto::when<InputPlaceholder, proto::functional::at(proto::_data, proto::_value)> > {};\n\nint main() {\n    matrix mat1(2,2), mat2(2,2), mat3(2,2), result(2,2);\n\n    mat1 << 1, 2, 3, 4;\n    mat2 << 5, 6, 7, 8;\n    mat3 << 1, 3, 6, 9;\n\n    MatmulGrammar mmg;\n\n    // THIS WORKS:\n    result = mmg(I1 * I2,\n            mpl::void_(),\n            (proto::data = fusion::make_vector(boost::cref(mat1), boost::cref(mat2), boost::cref(mat3)),\n             proto::transforms = matmul_transforms()));\n\n    std::cout << result << std::endl;\n\n    // THIS CRASHES:\n    result = mmg(I1 * I2 * I3,\n            mpl::void_(),\n            (proto::data = fusion::make_vector(boost::cref(mat1), boost::cref(mat2), boost::cref(mat3)),\n             proto::transforms = matmul_transforms()));\n\n    std::cout << result << std::endl;\n\n    return 0;\n}\n```\n\n    ", "Answer": "\r\nThis is my attempt at merging your approach with the solution linked in the comment. I have copied ```\nstored_result_expression```\n, ```\ndo_wrap_expression```\n and ```\nwrap_expression```\n from here. The changes I've made to either your code or the one from the talk are marked with ```\n//CHANGED```\n. \n\n```\n#include <iostream>\n\n#include <boost/fusion/container.hpp>\n#include <boost/mpl/int.hpp>\n#include <boost/mpl/void.hpp>\n#include <boost/proto/proto.hpp>\n#include <boost/ref.hpp>\n#include <boost/type_traits/remove_const.hpp>\n#include <boost/type_traits/remove_reference.hpp>\n#include <boost/utility.hpp>\n\n#include <Eigen/Dense>\n\nnamespace fusion = boost::fusion;\nnamespace mpl = boost::mpl;\nnamespace proto = boost::proto;\n\ntypedef Eigen::Matrix<float, Eigen::Dynamic, Eigen::Dynamic> matrix;\n\n// Placeholders\n\nconst proto::terminal<mpl::int_<0> >::type I1 = {{}};\nconst proto::terminal<mpl::int_<1> >::type I2 = {{}};\nconst proto::terminal<mpl::int_<2> >::type I3 = {{}};\n\n// Grammar\n\ntemplate<class Rule, class Callable = proto::callable>\nstruct External :\n    proto::when<Rule, proto::external_transform> {};\n\nstruct matmul_transform : proto::callable {\n    template<class Sig> struct result;\n\n    template<class This, class Expr, class MatrixExpr1, class MatrixExpr2>\n    struct result<This(Expr, MatrixExpr1, MatrixExpr2)> {\n            typedef typename Eigen::MatrixBase<\n                        typename Eigen::ProductReturnType<\n                            typename boost::remove_const<typename boost::remove_reference<MatrixExpr1>::type>::type,\n                            typename boost::remove_const<typename boost::remove_reference<MatrixExpr2>::type>::type\n                        >::Type \n                    >::PlainObject&\n                    type; //CHANGED - THIS IS THE TYPE THAT IS USED IN THE CODE OF THE TALK\n    };\n\n    template<class Expr, class MatrixExpr1, class MatrixExpr2>\n    typename result<matmul_transform(Expr, MatrixExpr1, MatrixExpr2)>::type\n    operator()(Expr& expr, const MatrixExpr1 &a, const MatrixExpr2 &b) const { //CHANGED - ADDED THE expr PARAMETER\n            expr.value = a*b; \n            return expr.value; \n    }\n};\n\n\nstruct MatmulGrammar;\n\nstruct InputPlaceholder : proto::terminal<proto::_> {};\n\nstruct MatrixMultiplication :\n    proto::multiplies<MatmulGrammar, MatmulGrammar> {};\n\nstruct MatmulGrammar : proto::or_<\n    External<InputPlaceholder>,\n    External<MatrixMultiplication> > {};\n\nstruct matmul_transforms : proto::external_transforms<\n    proto::when<MatrixMultiplication, matmul_transform(proto::_, MatmulGrammar(proto::_left), MatmulGrammar(proto::_right))>, //CHANGED - ADAPTED TO THE NEW SIGNATURE OF matmul_transform\n    proto::when<InputPlaceholder, proto::functional::at(proto::_data, proto::_value)> > {};\n\n// THE FOLLOWING CODE BLOCK IS COPIED FROM https://github.com/barche/eigen-proto/blob/master/eigen_calculator_solution.cpp\n//----------------------------------------------------------------------------------------------\n/// Wraps a given expression, so the value that it represents can be stored inside the expression itself\ntemplate<typename ExprT, typename ValueT>\nstruct stored_result_expression :\n  proto::extends< ExprT, stored_result_expression<ExprT, ValueT> >\n{\n  EIGEN_MAKE_ALIGNED_OPERATOR_NEW\n\n  typedef proto::extends< ExprT, stored_result_expression<ExprT, ValueT> > base_type;\n\n  explicit stored_result_expression(ExprT const &expr = ExprT())\n    : base_type(expr)\n  {\n  }\n\n  /// Temporary storage for the result of the expression\n  mutable ValueT value;\n};\n\nstruct do_wrap_expression : proto::transform< do_wrap_expression >\n{\n  template<typename ExprT, typename StateT, typename DataT>\n  struct impl : proto::transform_impl<ExprT, StateT, DataT>\n  {\n    typedef typename boost::result_of<MatmulGrammar(ExprT, StateT, DataT)>::type result_ref_type; //CHANGED - TO USE YOUR GRAMMAR\n    typedef typename boost::remove_reference<result_ref_type>::type value_type;\n    typedef typename boost::remove_const<typename boost::remove_reference<ExprT>::type>::type expr_val_type;\n    typedef stored_result_expression<expr_val_type, value_type> result_type;\n\n    result_type operator()(typename impl::expr_param expr, typename impl::state_param state, typename impl::data_param data)\n    {\n      return result_type(expr);\n    }\n  };\n};\n\n/// Wrap multiplies expressions so they can store a temporary result\nstruct wrap_expression :\n  proto::or_\n  <\n    proto::terminal<proto::_>,\n    proto::when\n    <\n      proto::multiplies<proto::_, proto::_>,\n      do_wrap_expression(\n        proto::functional::make_multiplies\n        (\n            wrap_expression(proto::_left), wrap_expression(proto::_right)\n        ),\n        proto::_state, //CHANGED - THESE EXTRA PARAMETERS ARE NEEDED TO CALCULATE result_ref_type IN do_wrap_expression\n        proto::_env\n      )\n    >,\n    proto::nary_expr< proto::_, proto::vararg<wrap_expression> >\n  >\n{\n};\n//--------------------------------------------------------------------------------------------------\n\nint main() {\n    matrix mat1(2,2), mat2(2,2), mat3(2,2), result(2,2);\n\n    mat1 << 1, 1, 0, 1;\n    mat2 << 1, 1, 0, 1;\n    mat3 << 1, 1, 0, 1;\n\n    MatmulGrammar mmg;\n    wrap_expression wrap;\n\n    //THIS WORKS:\n     result = mmg( //THIS IS REALLY HORRIBLE, BUT IT WORKS. IT SHOULD PROBABLY BE HIDDEN BEHIND A FUNCTION\n                wrap(\n                    I1 * I2,\n                    mpl::void_(),\n                    ( proto::data = fusion::make_vector(boost::cref(mat1), boost::cref(mat2), boost::cref(mat3)),\n                      proto::transforms = matmul_transforms() )\n                ),\n                mpl::void_(),\n                ( proto::data = fusion::make_vector(boost::cref(mat1), boost::cref(mat2), boost::cref(mat3)),\n                  proto::transforms = matmul_transforms() )\n            );\n\n    std::cout << result << std::endl;\n\n    // THIS DOESN'T CRASH ANYMORE:\n    result = mmg(\n                wrap(\n                    I1 * I2 * I3 * I1 * I2 * I3,\n                    mpl::void_(),\n                    ( proto::data = fusion::make_vector(boost::cref(mat1), boost::cref(mat2), boost::cref(mat3)),\n                      proto::transforms = matmul_transforms() )\n                ),\n                mpl::void_(),\n                ( proto::data = fusion::make_vector(boost::cref(mat1), boost::cref(mat2), boost::cref(mat3)),\n                  proto::transforms = matmul_transforms() )\n            );\n\n    std::cout << result << std::endl;\n\n    return 0;\n}\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Why does the following for-loop utilize all of the cores in my machine in R?\r\n                \r\nI have the following R code with parallelization not explicitly enabled:\n\n```\nmatrix <- matrix(rnorm(1000^2), ncol = 1000)\nvec <- rnorm(1000)\n\nfor (i in 1:10000){\n  a <- sum(matrix%*%vec)\n}\n```\n\n\nWhen I execute the for loop, I notice in my system monitor that all cores are being utilized at 100%. It was my understanding that for loops in R are always serial. I do notice with a single large matrix multiplication that only one core is utilized, so I do not believe that the parallelization is occurring in the matrix multiplication.\n\nThe larger problem here is that I've written an MCMC sampler that needs to be run in serial as a Markov chain, but when I run the sampler, I see that all cores are being utilized. The code above is just a minimum working example. Should I be concerned that the MCMC sampler is not running properly in serial (i.e. as a Markov chain)?\n\nI'm using R 3.5.2 inside of the rocker/tidyverse:3.5.2 Docker container and my local OS is Ubunutu 18.04.\n\nThanks for any help!\n\nHere is my session info:\n\n```\nR version 3.5.2 (2018-12-20)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Debian GNU/Linux 9 (stretch)\n\nMatrix products: default\nBLAS: /usr/lib/openblas-base/libblas.so.3\nLAPACK: /usr/lib/libopenblasp-r0.2.19.so\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8   \n [6] LC_MESSAGES=C              LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n[1] compiler_3.5.2 tools_3.5.2    yaml_2.2.0   \n```\n\n    ", "Answer": "\r\nThanks for all of the helpful comments. Looks like it is that BLAS utilizes multiple threads for matrix multiplication, and by default, it was using all 12.\n\nInterestly, when reducing the number of BLAS threads via ```\nRhpcBLASctl::blas_set_num_threads(1)```\n, the total compute time decreases. See the results below for my machine with 12 logical processors:\n\n```\nRhpcBLASctl::blas_get_num_procs()\nRhpcBLASctl::blas_set_num_threads(12)\n\nmatrix <- matrix(rnorm(1000^2), ncol = 1000)\nvec <- rnorm(1000)\n\nsystem.time(\nfor (i in 1:2000){\n  matrix1 <- matrix + 1\n  a <- sum(matrix1%*%vec)\n}\n)\n\nRhpcBLASctl::blas_set_num_threads(1)\nmatrix <- matrix(rnorm(1000^2), ncol = 1000)\nvec <- rnorm(1000)\nsystem.time(\n  for (i in 1:2000){\n    matrix <- matrix + 1\n    a <- sum(matrix1%*%vec)\n  }\n)\n```\n\n\nYou'll see that it actually runs faster with only one thread (maybe because of data transfer overhead?). For my MCMC sampler, I'll set the number of threads to 1, then make use of the other cores where parallel processing will actually improve compute times (i.e. running multiple chains in parallel).\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Examining multidimensional array passed to a function in gdb\r\n                \r\nI have written code for dynamic programming, matrix chain multiplication algorithm. For this question, I am not concerned with the implementation details of algorithm.\n\nI am trying to debug it using gdb. However, I am having a hard time examining ```\ncost_table```\n 2-D array inside ```\nmatrix_chain_order```\n function.\n\nInside ```\nmatrix_chain_order```\n function, I set a breakpoint and examine the ```\ncost_table```\n 2-D array. I have also used ```\nprintf```\n statements there.\nThe ```\nprintf```\n statements print the correct value of a cell in ```\ncost_table```\n.\n\nI found some revelant information in this SO QA: how to print 2d arry values in gdb.\n\nI did not understand what the answer really explained. But it gave me a direction, so I tried printing ```\ncost_table```\n and its cell values in gdb. (Session below)\n\n\n\nCode:\n\n```\n/* MATRIX-CHAIN-MULTIPLICATION - CLRS 3rd Edition, Chapter 15 */\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <limits.h>\n\n\n#define array_length(arr) (sizeof(arr) == 0 ? 0 : sizeof(arr) / sizeof((arr)[0]));\n\n/* define input sequence to matrix_chain_order function */\nconst int INPUT_SEQUENCE[] = {4, 10, 3, 12, 20};\n\n/* DEFINE m[i, j]:\n * Let m[i, j] be the minimum number of scalar multiplications needed to compute\n * matrix A_suffix_i..j; for the full problem, the lowest cost way to compute A_suffix_1..n\n * would thus be m[1, n].\n */\n/* The function computes the rows from bottom to top and from left to right within\n * each row.\n * It computes each entry m[i, j] using products p_suffix_i-1 * p_suffix_k * p_suffix_j\n * for k = i, i + 1, ...., j - 1 and all entries southwest and southeast from m[i, j].\n *\n * This prodedure assumes that matrix A_suffix_i has dimensions p_suffix_i-1 * p_suffix_i\n * for i = 1, 2, ...., n.\n * Its input is a sequence p = <p_suffix_0, p_suffix_1, ...., p_suffix_n>, where\n * p.length = n + 1.\n *\n * The procedure uses an auxiliary table m[1 ..n, 1 ..n] for storing the m[i, j] costs,\n * and another auxiliary table s[1 ..n - 1, 2 ..] that records which index of k achieved\n * the optimal cost in computing m[i, j].\n */\nvoid matrix_chain_order (int ct_rows, int ct_cols, int cost_table[ct_rows][ct_cols], int kit_rows, int kit_cols, int k_idx_table[kit_rows][kit_cols]);\n\nint main ()\n{\n  int sequence_len = array_length(INPUT_SEQUENCE);\n\n  /* initialize table (2-D array), m[1 ..n, 1..n] */\n  int m = 0, n = 0;\n  int cost_table[sequence_len][sequence_len];\n  for (m = 0; m < sequence_len; m++) {\n    for (n = 0; n < sequence_len; n++) {\n      /* m[i, i] = 0, for i = 1, 2, ...., n (the minimum costs for chains of length 1) */\n      if (n == m) {\n        cost_table[m][n] = 0;\n      } else {\n        cost_table[m][n] = INT_MAX;\n      }\n    }\n  }\n\n  /* initialize table (2-D array), s[1 ..n - 1, 2..n] */\n  int o = 0, p = 0;\n  int k_idx_table[sequence_len - 1][sequence_len - 1];\n  for (o = 0; o < sequence_len - 1; o++) {\n    for (p = 0; p < sequence_len - 1; p++) {\n      k_idx_table[o][p] = -1;\n    }\n  }\n\n  matrix_chain_order(sequence_len, sequence_len, cost_table, sequence_len, sequence_len - 1, k_idx_table);\n\n  return 0;\n}\n\n/* NOTE on array passed to the function. */\n/* When you pass an array to a function, it decays into a pointer to the first element,\n * at which point knowledge of its size is lost. You need to work it out before decay \n * and pass that information with the array.\n */\nvoid matrix_chain_order(int ct_rows, int ct_cols, int cost_table[ct_rows][ct_cols], int kit_rows, int kit_cols, int k_idx_table[kit_rows][kit_cols])\n{\n  int sequence_len = array_length(INPUT_SEQUENCE);\n\n  /* use recurrence,\n   *\n   * min[i, j] = 0 , if  i = j\n   * min[i, j] = min {m[i, k] + m[k + 1, j] + p_suffix_i-1 * p_suffix_k * p_suffix_j , if i < j\n   *\n   * to compute m[i, i + 1] for i = 1, 2, ...., n - 1 (the minimum costs of chains of length l = 2)\n   * during the first execution of the for loop.\n   * The second time through the loop, it computes m[i, i + 2] for i = 1, 2, ...., n - 2\n   * (the minimum costs for chains of length l = 3), and so forth.\n   */\n  int chain_len = 0, i = 1, j = 0, k = 0, cost = INT_MAX;\n  for (chain_len = 2; chain_len <= sequence_len; chain_len++) {\n    for (i = 1; i <= sequence_len - chain_len + 1; i++) {\n      j = i + chain_len - 1;\n\n      for (k = i; k <= j - 1; k++) {\n        /* at each step, the m[i, j] cost computed depends only on table entries m[i, k] and m[k + 1, j]\n         * already computed\n         */\n        printf(\"Printed cost_table[%d][%d] : %d\\n\", i, k, cost_table[i][k]);\n        printf(\"Printed cost_table[%d][%d] : %d\\n\", (k+1), j, cost_table[k+1][j]);\n        cost = cost_table[i][k] + cost_table[k + 1][j] + INPUT_SEQUENCE[i - 1] * INPUT_SEQUENCE[k] * INPUT_SEQUENCE[j];\n\n        if (cost < cost_table[i][j]) {\n          cost_table[i][j] = cost;\n          k_idx_table[i][j] = k;\n        }\n      }\n    }\n  }\n}\n```\n\n\ngdb session: \n\n```\n(gdb) p ((int (*) [5][5]) cost_table)[1][1]\n$3 = {0, 0, 65280, 0, -8944}\n(gdb) p (int [][5]) *cost_table \n$4 = 0x7fffffffdca0\n(gdb) p (int [5][5]) *cost_table \nInvalid cast.\n(gdb) p (int [][5]) **cost_table \nwarning: array element type size does not divide object size in cast\n$5 = 0x7fffffffdca0\n(gdb) p (int [][5]) *cost_table \n$6 = 0x7fffffffdca0\n(gdb) p (int [][5]) cost_table \nwarning: array element type size does not divide object size in cast\n$7 = 0x7fffffffdbe0\n(gdb) p cost_table@5@5\n$16 = {{0x7fffffffdca0, 0x500000005, 0x26, 0x100000002, 0x500000001}, {0x7fffffff00000002, 0x4, 0x3, 0x1f7ffe728, 0x7fffffffdca0}, {0x0, 0x5, 0x7fffffffddf0, 0x400952 <main+892>, 0xffffffffffffffff}, {\n    0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff}, {0xffffffffffffffff, 0xffffffffffffffff, 0x0, 0x7fffffffde10, 0x7fffffff00000000}}\n(gdb) p *cost_table@5@5\n$17 = {{{0, 2147483647, 2147483647, 2147483647, 2147483647}, {2147483647, 0, 2147483647, 2147483647, 2147483647}, {2147483647, 2147483647, 0, 2147483647, 2147483647}, {2147483647, 2147483647, \n      2147483647, 0, 2147483647}, {2147483647, 2147483647, 2147483647, 2147483647, 0}}, {{0, -140389360, 32767, 4, 0}, {0, 0, 65280, 0, -8944}, {32767, 4, 0, 0, 0}, {4, 0, 0, 0, 4}, {0, 0, 0, 4, 0}}, {{\n      0, 0, 0, 5, 5}, {4, 4, 5, 4, 0}, {4, 0, -9056, 32767, 3}, {0, 3, 0, -9136, 32767}, {1781326592, 1051810453, 0, 0, 0}}, {{0, 4195552, 0, -8496, 32767}, {0, 0, 0, 0, 4197632}, {0, -140322768, 32767, \n      0, 0}, {-8488, 32767, 0, 1, 4195798}, {0, 0, 0, 1661416990, 1731120}}, {{4195552, 0, -8496, 32767, 0}, {0, 0, 0, -989383138, -1731249}, {-690538978, -1735179, 0, 0, 0}, {0, 0, 0, 1, 0}, {4195798, \n      0, 4197744, 0, 0}}}\n(gdb) p **cost_table@5@5\n$18 = {{0, 2147483647, 2147483647, 2147483647, 2147483647}, {2147483647, 0, 2147483647, 2147483647, 2147483647}, {2147483647, 2147483647, 0, 2147483647, 2147483647}, {2147483647, 2147483647, 2147483647, \n    0, 2147483647}, {2147483647, 2147483647, 2147483647, 2147483647, 0}}\n(gdb) p cost_table[i][k] \nCannot perform pointer math on incomplete types, try casting to a known type, or void *.\n```\n\n\n\n\nI don't get how the commands that I have used in gdb session result in their respective outputs.\n\n\nWhy am I unable to use ```\np cost_table[i][k]```\n directly in gdb,\nwhereas the ```\nprintf```\n statements print the result in execution of\ncode?\n```\np ((int (*) [5][5]) cost_table)[1][1]```\n: What happens if I change\nvalue of numbers in this command or if I do something like\n```\np ((int(*) [][5]) cost_table)[1][1]```\n?\nWhy is the output of ```\np *cost_table@5@5```\n and ```\np **cost_table@5@5```\n so\ndifferent?\n\n\nMy requirement is to be able to examine the ```\ncost_table```\n and its cells in gdb. \n\nAny other suggestions is welcomed.\n    ", "Answer": "\r\nJust ask gbd for it :)\n\n```\nBreakpoint 2, matrix_chain_order (ct_rows=5, ct_cols=5, cost_table=0x7fffffffdac0, kit_rows=5, kit_cols=4, k_idx_table=0x7fffffffda80) at delme.c:96\n96              printf(\"Printed cost_table[%d][%d] : %d\\n\", (k+1), j, cost_table[k+1][j]);\n(gdb) ptype cost_table\ntype = int (*)[5]\n(gdb) p ((int (*) [5])cost_table)[i][j]\n$12 = 2147483647\n```\n\n\nYou may also go up one frame ('up' in gdb) and print directly ```\ncost_table[idx1][idx2]```\n but it is probably less user friendly to debug in the loop...\n\nthe type gdb gives (int(*)[5]) stand for pointer to array 5 of int (see \nhttps://cdecl.org/?q=int+%28*t%29%5B5%5D if you want to experience the syntax.)\n\nThe array type decays that's why only a pointer remains; you may have a look to Manipulate multidimensional array in a function for more explanation in C.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Terminal probabilities of a probability matrix Numpy\r\n                \r\nI have a matrix m that represents the probabilities transitioning from states to states.\nE.g. for the sample below I will always get stuck in states 1,3,4, and state 2 I will randomly transition to one of the 4 states.\n```\nimport numpy as np\nm = np.eye(4)\nm[1] = 0.25\nprint(m)\n```\n\n```\n[[1.   0.   0.   0.  ]\n\n [0.25 0.25 0.25 0.25]\n\n [0.   0.   1.   0.  ]\n\n [0.   0.   0.   1.  ]]\n```\n\nHow do I find a matrix representing the eventual end state following infinite transitions?\nE.g. if I do this, I get intuitive result of states 1,3,4 --> 100% sticking in 1,3,4 but state 2 --> 1/3 chance ending up in all the others. Since all cases from state 2 eventually allocated evenly between 1,3,4 through multiple transitions.\n```\nt = m\nfor _ in range(100_000):\n    t = t @ t\nprint(t)\n```\n\n```\n[[1.         0.         0.         0.        ]\n\n [0.33333333 0.         0.33333333 0.33333333]\n\n [0.         0.         1.         0.        ]\n\n [0.         0.         0.         1.        ]]\n```\n\nHow can I calculate this without using repeated multiplications? I thought it corresponds to the eigenvector/eigenvalues of the matrix, but I get something very different when I calculate this.\n```\nnp.linalg.eig(m)\n```\n\n```\n[[0.        , 0.9486833 , 0.        , 0.        ],\n\n[1.        , 0.31622777, 0.31622777, 0.31622777],\n\n[0.        , 0.        , 0.9486833 , 0.        ],\n\n[0.        , 0.        , 0.        , 0.9486833 ]]\n```\n\nIs there a methodology to calculate this using numpy? I need it to work for an arbitrary matrix, but there will be a known list of terminal states and positive probability of reaching these from all other states.\nAt the moment I am thinking of using the repeated multiplication method but it feels suboptimal and something there should be a function/trick that can calculate without looping.\nI was reading this but didn't fully understand what the methodology is and how to implement it.\nhttps://math.dartmouth.edu/archive/m20x06/public_html/Lecture14.pdf\nI also looked in this question. People seemed to give some tips for hand-solving but not a general algorithm:\nhttps://math.stackexchange.com/questions/2003258/calculating-the-probability-of-reaching-each-absorbing-state-in-markov-chain\n    ", "Answer": "\r\nMy friend pointed out the following trick.\nEigendecomposition means we can write the original matrix as\nV x D x V^-1\nWhere D is a diagonal matrix with the eigenvalues, and V is the eigenvector.\nIf we multiply this by itself infinite times, it is\nV x D^inf x V^-1\nWhich we can calculate in numpy using the below.\n```\nd, v = np.linalg.eig(m)\nv @ np.diag(d >= 1).astype(int) @ np.linalg.inv(v)\n```\n\nSince if the diagonal values are < 1 they will tend to 0 as we multiply (assuming we have a matrix with valid probabilities, and all states can reach the terminal states).\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Compute the equilibrium probabilities of the Markov chain using Jacobi Iteration in Python [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        Jacobi iteration to Gauss-Seidel\r\n                            \r\n                                (2 answers)\r\n                            \r\n                    \r\n                Closed 2 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI am trying to compute a function that calculates the equilibrium probabilities of a Markov chain.\nFor this problem, is have already got my transition matrix.\nNow I am trying to define a function called Jacobi but confused about the most effective way to do so. Any suggestions on how to do this?\nSo far I have tried setting it us like a system of equations and solving x=a^(-1)*b but fail to implement it correctly due to the transition matrix being singular.\nI know I need to multiple the transition matrix by a variable matrix to get 7 separate equations. Then I need to add the equation x0 + x1 + x2 + x3 + x4 + x5 + x6 = 1. After I have all 8 equations I can solve for x0 through x6 to get my equilibrium probabilities. Do you know how I can implement this process in python code?\n    ", "Answer": "\r\nI'm not sure the Jacobi method works for a Markov transition matrix. There are other, easier techniques for finding the stationary distribution though. First by solving the system of equations like you described:\n```\nimport numpy as np\n\n\n>>> M = np.array([[0.084, 0.1008, 0.168, 0.224, 0.224, 0.1494, 0.0498], \n                  [0.084, 0.1008, 0.168, 0.224, 0.224, 0.1494, 0.0498], \n                  [0.084, 0.1008, 0.168, 0.224, 0.224, 0.1494, 0.0498], \n                  [0.5768, 0.224, 0.1494, 0.0498, 0.0, 0.0, 0.0], \n                  [0.3528, 0.224, 0.224, 0.1494, 0.0498, 0.0, 0.0], \n                  [0.1848, 0.168, 0.224, 0.224, 0.1494, 0.0498, 0.0], \n                  [0.084, 0.1008, 0.168, 0.224, 0.224, 0.1494, 0.0498]])\n>>>\n>>> I = np.eye(len(M)) # identity matrix\n>>>\n>>> A = M.T - I  # rearrange each \"equation\" in the system\n>>>\n>>> A = np.vstack([A, np.ones((1, len(A)))]) # add row of ones\n>>>\n>>> b = np.zeros(len(A)) # prepare solution vector\n>>> b[-1] = 1.0 # add a one to the last entry\n>>>\n>>> np.linalg.solve(A.T @ A, A.T @ b) # solve the normal equation\narray([0.22288974, 0.14776044, 0.1781388 , 0.181211  , 0.1504296 ,\n       0.09080838, 0.02876204])\n```\n\nYou can also repeatedly multiply ```\nM```\n by itself until it converges:\n```\n>>> np.linalg.matrix_power(M, 25)[0]\narray([0.22288974, 0.14776044, 0.1781388 , 0.181211  , 0.1504296 ,\n       0.09080838, 0.02876204])\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How to multiply a 4x4 Matrix with a vector-array of arbitrary length?\r\n                \r\nWhen writing a specific scene in webgl, the usual procedure of transforming an object would be to define the original vertex position data and pass it to the vertex shader, where the vertices are multiplied with matrices, that hold the informations about perspective, translations, rotations and scale, so that the corresponding vertex shader code - for example - would look like this:\n\n```\ngl_Position = projectionMatrix * modelviewMatrix * vec4(vertexPosition, 1.0);\n```\n\n\nThe modelviewMatrix itself is then the result of the multiplication of the viewMatrix with the modelMatrix, which again are the results of successive matrix manipulations to translate, rotate and scale.\n\nWhat I'd like to know now is, how this last link in the chain of multiplications works - the multiplication of a mat4 with a vector array of arbitrary length.\n\n```\nsomeMatrix * vec4(vertexPosition, 1.0);\n```\n\n\nThat is because I'm writing on a webgl editor and I want to be able to save the vertex position data of the created and transformed 3D-objects without the need of adding information about matrix transformations but as raw position data, simply as {x, y, z, x, y, z, x, y, z, etc.}, just like the original array of vertices.\n\nAs a basic example, let's say we have the following vertices for a simple triangle:\n\n```\nvar vertices = [0.0, 1.0, 0.0,  -1.0, -1.0, 0.0,  1.0, -1.0, 0.0];\n```\n\n\nThen I create a mat4 and translate it by ```\n[2, 0, 0]```\n.\n\nThe function I need would then take this translated mat4 and the vertices array as parameters, would multiply both and return an array of translated vertices like:\n\n```\nvar translatedVertices = [2.0, 1.0, 0.0,  1.0, -1.0, 0.0,  3.0, -1.0, 0.0];\n```\n\n\nIt seems obvious, that for multiplying a 4x4 matrix with a vector array, there has to be added a fourth value to it, so the first step should be to split the original vec3 array and insert for each triple of values an additional ```\n1.0```\n, to make it a vec4 array, ```\n[x, y, z] --> [x, y, z, 1]```\n, but apart from that, I have absolutely no idea how this JavaScript function should look like.\n    ", "Answer": "\r\nWhen you say\n\n```\nsomeMatrix * vec4(vertexPosition, 1.0);\n```\n\n\n```\nsomeMatrix```\n is a 4x4 matrix and ```\nvertexPosition```\n is ALWAYS a 3x1 matrix that is converted to a 4x1 matrix with the addition of the 1.0. So a 4x4 matrix multiplied by a 4x1 matrix will produce again a valid 4x1 matrix (i.e. the ```\ngl_Position```\n). Note that a 4x1 matrix is a ```\nvec4```\n.\n\nSo you never multiply with a vector of \"arbitrary\" length. When you pass the data down (i.e. your ```\nvertices```\n variable) the system breaks them down into triplets, adds the 1.0 and does the 4x4 by 4x1 multiplication. \n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Plot how the probability P(Xn=s) changes as a function of time?\r\n                \r\nEntire problem: \nWe have a Markov chain model with with 5 states: s, t, m, f, r\n\nTPM follows: \n\n```\n      P <- matrix(c(.84,.03,.01,.03,.03,\n                    .11,.80,.15,.19,.09,\n                    .01,.04,.70,.02,.05,\n                    .04,.10,.07,.75,.00,\n                    .00,.03,.07,.01,.83),\n                  nrow=5\n\n                   )\n```\n\n\nWith matrix multiplication, the limiting distribution comes out to: \n\n(0.1478365,0.4149259,0.09555939,0.2163813,0.1252968)\n\nI am attempting to plot how P(Xn = s) changes as a function of time.\n\nGiven the initial distribution is P(X0 = i) = 1/5 \ni.e:\n\n```\n                  s   t   m   f   r  \n           α = ( 1/5 1/5 1/5 1/5 1/5 )\n```\n\n\nI need to plot P(Xn = s) (on the y-axis) against n = 0, 1, 2, 3, 4, 5 (x-axis).\n    ", "Answer": "\r\nThe ```\nexpm```\n package has a matrix-power function, ```\n%^%```\n. I first checked the 10th state, but it has not reach stability so I went with the 20th state\n\nEach successive state is in the progression ```\na %*% P, a %*% (P%^%2), ...., a %*% (P%^%20)```\n\n\n```\nlibrary(expm)\n\n#Attaching package: ‘expm’\n\n#The following object is masked from ‘package:Matrix’:\n\n #   expm\n```\n\n\nSo I guess I had it already available, no matter.\n\n```\nevolve <- sapply(1:20, function(n){ a%*% (P %^% n)})  # 5 x 20 matrix\npng(); matplot( 1:20, t(evolve) );dev.off()  # matplot needs data in rows\n```\n\n\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Simulate Steps Through a Markov Chain\r\n                \r\nI am trying to simulate a step through a Markov chain with the intent to loop through the procedure multiple times until a condition is met. (i.e., find out how many steps it takes, on average, to reach a specific state).\nIn this case, a state can only go one way. E.g., State 4 can transition forward to State 5, but cannot transition backward to State 3. This means the left-lower half of the transition matrix is set to zero. This is also why the method below puts arbitrarily large values in the 'prior' states. I attempt to find the correct new state by examining which probability in the specified row of the transition matrix is closest to a random number.\n```\nget_new_state <- function(current_state, trans_matrix)\n{\n  # generate a random number between 0-1 to compare to the transition matrix probabilities\n  rand <- runif(1)\n  \n  # transition to where the \n  # random number falls within the transition matrix\n  row <- current_state # initial condition determines the row of the trans_matrix\n  col = current_state # start in the column \n  # loop thru all columns and find the correct state\n  potential_states <- rep(0, each=ncol(trans_matrix)) # holds the value of the potential state it transitions to\n\n  # in this case, we can't transition to a previous state so we set the previous state values arbitrarily high \n  # so they don't get selected in the which.min() function later\n  potential_states[1:col] <- 999\n  \n  for(k in row:ncol(trans_matrix)) # loop thru non-zero matrix values\n  {\n    if(trans_matrix[row,k] > rand)\n    {\n      potential_states[k] <- trans_matrix[row,k] / rand\n      potential_states[k] <- 1 - potential_states[k]\n    }\n  }\n  \n  # new state is equal to the index of the lowest value\n  # lowest value = closest to random number\n  new_state = which.min(potential_states)\n  return(as.numeric(new_state))\n}\n```\n\nI'm not sure if this approach is reasonable. I'm assuming there is a better way to simulate without the kluge that puts arbitrarily large values in ```\npotential_states[]```\n.\n    ", "Answer": "\r\nWould something like this work better (it is a one-line Markov transition):\n```\n> new_state <- sample(1:number_states, size=1, \n\n             prob=transition_matrix[old_state,])\n```\n\nand just put this in a (for instance) while() loop with a counter.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "change values in dataframe by lookup matrix/df\r\n                \r\nI have a dataframe:\n\n```\ndf <- data.frame(rank = c('R1', 'R2', 'R3' ), cat = c(1, 2, 2))\n```\n\n\n\n```\nrank cat\n1   R1   1\n2   R2   2\n3   R3   2\n```\n\n\n\nand then a mapping table, which I store as a matrix (but it could be another format too)\n\n```\nmapping <- matrix(c('A', 'A', 'A', 'C', 'B', 'D'), nrow=3, ncol=2) \nrownames(mapping) <- c('R1', 'R2', 'R3')\ncolnames(mapping) <- c(1, 2)\n\n   1   2  \nR1 \"A\" \"C\"\nR2 \"A\" \"B\"\nR3 \"A\" \"D\"\n```\n\n\nso, I want the df to refer to the mapping with an output, e.g. \n\n```\nrank == R1 and cat == 1: out == A\n```\n\n\nUsually I spread the row-column pairs and merge this to the original df, but in this case the mapping table is quite large (dim = 8x8) in reality. So, I am unable to think of a solution. I also tried chaining multiple if-else (small sample below), \n\n```\nif (df$rank == 'R1' & df$cat == 1) {\n  df$out<- 'A'\n  } else if(df$rank == 'R2' & df$cat == 2) {\n    df$out <- 'C'\n  } else {\n      df$out<- 'X'\n      }\n```\n\n\nbut this becomes also too complex (and gives errors).\n\nHow do I achieve replacing values in the df from a mapping table?\n    ", "Answer": "\r\nAn option would be to ```\nmelt```\n the ```\nmatrix```\n and do a join\n\n```\nlibrary(dplyr)\nlibrary(reshape2)\nleft_join(df, melt(mapping), by = c(\"rank\" = \"Var1\", \"cat\" = \"Var2\"))\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How to print values in memoization method-Dynamic pragraming\r\n                \r\nI know for a problem that can be solved using DP, can be solved by either tabulation(bottom-up) approach or memoization(top-down) approach. personally i find memoization is easy and even efficient approach(analysis required just to get recursive formula,once recursive formula is obtained, a brute-force recursive method can easily be converted to store sub-problem's result and reuse it.) The only problem that i am facing in this approach is, i am not able to construct actual result from the table which i filled on demand.\nFor example, in Matrix Product Parenthesization problem ( to decide in which order to perform the multiplications on Matrices so that cost of multiplication is minimum) i am able to calculate minimum cost not not able to generate order in algo.\n\nFor example, suppose A is a 10 × 30 matrix, B is a 30 × 5 matrix, and C is a 5 × 60 matrix. Then,\n\n```\n(AB)C = (10×30×5) + (10×5×60) = 1500 + 3000 = 4500 operations\nA(BC) = (30×5×60) + (10×30×60) = 9000 + 18000 = 27000 operations.\n```\n\n\nhere  i am able to get min-cost as 27000 but unable to get order which is A(BC).\n\nI used this. Suppose F[i, j] represents least number of multiplication needed to multiply Ai.....Aj and an array p[] is given which represents the chain of matrices such that the ith matrix Ai is of dimension p[i-1] x p[i]. So\n\n\n\n```\n                    0                 if i=j\n     F[i,j]=\n                   min(F[i,k] + F[k+1,j] +P_i-1 * P_k * P_j   where k∈[i,j)\n```\n\n\n\n Below is the implementation that i have created.\n\n```\n#include<stdio.h>\n#include<limits.h>\n#include<string.h>\n#define MAX 4\nint lookup[MAX][MAX];\n\nint MatrixChainOrder(int p[], int i, int j)\n{\n    if(i==j) return 0;\n    int min = INT_MAX;\n    int k, count;\n\n    if(lookup[i][j]==0){\n        // recursively calculate count of multiplcations and return the minimum count\n        for (k = i; k<j; k++) {\n            int gmin=0;\n            if(lookup[i][k]==0)\n                lookup[i][k]=MatrixChainOrder(p, i, k);\n\n            if(lookup[k+1][j]==0)\n                lookup[k+1][j]=MatrixChainOrder(p, k+1, j);\n\n            count = lookup[i][k] + lookup[k+1][j] + p[i-1]*p[k]*p[j];\n            if (count < min){\n                min = count;\n```\n\n\n\n```\n              printf(\"\\n****%d  \",k); // i think something has be done here to represent the correct answer ((AB)C)D  where first mat is represented by  A second by B and so on.\n```\n\n\n\n```\n            }\n\n        }\n        lookup[i][j] = min;\n    }\n\n    return lookup[i][j];\n}\n\n// Driver program to test above function\nint main()\n{\n    int arr[] = {2,3,6,4,5};\n    int n = sizeof(arr)/sizeof(arr[0]);\n\n    memset(lookup, 0, sizeof(lookup));\n    int width =10;\n\n    printf(\"Minimum number of multiplications is %d \", MatrixChainOrder(arr, 1, n-1));\n    printf(\"\\n  ---->\");\n    for(int l=0;l<MAX;++l)\n    printf(\" %*d \",width,l);\n    printf(\"\\n\");\n    for(int z=0;z<MAX;z++){\n        printf(\"\\n  %d--->\",z);\n    for(int x=0;x<MAX;x++)\n    printf(\" %*d \",width,lookup[z][x]);\n    }\n\n    return 0;\n}\n```\n\n\nI know using tabulation approach printing the solution is much easy but i want to  do it in memoization technique.\n\n\nThanks.\n    ", "Answer": "\r\nYour code correctly computes the minimum number of multiplications, but you're struggling to display the optimal chain of matrix multiplications.\n\nThere's two possibilities:\n\n\nWhen you compute the table, you can store the best index found in another memoization array.\nYou can recompute the optimal splitting points from the results in the memoization array.\n\n\nThe first would involve creating the split points in a separate array:\n\n```\nint lookup_splits[MAX][MAX];\n```\n\n\nAnd then updating it inside your ```\nMatrixChainOrder```\n function:\n\n```\n    ...\n    if (count < min) {\n        min = count;\n        lookup_splits[i][j] = k;   \n    }\n```\n\n\nYou can then generate the multiplication chain recursively like this:\n\n```\nvoid print_mult_chain(int i, int j) {\n    if (i == j) {\n        putchar('A' + i - 1);\n        return;\n    }\n    putchar('(');\n    print_mult_chain(i, lookup_splits[i][j]);\n    print_mult_chain(lookup_splits[i][j] + 1, j);\n    putchar(')');\n}\n```\n\n\nYou can call the function with ```\nprint_mult_chain(1, n - 1)```\n from ```\nmain```\n.\n\nThe second possibility is that you don't cache ```\nlookup_splits```\n and recompute it as necessary.\n\n```\nint get_lookup_splits(int p[], int i, int j) {\n    int best = INT_MAX;\n    int k_best;\n    for (int k = i; k < j; k++) {\n        int count = lookup[i][k] + lookup[k+1][j] + p[i-1]*p[k]*p[j];\n        if (count < best) {\n            best = count;\n            k_best = k;\n        }\n    }\n    return k;\n}\n```\n\n\nThis is essentially the same computation you did inside ```\nMatrixChainOrder```\n, so if you go with this solution you should factor the code appropriately to avoid having two copies.\n\nWith this function, you can adapt ```\nprint_mult_chain```\n above to use it rather than the ```\nlookup_splits```\n array. (You'll need to pass the ```\np```\n array in).\n\n[None of this code is tested, so you may need to edit the answer to fix bugs].\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Maximizing arithmetic expression\r\n                \r\nI want to maximize the expression ```\n5-8+7*4-8+9```\n\nand answer is ```\n200```\n after splitting this way\n```\n(5 − ((8 + 7) × (4 − (8 + 9))))```\n.\nIt can be solved by using ```\nMatrix-chain multiplication```\n algorithm.\nIt gives correct answer if expression has only '+' and '*' operator\n```\n Let's take expression 5+2*4\n     1 2 3\n   1 5 7 28\n   2 - 2 8\n   3 - - 4\n```\n\nIt's a 3X3 Matrix in which (1,1) is 5 ,(2,2) is 2 and (3,3) is 4\nand if i want to know M[1][2] or M[1][3] then\n\nM[1][2] = M[1][1] o M[2][2]\nM[1][3] = max(M[1][1] o M[2][3],M[1][2] o M[3][3])\n\ncan someone help me to find the right method in case of '-' operator.\n    ", "Answer": "\r\nNot sure whether it can be solved with your algorithm, but here is how I would have solved it.\n\nAssume you have to simplify some expression: ```\na # b # c # d # e```\n, where # is some operation (# can be different). I would approach it with recursion (and memoization). On the first step of the recursion I will try to insert parenthesis at every possible position and to calculate expression after this expression:\n\n\n```\n(a # b) # c # d # e```\n = ```\nX # c # d # e```\n\n```\na # (b # c) # d # e```\n = ```\na # Y # d # e```\n\n```\na # b # (c # d) # e```\n = ```\na # b # Z # e```\n\n```\na # b # c # (d # e)```\n = ```\na # b # c # V```\n\n\n\nSo you basically just decreased 5 operator expression to a bunch of 4 operator expressions. Memoization will be helpful if 2 expression are the same. You finish your recursion when there is just one number (in this case you compares it with maximum and update maximum).\n\nNote that for your 5 operator expression you do not even need memoization.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "'list' object has no attribute 'matmul'\r\n                \r\nI have the code below to compute Markov chain iterations. Having two matrices: the current state matrix and transitional matrix; when stating the number of iterations (multiplications between the two matrices) the code should save the result of the state matrix after one iteration for the next iteration, and so on. When compiling the code, there is an error:\n\n\n  AttributeError: 'list' object has no attribute 'matmul'.\n\n\nI'm working with NumPy version 1.17. How can I solve it? \n\n```\nimport numpy as np\n\ntransitionalMatrix = ([0.42, 0.16, 0.36, 0.02 ],[0.05, 0.43, 0.04, 0.11 ], [0.24, 0.16, 0.51 , 0.04 ], [0.01, 0.31, 0.01, 0.59 ]) \nstateMatrix = ([0.20461531, 0.26104588, 0.19799357, 0.14561973]) \nmaxIterations = 6\n\nres = [stateMatrix]\nfor iteration in range(1, maxIterations):\n prev = res[iteration - 1]\n res.append(prev.matmul(transitionalMatrix))\n```\n\n    ", "Answer": "\r\nAs the error says, you are trying to apply matmul to a list, which doesn't have any such attribute. Assuming that what you want to use is ```\nnp.matmul()```\n, what you should be doing is:\n\n```\nnp.matmul(prev, transitionalMatrix))\n```\n\n\nHowever, as Prune pointed out, the lack of a minimal, reproducible example makes it impossible to help you any further.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "First Order Markov Transition Matrix for Person Period Data\r\n                \r\nUsing time series data for a single person, I can calculate a first order probability transition matrix i.e.library(markovchain)and calculate its density i.e.library(statnet)\nThis code works:\n```\nds = matrix(c(1,1,2,1,2,4,1,3,6,1,4,8),ncol=3,byrow=TRUE) #create person period data for a single person\ncolnames(ds) = c(\"Id\", \"Time\", \"Evt\")\nds = as.data.frame(ds)\nmc = markovchainFit(ds$Evt, name = \"mc\")$estimate #calculate markovchain\nam = mc@transitionMatrix #remove slot from S4 object\nem = network(am, matrix.type=\"adjacency\", directed=TRUE, Weighted = TRUE, loops = FALSE) #make network object\ngden(em)#calculate density of network, etc\n```\n\nBut I am having trouble making it work for a data with multiple ID's using tapply. This code doesn't work after line 4, but it is how a solution looks in my head:\n```\nds2 = matrix(c(1,1,2,1,2,4,1,3,6,1,4,8,2,1,3,2,2,5,2,3,7,2,4,9),ncol=3,byrow=TRUE) #create person period data for two people\ncolnames(ds2) = c(\"Id\", \"Time\", \"Evt\")\nds2 = as.data.frame(ds2)\nmc2 = tapply(ds2$Evt, ds2$Id, markovchainFit) #it works to here and I am STUCK for days *see below\nam2 = mc@transitionMatrix, #can't figure how to integrate these steps from above\nem2 = network(am, matrix.type=\"adjacency\", directed=TRUE, Weighted = TRUE, loops = FALSE) \ngden(em2)\n```\n\n*For each person in the list I can't figure out:\n\nhow to name the markov chain S4 object\nhow to remove the transition matrix slot from the S4 object\nhow to pass additional functions after markovchainFit\n\nDoes anybody have any suggestions about how to loop my analysis for a single person through an ID vector? It would be very much appreciated.\n    ", "Answer": "\r\nHow about something like below.  In the code below, I make a function that does all of the interim work and returns the results of ```\ngden()```\n on the appropriate object.\n```\n\nds2 = matrix(c(1,1,2,1,2,4,1,3,6,1,4,8,2,1,3,2,2,5,2,3,7,2,4,9),ncol=3,byrow=TRUE) #create person period data for two people\ncolnames(ds2) = c(\"Id\", \"Time\", \"Evt\")\nds2 = as.data.frame(ds2)\nmcfun <- function(x){\n  mc <- markovchainFit(x, name=\"mc\")$estimate\n  am <- mc@transitionMatrix\n  em <- network(am, matrix.type=\"adjacency\", directed=TRUE, Weighted = TRUE, loops = FALSE) #make network object\n  gden(em)#calculate density of network, etc\n  \n}\ntapply(ds2$Evt, ds2$Id, mcfun)\n#    1    2 \n# 0.25 0.25 \n\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Going from optimal substructure to the actual algorithm\r\n                \r\nAs I gain an understanding of dynamic programming, I am finding it easier and easier to develop a notion of optimal substructure in a given situation. For example, with finding the optimal ordering to multiply a matrix chain, I understand that (sorry to be verbose; it helps me out) the minimum number of multiplications needed to compute Ai * Ai+1 * ... * Aj can be found by finding the split/parenetheses placement point k between i and j that minimizes the sum of the multiplications needed for Ai*...Ak and Ak+1...*Aj, plus the cost that comes with the actual dimensions. In other words, M(i,j) = mink(M(i,k) + M(k+1,j) + di-1dkdj). \n\nLikewise, in finding the longest palindromic substring of a string, the optimal substructure is that the length l[i,j] of a maximum length palindrome between indices i and j and the input array is either 2 + l[i+1, j-1], when the elements at i and j are the same and can thus be added, or otherwise the maximum of l[i+1, j], l[i, j-1] (correct me if I mix anything up...) \n\nBut how, in any situation, do I translate this into an algorithm to find the length of an ideal sequence such as the above or even its contents? Do I basically just run loops to tabulate everything, and then essentially 'choose' what is needed from the table? With the matrix chain, that seems to be exactly what to do, but for the palindrome, I'm a little confused on how to construct the loops. \n\nThanks! \n    ", "Answer": "\r\n\n  Do I basically just run loops to tabulate everything, and then essentially 'choose' what is needed from the table?\n\n\nIn short, yes. Dynamic programming relies on two things: making the original problem smaller (which is well described in your question) and base cases: those (almost always small) situations where the solution is obvious, and no longer requires dividing the problem into sub-problems. For example, in your matrix multiplication example, once the sub-problem is reduced to 2 matrices, you no longer have a choice: you have to multiply them as is. In your palindrome example, I would choose a base case of a substring of length 1, which is obviously a palindrome.\n\nTherefore, once you create the memoization array / matrix etc, what you typically do is set the base case values in that array, and let the algorithm run. The end conditions are usually either when you reach the correct point in the array, or when there is nothing left to calculate (at which point you 'choose' what you need from the array / matrix etc)\n\nI hope that's concrete enough to be useful.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Multiplying the probability matrix, incorrect values on a large number of iterations\r\n                \r\nI have the next code, which multiplies the probability matrix ```\np```\n the certain number of times. For the first 50 iterations everything is ok, the sum of probabilities in each row is equal to ```\n1```\n, but then I recieve the ```\nsum > 1```\n and approximately on the 70th iteration I recieve infinity values. And I do not understand why.\nThe ```\nsum```\n of probabilities in each row must be equal to ```\n1```\n. This is the classic Markov's chain model. And regardless of num of multiplications you must receive the ```\nsum = 1```\n in each row. I suppose there is a problem in a floating-point calculation.\n```\npublic class Test {\n    public static void main(String[] args) {\n        int trials = Integer.parseInt(args[0]);\n\n        double[][] p = {\n                {0.02, 0.92, 0.02, 0.02, 0.02},\n                {0.02, 0.02, 0.38, 0.38, 0.2},\n                {0.02, 0.02, 0.02, 0.92, 0.02},\n                {0.92, 0.02, 0.02, 0.02, 0.02},\n                {0.47, 0.02, 0.47, 0.02, 0.02}};\n\n        for (int t = 0; t < trials; t++) {\n            p = multiply(p, p);\n        }\n\n        for (int i = 0; i < p.length; i++) {\n            for (int j = 0; j < p[i].length; j++) {\n                System.out.printf(\"%9.4f\", p[i][j]);\n            }\n            System.out.println();\n        }\n    }\n\n    public static double[][] multiply(double[][] a, double[][] b) {\n        int w = a[0].length;\n        int l = b.length;\n        if (w != l) {\n            throw new IllegalArgumentException(\"The number of columns \" +\n                    \"in the first matrix must be equal to the number \" +\n                    \"of rows in second matrix!\" + w + \" \" + l);\n        }\n\n        double[][] result = new double[a.length][b[0].length];\n        for (int i = 0; i < a.length; i++) {\n            for (int j = 0; j < b[0].length; j++) {\n                for (int k = 0; k < b.length; k++) {\n                    result[i][j] += a[i][k] * b[k][j];\n                }\n            }\n        }\n        return result;\n    }\n}\n\n/*\noutput for the trials = 30:\n   0,2730   0,2657   0,1462   0,2472   0,0678\n   0,2730   0,2657   0,1462   0,2472   0,0678\n   0,2730   0,2657   0,1462   0,2472   0,0678\n   0,2730   0,2657   0,1462   0,2472   0,0678\n   0,2730   0,2657   0,1462   0,2472   0,0678\n\noutput for the trials = 45:\n   0,2732   0,2659   0,1463   0,2474   0,0679\n   0,2732   0,2659   0,1463   0,2474   0,0679\n   0,2732   0,2659   0,1463   0,2474   0,0679\n   0,2732   0,2659   0,1463   0,2474   0,0679\n   0,2732   0,2659   0,1463   0,2474   0,0679\n\noutput for the trials = 55:\n   0,5183   0,5044   0,2775   0,4693   0,1288\n   0,5183   0,5044   0,2775   0,4693   0,1288\n   0,5183   0,5044   0,2775   0,4693   0,1288\n   0,5183   0,5044   0,2775   0,4693   0,1288\n   0,5183   0,5044   0,2775   0,4693   0,1288\n\noutput for the trials = 70:\n Infinity Infinity Infinity Infinity Infinity\n Infinity Infinity Infinity Infinity Infinity\n Infinity Infinity Infinity Infinity Infinity\n Infinity Infinity Infinity Infinity Infinity\n Infinity Infinity Infinity Infinity Infinity\n*/\n```\n\n    ", "Answer": "\r\nFloating point calculations, especially those with large fractional parts, are associated with rounding in most cases. The question is how and what to round?\nFloating point matrix multiplication\nYou can use matrix multiplication with ```\nBigDecimal```\n instead of ```\ndouble```\n. In this case, the 34-digit ```\nDECIMAL128```\n format can be enough for the first 151 trials. Result can be represented using scientific notation with an exponent if needed.\nTo convert ```\ndouble```\n to ```\nBigDecimal```\n use the ```\nvalueOf```\n method and don't use the constructor ```\nBigDecimal(double)```\n, otherwise you can get unpredictable appendix to each number. I guess, this is the main mistake in the calculations with ```\ndouble```\n.\nIn this case, starting from the 5th trial the row sums become less than ```\n1```\n because of rounding, and then they become even less, and after the 151st trial you will get an ```\nArithmeticException```\n underflow, because the numbers are getting smaller than the rounding bounds.\nSpherical horse in vacuum\nFor more precise calculations you can use ```\nUNLIMITED```\n precision arithmetic. In this case, the sums of the rows are stably equal to ```\n1```\n on each iteration, but it thinks too long, even in ```\nparallel```\n mode, so I stopped at the 20th trial with such a ```\nMathContext```\n. It takes about five minutes to calculate the 20th iteration, that's enough for me. The time for further trials grows in geometric progression with an approximate common ratio of ```\n3```\n, but it continues to work without a memory leaks. I hope this is the case, so I think it might take approximately more than a year to calculate the first 30 trials...\nWorking code\nThe first 151 trials in 34-digit ```\nDECIMAL128```\n format, every tenth trial is printed using scientific notation. You can convert these values to ```\ndoubleValue```\n and round the row sums back to ```\n1```\n until the 65th trial, but in this case you will get ```\n0.0```\n after the 128th trial:\n```\npublic static void main(String[] args) {\n    int d = 5; // dimensions\n    int trials = 151;\n\n    // rules for numerical operators\n    MathContext mc = MathContext.DECIMAL128;\n\n    BigDecimal[][] p = toBigDecimal(new double[][]{\n            {0.02, 0.92, 0.02, 0.02, 0.02},\n            {0.02, 0.02, 0.38, 0.38, 0.2},\n            {0.02, 0.02, 0.02, 0.92, 0.02},\n            {0.92, 0.02, 0.02, 0.02, 0.02},\n            {0.47, 0.02, 0.47, 0.02, 0.02}});\n\n    // matrix multiplication\n    for (int t = 0; t < trials; t++) {\n        long time = System.currentTimeMillis();\n        p = parallelMatrixMultiplication(mc, d, d, d, p, p);\n        // print every tenth trial\n        if (t % 10 == 0)\n            outputMatrix(p, t, time);\n    }\n}\n```\n\n```\nstatic void outputMatrix(BigDecimal[][] matrix, int t, long time) {\n    System.out.println(\"trial: \" + t);\n    for (BigDecimal[] row : matrix) {\n        BigDecimal sum = BigDecimal.valueOf(0);\n        for (BigDecimal element : row) {\n            sum = sum.add(element);\n            // string representation of this element, using\n            // scientific notation with an exponent if needed\n            System.out.print(element.toString() + \" \");\n        }\n        // sum of the row in the same format\n        System.out.println(\"|| \" + sum.toString());\n    }\n    System.out.println(\"time: \" + (System.currentTimeMillis() - time));\n}\n```\n\n```\nstatic BigDecimal[][] toBigDecimal(double[][] matrix) {\n    return Arrays.stream(matrix)\n            .map(row -> Arrays.stream(row)\n                    .mapToObj(BigDecimal::valueOf)\n                    .toArray(BigDecimal[]::new))\n            .toArray(BigDecimal[][]::new);\n}\n```\n\n```\n/**\n * Parallel Matrix multiplication\n *\n * @param mc rules for numerical operators\n * @param m  rows of 'a' matrix\n * @param n  columns of 'a' matrix\n *           and rows of 'b' matrix\n * @param p  columns of 'b' matrix\n * @param a  first matrix 'm×n'\n * @param b  second matrix 'n×p'\n * @return result matrix 'm×p'\n */\nstatic BigDecimal[][] parallelMatrixMultiplication(\n        MathContext mc, int m, int n, int p,\n        BigDecimal[][] a, BigDecimal[][] b) {\n    return IntStream.range(0, m)\n            .parallel()\n            .mapToObj(i -> IntStream.range(0, p)\n                    .mapToObj(j -> IntStream.range(0, n)\n                            .mapToObj(k -> a[i][k].multiply(b[k][j], mc))\n                            .reduce((bd1, bd2) -> bd1.add(bd2, mc))\n                            .orElse(new BigDecimal(\"0\")))\n                    .toArray(BigDecimal[]::new))\n            .toArray(BigDecimal[][]::new);\n}\n```\n\nOutput:\n```\ntrial: 0\n0.0470 0.0380 0.3602 0.3692 0.1856 || 1.0000\n0.4520 0.0380 0.1172 0.3692 0.0236 || 1.0000\n0.8570 0.0380 0.0362 0.0452 0.0236 || 1.0000\n0.0470 0.8480 0.0362 0.0452 0.0236 || 1.0000\n0.0470 0.4430 0.0362 0.4502 0.0236 || 1.0000\ntime: 48\ntrial: 10\n0.2730292887828770329701825732219565 0.2657263599045893296731643158997608 0.1461853247179238943858654633117944 0.2472282818117836636296180707045289 0.06783074478282607934116957686195689 || 0.99999999999999999999999999999999749\n0.2730292887828770329701825732219565 0.2657263599045893296731643158997608 0.1461853247179238943858654633117944 0.2472282818117836636296180707045289 0.06783074478282607934116957686195689 || 0.99999999999999999999999999999999749\n0.2730292887828770329701825732219566 0.2657263599045893296731643158997610 0.1461853247179238943858654633117944 0.2472282818117836636296180707045290 0.06783074478282607934116957686195692 || 0.99999999999999999999999999999999792\n0.2730292887828770329701825732219565 0.2657263599045893296731643158997607 0.1461853247179238943858654633117943 0.2472282818117836636296180707045288 0.06783074478282607934116957686195687 || 0.99999999999999999999999999999999717\n0.2730292887828770329701825732219565 0.2657263599045893296731643158997608 0.1461853247179238943858654633117944 0.2472282818117836636296180707045289 0.06783074478282607934116957686195689 || 0.99999999999999999999999999999999749\ntime: 11\ntrial: 20\n0.2730292887828770329701825732212719 0.2657263599045893296731643158990943 0.1461853247179238943858654633114277 0.2472282818117836636296180707039089 0.06783074478282607934116957686178676 || 0.99999999999999999999999999999748956\n0.2730292887828770329701825732212719 0.2657263599045893296731643158990943 0.1461853247179238943858654633114277 0.2472282818117836636296180707039089 0.06783074478282607934116957686178676 || 0.99999999999999999999999999999748956\n0.2730292887828770329701825732212719 0.2657263599045893296731643158990943 0.1461853247179238943858654633114277 0.2472282818117836636296180707039089 0.06783074478282607934116957686178676 || 0.99999999999999999999999999999748956\n0.2730292887828770329701825732212715 0.2657263599045893296731643158990941 0.1461853247179238943858654633114276 0.2472282818117836636296180707039086 0.06783074478282607934116957686178666 || 0.99999999999999999999999999999748846\n0.2730292887828770329701825732212719 0.2657263599045893296731643158990943 0.1461853247179238943858654633114277 0.2472282818117836636296180707039089 0.06783074478282607934116957686178676 || 0.99999999999999999999999999999748956\ntime: 9\ntrial: 30\n0.2730292887828770329701825725200014 0.2657263599045893296731643152165814 0.1461853247179238943858654629359535 0.2472282818117836636296180700689079 0.06783074478282607934116957668756482 || 0.99999999999999999999999999742900902\n0.2730292887828770329701825725200014 0.2657263599045893296731643152165814 0.1461853247179238943858654629359535 0.2472282818117836636296180700689079 0.06783074478282607934116957668756482 || 0.99999999999999999999999999742900902\n0.2730292887828770329701825725200014 0.2657263599045893296731643152165814 0.1461853247179238943858654629359535 0.2472282818117836636296180700689079 0.06783074478282607934116957668756482 || 0.99999999999999999999999999742900902\n0.2730292887828770329701825725200011 0.2657263599045893296731643152165811 0.1461853247179238943858654629359533 0.2472282818117836636296180700689076 0.06783074478282607934116957668756474 || 0.99999999999999999999999999742900784\n0.2730292887828770329701825725200014 0.2657263599045893296731643152165814 0.1461853247179238943858654629359535 0.2472282818117836636296180700689079 0.06783074478282607934116957668756482 || 0.99999999999999999999999999742900902\ntime: 10\ntrial: 40\n0.2730292887828770329701818544190935 0.2657263599045893296731636163232827 0.1461853247179238943858650784504105 0.2472282818117836636296174198278500 0.06783074478282607934116939828428938 || 0.99999999999999999999999736730492608\n0.2730292887828770329701818544190935 0.2657263599045893296731636163232827 0.1461853247179238943858650784504105 0.2472282818117836636296174198278500 0.06783074478282607934116939828428938 || 0.99999999999999999999999736730492608\n0.2730292887828770329701818544190935 0.2657263599045893296731636163232827 0.1461853247179238943858650784504105 0.2472282818117836636296174198278500 0.06783074478282607934116939828428938 || 0.99999999999999999999999736730492608\n0.2730292887828770329701818544190931 0.2657263599045893296731636163232822 0.1461853247179238943858650784504101 0.2472282818117836636296174198278496 0.06783074478282607934116939828428926 || 0.99999999999999999999999736730492426\n0.2730292887828770329701818544190935 0.2657263599045893296731636163232827 0.1461853247179238943858650784504105 0.2472282818117836636296174198278500 0.06783074478282607934116939828428938 || 0.99999999999999999999999736730492608\ntime: 8\ntrial: 50\n0.2730292887828770329694465190894863 0.2657263599045893296724479495854144 0.1461853247179238943854713652542387 0.2472282818117836636289515729844414 0.06783074478282607934098671333025123 || 0.99999999999999999999730412024383203\n0.2730292887828770329694465190894863 0.2657263599045893296724479495854144 0.1461853247179238943854713652542387 0.2472282818117836636289515729844414 0.06783074478282607934098671333025123 || 0.99999999999999999999730412024383203\n0.2730292887828770329694465190894863 0.2657263599045893296724479495854144 0.1461853247179238943854713652542387 0.2472282818117836636289515729844414 0.06783074478282607934098671333025123 || 0.99999999999999999999730412024383203\n0.2730292887828770329694465190894859 0.2657263599045893296724479495854140 0.1461853247179238943854713652542385 0.2472282818117836636289515729844411 0.06783074478282607934098671333025115 || 0.99999999999999999999730412024383065\n0.2730292887828770329694465190894863 0.2657263599045893296724479495854144 0.1461853247179238943854713652542387 0.2472282818117836636289515729844414 0.06783074478282607934098671333025123 || 0.99999999999999999999730412024383203\ntime: 9\ntrial: 60\n0.2730292887828770322164631415718825 0.2657263599045893289396052100083683 0.1461853247179238939823090523745175 0.2472282818117836629471244053337530 0.06783074478282607915391732039518029 || 0.99999999999999999723941912968370159\n0.2730292887828770322164631415718825 0.2657263599045893289396052100083683 0.1461853247179238939823090523745175 0.2472282818117836629471244053337530 0.06783074478282607915391732039518029 || 0.99999999999999999723941912968370159\n0.2730292887828770322164631415718825 0.2657263599045893289396052100083683 0.1461853247179238939823090523745175 0.2472282818117836629471244053337530 0.06783074478282607915391732039518029 || 0.99999999999999999723941912968370159\n0.2730292887828770322164631415718818 0.2657263599045893289396052100083676 0.1461853247179238939823090523745172 0.2472282818117836629471244053337525 0.06783074478282607915391732039518012 || 0.99999999999999999723941912968369922\n0.2730292887828770322164631415718825 0.2657263599045893289396052100083683 0.1461853247179238939823090523745175 0.2472282818117836629471244053337530 0.06783074478282607915391732039518029 || 0.99999999999999999723941912968370159\ntime: 9\ntrial: 70\n0.2730292887828762611614845635464324 0.2657263599045885785086398831140649 0.1461853247179234811441006635406023 0.2472282818117829647561047310298819 0.06783074478282588759485895488280742 || 0.99999999999999717316518879611378892\n0.2730292887828762611614845635464324 0.2657263599045885785086398831140649 0.1461853247179234811441006635406023 0.2472282818117829647561047310298819 0.06783074478282588759485895488280742 || 0.99999999999999717316518879611378892\n0.2730292887828762611614845635464324 0.2657263599045885785086398831140649 0.1461853247179234811441006635406023 0.2472282818117829647561047310298819 0.06783074478282588759485895488280742 || 0.99999999999999717316518879611378892\n0.2730292887828762611614845635464319 0.2657263599045885785086398831140646 0.1461853247179234811441006635406021 0.2472282818117829647561047310298813 0.06783074478282588759485895488280730 || 0.99999999999999717316518879611378720\n0.2730292887828762611614845635464324 0.2657263599045885785086398831140649 0.1461853247179234811441006635406023 0.2472282818117829647561047310298819 0.06783074478282588759485895488280742 || 0.99999999999999717316518879611378892\ntime: 8\ntrial: 80\n0.2730292887820867008634218082462759 0.2657263599038201372001462555418668 0.1461853247175007348187111094682799 0.2472282818110680171519592786367428 0.06783074478262973111909295411775437 || 0.99999999999710532115333140601091977\n0.2730292887820867008634218082462759 0.2657263599038201372001462555418668 0.1461853247175007348187111094682799 0.2472282818110680171519592786367428 0.06783074478262973111909295411775437 || 0.99999999999710532115333140601091977\n0.2730292887820867008634218082462759 0.2657263599038201372001462555418668 0.1461853247175007348187111094682799 0.2472282818110680171519592786367428 0.06783074478262973111909295411775437 || 0.99999999999710532115333140601091977\n0.2730292887820867008634218082462755 0.2657263599038201372001462555418664 0.1461853247175007348187111094682796 0.2472282818110680171519592786367424 0.06783074478262973111909295411775427 || 0.99999999999710532115333140601091817\n0.2730292887820867008634218082462759 0.2657263599038201372001462555418668 0.1461853247175007348187111094682799 0.2472282818110680171519592786367428 0.06783074478262973111909295411775437 || 0.99999999999710532115333140601091977\ntime: 12\ntrial: 90\n0.2730292879735769568454317780258554 0.2657263591169362384688919123320142 0.1461853242846084982613861358960980 0.2472282810789616715920519228547587 0.06783074458176550023240385632850718 || 0.99999999703584886540016560543723348\n0.2730292879735769568454317780258554 0.2657263591169362384688919123320142 0.1461853242846084982613861358960980 0.2472282810789616715920519228547587 0.06783074458176550023240385632850718 || 0.99999999703584886540016560543723348\n0.2730292879735769568454317780258554 0.2657263591169362384688919123320142 0.1461853242846084982613861358960980 0.2472282810789616715920519228547587 0.06783074458176550023240385632850718 || 0.99999999703584886540016560543723348\n0.2730292879735769568454317780258548 0.2657263591169362384688919123320136 0.1461853242846084982613861358960977 0.2472282810789616715920519228547582 0.06783074458176550023240385632850703 || 0.99999999703584886540016560543723133\n0.2730292879735769568454317780258554 0.2657263591169362384688919123320142 0.1461853242846084982613861358960980 0.2472282810789616715920519228547587 0.06783074458176550023240385632850718 || 0.99999999703584886540016560543723348\ntime: 8\ntrial: 100\n0.2730284600608555597809096423856914 0.2657255533490468070347525429793999 0.1461848810036310065886299754607182 0.2472275314032015596942117582195087 0.06783053889710522849818932256856966 || 0.99999696471384016159669324161388786\n0.2730284600608555597809096423856914 0.2657255533490468070347525429793999 0.1461848810036310065886299754607182 0.2472275314032015596942117582195087 0.06783053889710522849818932256856966 || 0.99999696471384016159669324161388786\n0.2730284600608555597809096423856914 0.2657255533490468070347525429793999 0.1461848810036310065886299754607182 0.2472275314032015596942117582195087 0.06783053889710522849818932256856966 || 0.99999696471384016159669324161388786\n0.2730284600608555597809096423856910 0.2657255533490468070347525429793995 0.1461848810036310065886299754607179 0.2472275314032015596942117582195082 0.06783053889710522849818932256856957 || 0.99999696471384016159669324161388617\n0.2730284600608555597809096423856914 0.2657255533490468070347525429793999 0.1461848810036310065886299754607182 0.2472275314032015596942117582195087 0.06783053889710522849818932256856966 || 0.99999696471384016159669324161388786\ntime: 12\ntrial: 110\n0.2721819935822030657304032357038538 0.2649017279742810454592283638310650 0.1457316659745904561852246134110141 0.2464610551981708732338898147466929 0.06762024478566887448452655718718783 || 0.99689668751491431509327258487981363\n0.2721819935822030657304032357038538 0.2649017279742810454592283638310650 0.1457316659745904561852246134110141 0.2464610551981708732338898147466929 0.06762024478566887448452655718718783 || 0.99689668751491431509327258487981363\n0.2721819935822030657304032357038538 0.2649017279742810454592283638310650 0.1457316659745904561852246134110141 0.2464610551981708732338898147466929 0.06762024478566887448452655718718783 || 0.99689668751491431509327258487981363\n0.2721819935822030657304032357038534 0.2649017279742810454592283638310646 0.1457316659745904561852246134110139 0.2464610551981708732338898147466923 0.06762024478566887448452655718718771 || 0.99689668751491431509327258487981191\n0.2721819935822030657304032357038538 0.2649017279742810454592283638310650 0.1457316659745904561852246134110141 0.2464610551981708732338898147466929 0.06762024478566887448452655718718783 || 0.99689668751491431509327258487981363\ntime: 8\ntrial: 120\n0.01132311287302140636187625536070984 0.01102024467759399595775450897719919 0.006062620386037311053865263230157305 0.01025308952324214872533623929149362 0.002813087133841649504461690768456174 || 0.041472154593736511603293957628016129\n0.01132311287302140636187625536070984 0.01102024467759399595775450897719919 0.006062620386037311053865263230157305 0.01025308952324214872533623929149362 0.002813087133841649504461690768456174 || 0.041472154593736511603293957628016129\n0.01132311287302140636187625536070984 0.01102024467759399595775450897719919 0.006062620386037311053865263230157305 0.01025308952324214872533623929149362 0.002813087133841649504461690768456174 || 0.041472154593736511603293957628016129\n0.01132311287302140636187625536070982 0.01102024467759399595775450897719917 0.006062620386037311053865263230157291 0.01025308952324214872533623929149360 0.002813087133841649504461690768456168 || 0.041472154593736511603293957628016049\n0.01132311287302140636187625536070984 0.01102024467759399595775450897719919 0.006062620386037311053865263230157305 0.01025308952324214872533623929149362 0.002813087133841649504461690768456174 || 0.041472154593736511603293957628016129\ntime: 8\ntrial: 130\n1.044639308739343328720850715228411E-1416 1.016697520482136028467012050376325E-1416 5.593207133268761858504096038885519E-1417 9.459218919844845701317393883059301E-1417 2.595276963035115177423085757384926E-1417 || 3.8261071308363516309123203335377106E-1416\n1.044639308739343328720850715228411E-1416 1.016697520482136028467012050376325E-1416 5.593207133268761858504096038885519E-1417 9.459218919844845701317393883059301E-1417 2.595276963035115177423085757384926E-1417 || 3.8261071308363516309123203335377106E-1416\n1.044639308739343328720850715228411E-1416 1.016697520482136028467012050376325E-1416 5.593207133268761858504096038885519E-1417 9.459218919844845701317393883059301E-1417 2.595276963035115177423085757384926E-1417 || 3.8261071308363516309123203335377106E-1416\n1.044639308739343328720850715228409E-1416 1.016697520482136028467012050376324E-1416 5.593207133268761858504096038885513E-1417 9.459218919844845701317393883059288E-1417 2.595276963035115177423085757384923E-1417 || 3.8261071308363516309123203335377054E-1416\n1.044639308739343328720850715228411E-1416 1.016697520482136028467012050376325E-1416 5.593207133268761858504096038885519E-1417 9.459218919844845701317393883059301E-1417 2.595276963035115177423085757384926E-1417 || 3.8261071308363516309123203335377106E-1416\ntime: 8\ntrial: 140\n1.511841812795049791388737404792298E-1449388 1.471403392128599201290355981548488E-1449388 8.094702488176411118777608478542366E-1449389 1.368974205715227102195005233661688E-1449388 3.755983711962022452727563939141449E-1449389 || 5.5372880306527194520246158617708555E-1449388\n1.511841812795049791388737404792298E-1449388 1.471403392128599201290355981548488E-1449388 8.094702488176411118777608478542366E-1449389 1.368974205715227102195005233661688E-1449388 3.755983711962022452727563939141449E-1449389 || 5.5372880306527194520246158617708555E-1449388\n1.511841812795049791388737404792298E-1449388 1.471403392128599201290355981548488E-1449388 8.094702488176411118777608478542366E-1449389 1.368974205715227102195005233661688E-1449388 3.755983711962022452727563939141449E-1449389 || 5.5372880306527194520246158617708555E-1449388\n1.511841812795049791388737404792296E-1449388 1.471403392128599201290355981548485E-1449388 8.094702488176411118777608478542352E-1449389 1.368974205715227102195005233661686E-1449388 3.755983711962022452727563939141443E-1449389 || 5.5372880306527194520246158617708465E-1449388\n1.511841812795049791388737404792298E-1449388 1.471403392128599201290355981548488E-1449388 8.094702488176411118777608478542366E-1449389 1.368974205715227102195005233661688E-1449388 3.755983711962022452727563939141449E-1449389 || 5.5372880306527194520246158617708555E-1449388\ntime: 7\ntrial: 150\n3.736410561203285932862056593199857E-1484172552 3.636469852606817133931883241380801E-1484172552 2.000548708909203057880207355325268E-1484172552 3.383323332480596714663696894190756E-1484172552 9.282649209930868784637712909494675E-1484172553 || 1.36850173761929897178016153750461495E-1484172551\n3.736410561203285932862056593199857E-1484172552 3.636469852606817133931883241380801E-1484172552 2.000548708909203057880207355325268E-1484172552 3.383323332480596714663696894190756E-1484172552 9.282649209930868784637712909494675E-1484172553 || 1.36850173761929897178016153750461495E-1484172551\n3.736410561203285932862056593199857E-1484172552 3.636469852606817133931883241380801E-1484172552 2.000548708909203057880207355325268E-1484172552 3.383323332480596714663696894190756E-1484172552 9.282649209930868784637712909494675E-1484172553 || 1.36850173761929897178016153750461495E-1484172551\n3.736410561203285932862056593199849E-1484172552 3.636469852606817133931883241380794E-1484172552 2.000548708909203057880207355325263E-1484172552 3.383323332480596714663696894190750E-1484172552 9.282649209930868784637712909494657E-1484172553 || 1.36850173761929897178016153750461217E-1484172551\n3.736410561203285932862056593199857E-1484172552 3.636469852606817133931883241380801E-1484172552 2.000548708909203057880207355325268E-1484172552 3.383323332480596714663696894190756E-1484172552 9.282649209930868784637712909494675E-1484172553 || 1.36850173761929897178016153750461495E-1484172551\ntime: 7\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How to enumerate all possibilities for brute-force algorithm?\r\n                \r\nThis question may be not specified, but I think it is very important. When you want to solve a optimization problem and you are not very familiar with ```\ndynamic programming```\n method, it is the first idea that comes to you mind. \n\nI can give some simple examples:\n\n\nget min element of a list (very simple)\nlist all permutation of a set\nlist all subset of a set\n\n\nThese problem all have mature method. But there are problem not very clear:\n\n\nlist all ```\nedit distance```\n of two string (i mean not the shortest one of edit operation)\nlist all ```\ncommon subsequence```\n of two sequence\nlist all possibilities of parenthesizing ```\nmatrix chain multiplication```\n\n\n\nI have no idea about solving these problems with brute-force method. My question is:\n\nIs there a systematic generic method for list all the possibilities with brute-force algorithm?\n    ", "Answer": "\r\nBacktracking is one of the most general methods for finding all solutions to a problem.  Per wikipedia,\n\n\n  Backtracking is a general algorithm for finding all (or some) solutions to some computational problem, that incrementally builds candidates to the solutions, and abandons each partial candidate c (\"backtracks\") as soon as it determines that c cannot possibly be completed to a valid solution.\n  \n  The classic textbook example of the use of backtracking is the eight queens puzzle, that asks for all arrangements of eight chess queens on a standard chessboard so that no queen attacks any other.\n\n\nTwo of the problems you mention,\n• list all common subsequence of two sequence\n• list all possibilities of parenthesizing matrix chain multiplication\ncan be easily handled using backtracking.  I am not sure about the edit-distance question.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Can a hit and trial matrix take place in a recursive function without creating multiple copies?\r\n                \r\nI have a matrix which needs to be changed by hit and trial method, evaluated and the values need to be re-assigned if it does not meet the requirements. I am doing this in a recursive function for chained assumption. Can this be done without creating multiple copies?\n\nCan I restore the matrix while backtracking?\n    ", "Answer": "\r\nYou ask: \"Can I restore the matrix while backtracking?\" I ask the same question - can you? If the modifications are easily reversible, then sure you can.\n\n```\nvoid f()\n{\n    foreach (possibilty)\n        modify ();\n        f();\n        unmodify();  \n}\n```\n\n\nIf unmodify is not trivial, then you'd be better off with\n\n```\nvoid f(matrix m)\n{\n   foreach (possibilty)\n        matrix tmp = m;\n        modify (tmp);\n        f(tmp);\n}\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Parallel method to get all the eigenvalues of a large sparse matrix\r\n                \r\n\nIs it possible to compute all the eigenvalues of a large sparse matrix using multiple CPUs ?\nIf yes, then is it possible to do it without storing the full dense matrix in memory ? (using only the stored sparse matrix)\nIf yes, then what's a good (rapid and low memory usage) method to do it ?\nCan ```\nnumpy```\n or ```\nscipy```\n do it ?\n\n\nMy matrix is complex, non-hermitian, as sparse as the identity matrix  and of dimension ```\nN x N```\n where ```\nN = BinomialCoefficient(L,Floor(L/2))```\n where we need to take ```\nL```\n as large as possible.\n\nFor example, with ```\nL = 20```\n, ```\nN = 184 756```\n it is 99.9995% sparse, having just ```\nN```\n non-zero elements. So, the memory usage of the sparse matrix is ~0.1GB but would be ~10TB for the dense matrix.\nWith ```\nL = 30```\n, ```\nN = 155 117 520```\n and we use ~60GB (sparse) and ~10EB (dense). So it's impraticable to store the full dense matrix in memory.\n\nI have access to Intel® Gold 6148 Skylake @ 2.4 [GHz] CPUs with up to 752 [GB] of RAM each. I could use Python, C (ScaLAPACK, OpenBLAS, MAGMA, ELPA, MUMPS, SuperLU, SuiteSparse, PETSc, Lis,...), C++ (Armadillo, Eigen, BLitz++, Trilinos,...), Matlab, R, Perl, Fortran, mpi4py, CUDA, Intel® Math Kernel Library, and a few other softwares.\n\nI build my matrix using Python (```\nscipy.sparse```\n, ```\nnumpy```\n and ```\nmultiprocessing```\n). I've tried using ```\nnumpy.linalg.eigvals()```\n and ```\nscipy.linalg.eigvals()```\n, but it seems that they only use the cores of one CPU. I could look further into those, but I wont if there's a better way to solve my matrix.\n\nFor the curious ones, my matrix comes from a representation of a non-hermitian operator on a subset of states of a length ```\nL```\n quantum spin 1/2 chain with strong interactions. I need the full spectrum because it allows me to study the level spacing distribution of the energy spectrum for a fixed set of quantum numbers.\n\nI'm far from being a professional in computer science, so if I missed some basic concept please be clement.\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Markov chains in Python - filling the transition matrix from another array and hitting probabilities\r\n                \r\nPython or R (preferably Python, since I am better with arrays and loops there)\n\nSuppose we have a two dimensional array A (of n^2 rows and n^2 columns) whose entries we have already filled in with for loops, using some complicated rules.\n\nNow I want to create a Markov chain on n^2 states with transition matrix A and then compute the following hitting probability: the probability that, starting from (2,3), say, I ever reach a state corresponding to an integer which is a multiple of n.\n\nHow is this possible? Are there some nice library/package functions for this? \n\nUpdate: I am also fine with not formally creating a chain but just a complicated system of equations which finds the hitting probability I am chasing.\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Does Zen 4 core have 48 flops per cycle for 32-bit precision fp?\r\n                \r\nSince amd zen 4 has only 256bit wide operations on vector data, the following diagram from chipsandcheese's Zen 4 article shows 6 FP pipelines (4 ALU and 2 memory):\n\nEach FMA does 1 multiplication and 1 add while fadd does only 1 add. So does this mean theoretically it can do a total of 2 multiplications and 4 adds = 6 operations of 256 bits each?\nAssuming all 4adds and 2 muls can be issued in same cycle, can this mean 256bits (or just 8 floats of 32bit precision) x 6 = 48 elements are computed per cycle (or 48 gflops/s per GHz)?\nAssuming all operands are in registers, there should be enough bandwidth to get the data to fpu (the L1 bandwidth says 2x256 bits per cycle for reading is only enough for 8 flops per cycle but registers must be much faster), but the fpu throughput isn't clearly shown.\nHow does this compare to Intel 11/12/13 gen? For example, some workstation xeons had 2x fpu of 512bits each but no dedicated \"add\"s? Is it fair to compare cpus with different ratios of muls and adds for flops-to-flops? Looks like amd is better on:\n```\nd += a * b + c;\n// or\nd += a * b;\ne += c;\n```\n\nwhile intel is better on:\n```\nd = a * b + c;\n// or\nd+=a*b;\n```\n\nper gflops. Intel's flops value looks better for matrix multiplication and blending. AMD's flops value looks better for chained matrix add & multiplication and some loop with float accumulator & matrix multiplication.\nSo when doing matrix multiplication, is zen 4 effectively 32 flops per cycle?\n    ", "Answer": "\r\nYes, 48 FLOP / cycle theoretical max throughput on Zen 4 if you have a use for adds and FMAs in the same loop.\nI'd guess that usually this is most useful when you have many short-vector dot products that aren't matmuls, so each cleanup loop needs to do some shuffling and adding.  Out-of-order exec can overlap that work with FMAs.\nAnd in code not using FMAs, you still have 2 mul + 2 add per clock, which is potentially quite useful for less well optimized code.  (A lot of real-life code is not well optimized.  How many times have you seen people give advice to not worry about performance?)\nAlso with a mix of shuffles and other non-FP-math vector work, that can run on a good mix of ports and still leave some room for FP adds and multiplies.\n\nAFAIK, Zen 4 can keep both FMA and both FP-ADD units busy at the same time, so yes, 2 vector FMAs and 2 vector ```\nvaddps```\n every cycle.  So that's 6x vector-width FLOPs.  It doesn't make sense to call it \"4adds and 2 muls\" being issued (and dispatched to execution units) in the same cycle, though, since the CPU sees them as 2 FMA and 2 ADD operations, not 6 separate uops.\n\nSo when doing matrix multiplication, is zen 4 effectively 32 flops per cycle?\n\nYes, standard matmal is all FMAs, little to no use for extra FP-add throughput.\nMaybe some large-matrix multiplies using Strassen's algorithm would result in a workload with more than 1 addition per multiply, if you can arrange it such that the adding work overlaps with multiplying.\nOr possibly run another thread on the same physical core doing the adding work, if you can arrange that without making things worse by competing for L1d cache footprint and bandwidth.  HPC workloads sometimes scale negatively with SMT / hyperthreading for that reason, but partly that's because a well tuned single thread can use all the FP throughput from a single core.  But if that's not the case on Zen 4, there's some theoretical room for gains.\nHowever, that would require your FMA code to need less than 1 load per FMA, otherwise load/store uops will be the bottleneck if a submatrix-add thread is trying to load+load+add+store at the same time as a submatrix-multiply thread is doing 2 loads + 2 FMAs per clock.\n\n\nFor example, some workstation xeons had 2x fpu of 512bits each but no dedicated \"add\"s?\n\nAnd yes, Intel CPUs with a second 512-bit FMA unit (like some Xeon scalable processors) can sustain 2x 512-bit FMAs per clock if you optimize your code well enough (e.g. not bottlenecking on loads+stores or FMA latency), so that gives you 2x 16 single-precision FMAs = 64 FLOP/cycle.\nAlder Lake / Sapphire Rapids re-added separate execution units for FP-add, but they're on the same ports as the FMA units, so the benefit is lower latency for things that bottleneck on the latency of separate ```\nvaddps```\n / ```\nvaddpd```\n, like in Haswell.  (But unlike Haswell, there are two of them, so the throughput is still 2/clock.)\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Markov generation and probabilities\r\n                \r\nI have been working various implementations of markov chains for a while, and I just want to clarify a generalisation of the chains.\n\nGeneration\n\nIf i want to generate a sequence of length n, we simply sample from the initial probabilities, then take this state just generated to find the row of the transition matrix, and do this n-1 times?\nSo if the state is \"A\" from the sample of the initial, we just use the \"A\" row of the transition matrix as the seed for the next sample?\n\n{I have an implementation in R of markov chains in which each iteration, the initial and the transition matrices are multiplied, the initial by the transition, and the transition by itself.\nWhere or when does one apply this matrix multiplication for chain generation? I have been told that these are used for determining the values of states after some number of repetitions.... but these repetitions are what? I just want to generate states for a particular length of sequence, where does this repetition come in if I am sampling from the transition matrix, based on nucleotide frequencies in the original/input sequence?} - sorted by biziclop below\n\nProbability of User entry\n\nI have seen several implementations here.\n\nInput - \"ACGT\"\n\nP(ACGT) = P(A) * P(C|A) * P(G|C) * P(T|G)\n\nDoes this imply that P(A) is from the initial/start probabilities and that conditional probabilities (P(C|A) etc) are from the transition matrix?\n\nOr does this imply a maximum estimation here, where P(A) = #A's/#nucleotides?\nAnd therefore P(C|A) = #C's / #A's?\n\nIf entries in the transition are zero, then do we use laplacian estimates or other forms of pseudocounts to combat this? \n\nIf so, where does one apply the pseudocounts?\nDoes each entry of the transition matrix get an extra count? If we use the transition matrix to generate the probabilities, then the pseudocounts would have to be added here....no?\n\nA discussion would be helpful. No code or any mathematics need to be given.\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Doing an Euler rotation in 2 operations different result than doing it in 1 operation\r\n                \r\nI want to perform multiple rotations in succession with Tait–Bryan angles and get the final rotation matrix. I tried to do this with ```\nscipy.spatial.transform.Rotation```\n, but it didn’t work as expected.\nThe problem is demonstrated with the example below.\n```\nfrom scipy.spatial.transform import Rotation as R\n\nprint(\n    R.from_euler('zxy', (90, 0, 90), degrees=True).apply(\n        R.from_euler('xyz', (-90, 0, 0), degrees=True).as_matrix()))\n\nprint(R.from_euler('xzy', (-90, 90, 90), degrees=True).as_matrix())\n```\n\nIn the 1st ```\nprint```\n, I perform 2 rotation operations:\n\nrotate -90º about X\nrotate 90º about Z and then rotate 90º about Y\n\nThese rotations can be combined into 1 operation, which I did in the 2nd ```\nprint```\n:\n\nrotate -90º about X, then rotate 90º about Z, then rotate 90º about Y\n\nThe output:\n```\n[[ 0.00000000e+00  1.00000000e+00 -2.22044605e-16]\n [ 1.00000000e+00  4.93038066e-32  4.44089210e-16]\n [ 4.44089210e-16 -2.22044605e-16 -1.00000000e+00]]\n\n[[ 0.00000000e+00 -1.00000000e+00  0.00000000e+00]\n [ 1.00000000e+00  0.00000000e+00  1.57009246e-16]\n [-1.57009246e-16  0.00000000e+00  1.00000000e+00]]\n```\n\nI don’t understand why the matrices aren’t the same.\nThe multi-rotation’s result is 180º off the single-rotation’s result.\n```\nprint(R.from_matrix(\n    R.from_euler('zxy', (90, 0, 90), degrees=True).apply(\n        R.from_euler('xyz', (-90, 0, 0), degrees=True).as_matrix()\n    )).as_euler('zxy', degrees=True))\n\nprint(R.from_euler('xzy', (-90, 90, 90), degrees=True).as_euler('zxy', degrees=True))\n```\n\nHere’s the output from printing the rotation matrices’ angles:\n```\n[ 9.00000000e+01 -2.54444375e-14 -1.80000000e+02]\n[90.  0.  0.]\n```\n\nHow do you make the 1st statement (the 2 chained rotations) give the same result as the 2nd statement (the 1 single rotation)?\n\nWhat I want to achieve is chain multiple Euler rotations in succession to create a final rotation matrix. My current approach that doesn’t work correctly:\n```\nR.from_euler('zxy', arbitrary_rotation_2, degrees=True).apply(\n    R.from_euler('zxy', arbitrary_rotation_1, degrees=True).as_matrix())\n```\n\n\nUPDATE:\n@joostblack's answer solved my problem. However, I don't get the reason how come calling ```\nRotation.apply```\n returns a matrix that’s NOT the dot product of the 2 rotation matrices. Scipy's ```\nscipy.spatial.transform.Rotation.apply```\n documentation says,\n\nIn terms of rotation matricies, this application is the same as ```\nself.as_matrix().dot(vectors)```\n.\n\nSo why isn't it the same?\n    ", "Answer": "\r\nTo see what is happening you can print the matrices in between.\nstep 1: rotation around the z and y axis with 90 degrees:\n```\nr1 = R.from_euler('xzy', (0, 90, 90), degrees=True).as_matrix()\n```\n\nstep 2: rotation around the x axis with -90 degrees:\n```\nr2 = R.from_euler('xzy', (-90, 0, 0), degrees=True).as_matrix()\n```\n\nstep 3: multiply your rotation matrices:\n```\nprint(r1@r2)\n```\n\nstep 4: check if it is the same as your 2nd statement:\n```\nprint(R.from_euler('xzy', (-90, 90, 90), degrees=True).as_matrix())\n```\n\noutput:\n```\n[[ 0. -1.  0.]\n [ 1.  0.  0.]\n [ 0.  0.  1.]]\n[[ 0. -1.  0.]\n [ 1.  0.  0.]\n [ 0.  0.  1.]]\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "C++ OpenCL matrix library with temporary elimination\r\n                \r\nThe armadillo matrix library writes\n\n\n  Armadillo employs a delayed evaluation approach to combine several operations into one and reduce (or eliminate) the need for temporaries. Where applicable, the order of operations is optimised. Delayed evaluation and optimisation are achieved through recursive templates and template meta-programming.\n\n\nThis means that you can write operations like\n\n```\narma::mat A, B;\narma::vec c, d;\n...\nd=(A % B)*c;\n```\n\n\nand no temporary variables are created. (note that % is the element-wise product operation in armadillo) \n\nI would like to be able to code in a similar style for an OpenCL application.  \n\nThe libraries I've looked at are VexCL, ViennaCL, Boost.Compute, and clBLAS.  VexCL and Boost.Compute don't even provide basic matrix functionality such as multiplication.  clBLAS doesn't work as a template library, so you need to manually invoke the operations.  ViennaCL provides all the operations I need, but it doesn't seem to be capable of chaining them together.\n\nFor example\n\n```\n    d= linalg::prod(linalg::element_prod(A,B), c);\n```\n\n\nfails to compile.\n\nI think there might be some possibility of using VexCL to automatically generate kernels based on the operations Armadillo decides on, but I can't see any way of making that work straightforwardly.\n\nAny suggestions?\n    ", "Answer": "\r\nYou might want to check out ArrayFire.\n\nArrayFire is a matrix based library with a JIT compilation engine which allows you to combine operations into a single kernel. This dramatically reduces the number of kernel calls for basic element wise operations that you posted above. For example the code you posted can be written as:\n\n```\narray A = randu(5, 5);       // 5x5 Matrix\narray B = randu(5, 5);       // 5x5 Matrix\narray c = constant(1, 1, 5); // 1x5 Matrix\n\narray d = (A % B) + tile(c, 5);\n```\n\n\nIn this example the modulus and the addition will be performed in one OpenCL kernel. No temporaries are created. We also have backends for single threaded CPU, CUDA, and OpenCL.\n\nDisclosure: I am one of the developers of the ArrayFire library.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Chaining rotation on model matrix\r\n                \r\nI have a small opengl world where I tried making a small cube with model matrix and rotating it around the origin axis. I simply got almost everything right but my problem is that whenever I try to chain the rotations .i.e. (rotating on x-axis once and y-axis next without resetting the matrix)  I don't get what I wanted. I wanted the cube to rotate on a fixed axis but the cube rotates in its own axis. I mean to say that I want to rotate using the origin's axis but the model rotates using its own axis, the axis stays on the origin but it kinda rotates with the model. I thought my camera was moving not the model but when I try using multiple boxes it proved that my camera was on its own position. I cant figure out how to make the correct rotations. Here's my code for what I did(some codes are from learnopengl.com):\n```\n\nx_Camera camera;\n\nclass XYZ_line\n{\npublic:\n    glm::vec3 xCol, yCol, zCol;\n    std::vector<glm::vec3>m_Vertices;\n    unsigned int VBO, VAO;\n    GAME::Shader shader;\n    glm::mat4 model;\n    inline void Init()\n    {\n        model = glm::mat4(1.0f);\n        shader.Init(GAME::CubeVsShader, GAME::CubeFsShader);\n        shader.Bind();\n        xCol = glm::vec3(1.0f, 0.0f, 0.0f);\n        yCol = glm::vec3(0.0f, 1.0f, 0.0f);\n        zCol = glm::vec3(0.0f, 0.0f, 1.0f);\n\n        float x1 = 0.0f, x2 = 800.0f;\n        m_Vertices.push_back(glm::vec3(x1, 0.0f, 0.0f)); m_Vertices.push_back(xCol);\n        m_Vertices.push_back(glm::vec3(x2, 0.0f, 0.0f)); m_Vertices.push_back(xCol);\n        m_Vertices.push_back(glm::vec3(0.0f, x1, 0.0f)); m_Vertices.push_back(yCol);\n        m_Vertices.push_back(glm::vec3(0.0f, x2, 0.0f)); m_Vertices.push_back(yCol);\n        m_Vertices.push_back(glm::vec3(0.0f, 0.0f, x1)); m_Vertices.push_back(zCol);\n        m_Vertices.push_back(glm::vec3(0.0f, 0.0f, x2)); m_Vertices.push_back(zCol);\n\n        glGenVertexArrays(1, &VAO);\n        glGenBuffers(1, &VBO);\n        glBindBuffer(GL_ARRAY_BUFFER, VBO);\n        glBindVertexArray(VAO);\n        glBufferData(GL_ARRAY_BUFFER, sizeof(glm::vec3) * m_Vertices.size(), &m_Vertices[0], GL_STATIC_DRAW);\n        glEnableVertexAttribArray(0);\n        glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, sizeof(float) * 6, 0);\n        glEnableVertexAttribArray(1);\n        glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, sizeof(float) * 6, (void*)(sizeof(float) * 3));\n\n    }\n\n    void SetMatrices(glm::mat4& v, glm::mat4& p)\n    {\n        shader.Bind();\n        glBindVertexArray(VAO);\n        shader.SetUniformMat4fv(\"projection\", 1, GL_FALSE, p);\n        shader.SetUniformMat4fv(\"view\", 1, GL_FALSE, v);\n        shader.SetUniformMat4fv(\"model\", 1, GL_FALSE, model);\n    }\n\n    void Draw()\n    {\n        shader.Bind();\n        glBindVertexArray(VAO);\n        glDrawArrays(GL_LINES, 0, m_Vertices.size() / 2);\n    }\n};\n\nvoid KeyCallback(GLFWwindow* window, int key, int scancode, int action, int mods);\nvoid processInput(GLFWwindow* window);\n\n\nfloat deltaTime = 0.0f;\nfloat lastFrame = 0.0f;\nglm::mat4 projection;\nglm::mat4 view;\n\nCube cube;\nconst glm::vec3 fCol = glm::vec3(1.0f, 1.0f, 1.0f);//white\nconst glm::vec3 bCol = glm::vec3(1.0f, 0.6f, 0.0f);//orange\nconst glm::vec3 rCol = glm::vec3(1.0f, 0.0f, 0.0f);//red\nconst glm::vec3 lCol = glm::vec3(1.0f, 1.0f, 0.0f);//yellow\nconst glm::vec3 uCol = glm::vec3(0.0f, 0.0f, 1.0f);//blue\nconst glm::vec3 dCol = glm::vec3(0.0f, 1.0f, 0.0f);//green\n\nint main()\n{\n    GLFWwindow* window;\n    if (!glfwInit())\n    {\n        return -1;\n    }\n    window = glfwCreateWindow(800, 800, \"TEST\", NULL, NULL);\n    if (!window)\n    {\n        glfwTerminate();\n        return -1;\n    }\n    glfwMakeContextCurrent(window);\n    if (glewInit() != GLEW_OK)\n    {\n        glfwTerminate();\n        return -1;\n    }\n    glfwSetKeyCallback(window, KeyCallback);\n\n    camera.Init(glm::vec3(0.0f, 0.0f, 10.0f));\n    XYZ_line xyzLine1;\n    xyzLine1.Init();\n\n    float bSize = 1.0f;\n    float x1 = -1.6f, x2 = -0.5f, x3 = 0.6f;\n    float z1 = 1.6f, z2 = 0.5f, z3 = -0.6f;\n\n    cube.Init(glm::vec3(x1, x3, z1), bSize);\n    cube.m_Color_L = lCol; cube.m_Color_R = rCol; cube.m_Color_F = fCol;\n    cube.m_Color_B = bCol; cube.m_Color_U = uCol; cube.m_Color_D = dCol;\n    cube.SetVertexData();\n\n    glEnable(GL_DEPTH_TEST);\n    while (!glfwWindowShouldClose(window))\n    {\n        float currentFrame = glfwGetTime();\n        deltaTime = currentFrame - lastFrame;\n        lastFrame = currentFrame;\n        processInput(window);\n\n        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);\n        glClearColor(0.8f, 0.8f, 0.8f, 1.0f);\n\n        view = camera.GetViewMatrix();\n        projection = glm::perspective(glm::radians(camera.Zoom), 1.0f, 0.1f, 10000.0f);\n\n        xyzLine1.model = cube.model;\n        xyzLine1.SetMatrices(view, projection);\n        xyzLine1.Draw();\n\n\n        cube.SetMatrices(view, projection);\n        cube.Draw();\n\n        glfwSwapBuffers(window);\n        glfwPollEvents();\n    }\n    glfwTerminate();\n    return 0;\n}\nvoid processInput(GLFWwindow* window)\n{\n    if (glfwGetKey(window, GLFW_KEY_W) == GLFW_PRESS)\n    {\n        camera.ProcessKeyboard(Camera_Movement::FORWARD, deltaTime);\n    }\n    if (glfwGetKey(window, GLFW_KEY_S) == GLFW_PRESS)\n    {\n        camera.ProcessKeyboard(Camera_Movement::BACKWARD, deltaTime);\n    }\n    if (glfwGetKey(window, GLFW_KEY_A) == GLFW_PRESS)\n    {\n        camera.ProcessKeyboard(Camera_Movement::LEFT, deltaTime);\n    }\n    if (glfwGetKey(window, GLFW_KEY_D) == GLFW_PRESS)\n    {\n        camera.ProcessKeyboard(Camera_Movement::RIGHT, deltaTime);\n    }\n    if (glfwGetKey(window, GLFW_KEY_Q) == GLFW_PRESS)\n    {\n        camera.ProcessKeyboard(Camera_Movement::UP, deltaTime);\n    }\n    if (glfwGetKey(window, GLFW_KEY_E) == GLFW_PRESS)\n    {\n        camera.ProcessKeyboard(Camera_Movement::DOWN, deltaTime);\n    }\n\n}\nvoid KeyCallback(GLFWwindow* window, int key, int scancode, int action, int mods)\n{\n    if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS)\n    {\n        glfwSetWindowShouldClose(window, true);\n    }\n    if (glfwGetKey(window, GLFW_KEY_X) == GLFW_PRESS)\n    {\n        cube.RotateX();\n    }\n    if (glfwGetKey(window, GLFW_KEY_Y) == GLFW_PRESS)\n    {\n        cube.RotateY();\n    }\n    if (glfwGetKey(window, GLFW_KEY_Z) == GLFW_PRESS)\n    {\n        cube.RotateZ();\n    }\n}\n\n```\n\nand my ```\nCube```\n class:\n```\n    class Cube\n    {\n    public:\n        glm::vec3 t1, t2, t3, t4;\n        glm::vec3 b1, b2, b3, b4;\n        glm::vec3 m_Color_L, m_Color_R, m_Color_U, m_Color_D, m_Color_F, m_Color_B;\n\n        glm::mat4 model;\n        float m_CubeSize;\n        float rot_angle_X = 0.0f;\n        float rot_angle_Y = 0.0f;\n        float rot_angle_Z = 0.0f;\n\n        Cube();\n\n        void Init(glm::vec3 _from, float CubeSize);\n\n        Cube(const Cube& e);\n        Cube& operator=(const Cube& e);\n        Cube(Cube&& e)noexcept;\n        Cube& operator=(Cube&& e)noexcept;\n        Cube* operator-> () { return this; }\n\n        operator Cube* () { return this; }\n        Cube* Clone() { return new Cube(*this); }\n\n        void SetVertexData();\n        unsigned int GetVertexDataSize() { return vertices.size(); }\n        void Reset();\n        glm::vec3 GetCenter();\n    private:\n        glm::vec3 m_Min, m_Max, m_Cpt;\n        std::vector<glm::vec3>vertices;\n        void SetEdgeVertices(glm::vec3 _from, float size);\n    public:\n        Shader cShader;\n        unsigned int cubeVBO, cubeVAO;\n\n        void RotateX();\n        void RotateY();\n        void RotateZ();\n\n        void Draw();\n        glm::vec3 GetPosition() { return model[3]; }\n        void SetMatrices(glm::mat4& v, glm::mat4& p);\n\n    private:\n    };\n    const std::string CubeVsShader =\n    {\n        \"#version 330 core\\n\"\n        \"layout(location=0) in vec4 pos;\\n\"\n        \"layout(location=1) in vec4 col;\\n\"\n        \"\\n\"\n        \"uniform mat4 model;\\n\"\n        \"uniform mat4 view;\\n\"\n        \"uniform mat4 projection;\\n\"\n        \"\\n\"\n        \"out vec4 color;\\n\"\n        \"void main(){\\n\"\n        \"gl_Position=projection*view*model*pos;\\n\"\n        \"color=col;\\n\"\n        \"}\\n\"\n        \"\\n\"\n    };\n    const std::string CubeFsShader =\n    {\n        \"#version 330 core\\n\"\n        \"out vec4 FragColor;\\n\"\n        \"\\n\"\n        \"in vec4 color;\\n\"\n        \"void main(){\\n\"\n        \"FragColor=color;\\n\"\n        \"}\\n\"\n        \"\\n\"\n    };\n\n    Cube::Cube()\n        :t1(glm::vec3()), t2(glm::vec3()), t3(glm::vec3()), t4(glm::vec3()),\n        b1(glm::vec3()), b2(glm::vec3()), b3(glm::vec3()), b4(glm::vec3()), m_CubeSize(0.0f)\n    {\n\n    }\n\n    void Cube::Init(glm::vec3 _from, float CubeSize)\n    {\n        SetEdgeVertices(_from, CubeSize);\n        model = glm::mat4(1.0f);\n        cShader.Init(CubeVsShader, CubeFsShader);\n        cShader.Bind();\n        glGenVertexArrays(1, &cubeVAO);\n        glGenBuffers(1, &cubeVBO);\n        glBindBuffer(GL_ARRAY_BUFFER, cubeVBO);\n        glBindVertexArray(cubeVAO);\n        glBufferData(GL_ARRAY_BUFFER, sizeof(glm::vec3) * 48, 0, GL_DYNAMIC_DRAW);\n        glEnableVertexAttribArray(0);\n        glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, sizeof(float) * 6, 0);\n        glEnableVertexAttribArray(1);\n        glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, sizeof(float) * 6, (void*)(sizeof(float) * 3));\n    }\n\n    Cube::Cube(const Cube& e)\n    {\n        t1 = e.t1; t2 = e.t2; t3 = e.t3; t4 = e.t4;\n        b1 = e.b1; b2 = e.b2; b3 = e.b3; b4 = e.b4;\n\n        m_CubeSize = e.m_CubeSize;\n        m_Color_L = e.m_Color_L;\n        m_Color_R = e.m_Color_R;\n        m_Color_U = e.m_Color_U;\n        m_Color_D = e.m_Color_D;\n        m_Color_F = e.m_Color_F;\n        m_Color_B = e.m_Color_B;\n        cShader = e.cShader;\n        cubeVBO = e.cubeVBO;\n        cubeVAO = e.cubeVAO;\n        rot_angle_X = e.rot_angle_X;\n        rot_angle_Y = e.rot_angle_Y;\n        rot_angle_Z = e.rot_angle_Z;\n        model = e.model;\n        AddToVector(vertices, e.vertices);\n        m_Min = e.m_Min;\n        m_Max = e.m_Max;\n        m_Cpt = e.m_Cpt;\n    }\n    Cube& Cube::operator=(const Cube& e)\n    {\n        t1 = e.t1; t2 = e.t2; t3 = e.t3; t4 = e.t4;\n        b1 = e.b1; b2 = e.b2; b3 = e.b3; b4 = e.b4;\n\n        m_CubeSize = e.m_CubeSize;\n        m_Color_B = e.m_Color_B;\n        m_Color_F = e.m_Color_F;\n        m_Color_L = e.m_Color_L;\n        m_Color_R = e.m_Color_R;\n        m_Color_U = e.m_Color_U;\n        m_Color_D = e.m_Color_D;\n        cShader = e.cShader;\n        cubeVBO = e.cubeVBO;\n        cubeVAO = e.cubeVAO;\n        model = e.model;\n        rot_angle_X = e.rot_angle_X;\n        rot_angle_Y = e.rot_angle_Y;\n        rot_angle_Z = e.rot_angle_Z;\n        AddToVector(vertices, e.vertices);\n        m_Min = e.m_Min;\n        m_Max = e.m_Max;\n        m_Cpt = e.m_Cpt;\n        return *this;\n    }\n    Cube::Cube(Cube&& e) noexcept\n    {\n        t1 = std::move(e.t1); t2 = std::move(e.t2); t3 = std::move(e.t3); t4 = std::move(e.t4);\n        b1 = std::move(e.b1); b2 = std::move(e.b2); b3 = std::move(e.b3); b4 = std::move(e.b4);\n\n        m_CubeSize = std::move(e.m_CubeSize);\n        m_Color_B = std::move(e.m_Color_B);\n        m_Color_F = std::move(e.m_Color_F);\n        m_Color_L = std::move(e.m_Color_L);\n        m_Color_R = std::move(e.m_Color_R);\n        m_Color_U = std::move(e.m_Color_U);\n        m_Color_D = std::move(e.m_Color_D);\n        cShader = std::move(e.cShader);\n        cubeVBO = std::move(e.cubeVBO);\n        cubeVAO = std::move(e.cubeVAO);\n        model = std::move(e.model);\n        rot_angle_X = std::move(e.rot_angle_X);\n        rot_angle_Y = std::move(e.rot_angle_Y);\n        rot_angle_Z = std::move(e.rot_angle_Z);\n        AddToVector(vertices, std::move(e.vertices));\n        m_Min = std::move(e.m_Min);\n        m_Max = std::move(e.m_Max);\n        m_Cpt = std::move(e.m_Cpt);\n    }\n    Cube& Cube::operator=(Cube&& e) noexcept\n    {\n        t1 = std::move(e.t1); t2 = std::move(e.t2); t3 = std::move(e.t3); t4 = std::move(e.t4);\n        b1 = std::move(e.b1); b2 = std::move(e.b2); b3 = std::move(e.b3); b4 = std::move(e.b4);\n\n        m_CubeSize = std::move(e.m_CubeSize);\n        m_Color_B = std::move(e.m_Color_B);\n        m_Color_F = std::move(e.m_Color_F);\n        m_Color_L = std::move(e.m_Color_L);\n        m_Color_R = std::move(e.m_Color_R);\n        m_Color_U = std::move(e.m_Color_U);\n        m_Color_D = std::move(e.m_Color_D);\n        cShader = std::move(e.cShader);\n        cubeVBO = std::move(e.cubeVBO);\n        cubeVAO = std::move(e.cubeVAO);\n        model = std::move(e.model);\n        rot_angle_X = std::move(e.rot_angle_X);\n        rot_angle_Y = std::move(e.rot_angle_Y);\n        rot_angle_Z = std::move(e.rot_angle_Z);\n        m_Min = std::move(e.m_Min);\n        m_Max = std::move(e.m_Max);\n        m_Cpt = std::move(e.m_Cpt);\n        AddToVector(vertices, std::move(e.vertices));\n        return *this;\n    }\n\n    void Cube::SetVertexData()\n    {\n        ResetVectors(&vertices);\n\n        vertices.push_back(b1); vertices.push_back(m_Color_D); vertices.push_back(b2); vertices.push_back(m_Color_D);\n        vertices.push_back(b3); vertices.push_back(m_Color_D); vertices.push_back(b4); vertices.push_back(m_Color_D);\n        vertices.push_back(t1); vertices.push_back(m_Color_U); vertices.push_back(t2); vertices.push_back(m_Color_U);\n        vertices.push_back(t3); vertices.push_back(m_Color_U); vertices.push_back(t4); vertices.push_back(m_Color_U);\n        vertices.push_back(b1); vertices.push_back(m_Color_L); vertices.push_back(b2); vertices.push_back(m_Color_L);\n        vertices.push_back(t2); vertices.push_back(m_Color_L); vertices.push_back(t1); vertices.push_back(m_Color_L);\n        vertices.push_back(b4); vertices.push_back(m_Color_R); vertices.push_back(b3); vertices.push_back(m_Color_R);\n        vertices.push_back(t3); vertices.push_back(m_Color_R); vertices.push_back(t4); vertices.push_back(m_Color_R);\n        vertices.push_back(b2); vertices.push_back(m_Color_B); vertices.push_back(b3); vertices.push_back(m_Color_B);\n        vertices.push_back(t3); vertices.push_back(m_Color_B); vertices.push_back(t2); vertices.push_back(m_Color_B);\n        vertices.push_back(b1); vertices.push_back(m_Color_F); vertices.push_back(b4); vertices.push_back(m_Color_F);\n        vertices.push_back(t4); vertices.push_back(m_Color_F); vertices.push_back(t1); vertices.push_back(m_Color_F);\n\n        cShader.Bind();\n        glBindVertexArray(cubeVAO);\n        glBindBuffer(GL_ARRAY_BUFFER, cubeVBO);\n        glBufferSubData(GL_ARRAY_BUFFER, 0, sizeof(glm::vec3) * vertices.size(), &vertices[0]);\n    }\n    void Cube::Reset()\n    {\n        b1 = b2 = b3 = b4 = t1 = t2 = t3 = t4 = glm::vec3(0.0f);\n        m_Color_B = m_Color_F = m_Color_U = glm::vec3(0.0f);\n        m_Color_D = m_Color_L = m_Color_R = glm::vec3(0.0f);\n        m_CubeSize = 0.0f;\n        this->cubeVBO = 0;\n        ResetVectors(&this->vertices);\n        this->cShader.Reset();\n    }\n    glm::vec3 Cube::GetCenter()\n    {\n        return m_Cpt;\n    }\n    void Cube::SetEdgeVertices(glm::vec3 _from, float size)\n    {\n        glm::vec3 _min(_from), _max;\n        _max.x = _min.x + size; _max.y = _min.y + size; _max.z = _min.z - size;\n\n        this->m_Min = _min; this->m_Max = _max;\n\n        this->m_Cpt = (_max + _min) / glm::vec3(2.0f);\n\n        this->b1 = glm::vec3(_min.x, _min.y, _min.z); this->b2 = glm::vec3(_min.x, _min.y, _max.z);\n        this->b3 = glm::vec3(_max.x, _min.y, _max.z); this->b4 = glm::vec3(_max.x, _min.y, _min.z);\n        this->t1 = glm::vec3(_min.x, _max.y, _min.z); this->t2 = glm::vec3(_min.x, _max.y, _max.z);\n        this->t3 = glm::vec3(_max.x, _max.y, _max.z); this->t4 = glm::vec3(_max.x, _max.y, _min.z);\n\n        this->m_CubeSize = size;\n\n    }\n\n    void Rotate(glm::mat4& mat, float ang_x, float ang_y, float ang_z)\n    {\n        glm::mat4 transformX = glm::mat4(1.0f);\n        glm::mat4 transformY = glm::mat4(1.0f);\n        glm::mat4 transformZ = glm::mat4(1.0f);\n        transformX = glm::rotate(transformX, glm::radians(ang_x), glm::vec3(1.0f, 0.0f, 0.0f));\n        transformY = glm::rotate(transformY, glm::radians(ang_y), glm::vec3(0.0f, 1.0f, 0.0f));\n        transformZ = glm::rotate(transformZ, glm::radians(ang_z), glm::vec3(0.0f, 0.0f, 1.0f));\n\n        mat = transformX * transformY * transformZ;\n    }\n    void Cube::RotateX()\n    {\n        model = glm::mat4(1.0f);\n        rot_angle_X += 90.0f;\n        if (rot_angle_X >= 360.0f)\n        {\n            rot_angle_X = 0.0f;\n        }\n        Rotate(model, rot_angle_X, rot_angle_Y, rot_angle_Z);\n    }\n    void Cube::RotateY()\n    {\n        model = glm::mat4(1.0f);\n        rot_angle_Y += 90.0f;\n        if (rot_angle_Y >= 360.0f)\n        {\n            rot_angle_Y = 0.0f;\n        }\n        Rotate(model, rot_angle_X, rot_angle_Y, rot_angle_Z);\n    }\n    void Cube::RotateZ()\n    {\n        model = glm::mat4(1.0f);\n        rot_angle_Z += 90.0f;\n        if (rot_angle_Z >= 360.0f)\n        {\n            rot_angle_Z = 0.0f;\n        }\n        Rotate(model, rot_angle_X, rot_angle_Y, rot_angle_Z);\n    }\n    void Cube::Draw()\n    {\n        cShader.Bind();\n        glBindVertexArray(cubeVAO);\n        glDrawArrays(GL_QUADS, 0, vertices.size() / 2);\n    }\n    void Cube::SetMatrices(glm::mat4& v, glm::mat4& p)\n    {\n        cShader.Bind();\n        glBindVertexArray(cubeVAO);\n        cShader.SetUniformMat4fv(\"model\", 1, GL_FALSE, model);\n        cShader.SetUniformMat4fv(\"view\", 1, GL_FALSE, v);\n        cShader.SetUniformMat4fv(\"projection\", 1, GL_FALSE, p);\n    }\n```\n\nI can't figure out where I did wrong. Any ideas or help would be appreciated!!!\n    ", "Answer": "\r\nMatrix multiplications a not commutative. Thins means that\n```\nrotateX(a) * rotateY(b) * rotateX(c)```\n is not the same as ```\nrotateX(a+c) * rotateY(b)```\n.\nDo not add up the angles, but multiply the new rotation matrix with the current model matrix:\n```\nclass Cube\n{\npublic:\n    glm::mat4 model = glm::mat4(1.0f);\n\n    // [...]\n}\n\nvoid Rotate(glm::mat4& mat, float ang_x, float ang_y, float ang_z)\n{\n    glm::mat4 transformX = glm::rotate(glm::mat4(1.0f), glm::radians(ang_x), glm::vec3(1.0f, 0.0f, 0.0f));\n    glm::mat4 transformY = glm::rotate(glm::mat4(1.0f), glm::radians(ang_y), glm::vec3(0.0f, 1.0f, 0.0f));\n    glm::mat4 transformZ = glm::rotate(glm::mat4(1.0f), glm::radians(ang_z), glm::vec3(0.0f, 0.0f, 1.0f));\n\n    mat = transformX * transformY * transformZ * mat;\n}\n\nvoid Cube::RotateX()\n{\n    Rotate(model, 90.0f, 0.0f, 0.0f);\n}\n\nvoid Cube::RotateY()\n{\n    Rotate(model, 0.0f, 90.0f, 0.0f);\n}\n\nvoid Cube::RotateZ()\n{\n    Rotate(model, 0.0f, 0.0f, 90.0f);\n}\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How to chain a condition for multiple arrays?\r\n                \r\nI created a condition for an array which if the last value in a row is less than the first value in the next row, then increases the next row by +10.\nI tried to do this for multiple arrays in a row, which it reads from the input in a row. The problem is that with each matrix, it starts working from the beginning. Is it possible to chain it somehow so that the condition on consecutive matrices follows each other?\nInput\n```\n[[11 12 13 14 15 16 17 18 19]\n [21 22 23 24 25 26 27 28 29]] \n\n[[31 32 33 34 35 36 37 38 39 40 42]\n [41 42 43 44 45 46 47 48 49 50 52]\n [51 52 53 54 55 56 57 58 59 60 62]] \n\n[[61 62 63 64 65 66 67 68 69 70 71]\n [71 72 73 74 75 76 77 78 79 80 81]\n [81 82 83 84 85 86 87 88 89 90 91]] \n```\n\nthis is the part of the code where I work with it\n```\nsedem[1:][sedem[:-1,-1] >= sedem[1:, 0]] += 10\n```\n\ncan it be concatenated so that with each nut the condition does not start from the beginning but continues?\nmy output:\n```\n[[11 12 13 14 15 16 17 18 19]\n [21 22 23 24 25 26 27 28 29]] \n\n[[31 32 33 34 35 36 37 38 39 40 42]\n [51 52 53 54 55 56 57 58 59 60 62]\n [61 62 63 64 65 66 67 68 69 70 72] \n\n[[ 61  62  63  64  65  66  67  68  69  70  71]\n [ 81  82  83  84  85  86  87  88  89  90  91]\n [ 91  92  93  94  95  96  97  98  99 100 101]]\n```\n\nI need\nrequired output:\n```\n[[11 12 13 14 15 16 17 18 19]\n [21 22 23 24 25 26 27 28 29]] \n\n[[31 32 33 34 35 36 37 38 39 40 42]\n [51 52 53 54 55 56 57 58 59 60 62]\n [61 62 63 64 65 66 67 68 69 70 72]] \n\n[[ 71  72  73  74  75  76  77  78  79  80  81]\n [ 91  92  93  94  95  96  97  98  99  100  101]\n [ 111  112  113  114  115  116  117  118  119 120 121]]\n```\n\nI read the values from demofile.txt in the whole code and convert them into arrays and then manipulate them\nI also attach the entire code with comments\nfull code:\n```\nimport os\nimport sys\nimport numpy as np\n     \n\n#read data\nf = open(\"demofile.txt\", \"r\")\nlines = f.readlines()\n#input preprocessing\np=1\nfor i in list(lines):\n    if i[0] != '<' and i[0] != '>' and i[0] != '=':\n        d = str(' '.join(i.split()))\n        print(d)\n            \n    else:\n        w = i.replace(\"=\",'')\n        w = w.replace(\">\",'')\n        w = w.replace(\"<\",'')\n        w = ', '.join(w.split())\n        c=np.array([w])            \n        c1 = [int(i) for i in c[0].replace(\" \", \"\").split(\",\")]\n         #insert input to array\n        c1=np.array(c1)\n        # save first value in array\n        frst=c1[0]\n         #remove first value in array\n        c1=np.delete(c1, 0)       \n        n=len(c1)\n        #multiply array\n        c1=np.array([c1]*frst)\n        #print(c1)       \n        \n        #transpose array\n        c1=np.transpose(c1)\n        #adding a value to each row\n        left = np.array([[(p + j) * 10  for j in range(frst)]] * n) +c1 \n                 \n        left=left*-1\n        sedem=np.transpose(left)*-1\n    \n        \n        #condition\n        sedem[1:][sedem[:-1,-1] >= sedem[1:, 0]] += 10\n        print(sedem,'\\n')\n              \n        p +=frst\n```\n\ndemofile.txt\n```\n<=2 1 2 3 4 5 6 7 8 9  \n<=3 1 2 3 4 5 6 7 8 9 10 12 \n<=3 1 2 3 4 5 6 7 8 9 10 11\n```\n\n    ", "Answer": "\r\nYou just need to merge the lists so that all of the rows are together\n```\nl1 = [[11,12, 13, 14, 15, 16, 17, 18, 19],\n [21, 22, 23, 24, 25, 26, 27, 28, 29]] \n\nl2 = [[31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42],\n [41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52],\n [51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62]] \n\nl3 = [[61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71],\n [71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81],\n [81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91]] \n\nbiglist = l1\nbiglist.extend(l2)\nbiglist.extend(l3)\n\nfor index, item in enumerate(biglist):\n    try:\n        # if last element of l is greater than first element of next row\n        if item[len(item) - 1] > biglist[index + 1][0]:\n            print('adding 10 to row {}'.format(i))\n            biglist[index + 1] = [m + 10 for m in biglist[index + 1]]\n        \n    except IndexError:\n        pass\nbiglist\n```\n\nThis outputs the rows in one big list\n```\nadding 10 to row 7\nadding 10 to row 7\nadding 10 to row 7\nadding 10 to row 7\nadding 10 to row 7\n[[11, 12, 13, 14, 15, 16, 17, 18, 19],\n [21, 22, 23, 24, 25, 26, 27, 28, 29],\n [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42],\n [51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62],\n [61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72],\n [71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81],\n [81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91],\n [91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101]]\n```\n\nIf you needed to keep the separation you could store the lengths of the original lists (l1, l2 and l3) and then split this list based on those lengths.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Calculate population size with multiple sub-annual projection matrices\r\n                \r\nI have a population vector with juveniles and adults that I would like to record new population size after each sub-annual transition. The expected output would have the original population vector on the first row, and population at each following time step at the following row. I've modified the code presented at section 4 here but haven't arrived at what I need https://hankstevens.github.io/Primer-of-Ecology/DID.html The original algorithm use an annual projection matrix and project populations for 8 years.\n```\nA <- matrix(c(0, .3, 2, .7), nrow=2) # spring transition matrix \nB <- matrix(c(0.5, .3, 3, .7), nrow = 2) # summer transition matrix\nC <- matrix(c(0, .3, 4, .7), nrow=2) # fall transition matrix \nD <- matrix(c(0.1, .1, 6, .7), nrow = 2) # winter transition matrix\n\nN0 <- c(Juveniles=1,Adults=10) # initial population\nsteps <- 12 # number of time steps; each chain of 4 time step represent a year\n```\n\nMy rough idea is to record population size at the end of each season on every row of the blank matrix ```\nN```\n.\n```\n# with a column for each stage and a row for each time step\nN <- rbind(N0, matrix(0, ncol=2, nrow=steps) )\n# use a for-loop to project the population each season and store it.\nfor(t in 1:steps) {\n  N[t+1,] <- A%*%N[t,]\n  N[t+2,] <- B%*%A%*%N[t,]\n  N[t+3,] <- C%*%B%*%A%*%N[t,]\n  N[t+4,] <- D%*%C%*%B%*%A%*%N[t,]\nN[t+5,] <- A%*%D%*%C%*%B%*%A%*%N[t,]\n\n}\n```\n\nTo continue, at ```\nN[t+6,]```\n, the population should be ```\nB%*%A%*%D%*%C%*%B%*%A%*%N[t,]```\n, and so on.\nAt this point, I got an error ```\nError in D %*% C : requires numeric/complex matrix/vector arguments```\n, which I don't understand what it means, and why my ```\nN[t+4,]```\n and ```\nN[t+5,]```\n were not calculated despite the supplied formulae.\nHere is an incomplete table of ```\nN[t+i]```\n\n```\nN\n   Juveniles Adults\nN0      1.00 10.000\n       20.00  7.300\n       31.90 11.110\n       44.44 17.347\n        0.00  0.000\n        0.00  0.000\n        0.00  0.000\n        0.00  0.000\n        0.00  0.000\n        0.00  0.000\n        0.00  0.000\n        0.00  0.000\n        0.00  0.000\n```\n\nHow do I change my code so that I don't have to spell out every multiplication chain? Thanks for stopping by my question.\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Freeman Chain Code Infinite Loop [4-adjacency]\r\n                \r\nI am trying to implement Freeman Chain Code [4 adjacency] on matlab using the notation shown in the picture:\n\n\nMy code gives correct chain code for multiple small matrices I tested it with. However I run into an infinite while loop for some connected components when I run the code on my actual image file. By infinite loop I mean, it doesnt loop between just two points, but it keeps on traversing the component without reaching the starting point. \n\nI will explain the approach here.\nMy connected component is of 4 adjacency, and all pixels are marked as \"label\" in the matrix.\nI start from the first top left most pixel (x,y) of the component and traverse using the following rules:\nMy initial traversal (xT,yT) is left to right. horDir = 0, since 0 is for right.\n\n```\nwhile(true)\nif (horDir == 0)\n    go UP, or RIGHT, or DOWN, or LEFT (adjust x,y)\n    if (went LEFT)\n        horDir = 2\nelse\n    go DOWN, or LEFT, or UP, or RIGHT (adjust x,y)\n    if (went LEFT)\n        horDir = 0\nif (xT,yT == x,y)\n    break;\n```\n\n\nWhen i decide to move in any position, I make sure that my last movement was not the opposite of it, to avoid infinite loop. For example, if I reached (x,y) via a 0 movement, my code makes sure that I do a 2 movement after checking 1 and 3 movements, so this is not what causing me to enter an infinite loop I think.\n\nIf there is ambiguity in what I am trying to achieve, I am trying to do this:\n\n\nAny insight would be appreciated.\nI can post my complete code if required, however it would be quite tedious to read.\n    ", "Answer": "\r\nFollow the algorithm as shown in this answer to a somewhat related question, which is further described on my blog here.\n\nIt does 8-connected chain codes, but it’s easy to adapt that code to 4-connected chains.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Monotonicity in Knuth Optimization\r\n                \r\nI'm in the middle of learning what is Knuth Optimization.\n\nThe relevant information can be accessed through here\n\nBasically, there are two assumption in Knuth Optimization.\n\nOne is Quadrangle Inequality and the other is Monotonicity\n\nI can totally understand what is Quadrangle Inequality. However, cause there is no examples explaining about Monotoniciy, I can't get it.\n\nMonotonicity : C[b][c] < C[a][d] (a, b, c, d)\n\nAs far as I know, the Monotonicity is kinda linear feature and if there are two different element(b, c) in between the elements(a, d) outside of them, the cost in range b to c is smaller than the cost in range a to d.\n\nSo why is this not applicable in Chained Matrix Problem? \n\nAssume there is a set of matrix {x1, x2, ..., xn}\n\nObviously the cost of the multiplication in range b to c is smaller than the cost of the multiplication in range a to d cause, there is more element in range a to d than b to c.\n\nCan somebody explain about this?\n    ", "Answer": "\r\nRelative Monotonicity can be in a higher dimensions as well .\nImagine a 2D plane where you hold the bottom right conrener and lift it such that we get ```\nA[i-1][j] <= A[i][j] <= A[i][j+1]```\n.\n\nIf such monotonicity holds then we say that the problem space can be optimized using Knuth Optinimzaton.\nie ```\nF[i][j] = min{F[i][k]+F[k+1][j]}+C[i][j] for k=i to j-1```\n,\nthen it can be optimized by traversing only ```\nfrom k=P[i-1][j] to P[i][j+1]```\n\nwhere ```\nP[i][j]```\n is the point where ```\nA[i][j]```\n is minimum.\n\nOriginal problem need O(n^3) whereas due to the above monotonicity it can now be solved in O(n^2)\n\n(Note: here there is no absolute monotonicity between any two elements, that's why I termed it as relative monotonicity, if two elements are such that one is to the south east of another then the south eastern element is greater than or equal to the other, such relationship is good enough for Knuth Optimization)\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Avoiding upcasting in S4 R class system\r\n                \r\nI'm trying to create implicitly centered/scaled matrices in R using S4 (with a view to doing this for large sparse matrices).\nI can create an implicitly scaled matrix that perform correctly left and right multiplication with a vector:\n```\nN = 500\nP = 100\nX = matrix(runif(N * P), N)\n\nsetClass(\"scaled_matrix\", contains=\"matrix\", slots=c(scale=\"numeric\"))\nsetMethod(\"%*%\", signature(x=\"scaled_matrix\", y=\"numeric\"),\n          function(x, y) x@.Data %*% (y / x@scale))\nsetMethod(\"%*%\", signature(x=\"numeric\", y=\"scaled_matrix\"),\n          function(x, y) (x %*% y@.Data) / y@scale)\n\nget_scaled = function(A) {\n  rmsd = sqrt(apply(A*A, 2, sum)/(nrow(A)-1))\n  new(\"scaled_matrix\", A, scale = rmsd)\n}\n\nX_scaled = get_scaled(X)\nleft_test = runif(N)\nmax(abs(left_test %*% X_scaled - left_test %*% scale(X, center = F))) # small, yay!\nright_test = runif(P)\nmax(abs(X_scaled %*% right_test - scale(X, center = F) %*% right_test )) # small, yay!\n```\n\nAnd an implicitly centered matrix:\n```\nsetClass(\"centered_matrix\", \n         contains=\"matrix\", \n         slots=c(center=\"numeric\"))\nsetMethod(\"%*%\", signature(x=\"centered_matrix\", y=\"numeric\"),\n          function(x, y) (x@.Data %*% y - as.numeric(x@center %*% y)))\nsetMethod(\"%*%\", signature(x=\"numeric\", y=\"centered_matrix\"),\n          function(x, y) (x %*% y@.Data - sum(x) * y@center ))\nget_centered = function(A) {\n  new(\"centered_matrix\", A, center = apply(A, 2, mean))\n}\n\nX_centered = get_centered(X)\nmax(abs(left_test %*% X_centered - left_test %*% scale(X, scale = F))) # small, yay!\nmax(abs(X_centered %*% right_test - scale(X, scale = F) %*% right_test )) # small, yay!\n```\n\nBut what if I want to combine these? I thought the follow would work\n```\nX_centered_scaled = get_scaled(X_centered)\n\nmax(abs(left_test %*% X_centered_scaled - left_test %*% scale(X))) # not small, oh no! \nmax(abs(X_centered_scaled %*% right_test - scale(X) %*% right_test )) # not small, oh no! \n```\n\nFrom what I can tell, the problem is that\n```\nclass(X_centered_scaled@.Data) # should be centered_matrix but is matrix\n```\n\ni.e. when ```\nX_centered_scaled```\n gets created ```\nX_centered```\n gets upcast to a ```\nmatrix```\n instead of remaining a ```\ncentered_matrix```\n. Is there some way I can avoid that happening? Of course I could make a single ```\nmatrix_centered_scaled```\n class but I like the elegance of chaining these two together and it gives the option of just using one or the other.\n    ", "Answer": "\r\nOK I figured this out. Trick is to use an explicit ```\ndata```\n slot and have it be of special class ```\nANY```\n.\n```\n\n\nN = 500\nP = 100\nX = matrix(runif(N * P), N)\n\nsetClass(\"scaled_matrix\", \n         slots=c(data = \"ANY\", scale=\"numeric\"))\nsetMethod(\"%*%\", signature(x=\"scaled_matrix\", y=\"numeric\"),\n          function(x, y) (x@data %*% (y / x@scale)))\nsetMethod(\"%*%\", signature(x=\"numeric\", y=\"scaled_matrix\"),\n          function(x, y) ((x %*% y@data) / y@scale))\n\nget_scaled = function(A, scale = sqrt(apply(A*A, 2, sum)/(nrow(A)-1))) {\n  new(\"scaled_matrix\", data = A, scale = scale)\n}\n\nX_scaled = get_scaled(X)\nleft_test = runif(N)\nmax(abs(left_test %*% X_scaled - left_test %*% scale(X, center = F))) # small, yay!\nright_test = runif(P)\nmax(abs(X_scaled %*% right_test - scale(X, center = F) %*% right_test )) # small, yay!\n\nsetClass(\"centered_matrix\",  \n         slots=c(data = \"ANY\", center=\"numeric\"))\nsetMethod(\"%*%\", signature(x=\"centered_matrix\", y=\"numeric\"),\n          function(x, y) ( x@data %*% y - as.numeric(x@center %*% y)))\nsetMethod(\"%*%\", signature(x=\"numeric\", y=\"centered_matrix\"),\n          function(x, y) (x %*% y@data - sum(x) * y@center ))\nget_centered = function(A) {\n  new(\"centered_matrix\", data = A, center = apply(A, 2, mean))\n}\n\nX_centered = get_centered(X)\nmax(abs(left_test %*% X_centered - left_test %*% scale(X, scale = F))) # small, yay!\nmax(abs(X_centered %*% right_test - scale(X, scale = F) %*% right_test )) # small, yay!\n\nX_centered_scaled = get_scaled(X_centered, scale = apply(X, 2, sd)) # doesnt' work either\n\nmax(abs(left_test %*% X_centered_scaled - left_test %*% scale(X))) # small, yay! \nmax(abs(X_centered_scaled %*% right_test - scale(X) %*% right_test )) # small, yay! \n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Multiple unmatched matrices in backpropagation through time\r\n                \r\nI am going to implement binary addition by Recurrent Neural Network (RNN) as a sample. I have coped with an issue to implement it by Python, so I decided to share my problem in there to come up with ideas to fix it.\n\nAs can be seen in my notebook code (Backpropagation through time (BPTT) section), \nThere is a chain rule like below to update input weight matrix like below:\n\n\n\nMy problem is this part:\n\n\n\nI've tried to implement this part in my Python code or notebook code (```\nclass input_layer```\n, ```\nbackward```\n method), but unmatched dimensions raises an error.\n\nIn my sample code, ```\nW_hidden```\n is ```\n16*16```\n, whereas the result of ```\ndelta pre_hidden```\n is ```\n1*2```\n. This makes the error. If you run the code, you could see the error.\n\nI spent a lot of time to check my chain rule as well as my code. I guess my chain rule is right. Only reason to make this error is my code.\n\nAs I know, multiple unmatched matrices in terms of dimension is impossible. If my chain rule is correct, how it could be implemented by Python?\nAny idea?\n\nThanks in advance.\n    ", "Answer": "\r\nYou need to apply dimension balancing on the gradients. Taken from the Stanford's cs231n course, it comes down to two simple modifications:\n\nGiven , and , we will have:\n\n, \n\nHere is the code I used to ensure the gradient calculation is correct. You should be able to update your code accordingly.\n\n```\nimport torch\n\ntorch.random.manual_seed(0)\n\nx_1, x_2 = torch.zeros(size=(1, 8)).normal_(0, 0.01), torch.zeros(size=(1, 8)).normal_(0, 0.01)\ny = torch.zeros(size=(1, 8)).normal_(0, 0.01)\n\nh_0 = torch.zeros(size=(1, 16)).normal_(0, 0.01)\nweight_ih = torch.zeros(size=(8, 16)).normal_(mean=0, std=0.01).requires_grad_(True)\nweight_hh = torch.zeros(size=(16, 16)).normal_(mean=0, std=0.01).requires_grad_(True)\nweight_ho = torch.zeros(size=(16, 8)).normal_(mean=0, std=0.01).requires_grad_(True)\n\nh_1 = x_1.mm(weight_ih) + h_0.mm(weight_hh)\nh_2 = x_2.mm(weight_ih) + h_1.mm(weight_hh)\ng_2 = h_2.sigmoid()\nj_2 = g_2.mm(weight_ho)\ny_predicted = j_2.sigmoid()\n\nloss = 0.5 * (y - y_predicted).pow(2).sum()\n\nloss.backward()\n\n\ndelta_1 = -1 * (y - y_predicted) * y_predicted * (1 - y_predicted)\ndelta_2 = delta_1.mm(weight_ho.t()) * (g_2 * (1 - g_2))\ndelta_3 = delta_2.mm(weight_hh.t())\n\n# 16 x 8\nweight_ho_grad = g_2.t() * delta_1\n\n# 16 x 16\nweight_hh_grad = h_1.t() * delta_2 + (h_0.t() * delta_3)\n\n# 8 x 16\nweight_ih_grad = x_2.t() * delta_2 + x_1.t() * delta_3\n\natol = 1e-10\nassert torch.allclose(weight_ho.grad, weight_ho_grad, atol=atol)\nassert torch.allclose(weight_hh.grad, weight_hh_grad, atol=atol)\nassert torch.allclose(weight_ih.grad, weight_ih_grad, atol=atol)\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "mice package in R, mipo object does not return variance covariance matrix anymore after updating to mice 3.0\r\n                \r\nMy code stopped working after updating the mice  (Multiple Equations by Chained Equations)  package to version >3. I wish to retrieve the estimated variance-covariance matrix from linear regressions on multiply imputed datasets. This quantity (which mice calls t) could be easily accessed in version 2.46.0 using the pool function. In version >3.0 of mice, the pool function does not return the full variance-covariance matrix anymore, it only returns the diagonal elements of the variance-covariance matrix.\n\nHere is a working example:\n\nFirst create some dataset with missing values:\n\n```\nset.seed(243)\niris$Sepal.Length[sample(length(iris$Sepal.Length), size = 5)] <- NA\niris$Sepal.Width[sample(length(iris$Sepal.Width), size = 5)] <- NA\niris$Petal.Length[sample(length(iris$Petal.Length), size = 5)] <- NA\niris$Species[sample(length(iris$Species), size = 5)] <- NA\n```\n\n\nSecond multiply impute the missing data\n\n```\niris.mi <- mice(iris, 5)\n```\n\n\nThird perform linear regression on each of the multiply imputed dataset, storing results in a mira object \n\n```\nmira.out <- with(iris.mi, lm(Sepal.Width ~ Sepal.Length + Petal.Length + Petal.Width + Species))\n```\n\n\nFourth, pool results from these analyses using Rubin's rules. This is implemented by the pool function in mice.\n\n```\npool.out <- pool(analyses)\n```\n\n\nIn version 2.46.0 of the mice package, one could retrieve the full variance covariance matrix t by typing \n\n```\npool.out$t\n```\n\n\nIn newer versions (>3.0) of the mice package, the pool.out$t object does not exist. All one can do, is retrieve the variances by typing \n\n```\npool.out$pooled\n```\n\n\nand selecting the column labeled t. There seems to be no way of accessing the full variance-covariance matrix. All one has access to are the diagonal elements of the matrix, which are stored in the t column of the pool.out$pooled data.frame.   \n\nI want to access the full variance covariance matrix because I need to calculate marginal effects and confidence intervals for interacted terms in a linear regression with multiply imputed data. These confidence intervals can be approximated by using only the diagonal elements of the variance-covariance matrix, but it would make much better sense to use the full variance-covariance matrix.\n\nI wonder why this change was implemented in the mice package, and how I might be able to access the variance-covariance matrix in the newer versions.\n\nThank you for your help.\n    ", "Answer": "\r\nAs to why it's no longer available, I assume it has something to do with ```\nmice > 3.0```\n depending on ```\nbroom```\n functionality to gather model output. Its vignette (https://cran.r-project.org/web/packages/broom/vignettes/broom.html) states \"The broom package takes the messy output of built-in functions in R, such as lm, nls, or t.test, and turns them into tidy data frames.\" While indeed try, this doesn't easily accommodate the ```\nvcov```\n matrices of the individual models necessary to derive the full matrix ```\nt```\n instead of the currently displayed diagonal of what was previously ```\nt```\n. \n\nAs a work around, you can derive it yourself (see for instance Dong and Peng 2013 http://springerplus.springeropen.com/articles/10.1186/2193-1801-2-222) with the following code (including your example code with some very minor renaming):\n\n```\nset.seed(243)\niris$Sepal.Length[sample(length(iris$Sepal.Length), size = 5)] <- NA\niris$Sepal.Width[sample(length(iris$Sepal.Width), size = 5)] <- NA\niris$Petal.Length[sample(length(iris$Petal.Length), size = 5)] <- NA\niris$Species[sample(length(iris$Species), size = 5)] <- NA\n\niris.mi <- mice(iris, 5)\n\nfit.mi <- with(iris.mi, lm(Sepal.Width ~ Sepal.Length + Petal.Length + Petal.Width + Species))\n\nfil.pooled <- pool(fit.mi)\n\n# get the full matrix ubar (instead of only the diagonal)\nm <- fil.pooled$m\nubar <- Reduce(\"+\", lapply(fit.mi$analyses, vcov)) / (m)\nb <- fil.pooled$pooled$b # this one is still provided by mice\n\n# # or by hand as well\n# qbar <- getqbar(fil.pooled)  # pooled estimates  \n# b <- 1 / (m-1) * rowSums((sapply(fit.mi$analyses, coef) - qbar)^2)\n\nt <- ubar + (1 + 1 / (m)) * b  # this is t as it used to be\n\n# check versus the diagonal of t that is still provided\nall.equal(as.numeric(diag(t)), fil.pooled$pooled$t) # check\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How to optimize pipeline stalls due to L1D Cache Bound code in Haswell for a Matrix-Matrix multiply kernel?\r\n                \r\nI'm trying to optimize several kernels for AVX2 to further my understanding on micro-architectural software optimizations. One of the kernels I am writing is a tiled matrix-matrix multiply. I profiled the execution with Intel VTune and found the code is L1D Cache bound. I did some research on what this means and came across this article from Intel where some possible causes are outlined. After reading the distinct possibilities, I alleviated some of the issues by adding an accumulator to prevent the longer dependency chain. I've peeked into the generated assembly, but I am not too knowledgable in assembly code. \n\nMy implementation performs at roughly 50% the MKL DGEMM performance for the same inputs. This coincides with VTune which indicates 50% performance of the memory pipeline stalls. \n\nThe code spends over 90% of the time in the following kernel:\n\n```\n\n#include <xmmintrin.h> //AVX2\n\n#define MU 16\n#define NU 16\n#define KU 8\n#define MINIMUM(a,b) (((a)<(b))?(a):(b))\n\nstatic inline void tiny_dgemm_ijk(const double* A, const double* B, double *restrict C, const int i, const int j, const int k, const int lda, const int ldb, const int ldc){\n    __m256d cvec1, cvec2, cvec3, cvec4, cvec5, cvec6, cvec7, cvec8;\n    __m256d cvec9, cvec10, cvec11, cvec12, cvec13, cvec14, cvec15, cvec16;\n    __m256d avec1, avec2, avec3, avec4, avec5, avec6, avec7, avec8;\n    __m256d bvec1, bvec2;\n    // Iterate over a chunk of NU columns of C.\n    for (int jjj = 0; (jjj < NU); jjj++){\n        // Load a chunk of C of dimensions 16 by 1\n        cvec1 = _mm256_loadu_pd((__m256d*) (C + i + (jjj+j)*ldc + 0));\n        cvec2 = _mm256_loadu_pd((__m256d*) (C + i + (jjj+j)*ldc + 4));\n        cvec3 = _mm256_loadu_pd((__m256d*) (C + i + (jjj+j)*ldc + 8));\n        cvec4 = _mm256_loadu_pd((__m256d*) (C + i + (jjj+j)*ldc + 12));\n        cvec5 = _mm256_set1_pd(0.0);\n        cvec6 = _mm256_set1_pd(0.0);\n        cvec7 = _mm256_set1_pd(0.0);\n        cvec8 = _mm256_set1_pd(0.0);\n        // Iterate over KU columns of A and rows of B\n        // Perform FMA operation over all 16 rows of A corresponding to the 16 rows of C.\n        for (int kkk = 0; (kkk < KU); kkk+=2){\n            bvec1 = _mm256_set1_pd(B[(kkk + k + 0) + (jjj + j)*ldb]);\n            bvec2 = _mm256_set1_pd(B[(kkk + k + 1) + (jjj + j)*ldb]);\n\n            avec1 = _mm256_loadu_pd((__m256d*) (A + i + (kkk+k)*lda + 0));\n            avec2 = _mm256_loadu_pd((__m256d*) (A + i + (kkk+k)*lda + 4));\n            cvec1 = _mm256_fmadd_pd(avec1, bvec1, cvec1);\n            cvec2 = _mm256_fmadd_pd(avec2, bvec1, cvec2);\n\n            avec3 = _mm256_loadu_pd((__m256d*) (A + i + (kkk+k)*lda + 8));\n            avec4 = _mm256_loadu_pd((__m256d*) (A + i + (kkk+k)*lda + 12));\n            cvec3 = _mm256_fmadd_pd(avec3, bvec1, cvec3);\n            cvec4 = _mm256_fmadd_pd(avec4, bvec1, cvec4);\n\n            avec5 = _mm256_loadu_pd((__m256d*) (A + i + ((kkk+k)+1)*lda + 0));\n            avec6 = _mm256_loadu_pd((__m256d*) (A + i + ((kkk+k)+1)*lda + 4));\n            cvec5 = _mm256_fmadd_pd(avec5, bvec2, cvec5);\n            cvec6 = _mm256_fmadd_pd(avec6, bvec2, cvec6);\n\n            avec7 = _mm256_loadu_pd((__m256d*) (A + i + ((kkk+k)+1)*lda + 8));\n            avec8 = _mm256_loadu_pd((__m256d*) (A + i + ((kkk+k)+1)*lda + 12));\n            cvec7 = _mm256_fmadd_pd(avec7, bvec2, cvec7);\n            cvec8 = _mm256_fmadd_pd(avec8, bvec2, cvec8);\n        }\n        // Write back to C\n        _mm256_storeu_pd((__m256d*) (C + i + (jjj+j)*ldc + 0), _mm256_add_pd(cvec1, cvec5));\n        _mm256_storeu_pd((__m256d*) (C + i + (jjj+j)*ldc + 8), _mm256_add_pd(cvec3, cvec7));\n        _mm256_storeu_pd((__m256d*) (C + i + (jjj+j)*ldc + 4), _mm256_add_pd(cvec2, cvec6));\n        _mm256_storeu_pd((__m256d*) (C + i + (jjj+j)*ldc + 12), _mm256_add_pd(cvec4, cvec8));\n    }\n}\n```\n\n\nFor context, the kernel is called inside the following function,\n\n```\nvoid square_dgemm (const int n, const double* A, const double* B, double *restrict C){\n    for (int j = 0; j < n; j += NU){\n        for (int k = 0; k < n; k += KU){\n            for (int i = 0; i < n; i += MU){\n                if (((i+MU) < n) && ((j+NU) < n) && ((k+KU) < n)){\n                    // Handle core of the GEMM divisible by chunks.\n                    // The remainder of the branches are handled by\n                    // less optimal sections. Over 90% of runtime is\n                    // spent in tiny_dgemm_ijk.\n                    tiny_dgemm_ijk(A, B, C, i, j, k, n, n, n);\n                } else if (((i+MU) < n) && ((k+KU) < n)){\n                   int J = MINIMUM((j+NU), n);\n                   for (int jjj = j; (jjj < J); jjj++){\n                       for (int kkk = 0; (kkk < KU/2); kkk++){\n                           const double bij1 = B[kkk+k+jjj*n];\n                           const double bij2 = B[kkk+k+(KU/2)+jjj*n];\n                           for (int iii = 0; (iii < MU/4); iii++){\n                               C[iii+i+0+(jjj)*n] += A[iii+i+0+(kkk+k)*n] * bij1;\n                               C[iii+i+(MU/4)+0+(jjj)*n] += A[iii+i+(MU/4)+0+(kkk+k)*n] * bij1;\n                               C[iii+i+(MU/2)+0+(jjj)*n] += A[iii+i+(MU/2)+0+(kkk+k)*n] * bij1;\n                               C[iii+i+(3*(MU/4))+0+(jjj)*n] += A[iii+i+(3*(MU/4))+0+(kkk+k)*n] * bij1;\n\n                               C[iii+i+0+(jjj)*n] += A[iii+i+0+(kkk+k+(KU/2))*n] * bij2;\n                               C[iii+i+(MU/4)+0+(jjj)*n] += A[iii+i+(MU/4)+0+(kkk+k+(KU/2))*n] * bij2;\n                               C[iii+i+(MU/2)+0+(jjj)*n] += A[iii+i+(MU/2)+0+(kkk+k+(KU/2))*n] * bij2;\n                               C[iii+i+(3*(MU/4))+0+(jjj)*n] += A[iii+i+(3*(MU/4))+0+(kkk+k+(KU/2))*n] * bij2;\n                           }\n                       }\n                   }\n                } else if ((i+MU) < n) {\n                   int J = MINIMUM((j+NU), n);\n                   int K = MINIMUM((k+KU), n);\n                   for (int jjj = j; (jjj < J); jjj++){\n                       for (int kkk = k; (kkk < K); kkk++){\n                           const double bij1 = B[kkk+jjj*n];\n                           for (int iii = 0; (iii < MU/4); iii++){\n                               C[iii+i+0+(jjj)*n] += A[iii+i+0+(kkk)*n] * bij1;\n                               C[iii+i+(MU/4)+0+(jjj)*n] += A[iii+i+(MU/4)+0+(kkk)*n] * bij1;\n                               C[iii+i+(MU/2)+0+(jjj)*n] += A[iii+i+(MU/2)+0+(kkk)*n] * bij1;\n                               C[iii+i+(3*(MU/4))+0+(jjj)*n] += A[iii+i+(3*(MU/4))+0+(kkk)*n] * bij1;\n                           }\n                       }\n                   }\n                } else {\n                    int J = MINIMUM((j+NU), n);\n                    int K = MINIMUM((k+KU), n);\n                    for (int jjj = j; (jjj < J); jjj++){\n                        for (int kkk = k; (kkk < K); kkk++){\n                            const double bij = B[kkk+jjj*n];\n                            for (int iii = i; (iii < n); iii++){\n                                C[iii+jjj*n] += A[iii+kkk*n] * bij;\n                            }\n                        }\n                    }\n               }\n            }\n        }\n    }\n}\n```\n\n\nI am not an expert in either low-level programming or micro-arch optimizations, but I am certain the data is in L1D cache for the majority of the computation. Are there any obvious causes for high L1D latency? I am compiling using the Intel C Compiler and have tried multiple optimization flag combinations with extremely similar results.\n\nI would greatly appreciate any guidance.\n\nUPDATE\n\nJust in case anyone would like to take a look at the assembly output by ICC, I've extracted the relevant lines (at least that I can tell). \n\n```\n        movslq    %r14d, %r14                                   #51.49\n        xorb      %r9b, %r9b                                    #38.5\n        movl      %esi, 1896(%rsp)                              #[spill]\n        movq      264(%rsp), %rsi                               #[spill]\n        movq      248(%rsp), %rcx                               #[spill]\n        vmovupd   64(%rsi,%r14,8), %ymm15                       #56.49\n        vmovupd   32(%rsi,%r14,8), %ymm12                       #52.49\n        vmovupd   %ymm15, 704(%rsp)                             #56.49[spill]\n        vmovupd   96(%rsi,%r14,8), %ymm15                       #57.49\n        vmovupd   %ymm12, 1120(%rsp)                            #38.5[spill]\n        vmovupd   %ymm15, 672(%rsp)                             #57.49[spill]\n        vmovupd   (%rcx,%r14,8), %ymm15                         #61.49\n        vmovupd   %ymm15, 640(%rsp)                             #61.49[spill]\n        vmovupd   32(%rcx,%r14,8), %ymm15                       #62.49\n        movl      %edi, 2056(%rsp)                              #[spill]\n        movq      216(%rsp), %r12                               #[spill]\n        movq      224(%rsp), %r11                               #[spill]\n        movq      240(%rsp), %rdi                               #[spill]\n        vmovupd   %ymm15, 608(%rsp)                             #62.49[spill]\n        vmovupd   96(%rdi,%r14,8), %ymm13                       #67.49\n        vmovupd   32(%r11,%r14,8), %ymm14                       #62.49\n        vmovupd   64(%r11,%r14,8), %ymm7                        #66.49\n        vmovupd   96(%r11,%r14,8), %ymm8                        #67.49\n        vmovupd   (%r12,%r14,8), %ymm9                          #51.49\n        vmovupd   96(%r12,%r14,8), %ymm10                       #57.49\n        vmovupd   64(%rcx,%r14,8), %ymm15                       #66.49\n        vmovupd   (%rdi,%r14,8), %ymm2                          #61.49\n        vmovupd   32(%rdi,%r14,8), %ymm3                        #62.49\n        vmovupd   64(%rdi,%r14,8), %ymm4                        #66.49\n        vmovupd   %ymm13, 544(%rsp)                             #67.49[spill]\n        vmovupd   %ymm14, 736(%rsp)                             #62.49[spill]\n        vmovupd   %ymm7, 768(%rsp)                              #66.49[spill]\n        vmovupd   %ymm8, 800(%rsp)                              #67.49[spill]\n        vmovupd   %ymm9, 832(%rsp)                              #51.49[spill]\n        vmovupd   %ymm10, 864(%rsp)                             #57.49[spill]\n        vmovupd   %ymm15, 576(%rsp)                             #66.49[spill]\n        vmovupd   32(%r12,%r14,8), %ymm14                       #52.49\n        vmovupd   64(%r12,%r14,8), %ymm13                       #56.49\n        vmovupd   (%rsi,%r14,8), %ymm7                          #51.49\n        vmovupd   %ymm2, 448(%rsp)                              #61.49[spill]\n        vmovupd   96(%rcx,%r14,8), %ymm15                       #67.49\n        vmovupd   %ymm3, 480(%rsp)                              #62.49[spill]\n        vmovupd   %ymm4, 512(%rsp)                              #66.49[spill]\n        vmovupd   %ymm7, 1088(%rsp)                             #38.5[spill]\n        vmovupd   %ymm13, 928(%rsp)                             #38.5[spill]\n        vmovupd   %ymm15, 352(%rsp)                             #67.49[spill]\n        vmovupd   %ymm14, 896(%rsp)                             #38.5[spill]\n        movl      %ebx, 344(%rsp)                               #[spill]\n        movq      256(%rsp), %rbx                               #[spill]\n        movq      208(%rsp), %r13                               #[spill]\n        vmovupd   64(%rbx,%r14,8), %ymm0                        #56.49\n        vmovupd   96(%rbx,%r14,8), %ymm1                        #57.49\n        vmovupd   (%r13,%r14,8), %ymm11                         #61.49\n        vmovupd   32(%r13,%r14,8), %ymm10                       #62.49\n        vmovupd   64(%r13,%r14,8), %ymm9                        #66.49\n        vmovupd   96(%r13,%r14,8), %ymm8                        #67.49\n        vmovupd   (%rbx,%r14,8), %ymm6                          #51.49\n        vmovupd   32(%rbx,%r14,8), %ymm5                        #52.49\n        vmovupd   %ymm0, 384(%rsp)                              #56.49[spill]\n        vmovupd   %ymm1, 416(%rsp)                              #57.49[spill]\n        vmovupd   (%r11,%r14,8), %ymm0                          #61.49\n        vmovupd   %ymm8, 1056(%rsp)                             #38.5[spill]\n        vmovupd   %ymm9, 1024(%rsp)                             #38.5[spill]\n        vmovupd   %ymm10, 992(%rsp)                             #38.5[spill]\n        vmovupd   %ymm11, 960(%rsp)                             #38.5[spill]\n        movq      232(%rsp), %r15                               #[spill]\n        movq      1976(%rsp), %r8                               #[spill]\n        movl      %edx, 1888(%rsp)                              #[spill]\n        movl      %r10d, 1200(%rsp)                             #[spill]\n        lea       (%r8,%r14,8), %r10                            #39.45\n        movl      %eax, 1208(%rsp)                              #[spill]\n        xorl      %eax, %eax                                    #38.5\n        movl      272(%rsp), %edx                               #[spill]\n        movl      344(%rsp), %ebx                               #38.5[spill]\n        movl      1896(%rsp), %esi                              #38.5[spill]\n        movl      1936(%rsp), %r12d                             #38.5[spill]\n        movl      2024(%rsp), %r8d                              #38.5[spill]\n        movl      1904(%rsp), %ecx                              #38.5[spill]\n        movl      2056(%rsp), %edi                              #38.5[spill]\n        movq      1968(%rsp), %r13                              #38.5[spill]\n        vmovupd   (%r15,%r14,8), %ymm4                          #51.49\n        vmovupd   32(%r15,%r14,8), %ymm3                        #52.49\n        vmovupd   64(%r15,%r14,8), %ymm2                        #56.49\n        vmovupd   96(%r15,%r14,8), %ymm1                        #57.49\n                                # LOE r10 r13 eax edx ecx ebx esi edi r8d r12d r14d r9b ymm0 ymm1 ymm2 ymm3 ymm4 ymm5 ymm6\nL_B1.15:                        # Preds L_B1.15 L_B1.14\n                                # Execution count [1.10e+02]\n        vmovupd   416(%rsp), %ymm8                              #59.21[spill]\n        lea       (%r12,%rax), %r11d                            #39.61\n        movslq    %r11d, %r11                                   #39.61\n        lea       (%rdx,%rax), %r15d                            #48.64\n        movslq    %r15d, %r15                                   #48.64\n        incb      %r9b                                          #38.5\n        addl      %edi, %eax                                    #38.5\n        vmovupd   64(%r10,%r11,8), %ymm12                       #45.45\n        vmovupd   (%r10,%r11,8), %ymm14                         #39.45\n        vmovupd   32(%r10,%r11,8), %ymm13                       #44.45\n        vbroadcastsd (%r13,%r15,8), %ymm15                      #48.21\n        vbroadcastsd 8(%r13,%r15,8), %ymm7                      #49.21\n        vfmadd231pd 384(%rsp), %ymm15, %ymm12                   #58.21[spill]\n        vfmadd231pd %ymm15, %ymm6, %ymm14                       #53.21\n        vfmadd231pd %ymm15, %ymm5, %ymm13                       #54.21\n        vfmadd213pd 96(%r10,%r11,8), %ymm8, %ymm15              #59.21\n        vmulpd    448(%rsp), %ymm7, %ymm9                       #63.21[spill]\n        vmulpd    480(%rsp), %ymm7, %ymm10                      #64.21[spill]\n        vmulpd    512(%rsp), %ymm7, %ymm11                      #68.21[spill]\n        vmulpd    544(%rsp), %ymm7, %ymm8                       #69.21[spill]\n        vbroadcastsd 16(%r13,%r15,8), %ymm7                     #48.21\n        vfmadd231pd %ymm4, %ymm7, %ymm14                        #53.21\n        vfmadd231pd %ymm3, %ymm7, %ymm13                        #54.21\n        vfmadd231pd %ymm2, %ymm7, %ymm12                        #58.21\n        vfmadd231pd %ymm1, %ymm7, %ymm15                        #59.21\n        vbroadcastsd 24(%r13,%r15,8), %ymm7                     #49.21\n        vfmadd231pd 736(%rsp), %ymm7, %ymm10                    #64.21[spill]\n        vfmadd231pd 768(%rsp), %ymm7, %ymm11                    #68.21[spill]\n        vfmadd231pd 800(%rsp), %ymm7, %ymm8                     #69.21[spill]\n        vfmadd231pd %ymm0, %ymm7, %ymm9                         #63.21\n        vbroadcastsd 32(%r13,%r15,8), %ymm7                     #48.21\n        vfmadd231pd 832(%rsp), %ymm7, %ymm14                    #53.21[spill]\n        vfmadd231pd 896(%rsp), %ymm7, %ymm13                    #54.21[spill]\n        vfmadd231pd 928(%rsp), %ymm7, %ymm12                    #58.21[spill]\n        vfmadd231pd 864(%rsp), %ymm7, %ymm15                    #59.21[spill]\n        vbroadcastsd 40(%r13,%r15,8), %ymm7                     #49.21\n        vfmadd231pd 960(%rsp), %ymm7, %ymm9                     #63.21[spill]\n        vfmadd231pd 992(%rsp), %ymm7, %ymm10                    #64.21[spill]\n        vfmadd231pd 1024(%rsp), %ymm7, %ymm11                   #68.21[spill]\n        vfmadd231pd 1056(%rsp), %ymm7, %ymm8                    #69.21[spill]\n        vbroadcastsd 48(%r13,%r15,8), %ymm7                     #48.21\n        vfmadd231pd 1088(%rsp), %ymm7, %ymm14                   #53.21[spill]\n        vfmadd231pd 1120(%rsp), %ymm7, %ymm13                   #54.21[spill]\n        vfmadd231pd 704(%rsp), %ymm7, %ymm12                    #58.21[spill]\n        vfmadd231pd 672(%rsp), %ymm7, %ymm15                    #59.21[spill]\n        vbroadcastsd 56(%r13,%r15,8), %ymm7                     #49.21\n        vfmadd231pd 640(%rsp), %ymm7, %ymm9                     #63.21[spill]\n        vfmadd231pd 608(%rsp), %ymm7, %ymm10                    #64.21[spill]\n        vfmadd231pd 576(%rsp), %ymm7, %ymm11                    #68.21[spill]\n        vfmadd231pd 352(%rsp), %ymm7, %ymm8                     #69.21[spill]\n        vaddpd    %ymm9, %ymm14, %ymm9                          #72.64\n        vaddpd    %ymm10, %ymm13, %ymm10                        #74.64\n        vaddpd    %ymm11, %ymm12, %ymm11                        #73.64\n        vaddpd    %ymm8, %ymm15, %ymm12                         #75.65\n        vmovupd   %ymm9, (%r10,%r11,8)                          #72.38\n        vmovupd   %ymm10, 32(%r10,%r11,8)                       #74.38\n        vmovupd   %ymm11, 64(%r10,%r11,8)                       #73.38\n        vmovupd   %ymm12, 96(%r10,%r11,8)                       #75.38\n        cmpb      $16, %r9b                                     #38.5\n        jb        L_B1.15       # Prob 93%                      #38.5\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Can Google Maps API calculate route along multiple locations or journey legs?\r\n                \r\nI'm using the Google Maps API Web Services Directions API or the Distance Matrix API to find the travel distance and time between locations.\n\nIt seems that the API only supports calculation of the route between one origin and one destination. (In case of the Distance Matrix API, multiple combinations directly between origins and destinations are computed.)\n\nMy case is that I would like to know the route (really, just traveling time and distance) of a multiple-leg journey along a series (as in an ordered array) of locations.\n\nSo, considering four locations, ```\nA```\n, ```\nB```\n, ```\nC```\n, ```\nD```\n, I know how to compute the route between any pair, ```\nA-B```\n, ```\nA-C```\n, ```\nA-D```\n, ```\nB-C```\n and so on. I want to compute the route of ```\nA-B-C-D```\n or ```\nA-C-D-B```\n or ```\nA-D-B-C```\nand so on. I supply the route and the order of the legs, so I'm not asking to solve the Traveling Salesman Problem.\n\nIs this possible with the Google Maps Directions API or Distance Matrix API?\n\nObviously, I can chain the locations myself, so ask for the routes of the individual legs in separate calls, and then add them together in the desired order: ```\nA-C```\n + ```\nC-D```\n + ```\nD-B```\n becomes ```\nA-C-D-B```\n. I'm hoping that it's possible with one call.\n\n(I've looked for similar questions, but haven't found this exact one.)\n    ", "Answer": "\r\nThanks to @geocodezip, the answer is to add 'waypoints' between the origin and the destination, as described in the documentation of the Directions API.\n\nFor example, the request ```\nhttps://maps.googleapis.com/maps/api/directions/json?origin=Boston,MA&destination=Concord,MA&waypoints=Charlestown,MA|Lexington,MA```\n calculates the route between Boston and Concord via Charlestown and Lexington.\n\nAnd the Traveling Salesman Problem is partly being solved as well, per\n\n\n  By default, the Directions service calculates a route through the provided waypoints in their given order. Optionally, you may pass ```\noptimize:true```\n as the first argument within the waypoints parameter to allow the Directions service to optimize the provided route by rearranging the waypoints in a more efficient order.\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Value Error : could not broadcast input array from shape (3,) into shape (3,1)\r\n                \r\n```\nclass ForwardKinematicsAgent(PostureRecognitionAgent):\n    def __init__(self, simspark_ip='localhost',\n                 simspark_port=3100,\n                 teamname='DAInamite',\n                 player_id=0,\n                 sync_mode=True):\n        super(ForwardKinematicsAgent, self).__init__(simspark_ip, simspark_port, teamname, player_id, sync_mode)\n        self.transforms = {n: identity(4) for n in self.joint_names}\n\n        # chains defines the name of chain and joints of the chain\n        self.chains = {'Head': ['HeadYaw', 'HeadPitch'],\n                       'LArm': ['LShoulderPitch']}\n        \n        self.link_translation = {'HeadYaw': [0., 0., 126.50], 'HeadPitch':  [0., 0., 0.], 'LShoulderPitch': [0., 98., 100.]}\n\n    def think(self, perception):\n        self.forward_kinematics(perception.joint)\n        return super(ForwardKinematicsAgent, self).think(perception)\n\n    def local_trans(self, joint_name, joint_angle):\n        '''calculate local transformation of one joint\n\n        :param str joint_name: the name of joint\n        :param float joint_angle: the angle of joint in radians\n        :return: transformation\n        :rtype: 4x4 matrix\n        '''\n        T = identity(4)\n        c = cos(joint_angle)\n        s = sin(joint_angle)\n        if(joint_name.find('Roll') != -1):                #find returns index of searched string or -1 if not found\n            R = matrix([[1, 0, 0], [0,c,-s], [0, s, c]])  #if we have roll we have Rx matrix\n        if(joint_name.find('Pitch') != -1):    \n            R = matrix([[c, 0, s], [0, 1, 0], [-s, 0, c]]) #pitch -> Ry\n        if(joint_name.find('Yaw') != -1):\n            R = matrix([[c, s, 0], [-s, c, 0], [0, 0, 1]]) #Yaw -> Rz\n\n        T[0:3, 0:3] = R  #insert appropriate rotation matrix in top left of transform matrix\n        T[0:3, 3] = self.link_translation[joint_name] #insert the spatial translation of the link in 4th colum of the T-matrix\n        return T\n\n    def forward_kinematics(self, joints):\n        '''forward kinematics\n\n        :param joints: {joint_name: joint_angle}\n        '''\n        for chain_joints in self.chains.values():\n            T = identity(4)\n            for joint in chain_joints:\n                angle = joints[joint]\n                Tl = self.local_trans(joint, angle)\n                T = T * Tl              #matrix multiplication T0_N = T0_1 * T1_2 * T1_3 etc\n                self.transforms[joint] = T\n```\n\nI am simply trying to replace the three first elements of the 4th column of a 4x4 identity matrix,\nbut the line ```\n  T[0:3, 3] = self.link_translation[joint_name]```\n gives me the error in the title.\nI don't understand why this line doesn't work because I'm trying to replace 3 elements of a list by 3 elements of another list and in fact when I try just the line ```\n  T[0:3, 3] = [0,1,2]```\n in a new program it works. So I don't think it is a syntax error\nPS : I took out most of the elements of self.chains and self.link_translations because they made it all unreadable and aren't part of the problem I thinl\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "CGAffineTransform operations inconsistency in order applied\r\n                \r\nI am trying to understand the results of chaining two transformations using CGAffineTransform in iOS. Based on Apple's documentation, combining translation and scaling is working as expected, but combining translation and rotation is not.\n\nI think the question in this post was onto the same observation, but I am combining translation with scaling to show the inconsistent behavior. Or is there some consistent way to understand what order the transformations will take place using these methods?\n\nApple's CGAffineTransform documentation shows transforming a point, represented by a row vector ```\n[x y 1]```\n, by multiplying on the right by a matrix. To use the notation used in the CGAffineTransform header file, this matrix is ```\n[a b c d tx ty]```\n (because the last column is always the transpose of ```\n[0 0 1]```\n). Because the matrix is on the right of the row vector, if we have two CGAffineTransform matrices ```\nA```\n and ```\nB```\n, the product ```\nAB```\n applied to a point will first apply the transformation ```\nA```\n and then apply the operation ```\nB```\n (which is opposite of what typical linear algebra books do).\n\nUsing a translation transform ```\nt```\n, a scaling transformation ```\ns```\n, and a rotation transform ```\nr```\n, I have examined the resulting transforms and their effects on views for the following:\n\n```\n s.translatedBy(x: 100, y: 0) // translates first, then scales\n s.concatenating(t) // scales first, then translates\n t.rotated(by: 45 * .pi/180) // translates first, then rotates\n t.concatenating(r) // rotates first, then translates\n```\n\n\nI understand that ```\nconcatenating```\n will perform in the reverse order as you see when performing an operation such as ```\ntranslatedBy```\n. But, per concatenating: documentation, ```\nA.concatenatig(B)```\n should give the transformation ```\nAB```\n, which as noted above performs transformation ```\nA```\n followed by ```\nB```\n. That indeed happens on ```\ns.concatenating(t)```\n, but not ```\nt.concatenating(r)```\n. Based on the example in Matt's iOS book, here is some code to setup.\n\n```\n let v1 = UIView(frame:CGRect(20, 111, 132, 194))\n v1.backgroundColor = .red\n view.addSubview(v1)\n\n let v2 = UIView(frame:v1.bounds)\n v2.backgroundColor = .green\n v1.addSubview(v2)\n\n let v3 = UIView(frame: v1.bounds)\n v3.backgroundColor = .blue\n v1.addSubview(v3)\n\n let t = CGAffineTransform(translationX:100, y:0)\n let r = CGAffineTransform(rotationAngle: 45 * .pi/180)\n let s = CGAffineTransform(scaleX: 0.1, y: 0.1)\n```\n\n\nThen you can add this code to see that translating and scaling works as expected:\n\n```\n // translates first, then scales\n v2.transform = s.translatedBy(x: 100, y: 0)\n // scales first, then translates\n v3.transform = s.concatenating(t)\n```\n\n\nGreen v2 translates 100 to the right and then is scaled by .1, where blue v3 is scaled by .1 and then translated 100 to the right\n\nHowever, the behavior for translating and rotating is different:\n\n```\n // translates first, then rotates\n v2.transform = t.rotated(by: 45 * .pi/180)\n // rotates first, then translates\n v3.transform = t.concatenating(r)\n```\n\n\nGreen v2 is translated first and then rotated by 45 degrees, where as blue v3 is rotated first and then translated\n\nFurthermore, the header doc information for ```\nrotated```\n shows \n\n```\nRotate t by angle radians and return the result:\n         t =  [ cos(angle) sin(angle) -sin(angle) cos(angle) 0 0 ] * t\n```\n\n\nThe multiplication should imply the rotation happens first, but the wording makes it seem that the rotation is second. Based on the results above, the wording correct (rotation is second).\n\nThe header doc for ```\ntranslatedBy```\n also has wording for translation being second and the matrix multiplication showing the translation is first. But based on the results above, the matrix multiplication is correct (translation is first).\n\nAm I making a mistake in this analysis? Or is there some inconsistency in the order of transformations based on concatenation and the descriptions in the documentation for these transformation and concatenating methods.\n    ", "Answer": "\r\nThe problem is that you have misinterpreted the first diagram: \n\n\n\nYou say:\n\n\n  Green v2 translates 100 to the right and then is scaled by .1, where blue v3 is scaled by .1 and then translated 100 to the right\n\n\nNo. Your words are backwards from what the diagram actually shows.\n\nRemember, a transform takes place around a view’s center. Ok, so why is the green view only a tiny bit to the right of its original center?\n\nIt’s because  first we scaled down to the center and then we moved 10 points right — 10 points because the meaning of a point has first been scaled down to 1/10 of a normal point. \n\nBut the blue view is a full 100 points right of its original center, because it translated that 100 points before scaling down. \n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Hittest using screen coordinates in SVG images in World coordinates\r\n                \r\nHow do I translate mouse coordinates into world coordinates using GDI+?\nOr get bounding boxes (or even better) old skool regions for SVG shapes drawn using GDI+?\n\nAnyway. I've been looking for SVG code and found:\nhttp://development.mwcs.de/svgimage.html\nThis is the first Delphi component that actually works for SVG, but I digress.\n\nThis component uses GDI+ to display circles, curves etc.\nGDI+ uses matrixes to convert world coordinates, rotations and distortions into screen coordinates.\nThis part I understand. You use matrix multiplication to do the translation.\n\nThe problem is this\nIf I point my mouse cursor over a closed shape:\n\n\nWhere do I get the matrix from that will translate my screen-point of my mouse to a world point that I can hittest into the circle that I see drawn on the screen?\nThere are soo many matrixes to choose from in all those GDI objects.\nPlease don't give me stuff about drawing to a bitmap and testing for magic colors under the cursor, this is not what I'm looking for.\nIf there is a chain of matrixes, how do I traverse them in the correct (inverted?) order so that my screen coordinate gets guided correctly to the world coordinate?\n\n\nIn other words\nThe shapes that are read in from an SVG image are primitives that get distorted by matrixes into screen-coordinates. \nHow do I do the reverse from a screen coordinate into the coordinates that I can use to see if I'm inside a shape or not.\n\nplease note \nI need to know which shape I am in.\nBecause of the way the SVG image is set up, each shape has an id, and I want to use that to see what region I have hit with my mouse. \n\nEDIT\n\nAlternatively\n\n\nCan I get a bounding rect per shape in screen coordinates so I can check my mouse coordinates against that.\nCan I get a old skool GDI region where I can do a PtInRegion with in screen coordinates.\n\n\nHope you can help me find my way with all these distorted paths :-).\n    ", "Answer": "\r\nI didn't dug into code, but I can help a little with matrices (point 3).\n\nI guess, that the three basic transformation matrices are used: the rotation, scale and translation matrix. Let's call them R, S and T, respectively.\n\nThere's a tricky part about applying matrices to the point. Say, you want to translate the point, and then rotate around the center of origin. In other words, you want to apply the rotation to the effect of the translation of the point. So, matrices will be applied in the following way:\n\nR(T(P)) = R * T * P = S\n\nWhere * is the matrix multiplication. Note, that the order of multiplied matrices is reversed in relation to your intent.\n\nHowever, if you want to make the inverse transformation, apart from reversing the order of matrices, you also have to evaluate their inverses. We translated the point, then rotated - so now we shall rotate it back and then translate back:\n\nT^-1 ( R^-1 (S)) = T^-1 * R^-1 * S = P\n\nPlease note, that you don't have to calculate each matrice's inverse, as obviously T^-1(x) = T(-x), R^-1(angle) = R(-angle) and so on. You would have to deduce the transformation's argument, however, which may not be easy if you have access only to the transformation matrix.\n\nI'd guess, that world coordinates are converted to screen coordinates by a combination of translate and scale matrix. The last one is responsible for \"changing the unit\" from world coordinates to pixels in respect to zoom factor of the whole scene (and, possibly, DPI of the display). The translation matrix, on the other hand, reflects the scene panning and may be applied either before or after the scale matrix; in the first case the panning is stored in world coordinates, in the second - panning is stored in screen coordinates.\n\nI would also guess, that all the object transformations are being done in the world coordinates (it sounds more convenient to me than doing so in screen coordinates). So, you may expect, that each object's point is subjected to following transformation:\n\nW(S(R(T(P)))) = W * S * R * T * P,\n\nwhere W is the World-to-screen transformation, S is scale, R is rotation and T is translation.\n\nHope I helped at least a little...\n\n\n\nUpdated 17-04-2011\n\nOk, I've looked inside the code now. The PaintTo method of SVG object looks like this:\n\n```\nprocedure TSVG.PaintTo(Graphics: TGPGraphics; Bounds: TGPRectF;\n  Rects: PRectArray; RectCount: Integer);\nvar \n  M: TGPMatrix;\n  MA: TMatrixArray;\nbegin\n  M := TGPMatrix.Create;\n  try\n    Graphics.GetTransform(M);\n    try\n      M.GetElements(MA);\n\n      FInitialMatrix.Cells[0, 0] := MA[0];\n      FInitialMatrix.Cells[0, 1] := MA[1];\n      FInitialMatrix.Cells[1, 0] := MA[2];\n      FInitialMatrix.Cells[1, 1] := MA[3];\n      FInitialMatrix.Cells[2, 0] := MA[4];\n      FInitialMatrix.Cells[2, 1] := MA[5];\n      FInitialMatrix.Cells[2, 2] := 1;\n\n      SetBounds(Bounds);\n\n      Paint(Graphics, Rects, RectCount);\n    finally\n      Graphics.SetTransform(M);\n    end;\n  finally\n    M.Free;\n  end;\nend;\n```\n\n\nPrior to any drawing, the method calls Graphics.GetTransform(M). This one, in turn, calls GdipGetWorldTransform, which appears to be a wrapper function on WinAPI's GetWorldTransform.\n\nI guess, that it might be a good place to start :)\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Assessing performance of a zero inflated negative binomial model\r\n                \r\nI am modelling the diffusion of movies through a contact network (based on telephone data) using a zero inflated negative binomial model (package: pscl)\n\n```\nm1 <- zeroinfl(LENGTH_OF_DIFF ~ ., data = trainData, type = \"negbin\")\n```\n\n\n(variables described below.)\nThe next step is to evaluate the performance of the model. \n\nMy attempt has been to do multiple out-of-sample predictions and calculate the MSE.\n\nUsing\n\n```\npredict(m1, newdata = testData)\n```\n\n\nI received a prediction for the mean length of a diffusion chain for each datapoint, and using\n\n```\npredict(m1, newdata = testData, type = \"prob\")\n```\n\n\nI received a matrix containing the probability of each datapoint being a certain length.\n\nProblem with the evaluation: Since I have a 0 (and 1) inflated dataset, the model would be correct most of the time if it predicted 0 for all the values. The predictions I receive are good for chains of length zero (according to the MSE), but the deviation between the predicted and the true value for chains of length 1 or larger is substantial. \n\nMy question is: \n\n\nHow can we assess how well our model predicts chains of non-zero length? \nIs this approach the correct way to make predictions from a zero inflated negative binomial model?\n\nIf yes: how do I interpret these results?\nIf no: what alternative can I use?\n\n\n\n\n\nMy variables are:\n\n\nDependent variable: \n\nlength of the diffusion chain (count [0,36])\n\nIndependent variables:\n\nmovie characteristics (both dummies and continuous variables).\n\n\n\n\nThanks!\n    ", "Answer": "\r\nIt is straightforward to evaluate RMSPE (root mean square predictive error), but is probably best to transform your counts beforehand, to ensure that the really big counts do not dominate this sum.\n\nYou may find false negative and false positive error rates (FNR and FPR) to be useful here. FNR is the chance that a chain of actual non-zero length is predicted to have zero length (i.e. absence, also known as negative). FPR is the chance that a chain of actual zero length is falsely predicted to have non-zero (i.e. positive) length. I suggest doing a Google on these terms to find a paper in your favourite quantitative journals or a chapter in a book that helps explain these simply. For ecologists I tend to go back to Fielding & Bell (1997, Environmental Conservation).\nFirst, let's define a repeatable example, that anyone can use (not sure where your trainData comes from). This is from help on zeroinfl function in the pscl library:\n\n```\n    # an example from help on zeroinfl function in pscl library\n    library(pscl)\n    fm_zinb2 <- zeroinfl(art ~ . | ., data = bioChemists, dist = \"negbin\")\n```\n\n\nThere are several packages in R that calculate these. But here's the by hand approach. First calculate observed and predicted values.\n\n```\n    # store observed values, and determine how many are nonzero\n    obs <- bioChemists$art\n    obs.nonzero <- obs > 0\n    table(obs)\n    table(obs.nonzero)\n\n    # calculate predicted counts, and check their distribution\n    preds.count <- predict(fm_zinb2, type=\"response\")\n    plot(density(preds.count))\n\n    # also the predicted probability that each item is nonzero\n    preds <- 1-predict(fm_zinb2, type = \"prob\")[,1]\n    preds.nonzero <- preds > 0.5\n    plot(density(preds))\n    table(preds.nonzero)\n```\n\n\nThen get the confusion matrix (basis of FNR, FPR)\n\n```\n    # the confusion matrix is obtained by tabulating the dichotomized observations and predictions\n    confusion.matrix <- table(preds.nonzero, obs.nonzero)\n    FNR <- confusion.matrix[2,1] / sum(confusion.matrix[,1])\n    FNR\n```\n\n\nIn terms of calibration we can do it visually or via calibration\n\n```\n    # let's look at how well the counts are being predicted\n    library(ggplot2)\n    output <- as.data.frame(list(preds.count=preds.count, obs=obs))\n    ggplot(aes(x=obs, y=preds.count), data=output) + geom_point(alpha=0.3) + geom_smooth(col=\"aqua\")\n```\n\n\nTransforming the counts to \"see\" what is going on:\n\n```\n    output$log.obs <- log(output$obs)\n    output$log.preds.count <- log(output$preds.count)\n    ggplot(aes(x=log.obs, y=log.preds.count), data=output[!is.na(output$log.obs) & !is.na(output$log.preds.count),]) + geom_jitter(alpha=0.3, width=.15, size=2) + geom_smooth(col=\"blue\") + labs(x=\"Observed count (non-zero, natural logarithm)\", y=\"Predicted count (non-zero, natural logarithm)\")\n```\n\n\nIn your case you could also evaluate the correlations, between the predicted counts and the actual counts, either including or excluding the zeros.  \n\nSo you could fit a regression as a kind of calibration to evaluate this!\nHowever, since the predictions are not necessarily counts, we can't use a poisson\nregression, so instead we can use a lognormal, by regressing the log \nprediction against the log observed, assuming a Normal response.\n\n```\n    calibrate <- lm(log(preds.count) ~ log(obs), data=output[output$obs!=0 & output$preds.count!=0,])\n    summary(calibrate)\n    sigma <- summary(calibrate)$sigma\n    sigma\n```\n\n\nThere are more fancy ways of assessing calibration I suppose, as in any modelling exercise ... but this is a start.\n\nFor a more advanced assessment of zero-inflated models, check out the ways in which the log likelihood can be used, in the references provided for the zeroinfl function. This requires a bit of finesse.  \n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Longest unique chains in a graph with edges that follow some criteria\r\n                \r\nProblem\nThis is a portion of a graph I ended up with in a problem I am trying to solve. For illustration purposes this will do -\n\nThe red line marks the a chain where all the edges have a weight that obeys a criterion (in this case: 60<weight<90)\nI want to find all such chains in a graph like this. As an example, if the weight condition was - 105<weight<205 then all the chains I would want to find would be like this-\n\nEdit This might be a clear mathematical statement of the problem\n\nMy Attempts\n1\nThe gist of my naive approach was to -\n\nloop through each vertex\nloop through all of the edges and see if any of them fall within the criterion\nIf any of them are yes, initiate a \"chain\" array which stores the current vertex\nGo to the other end of this edge and repeat steps 2-4\nIf we reach a vertex where none of the edges fall within the criterion, stop the search\nContinue step 2 from the previous vertex ignoring the edges that have been checked.\nJoin chains together if there are any common vertices (split each chain at the common vertex and join the first part of the first chain with the second part of the second chain and the first part of the second chain to the second part of the first chain) (A->B->C->D and E->C->F will produce two new chains A->B->C->F and E->C->D)\nRemove any redundancy like subchains saved as separate chains\n\nI tried doing this in MATLAB, and it was taking an absurdly long time for my dataset of >5000 vertices. Since this looks like it might go to O(n4), I wasn't very surprised.\n\n2\nI tried to transform it into some other problem and see if a solution existed but I couldn't figure that out. This might become like a multiple travelling salesman problem if instead of finding the shortest path I need to follow these criteria-\n\nYou can only give each of them a fixed gas allowance per day thus limiting the distance they can travel in a day (Edge weight must follow some criteria)\nThey do not need to return to the starting city (only chains)\nMultiple salesmen visiting the same city is okay, more profit (multiple paths overlapping in part is allowed)\n\nThen I could make a subgraph by removing all the edges (below, for example-2) that do not follow the criteria and then I would try to find the shortest distance in each maximally connected subgraph but I don't think this approach makes a lot of sense.\n\n\n3\nAnother idea I had was that in these maximally connected subgraphs, I could also try constructing the MST for each of them and then traverse from each leaf node to every other leaf node. I haven't been able to fully implement it correctly yet, but it still seems like it might have a really bad worst-case complexity.\n\n4\nI also tried to look for patterns in the adjacency matrix but I couldn't identify any.\n\n5\nIn hopes of again transforming it into a different problem, I also tried changing the vertices into edges and edges into vertices giving me a graph looking like this (red line marks the same path as example 1) -\n\nThis just seems to make the problem more complicated.\n\nThose are all of the things I have attempted. I don't know much about graph theory, so this might be a simple, well-established problem that I just don't know how to look for. Any help is appreciated.\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How computational expensive is running data through a Neural Network? Can Smartphones or Raspberry PIs do it?\r\n                \r\nI have only little background knowledge about Neural Networks (NN).\nHowever, up to know I learnt, that training the network is the actual expensive part. Processing data by an already trained network is much cheaper/faster, ultimately.\n\nStill, I'm not entirely sure what the expensive parts are within the processing chain. As far as I know, it's mostly Matrix-Multiplication for standard layers. Not the cheapest operation, but definitly doable. On top, there are are other layers, like max-pooling, or activation-functions at each node, which might have higher complexities. Are those the bottle-necks?\n\nNow, I wonder if \"simple\" Hardware provided by Smartphones or even cheap stand-alone Hardware like Raspberry PIs are capable of utilizing a (convolutional-) Neuronal Networks to do, for example, Image Processing, like Object Detection. Of course, I mean doing the calculations on the device itself, not by transmitting the data to a second, powerful machine or even a cloud, which does the calculations, before sending back the results to the smartphone. \n\nIf so, what are the maximum Neurons such a Network should have (e.g. how many layers and how many neurons per layer), roughly estimated. And last, are there any good either projects, or librarys, using NNs for reduced simpler Hardware?\n    ", "Answer": "\r\nCurrent neural networks use convolutional layers, which perform a convolution on the input image. Also the high amount of parameters and dimensions is a real problem for low budget hardware. But anyways there are approaches that work on android for newer smartphones, like the SqueezeNet. Much of the work is actually done on gpus nowadays and so I am not sure if it works on a rasperry.\n\nA better description than I could ever write on the topic can be found here: https://hackernoon.com/how-hbos-silicon-valley-built-not-hotdog-with-mobile-tensorflow-keras-react-native-ef03260747f3?gi=adb83ae18a85, where they actually built a neural network for a mobile phone. You can actually download the app and try it on your mobile phone if you have android or ios.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Stuck implementing simple neural network\r\n                \r\nI've been bashing my head against this brick wall for what seems like an eternity, and I just can't seem to wrap my head around it. I'm trying to implement an autoencoder using only numpy and matrix multiplication. No theano or keras tricks allowed.\n\nI'll describe the problem and all its details. It is a bit complex at first since there are a lot of variables, but it really is quite straightforward.\n\nWhat we know\n\n1) ```\nX```\n is an ```\nm```\n by ```\nn```\n matrix which is our inputs. The inputs are rows of this matrix. Each input is an ```\nn```\n dimensional row vector, and we have ```\nm```\n of them.\n\n2)The number of neurons in our (single) hidden layer, which is ```\nk```\n.\n\n3) The activation function of our neurons (sigmoid, will be denoted as ```\ng(x)```\n) and its derivative ```\ng'(x)```\n\n\nWhat we don't know and want to find\n\nOverall our goal is to find 6 matrices: ```\nw1```\n which is ```\nn```\n by ```\nk```\n, ```\nb1```\n which is ```\nm```\n by ```\nk```\n, ```\nw2```\n which is ```\nk```\n by ```\nn```\n, b2 which is ```\nm```\n by ```\nn```\n, ```\nw3```\n which is ```\nn```\n by ```\nn```\n and ```\nb3```\n which is ```\nm```\n by ```\nn```\n.\n\nThey are initallized randomly and we find the best solution using gradient descent.\n\nThe process\n\nThe entire process looks something like this\n\n\nFirst we compute ```\nz1 = Xw1+b1```\n. It is ```\nm```\n by ```\nk```\n and is the input to our hidden layer. We then compute ```\nh1 = g(z1)```\n, which is simply applying the sigmoid function to all elements of ```\nz1```\n. naturally it is also ```\nm```\n by ```\nk```\n and is the output of our hidden layer.\n\nWe then compute ```\nz2 = h1w2+b2```\n which is ```\nm```\n by ```\nn```\n and is the input to the output layer of our neural network. Then we compute ```\nh2 = g(z2)```\n which again is naturally also ```\nm```\n by ```\nn```\n and is the output of our neural network.\n\nFinally, we take this output and perform some linear operator on it: ```\nXhat = h2w3+b3```\n which is also ```\nm```\n by ```\nn```\n and is our final result.\n\nWhere I am stuck\n\nThe cost function I want to minimize is the mean squared error. I already implemented it in numpy code\n\n```\ndef cost(x, xhat):\n    return (1.0/(2 * m)) * np.trace(np.dot(x-xhat,(x-xhat).T))\n```\n\n\nThe problem is finding the derivatives of cost with respect to ```\nw1,b1,w2,b2,w3,b3```\n. Let's call the cost ```\nS```\n.\n\nAfter deriving myself and checking myself numerically, I have established the following facts:\n\n1) ```\ndSdxhat = (1/m) * np.dot(xhat-x)```\n\n\n2) ```\ndSdw3 = np.dot(h2.T,dSdxhat)```\n\n\n3) ```\ndSdb3 = dSdxhat```\n\n\n4) ```\ndSdh2 = np.dot(dSdxhat, w3.T)```\n\n\nBut I can't for the life of me figure out dSdz2. It's a brick wall.\n\nFrom chain-rule, it should be that dSdz2 = dSdh2 * dh2dz2 but the dimensions don't match. \n\nWhat is the formula to compute the derivative of S with respect to z2?\n\nEdit - This is my code for the entire feed forward operation of the autoencoder.\n\n```\nimport numpy as np\n\ndef g(x): #sigmoid activation functions\n    return 1/(1+np.exp(-x)) #same shape as x!\n\ndef gGradient(x): #gradient of sigmoid\n    return g(x)*(1-g(x)) #same shape as x!\n\ndef cost(x, xhat): #mean squared error between x the data and xhat the output of the machine\n    return (1.0/(2 * m)) * np.trace(np.dot(x-xhat,(x-xhat).T))\n\n#Just small random numbers so we can test that it's working small scale\nm = 5 #num of examples\nn = 2 #num of features in each example\nk = 2 #num of neurons in the hidden layer of the autoencoder\nx = np.random.rand(m, n) #the data, shape (m, n)\n\nw1 = np.random.rand(n, k) #weights from input layer to hidden layer, shape (n, k)\nb1 = np.random.rand(m, k) #bias term from input layer to hidden layer (m, k)\nz1 = np.dot(x,w1)+b1 #output of the input layer, shape (m, k)\nh1 = g(z1) #input of hidden layer, shape (m, k)\n\nw2 = np.random.rand(k, n) #weights from hidden layer to output layer of the autoencoder, shape (k, n)\nb2 = np.random.rand(m, n) #bias term from hidden layer to output layer of autoencoder, shape (m, n)\nz2 = np.dot(h1, w2)+b2 #output of the hidden layer, shape (m, n)\nh2 = g(z2) #Output of the entire autoencoder. The output layer of the autoencoder. shape (m, n)\n\nw3 = np.random.rand(n, n) #weights from output layer of autoencoder to entire output of the machine, shape (n, n)\nb3 = np.random.rand(m, n) #bias term from output layer of autoencoder to entire output of the machine, shape (m, n)\nxhat = np.dot(h2, w3)+b3 #the output of the machine, which hopefully resembles the original data x, shape (m, n)\n```\n\n    ", "Answer": "\r\nOK, here's a suggestion.  In the vector case, if you have x as a vector of length ```\nn```\n, then ```\ng(x)```\n is also a vector of length ```\nn```\n.  However, ```\ng'(x)```\n is not a vector, it's the Jacobian matrix, and will be of size ```\nn X n```\n.  Similarly, in the minibatch case, where X is a matrix of size ```\nm X n```\n, ```\ng(X)```\n is ```\nm X n```\n but ```\ng'(X)```\n is ```\nn X n```\n.  Try:\n\n```\ndef gGradient(x): #gradient of sigmoid\n    return np.dot(g(x).T, 1 - g(x))\n```\n\n\n@Paul is right that the bias terms should be vectors, not matrices.  You should have:\n\n```\nb1 = np.random.rand(k) #bias term from input layer to hidden layer (k,)\nb2 = np.random.rand(n) #bias term from hidden layer to output layer of autoencoder, shape (n,)\nb3 = np.random.rand(n) #bias term from output layer of autoencoder to entire output of the machine, shape (n,)\n```\n\n\nNumpy's broadcasting means that you don't have to change your calculation of ```\nxhat```\n.\n\nThen (I think!) you can compute the derivatives like this:\n\n```\ndSdxhat = (1/float(m)) * (xhat-x)\ndSdw3 = np.dot(h2.T,dSdxhat)\ndSdb3 = dSdxhat.mean(axis=0)\ndSdh2 = np.dot(dSdxhat, w3.T)\ndSdz2 = np.dot(dSdh2, gGradient(z2))\ndSdb2 = dSdz2.mean(axis=0)\ndSdw2 = np.dot(h1.T,dSdz2)\ndSdh1 = np.dot(dSdz2, w2.T)\ndSdz1 = np.dot(dSdh1, gGradient(z1))\ndSdb1 = dSdz1.mean(axis=0)\ndSdw1 = np.dot(x.T,dSdz1)\n```\n\n\nDoes this work for you?\n\nEdit\n\nI've decided that I'm not at all sure that ```\ngGradient```\n is supposed to be a matrix.  How about:\n\n```\ndSdxhat = (xhat-x) / m\ndSdw3 = np.dot(h2.T,dSdxhat)\ndSdb3 = dSdxhat.sum(axis=0)\ndSdh2 = np.dot(dSdxhat, w3.T)\ndSdz2 = h2 * (1-h2) * dSdh2\ndSdb2 = dSdz2.sum(axis=0)\ndSdw2 = np.dot(h1.T,dSdz2)\ndSdh1 = np.dot(dSdz2, w2.T)\ndSdz1 = h1 * (1-h1) * dSdh1\ndSdb1 = dSdz1.sum(axis=0)\ndSdw1 = np.dot(x.T,dSdz1)\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "OpenGL draw multiple isometric cubes\r\n                \r\nI'm trying to draw multiple cubes at an isometric camera angle. Here's the code that draws one. (OpenGL ES 2.0 with GLKit on iOS). \n\n```\nfloat startZ = -4.0f;\n\n// position\nGLKMatrix4 modelViewMatrix = GLKMatrix4Identity;    \nmodelViewMatrix = GLKMatrix4Translate(modelViewMatrix, location.x, location.y, location.z + startZ);\n\n// isometric camera angle\nmodelViewMatrix = GLKMatrix4Rotate(modelViewMatrix, GLKMathDegreesToRadians(45), 1.0, 0, 0);\nmodelViewMatrix = GLKMatrix4Rotate(modelViewMatrix, GLKMathDegreesToRadians(45), 0.0, 1.0, 0);\n\nself.effect.transform.modelviewMatrix = modelViewMatrix;\n\n[self.effect prepareToDraw];\nglDrawArrays(GL_TRIANGLES, 0, 36);\n```\n\n\nThe problem is that it is translating first, then rotating, which means with more than one box, they do not line up (they look like a chain of diamonds. Each one is in position and rotated so the corners overlap). \n\n\n\nI've tried switching the order so the rotation is before the translation, but they don't show up at all. My vertex array is bound to a unit cube centered around the origin. \n\nI really don't understand how to control the camera separate from the object. I screwed around with the projection matrix for a while without getting it. As far as I understand, the camera is supposed to be controlled with the modelViewMatrix, right? (The \"View\" part). \n    ", "Answer": "\r\nYour 'camera' transform (modelview) seems correct, however it looks like you're using a perspective projection - if you want isometric you will need to change your projection matrix.\n\nIt looks like you are applying the camera rotation to each object as you draw it. Instead, simulate a 2-deep matrix stack if your use-case is this simple, so you just have your camera matrix and each cube's matrix.\n\n\nSet your projection and camera matrices - keep a reference to your camera matrix.\nFor each cube generate the individual cube transformation matrix (which should probably consist of translation only - no rotation so the cubes remain axis aligned - I think this is what you're going for).\nBackwards-multiply your cube matrix by the camera matrix and use that as the modelview matrix.\n\n\nNote that the camera matrix will remain unchanged for each cube you render, but the modelview matrix will incorporate both the cube's individual transformation matrix and the camera matrix into a single modelview matrix. This is equivalent to the old matrix stack methods ```\nglPushMatrix```\n and ```\nglPopMatrix```\n (not available in GLES 2.0). If you need more complex object hierarchies (where the cubes have child-objects in their 'local' coordinate space) then you should probably implement your own full matrix stack, instead of the 2-deep equivalent discussed above.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Caching intermediate results in Spark ML pipeline\r\n                \r\nLately I'm planning to migrate my standalone python ML code to spark. The ML pipeline in ```\nspark.ml```\n turns out quite handy, with streamlined API for chaining up algorithm stages and hyper-parameter grid search.\n\nStill, I found its support for one important feature obscure in existing documents: caching of intermediate results. The importance of this feature arise when the pipeline involves computation intensive stages. \n\nFor example, in my case I use a huge sparse matrix to perform multiple moving averages on time series data in order to form input features. The structure of the matrix is determined by some hyper-parameter. This step turns out to be a bottleneck for the entire pipeline because I have to construct the matrix in runtime.\n\nDuring parameter search, I usually have other parameters to examine other than this \"structure parameter\". So if I can reuse the huge matrix when the \"structure parameter\" is unchanged, I can save tons of time. For this reason, I intentionally formed my code to cache and reuse these intermediate results. \n\nSo my question is: can Spark's ML pipeline handle intermediate caching automatically? Or do I have to manually form code to do so? If so, is there any best practice to learn from?\n\nP.S. I have looked into the official document and some other material, but none of them seems to discuss this topic.\n    ", "Answer": "\r\nSo I ran into the same problem and the way I solved is that I have implemented my own PipelineStage, that caches the input DataSet and returns it as it is.\n\n\n```\nimport org.apache.spark.ml.Transformer\nimport org.apache.spark.ml.param.ParamMap\nimport org.apache.spark.ml.util.{DefaultParamsWritable, Identifiable}\nimport org.apache.spark.sql.{DataFrame, Dataset}\nimport org.apache.spark.sql.types.StructType\n\nclass Cacher(val uid: String) extends Transformer with DefaultParamsWritable {\n  override def transform(dataset: Dataset[_]): DataFrame = dataset.toDF.cache()\n\n  override def copy(extra: ParamMap): Transformer = defaultCopy(extra)\n\n  override def transformSchema(schema: StructType): StructType = schema\n\n  def this() = this(Identifiable.randomUID(\"CacherTransformer\"))\n}\n```\n\n\nTo use it then you would do something like this: \n\n```\nnew Pipeline().setStages(Array(stage1, new Cacher(), stage2))\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Better way to program in matrix style selections in plsql?\r\n                \r\nBy matrix style, I mean having n variables, each with some number of inputs, and having to handle all possible values.  The simplest case of this is multiple boolean values and having to handle every combination of true/false.  This is easy if the returned values follow certain patterns, but otherwise it seems quite difficult.\n\n(If there is a better name than 'matrix style', please comment and tell me so I can update the title.)\n\nThe ugly way to handle this is an if else chain.\n\n```\nIF self.A = 'N' THEN\n    IF self.B = 'N' THEN\n        ...\n    ELSE\n        ...\n    END IF;\nELSE\n    IF self.B = 'N' THEN\n        ...\n    ELSE\n        ...\n    END IF;\nEND IF;\n```\n\n\nGood luck keeping track of that mess, especially with more than 4 variables.\n\nA slightly more readable way of doing this is to do all the checks together.\n\n```\nIF self.A = 'N' AND ... self.Y = 'N' AND self.Z = 'N' THEN\n    returnValue := 'Bob';\nEND IF;\nIf self.A = 'N' AND ... self.Y = 'N' AND self.Z = 'Y' THEN\n    returnValue := 'Birthday Party';\nEND IF;\n...\nIf self.A = 'Y' AND ... self.Y = 'N' AND self.Z = 'N' THEN\n    returnValue := 'What did I ever do to deserve this?';\nEND IF;\n...\nIf self.A = 'Y' AND ... self.Y = 'Y' AND self.Z = 'Y' THEN\n    returnValue := 'Thank God I am done!';\nEND IF;\n```\n\n\nYou can make that a little better if you do a CASE statement instead of a bunch of if/elses, but that is still very hard to maintain.  Imagine accidentally putting a Y instead of an N some place and having to go find it.  Considering the chance for errors grows exponentially with each new variable added (as you at least double the amount of code you need to write), there is a good chance for errors in any significant sized problem like this.\n\nYou can potentially do some interesting text replacement to try to reduce errors.  I recently did this with 5 variables.  I started with...\n\n```\nNNNNN\nNNNNY\n...\nYYYYN\nYYYYY\n```\n\n\nThen I ran some find and replace over them using Notepad++ to try to reduce the chance of mistyping a N or Y.  But the end product still looks nasty to maintain.  So I'm wondering if there are any better ways to handle this (mostly in terms of maintainability, though any efficiency boost without loosing maintainability are also welcome suggestions).  While I'm looking specifically for PL/SQL solutions, any solutions in other languages are still welcome because they might be able to be translated to PL/SQL.\n\nEdit:  In case anyone is trying to solve this problem and wants to use my current solution, here is the find and replace.\n\nFind: ```\n([Y,N])```\n repeated as many times as you have variables.\nReplace: ```\n\\t\\t\\tWHEN self.valueName = '\\1' THEN\\r\\n\\t\\t\\t\\treturnValue := ''```\n where the ```\nself.valueName = '\\1'```\n is repeated once for each variable you have, with the \\1 incremented each time.  You'll also need to set the correct number of \\t's so that it matches however much indented it should be.  This works in Notepad++, regex mode.\n    ", "Answer": "\r\nWhy do you have that problem? I assume that this is a variable of a type consisting out of variables from A-Z. So how do you populate this in the first place? Can't you simplify right there? \n\nBut if there is no alternative you can first check if there is only 'Y' and 'N' in the single fields and convert to 1 and 0 and make numbers out of it and check against the numbers. E.g. NNNNY becomes one and NNNYN becomes 2 etc. Then it is IF r=1 then .. elsif r=2 .. \n\nA probably even better alternative is to generate the code. You can form a string that has the \"create or replace functionX as ...\" and do an execute immediate on it.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Use Subexpressions to Simplify Long Symbolic Equations in Matlab\r\n                \r\nMy question is essentially the same as this one:\n\nSimplifying a very long symbolic expression by automatically introducing temporal variables or in any other way\n\nHowever, I don't have Mathematica and the question was not answered for Matlab, further, this is 2 years old and maybe people have had some ideas since then.\n\nLike Andrey, I have an extremely large equation (about 13000 characters) as a result of a multiple-chain-rule derivate of an already long function. The derivate contains numerous instances of the subfunctions in the original equation and their derivates. I believe it's possible to compress the function to at least a 10th with suitable replacements. I am wondering if there is a way to have Matlab make these replacements automatically for me.\n\nThis is also relevant from a performance standpoint, because I have thens of these equations that are evaluated for a Jacobi matrix to solve a complicated system of nonlinear equations.\n\nThank you for your time.\n    ", "Answer": "\r\nThe closest thing MatLab has is the subexpr() function. For instance you have a formula:\n\n```\n% Declare symnbolic    \nsyms x\n% Define equation\neq1 = x^2 + 3*x^2 + 6*x^2 + x^2/57*x + sqrt(x^2)\n\n% Simplify by substitution\nsubexpr(eq1)\n```\n\n\nWith the output:\n\n```\nsigma = \n\nx^2\n\nans =\n\n10*sigma + (sigma*x)/57 + sigma^(1/2)\n```\n\n\nSource:\nhttp://www.mathworks.nl/help/symbolic/subexpr.html\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Computing a company's shareholders ownership percentage\r\n                \r\nI have a graph that contains two types of nodes: Companies and Persons.\n\nA Company node has a list of edges that represent Shareholders. A Shareholder has a percentage of shares and is either a Company or a Person. A Person node is always a leaf.\n\nHere's an example:\n\n```\nCompanyA has 50% of CompanyB's shares\nUserA has 50% of CompanyA's shares\nUserB has 50% of CompanyB's shares\nCompanyB has 50% of CompanyA's shares\n```\n\n\nThe arrows could be reversed, depending on whether they represent shares or owners\n\n\n\nWho in truth owns CompanyA and with what percentage. In this example, we should get that UserA owns 66.66% of CompanyA and UserB owns 33.33% of CompanyB.\n\nThis can be computed using a Transition Matrix and multiplying it by itself multiple times, like this.\n\nSadly, this is an estimate and requires quite a lot of iterations to get a very precise one. I suspect that there's a way to get a exact answer. I've looked at eigenvalues but I think my maths are failing me. In terms of matrices, I think I'm looking for the stable distribution of a transition matrix (or Markov Chain).\n\nPerhaps I'm overcomplicating this? I feel like there should be a way to get this result without resolving to matrices and with a recursive algorithm. Especially considering that the graph contains a lot of leaves and that I am only interested in the shareholders of a single company (the \"root\" of the graph).\n\nI will implement the final solution in Java. Third party libraries can be used.\n\nThanks!\n    ", "Answer": "\r\nI assume that the labeling of your matrix is more or less like so\n\n```\n   cA  cB  uA  uB\ncA 0    0.5 0.5 0\ncB 0.5  0   0   0.5\nuA 0    0   1   0\nuB 0    0   0   1\n```\n\n\nwhere cA/B denotes Company A/B while uA/B stands for User A/B.\n\nLet's denote this matrix as ```\nA```\n. Then the expression ```\n(1, 0, 0, 0).A```\n gives us the immediate \"distribution of resources\" after \"investing\" 1 \"unit\" into Company A. In this case the result is indeed ```\n(0, 0.5, 0.5, 0)```\n, i.e., Company B gets 50% and User A gets 50% as well. However, the resources attributed to Company B \"propagate\" further, so in order to find the \"equilibrium\" distribution, we need to calculate\n\n```\n(1, 0, 0, 0).A^n\n```\n\n\nin the limit of ```\nn```\n going to infinity. In terms of the left eigenvectors, the original matrix ```\nA```\n can be rewritten (assuming that it is diagonalizable) as ```\nA=Inverse[P].w.P```\n, where ```\nw```\n is a diagonal matrix containing the eigenvalues. Then one has\n\n```\nA^n = (Inverse[P].w.P)^n = Inverse[P].w^n.P\n```\n\n\nIn this particular case, the eigenvalues are ```\n1, 1, 0.5, -0.5```\n so when ```\nn```\n goes to infinity, only the eigenvalue ```\n1```\n survive(s). Thus the limit of ```\nw^n```\n is ```\nDiagonalMatrix[{1,1,0,0}]```\n. The final result can be therefore written as\n\n```\nInverse[P].DiagonalMatrix[{1,1,0,0}].P\n```\n\n\nwhich yields\n\n```\n0.  0.  0.666667    0.333333\n0.  0.  0.333333    0.666667\n0.  0.  1.  0.\n0.  0.  0.  1.\n```\n\n\nFinally, the eigenvectors corresponding to the eigenvalue 1 are ```\n(0, 0, 1, 0)```\n and ```\n(0, 0, 0, 1)```\n. The meaning of this is that if one \"invests\" 1 unit of resources into User A/B, the corresponding user \"keeps everything\" and nothing propagates further, i.e., an equilibrium has been already reached. The eigenvalue is then doubly degenerate since there are two Users (leaves).\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "GPU-based inclusive scan on an unbalanced tree\r\n                \r\nI have the following problem: I need to compute the inclusive scans (e.g. prefix sums) of values based on a tree structure on the GPU. These scans are either from the root node (top-down) or from the leaf nodes (bottom-up). The case of a simple chain is easily handled, but the tree structure makes parallelization rather difficult to implement efficiently.\n\n\n\nFor instance, after a top-down inclusive scan, ```\n(12)```\n would hold ```\n(0)[op](6)[op](7)[op](8)[op](11)[op](12)```\n, and for a bottom-up inclusive scan, ```\n(8)```\n would hold ```\n(8)[op](9)[op](10)[op](11)[op](12)```\n, where ```\n[op]```\n is a given binary operator (matrix addition, multiplication etc.).\n\nOne also needs to consider the following points:\n\n\nFor a typical scenario, the length of the different branches should not be too long (~10), with something like 5 to 10 branches, so this is something that will run inside a block and work will be split between the threads. Different blocks will simply handle different values of nodes. This is obviously not optimal regarding occupancy, but this is a constraint on the problem that will be tackled sometime later. For now, I will rely on Instruction-level parallelism.\nThe structure of the graph cannot be changed (it describes an actual system), thus it cannot be balanced (or only by changing the root of the tree, e.g. using ```\n(6)```\n as the new root). Nonetheless, a typical tree should not be too unbalanced.\nI currently use CUDA for GPGPU, so I am open to any CUDA-enabled template library that can solve this issue.\nNode data is already in global memory and the result will be used by other CUDA kernels, so the objective is just to achieve this without making it a huge bottleneck.\nThere is no \"cycle\", i.e. branches cannot merge down the tree.\nThe structure of the tree is fixed and set in an initialization phase.\nA single binary operation can be quite expensive (e.g. multiplication of polynomial matrices, i.e. each element is a polynomial of a given order).\n\n\nIn this case, what would be the \"best\" data structure (for the tree structure) and the best algorithms (for the inclusive scans/prefix sums) to solve this problem?\n    ", "Answer": "\r\nProbably a harebrained idea, but imagine that you insert nodes of 0 value into the tree, in such a way that you get a 2D matrix. For instance, there would be 3 zero value nodes below the 5 node in your example. Then use one thread to travel each level of the matrix horizontally. For the top-down prefix sum, offset the threads in such a way that each lower thread is delayed by the maximum number of branches the tree can have in that location. So, you get a \"wave\" with a slanted edge running over the matrix. The upper threads, being further along, calculate those nodes in time for them to be processed further by threads running further down. You would need the same number of threads as the tree is deep.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Proper way of freeing pointers when using method chaining\r\n                \r\nI'm currently writing multiple different implementations of matrix multiplications in c. So I wrote utility functions for matrix addition and subtraction, which have the following structure:\n\n```\nint** m_sub(int** a, int** b, int size) {\n    int **result = get_matrix(size);\n    // calculate addition of a & b\n    return result;\n```\n\n\n}\n\nwith ```\nget_matrix():```\n\n\n```\nint** get_matrix(int size){\n    int** m = malloc(size*sizeof(int));\n    for (int i=0;i<size;i++){\n        m[i] = malloc(size*sizeof(int));\n    }\n    return m;\n```\n\n\n}\n\nI designed all functions to work with and return ```\nint**```\n because to my understanding, you cannot return variable sized 2-D arrays in c.\n\nNow the program works fine as is, however through running a memory checker (Valgrind) I discovered that all the return values from calls to, e.g. ```\nm_add```\n are causing memory leaks, because I am using the returned value directly in method chaining and I don't ```\nfree()```\n them, e.g.:\n\n```\nm_copy(c_11,m_add(matmul_recursive(n/2, a,e),matmul_recursive(n/2, b, g), n/2), n/2);\n```\n\n\nI know I could fix this by assigning each returned ```\nint**```\n to a variable and manually freeing it afterwards. However that would lead to a huge amount of temporarily assigned variables and thus (arguably) way less readable code. \n\nNow I was wondering if there is a \"proper\" way of doing this in c? Or is the fact that I'm returning ```\nint**```\n pointers for matrices already a bad design choice?\n    ", "Answer": "\r\nThe problem is that C has no notion of automatic destructor call, as C++ as. So AFAIK, you as the programmer are responsable to free anything that has been allocated.\n\nOf course, you can imagine a library that keeps references of anything it has allocated and provide a way to free that when you no longer need it. For example, you could implement a dynamic stack to store each newly allocated memory block, and use that stack to reclaim the whole memory later.\n\nSimply I am too lazy to write an implementation of it... But feel free to ping me in a comment if you feel you want to do that but cannot implement it from the beginning.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How to avoid a huge list of JavaFX coordinate translations (caused by UI responses)\r\n                \r\nI'm making a ScalaFX (but use of Scala is irrelevant here) application with a user interface similar to i.e. Google maps. There's panning and zooming.\n\nFor each such change of the user's viewpoint, I add a transform into a Group's ```\n.transforms```\n.\n\n```\ntransforms += new Translate( dx, dy )\n```\n\n\nor\n\n```\ntransforms += new Scale( 1/f,1/f, cx, cy )\n```\n\n\nThis seems like the only way to affect transformations (apart from ```\ntranslateXYZ```\n, ```\nlayoutXYZ```\n, which I'm ignoring), and it works.\n\nThe docs say this:\n\n\n  Multiple transformations may be applied to a node by specifying an\n  ordered chain of transforms. The order in which the transforms are\n  applied is defined by the ObservableList specified in the transforms\n  variable.\n\n\nDoesn't this imply that there's a list (even, an observable list) of potentially hundreds or thousands of entries long?\n\nIf so, I would like to flatten the list occasionally. Tried calling ```\n.localToSceneTransoform```\n and ```\n.localToParentTransform```\n for this (thinking I'd then set the .transforms with the received overall affine matrix). That crashed the JVM. \n\nAm I doing something wrong here, or should I just stop caring about the list growing, well, indefinately?\n\nCan provide a short ScalaFX sample code to highlight all this (including the crash). Please ask.\n\nSystem: OS X, JVM 7u10\n    ", "Answer": "\r\nIt took a while to get to the 'thinking' of JavaFX transformations. The idea is that one makes a list of transforms, and changes the Observable parameters of those transforms. This takes away the need to constantly add more and more transforms to the list.\n\nThis is actually a very cute way of handling it. Sadly it's not obvious from any of the docs I've read (reason to leave this entry in SO me thinks).\n\nThe necessary code is something like:\n\n```\nprivate val panTrans = new Translate(0,0)\n\ntransforms = \n  panTrans ::\n  Nil\n\n...\n\npanTrans.x = panTrans.x() + dx\npanTrans.y = panTrans.y() + dy\n```\n\n\nI think it will be obvious from here.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Remove all non-upper alphabet characters, hits ArrayIndexOutOfBoundsException\r\n                \r\nScanner hit empty line throw ArrayIndexOutOfBoundsException My code will throw an ArrayIndexOutOfBoundsException when hits with an empty line, how can I fix this? For example, the sample text file's line 3 is an empty line, that will throw an exception.\nAnd I want to remove all non-upper alphabet characters. How can I do that?\nSample text file\n```\nThis is an \nExample\n\nfor this\nClass\n\nABC\nDEF\n\nG\n\nH\n\n\n\nIIIIII\n\n\nXYZ\n\n\n\n!@#\n\n(\n\nAaaabb\n\n)\n\n\n13\n\n\nABC\n\nX\n\n...//}{\n\n--=+-\n\n\nEND\n```\n\n```\n    import java.io.File;\n    import java.io.FileNotFoundException;\n    import java.util.Scanner;\n\n    class Test {\n        // A utility function to get max of two integers \n        static int max(int x, int y) {\n            return (x > y) ? x : y;\n        }\n\n        // Returns the length of the longest  \n        // palindromic subsequence in seq \n        static int lps(String seq) {\n            int n = seq.length();\n            int i, j, cl;\n            // Create a table to store results of subproblems \n            int L[][] = new int[n][n];\n\n            // Strings of length 1 are palindrome of lentgh 1 \n            for (i = 0; i < n; i++)\n                L[i][i] = 1;\n\n            // Build the table. Note that the lower  \n            // diagonal values of table are \n            // useless and not filled in the process.  \n            // The values are filled in a manner similar \n            //  to Matrix Chain Multiplication DP solution (See \n            // https://www.geeksforgeeks.org/matrix-chain-multiplication-dp-8/).  \n            // cl is length of substring \n            for (cl = 2; cl <= n; cl++) {\n                for (i = 0; i < n - cl + 1; i++) {\n                    j = i + cl - 1;\n\n                    if (seq.charAt(i) == seq.charAt(j) && cl == 2)\n                        L[i][j] = 2;\n\n\n                    if (seq.charAt(i) == seq.charAt(j))\n                        L[i][j] = L[i + 1][j - 1] + 2;\n\n                    else\n                        L[i][j] = max(L[i][j - 1], L[i + 1][j]);\n                }\n            }\n\n            return L[0][n - 1];\n        }\n\n        /* Driver program to test above functions */\n        public static void main(String args[]) throws FileNotFoundException {\n            Scanner file = new Scanner(new File(\"Sample.txt\"));\n\n            while (file.hasNextLine()) {\n                String input = file.nextLine();\n                String seq = input.toUpperCase().replaceAll(\"\\\\P{Alnum}\", \"\");\n\n\n                System.out.println(\"The length of the lps is \" + lps(seq));\n\n            }\n        }\n    }\n```\n\n    ", "Answer": "\r\nSkip empty lines?\nAdd condition ```\nif(n < 1) return 0;```\n?\nIf you want to remove all non-uppercase character from a string, you can use\n```\nsomeString.replaceAll(\"[^A-Z]+\", \"\");\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Scanner hit empty line throw ArrayIndexOutOfBoundsException\r\n                \r\nScanner hit empty line throw ArrayIndexOutOfBoundsException\nMy code will throw an ArrayIndexOutOfBoundsException when hits with an empty line, how can I fix this?\nFor example, the sample text file's line 3 is an empty line, that will throw an exception.\nScanner hit empty line throw ArrayIndexOutOfBoundsException\nSample text file\n```\nThis is an \nExample\n\nfor this\nClass\n\nABC\nDEF\n\nG\n\nH\n\n\n\nIIIIII\n\n\nXYZ\n\n\n```\n\n```\nimport java.io.File;\nimport java.io.FileNotFoundException;\nimport java.util.Scanner;\n\nclass Test \n{ \n        // A utility function to get max of two integers \n    static int max (int x, int y) { return (x > y)? x : y; } \n      \n    // Returns the length of the longest  \n    // palindromic subsequence in seq \n    static int lps(String seq) \n    { \n    int n = seq.length(); \n    int i, j, cl; \n    // Create a table to store results of subproblems \n    int L[][] = new int[n][n];  \n      \n    // Strings of length 1 are palindrome of lentgh 1 \n    for (i = 0; i < n; i++) \n        L[i][i] = 1; \n              \n        // Build the table. Note that the lower  \n        // diagonal values of table are \n        // useless and not filled in the process.  \n        // The values are filled in a manner similar \n        //  to Matrix Chain Multiplication DP solution (See \n        // https://www.geeksforgeeks.org/matrix-chain-multiplication-dp-8/).  \n        // cl is length of substring \n        for (cl=2; cl<=n; cl++) \n        { \n            for (i=0; i<n-cl+1; i++) \n            { \n                j = i+cl-1; \n       \n                if (seq.charAt(i) == seq.charAt(j) && cl == 2) \n                L[i][j] = 2; \n           \n         \n                if (seq.charAt(i) == seq.charAt(j)) \n                L[i][j] = L[i+1][j-1] + 2; \n                \n                else\n                L[i][j] = max(L[i][j-1], L[i+1][j]);\n            } \n        } \n              \n        return L[0][n-1]; \n    } \n          \n    /* Driver program to test above functions */\n    public static void main(String args[]) throws FileNotFoundException \n    { \n        Scanner file = new Scanner(new File(\"Sample.txt\"));\n        \n        while (file.hasNextLine()) {\n            String input = file.nextLine();\n            String seq = input.toUpperCase().replaceAll(\"\\\\P{Alnum}\", \"\");\n\n          \n        System.out.println(\"The length of the lps is \"+ lps(seq)); \n        \n        }   \n    } \n} \n```\n\n    ", "Answer": "\r\nSimple. Just add a \"isBlank\" check to the string.\n```\n  public static void main(String args[]) throws FileNotFoundException\n  {\n    Scanner file = new Scanner(new File(\"src/main/resources/Sample.txt\"));\n\n    while (file.hasNextLine()) {\n      String input = file.nextLine();\n\n      if(!input.isBlank()){\n        String seq = input.toUpperCase().replaceAll(\"\\\\P{Alnum}\", \"\");\n\n\n        System.out.println(\"The length of the lps is \"+ lps(seq));\n      }\n\n\n    }\n  }\n```\n\nand it gives output like this:\n```\nThe length of the lps is 3\nThe length of the lps is 3\nThe length of the lps is 1\nThe length of the lps is 2\nThe length of the lps is 1\nThe length of the lps is 1\nThe length of the lps is 1\nThe length of the lps is 1\nThe length of the lps is 6\nThe length of the lps is 1\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "TensorFlow 2-gpu slower then single gpu\r\n                \r\nI have two gpu (TitanX (Pascal) and GTX 1080). I am trying\nto run single-thread graph computation. The graph is two separate matrix multiplication chains (each assigned to corresponding gpu).\n\nHere is the code that I'm using:\n\nimport tensorflow as tf\n    import numpy as np\n    import random\n    import time\n    import logging\n\n```\nfrom tensorflow.python.ops import init_ops\nfrom tensorflow.python.client import timeline\n\n\ndef test():\n    n = 5000\n\n    with tf.Graph().as_default():\n        A1 = tf.placeholder(tf.float32, shape=[n, n], name='A')\n        A2 = tf.placeholder(tf.float32, shape=[n, n], name='A')\n        with tf.device('/gpu:0'):\n            B1 = A1\n            for l in xrange(10):\n                B1 = tf.matmul(B1, A1)\n\n        with tf.device('/gpu:1'):\n            B2 = A2\n            for l in xrange(10):\n                B2 = tf.matmul(B2, A2)\n            C = tf.matmul(B1, B2)\n\n        run_metadata = tf.RunMetadata()\n        with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n            start = time.time()\n            logging.info('started')\n            A1_ = np.random.rand(n, n)\n            A2_ = np.random.rand(n, n)\n            sess.run([C],\n                     feed_dict={A1: A1_, A2: A2_},\n                     options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n                     run_metadata=run_metadata)\n            logging.info('writing trace')\n            trace = timeline.Timeline(step_stats=run_metadata.step_stats)\n            trace_file = open('timeline.ctf.json', 'w')\n            trace_file.write(trace.generate_chrome_trace_format())\n            logging.info('trace written')\n            end = time.time()\n            logging.info('computed')\n            logging.info(end - start)\n\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n    test()\n```\n\n\n\nIt takes 20.4 secs to finish.\nIt takes 14 secs to finish if I set all ops to gpu0 (TitanX).\nIt takes 19.8 secs to finish if I set all ops to gpu1 (GTX 1080).\n\n\nI can see that tensorflow found both gpus and have set all devices correctly.\nWhy is there no speed up for using two gpu instead of one? Could be the problem that the gpus are different models (AFAIK cuda allows it)?\n\nThanks.\n\nEDIT\nI updated code to use different initial matrices for both chains since otherwise tensorflow seems to do some optimizations.\n\nHere is a timeline profile json-file link: https://api.myjson.com/bins/23csi\n\nScreenshot\n\nThis timeline raises more questions than answers:\n\n\nWhy pid 7 (gpu0) has two lines of execution?\nWhat are long MatMuls in pid 3 and 5? (input0 \"_recv_A_0/_3\", input1 \"_recv_A_0/_3\", name \"MatMul\", op \"MatMul\")\nIt seems that every op is executed on gpu0 execept pid 5.\nThere are a lot of small MatMul ops (can't be seen from the screenshot) right after the long MatMuls ops from pid 3 and pid 5. What is this?\n\n    ", "Answer": "\r\nThere's significant delay when launching kernel for the first time on a GPU, possibly caused by PTXAS compilation. This delay can be on the order of seconds and accumulates when you use more than 1 GPUs, so in your case the run is slower because time is dominated by an extra \"initial kernel launch\". One way to benchmark pure computation time is to to \"pre-warming\" by executing each cuda operation at least once on each GPU. I've observed the same slowness by running your benchmark on 2 TitanX cards, but this delay disappeared when I \"pre-warmed\" the kernels.\n\nHere's before pre-warming:\n\n\nHere's after pre-warming:\n\nBelow is your code modified to do pre-warming, and also to remove any TensorFlow<->Python transfers.\n\n```\nimport tensorflow as tf\n\nfrom tensorflow.python.ops import init_ops\nfrom tensorflow.python.client import timeline\nimport logging, time\nimport numpy as np\n\ndef test():\n    n = 5000\n\n    with tf.device('/gpu:0'):\n        A1 = tf.Variable(tf.ones_initializer(shape=[n, n]), name='A1')\n        B1 = A1\n        for l in xrange(10):\n            B1 = tf.matmul(A1, B1, name=\"chain1\")\n\n    with tf.device('/gpu:1'):\n        A2 = tf.Variable(tf.ones_initializer(shape=[n, n]), name='A2')\n        B2 = A2\n        for l in xrange(10):\n            B2 = tf.matmul(A2, B2, name=\"chain2\")\n        C = tf.matmul(B1, B2)\n\n    run_metadata = tf.RunMetadata()\n    start = time.time()\n    logging.info('started')\n    sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=False, log_device_placement=True))\n    sess.run(tf.initialize_all_variables())\n    # do warm-run\n    sess.run([C.op],\n             options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n             run_metadata=run_metadata)\n    run_metadata = tf.RunMetadata()\n    sess.run([C.op],\n             options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n             run_metadata=run_metadata)\n    logging.info('writing trace')\n    trace = timeline.Timeline(step_stats=run_metadata.step_stats)\n    trace_file = open('timeline.ctf.json', 'w')\n    trace_file.write(trace.generate_chrome_trace_format(show_memory=True))\n    logging.info('trace written')\n    end = time.time()\n    logging.info('computed')\n    logging.info(end - start)\n\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n    test()\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Predict values from complex Rjags model\r\n                \r\nIt's the first time I'm working with R2Jags, MCM chains and Bayesian models and I'm having trouble to compute the predicted values for my model.\nThe model is based on research by Hallmann et al. 2017 (https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0185809), specifically the basic model (R code can be found in the appendix of the paper)\nHere's my jags code\n```\ncat(\"model{\n## Likelihood function for the latent expected daily biomass\nfor (i in 1:n) {\nm_bio[i] ~ dnorm(sum(y[tau1[i]:tau2[i]]), sig_sq[i])\nsig_sq[i] <- 1/Var[i]\nVar[i] <- sum(vr[tau1[i]:tau2[i]])\n}\n\n## Likelihood function for muHat, it's dependent function and variance\nfor (i in 1:ndaily) {\nz[i] <- exp(y[i])\ny[i] <- g_intcp + log.lambda * year[i] + c[1] * daynr[i] + c[2] * daynr2[i] +\n  c[3] * daynr[i] * year[i] + c[4] * daynr2[i] * year[i] + b[loctype[i]] +\n  eps[plot[i]]\nvr[i] <- exp(2 * y[i] + lvar) * (exp(lvar) - 1)\n} \n\n## Priors\ng_intcp ~ dnorm(0, .01)\nlog.lambda ~ dnorm(0, .01)\nb[1] <- 0\nfor( i in 2:3) {b[i] ~ dnorm(0, .01)}\nfor( i in 1:4) {c[i] ~ dnorm(0, .01)}\nsdhat ~ dunif(0, 5)\nlvar <- pow(sdhat, 2)\nfor (i in 1:nrandom) {\neps[i] ~ dnorm(0, tau.re)\n}\ntau.re <- pow(sd.re, -2)\nsd.re ~ dunif(0, 1)\n}\n```\n\nThe mathematical equations can be found in the paper (eqs. 2, 3, 4, 6)\nI'm trying to get values for m_bio. I've looked into other posts like this one: How to predict values using estimates from rjags / JAGS but couldn't 'extrapolate' the solution from the simple regression formula (a + b * x) to mine.\nI would start by extracting the mean of every parameter, with something along the lines of this:\n```\njags$BUGSoutput$mean\n```\n\nThe part where I'm stuck is the matrix multiplication. What changes when I have more than one predictor ?\nI'm also unsure about what I have to do after that. If I understood the model correctly, I need to do that with all three equations, i.e. z[i], y[i], and vr[i] to then be able to calculate the values of m_bio (and the dependent eqs. sig_sq and Var), is that correct ?\nHope I adequately conveyed my problem. Appreciate any and all replies :)\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How to properly recurse and update values within a self-referential struct?\r\n                \r\nI have a linked-list like chain of structs that point to eachother. Normally it wouldn't be so difficult, but I'm running into problems freeing memory that has already been freed, because different structs can point to the same struct down below. Now, I am not referring to freeing a node itself, but rather an element within the node (a matrix). The issue is not that I am freeing an object that I am referencing later, it is that I am freeing a member of an object multiple times. It looks like this:\n```\n      d\n     / \\\n    c   b\n  /   \\\n a     b\n```\n\nwhere if I just recurse through the graph, I'll end up freeing a member of ```\nb```\n twice. Thus, I need a way to update ```\nb```\n's state with some boolean value ```\ndone```\n after I free it's member once so that when I come across it a second time I can avoid freeing something that has already been freed.\nThe structure ```\nobj```\n is acting as a sort of node within this chain. The goal is for ```\nprev```\n to be an array of previous nodes (order doesn't matter). If a node ```\na```\n has a previous node ```\nprev```\n ```\nb```\n, where ```\nb```\n also has ```\nprev```\n set to say, ```\nc```\n, the purpose is to be able to recurse through until you find all nodes that have no ```\nprev```\n set (effectively a leaf node). The issue is that, the way this is currently implemented, updating the states of any nodes that are stored in ```\nprev```\n does not actually update the value of the initial ```\nnode```\n - instead, it just updates the value of the node within ```\nobj->prev```\n.\nI have some test code for the scenario that I am dealing with:\n```\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct obj obj;\nstruct obj {\n    char name;\n    int done;\n    obj* prev;\n};\n\nvoid recurse(obj *o) {\n    \n    printf(\"(before) node %c: %i\\n\", o->name, o->done);\n    o->done = 0;\n    printf(\"(after) node %c: %i\\n\", o->name, o->done);\n\n    if (o->prev) {\n        // *this* should be generalized to handle for n elems in \n        // prev, and can be handled by just adding a num_prev value \n        // to obj\n        recurse(o->prev);\n        recurse(o->prev+1);\n    }\n}\n\nint main() {\n\n    obj node1 = {'a', 1, NULL};\n    obj node2 = {'b', 1, NULL};\n\n    obj node3 = {'c', 0, NULL};\n    node3.prev = (obj *)malloc(2 * sizeof(obj));\n    *node3.prev = node1;\n    *(node3.prev+1) = node2;\n\n    obj node4 = {'d', 0, NULL};\n    node4.prev = (obj *)malloc(2 * sizeof(obj));\n    *node4.prev = node3;\n    *(node4.prev+1) = node2;\n\n    recurse(&node4);\n    printf(\"(final) node %c: %i\\n\", node1.name, node1.done);\n    printf(\"(final) node %c: %i\\n\", node2.name, node2.done);\n\n    free(node3.prev);\n    free(node4.prev);\n}\n```\n\nwhere the output ends up being:\n```\n(before) node d: 0\n(after) node d: 0\n(before) node c: 0\n(after) node c: 0\n(before) node a: 1\n(after) node a: 0\n(before) node b: 1\n(after) node b: 0\n(before) node b: 1\n(after) node b: 0\n(final) node a: 1\n(final) node b: 1\n```\n\nAs you can see through the results, two things are happening. First, ```\nb```\n (node2) is getting recursed twice, but the second time the value is still set to ```\n1```\n (even though it was just set to ```\n0```\n). The second thing is that after the whole program execution, ```\na```\n (node1) and ```\nb```\n (node2) are both not updated.\nI think it's something like: I'm only updating the local (copied) pointer of ```\na->val```\n and not the actual pointer of ```\na```\n (I think that sounds right).\n    ", "Answer": "\r\nThanks for the final update.\nA few things. Unless you have complexities beyond what's in your posted code, doing a ```\nmalloc```\n on ```\nobj->prev```\n isn't needed. You can just do: ```\nobj *prev[2]```\n instead.\nAlso, I'd use a custom allocate function to simplify.\nThe real issue seems to be not using ```\ndone```\n correctly. When created, all nodes should set it to zero. Then, ```\nrecurse```\n should check ```\ndone```\n and return immediately if ```\ndone```\n is set. Then, ```\nrecurse```\n should set ```\ndone```\n.\nThis may not be what you're thinking of, but I think it will get you closer.\nI've refactored your code to illustrate:\n```\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct obj obj;\nstruct obj {\n    char name;\n    int done;\n    obj *link[2];\n};\n#define left    link[0]\n#define right   link[1]\n\n#ifdef DEBUG\n#define dbgprt(_fmt...)         printf(_fmt)\n#else\n#define dbgprt(_fmt...)         /**/\n#endif\n\nvoid\nrecurse(obj *o)\n{\n\n    if (o->done)\n        return;\n\n    dbgprt(\"recurse: ENTER '%c'\\n\",o->name);\n\n    printf(\"(before) node %c: %i\\n\", o->name, o->done);\n    o->done = 1;\n    printf(\"(after) node %c: %i\\n\", o->name, o->done);\n\n#if 0\n    if (o->prev) {\n        // *this* should be generalized to handle for n elems in\n        // prev, and can be handled by just adding a num_prev value\n        // to obj\n        recurse(o->left);\n        recurse(o->right);\n    }\n#else\n    if (o->left)\n        recurse(o->left);\n    if (o->left)\n        recurse(o->right);\n#endif\n\n    dbgprt(\"recurse: EXIT '%c'\\n\",o->name);\n}\n\nobj *\nnewnode(char name,int done)\n{\n    obj *node = calloc(1,sizeof(obj));\n    node->name = name;\n#if 0\n    node->done = done;\n#endif\n    return node;\n}\n\nint\nmain()\n{\n\n    obj *node_a = newnode('a',1);\n    obj *node_b = newnode('b',1);\n    obj *node_c = newnode('c',0);\n\n    node_c->left = node_a;\n    node_c->right = node_b;\n\n    obj *node_d = newnode('d',0);\n    node_d->left = node_c;\n    node_d->right = node_b;\n\n    recurse(node_d);\n\n    printf(\"(final) node %c: %i\\n\", node_a->name, node_a->done);\n    printf(\"(final) node %c: %i\\n\", node_b->name, node_b->done);\n\n    return 0;\n}\n```\n\n\nHere's the output:\n```\n(before) node d: 0\n(after) node d: 1\n(before) node c: 0\n(after) node c: 1\n(before) node a: 0\n(after) node a: 1\n(before) node b: 0\n(after) node b: 1\n(final) node a: 1\n(final) node b: 1\n```\n\n\nUPDATE:\n\nAh yes okay this is far closer, I think this makes a lot more sense. The big thing that's missing is I need to be able to define n children on ```\nobj->link```\n on demand. Sometimes it could have one child, sometimes it could have 5. That was why I was using the ```\nmalloc```\n + a pointer. Is there any way you could imagine on how to avoid doing ```\nlink[2]```\n and being able to define the number of children when instantiating the struct?\n\nIf, when you create the parent, you know the number of children, you can do a single ```\ncalloc```\n for ```\nlink```\n. This is less allocating, but you may be allocating child pointers that you don't use.\n```\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct obj obj;\nstruct obj {\n    char name;\n    int done;\n\n    int ncld;\n    obj **link;\n};\n\nvoid\nrecurse(obj *o)\n{\n    obj *cld;\n\n    if (o == NULL)\n        return;\n    if (o->done)\n        return;\n\n    printf(\"(before) node %c: %i\\n\", o->name, o->done);\n    o->done = 1;\n\n    for (int idx = 0;  idx < o->ncld;  ++idx) {\n        cld = o->link[idx];\n        recurse(cld);\n    }\n\n    printf(\"(after) node %c: %i\\n\", o->name, o->done);\n}\n\nobj *\nnewnode(char name,int ncld)\n{\n    obj *node = calloc(1,sizeof(obj));\n\n    node->name = name;\n\n    node->ncld = ncld;\n    node->link = calloc(ncld,sizeof(obj **));\n\n    return node;\n}\n\nvoid\naddchild(obj *par,obj *cld)\n{\n\n    for (int idx = 0;  idx < par->ncld;  ++idx) {\n        if (par->link[idx] == NULL) {\n            par->link[idx] = cld;\n            break;\n        }\n    }\n}\n\nint\nmain()\n{\n\n    obj *node_a = newnode('a',2);\n    obj *node_b = newnode('b',2);\n\n    obj *node_c = newnode('c',2);\n    addchild(node_c,node_a);\n    addchild(node_c,node_b);\n\n    obj *node_d = newnode('d',2);\n    addchild(node_d,node_c);\n    addchild(node_d,node_b);\n\n    recurse(node_d);\n\n    printf(\"(final) node %c: %i\\n\", node_a->name, node_a->done);\n    printf(\"(final) node %c: %i\\n\", node_b->name, node_b->done);\n\n    return 0;\n}\n```\n\nIf you'd like to add an arbitrary number of children to a given node and you do not know the limit when you allocate the parent node, you can do this.\nIt has the virtue of never allocating more than you need but, do ```\nrealloc```\n every time a child is added to a parent can be expensive. This can be alleviated somewhat by having a cache of free/unused nodes in an allocation pool [not shown].\n```\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct obj obj;\nstruct obj {\n    char name;\n    int done;\n\n    int ncld;\n    obj **link;\n};\n\nvoid\nrecurse(obj *o)\n{\n    obj *cld;\n\n    if (o == NULL)\n        return;\n    if (o->done)\n        return;\n\n    printf(\"(before) node %c: %i\\n\", o->name, o->done);\n    o->done = 1;\n\n    for (int idx = 0;  idx < o->ncld;  ++idx) {\n        cld = o->link[idx];\n        recurse(cld);\n    }\n\n    printf(\"(after) node %c: %i\\n\", o->name, o->done);\n}\n\nobj *\nnewnode(char name)\n{\n    obj *node = calloc(1,sizeof(obj));\n\n    node->name = name;\n\n    return node;\n}\n\nvoid\naddchild(obj *par,obj *cld)\n{\n    int idx;\n\n    idx = par->ncld++;\n    par->link = realloc(par->link,sizeof(obj **) * par->ncld);\n    par->link[idx] = cld;\n}\n\nint\nmain()\n{\n\n    obj *node_a = newnode('a');\n    obj *node_b = newnode('b');\n\n    obj *node_c = newnode('c');\n    addchild(node_c,node_a);\n    addchild(node_c,node_b);\n\n    obj *node_d = newnode('d');\n    addchild(node_d,node_c);\n    addchild(node_d,node_b);\n\n    recurse(node_d);\n\n    printf(\"(final) node %c: %i\\n\", node_a->name, node_a->done);\n    printf(\"(final) node %c: %i\\n\", node_b->name, node_b->done);\n\n    return 0;\n}\n```\n\n\nFor what it's worth, there is a significant amount of complexity outside of just this functionality and it pretty much has to be generalized\n\nFair enough. If it's complex enough, the child ```\nlink```\n could, itself, be an indirect linked list instead of an array of pointers.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Retrieving value from Measure, and using it in further calculation in Power BI\r\n                \r\nCurrently working on Supply chain project and got multiple tables in hand for Stock on Hand (SOH), Inbound Orders (INBD_ORD), Sales (MB_SALES) as data tables and other lookup tables for Calendar LT, Product Codes LT and Warehouses LT (which stores respective details).\nNow, the task is to calculate SOH_EndOfMonth (SOH_EOM), based on the measures I have created for SOH, INBD_ORD, and Sales_FC in respective tables\n```\nMeasure SOH_SUM = SUM('AU - SOH Mar-23'[Quantity])```\n\n```\nMeasure INBD_ORD = SUM('Inbound Orders - 20-03'[Qty Ord])```\n\n```\nMeasure Sales_FC = SUM('MB_Sales (2)'[Sales FC])```\n\nJust so you guys know, all those tables are connected in data modelling pane in Power BI based on One-Many relationships.\nAs am new to PowerBI, so I am hoping this is a silly problem I've caused myself and can be worked around.\nNow I understand that the measures in Power BI stores a single value for the above created measures and it will not be more than a summation of specific column, but when tried to put in Matrix visual in Power BI, each measure breaks down as per Month and Product code as shown in snippet below;\nBreakdown of Measures as per Products and Months in Matrix\nFollowing above scenario, I have tried calculating a measure which is as below;\n```\nMeasure SOH_EOM = ([SOH_SUM] + [INBD_ORD]) - 'MB_Sales (2)'[Sales_FC]```\n\nThis is the formula am trying to implement where I want SOH_EOM for each month which should calculate SOH_SUM from previous month (which currently is not working and only calculating SOH for the current month and not fetching value from previous month), INBD_ORD for the current month and Sales_FC for the current month (Sales_FC is a fixed and hard coded value for each month)\nI am struggling a lot to calculate SOH_SUM for the last or previous month, as I want that value to be taken into account to calculate SOH_SUM for the next and following months.\nHighlighted Measures under consideration\nI will try to clarify more on this, if we take a look in the above snippet, from the highlighted measures, I want to retrieve the value from SOH_EOM for the month of February and take it into account for calculating SOH_SUM for the following month of March. Similarly, SOH_EOM of March to be taken into account for calculating SOH_SUM for April.\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Seemingly inexplicable result of CGAffineTransformInvert\r\n                \r\nFolks,  [Edited at end to add new information]\n\nI am either at my wit's end or completely lacking in wits, not sure which, so any help would be loverly…  \n\nI have two views in a container view. The state of each subview is defined, in part, by a CGAffineTransform. Call each 'initial' transform 'M', then at some time, after an arbitrary series of gestures, the 'final' state is defined by transform 'N'. The task is to extract the cumulative effect of the gestures in a transform 'Q' such that: \n\nQ: QM -> N  \n\nso I thought \n\nQM(M_Inverse) -> N(M_Inverse)\n\ni.e.\nQ = N(M_Inverse), problem solved [NOT].\n\nTested the simple code below (now peppered with nslogs) with the simplest case (a translation in X-Y applied equally to both subviews (not that they should matter because everything here is about transforms, but anyways).\n\n```\n- (void) saveLastTransform:(BOOL)returnA {\nif (returnA) {\n    helper.xformLastA  = CGAffineTransformIdentity;\n    if (svDelegate.isAlignmentActivated) {\n        if ((int)(100.0 * helper.xformDefaultA.a) != 0) {\n            NSLog(@\"AM = %f, %f, %f\", helper.xformDefaultA.a, helper.xformDefaultA.b, helper.xformDefaultA.tx);\n            NSLog(@\"     %f, %f, %f\", helper.xformDefaultA.c, helper.xformDefaultA.d, helper.xformDefaultA.ty);\n            CGAffineTransform defInvA = CGAffineTransformInvert(helper.xformDefaultA);\n            NSLog(@\"AM_1 = %f, %f, %f\", defInvA.a, defInvA.b, defInvA.tx);\n            NSLog(@\"       %f, %f, %f\", defInvA.c, defInvA.d, defInvA.ty);\n            CGAffineTransform defInvAInv = CGAffineTransformInvert(defInvA);\n            NSLog(@\"AM_1_1 = %f, %f, %f\", defInvAInv.a, defInvAInv.b, defInvAInv.tx);\n            NSLog(@\"         %f, %f, %f\", defInvAInv.c, defInvAInv.d, defInvAInv.ty);\n            CGAffineTransform ident = CGAffineTransformConcat(defInvA, helper.xformDefaultA);\n            NSLog(@\"Identity? = %f, %f, %f\", ident.a, ident.b, ident.tx);\n            NSLog(@\"            %f, %f, %f\", ident.c, ident.d, ident.ty);\n            ident = CGAffineTransformConcat(defInvA, defInvAInv);\n            NSLog(@\"Identity? = %f, %f, %f\", ident.a, ident.b, ident.tx);\n            NSLog(@\"            %f, %f, %f\", ident.c, ident.d, ident.ty);\n            ident = CGAffineTransformConcat(defInvAInv, defInvA);\n            NSLog(@\"Identity? = %f, %f, %f\", ident.a, ident.b, ident.tx);\n            NSLog(@\"            %f, %f, %f\", ident.c, ident.d, ident.ty);\n            helper.xformLastA  = CGAffineTransformConcat([self getActiveTransform:groupA], defInvA);\n            CGAffineTransform N = [self getActiveTransform:groupA];\n            NSLog(@\"AN = %f, %f, %f\", N.a, N.b, N.tx);\n            NSLog(@\"     %f, %f, %f\", N.c, N.d, N.ty);\n            NSLog(@\"AQ = %f, %f, %f\", helper.xformLastA.a, helper.xformLastA.b, helper.xformLastA.tx);\n            NSLog(@\"     %f, %f, %f\", helper.xformLastA.c, helper.xformLastA.d, helper.xformLastA.ty);\n        }\n    }\n}\nelse {\n    helper.xformLastB  = CGAffineTransformIdentity;\n    if (svDelegate.isAlignmentActivated) {\n        if ((int)(100.0 * helper.xformDefaultB.a) != 0) {\n            NSLog(@\"BM = %f, %f, %f\", helper.xformDefaultB.a, helper.xformDefaultB.b, helper.xformDefaultB.tx);\n            NSLog(@\"     %f, %f, %f\", helper.xformDefaultB.c, helper.xformDefaultB.d, helper.xformDefaultB.ty);\n            CGAffineTransform defInvB = CGAffineTransformInvert(helper.xformDefaultB);\n            NSLog(@\"BM_1 = %f, %f, %f\", defInvB.a, defInvB.b, defInvB.tx);\n            NSLog(@\"       %f, %f, %f\", defInvB.c, defInvB.d, defInvB.ty);\n            CGAffineTransform defInvBInv = CGAffineTransformInvert(defInvB);\n            NSLog(@\"BM_1_1 = %f, %f, %f\", defInvBInv.a, defInvBInv.b, defInvBInv.tx);\n            NSLog(@\"         %f, %f, %f\", defInvBInv.c, defInvBInv.d, defInvBInv.ty);\n            CGAffineTransform ident = CGAffineTransformConcat(defInvB, helper.xformDefaultB);\n            NSLog(@\"Identity? = %f, %f, %f\", ident.a, ident.b, ident.tx);\n            NSLog(@\"            %f, %f, %f\", ident.c, ident.d, ident.ty);\n            ident = CGAffineTransformConcat(defInvB, defInvBInv);\n            NSLog(@\"Identity? = %f, %f, %f\", ident.a, ident.b, ident.tx);\n            NSLog(@\"            %f, %f, %f\", ident.c, ident.d, ident.ty);\n            ident = CGAffineTransformConcat(defInvBInv, defInvB);\n            NSLog(@\"Identity? = %f, %f, %f\", ident.a, ident.b, ident.tx);\n            NSLog(@\"            %f, %f, %f\", ident.c, ident.d, ident.ty);\n            helper.xformLastB  = CGAffineTransformConcat([self getActiveTransform:groupB], defInvB);\n            CGAffineTransform N = [self getActiveTransform:groupB];\n            NSLog(@\"BN = %f, %f, %f\", N.a, N.b, N.tx);\n            NSLog(@\"     %f, %f, %f\", N.c, N.d, N.ty);\n            NSLog(@\"BQ = %f, %f, %f\", helper.xformLastB.a, helper.xformLastB.b, helper.xformLastB.tx);\n            NSLog(@\"     %f, %f, %f\", helper.xformLastB.c, helper.xformLastB.d, helper.xformLastB.ty);\n        }\n    }\n}\n```\n\n\n}\n\nIf you look at the source matrices (AM & BM), you can 'see' the translation is the same for each set (AN & BN) but the inverse calculation for the second case is bizarre… either by hand or using the handy website: http://www.bluebit.gr/matrix-calculator/ I cannot see how that is a valid inverse (and the calculated Q reflects that fact).\n\n```\nOutput\n```\n\n\nTransform 'A'\n\n2013-05-17 13:19:18.349 AffineTest[16929:707] AM = 0.993584, -0.003874, 54.730000\n2013-05-17 13:19:18.351 AffineTest[16929:707]      0.005911, 0.993446, 26.889999\n2013-05-17 13:19:18.355 AffineTest[16929:707] AM_1 = 1.006434, 0.003925, -54.921101\n2013-05-17 13:19:18.359 AffineTest[16929:707]        -0.005988, 1.006574, -27.281588\n2013-05-17 13:19:18.371 AffineTest[16929:707] AM_1_1 = 0.993584, -0.003874, 54.730003\n2013-05-17 13:19:18.375 AffineTest[16929:707]          0.005911, 0.993446, 26.889999\n2013-05-17 13:19:18.379 AffineTest[16929:707] Identity? = 1.000000, 0.000000, -0.000002\n2013-05-17 13:19:18.383 AffineTest[16929:707]             0.000000, 1.000000, -0.000001\n2013-05-17 13:19:18.386 AffineTest[16929:707] Identity? = 1.000000, 0.000000, 0.000002\n2013-05-17 13:19:18.390 AffineTest[16929:707]             0.000000, 1.000000, -0.000001\n2013-05-17 13:19:18.393 AffineTest[16929:707] Identity? = 1.000000, -0.000000, 0.000001\n2013-05-17 13:19:18.397 AffineTest[16929:707]             -0.000000, 1.000000, -0.000000\n2013-05-17 13:19:18.401 AffineTest[16929:707] AN = 0.993584, -0.003874, 308.729980\n2013-05-17 13:19:18.405 AffineTest[16929:707]      0.005911, 0.993446, 220.889999\n2013-05-17 13:19:18.408 AffineTest[16929:707] AQ = 1.000000, -0.000000, 254.472458\n2013-05-17 13:19:18.411 AffineTest[16929:707]      -0.000000, 1.000000, 196.272278  \n\nTransform 'B'\n\n2013-05-17 13:19:18.415 AffineTest[16929:707] BM = 0.753817, 0.038102, 344.529999\n2013-05-17 13:19:18.419 AffineTest[16929:707]      -0.041526, 0.740303, 152.130005\n2013-05-17 13:19:18.422 AffineTest[16929:707] BM_1 = 1.322831, -0.068084, -467.043274\n2013-05-17 13:19:18.425 AffineTest[16929:707]        0.074201, 1.346979, -181.458923\n2013-05-17 13:19:18.429 AffineTest[16929:707] BM_1_1 = 0.753817, 0.038102, 344.530029\n2013-05-17 13:19:18.432 AffineTest[16929:707]          -0.041526, 0.740303, 152.130005\n2013-05-17 13:19:18.435 AffineTest[16929:707] Identity? = 1.000000, -0.000000, -0.000008\n2013-05-17 13:19:18.439 AffineTest[16929:707]             -0.000000, 1.000000, 0.000003\n2013-05-17 13:19:18.442 AffineTest[16929:707] Identity? = 1.000000, -0.000000, -0.000005\n2013-05-17 13:19:18.446 AffineTest[16929:707]             0.000000, 1.000000, 0.000003\n2013-05-17 13:19:18.449 AffineTest[16929:707] Identity? = 1.000000, -0.000000, 0.000012\n2013-05-17 13:19:18.452 AffineTest[16929:707]             0.000000, 1.000000, 0.000007\n2013-05-17 13:19:18.456 AffineTest[16929:707] BN = 0.753817, 0.038102, 598.530029\n2013-05-17 13:19:18.459 AffineTest[16929:707]      -0.041526, 0.740303, 346.130005\n2013-05-17 13:19:18.463 AffineTest[16929:707] BQ = 1.000000, 0.000000, 350.394165\n2013-05-17 13:19:18.466 AffineTest[16929:707]      0.000000, 1.000000, 244.020630  \n\nYet multiple inversions restore the original transform and iOS says they are true inverses. Can someone please tell me what [blinding flash of the obvious] I'm missing here? Thanks!\n\nEdit. \n\nTurns out some of this is due to iOS convention that x' = xT instead of Tx so that the matrix is\n\n|a  b  0|\n|c  d  0|\n|tx ty 1|  \n\ninstead of the usual convention\n\n|a  b tx|\n|c  d ty|\n|0  0  1|  \n\nso conventional matrix algebra seems to not apply. If I follow the chain down for the second case (using an external tool) I get:\n\nM matrix:\n  0.754   0.038 344.530\n -0.042   0.740 152.130\n  0.000   0.000   1.000  \n\nM Inverse:\n   1.322   -0.068 -445.302\n   0.075    1.347 -230.855\n   0.000    0.000    1.000  \n\nN Matrix\n  0.754   0.038 598.530\n -0.042   0.740 346.130\n  0.000   0.000   1.000  \n\nQ Matrix  = N x M-Inverse [CORRECT TRANSLATION]\n  0.999   0.000 254.058\n  0.001   1.000 193.719\n  0.000   0.000   1.000  \n\nBut using iOS form you get:\n\nM matrix:\n  0.754   0.038   0.000\n -0.042   0.740   0.000\n344.530 152.130   1.000  \n\nM Inverse:\n   1.323   -0.068    0.000\n   0.074    1.347    0.000\n-467.043 -181.459    1.000  \n\nN Matrix:\n  0.754   0.038   0.000\n -0.042   0.740   0.000\n598.530 346.130   1.000  \n\nQ Matrix = N x M-Inverse [WRONG TRANSLATION]\n  1.000   0.000   0.000\n  0.000   1.000   0.000\n350.426 244.078   1.000  \n\nBut Q' = M-Inverse x N [CORRECT??? TRANSLATION]\n  1.000   0.000   0.000\n -0.001   1.000   0.000\n254.001 194.103   1.000  \n\nThis just seems so wrong - what on earth is going on here. Is there an alternate universe in which this makes [mathematical] sense???\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "CRAN package submission: \"Error: C stack usage is too close to the limit\"\r\n                \r\nRight upfront: this is an issue I encountered when submitting an R package to CRAN. So I\n\n\ndont have control of the stack size (as the issue occured on one of CRANs platforms)\nI cant provide a reproducible example (as I dont know the exact configurations on CRAN)\n\n\nProblem\n\nWhen trying to submit the cSEM.DGP package to CRAN the automatic pretest (for Debian x86_64-pc-linux-gnu; not for Windows!) failed with the NOTE: ```\nC stack usage  7975520 is too close to the limit```\n. \n\nI know this is caused by a function with three arguments whose body is about 800 rows long. The function body consists of additions and multiplications of these arguments. It is the function ```\nvarzeta6()```\n which you find here (from row 647 onwards).\n\nHow can I adress this?\n\nThings I cant do:\n\n\nprovide a reproducible example (at least I would not know how)\nchange the stack size\n\n\nThings I am thinking of:\n\n\ntry to break the function into smaller pieces. But I dont know how to best do that.\nsomehow precompile? the function (to be honest, I am just guessing) so CRAN doesnt complain?\n\n\nLet me know your ideas!\n\nDetails / Background\n\nThe reason why ```\nvarzeta6()```\n (and ```\nvarzeta4()```\n / ```\nvarzeta5()```\n and even more so ```\nvarzeta7()```\n) are so long and R-inefficient is that they are essentially copy-pasted from mathematica (after simplifying the mathematica code as good as possible and adapting it to be valid R code). Hence, the code is by no means R-optimized (which @MauritsEvers righly pointed out).\n\nWhy do we need mathematica? Because what we need is the general form for the model-implied construct correlation matrix of a recursive strucutral equation model with up to 8 constructs as a function of the parameters of the model equations. In addition there are constraints.\nTo get a feel for the problem, lets take a system of two equations that can be solved recursivly:\n\n\nY2 = beta1*Y1 + zeta1 \nY3 = beta2*Y1 + beta3*Y2 + zeta2\n\n\nWhat we are interested in is the covariances: E(Y1*Y2), E(Y1*Y3), and E(Y2*Y3) as a function of beta1, beta2, beta3 under the constraint that \n\n\nE(Y1) = E(Y2) = E(Y3) = 0, \nE(Y1^2) = E(Y2^2) = E(Y3^3) = 1\nE(Yi*zeta_j) = 0 (with i = 1, 2, 3 and j = 1, 2)\n\n\nFor such a simple model, this is rather trivial:\n\n\nE(Y1*Y2) = E(Y1*(beta1*Y1 + zeta1) = beta1*E(Y1^2) + E(Y1*zeta1) = beta1\nE(Y1*Y3) = E(Y1*(beta2*Y1 + beta3*(beta1*Y1 + zeta1) + zeta2) = beta2 + beta3*beta1\nE(Y2*Y3) = ...\n\n\nBut you see how quickly this gets messy when you add Y4, Y5, until Y8.\nIn general the model-implied construct correlation matrix can be written as (the expression actually looks more complicated because we also allow for up to 5 exgenous constructs as well. This is why ```\nvarzeta1()```\n already looks complicated. But ignore this for now.):\n\n\nV(Y) = (I - B)^-1 V(zeta)(I - B)'^-1\n\n\nwhere I is the identity matrix and B a lower triangular matrix of model parameters (the betas). V(zeta) is a diagonal matrix. The functions ```\nvarzeta1()```\n, ```\nvarzeta2()```\n, ..., ```\nvarzeta7()```\n compute the main diagonal elements. Since we constrain Var(Yi) to always be 1, the variances of the zetas follow. Take for example the equation Var(Y2) = beta1^2*Var(Y1) + Var(zeta1) --> Var(zeta1) = 1 - beta1^2. This looks simple here, but is becomes extremly complicated when we take the variance of, say, the 6th equation in such a chain of recursive equations because Var(zeta6) depends on all previous covariances betwenn Y1, ..., Y5 which are themselves dependend on their respective previous covariances.\n\nOk I dont know if that makes things any clearer. Here are the main point:\n\n\nThe code for ```\nvarzeta1()```\n, ..., ```\nvarzeta7()```\n is copy pasted from mathematica and hence not R-optimized.\nMathematica is required because, as far as I know, R cannot handle symbolic calculations.\nI could R-optimze \"by hand\" (which is extremly tedious)\nI think the structure of the ```\nvarzetaX()```\n must be taken as given. The question therefore is: can I somehow use this function anyway? \n\n    ", "Answer": "\r\nOnce conceivable approach is to try to convince the CRAN maintainers that there's no easy way for you to fix the problem.  This is a ```\nNOTE```\n, not a ```\nWARNING```\n; The CRAN repository policy says \n\n\n  In principle, packages must pass R CMD check without warnings or significant notes to be admitted to the main CRAN package area. If there are warnings or notes you cannot eliminate (for example because you believe them to be spurious) send an explanatory note as part of your covering email, or as a comment on the submission form\n\n\nSo, you could take a chance that your well-reasoned explanation (in the comments field on the submission form) will convince the CRAN maintainers. In the long run it would be best to find a way to simplify the computations, but it might not be necessary to do it before submission to CRAN.\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Parametrizing test with multiple fixtures that accept arguments [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        How to concatenate several parametrized fixtures into a new fixture in py.test?\r\n                            \r\n                                (3 answers)\r\n                            \r\n                    \r\n                Closed 4 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI am trying to test a math function that I wrote. I would like to supply data to it from a number of different fixtures. The issue is that all of the fixtures accept different fixture parameters of their own.\n\nThe test that I run is always the same (```\ntest_myfunc```\n in the example), and the fixtures that I want to plug into it all have the same compatible return values (```\nclean_data```\n and ```\nnoisy_data```\n in the code). I would therefore like to \"chain\" these two fixtures together so that one or the other will provide inputs to the test.\n\nHere is what the setup looks like:\n\n```\nimport numpy as np\nimport pytest\nfrom scipy import stats\n\ndef myfunc(x, y):\n    return True\n\n_noises = {\n    'normal': lambda scale, n: np.random.normal(scale=scale, size=n),\n    'uniform': lambda scale, n: np.random.uniform(-scale, scale, size=n),\n    'triangle': lambda scale, n: np.random.triangular(-scale, 0, scale, size=n),\n}\n\n@pytest.fixture(params=[10**x for x in range(1, 4)])\ndef x_data(request):\n    \"\"\" Run the test on a few different densities \"\"\"\n    return np.linspace(-10, 10, request.param)\n\n@pytest.fixture(params=[0, 1, 0xABCD, 0x1234])\ndef random_seed(request):\n    \"\"\" Run the test for a bunch of datasets, but reporoducibly \"\"\"\n    np.random.seed(request.param)\n\n@pytest.fixture(params=np.arange(0.5, 5.5, 0.5))\ndef shape(request):\n    \"\"\" Run the test with a bunch of different curve shapes \"\"\"\n    return request.param\n\n@pytest.fixture()\ndef clean_data(x_data, shape):\n    \"\"\" Get a datset with no noise \"\"\"\n    return shape, stats.gamma.pdf(x_data, shape)\n\n@pytest.fixture(params=[\"triangle\", \"uniform\", \"normal\"])\ndef noisy_data(request, clean_data, random_seed):\n    shape, base = clean_data\n    noise = _noises[request.param](10, base.shape)\n    return shape, base + noise\n\ndef test_myfunc(x_data, data):\n    shape, y_data = data\n    assert myfunc(x_data, y_data)\n```\n\n\nThe reason that I am using so many fixtures is that I want to run the complete matrix of tests, with the ability to enable, disable, xfail, etc. any of them at will.\n\nSince the ```\nclean_data```\n and ```\nnoisy_data```\n fixtures return the same type of result, I would like to be able to use both of them for my test, one after the other. How do I run a single test with multiple fixtures that accept arguments?\n\nIf possible, I would like to avoid test generation. I am familiar with the idea of indirectly parametrizing the test, for example as in Running the same test on two different fixtures. I have tried to create a meta-fixture that can execute the y-data providers by name:\n\n```\n@pytest.fixture()\ndef data(request):\n    \"\"\" Get the appropriate datset based on the request \"\"\"\n    return request.getfuncargvalue(request.param)\n\n@pytest.mark.parametrize('data', ['clean_data', 'noisy_data'], indirect=True)\ndef test_myfunc(x_data, data):\n    shape, y_data = data\n    assert myfunc(x_data, y_data)\n```\n\n\nWhen I run the tests with\n\n```\npytest -v pytest-parametrized.py\n```\n\n\nI get a slew of errors, which all seem to point at the fact that the indirected fixture require parameters, which aren't supplied:\n\n```\n_________________ ERROR at setup of test_myfunc[10-clean_data] _________________\n\nself = <_pytest.python.CallSpec2 object at 0x7f8a4ff06518>, name = 'shape'\n\n    def getparam(self, name):\n        try:\n>           return self.params[name]\nE           KeyError: 'shape'\n\n/usr/lib/python3.6/site-packages/_pytest/python.py:684: KeyError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <SubRequest 'clean_data' for <Function 'test_myfunc[10-clean_data]'>>\nfixturedef = <FixtureDef name='shape' scope='function' baseid='pytest-parametrized.py' >\n\n    def _compute_fixture_value(self, fixturedef):\n        \"\"\"\n            Creates a SubRequest based on \"self\" and calls the execute method of the given fixturedef object. This will\n            force the FixtureDef object to throw away any previous results and compute a new fixture value, which\n            will be stored into the FixtureDef object itself.\n\n            :param FixtureDef fixturedef:\n            \"\"\"\n        # prepare a subrequest object before calling fixture function\n        # (latter managed by fixturedef)\n        argname = fixturedef.argname\n        funcitem = self._pyfuncitem\n        scope = fixturedef.scope\n        try:\n>           param = funcitem.callspec.getparam(argname)\n\n/usr/lib/python3.6/site-packages/_pytest/fixtures.py:484: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <_pytest.python.CallSpec2 object at 0x7f8a4ff06518>, name = 'shape'\n\n    def getparam(self, name):\n        try:\n            return self.params[name]\n        except KeyError:\n            if self._globalparam is NOTSET:\n>               raise ValueError(name)\nE               ValueError: shape\n\n/usr/lib/python3.6/site-packages/_pytest/python.py:687: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nrequest = <SubRequest 'data' for <Function 'test_myfunc[10-clean_data]'>>\n\n    @pytest.fixture()\n    def data(request):\n        \"\"\" Get the appropriate datset based on the request \"\"\"\n>       return request.getfuncargvalue(request.param)\n\npytest-parametrized.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.6/site-packages/_pytest/fixtures.py:439: in getfuncargvalue\n    return self.getfixturevalue(argname)\n/usr/lib/python3.6/site-packages/_pytest/fixtures.py:430: in getfixturevalue\n    return self._get_active_fixturedef(argname).cached_result[0]\n/usr/lib/python3.6/site-packages/_pytest/fixtures.py:455: in _get_active_fixturedef\n    self._compute_fixture_value(fixturedef)\n/usr/lib/python3.6/site-packages/_pytest/fixtures.py:526: in _compute_fixture_value\n    fixturedef.execute(request=subrequest)\n/usr/lib/python3.6/site-packages/_pytest/fixtures.py:778: in execute\n    fixturedef = request._get_active_fixturedef(argname)\n/usr/lib/python3.6/site-packages/_pytest/fixtures.py:455: in _get_active_fixturedef\n    self._compute_fixture_value(fixturedef)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <SubRequest 'clean_data' for <Function 'test_myfunc[10-clean_data]'>>\nfixturedef = <FixtureDef name='shape' scope='function' baseid='pytest-parametrized.py' >\n\n    def _compute_fixture_value(self, fixturedef):\n        \"\"\"\n            Creates a SubRequest based on \"self\" and calls the execute method of the given fixturedef object. This will\n            force the FixtureDef object to throw away any previous results and compute a new fixture value, which\n            will be stored into the FixtureDef object itself.\n\n            :param FixtureDef fixturedef:\n            \"\"\"\n        # prepare a subrequest object before calling fixture function\n        # (latter managed by fixturedef)\n        argname = fixturedef.argname\n        funcitem = self._pyfuncitem\n        scope = fixturedef.scope\n        try:\n            param = funcitem.callspec.getparam(argname)\n        except (AttributeError, ValueError):\n            param = NOTSET\n            param_index = 0\n            if fixturedef.params is not None:\n                frame = inspect.stack()[3]\n                frameinfo = inspect.getframeinfo(frame[0])\n                source_path = frameinfo.filename\n                source_lineno = frameinfo.lineno\n                source_path = py.path.local(source_path)\n                if source_path.relto(funcitem.config.rootdir):\n                    source_path = source_path.relto(funcitem.config.rootdir)\n                msg = (\n                    \"The requested fixture has no parameter defined for the \"\n                    \"current test.\\n\\nRequested fixture '{0}' defined in:\\n{1}\"\n                    \"\\n\\nRequested here:\\n{2}:{3}\".format(\n                        fixturedef.argname,\n                        getlocation(fixturedef.func, funcitem.config.rootdir),\n                        source_path,\n                        source_lineno,\n                    )\n                )\n>               fail(msg)\nE               Failed: The requested fixture has no parameter defined for the current test.\nE               \nE               Requested fixture 'shape' defined in:\nE               pytest-parametrized.py:27\nE               \nE               Requested here:\nE               /usr/lib/python3.6/site-packages/_pytest/fixtures.py:526\n\n/usr/lib/python3.6/site-packages/_pytest/fixtures.py:506: Failed\n```\n\n\nIf supplying the missing parameters somehow is the answer, that's great, but I don't want to ask the question that way because I think I may be running into a massive XY problem here.\n    ", "Answer": "\r\nPassing fixture as parameters in the parametrization marker is not supported by ```\npytest```\n. See issue #349 for more details: Using fixtures in pytest.mark.parametrize. When in need of parametrizing with fixtures, I usually resort to creating an auxiliary fixture that accepts all the parameter fixtures and then parametrizing that indirectly in the test. Your example would thus become:\n\n```\n@pytest.fixture\ndef data(request, clean_data, noisy_data):\n    type = request.param\n    if type == 'clean':\n        return clean_data\n    elif type == 'noisy':\n        return noisy_data\n    else:\n        raise ValueError('unknown type')\n\n@pytest.mark.parametrize('data', ['clean', 'noisy'], indirect=True)\ndef test_myfunc(x_data, data):\n    shape, y_data = data\n    assert myfunc(x_data, y_data)\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "How to set up Jenkins for build, unit test and system tests\r\n                \r\nI want to set up Jenkins for a decent build chain for a JavaFX application that controls a robotic arm and other hardware:\n\n\nWe are using BitBucket with the Git Flow model.\nWe have 2 development modules and 1 System Test module in IntelliJ that we build with Maven.\nWe have Unit tests, Integration test and System tests. Unit and Integration tests use JUnit and can run on the Jenkins master, for the System tests we use TestNG and they can run the TestFX tests on a Jenkins agent.\n(I think TestNG is more suited for System tests than JUnit)\n\n\nDevelopment build project (build, unit+integration tests) was already in place. The Test chain has been recently set up by copying the development project, adding the system tests and ignoring the Unit/Integration tests. (so building the application is done twice)\n\nWe have 2 types of System tests:\n\n\nTests that are fairly simple and run on the application itself\nTests that are more complex and run on the application that interacts with several simulators for the robotic arm\n\n\nNow I need to set up the 2nd type of tests.\nMy question would be: what is the best way to set this up in Jenkins?\n\nI'm reading about Jenkins Pipelines and the Blue Ocean plugin here, about a matrix configuration project here. To me it is all a bit confusing what is the ideal way to achieve my goals.\n\nI have no clue how to scale from a testng.xml file in my SystemTest module to flexible tests.\nCan I put a sort of capabilities tag to tests so that the correct preconditions are set?  For example, for tests in category 1, only the main application needs to be started for TestFX. However, for tests in the category 2, several simulators needs to be started and configured. I think using a sort of capabilities tag, will make this much more maintainable.\n\nMy goals:\n\n\nEasy to maintain Jenkins flow\nEfficient building, so preference to copying artifacts instead of building a second time\nPossibility to split the system tests over multiple agents, preferably without me having to be concerned about what runs where (similar to Selenium Grid)\nCorrect dependencies (simulators etc) are started depending if the test needs them\nWe are looking into running the tests on VMs with OpenGL 3D acceleration due to a canvas used in the application. If tests are able to allocate, start, stop VMs on demand, that would be cool (but would only save some electricity)\nEasy reporting where all test results are gathered from all agents.  Notice that I prefer the JUnit report that highlights which tests were @Ignored. TestNg report format, doesn't say anything about @Ignored tests.\n\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Simplify huge conditional statement\r\n                \r\nAbstract\nThere are times in life when your signals are noisy and you want to go from this\n\nto this\n\nThere are many existing approaches that allow you to smooth data: local linear and polynomial regressions, different kinds of moving averages:\nhttps://en.wikipedia.org/wiki/Kernel_smoother\nhttps://homepages.inf.ed.ac.uk/rbf/HIPR2/gsmooth.htm\nhttps://www.stat.wisc.edu/~mchung/softwares/hk/hk.html\nhttps://matthew-brett.github.io/teaching/smoothing_intro.html\nHow to calculate a Gaussian kernel matrix efficiently in numpy?\nHow to smooth the blocks of a 3D voxel world?\nHowever I've found that for my case the best suited approach is gaussian kernel smoothing. It worked like a charm for me on a desktop but when switched to mobile device the algorithm stalled the device due to high computational requirements.\nOne of the reasons to that was the fact that prior to smoothing I had to equalize the sampling rate with other signal, which heavily increased the sampling rate and thus the amount of data required for processing.\nThis also yielded to the fact that the size of the gaussian kernel had to be tens of thousands of components which directly influenced the complexity of the algorithm for my naive approach it requires tens of thousands of elements in the filter to be multiplied and summed with tens of thousands of components from signal to receive just one component of smoothed data.\nThere is way to do gaussian kernel smoothing efficiently that requires the use of Fourier Transform which is very complex to implement efficiently.\nSo instead of going along this path I've thought that you could actually do smoothing a lot more efficiently without diving into complexities of Fourier Transforms.\nBasically any signal is just a collection of pairs ```\n[time, value]```\n ordered by time. When interpolated using linear interpolation it can always be represented with Polygonal chain and you can actually smooth one component of Polygonal chain (i.e. Line Segment) analytically. I won't dive deeper into how you actually compute the convolutional integral of analytically defined kernel over analytically defined line segment. It's just worth saying here that the result is a huge piecewise function:\n\nThat yields to a number of ```\nif```\n statements:\n```\npublic static Double Solution(Double x, Double w, Double x1, Double y1, Double x2, Double y2)\n{\n    Double result;\n\n    if (x + w < x2 && w + x1 <= x)\n    {\n        result = (x * y1 - x2 * y1 - x * y2 + x1 * y2) / (x1 - x2);\n    }\n    else if (x1 < x + w && x < x1 && x + w < x2)\n    {\n        result = Math.Pow(w + x - x1, 2) * ((w + x + 2 * x1 - (3 * x2)) * y1 - (w + x - x1) * y2) * Math.Pow(w, -2) / (x1 - x2) / 6;\n    }\n    else if (x == x1 && x + w < x2)\n    {\n        result = y1 / 2 + w * (y1 - y2) / (x1 - x2) / 6;\n    }\n    else if (x + w < x2 && x1 < x && x < w + x1)\n    {\n        result = Math.Pow(w, -2) / (x1 - x2) * (Math.Pow(w, 3) * (y1 - y2) + 3 * w * w * (-x2 * y1 + x * (y1 - y2) + x1 * y2) - Math.Pow(x - x1, 2) * ((x + 2 * x1 - (3 * x2)) * y1 + (-x + x1) * y2) + 3 * w * (x - x1) * ((x + x1 - (2 * x2)) * y1 + (-x + x1) * y2)) / 6;\n    }\n    else if (x2 <= x + w && x < x1)\n    {\n        result = (x1 - x2) * (2 * y1 * x1 + x2 * y1 + x1 * y2 + 2 * x2 * y2 - 3 * w * (y1 + y2) - 3 * x * (y1 + y2)) * Math.Pow(w, -2) / 6;\n    }\n    else if (x2 <= x && w + x1 <= x && x < w + x2)\n    {\n        result = -Math.Pow(w - x + x2, 2) * ((w - x + x2) * y1 + (-w + x - 3 * x1 + (2 * x2)) * y2) * Math.Pow(w, -2) / (x1 - x2) / 6;\n    }\n    else if (x2 <= x && x < w + x1)\n    {\n        result = -(x1 - x2) * (2 * y1 * x1 + x2 * y1 + x1 * y2 + 2 * x2 * y2 + 3 * w * (y1 + y2) - 3 * x * (y1 + y2)) * Math.Pow(w, -2) / 6;\n    }\n    else if (x == x1 && (x + w == x2 && (x2 <= x && x + w < x1 && w + x2 <= x || x < w + x1) || x < w + x1 && x2 <= x + w && x < x2))\n    {\n        result = (-x1 + x2) * (3 * w * (y1 + y2) + (x1 - x2) * (y1 + 2 * y2)) * Math.Pow(w, -2) / 6;\n    }\n    else if (x < x2 && x2 <= x + w && w + x1 <= x)\n    {\n        result = Math.Pow(w, -2) / (x1 - x2) * (Math.Pow(w, 3) * (-y1 + y2) + 3 * w * w * (-x2 * y1 + x * (y1 - y2) + x1 * y2) + Math.Pow(x - x2, 2) * ((-x + x2) * y1 + (x - 3 * x1 + (2 * x2)) * y2) + 3 * w * (x - x2) * (-2 * x1 * y2 + x * (-y1 + y2) + x2 * (y1 + y2))) / 6;\n    }\n    else if (x < x2 && x2 <= x + w && x1 < x && x < w + x1)\n    {\n        result = Math.Pow(w, -2) / (x1 - x2) * (-2 * Math.Pow(x1, 3) * y1 + 3 * x1 * x1 * x2 * y1 + Math.Pow(x2, 3) * y1 - Math.Pow(x1, 3) * y2 - 3 * x1 * (x2 * x2) * y2 + 2 * Math.Pow(x2, 3) * y2 + 2 * Math.Pow(x, 3) * (-y1 + y2) - 3 * w * Math.Pow(x1 - x2, 2) * (y1 + y2) + 6 * x * x * (x2 * y1 - x1 * y2) + 3 * x * (2 * x1 * x2 * (-y1 + y2) + x1 * x1 * (y1 + y2) - (x2 * x2) * (y1 + y2))) / 6;\n    }\n    else\n    {\n        result = 0.0e0;\n    }\n\n    return result;\n}\n```\n\nAnd here's how it visually looks like:\n\nYou can also combine multiple line segments via sum of smoothing functions for these segments\n\nThus reducing the computational complexity down to number of points that you have:\nThe problem\nIf statement above looks inefficient and there are numerical stability problems with it. When line segments defined by ```\nx1,y1,x2,y2```\n are getting big numbers the result explodes. I'm trying deal with these problems but it's harder than I expected. Even careful expansion of equations introduces some strange errors in to computation. So I thought it was a good idea to consult with StackOverflow to probably get more ideas on how to optimize this statement and make it more numerically stable.\nThank you in advance,\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "java - Google Foobar Challenge Level 3: doomsday-fuel [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs to be more focused. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\r\n                \r\n                    \r\n                        Closed 6 months ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI have been working on this java code for the doomsday-fuel problem which deals with the absorbing markov chains. It has passed every test except for test four. Is there any particular type of input I may have missed while testing my code? I have only about 12 hours left. I have tested four one dimensional arrays and am curious as to if this test failure is somehow a precision error or something else.\nContext:\nMaking fuel for the LAMBCHOP's reactor core is a tricky process because of the exotic matter involved. It starts as raw ore, then during processing, begins randomly changing between forms, eventually reaching a stable form. There may be multiple stable forms that a sample could ultimately reach, not all of which are useful as fuel.\nCommander Lambda has tasked you to help the scientists increase fuel creation efficiency by predicting the end state of a given ore sample. You have carefully studied the different structures that the ore can take and which transitions it undergoes. It appears that, while random, the probability of each structure transforming is fixed. That is, each time the ore is in 1 state, it has the same probabilities of entering the next state (which might be the same state).  You have recorded the observed transitions in a matrix. The others in the lab have hypothesized more exotic forms that the ore can become, but you haven't seen all of them.\nWrite a function solution(m) that takes an array of array of nonnegative ints representing how many times that state has gone to the next state and return an array of ints for each terminal state giving the exact probabilities of each terminal state, represented as the numerator for each state, then the denominator for all of them at the end and in simplest form. The matrix is at most 10 by 10. It is guaranteed that no matter which state the ore is in, there is a path from that state to a terminal state. That is, the processing will always eventually end in a stable state. The ore starts in state 0. The denominator will fit within a signed 32-bit integer during the calculation, as long as the fraction is simplified regularly.\n```\n    public static int[] returnFractionPair(double x) {\n        double tolerance = 1.0E-14;//Handles the extent of precision used\n        double numerator=1;//Kept as one because initially the decimal may be greater than zero\n        double numeratorStorage=0;\n        double denominator=0;\n        double denominatorStorage=1;//prevents division by zero\n        double decimal = x;\n        double comparison = 0;\n        do {\n            double flooredDecimal = (double)(int)decimal;//Floors decimal\n            double aux = numerator;//Sets auxilary to be the numerator\n            numerator =(flooredDecimal*numerator)+numeratorStorage;\n            numeratorStorage = aux;\n      \n            aux = denominator;\n        \n            denominator = (flooredDecimal*denominator)+denominatorStorage;\n            denominatorStorage = aux;\n            decimal = 1/(decimal-flooredDecimal);\n            comparison = x-(numerator/denominator);\n        } while( returnAbs(comparison) > (x*tolerance) );//Tests if the difference between the initial decimal and this new numerator/denominator is greater than that of x multiplied by the level of tolerance it has\n        int[] res = new int[]{(int)numerator, (int)denominator};\n        return res;\n    }\n    public static double returnAbs(double value){\n        if(value < 0){\n        value *= -1;\n        }\n        return value;\n    }\n    public static int getLCD(int[][] fractions){\n        int num = 0;\n        int den = 1;\n\n        int lcd = 1;\n        for(int i = 0; i < fractions.length; i++){\n        lcd *= fractions[i][den];\n        }\n        for(int i = 2; i < lcd; i++){\n            boolean foundLeastCommon = true;\n            for(int j = 0; j < fractions.length; j++){\n                if( (double)( i%fractions[j][den] ) != 0){\n                    foundLeastCommon = false;\n                }\n            }\n            if(foundLeastCommon == true){\n                lcd = i;\n                return lcd;\n            }\n        }\n        return lcd;\n    }\n    public static double[] returnRowSums(int[][] matrix){    \n      //Assume all values in matrix are positive\n        double[] sumsOfEachRow = new double[matrix.length];\n            for(int i = 0; i < matrix.length; i++){\n              for(int j = 0; j < matrix.length; j++){\n                  sumsOfEachRow[i] += matrix[i][j];\n              }\n            }\n            return sumsOfEachRow;\n    }\n    public static double returnMatrixCellSum(double[] row, double[] column){//Assume row size == column size.\n        if(row.length != column.length){\n            return 0;\n        }\n        double sum = 0;\n        for(int i = 0; i < row.length; i++){\n            sum += (column[i] * row[i]);\n        }\n        return sum;\n    }\n    public static int[] returnRearrangedIndices(double[] sumsOfEachRow){\n      int[] indicesOfRearrangedMatrix = new int[sumsOfEachRow.length];  \n\n      int indicesIndex = 0;\n      for(int i = 0; i < sumsOfEachRow.length; i++){ \n        if(sumsOfEachRow[i] <= 1){\n          indicesOfRearrangedMatrix[indicesIndex] = i;\n          indicesIndex++;\n        }//TerminalStates first\n      }\n      for(int i = 0; i < sumsOfEachRow.length; i++){ \n        if(sumsOfEachRow[i] > 1){\n          indicesOfRearrangedMatrix[indicesIndex] = i;\n          indicesIndex++;\n        }\n      }\n      return indicesOfRearrangedMatrix;\n    }\n  \n    public static double[][] subtractMatrix(double[][] matrix1, double[][] matrix2){//assumes matrices are of same dimensions\n        double[][] matrix3 = new double[matrix1.length][matrix1.length];\n        for(int i = 0; i < matrix1.length;i++){\n            for(int j = 0; j < matrix1[i].length; j++){\n                matrix3[i][j] = matrix1[i][j] - matrix2[i][j];\n            }\n        }\n        return matrix3;\n    }\n    public static double[][] rotateMatrix(double[][] matrix){\n        double[][] rotatedMatrix = new double[matrix[0].length][matrix.length];\n        for(int i = 0; i < rotatedMatrix.length;i++){\n          for(int j = 0; j < rotatedMatrix[0].length; j++){\n            rotatedMatrix[i][j] = matrix[j][i];\n          }\n        }\n      return rotatedMatrix;\n    }\n    public static double[][] getRemainingValues(double[][] matrix, int rowIgnored, int columnIgnored){\n      double[][] newMatrix = new double[matrix.length-1][matrix.length-1];\n      int iC = 0;\n      int iR = 0;\n      for(int k = 0; k < matrix.length; k++){\n        if(k != rowIgnored){\n          iR = 0;\n          for(int j = 0; j < matrix[k].length;j++){\n            if(j != columnIgnored){\n              newMatrix[iC][iR] = matrix[k][j];\n              iR++;\n            }\n          }\n          iC++;\n        }\n      }\n      return newMatrix;\n    }\n\n    public static double getDeterminant(double[][] matrix){\n      //uses top rows only\n      double determinant = 0;\n      if(matrix.length == 1 && matrix[0].length == 1){\n        return matrix[0][0];\n      }\n\n      boolean negative = false;\n      double[][] newMatrix = new double[matrix.length-1][matrix.length-1];\n      for(int i = 0; i < matrix.length; i++){\n        newMatrix = getRemainingValues(matrix, 0, i);\n        if(negative == false){\n          determinant += matrix[0][i]*getDeterminant(newMatrix);\n          negative = true;\n          }else{\n          determinant -= matrix[0][i]*getDeterminant(newMatrix);\n          negative = false;\n        }\n        //System.out.println(determinant);\n      }\n      return determinant;\n    }\n  \n    public static double[][] getMinorMatrix(double[][] matrix){\n      double[][] newMatrix = new double[matrix.length][matrix.length];\n        double[][] remainderMatrix;\n      if(matrix.length-1 != 0){\n        remainderMatrix = new double[matrix.length-1][matrix.length-1];\n      }else{\n        remainderMatrix = new double[matrix.length][matrix.length];\n      }\n      for(int i = 0; i < newMatrix.length;i++){\n        for(int j = 0; j < newMatrix.length;j++){\n          remainderMatrix = getRemainingValues(matrix, i, j);\n          newMatrix[i][j] = getDeterminant(remainderMatrix) + 0.0;//Prevent -0.0 float values\n        }\n      }\n      return newMatrix;\n    }\n\n    public static double[][] divideMatrixByScalar(double[][] matrix, double scalar){\n      double[][] newMatrix = new double[matrix.length][matrix[0].length];\n      newMatrix = matrix;\n      for(int i = 0; i < matrix.length; i++){\n        for(int j = 0; j < matrix[i].length;j++){\n          newMatrix[i][j] /= scalar;\n        }\n      }\n      return newMatrix;\n    }\n  \n    public static double[][] invertMatrix(double[][] matrix){\n      double[][] minorMatrix = new double[matrix.length][matrix.length];\n      if(minorMatrix.length == 2){\n        minorMatrix = matrix;\n\n        double temp = minorMatrix[0][0];\n        minorMatrix[0][0] = minorMatrix[1][1];\n        minorMatrix[1][1] = temp;\n        minorMatrix[0][1] *= -1;\n        minorMatrix[0][1] += 0;\n        minorMatrix[1][0] *= -1;\n        minorMatrix[1][0] += 0;\n      for(int i = 0; i < minorMatrix.length; i++){\n        for(int j = 0; j < minorMatrix[i].length; j++){\n            System.out.print(minorMatrix[i][j] + \" \");\n          }\n        System.out.print(\"\\n\");\n      }\n        }else{\n      minorMatrix = getMinorMatrix(matrix);\n      System.out.println(\"Getting minorMatrix\");\n      for(int i = 0; i < minorMatrix.length; i++){\n        for(int j = 0; j < minorMatrix[i].length; j++){\n            System.out.print(minorMatrix[i][j] + \" \");\n          }\n        System.out.print(\"\\n\");\n      }\n      boolean isNegative = false;\n      System.out.println(\"Getting adjoint of minorMatrix\");//Not doing things correctly\n      for(int i = 0; i < minorMatrix.length;i++){\n        for(int j = 0; j < minorMatrix[i].length;j++){\n            if(isNegative == true){\n              minorMatrix[i][j] *= -1;\n              minorMatrix[i][j] += 0;\n              isNegative = false;\n            }else{\n              isNegative = true;\n            }\n            System.out.print(minorMatrix[i][j] + \" \");\n          }\n          if(minorMatrix[i].length % 2 == 0){\n            if(isNegative == true){\n                isNegative = false;\n              }else{\n                isNegative = true;\n              }\n            }\n          System.out.print(\"\\n\");\n        }\n      \n        minorMatrix = rotateMatrix(minorMatrix);//rotates the minorMatrix\n      }\n      \n      double determinant = getDeterminant(matrix);\n      System.out.println(determinant);\n      if(determinant != 0){\n        minorMatrix = divideMatrixByScalar(minorMatrix, determinant);\n        System.out.println(\"Result\");\n              for(int i = 0; i < minorMatrix.length; i++){\n        for(int j = 0; j < minorMatrix[i].length; j++){\n            System.out.print(minorMatrix[i][j] + \" \");\n          }\n        System.out.print(\"\\n\");\n      }\n      return minorMatrix;//Inverse is good\n      }else{\n        return matrix;\n      }\n      \n    }\n    public static double[][] returnUnabsorbedToUnabsorbed(double[][] matrix, int terminalStates){//Assumes matrix layers go from absorbed to unabsorbed\n        double[][] unabsorbedToUnabsorbed = new double[matrix.length-terminalStates][matrix.length-terminalStates];\n        int uIndex = 0;\n        int uuIndex = 0;\n        for(int i = terminalStates; i < matrix.length;i++){\n          uuIndex = 0;\n          for(int j = terminalStates; j < matrix.length;j++){\n            unabsorbedToUnabsorbed[uIndex][uuIndex] = matrix[i][j];\n            uuIndex++;\n          }\n          uIndex++;\n        }\n      return unabsorbedToUnabsorbed;\n    }\n    public static double[][] returnUnabsorbedToAbsorbed(double[][] matrix, int terminalStates){//Assumes matrix layers go from absorbed to unabsorbed\n        double[][] unabsorbedToAbsorbed = new double[matrix.length-terminalStates][terminalStates];\n        int uIndex = 0;\n        int uuIndex = 0;\n        for(int i = terminalStates; i < matrix.length;i++){\n          uuIndex = 0;\n          for(int j = 0; j < terminalStates;j++){\n            unabsorbedToAbsorbed[uIndex][uuIndex] = matrix[i][j];\n            uuIndex++;\n          }\n          uIndex++;\n        }\n      return unabsorbedToAbsorbed;\n    }\n  \n  public static double[][] getFundamental(double[][] matrix){\n      double[][] modifiedMatrix = new double[matrix.length][matrix[0].length];\n      modifiedMatrix = matrix;\n      double[][] identity = new double[matrix.length][matrix.length];\n      for(int i = 0; i < identity.length; i++){\n        for(int j = 0;j < identity[i].length;j++){\n          if(i == j){\n            identity[i][j] = 1;\n          }else{\n            identity[i][j] = 0;\n          }\n        }\n      }\n      modifiedMatrix = subtractMatrix(identity, modifiedMatrix);//Modified matrix is returning properly\n      /*System.out.println(\"Getting matrix to be inverted\");\n      for(int i = 0; i < modifiedMatrix.length; i++){\n        for(int j = 0; j < modifiedMatrix[i].length; j++){\n            System.out.print(modifiedMatrix[i][j] + \" \");\n          }\n        System.out.print(\"\\n\");\n      }*/\n      modifiedMatrix = invertMatrix(modifiedMatrix);//Problem here(?)\n      return modifiedMatrix;\n    }\n\n  public static double[][] multiplyMatrix(double[][] matrix1, double[][] matrix2){//Assume all rows are equal.\n      double[][] result = new double[matrix1.length][matrix2[0].length];\n      double[][] rotatedM2 = new double[matrix2[0].length][matrix2.length];\n      rotatedM2 = rotateMatrix(matrix2);\n      for(int i = 0; i < result.length;i++){\n          for(int j = 0; j < result[i].length; j++){\n              result[i][j] = returnMatrixCellSum(matrix1[i], rotatedM2[j]);\n            //RotateMatrix does not increase matrix sums by how it should be\n          }\n      }\n      return result;\n    }\n  public static int[] algorithm(int[][] matrix, int startingPoint){\n        if(matrix.length == 0){\n          return new int[]{0, 1};\n        }\n        if(matrix.length == 1){\n          int[] ans = new int[matrix.length+1];\n          for(int i = 0; i < ans.length;i++){\n            ans[i] = 1;\n          }\n          for(int i = 0; i < ans.length; i++){\n            System.out.println(ans[i]);\n          }\n          return ans;\n        }\n        double[] sumsOfEachRow = new double[matrix.length];\n          sumsOfEachRow = returnRowSums(matrix);\n          \n          double[][] probMatrix = new double[matrix.length][matrix.length];\n          int terminalStates = 0;//Number of terminal states\n            for(int i = 0; i < probMatrix.length; i++){\n              for(int j = 0; j < probMatrix[i].length; j++){\n              if(sumsOfEachRow[i] != 0){\n                probMatrix[i][j] = (double)matrix[i][j];\n                probMatrix[i][j] /= sumsOfEachRow[i];\n              }else{\n                probMatrix[i][j] = 0;\n              }\n            }\n            }\n            boolean startingIsTerminal = false;\n            for(int i = 0; i < probMatrix.length;i++){\n              boolean foundOne = false;\n              for(int j = 0; j < probMatrix[i].length;j++){\n                if(probMatrix[i][j] == 1 && i == j){\n                  terminalStates++;\n                  foundOne = true;\n                  if(i == startingPoint){\n                    startingIsTerminal = true;\n                  }\n                }\n              }\n              if(foundOne == false){\n                if(sumsOfEachRow[i] == 0){\n                  terminalStates++;\n                }\n              }\n            }\n            if( (sumsOfEachRow[startingPoint] == 0) || startingIsTerminal == true){\n              int[] ans = new int[terminalStates+1];\n              for(int i = 0; i < terminalStates;i++){\n                if(i != startingPoint){\n                  ans[i] = 0;\n                }else{\n                  ans[i] = 1;\n                }\n              }\n              ans[terminalStates] = 1;\n                        for(int i = 0; i < ans.length; i++){\n            System.out.println(ans[i]);\n          }\n              return ans;\n            }\n          int[] indicesOfRearrangedMatrix = new int[probMatrix.length];\n          indicesOfRearrangedMatrix = returnRearrangedIndices(sumsOfEachRow);\n          double[][] rearranged = new double[probMatrix.length][probMatrix[0].length];\n          \n          for(int i = 0; i < matrix.length; i++){\n            for(int j = 0; j < matrix[i].length; j++){\n              rearranged[i][j] = probMatrix[indicesOfRearrangedMatrix[i]][indicesOfRearrangedMatrix[j]];\n              System.out.print(rearranged[i][j] + \" \");\n            }\n            System.out.print(\"\\n\");\n          }//Get rearranged matrix divided\n          System.out.println(\"Matrix rearranged\");\n          double[][] unabsorbedToUnabsorbed = new double[probMatrix.length-terminalStates][probMatrix.length-terminalStates];\n          unabsorbedToUnabsorbed = returnUnabsorbedToUnabsorbed(rearranged, terminalStates);//Get Unabsorbed Matrix\n          for(int i = 0; i < unabsorbedToUnabsorbed.length; i++){\n            for(int j = 0; j < unabsorbedToUnabsorbed[i].length; j++){\n              System.out.print(unabsorbedToUnabsorbed[i][j] + \" \");\n            }\n            System.out.print(\"\\n\");\n          }\n          System.out.println(\"unabsorbedToUnabsorbed\");\n        double[][] unabsorbedToAbsorbed = new double[probMatrix.length-terminalStates][terminalStates];\n          unabsorbedToAbsorbed = returnUnabsorbedToAbsorbed(rearranged, terminalStates);\n          for(int i = 0; i < unabsorbedToAbsorbed.length; i++){\n            for(int j = 0; j < unabsorbedToAbsorbed[i].length; j++){\n                System.out.print(unabsorbedToAbsorbed[i][j] + \" \");\n              }\n            System.out.print(\"\\n\");\n          }\n          System.out.println(\"unabsorbedToAbsorbed\");\n        double[][] fundamental = new double[unabsorbedToUnabsorbed.length][unabsorbedToUnabsorbed.length];\n          fundamental = getFundamental(unabsorbedToUnabsorbed);//Gets fundamental\n\n          double[][] probResult = multiplyMatrix(fundamental, unabsorbedToAbsorbed);\n          System.out.println(\"ProbResult got\");\n          for(int i = 0; i < probResult.length; i++){\n            for(int j = 0; j < probResult[i].length; j++){\n                System.out.print(probResult[i][j] + \" \");\n              }\n            System.out.print(\"\\n\");\n          }\n          int[][] fractionPairs = new int[terminalStates][2];\n          for(int i = 0; i < probResult[startingPoint].length; i++){\n            fractionPairs[i] = returnFractionPair(probResult[startingPoint][i]);\n          }\n          int lcd = getLCD(fractionPairs);\n          int[] ans = new int[terminalStates+1];\n          int num = 0;\n          int den = 1;\n          for(int i = 0; i < fractionPairs.length;++i){\n          int newNumerator = (lcd/fractionPairs[i][den]) * fractionPairs[i][num];\n            ans[i] = newNumerator;\n          }\n          ans[ans.length-1] = lcd;\n          for(int i = 0; i < ans.length; i++){\n            System.out.println(ans[i]);\n          }\n          \n          return ans;\n        }\n    public static int[] solution(int[][] m) {\n        return algorithm(m, 0);\n    }\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Rotating an Object properly around a pivot point given axis and angle\r\n                \r\nIn Three.js there seems to be quite a few ways of rotation which i personally do not find very intuitive. See e.g. the example\nhttp://cloud.engineering-bear.com/apps/robot/robot.html  \n\nI get very strange unexpected effects when I apply rotation to multiple objects. E.g. when I rotate objects that have been added to each other and start rotating the parent the individual objects will all over sudden by placed differently in respect to each other then they originally where. I am now experimenting with grouping and would like to avoid the same effect. \n\nSee http://pi-q-robot.bitplan.com/example/robot?robot=/models/thing3088064.json for the current state of affairs and https://github.com/BITPlan/PI-Q-Robot for the source code.\n\nSo i searched for proper examples following the different API options:\n\nrotation\n\n```\nfunction renderScene() {\n    stats.update();\n    //side1.rotation.z += 0.02;\n    pivot.rotation.z += 0.02;\n```\n\n\n\nhttps://jsfiddle.net/of1vfhzz/1/ \nhttps://github.com/mrdoob/three.js/issues/1958\n\n\nrotateOnAxis\n\n\nthree.js rotate Object3d around Y axis at it center\nHow to rotate a 3D object on axis three.js?\nThreeJS - rotation around object's own axis\n\n\nrotateAroundWorldAxis\n\n```\n   object.rotateAroundWorldAxis(p, ax, r * Math.PI * 2 / frames);\n```\n\n\n\nHow to rotate a object on axis world three.js?\nhttps://stackoverflow.com/a/32038265/1497139\nhttps://jsfiddle.net/b4wqxkjn/7/\nTHREE.js Update rotation property of object after rotateOnWorldAxis\n\n\nrotateOnWorldAxis\n\n```\nobject.rotateOnWorldAxis( axis, angle );\n```\n\n\n\nRotate around World Axis\n\n\nrotateAboutPoint\n\n\nThree JS Pivot point\nRotation anchor point in Three.js\n\n\nsetRotationFromAxisAngle\n\n\nhttps://threejs.org/docs/#api/en/core/Object3D.setRotationFromAxisAngle\n\n\nsetEulerFromQuaternion\n\n```\n   quaternion = new THREE.Quaternion().setFromAxisAngle( axisOfRotation, angleOfRotation );\n   object.rotation.setEulerFromQuaternion( quaternion );\n```\n\n\n\nThree.js - Rotating a sphere around a certain axis\n\n\napplyMatrix\n\n```\nthis.mesh.updateMatrixWorld(); // important !\nchildPart.mesh.applyMatrix(new THREE.Matrix4().getInverse(this.mesh.matrixWorld))\n```\n\n\n\nApplying a matrix in Three.js does not what I expect\n\n\nI like the jsFiddle for https://stackoverflow.com/a/56427636/1497139\n\n```\n  var pivot = new THREE.Object3D();\n  pivot.add( cube );\n  scene.add( pivot );\n```\n\n\nI also found the following discussions \npivot issue in discourcee.three.js.org\n\n\nhttps://discourse.threejs.org/t/rotate-group-around-pivot/3656\nhttps://discourse.threejs.org/t/how-to-rotate-an-object-around-a-pivot-point/6838 \nhttps://discourse.threejs.org/t/set-dynamically-generated-groups-pivot-position-to-the-center-of-its-children-objects-position/6349\nhttps://discourse.threejs.org/t/my-3d-model-is-not-rotating-around-its-origin/3339/3\n\n\nhttps://jsfiddle.net/blackstrings/c0o3Lm45/\n\nhttps://discourse.threejs.org/t/rotate-object-at-end-point/2190 \n\n\nhttps://jsfiddle.net/f2Lommf5/3594/\n\n\n\nQuestions\nNone of the above information is clear enough to get to the point of the problem to be solved. The graphics above are much clearer stating the problem than the proposals are stating a solution.\n\na)\n I'd like to use the cylinder as the axis even when the cylinder is moved.I'd expect the easiest way to go would be to use rotateAroundWorldAxis - is that available in the latest revision from three.js or do i have to add it from e.g. https://stackoverflow.com/a/32038265/1497139?\n\nb) I'd like to get a chain of objects to be rotated to later apply inverse kinematics as in \n\n\nhttps://github.com/jsantell/THREE.IK \nhttps://jsantell.github.io/THREE.IK/\n\n\nAlthough i looked at the source code of that solutions I can't really find the place where the parent-child positioning and rotating is happening. What are the relevant lines of code / API functions that would make proper rotation around a chain of joints happen?\nI already looked in the Bone/Skeleton API of Three.js but had the same problem there - lots of lines of code but no clear point where the rotation/positioning between child and parent happens.\n    ", "Answer": "\r\nQuestion a) \n\nBasically it works as expected:\n\n```\n    cylinder.position.set( options.x, 15, options.z );\n    pivot.position.x=options.x;\n    pivot.position.z=options.z;\n```\n\n\nsee\nhttps://jsfiddle.net/wf_bitplan_com/4f6ebs90/13/\n\n\n\n\nQuestion b) \n\nsee\nhttps://codepen.io/seppl2019/pen/zgJVKM\n\n\n\nThe key is to set the positions correctly. Instead of the proposal at https://stackoverflow.com/a/43837053/1497139 the size is computed in this case. \n\n```\n// create the pivot to rotate around/about\nthis.pivot = new THREE.Group();\nthis.pivot.add(this.mesh);\n// shift the pivot position to fit my size + the size of the joint\nthis.pivot.position.set(\n      x,\n      y + this.size.y / 2 + this.pivotr,\n      z + this.size.z / 2\n);\n// reposition the mesh accordingly\nthis.mesh.position.set(0, this.size.y / 2, 0);\n```\n\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Solving stochastic maximum bipartite matching problem\r\n                \r\nI have faced the following problem:\n\n\nthere are two disjoint sets, ```\nA```\n and ```\nB```\n\nfor each pair of elements (```\na```\n, ```\nb```\n) (```\na```\n belongs to set ```\nA```\n, where ```\nb```\n belongs to set ```\nB```\n) there a probability ```\npij```\n is known in advance. It represents the probability (certainty level) that ```\na```\n matches ```\nb```\n, or in other words, how closely ```\na```\n matches ```\nb```\n (and vice-versa, because ```\npij```\n == ```\npji```\n).\nI have to find a matching with the highest probability/certainty and find out pairs (```\na```\n, ```\nb```\n) which describe the matching\nevery element must be matched / paired with another from the other set exactly once (like in the standard bipartite matching problem)\nif possible, I would like to compute a number which approximately expresses the uncertainty level for the obtained matching (let's say that 0 represents random guess and 1 represents certainty)\n\n\nA simple practical example in which such algorithm is required is described below (this is not actually the problem I am solving!):\n\n\ntwo people are asked to write letters\na - z on a piece of paper\nfor each pair of letters (```\na```\n, ```\nb```\n) we run a pattern matcher to determine the probability that letter ```\na```\n written by person ```\nA```\n represents letter ```\nb```\n wrote by person ```\nB```\n. This gives us the\nprobability matrix which expresses some kind of similarity correlation\nfor each pair of letters (```\na```\n, ```\nb```\n)\nfor each letter that person ```\nA```\n wrote,\nwe need to find the corresponding\nletter written by person ```\nB```\n\n\n\nCurrent approach:\nI am wondering if I could just assign weights which are proportional to the logarithm of certainty level / probability that element ```\na```\n from set ```\nA```\n matches element ```\nb```\n from set ```\nB```\n and then run maximum weighted bipartite matching to find the maximum sum. The logarithm is because I want to maximize the total probability of multiple matching, and since single matches (represented as pairs of matched elements ```\na```\n - ```\nb```\n) form a chain of events, which is a product of probabilities, by taking the logarithm we converts this to a sum of probabilities, which is then easily maximized using an algorithm for weighted bipartite matching, such as Hungarian algorithm. But I somehow doubt this approach would ensure the best matching in terms of statistical expected maximum.\n\nAfter searching a bit, the closest problem I found was a two-stage stochastic maximum weighted matching problem, which is NP-hard, but I actually need some kind of \"one-stage\" stochastic maximum weighted matching problem.\n    ", "Answer": "\r\nI wonder if you can use MaxFlow/MinCut.  I can't prove it's optimal at the moment, but your problem may be NP-hard anyway.  You can use MF/MC to find a perfect matching when you have a bipartite graph with V=(A,B) by creating a source connected to all nodes in A with a weight of 1 and a sink connected to all nodes in B with weight 1.  I'm proposing you make the weights of edges that cross from A to B be the probabilities you mentioned above.  What do you think?\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "PARPACK implementation runs into memory errors\r\n                \r\nI am making a module in Fortran 90 to run PARPACK on a given matrix. I have an existing ARPACK code which functions normally as expected. I tried converting it into PARPACK and it runs into memory clear errors. I am fairly new to coding and fortran, please excuse any blunders I've made.\nThe code:\n```\n!ARPACK module\nmodule parpack\n\nimplicit none\n\ncontains\n\nsubroutine parp\n    \n!   use mpi\n    include '/usr/lib/x86_64-linux-gnu/openmpi/include/mpif.h'\n\n    integer     comm, myid, nprocs, rc, nloc, status(MPI_STATUS_SIZE)\n\n    integer, parameter ::   pres=8\n    \n    integer     nev, ncv, maxn, maxnev, maxncv\n    parameter       (maxn=10**7, maxnev=maxn-1, maxncv=maxn)\n\n!   Arrays for SNAUPD\n\n    integer             iparam(11), ipntr(14)\n    logical, allocatable ::     select(:)\n    real(kind=pres), allocatable :: workd(:), workl(:), worktmp1(:), worktmp2(:)\n\n!   Scalars for SNAUPD\n\n    character               bmat*1, which*2\n    integer             ido, n, info, ierr, ldv\n    integer             i, j, ishfts, maxitr, mode1, nconv\n    integer(kind=pres)          lworkl\n    real(kind=pres)         tol\n\n!   Arrays for SNEUPD\n\n    real(kind=pres), allocatable :: d(:,:), resid(:), v(:,:), workev(:), z(:,:)\n    \n!   Scalars for SNEUPD\n\n    logical rvec, first\n    real        sigmar, sigmai\n!============================================== \n\n    real(kind=pres), allocatable :: mat(:,:)\n\n    open (11, file = 'matrix.dat', status = 'old')\n\n    read (11,*) n\n\n\n\n!=============================================\n    \n!   Dimension of the problem\n    \n    nev = n/10  \n    ncv = nev+2\n    ldv = n \n    bmat = 'I'  \n    which = 'LM'    \n\n!   Additional environment variables\n\n    ido = 0         \n    tol = 0.0E+0        \n    info = 0            \n    lworkl = 3*ncv**2+6*ncv \n\n\n\n!   Algorithm Mode specifications:\n\n    ishfts = 1  \n    maxitr = 300\n    mode1 = 1   \n    \n    iparam(1) = ishfts\n    iparam(3) = maxitr\n    iparam(7) = mode1\n\n!   Distribution to nodes\n    \n!=============================================\n\n!   Matrix allocation\n    allocate (mat(n,n)) \n\n!   PDNAUPD \n    allocate (workd(5*n))\n    allocate (workl(lworkl))\n    allocate (resid(n))\n    allocate (worktmp1(n))\n    allocate (worktmp2(n))\n    \n!   PDNEUPD\n    allocate (d(n,3))\n    allocate (v(ldv,ncv))\n    allocate (workev(3*n))\n    allocate (z(ldv,ncv))\n    allocate (select(ncv))\n    \n\n!===========================================\n!   Read Matrix from the provided file\n\n    mat = 0\n\n    read(11,*) mat\n\n    mat = transpose(mat)\n\n!===========================================\n!   MPI Calling \n    call MPI_INIT(ierr)\n    comm = MPI_COMM_WORLD\n    call MPI_COMM_RANK(comm, myid, ierr)\n    call MPI_COMM_SIZE(comm, nprocs, ierr)\n    \n    nloc = n/nprocs\n\n!   if ( mod(n, nprocs) .gt. myid ) nloc = nloc + n\n    \n!===============================================    \n20  continue\n    \n    call pdnaupd(comm, ido, bmat, nloc, which, nev, tol, resid, ncv, v, ldv, iparam, ipntr, workd, workl, lworkl, info) !Top level solver\n\n    call MPI_BARRIER(comm,ierr)\n\n    print *, ido, info, iparam(5)   !for testing\n!===============================================\n    if (ido .eq. -1 .or. ido .eq. 1) then\n    \n        worktmp1 = 0\n        if (myid .ne. 0) then   !It is slave\n            call MPI_SEND(workd(ipntr(1)), nloc, MPI_DOUBLE_PRECISION, 0, 0, comm, ierr)\n            \n        else            !It is host\n            worktmp1(1:nloc) = workd(ipntr(1):ipntr(1)+nloc-1)\n            i = nprocs\n            if (i .gt. 1) then\n                do i=1,nprocs-1\n                    call MPI_RECV(worktmp1(i*nloc+1), nloc, MPI_DOUBLE_PRECISION, i, 0, comm, status, ierr)\n                end do\n            endif\n        endif\n        \n        call MPI_BARRIER(comm,ierr)\n        \n        if (myid .eq. 0) then   !It is host\n\n!           Matrix multiplication\n            worktmp2 = 0\n            call matmultiply(n, mat, worktmp1, worktmp2)\n            workd(ipntr(2):ipntr(2)+nloc-1) = worktmp2(1:nloc)\n\n            i = nprocs\n            \n            if (i .gt. 1) then\n                do i=1,nprocs-1\n                    call MPI_SEND(worktmp2(i*nloc+1), nloc, MPI_DOUBLE_PRECISION, i, 100*i, comm, ierr)\n                end do\n            endif\n        else            !It is slave\n            call MPI_RECV(workd(ipntr(2)), nloc, MPI_DOUBLE_PRECISION, 0, 100*myid, comm, status, ierr)\n        endif\n        go to 20\n!       call matmultiply(n, mat, workd(ipntr(1):ipntr(1)+n-1), workd(ipntr(2):ipntr(2)+n-1))\n\n!       go to 20\n    endif\n!   print *, info   !for testing\n!===============================================================\n!   Post-processing for eigenvalues\n\n\n    rvec = .true.\n    \n    if (myid .eq. 0) then\n        call pdneupd ( comm, rvec, 'A', select, d, d(1,2), z, ldv, sigmar, sigmai, &\n        workev, bmat, n, which, nev, tol, resid, ncv, v, ldv, iparam, ipntr, &\n        workd, workl, lworkl, info)\n    endif\n\n!   print *, info   !for testing\n\n    close(11)\n    call MPI_FINALIZE(ierr)\nreturn\nend subroutine\n!==============================================================================================\n\n!   Additional Function definitions\nsubroutine matmultiply(n, mat, v, w)\n\n    integer     n, i, j\n    integer, parameter ::   pres=8\n    real(kind = pres)   mat(n,n), temp(n)\n    real(kind = pres)   v(n), w(n)\n    \n    temp = 0\n    do j = 1,n\n        do i = 1,n\n            temp(j) = temp(j) + mat(i,j)*v(i)\n        end do\n    end do\n    w = temp\nreturn\nend subroutine\n\nend module\n```\n\nI apologize for the ton of redundant lines and comments, I am yet to clean it up for finalization.\nWhen I run the code on a single thread with ```\n./a.out```\n, I get the following output:\n```\nInvalid MIT-MAGIC-COOKIE-1 key           1           0  1629760560\n           1           0  1629760560\n           1           0  1629760560\n           1           0  1629760560\n.\n.\n. <A long chain as the code is exhausting all iterations>\n.<first of the numbers is ido, which starts with 1 instead of -1 for some reason, second being\n.info and third being iparam(5) which is a random number until the final iteration>\n.\n          99           1           1\nmunmap_chunk(): invalid pointer\n\nProgram received signal SIGABRT: Process abort signal.\n\nBacktrace for this error:\n#0  0x7f5a863d0d01 in ???\n#1  0x7f5a863cfed5 in ???\n#2  0x7f5a8620420f in ???\n#3  0x7f5a8620418b in ???\n#4  0x7f5a861e3858 in ???\n#5  0x7f5a8624e3ed in ???\n#6  0x7f5a8625647b in ???\n#7  0x7f5a862566cb in ???\n#8  0x560f05ac1819 in ???\n#9  0x560f05abd7bc in checker\n    at /home/srivatsank/Desktop/fortran/lap_vs_arp/ptest/ptest.f90:45\n#10  0x560f05abd8d9 in main\n    at /home/srivatsank/Desktop/fortran/lap_vs_arp/ptest/ptest.f90:3\nAborted (core dumped)\n```\n\nline 45 in ```\nptest```\n is ```\ncall parp```\n\nline 3 in ```\nptest```\n is ```\nuse parpack(name of the module)```\n\nThe main code is as follows:\n```\nprogram checker\n\n    use parpack\n    use arpack\n!   use lapack\n    implicit none\n    !Program to test LAPACK and ARPACK\n\n!   1. Variable definition\n\n    integer         a,n,i\n    real, allocatable ::        mat(:,:)\n    real                t0, t1\n    \n    a=2\n!   Loop\n!   do 20 a = 1,3\n    \n!   Open File   \n        open(unit=10, file = 'matrix.dat', status = 'replace')\n        \n!   2. Generate Symmetric matrices\n        n = 10**a\n        allocate (mat(n,n))\n        call RANDOM_NUMBER(mat)\n        \n!   3. Save symmetric matrices to r.dat     \n        write (10,*) n\n        \n        do 30 i=1,n\n            write(10,*) mat(i,:)\n30      end do\n\n\n        deallocate(mat)\n        close(10)\n\n!   4. Test time taken by each of the routines\n\n!       call cpu_time(t0)\n!       call arp\n!       call cpu_time(t1)\n!       print *, 'n:', n, 'ARPACK time taken:', t1-t0\n        call cpu_time(t0)\n        call parp\n        call cpu_time(t1)\n        print *, 'n:', n, 'PARPACK time taken:', t1-t0\n\n\n!20 end do\n\n\nend program checker\n```\n\nThe memory error occurs at the very end of the subroutine, when the mail program tries to exit from the subroutine. I have verified this by printing statements as the last line in the subroutine.\nAnd on running ```\nmpirun -np 4 a.out```\n, the code just enters the pdneupd process and sits there for eternity. Could anyone help?\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Good approaches to OOP with large data sets in Python [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs to be more focused. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\r\n                \r\n                    \r\n                        Closed 5 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nThis might be a soft question, but here it goes. I have a large data set that has a particular structure and I want to move to Python to start using ```\nsklearn```\n package (previously I was using MATLAB). I am no Python expert, for most purposes you can consider me a beginner. The background is the following:\n\n\n\nThe structure of the data is as follows. The raw data are a 33 x 300 matrices (say I have about 500 such samples) which are time-series. Each row comes from one generating variable, and these are collected over 300 seconds. These data points are labelled with tags (corresponding to their classes/types, its actually a multi-label problem), names corresponding to who the sample was collected from, but also with attributes depending on when the data points were collected. Points collected in order are labelled ```\nrun1```\n, ```\nrun2```\n if collected in a single sitting; called a ```\nsession```\n. Samples collected one or more days apart belong to different sessions; and I have multiple sessions.  \n\nHow I analyzed the data in MATLAB was to make a class of my own, which held an array of ```\nstruct```\ns and then I defined methods and functions so that I can add or remove specific samples, add or remove ```\nruns```\n from the data set, add or remove ```\nsessions```\n, add or remove rows from the time-series across the whole data-set, consider classes of samples seperately etc. Each instance of the MATLAB class held the covariance matrix for PCA dimension reduction; other generated features like correlation matrices, etc. for the ```\nstruct```\n of that instance. All together it is about 2k lines in MATLAB. The primary purpose is just to load the data once into ```\nMATLAB```\n, indeed into an instance of the class, and then chain together a list of instructions/calls to the class methods, so that I could prune and edit the data-set as I wanted. \n\n\n\nSo now for the questions:\n\n\nWhat would be the most pythonic was to approach this situation? I started with a ```\nlist```\n of ```\ndicts```\n approach and some parts of the code felt very un-pythonic. Here is an example of removing sample from a study or instance of the class, \n\n```\ndef mod_samples(self, op, idxs):\n     if not type(idxs) == list:\n          print('Error: mod_samples must be called with a list of sample names!')\n     if op == 'rem':\n         for idx in idxs:\n             for sample in self.samples:\n                 if sample['Name'] == idx:\n                     self.removed_samples.append(sample)\n                     self.samples.remove(sample)\n     if op == 'add':\n         for idx in idxs:\n             for sample in self.removed_samples:\n                 if sample['Name'] == idx:\n                     self.samples.append(sample)\n                     self.removed_samples.remove(sample)\n     self.recompute()\n```\n\n\n\nSurely there must be a more elegant way than the double for loop with string comparison? ```\nrecompute```\n here just does the dimension reduction etc. again for the 'new' data-set. Also enforcing that the ```\nidxs```\n is a list seemed odd to me. But on the other hand the ```\nfor item in itemList```\n doesn't differentiate between strings or lists. :/\n\n\nIs there a better approach? Some other data type from a utility package or something? Because ```\nname```\n is a key and I am removing samples based on the value instead of the key, the efficiency of ```\ndicts```\n seem lost to me. \nMy MATLAB implementation was poor in the sense that implementing a deep copy was notoriously laborious; I side-stepped the issue by having a second constructor that created a new instance of the class from a reduced ```\nstruct```\n instead of the disk/data-files. For example, assuming the set had samples tagged as being from ```\nrun1```\n, calling\n\n```\n dataSet.removeRun('run1') \n```\n\n\nwould result in a struct object that I could then use as, \n\n```\n modifiedDataSet = clusterClass('isPoor', true, 'poorStruct', dataSet.removeRun('run1'))\n```\n\n\nQuestion here is what are Python's deep copy abilities? I am very new to OOP in Python. Would I have to override the default copy constructor bit for bit, variable for variable, attribute for attribute? Sometimes it is necessary to have two different (internally) instances because it is for comparative purposes. \nFinally, speed considerations: my data set is not huge. I reckon the .MAT file I save to disk at times is usually about 12-15 Mb at the end of a day. But MATLAB has had decades of honing its internals, whereas ```\nNumPy```\n/```\nSciPy```\n I think are comparatively new (yes OOP in MATLAB can be considered even newer, but I didn't find it too bad). Most of my data is not sparse. Are their any tips with regards to performance in this regard? Mostly what I do is large matrix multiplications, numerical integration, differentiation etc. \n\n\n\n\nAs stackexchange is reminding me, yes the preference is for questions that can be answered; that being said I am not looking for a/the answer. I am new to OOP in Python so I would just like to overlay of the land, people's favorite approaches to such problems, pointers to packages I don't know for this kind of stuff etc. (and oh ... I do know ```\npandas```\n; but I don't like it, it abstracts away too much of the internals for me, or rather ... makes them hard to get at in a pinch for my liking.) \n    ", "Answer": "\r\nThere are too many things asked in one question, I think that what makes it an off-topic. I think you could be better off by splitting the question and cutting off the subjective part. Part 3  is especially demotivating to answer.   \n\nA quick tour though:\n\n\npython/pandas is not MATLAB and never will be, you should not expect the session functionality from them or complain it is not there. it is by design, not flaw.\nmoving from MATLAB is a chance to review your datamodel and the way you handle it, one path is replicating functionality you had using the classes, the other is changing the data model, forgetting about the sessions and treating your project more as a pipeline. both are valid paths.\nis there new data being added to your dataset or is it fixed? if there is some new data coming, you probably want to change your data pipline, perhaps consider flatten it to a SQL database, or use NoSQL database, which effectively the same as storing dicts/json's, other options below. \n\n\n\n  33 x 300 matrices (say I have about 500 such samples) which are time-series. Each row comes from one generating variable, and these are collected over 300 seconds.  \n\n\nSo there are 33 variables, which span 300 sec and there are 500 such observations, annotated with some extra attributes? This is a list of dicts, if you want a single data structure. If that has to stay in class, as you are doing it now, you can persist a class instance. \n\nYou can also write a little file manager that stores individual observation in own folder, each folder containing a csv file and a json. \n\n\nfor some good ideas about data pipeline I think Data Science Cookiecutter is great. \n\n\nHope it's not too didactic! \n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "MultiLayer Neural Network giving wrong output\r\n                \r\nThis is the open source code that I am using:\n\n```\nimport math\nimport random\nimport string\n\nclass NN:\n  def __init__(self, NI, NH, NO):\n    # number of nodes in layers\n    self.ni = NI + 1 # +1 for bias\n    self.nh = NH\n    self.no = NO\n\n    # initialize node-activations\n    self.ai, self.ah, self.ao = [],[], []\n    self.ai = [1.0]*self.ni\n    self.ah = [1.0]*self.nh\n    self.ao = [1.0]*self.no\n\n    # create node weight matrices\n    self.wi = makeMatrix (self.ni, self.nh)\n    self.wo = makeMatrix (self.nh, self.no)\n    # initialize node weights to random vals\n    randomizeMatrix ( self.wi, -0.2, 0.2 )\n    randomizeMatrix ( self.wo, -2.0, 2.0 )\n    # create last change in weights matrices for momentum\n    self.ci = makeMatrix (self.ni, self.nh)\n    self.co = makeMatrix (self.nh, self.no)\n\n  def runNN (self, inputs):\n    if len(inputs) != self.ni-1:\n      print 'incorrect number of inputs'\n\n    for i in range(self.ni-1):\n      self.ai[i] = inputs[i]\n\n    for j in range(self.nh):\n      sum = 0.0\n      for i in range(self.ni):\n        sum +=( self.ai[i] * self.wi[i][j] )\n      self.ah[j] = sigmoid (sum)\n\n    for k in range(self.no):\n      sum = 0.0\n      for j in range(self.nh):        \n        sum +=( self.ah[j] * self.wo[j][k] )\n      self.ao[k] = sigmoid (sum)\n\n    return self.ao\n\n\n\n  def backPropagate (self, targets, N, M):\n    # calc output deltas\n    # we want to find the instantaneous rate of change of ( error with respect to weight from node j to node k)\n    # output_delta is defined as an attribute of each ouput node. It is not the final rate we need.\n    # To get the final rate we must multiply the delta by the activation of the hidden layer node in question.\n    # This multiplication is done according to the chain rule as we are taking the derivative of the activation function\n    # of the ouput node.\n    # dE/dw[j][k] = (t[k] - ao[k]) * s'( SUM( w[j][k]*ah[j] ) ) * ah[j]\n    output_deltas = [0.0] * self.no\n    for k in range(self.no):\n      error = targets[k] - self.ao[k]\n      output_deltas[k] =  error * dsigmoid(self.ao[k]) \n\n    # update output weights\n    for j in range(self.nh):\n      for k in range(self.no):\n        # output_deltas[k] * self.ah[j] is the full derivative of dError/dweight[j][k]\n        change = output_deltas[k] * self.ah[j]\n        self.wo[j][k] += N*change + M*self.co[j][k]\n        self.co[j][k] = change\n\n    # calc hidden deltas\n    hidden_deltas = [0.0] * self.nh\n    for j in range(self.nh):\n      error = 0.0\n      for k in range(self.no):\n        error += output_deltas[k] * self.wo[j][k]\n      hidden_deltas[j] = error * dsigmoid(self.ah[j])\n\n    #update input weights\n    for i in range (self.ni):\n      for j in range (self.nh):\n        change = hidden_deltas[j] * self.ai[i]\n        #print 'activation',self.ai[i],'synapse',i,j,'change',change\n        self.wi[i][j] += N*change + M*self.ci[i][j]\n        self.ci[i][j] = change\n\n    # calc combined error\n    # 1/2 for differential convenience & **2 for modulus\n    error = 0.0\n    for k in range(len(targets)):\n      error = 0.5 * (targets[k]-self.ao[k])**2\n    return error\n\n  def weights(self):\n    print 'Input weights:'\n    for i in range(self.ni):\n      print self.wi[i]\n    print\n    print 'Output weights:'\n    for j in range(self.nh):\n      print self.wo[j]\n    print ''\n\n  def test(self, patterns):\n    for p in patterns:\n      inputs = p[0]\n      print 'Inputs:', p[0], '-->', self.runNN(inputs), '\\tTarget', p[1]\n\n  def train (self, patterns, max_iterations = 1000, N=0.5, M=0.1):\n    for i in range(max_iterations):\n      for p in patterns:\n        inputs = p[0]\n        targets = p[1]\n        self.runNN(inputs)\n        error = self.backPropagate(targets, N, M)\n      if i % 50 == 0:\n        print 'Combined error', error\n    self.test(patterns)\n\n\ndef sigmoid (x):\n  return math.tanh(x)\n\ndef dsigmoid (y):\n  return 1 - y**2\n\ndef makeMatrix ( I, J, fill=0.0):\n  m = []\n  for i in range(I):\n    m.append([fill]*J)\n  return m\n\ndef randomizeMatrix ( matrix, a, b):\n  for i in range ( len (matrix) ):\n    for j in range ( len (matrix[0]) ):\n      matrix[i][j] = random.uniform(a,b)\n\ndef main ():\n\n    #print mylist\n    pat = [\n    [ [0.0,0.0], [0.0] ],\n    [ [0.0,0.5], [2.0] ],\n    [ [0.0,1.0], [0.0] ],\n\n    [ [0.5,0.0], [3.0] ],\n    [ [0.5,0.5], [0.0] ],\n    [ [0.5,1.0], [5.0] ],\n\n    [ [1.0,0.0], [0.0] ],\n    [ [1.0,0.5], [89.0] ],\n    [ [1.0,1.0], [0.0] ]\n    ]\n\n    myNN = NN ( 2, 10, 1)\n    myNN.train(pat)\n\nif __name__ == \"__main__\":\n    main()\n```\n\n\nBut, when I run the code, I get almost the same output which is wrong.\n\n```\nCombined error 0.499991904422\nCombined error 0.499996323964\nCombined error 0.499997646742    \nCombined error 0.499998277742\nCombined error 0.499998645609\nCombined error 0.499998885941\nCombined error 0.499999054982\nCombined error 0.49999918021\nCombined error 0.499999276619    \nCombined error 0.49999935308\nCombined error 0.499999415171\nCombined error 0.499999466571\nCombined error 0.499999509808\nCombined error 0.499999546673\nCombined error 0.499999578468\nCombined error 0.499999606167\nCombined error 0.499999630508\nCombined error 0.499999652063\nCombined error 0.499999671282\nCombined error 0.499999688523\nInputs: [0.0, 0.0] --> [0.9999971763261493]     Target [0.0]\nInputs: [0.0, 0.5] --> [0.9999991710833099]     Target [2.0]\nInputs: [0.0, 1.0] --> [0.9999996328965068]     Target [0.0]\nInputs: [0.5, 0.0] --> [0.9999976785687611]     Target [3.0]\nInputs: [0.5, 0.5] --> [0.9999992837399216]     Target [0.0]\nInputs: [0.5, 1.0] --> [0.9999996729737041]     Target [5.0]\nInputs: [1.0, 0.0] --> [0.9999980402687116]     Target [0.0]\nInputs: [1.0, 0.5] --> [0.9999993680567348]     Target [89.0]\nInputs: [1.0, 1.0] --> [0.9999997038262324]     Target [0.0]\n```\n\n\nIs there anything wrong with the code or usage of code?\nWhy I am always getting an output value less than 1? \n    ", "Answer": "\r\nYou are using sigmmoid activation function and require your network to output values greater than 1, which is impossible. Scale down all your output values by the maximum value (89 in your case).\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "Effects processor: Thoughts about software architecture, choice of programming language, API\r\n                \r\nI'm currently working on a project where a major element is a piece of software that can do signal processing in real-time.\n\nThe basic idea/concept is the following. Audio data is captured continuously from a (USB) audio interface (running at 96 kHz, 24 bit). It is then run through a \"processing chain\" (like a \"virtual effects chain\"), where each element can perform arbitrary processing on the data. The data is handed from one element to the next, until it arrives at a sink. Data which flows into the sink is sent back to the audio interface for output.\n\nThe signal chain consists of \"objects\" that implement some \"processing\" method, which works on chunks of data of 1920 samples (20 ms) size (though one might change this number).\n\nThe basic idea in \"pseudo code\".\n\n```\nwhile (true) {\n   float[] samples = audio.read(BLOCK_SIZE);\n\n   foreach (Effect e in signal_flow)\n      e.process(samples);\n\n   audio.write(samples);\n}\n```\n\n\nA first prototype has been implemented in Python which uses the ALSA API for audio I/O. Three separate threads are started.\n\nThe first one is continuously reading from ALSA (which is a blocking operation) and puts the data into a queue, then goes on with reading the next block. (ALSA requires me to \"read(...)\" at least every 20 ms, so I need a very lightweight thread for that, which does nothing but read and store data, so I can meet my time constraints.)\n\nThe second one reads the samples from the input from this queue, puts them through the signal chain and finally into another queue for output.\n\nThe third thread reads from this output queue (which is a blocking operation) and writes the blocks out to ALSA.\n\nI basically have two \"numeric\" variables here, one being the block size and the other being the number of blocks that I \"pre-post\" to the output queue before I even begin processing, which gives me some time to \"deliver more samples\" without the output buffer underrunning. In addition, I can decide to do these things either in separate threads or in separate processes.\n\nAfter some serious debugging (which involved the use of both a signal generator and an oscilloscope!), I finally got this approach running. The biggest problem was a bug in the ALSA API, namely that \"period_size\", which is specified as \"the number of frames that are read/written\" appears to actually be the number of frames read, but the number of bytes written. When I specify 1920 (20 ms of audio at 96 kHz sampling rate) for both, input and output, I get only 1/4 of output, then 3/4 of silence, then 1/4 of output. When I specify 1920 * 4 = 7680 for both, input and output, I get an error that the device's buffer is not large enough to read this many frames. When I specify 1920 for input and 7680 for output, it works perfectly (and my queues do not \"overfill\" either).\n\nHaving that solved, I have one serious problem left and that is: Latency!\n\nI basically started this entire project in order to create my own effects, so I want this software to operate as an effects unit for stage/live use. I've read that when two events are less than 30 ms apart, e. g. two strobe lights are fired 30 ms apart, the human brain can no longer tell which one was first and which was second. So a delay of 30 ms or less would basically be percieved as \"instant\". It's the threshold where events \"merge\" and are percieved as \"one\". If the latency were that low, you couldn't tell which event is first, so e. g. a guitarist could no longer tell, if he struck the string and then sound came from the PA or if sound came from the PA and then he struck the string, so it would basically feel like \"zero latency\" and thus like a real amp.\n\nNow the latency I have currently arrived at is ... well ... I didn't have the opportunity to exactly measure them yet, but it's in the order of tenths of a second, say 200 or 300 ms. It's far too much! I tried both separate threads and processes for the I/O (since in Python you never know if threads are really gonna be faster due to the \"global interpreter lock\") and processes were significantly slower, which was to be expected, due to the overhead associated with inter-process communication and the fact that the two I/O processes don't do anything \"intensive\". They just wait on blocking operations and perform fast I/O.\n\nAs another remark, I would like to say that I want my application to host a web server (of course in a separate thread or even process) to allow the user to configure the signal path and adjust the parameters for the effects \"devices\" in an intuitive way.\n\nSo obviously I need to get latency down! I have several paths to follow now.\n\n\nMy first idea is to replace ALSA with JACK, which is said to be \"low-latency\". Drawbacks are that I lose control over the exact levels at the ADC/DAC (JACK always works with floats, which are already scaled to [-1.0, 1.0], no matter what the hardware does) and over sampling rate (as far as I know, JACK \"dictates\" a sampling rate - I can no longer chose - with ALSA I could select a sampling rate I want to work with and it would transparently upsample/downsample for me if the hardware deviated from that), that the blocking I/O (that I find a pretty nice paradigm) is replaced with a callback mechanism and that timing constraints are probably much harder to meet. (I cannot \"buffer\" on my own with JACK. It always requires processing to be done in a certain amount of time.) Also, the JACK API appears to be more complicated in general, than the ALSA API. I could probably replace ALSA with JACK, but I'm not sure how much I could \"win\", given that ALSA is already a pretty \"low-level\" API and JACK builds upon, but probably uses in a very specific way to keep latencies low. To be honest, I'm not exactly sure just how much of that latency is due to ALSA and \"below\" and how much is due to \"higher layers\".\nI currently make use of an interpreted, garbage-collected language. That's bad for real-time requirements. But what are the alternatives? Well, of course C comes to mind when thinking about real-time applications, but there are serious drawbacks.\n\n\n2.1 - I want the software to have a web-based UI. Creating a web server in Python is simple. There's a class for it in the Python standard library. Creating a web server in C is a pain. There's basically NOTHING in C that could do \"web\". I'll have to start from scratch based on nothing but a socket API. Good luck! :-(\n\n2.2 - Python has support for numerics. It has numpy and scipy and therefore vector data types, matrix multiplication, fast fourier transform, fast convolution, interpolation (splines, etc.). This is all very useful for the problem at hand here. In C, I lose all this, which means I either have to get the job done without, which is very unlikely, or I'll have to recreate all of this on my own in C, which is both time-consuming and error-prone.\n\n2.3 - Python has \"high-level\" support for multiprocessing and multithreading. I can communicate between processes and threads via synchronized queues, implementing my solution in a \"thread pool / replicated workers\"-style fashion, which is an extremely useful paradigm for the problem at hand here. In C, I'll have to resort to POSIX threads and low-level synchronization primitives like mutices. (Is that the correct plural for \"mutex\"? Like in \"Unix\" --> \"Unices\"?) Again, this is both time-consuming and error-prone.\n\nAny suggestions on which languages to use? Languages I'm familiar with include Python, C-Sharp, Java, C, Go, a little bit of C++ (I never need that language - either it's low-level, then I use C, or it's high-level, then I use a garbage-collected, interpreter or bytecode-compiled language), and some web technologies (especially JavaScript with AJAX, etc., which will be useful when it comes to the UI).\n\nAll of this has to run under a Linux distribution, preferably with as little dependencies / libraries as possible. \"Standard\" libraries are thus preferred over \"exotic\" ones. Platform-independance, especially the ability to also run under Windows, is a plus, but not strictly a requirement.\n\nI'm ok with the UI being implemented in a different language (Go for the web server comes to mind) than the actual processing (which might \"have to be done in C\" if it needs to be real-time?), though this brings a lot of extra complexity, as both will then run in separate processes and communicate via, say, Unix Domain Sockets, which requires all data to be passed back and forth to be represented as a byte stream (since that's all a socket transports), so one needs to design an inter-process communication protocol and do lots of parsing at this level as well. Any chance to avoid this huge overhead and do it in a single language?\n\nAny other ideas? Specifically, will I gain anything by going from ALSA to JACK? Are there other alternatives I haven't considered yet, which might suit the task even better?\n\nThanks a lot for your time!\n    ", "Answer": "", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "What am I missing that prevents me from making a generic NSStackView-like container with Auto Layout?\r\n                \r\nI am trying to implement a container view with Auto Layout for OS X that operates similarly to NSStackView, but with a few differences that NSStackView does not handle (and I need 10.7 support anyway). My rules are:\n\n\nThe subviews are arranged either horizontally or vertically.\nIn the primary direction, the subviews by default take their intrinsic size.\nIf a subview is marked \"stretchy\", it will take whatever space remains after laying out all non-stretchy subviews. Multiple stretchy subviews get equal distributions of the remaining space.\nIf no subviews are stretchy, the container can grow in the primary direction, showing empty space after the last subview. Nesting two such stacks with the same orientation prefers the outer one.\nAlong the secondary direction, subviews clamp to the edges of the container view and grow freely.\n\n\nI thought this could be done in a simple way, connecting the views in the primary direction one after another and then in the secondary direction using the ```\n|[view]|```\n visual format. Lack of a stretchy view is handled with a NSView with intrinsic content size 0x0 as the last view.\n\nThis mostly worked. Unfortunately, ambiguity arose with a nested tree of horizontally oriented stacks of the form (represented using HTML for expository purposes)\n\n\r\n\r\n```\n.box {\r\n  display: inline-block;\r\n  border: 1px solid black;\r\n  padding: 0.5em 0.5em 0.5em 0.5em;\r\n}\r\n\r\n.outermost-box {\r\n  display: inline-block;\r\n  border: 1px solid black;\r\n  padding: 0.5em 0.5em 0.5em 0.5em;\r\n  width: 100%;\r\n}```\n\r\n```\n<div class=\"outermost-box\">\r\n  <div class=\"box\">\r\n    <input type=\"button\" value=\"These\">\r\n    <input type=\"button\" value=\"Buttons\" disabled>\r\n  </div>\r\n  <div class=\"box\">\r\n    <input type=\"button\" value=\"are\">\r\n    <div class=\"box\">\r\n      <input type=\"button\" value=\"in\" disabled>\r\n    </div>\r\n  </div>\r\n  <div class=\"box\">\r\n    <div class=\"box\">\r\n      <input type=\"button\" value=\"nested\">\r\n      <div class=\"box\">\r\n        <input type=\"button\" value=\"boxes\" disabled>\r\n      </div>\r\n    </div>\r\n  </div>\r\n</div>```\n\r\n\r\n\r\n\n\nwhere all the stacks have no stretchy subviews. Under my definition, the outermost box stretches, and only that one stretches. However, Auto Layout will randomly assign the extra space to one of the inner boxes:\n\n\n\nChanging the extra view to a ```\nNSLayoutRelationLessThanOrEqual```\n relation (```\nlast view.trailing <= superview.trailing```\n) also did not help. I'm going to keep this model for the rest of this post, though, as my next attempts are based on it.\n\nThen I decided to try having the container ask its superview if it should expand. This fixed the above problem, but introduced another problem with deep chains of containers that alternate between horizontal and vertical:\n\n\n\nThe buttons labelled \"Right Margin Test\" should stretch, but they either aren't stretching or are stretching but also clipping the views on the sides (I don't have a screenshot of this right now; sorry).\n\nThen I decided to have both the ```\n<=```\n and alternate ```\n==```\n constraints on the right edge on at the same time, setting ```\n==```\n to a low priority if there should be extra space. This new one mostly works, but now has a weird problem. If I resize the window large enough on the Page 3 shown above, then switch to Page 4, I get\n\n\n\nand then if I resize I get\n\n\n\neven though Page 4 should have space at the bottom under all conditions. Sometimes the bottom of the button can be seen, and visualizing its vertical constraints show it thinks it wants to be as tall as the matrix of radio buttons (right now a NSMatrix; changing it to a bunch of NSButtons will wait until after I fix all these Auto Layout issues).\n\nI'm really not sure what's going on or how to fix any of this. I tried making the ```\n==```\n constraint I mentioned have a settable \"real hugging priority\" of its own, but that just made things break in more spectacular ways.'\n\nThere's also problems with positions of tab views being too low initially and taking a few layout cycles to set properly...\n\nEverything shown is done with these containers, NSBoxes with one subview, and NSTabs with one subview. I'll paste the code for my container as it stands now below.\n\nSo what about Auto Layout do I not understand that I can't just make it work right with the obvious code? Or can NSStackView do all of what I want and I should just use it instead? (That assumes ```\nalignment```\n takes ```\nWidth```\n and ```\nHeight```\n as valid, which Interface Builder does not seem to say it does).\n\nThanks!\n\n```\n// 15 august 2015\n#import \"uipriv_darwin.h\"\n\n// TODOs:\n// - tab on page 2 is glitched initially and doesn't grow\n// - page 3 doesn't work right; probably due to our shouldExpand logic being applied incorrectly\n\n// TODOs to confirm\n// - 10.8: if we switch to page 4, then switch back to page 1, check Spaced, and go back to page 4, some controls (progress bar, popup button) are clipped on the sides\n\n@interface boxChild : NSObject\n@property uiControl *c;\n@property BOOL stretchy;\n@property NSLayoutPriority oldHorzHuggingPri;\n@property NSLayoutPriority oldVertHuggingPri;\n- (NSView *)view;\n@end\n\n@interface boxView : NSView {\n    uiBox *b;\n    NSMutableArray *children;\n    BOOL vertical;\n    int padded;\n\n    NSLayoutConstraint *first;\n    NSMutableArray *inBetweens;\n    NSLayoutConstraint *last, *last2;\n    NSMutableArray *otherConstraints;\n\n    NSLayoutAttribute primaryStart;\n    NSLayoutAttribute primaryEnd;\n    NSLayoutAttribute secondaryStart;\n    NSLayoutAttribute secondaryEnd;\n    NSLayoutAttribute primarySize;\n    NSLayoutConstraintOrientation primaryOrientation;\n    NSLayoutConstraintOrientation secondaryOrientation;\n}\n- (id)initWithVertical:(BOOL)vert b:(uiBox *)bb;\n- (void)onDestroy;\n- (void)removeOurConstraints;\n- (void)forAll:(void (^)(uintmax_t i, boxChild *b))closure;\n- (boxChild *)child:(uintmax_t)i;\n- (BOOL)isVertical;\n- (void)append:(uiControl *)c stretchy:(int)stretchy;\n- (void)delete:(uintmax_t)n;\n- (int)isPadded;\n- (void)setPadded:(int)p;\n@end\n\nstruct uiBox {\n    uiDarwinControl c;\n    boxView *view;\n};\n\n@implementation boxChild\n\n- (NSView *)view\n{\n    return (NSView *) uiControlHandle(self.c);\n}\n\n@end\n\n@implementation boxView\n\n- (id)initWithVertical:(BOOL)vert b:(uiBox *)bb\n{\n    self = [super initWithFrame:NSZeroRect];\n    if (self != nil) {\n        // the weird names vert and bb are to shut the compiler up about shadowing because implicit this/self is stupid\n        self->b = bb;\n        self->vertical = vert;\n        self->children = [NSMutableArray new];\n        self->inBetweens = [NSMutableArray new];\n        self->otherConstraints = [NSMutableArray new];\n\n        if (self->vertical) {\n            self->primaryStart = NSLayoutAttributeTop;\n            self->primaryEnd = NSLayoutAttributeBottom;\n            self->secondaryStart = NSLayoutAttributeLeading;\n            self->secondaryEnd = NSLayoutAttributeTrailing;\n            self->primarySize = NSLayoutAttributeHeight;\n            self->primaryOrientation = NSLayoutConstraintOrientationVertical;\n            self->secondaryOrientation = NSLayoutConstraintOrientationHorizontal;\n        } else {\n            self->primaryStart = NSLayoutAttributeLeading;\n            self->primaryEnd = NSLayoutAttributeTrailing;\n            self->secondaryStart = NSLayoutAttributeTop;\n            self->secondaryEnd = NSLayoutAttributeBottom;\n            self->primarySize = NSLayoutAttributeWidth;\n            self->primaryOrientation = NSLayoutConstraintOrientationHorizontal;\n            self->secondaryOrientation = NSLayoutConstraintOrientationVertical;\n        }\n    }\n    return self;\n}\n\n- (void)onDestroy\n{\n    boxChild *bc;\n    uintmax_t i, n;\n\n    [self removeOurConstraints];\n    [self->first release];\n    [self->inBetweens release];\n    [self->last release];\n    [self->last2 release];\n    [self->otherConstraints release];\n\n    n = [self->children count];\n    for (i = 0; i < n; i++) {\n        bc = [self child:i];\n        uiControlSetParent(bc.c, NULL);\n        uiDarwinControlSetSuperview(uiDarwinControl(bc.c), nil);\n        uiControlDestroy(bc.c);\n    }\n    [self->children release];\n}\n\n- (void)removeOurConstraints\n{\n    [self removeConstraint:self->first];\n    [self removeConstraints:self->inBetweens];\n    [self removeConstraint:self->last];\n    [self removeConstraint:self->last2];\n    [self removeConstraints:self->otherConstraints];\n}\n\n- (void)forAll:(void (^)(uintmax_t i, boxChild *b))closure\n{\n    uintmax_t i, n;\n\n    n = [self->children count];\n    for (i = 0; i < n; i++)\n        closure(i, [self child:i]);\n}\n\n- (boxChild *)child:(uintmax_t)i\n{\n    return (boxChild *) [self->children objectAtIndex:i];\n}\n\n- (BOOL)isVertical\n{\n    return self->vertical;\n}\n\n// TODO something about spinbox hugging\n- (void)updateConstraints\n{\n    uintmax_t i, n;\n    BOOL hasStretchy;\n    NSView *firstStretchy = nil;\n    CGFloat padding;\n    NSView *prev, *next;\n    NSLayoutConstraint *c;\n    NSLayoutPriority priority;\n\n    [super updateConstraints];\n    [self removeOurConstraints];\n\n    n = [self->children count];\n    if (n == 0)\n        return;\n    padding = 0;\n    if (self->padded)\n        padding = 8.0;      // TODO named constant\n\n    // first, attach the first view to the leading\n    prev = [[self child:0] view];\n    self->first = mkConstraint(prev, self->primaryStart,\n        NSLayoutRelationEqual,\n        self, self->primaryStart,\n        1, 0,\n        @\"uiBox first primary constraint\");\n    [self addConstraint:self->first];\n    [self->first retain];\n\n    // next, assemble the views in the primary direction\n    // they all go in a straight line\n    // also figure out whether we have stretchy controls, and which is the first\n    if ([self child:0].stretchy) {\n        hasStretchy = YES;\n        firstStretchy = prev;\n    } else\n        hasStretchy = NO;\n    for (i = 1; i < n; i++) {\n        next = [[self child:i] view];\n        if (!hasStretchy && [self child:i].stretchy) {\n            hasStretchy = YES;\n            firstStretchy = next;\n        }\n        c = mkConstraint(next, self->primaryStart,\n            NSLayoutRelationEqual,\n            prev, self->primaryEnd,\n            1, padding,\n            @\"uiBox later primary constraint\");\n        [self addConstraint:c];\n        [self->inBetweens addObject:c];\n        prev = next;\n    }\n\n    // and finally end the primary direction\n    self->last = mkConstraint(prev, self->primaryEnd,\n        NSLayoutRelationLessThanOrEqual,\n        self, self->primaryEnd,\n        1, 0,\n        @\"uiBox last primary constraint\");\n    [self addConstraint:self->last];\n    [self->last retain];\n\n    // if there is a stretchy control, add the no-stretchy view\n    self->last2 = mkConstraint(prev, self->primaryEnd,\n        NSLayoutRelationEqual,\n        self, self->primaryEnd,\n        1, 0,\n        @\"uiBox last2 primary constraint\");\n    priority = NSLayoutPriorityRequired;\n    if (!hasStretchy) {\n        BOOL shouldExpand = NO;\n        uiControl *parent;\n\n        parent = uiControlParent(uiControl(self->b));\n        if (parent != nil)\n            if (self->vertical)\n                shouldExpand = uiDarwinControlChildrenShouldAllowSpaceAtBottom(uiDarwinControl(parent));\n            else\n                shouldExpand = uiDarwinControlChildrenShouldAllowSpaceAtTrailingEdge(uiDarwinControl(parent));\n        if (shouldExpand)\n            priority = NSLayoutPriorityDefaultLow;\n    }\n    [self->last2 setPriority:priority];\n    [self addConstraint:self->last2];\n    [self->last2 retain];\n\n    // next: assemble the views in the secondary direction\n    // each of them will span the secondary direction\n    for (i = 0; i < n; i++) {\n        prev = [[self child:i] view];\n        c = mkConstraint(prev, self->secondaryStart,\n            NSLayoutRelationEqual,\n            self, self->secondaryStart,\n            1, 0,\n            @\"uiBox start secondary constraint\");\n        [self addConstraint:c];\n        [self->otherConstraints addObject:c];\n        c = mkConstraint(prev, self->secondaryEnd,\n            NSLayoutRelationEqual,\n            self, self->secondaryEnd,\n            1, 0,\n            @\"uiBox end secondary constraint\");\n        [self addConstraint:c];\n        [self->otherConstraints addObject:c];\n    }\n\n    // finally, set sizes for stretchy controls\n    if (hasStretchy)\n        for (i = 0; i < n; i++) {\n            if (![self child:i].stretchy)\n                continue;\n            prev = [[self child:i] view];\n            if (prev == firstStretchy)\n                continue;\n            c = mkConstraint(prev, self->primarySize,\n                NSLayoutRelationEqual,\n                firstStretchy, self->primarySize,\n                1, 0,\n                @\"uiBox stretchy sizing\");\n            [self addConstraint:c];\n            [self->otherConstraints addObject:c];\n        }\n}\n\n- (void)append:(uiControl *)c stretchy:(int)stretchy\n{\n    boxChild *bc;\n    NSView *childView;\n\n    bc = [boxChild new];\n    bc.c = c;\n    bc.stretchy = stretchy;\n    childView = [bc view];\n    bc.oldHorzHuggingPri = horzHuggingPri(childView);\n    bc.oldVertHuggingPri = vertHuggingPri(childView);\n\n    uiControlSetParent(bc.c, uiControl(self->b));\n    uiDarwinControlSetSuperview(uiDarwinControl(bc.c), self);\n    uiDarwinControlSyncEnableState(uiDarwinControl(bc.c), uiControlEnabledToUser(uiControl(self->b)));\n\n    // if a control is stretchy, it should not hug in the primary direction\n    // otherwise, it should *forcibly* hug\n    if (stretchy)\n        setHuggingPri(childView, NSLayoutPriorityDefaultLow, self->primaryOrientation);\n    else\n        // TODO will default high work?\n        setHuggingPri(childView, NSLayoutPriorityRequired, self->primaryOrientation);\n    // make sure controls don't hug their secondary direction so they fill the width of the view\n    setHuggingPri(childView, NSLayoutPriorityDefaultLow, self->secondaryOrientation);\n\n    [self->children addObject:bc];\n    [bc release];       // we don't need the initial reference now\n\n    [self setNeedsUpdateConstraints:YES];\n}\n\n- (void)delete:(uintmax_t)n\n{\n    boxChild *bc;\n    NSView *removedView;\n\n    bc = [self child:n];\n    removedView = [bc view];\n\n    uiControlSetParent(bc.c, NULL);\n    uiDarwinControlSetSuperview(uiDarwinControl(bc.c), nil);\n\n    setHorzHuggingPri(removedView, bc.oldHorzHuggingPri);\n    setVertHuggingPri(removedView, bc.oldVertHuggingPri);\n\n    [self->children removeObjectAtIndex:n];\n\n    [self setNeedsUpdateConstraints:YES];\n}\n\n- (int)isPadded\n{\n    return self->padded;\n}\n\n- (void)setPadded:(int)p\n{\n    CGFloat padding;\n    uintmax_t i, n;\n    NSLayoutConstraint *c;\n\n    self->padded = p;\n\n    // TODO split into method (using above code)\n    padding = 0;\n    if (self->padded)\n        padding = 8.0;\n    n = [self->inBetweens count];\n    for (i = 0; i < n; i++) {\n        c = (NSLayoutConstraint *) [self->inBetweens objectAtIndex:i];\n        [c setConstant:padding];\n    }\n    // TODO call anything?\n}\n\n@end\n\nstatic void uiBoxDestroy(uiControl *c)\n{\n    uiBox *b = uiBox(c);\n\n    [b->view onDestroy];\n    [b->view release];\n    uiFreeControl(uiControl(b));\n}\n\nuiDarwinControlDefaultHandle(uiBox, view)\nuiDarwinControlDefaultParent(uiBox, view)\nuiDarwinControlDefaultSetParent(uiBox, view)\nuiDarwinControlDefaultToplevel(uiBox, view)\nuiDarwinControlDefaultVisible(uiBox, view)\nuiDarwinControlDefaultShow(uiBox, view)\nuiDarwinControlDefaultHide(uiBox, view)\nuiDarwinControlDefaultEnabled(uiBox, view)\nuiDarwinControlDefaultEnable(uiBox, view)\nuiDarwinControlDefaultDisable(uiBox, view)\n\nstatic void uiBoxSyncEnableState(uiDarwinControl *c, int enabled)\n{\n    uiBox *b = uiBox(c);\n\n    if (uiDarwinShouldStopSyncEnableState(uiDarwinControl(b), enabled))\n        return;\n    [b->view forAll:^(uintmax_t i, boxChild *bc) {\n        uiDarwinControlSyncEnableState(uiDarwinControl(bc.c), enabled);\n    }];\n}\n\nuiDarwinControlDefaultSetSuperview(uiBox, view)\n\nstatic BOOL uiBoxChildrenShouldAllowSpaceAtTrailingEdge(uiDarwinControl *c)\n{\n    uiBox *b = uiBox(c);\n\n    // return NO if this box is horizontal so nested horizontal boxes don't lead to ambiguity\n    return [b->view isVertical];\n}\n\nstatic BOOL uiBoxChildrenShouldAllowSpaceAtBottom(uiDarwinControl *c)\n{\n    uiBox *b = uiBox(c);\n\n    // return NO if this box is vertical so nested vertical boxes don't lead to ambiguity\n    return ![b->view isVertical];\n}\n\nvoid uiBoxAppend(uiBox *b, uiControl *c, int stretchy)\n{\n    [b->view append:c stretchy:stretchy];\n}\n\nvoid uiBoxDelete(uiBox *b, uintmax_t n)\n{\n    [b->view delete:n];\n}\n\nint uiBoxPadded(uiBox *b)\n{\n    return [b->view isPadded];\n}\n\nvoid uiBoxSetPadded(uiBox *b, int padded)\n{\n    [b->view setPadded:padded];\n}\n\nstatic uiBox *finishNewBox(BOOL vertical)\n{\n    uiBox *b;\n\n    uiDarwinNewControl(uiBox, b);\n\n    b->view = [[boxView alloc] initWithVertical:vertical b:b];\n\n    return b;\n}\n\nuiBox *uiNewHorizontalBox(void)\n{\n    return finishNewBox(NO);\n}\n\nuiBox *uiNewVerticalBox(void)\n{\n    return finishNewBox(YES);\n}\n```\n\n    ", "Answer": "\r\nSolved this myself.\n\nThe primary change is that instead of having the has-extra-space-after-it is not done by the constraints on self, but on its superview. The superview asks self if it should take the extra space, and if so, it allocates the extra space (using a >= constraint to the superview edge instead of a == constraint).\n\nA variety of other minor fixes fixes the edge case. In particular, everywhere where I do\n\n```\nrelation = NSLayoutRelationSomething;\nif (condition)\n    relation = NSLayoutRelationSomethingElse;\nconstraint = [NSLayoutConstraint constraintWithArg:arg arg:arg\n    relation:relation\n    ...]\n```\n\n\nI change to using two constraints, setting the priority of them both based on the condition. This should probably be an Auto Layout best practice, since it works so well...\n\nThanks anyway!\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
{"Question": "'x' must be an array of at least two dimensions: Error while running textmineR package for document clustering in R\r\n                \r\nI was running the ```\ntextmineR```\n library to perform document clustering and generate word cloud, however come across the below error message.\n\nError in base::colSums(x, na.rm = na.rm, dims = dims, ...) : \n'x' must be an array of at least two dimensions\n\nHere is the data structure:\n```\ndput(my_entrez_df_v1)\nstructure(list(PMID = c(32646047L, 32641214L, 32370561L, 32661206L, \n30089512L, 26694452L, 26602089L, 25542463L, 20462354L, 16824203L, \n16571117L, 16227300L, 16390004L, 15766558L, 15777647L, 15651759L, \n15135736L), Title = c(\"Protein Coding and Long Noncoding RNA (lncRNA) Transcriptional Landscape in  SARS-CoV-2 Infected Bronchial Epithelial Cells Highlight a Role for Interferon  and Inflammatory Response.\", \n\"SARS-CoV-2 infection risk assessment in the endometrium: viral infection-related gene expression across the menstrual cycle.\", \n\"Multi-tiered screening and diagnosis strategy for COVID-19: a model for sustainable testing capacity in response to pandemic.\", \n\"Assessment of risk conferred by coding and regulatory variations of TMPRSS2 and  CD26 in susceptibility to SARS-CoV-2 infection in human.\", \n\"Human _-defensin 2 plays a regulatory role in innate antiviral immunity and is capable of potentiating the induction of antigen-specific immunity.\", \n\"Glucose-6-Phosphate Dehydrogenase Enhances Antiviral Response through Downregulation of NADPH Sensor HSCARG and Upregulation of NF-_B Signaling.\", \n\"Middle East respiratory syndrome coronavirus shows poor replication but  significant induction of antiviral responses in human monocyte-derived macrophages and dendritic cells.\", \n\"Blood MxA protein as a marker for respiratory virus infections in young children.\", \n\"Significance of the myxovirus resistance A (MxA) gene -123C>a single-nucleotide  polymorphism in suppressed interferon beta induction of severe acute respiratory syndrome coronavirus infection.\", \n\"Association of SARS susceptibility with single nucleic acid polymorphisms of OAS1 and MxA genes: a case-control study.\", \n\"Inhibition of cytokine gene expression and induction of chemokine genes in non-lymphatic cells infected with SARS coronavirus.\", \n\"Severe acute respiratory syndrome coronavirus fails to activate  cytokine-mediated innate immune responses in cultured human monocyte-derived dendritic cells.\", \n\"A case-control study on the mxA polymorphisms and susceptibility to severe acute respiratory syndromes\", \n\"Polymorphisms of interferon-inducible genes OAS-1 and MxA associated with SARS in the Vietnamese population.\", \n\"Microarray and real-time RT-PCR analyses of differential human gene expression  patterns induced by severe acute respiratory syndrome (SARS) coronavirus infection of Vero cells.\", \n\"Increased sensitivity of SARS-coronavirus to a combination of human type I and type II interferons.\", \n\"The antiviral effect of interferon-beta against SARS-coronavirus is not mediated by MxA protein.\"\n), Abstract_v1 = c(\"The global spread of COVID-19 caused by pathogenic severe acute respiratory syndrome coronavirus 2 SARS-CoV-2 underscores the need for an imminent response from medical research communities to better understand this rapidly  spreading infection Employing multiple bioinformatics and computational  pipelines on transcriptome data from primary normal human bronchial epithelial  cells NHBE during SARS-CoV-2 infection revealed activation of several  mechanistic networks including those involved in immunoglobulin G IgG and  interferon lambda IFNL in host cells Induction of acute inflammatory response  and activation of tumor necrosis factor TNF was prominent in SARS-CoV-2  infected NHBE cells Additionally disease and functional analysis employing  ingenuity pathway analysis IPA revealed activation of functional categories related to cell death while those associated with viral infection and  replication were suppressed Several interferon IFN responsive gene targets  IRF9 IFIT1 IFIT2 IFIT3 IFITM1 MX1 OAS2 OAS3 IFI44 and IFI44L were  highly upregulated in SARS-CoV-2 infected NBHE cell implying activation of  antiviral IFN innate response Gene ontology and functional annotation of differently expressed genes in patient lung tissues with COVID-19 revealed  activation of antiviral response as the hallmark Mechanistic network analysis  in IPA identified 14 common activated and 9 common suppressed networks in  patient tissue as well as in the NHBE cell model suggesting a plausible role  for these upstream regulator networks in the pathogenesis of COVID-19 Our data  revealed expression of several viral proteins in vitro and in patient-derived  tissue while several host-derived long noncoding RNAs lncRNAs were  identified Our data highlights activation of IFN response as the main hallmark associated with SARS-CoV-2 infection in vitro and in human and identified  several differentially expressed lncRNAs during the course of infection which could serve as disease biomarkers while their precise role in the host response to SARS-CoV-2 remains to be investigated\", \n\"To determine the susceptibility of the endometrium to infection by-and thereby potential damage from-SARS-CoV-2 Analysis of SARS-Cov-2 infection-related gene expression from endometrial transcriptomic data sets Infertility research department affiliated with a public hospital Gene expression data from five studies in 112 patients with normal endometrium collected throughout the menstrual cycle None Gene expression and correlation between viral infectivity genes and age throughout the menstrual cycle Gene expression was high for TMPRSS4 CTSL CTSB FURIN MX1 and BSG medium for TMPRSS2 and low for ACE2 ACE2 TMPRSS4 CTSB CTSL and MX1 expression increased toward the window of implantation TMPRSS4 expression was positively correlated with ACE2 CTSB CTSL MX1 and FURIN during several cycle phases TMPRSS2 was not statistically significantly altered across the cycle ACE2 TMPRSS4 CTSB CTSL BSG and MX1 expression increased with age especially in early phases of the cycle Endometrial tissue is likely safe from SARS-CoV-2 cell entry based on ACE2 and TMPRSS2 expression but susceptibility increases with age Further TMPRSS4 along with BSG-mediated viral entry into cells could imply a susceptible environment for SARS-CoV-2 entry via different mechanisms Additional studies are warranted to determine the true risk of endometrial infection by SARS-CoV-2 and implications for fertility treatments\", \n\"Coronavirus disease 2019 COVID-19 caused by novel enveloped single stranded RNA coronavirus SARS-CoV-2 is responsible for an ongoing global pandemic While other countries deployed widespread testing as an early mitigation strategy the US experienced delays in development and deployment of organism identification assays As such there is uncertainty surrounding disease burden and community spread severely hampering containment efforts COVID-19 illuminates the need for a tiered diagnostic approach to rapidly identify clinically significant infections and reduce disease spread Without the ability to efficiently screen patients hospitals are overwhelmed potentially delaying treatment for other emergencies A multi-tiered diagnostic strategy incorporating a rapid host immune response assay as a screening test molecular confirmatory testing and rapid IgM/IgG testing to assess benefit from quarantine/further testing and provide information on population exposure/herd immunity would efficiently evaluate potential COVID-19 patients Triaging patients within minutes with a fingerstick rather than hours/days after an invasive swab is critical to pandemic response as reliance on the existing strategy is limited by assay accuracy time to results and testing capacity Early screening and triage is achievable from the outset of a pandemic with point-of-care host immune response testing which will improve response time to clinical and public health actionsKey messagesDelayed testing deployment has led to uncertainty surrounding overall disease burden and community spread severely hampering public health containment and healthcare system preparation effortsA multi-tiered testing strategy incorporating rapid host immune point-of-care tests can be used now and for future pandemic planning by effectively identifying patients at risk of disease thereby facilitating quarantine earlier in the progression of the outbreak during the weeks and months it can take for pathogen specific confirmatory tests to be developed validated and manufactured in sufficient quantitiesThe ability to triage patients at the point of care and support the guidance of medical and therapeutic decisions for viral isolation or confirmatory testing or for appropriate treatment of COVID-19 and/or bacterial infections is a critical component to our national pandemic response and there is an urgent need to implement the proposed strategy to combat the current outbreak\", \n\"At present more than 200 countries and territories are directly affected by the coronavirus disease-19 COVID-19 pandemic Incidence and case fatality rate are significantly higher among elderly individuals age60 years type 2 diabetes and hypertension patients Cellular receptor ACE2 serine protease TMPRSS2 and exopeptidase CD26 also known as DPP4 are the three membrane bound proteins potentially implicated in SARS-CoV-2 infection We hypothesised that common variants from TMPRSS2 and CD26 may play critical role in infection susceptibility of predisposed population or group of individuals Coding missense and regulatory variants from TMPRSS2 and CD26 were studied across 26 global populations Two missense and five regulatory SNPs were identified to have differential allelic frequency Significant linkage disequilibrium LD signature was observed in different populations Modelled protein-protein interaction PPI predicted strong molecular interaction between these two receptors and SARS-CoV-2 spike protein S1 domain However two missense SNPs rs12329760 TMPRSS2 and rs1129599 CD26 were not found to be involved physically in the said interaction Four regulatory variants rs112657409 rs11910678 rs77675406 and rs713400 from TMPRSS2 were found to influence the expression of TMPRSS2 and pathologically relevant MX1 rs13015258 a 50 UTR variant from CD26 have significant role in regulation of expression of key regulatory genes that could be involved in SARS-CoV-2 internalization Overexpression of CD26 through epigenetic modification at rs13015258-C allele was found critical and could explain the higher SARS-CoV-2 infected fatality rate among type 2 diabetes\", \n\"Antimicrobial peptides AMPs are primarily known for their innate immune defense against invading microorganisms including viruses In addition recent research has suggested their modulatory activity in immune induction Given that most subunit vaccines require an adjuvant to achieve effective immune induction through the activation of innate immunity AMPs are plausible candidate molecules for stimulating not only innate immune but also adaptive immune responses In this study we investigated the ability of human -defensin HBD 2 to promote antiviral immunity in vitro and in vivo using a receptor-binding domain RBD of Middle East respiratory syndrome-coronavirus MERS-CoV spike protein S RBD as a model antigen Ag When HBD 2-conjugated S RBD was used to treat THP-1 human monocytic cells the expression levels of antiviral IFN- IFN- MxA PKR and RNaseL and primary immune-inducing NOD2 TNF- IL-1 and IL-6 molecules were enhanced compared to those expressed after treatment with S RBD only The expression of chemokines capable of recruiting leukocytes including monocytes/macrophages natural killer cells granulocytes T cells and dendritic cells was also increased following HBD 2-conjugated S RBD treatment More important immunization of mice with HBD 2-conjugated S RBD enhanced the immunogenicity of the S RBD and elicited a higher S RBD-specific neutralizing antibody response than S RBD alone We conclude that HBD 2 activates the primary antiviral innate immune response and may also mediate the induction of an effective adaptive immune response against a conjugated Ag\", \n\"Glucose-6-phosphate dehydrogenase G6PD-deficient cells are highly susceptible to viral infection This study examined the mechanism underlying this phenomenon by measuring the expression of antiviral genes-tumor necrosis factor alpha TNF- and GTPase myxovirus resistance 1 MX1-in G6PD-knockdown cells upon human coronavirus 229E HCoV-229E and enterovirus 71 EV71 infection Molecular analysis revealed that the promoter activities of TNF- and MX1 were downregulated in G6PD-knockdown cells and that the IB degradation and DNA binding activity of NF-B were decreased The HSCARG protein a nicotinamide adenine dinucleotide phosphate NADPH sensor and negative regulator of NF-B was upregulated in G6PD-knockdown cells with decreased NADPH/NADP ratio Treatment of G6PD-knockdown cells with siRNA against HSCARG enhanced the DNA binding activity of NF-B and the expression of TNF- and MX1 but suppressed the expression of viral genes however the overexpression of HSCARG inhibited the antiviral response Exogenous G6PD or IDH1 expression inhibited the expression of HSCARG resulting in increased expression of TNF- and MX1 and reduced viral gene expression upon virus infection Our findings suggest that the increased susceptibility of the G6PD-knockdown cells to viral infection was due to impaired NF-B signaling and antiviral response mediated by HSCARG\", \n\"In this study we assessed the ability of Middle East respiratory syndrome coronavirus MERS-CoV to replicate and induce innate immunity in human monocyte-derived macrophages and dendritic cells MDDCs and compared it with severe acute respiratory syndrome coronavirus SARS-CoV Assessments of viral protein and RNA levels in infected cells showed that both viruses were impaired in their ability to replicate in these cells Some induction of IFN-1 CXCL10 and MxA mRNAs in both macrophages and MDDCs was seen in response to MERS-CoV infection but almost no such induction was observed in response to SARS-CoV infection ELISA and Western blot assays showed clear production of CXCL10 and MxA in MERS-CoV-infected macrophages and MDDCs Our data suggest that SARS-CoV and MERS-CoV replicate poorly in human macrophages and MDDCs but MERS-CoV is nonetheless capable of inducing a readily detectable host innate immune response Our results highlight a clear difference between the viruses in activating host innate immune responses in macrophages and MDDCs which may contribute to the pathogenesis of infection\", \n\"Type I interferon induced MxA response can differentiate viral from bacterial infections but MxA responses in rhinovirus or asymptomatic virus infections are not known To study MxA protein levels in healthy state and during respiratory virus infection of young children in an observational prospective cohort Blood samples and nasal swabs were collected from 153 and 77 children with and without symptoms of respiratory infections respectively Blood MxA protein levels were measured by an enzyme immunoassay and PCR methods were used for the detection of respiratory viruses in nasal swabs Respiratory viruses were detected in 81 of symptomatic children They had higher blood MxA protein levels median interquartile range than asymptomatic virus-negative children 695 345-1370 g/L vs 110 55-170 g/L p  0001 Within asymptomatic children no significant difference was observed in MxA responses between virus-positive and virus-negative groups A cut-off level of 175 g/L had 92 sensitivity and 77 specificity for a symptomatic respiratory virus infection Rhinovirus respiratory syncytial virus parainfluenza virus influenza virus coronavirus and human metapneumovirus infections were associated with elevated MxA responses Asymptomatic virus-negative children vaccinated with a live virus vaccine had elevated MxA protein levels 240 120-540 g/L but significantly lower than children with an acute respiratory infection who had not received vaccinations 740 350-1425 g/L p0001 Blood MxA protein levels are increased in young children with symptomatic respiratory virus infections including rhinovirus infections MxA is an informative general marker for the most common acute virus infections\", \n\"Myxovirus resistance A MxA is an antiviral protein induced by interferon alpha and beta IFN-alpha IFN-beta that can inhibit viral replication The minor alleles of the -88GT and -123CA MxA promoter single-nucleotide polymorphisms SNPs are associated with increased promoter activity and altered response to IFN-alpha and IFN-beta treatment Here we demonstrate that the -123A minor allele provided stronger binding affinity to nuclear proteins extracted from IFN-beta-untreated cells than did the wild-type allele whereas the -88T allele showed preferential binding after IFN-beta stimulation Endogenous IFN-alpha and IFN-beta induction can be suppressed in severe acute respiratory syndrome SARS coronavirus infection In support of our in vitro findings a large case-control genetic-association study for SARS coronavirus infection confirmed that the -123A minor-allele carriers were significantly associated with lower risk of SARS coronavirus infection whereas the -88T minor-allele carriers were insignificant after adjustment for confounding effects This suggests that -123CA plays a more important role in modulating basal MxA expression thus contributing more significantly to innate immune response against viral infections that suppress endogenous IFN-alpha and IFN-beta induction such as SARS coronavirus\", \n\"Host genetic factors may play a role in susceptibility and resistance to SARS associated coronavirus SARS-CoV infection The study was carried out to investigate the association between the genetic polymorphisms of 25-oligoadenylate synthetase 1 OAS1 gene as well as myxovirus resistance 1 MxA gene and susceptibility to SARS in Chinese Han population A hospital-based case-control study was conducted A collective of 66 SARS cases and 64 close contact uninfected controls were enrolled in this study End point real time polymerase chain reaction PCR and PCR-based Restriction Fragment Length Polymorphism RFLP analysis were used to detect the single nucleic polymorphisms SNPs in OAS1 and MxA genes Information on other factors associated with SARS infection was collected using a pre-tested questionnaire Univariate and multivariate logistic analyses were conducted One polymorphism in the 3-untranslated region 3-UTR of the OAS1 gene was associated with SARS infection Compared to AA genotype AG and GG genotypes were found associated with a protective effect on SARS infection with ORs 95 CI of 042 020-089 and 030 009-097 respectively Also a GT genotype at position 88 in the MxA gene promoter was associated with increased susceptibility to SARS infection compared to a GG genotype OR  306 95 CI 125-750 The associations of AG genotype in OAS1 and GT genotype in MxA remained significant in multivariate analyses after adjusting for SARS protective measures OR  038 95 CI 014-098 and OR  322 95 CI 113-918 respectively SNPs in the OAS1 3-UTR and MxA promoter region appear associated with host susceptibility to SARS in Chinese Han population\", \n\"SARS coronavirus SARS-CoV is the etiologic agent of the severe acute respiratory syndrome SARS-CoV mainly infects tissues of non-lymphatic origin and the cytokine profile of those cells can determine the course of disease Here we investigated the cytokine response of two human non-lymphatic cell lines Caco-2 and HEK 293 which are fully permissive for SARS-CoV A comparison with established cytokine-inducing viruses revealed that SARS-CoV only weakly triggered a cytokine response In particular SARS-CoV did not activate significant transcription of the interferons IFN-alpha IFN-beta IFN-lambda1 IFN-lambda2/3 as well as of the interferon-induced antiviral genes ISG56 and MxA the chemokine RANTES and the interleukine IL-6 Interestingly however SARS-CoV strongly induced the chemokines IP-10 and IL-8 in the colon carcinoma cell line Caco-2 but not in the embryonic kidney cell line 293 Our data indicate that SARS-CoV suppresses the antiviral cytokine system of non-immune cells to a large extent thus buying time for dissemination in the host However synthesis of IP-10 and IL-8 which are established markers for acute-stage SARS escapes the virus-induced silencing at least in some cell types Therefore the progressive infiltration of immune cells into the infected lungs observed in SARS patients could be due to the production of these chemokines by the infected tissue cells\", \n\"Activation of host innate immune responses was studied in severe acute respiratory syndrome coronavirus SCV-infected human A549 lung epithelial cells macrophages and dendritic cells DCs In all cell types SCV-specific subgenomic mRNAs were seen whereas no expression of SCV proteins was found No induction of cytokine genes alpha interferon IFN-alpha IFN-beta interleukin-28A/B IL-28A/B IL-29 tumor necrosis factor alpha CCL5 or CXCL10 or IFN-alpha/beta-induced MxA gene was seen in SCV-infected A549 cells macrophages or DCs SCV also failed to induce DC maturation CD86 expression or enhance major histocompatibility complex class II expression Our data strongly suggest that SCV fails to activate host cell cytokine gene expression in human macrophages and DCs\", \n\"To investigate the association between the genetic polymorphisms of myxovirus resistance 1 MxA gene and susceptibility to severe acute respiratory syndromes SARS A case-control study was conducted and polymerase chain reaction-restriction fragment length polymorphism PCR-RFLP was used to detect the T/G polymorphism at position-88 in the mxA gene promoter Information on related factors of SARS was collected using a pre-testing questionnaire Univariate and multivariate logistic analyses were conducted with SPSS software package Sixty-six cases and sixty-four controls were selected for the study Comparing with GG genotype the proportion of GT genotype were significantly higher in the case group 813 than that in the control group 625 with an OR 95 CI of 2700 1208-6037 Multivariate logistic regression analysis revealed that the significant association remained after factors as wearing masks protection gowns and eye-protection when contacting with SARS patient etc were adjusted with an OR 95  CI of 2911 1027-8250 mxA promoter-88G/T SNP might be confered to host genetic susceptibility to SARS in Chinese Han population\", \n\"We hypothesized that host antiviral genes induced by type I interferons might affect the natural course of severe acute respiratory syndrome SARS We analyzed single nucleotide polymorphisms SNPs of 25-oligoadenylate synthetase 1 OAS-1 myxovirus resistance-A MxA and double-stranded RNA-dependent protein kinase in 44 Vietnamese SARS patients with 103 controls The G-allele of non-synonymous A/G SNP in exon 3 of OAS-1 gene showed association with SARS p00090 The G-allele in exon 3 of OAS-1 and the one in exon 6 were in strong linkage disequilibrium and both of them were associated with SARS infection The GG genotype and G-allele of G/T SNP at position -88 in the MxA gene promoter were found more frequently in hypoxemic group than in non-hypoxemic group of SARS p00195 Our findings suggest that polymorphisms of two IFN-inducible genes OAS-1 and MxA might affect susceptibility to the disease and progression of SARS at each level\", \n\"Vero E6 African green monkey kidney cells are highly susceptible to infection with the newly emerging severe acute respiratory syndrome coronavirus SARS-CoV and they are permissive for rapid viral replication with resultant cytopathic effects We employed cDNA microarray analysis to characterize the cellular transcriptional responses of homologous human genes at 12 h post-infection Seventy mRNA transcripts belonging to various functional classes exhibited significant alterations in gene expression There was considerable induction of heat shock proteins that are crucial to the immune response mechanism Modified levels of several transcripts involved in pro-inflammatory and anti-inflammatory processes exemplified the balance between opposing forces during SARS pathogenesis Other genes displaying altered transcription included those associated with host translation cellular metabolism cell cycle signal transduction transcriptional regulation protein trafficking protein modulators and cytoskeletal proteins Alterations in the levels of several novel transcripts encoding hypothetical proteins and expressed sequence tags were also identified In addition transcription of apoptosis-related genes DENN and hIAP1 was upregulated in contrast to FAIM Elevated Mx1 expression signified a strong host response to mediate antiviral resistance Also expressed in infected cells was the C-terminal alternative splice variant of the p53 tumor suppressor gene encoding a modified truncated protein that can influence the activity of wild-type p53 We observed the interplay between various mechanisms to favor virus multiplication before full-blown apoptosis and the triggering of several pathways in host cells in an attempt to eliminate the pathogen Microarray analysis identifies the critical host-pathogen interactions during SARS-CoV infection and provides new insights into the pathophysiology of SARS\", \n\"There is currently an urgent need to identify effective antiviral agents that will prevent and treat severe acute respiratory syndrome coronavirus SARS-CoV infection In this study we have investigated and compared the antiviral effect of different interferons IFNs on SARS-CoV replication in the epithelial kidney monkey Vero cell line The results showed that SARS-CoV grown in Vero cells is moderately sensitive to IFN-beta and only weakly sensitive to IFN-alpha and IFN-gamma in comparison to other IFN-sensitive viruses such as those for encephalomyocarditis vesicular stomatitis and Newcastle disease Simultaneous incubation of Vero cells with IFN-beta and IFN-gamma indicated that they may act synergistically against SARS-CoV replication The IFN-induced MxA protein was detected in the IFN-treated Vero cells The data however suggest that the antiviral activity of IFN against SARS-CoV virus is independent of MxA expression\", \n\"Severe acute respiratory syndrome SARS is caused by a novel coronavirus termed SARS-CoV No antiviral treatment has been established so far Interferons are cytokines which induce the synthesis of several antivirally active proteins in the cell In this study we demonstrated that multiplication of SARS-CoV in cell culture can be strongly inhibited by pretreatment with interferon-beta Interferon-alpha and interferon-gamma by contrast were less effective The human MxA protein is one of the most prominent proteins induced by interferon-beta Nevertheless no interference with SARS-CoV replication was observed in Vero cells stably expressing MxA Therefore other interferon-induced proteins must be responsible for the strong inhibitory effect of interferon-beta against SARS-CoV\"\n)), class = \"data.frame\", row.names = c(NA, -17L))\n\n\nlibrary(textmineR)\nlibrary(dplyr) # pipes\nlibrary(stringi) # for stri_enc_isutf8\n\n#The below code uses regular expressions to cleanse. May need to tinker with the last \n#portion that selects the grammar to retain\n\nmy_entrez_df_v1<- my_entrez_df %>% \n  mutate(Abstract = gsub(\"[^[:alnum:][:blank:]?&/\\\\-]\", \"\", my_entrez_df$Abstract)) %>%\n  rename(Abstract_v1 = Abstract)\n\n#this column is now utf 8.\n\nall(stri_enc_isutf8(my_entrez_df_v1$Abstract_v1))\n\n# create a document term matrix \ndtm <- CreateDtm(doc_vec = my_entrez_df_v1$Abstract_v1, # character vector of documents\n                 doc_names = my_entrez_df_v1$PMID, # document names\n                 ngram_window = c(1, 2), # minimum and maximum n-gram length\n                 stopword_vec = c(stopwords::stopwords(\"en\"), # stopwords from tm\n                                  stopwords::stopwords(source = \"smart\")), # this is the default value\n                 lower = TRUE, # lowercase - this is the default value\n                 remove_punctuation = TRUE, # punctuation - this is the default\n                 remove_numbers = TRUE, # numbers - this is the default\n                 verbose = FALSE, # Turn off status bar for this demo\n                 cpus = 2) # default is all available cpus on the system\n\n\n# construct the matrix of term counts to get the IDF vector\ntf_mat <- TermDocFreq(dtm)\n\n\n# TF-IDF and cosine similarity\ntfidf <- t(dtm[ , tf_mat$term ]) * tf_mat$idf\n\ntfidf <- t(tfidf)\n\ncsim <- tfidf / sqrt(rowSums(tfidf * tfidf))\n\ncsim <- csim %*% t(csim)\ncdist <- as.dist(1 - csim)\n\nhc <- hclust(cdist, \"ward.D\")\n\nclustering <- cutree(hc, 10)\n\np_words <- colSums(dtm) / sum(dtm)\n\ncluster_words <- lapply(unique(clustering), function(x){\n  rows <- dtm[ clustering == x , ]\n  \n  # for memory's sake, drop all words that don't appear in the cluster\n  rows <- rows[ , colSums(rows) > 0 ]\n  \n  colSums(rows) / sum(rows) - p_words[ colnames(rows) ]\n})\n```\n\n    ", "Answer": "\r\ndtm is a sparse matrix. Your filter ```\nrows <- dtm[ clustering == x , ]```\n gives a new sparse matrix for x = 1 or 2, but in your example if you choose x = 3 it turns out to become a normal vector. That is when the error is triggered on ```\ncolSums()```\n, which cannot have a vector as input.\nThis might be caused because all the clustering = 3 cases occur in a single row of the matrix?\n    ", "Knowledge_point": "Matrix Chain Multiplication", "Tag": "算法分析"}
