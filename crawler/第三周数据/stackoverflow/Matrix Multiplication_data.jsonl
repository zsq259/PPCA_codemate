{"Question": "Sparse matrix-matrix multiplication\r\n                \r\nI'm currently working with sparse matrices, and I have to compare the computation time of sparse matrix-matrix multiplication with full matrix-matrix multiplication. The issue is that sparse matrix computation is waaaaay slower than full matrix computation.\n\nI'm compressing my matrices with the Compressed Row Storage, and multiplicating 2 matrices is very time consuming (quadruple for loop), so I'm wondering if there is a better compression format more suitable for matrix-matrix operation (CRS is very handy with matrix-vector computation).\n\nThanks in advance!\n    ", "Answer": "\r\nIt's usually referred to as \"Compressed Sparse Rows\" (CSR), not CRS. The transpose, Compressed Sparse Columns (CSC) is also commonly used, including by the CSparse package that ends up being the backend of quite a lot of systems including MatLAB and SciPy (I think).\n\nThere is also a less-common Doubly-Compressed Sparse Columns (DCSC) format used by the Combinatorial BLAS. It compresses the column index again, and is useful for cases where the matrix is hypersparse. A hypersparse matrix has most columns empty, something that happens with 2D matrix decomposition.\n\nThat said, yes there is more overhead. However your operations are now dominated by the number of nonzeros, not the dimensions. So your FLOPS might be less but you still get your answer quicker.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Transformation Matrix Multiplication by matrix type, C++\r\n                \r\nTheoretically, let us assume we were to hard-code matrix multiplications for each different combination of 3D Homogeneous (4x4) transformation matrix (translation, rotation, scaling), and then for also each possible result of those (translation-rotation, translation-scaling, scaling-rotation)...\n\nSuppose we were to handle matrix multiplication like that, a different function for each matrix type combination, where each matrix has an extra variable (type), and with the specific functions to use being determined at runtime (using a function pointer array).   If we applied this kind of matrix multiplication, could it theoretically be faster than doing basic, standard 4x4 homogeneous matrix multiplication (which is still admittedly faster than generic 4x4 matrix multiplication)?\n\nI'm doing this right now, its kinda hellish to code.  I'm going to test it against standard matrix multiplication in the end, and compare results.  I just wanted to see what other people think the results might be.  Any ideas?\n    ", "Answer": "\r\nI think a better idea is to store only position and orientation of an object instead of the whole matrix. You only compute the matrix for rendering purpose, once after all transformations. The transformations are done by adding translations (for the position) and multiplying quaternions (for the orientation).\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Scipy sparse matrix multiplication\r\n                \r\nI have this example of matrix by matrix multiplication using numpy arrays:\n\n```\nimport numpy as np\nm = np.array([[1,2,3],[4,5,6],[7,8,9]])\nc = np.array([0,1,2])\nm * c\narray([[ 0,  2,  6],\n       [ 0,  5, 12],\n       [ 0,  8, 18]])\n```\n\n\nHow can i do the same thing if m is scipy sparse CSR matrix? This gives dimension mismatch:\n\n```\nsp.sparse.csr_matrix(m)*sp.sparse.csr_matrix(c)\n```\n\n    ", "Answer": "\r\nYou can call the ```\nmultiply```\n method of ```\ncsr_matrix```\n to do pointwise multiplication.  \n\n```\nsparse.csr_matrix(m).multiply(sparse.csr_matrix(c)).todense()\n\n# matrix([[ 0,  2,  6],\n#         [ 0,  5, 12],\n#         [ 0,  8, 18]], dtype=int64)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication in Apache Spark [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs debugging details. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     Edit the question to include desired behavior, a specific problem or error, and the shortest code necessary to reproduce the problem. This will help others answer the question.\r\n                \r\n                    \r\n                        Closed 7 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI am trying to perform matrix multiplication using Apache Spark and Java.\n\nI have 2 main questions:\n\n\nHow to create RDD that can represent matrix in Apache Spark?  \nHow to multiply two such RDDs?\n\n    ", "Answer": "\r\nAll depends on the input data and dimensions but generally speaking what you want is not a ```\nRDD```\n but one of the distributed data structures from ```\norg.apache.spark.mllib.linalg.distributed```\n. At this moment it provides four different implementations of the ```\nDistributedMatrix```\n\n\n\n```\nIndexedRowMatrix```\n - can be created directly from a ```\nRDD[IndexedRow]```\n where ```\nIndexedRow```\n consist of row index and ```\norg.apache.spark.mllib.linalg.Vector```\n\n\n```\nimport org.apache.spark.mllib.linalg.{Vectors, Matrices}\nimport org.apache.spark.mllib.linalg.distributed.{IndexedRowMatrix,\n  IndexedRow}\n\nval rows =  sc.parallelize(Seq(\n  (0L, Array(1.0, 0.0, 0.0)),\n  (0L, Array(0.0, 1.0, 0.0)),\n  (0L, Array(0.0, 0.0, 1.0)))\n).map{case (i, xs) => IndexedRow(i, Vectors.dense(xs))}\n\nval indexedRowMatrix = new IndexedRowMatrix(rows)\n```\n\n```\nRowMatrix```\n - similar to ```\nIndexedRowMatrix```\n but without meaningful row indices. Can be created directly from ```\nRDD[org.apache.spark.mllib.linalg.Vector]```\n\n\n```\nimport org.apache.spark.mllib.linalg.distributed.RowMatrix\n\nval rowMatrix = new RowMatrix(rows.map(_.vector))      \n```\n\n```\nBlockMatrix```\n - can be created from ```\nRDD[((Int, Int), Matrix)]```\n where first element of the tuple contains coordinates of the block and the second one is a local ```\norg.apache.spark.mllib.linalg.Matrix```\n\n\n```\nval eye = Matrices.sparse(\n  3, 3, Array(0, 1, 2, 3), Array(0, 1, 2), Array(1, 1, 1))\n\nval blocks = sc.parallelize(Seq(\n   ((0, 0), eye), ((1, 1), eye), ((2, 2), eye)))\n\nval blockMatrix = new BlockMatrix(blocks, 3, 3, 9, 9)\n```\n\n```\nCoordinateMatrix```\n - can be created from ```\nRDD[MatrixEntry]```\n where ```\nMatrixEntry```\n consist of row, column and value.\n\n```\nimport org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix,\n  MatrixEntry}\n\nval entries = sc.parallelize(Seq(\n   (0, 0, 3.0), (2, 0, -5.0), (3, 2, 1.0),\n   (4, 1, 6.0), (6, 2, 2.0), (8, 1, 4.0))\n).map{case (i, j, v) => MatrixEntry(i, j, v)}\n\nval coordinateMatrix = new CoordinateMatrix(entries, 9, 3)\n```\n\n\n\nFirst two implementations support multiplication by a local ```\nMatrix```\n:\n\n```\nval localMatrix = Matrices.dense(3, 2, Array(1.0, 2.0, 3.0, 4.0, 5.0, 6.0))\n\nindexedRowMatrix.multiply(localMatrix).rows.collect\n// Array(IndexedRow(0,[1.0,4.0]), IndexedRow(0,[2.0,5.0]),\n//   IndexedRow(0,[3.0,6.0]))\n```\n\n\nand the third one can be multiplied by an another ```\nBlockMatrix```\n as long as number of columns per block in this matrix matches number of rows per block of the other matrix. ```\nCoordinateMatrix```\n doesn't support multiplications but is pretty easy to create and transform to other types of distributed matrices:\n\n```\nblockMatrix.multiply(coordinateMatrix.toBlockMatrix(3, 3))\n```\n\n\nEach type has its own strong and weak sides and there are some additional factors to consider when you use sparse or dense elements (```\nVectors```\n or block ```\nMatrices```\n). Multiplying by a local matrix is usually preferable since it doesn't require expensive shuffling. \n\nYou can find more details about each type in the MLlib Data Types guide. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix-Matrix Multiplication\r\n                \r\nI'm writing a C code including matrix multiplication and I'm using 3 nested loops for that operation. So, does anyone know how we can improve that code by removing one of the nested loops?\n\n```\nfor (i = 0; i < SIZE; ++i)\n    for (j = 0; j < SIZE; ++j)\n        for (k = 0; k < SIZE; ++k)\n            c[i][j] += a[i][k] * b[k][j];\n```\n\n    ", "Answer": "\r\nMatrix multiplication for dense matrices has O(n^3). This can be accelerated by using Strassen's algorithm to O(n^(2.8)) or Coppersmith-Winogar to O(n^(2.37)).\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Python matrix multiplication - result matrix size\r\n                \r\nI am trying to create the product matrix for matrix multiplication in Python, but I am not sure what size the matrix will be as the user can give any input for the matrix multiplication.\n\nI've approached the situation using this for a previous task on matrices when the actual matrix size is provided\nproduct_matrix = [[col for col in range(4)] for row in range(4)]\n\nBut I'm not sure how to tackle it in this case. \n    ", "Answer": "\r\nFor ```\nx = range(len(B[0]))```\n, did you mean ```\nx = len(B[0])```\n?\n\nBy multiplying ```\nA * B```\n, your resulting matrix ```\nresult```\n should have the ```\nnum_raw```\n of ```\nA```\n and ```\nnum_col```\n of ```\nB```\n.\n\n```\nx = len(B[0])```\n means that your ```\nx```\n is counting how many elements are there for each row of ```\nB```\n, that is ```\nx```\n is ```\nnum_col```\n of ```\nB```\n. ```\nlen(A)```\n is counting how many rows are there in ```\nA```\n, that is ```\nlen(A)```\n is ```\nnum_row```\n of ```\nA```\n. Therefore, your ```\nresult```\n is initialized as \"each row has ```\nx```\n elements, and there are ```\nlen(A)```\n rows\" with all entries of 0.\n\nAnd the second line you provided should be in a for-loop, which is exactly the same how you calculate each entry of resulting matrix by hand.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix-Matrix Multiplication\r\n                \r\nI'm writing a C code including matrix multiplication and I'm using 3 nested loops for that operation. So, does anyone know how we can improve that code by removing one of the nested loops?\n\n```\nfor (i = 0; i < SIZE; ++i)\n    for (j = 0; j < SIZE; ++j)\n        for (k = 0; k < SIZE; ++k)\n            c[i][j] += a[i][k] * b[k][j];\n```\n\n    ", "Answer": "\r\nMatrix multiplication for dense matrices has O(n^3). This can be accelerated by using Strassen's algorithm to O(n^(2.8)) or Coppersmith-Winogar to O(n^(2.37)).\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication using arrays\r\n                \r\nI'm trying to make a simple matrix multiplication method using multidimensional arrays (```\n[2][2]```\n). I'm kinda new at this, and I just can't find what it is I'm doing wrong. I'd really appreciate any help in telling me what it is. I'd rather not use libraries or anything like that, I'm mostly doing this to learn how it works. Thank you so much in advance.\n\nI'm declaring my arays in the main method as follows:\n\n```\nDouble[][] A={{4.00,3.00},{2.00,1.00}}; \nDouble[][] B={{-0.500,1.500},{1.000,-2.0000}};\n```\n\n\nA*B should return the identity matrix. It doesn't.\n\n```\npublic static Double[][] multiplicar(Double[][] A, Double[][] B){\n//the method runs and returns a matrix of the correct dimensions\n//(I actually changed the .length function to a specific value to eliminate \n//it as a possible issue), but not the correct values\n\n    Double[][] C= new Double[2][2];\n    int i,j;\n\n    ////I fill the matrix with zeroes, if I don't do this it gives me an error\n    for(i=0;i<2;i++) {\n        for(j=0;j<2;j++){\n            C[i][j]=0.00000;\n        }\n    } \n    ///this is where I'm supposed to perform the adding of every element in\n    //a row of A multiplied by the corresponding element in the\n    //corresponding column of B, for all columns in B and all rows in A\n    for(i=0;i<2;i++){\n        for(j=0;j<2;j++)\n            C[i][j]+=(A[i][j]*B[j][i]);\n    }\n    return C;\n}\n```\n\n    ", "Answer": "\r\nYou can try this code:\n\n```\npublic class MyMatrix {\n    Double[][] A = { { 4.00, 3.00 }, { 2.00, 1.00 } };\n    Double[][] B = { { -0.500, 1.500 }, { 1.000, -2.0000 } };\n\n    public static Double[][] multiplicar(Double[][] A, Double[][] B) {\n\n        int aRows = A.length;\n        int aColumns = A[0].length;\n        int bRows = B.length;\n        int bColumns = B[0].length;\n\n        if (aColumns != bRows) {\n            throw new IllegalArgumentException(\"A:Rows: \" + aColumns + \" did not match B:Columns \" + bRows + \".\");\n        }\n\n        Double[][] C = new Double[aRows][bColumns];\n        for (int i = 0; i < aRows; i++) {\n            for (int j = 0; j < bColumns; j++) {\n                C[i][j] = 0.00000;\n            }\n        }\n\n        for (int i = 0; i < aRows; i++) { // aRow\n            for (int j = 0; j < bColumns; j++) { // bColumn\n                for (int k = 0; k < aColumns; k++) { // aColumn\n                    C[i][j] += A[i][k] * B[k][j];\n                }\n            }\n        }\n\n        return C;\n    }\n\n    public static void main(String[] args) {\n\n        MyMatrix matrix = new MyMatrix();\n        Double[][] result = multiplicar(matrix.A, matrix.B);\n\n        for (int i = 0; i < 2; i++) {\n            for (int j = 0; j < 2; j++)\n                System.out.print(result[i][j] + \" \");\n            System.out.println();\n        }\n    }\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Template Matrix-Matrix multiplication c++\r\n                \r\nI am trying to do Matrix-Matrix multiplication with template and I keep getting following error. ( I am trying to multiply non-square matrix)\n\nError 1   error C2593: 'operator *' is ambiguous    \n\nCan any one give me an advice on how to fix this?\n\n```\n//Matrix.h\n#pragma once\n#include <iostream>\n#include <vector>\nusing namespace std;\n\ntemplate<class T, int m, int n>\nclass Matrix;\n\ntemplate<class T, int m, int n, int l>\nMatrix<T, m, n> operator*(const Matrix<T, m, n>&, const Matrix<T, n, l>&);\n\ntemplate<class T, int m, int n>\nclass Matrix\n{\nvector<vector<T>> elements;\nint nrow;\nint ncol;\n\npublic:\n    Matrix();\n    ~Matrix();\n    void print();\n    template<int l>\n    friend Matrix<T, m, l> operator*<>(const Matrix<T, m, n>&, const Matrix<T, n, l>&);\n\n};\n\ntemplate<class T, int m, int n>\nMatrix<T, m, n>::Matrix() : nrow(m), ncol(n)\n{\n    for (int i = 0; i < nrow; i++){\n        vector<T> row(ncol, i);\n        elements.push_back(row);\n    }\n}\n\ntemplate<class T, int m, int n>\nMatrix<T, m, n>::~Matrix(){}\n\ntemplate<class T, int m, int n>\nvoid Matrix<T, m, n>::print()\n{\n    for (int i = 0; i < nrow; i++){\n        for (int j = 0; j < ncol; j++){\n            cout << elements[i][j] << \" \";\n        }\n    cout << endl;\n    }\n}\n\ntemplate<class T, int m, int n, int l> \nMatrix<T, m, l> operator*(const Matrix<T, m, n>& m1, const Matrix<T, n, l>& m2){\n    int nrow = m1.nrow;\n    int ncol = m2.ncol;\n    Matrix<T, m, l> m3;\n    for (int i = 0; i < nrow; ++i){\n        for (int j = 0; j < ncol; ++j){\n            m3.elements[i][j] = 0;\n            for (int k = 0; k < m1.ncol; k++){\n                T temp = m1.elements[i][k] * m2.elements[k][j];\n                m3.elements[i][j] = temp + m3.elements[i][j];\n            }\n        }\n    }\nreturn m3;\n}\n\n//main.cpp\n#include \"Matrix.h\"\nusing namespace std;\n\nint main()\n{\nMatrix<int, 3, 2> a;\nMatrix<int, 2, 1> b;\nMatrix<int, 3, 1> c;\nc = a*b;\n\nc.print();\n}\n```\n\n\nThe problem occurs in the matrix multiplication possibly due to the coding error in the template.\n    ", "Answer": "\r\nI had to change what Richard changed, but I also had to change the declaration of ```\noperator*```\n and the ```\nfriend```\n as follows:\n\n```\ntemplate<class T, int m, int n, int l>\nMatrix<T, m, l> operator*(const Matrix<T, m, n>&, const Matrix<T, n, l>&);\n          // ^ here\n```\n\n\nand:\n\n```\ntemplate<class _T, int _m, int _n, int l>\nfriend Matrix<_T, _m, l> operator*(const Matrix<_T, _m, _n>&, const Matrix<_T, _n, l>&);\n```\n\n\nI got the \"```\noperator*```\n is ambiguous\" error if I didn't change the first of these two, since the forward declaration doesn't match the instantiation further down. \n\nIt's currently outputting:\n\n```\n0\n1\n2\n```\n\n\nThat doesn't seem quite right, but I'm not awake enough to debug further.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "ilnumerics matrix multiplication operator\r\n                \r\nIlnumerics is great, and I really like it. However, the matrix multiplication operator * is set to ILMath.multiplyElem, the element wise multiplication.\nI wonder why not make it ILMath.multiply, the normal matrix multiplication which is consistent with matlab, and more natural to use.\nIn mathematics, the element wise multiplication is less often used.\nI think it will be much better to change the * behavior to normal matrix multiplication.\n    ", "Answer": "\r\nHere are just some very common examples, where your suggestion would give less convenience: \n\n```\nILArray<double> A = rand(100,200) * 10 - 5; \n\n// square of A\nA = A * A; \n\n// multidimensional arrays\nrand(10,20,5) * ...\n\n// vector expansion\nB = A * linspace(0.0, 9.0, 100); \n```\n\n\n\n  In mathematics, the element wise multiplication is less often used\n\n\nAre you positive about that? It heavily depends on the domain, I suppose. \n\nThe decision has been discussed. And your suggestion would be a major breaking change. But you can open a feature request and collect votes for it: \n\nhttp://ilnumerics.net/mantis \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication of matrix sequences\r\n                \r\nI searched for a way to do a sequential matrix multiplication \nsimilarly to the sum(A,dim) or prod(A,dim) operations do for the sum or the element-wise multiplication.\n\nfor example:\n\n```\nA = arrayfun(@(x) rand(5), 1:n, 'UniformOutput', false);\nP = A{1} * A{2} * ... * A{n};  % <-- search for an elegant way to do this\n```\n\n\nI would use it to multiply a large number of Transfer matrices.\n    ", "Answer": "\r\nUse a for loop for this. It is what an 'elegant' method would do eventually. \n\n```\nP = A{1};\nfor i=2:length(A), P = P * A{i}, end\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication value assigning using dlib::matrix\r\n                \r\nThis works (matrix addition)\n```\ndlib::matrix<double, 2, 2> a;\ndlib::matrix<double, 2, 2> b;\ndlib::matrix<double> rez;\na = 1.0, 1.0, 1.0, 1.0;\nb = 3.0, 3.0, 3.0, 3.0;\nrez = a+b;\n```\n\nBut this doesn't (assigning matrix multiplication result to previously defined matrix)\n```\ndlib::matrix<double, 2, 2> a;\ndlib::matrix<double, 2, 2> b;\ndlib::matrix<double> rez;\na = 1.0, 1.0, 1.0, 1.0;\nb = 3.0, 3.0, 3.0, 3.0;\nrez = a*b;\n```\n\nMatrix multiplication result can be assigned, but only if I assign the result to new dlib::matrix.\n```\ndlib::matrix<double> rez = a*b;\n```\n\nHow can I make dlib::matrix multiplication work, so that I can assign the result to previously defined dlib::matrix?\nUsing (MinGW.org GCC Build-2) 9.2.0; Win10 and Visual Studio Code\nActual error is slightly longer, here is the summary:\n```\nIn file included from ...\\dlib-master\\dlib\\matrix\\matrix.h:17, from kalman_filtr.cpp:3:\n...\\dlib-master\\dlib\\matrix\\matrix_op.h: In instantiation of \n'struct dlib::matrix_traits<dlib::matrix_op<dlib::op_pointer_to_col_vect<double> > >':\n...\\dlib-master\\dlib\\matrix\\matrix_exp.h:130:51:   required from ...\n\n... required from here\n...\\dlib-master\\dlib\\matrix\\matrix_op.h:20:35: error: invalid use of incomplete type \n'struct dlib::op_pointer_to_col_vect<double>' typedef typename OP::type type;\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Chain Matrix Multiplication\r\n                \r\nIm trying to learn chain matrix multiplication. \n\nSuppose A is a 10 × 30 matrix, B is a 30 × 5 matrix, and C is a 5 × 60 matrix. Then,\n\nHow do we get  the following number of operations? (Is it number of rows into columns ???) \n\n```\n(AB)C = (10×30×5) + (10×5×60) = 1500 + 3000 = 4500 operations\nA(BC) = (30×5×60) + (10×30×60) = 9000 + 18000 = 27000 operations.\n```\n\n\nhttp://www.geeksforgeeks.org/dynamic-programming-set-8-matrix-chain-multiplication/\n    ", "Answer": "\r\nThe number of operations is the number of multiplications required to calculate the result. ```\nA * B```\n will result in a 10 x 5 matrix. Each entry in this matrix is the dotproduct of the respective row of ```\nA```\n with the column of ```\nB```\n with the same index. Thus: ```\nA * B```\n requires calculation of 10 x 5 cells, where each cell is the sum of 30 multiplication, so 10 x 5 x 30. Though this is a rather strange representation.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "dgemm or dgemv for Matrix Multiplication?\r\n                \r\nI know ```\ndgemv```\n is for matrix-vector, but which is more efficient? Using ```\ndgemm```\n directly for matrix multiplication or using ```\ndgemv```\n to do the matrix multiplication by multiplying the Matrix A with each individual column of matrix B using ```\ndgemv```\n?\n    ", "Answer": "\r\nIf you make repeated calls to DGEMV, you will not benefit from cache tiling and re-use, which are the biggest advantages good DGEMM implementations have.  DGEMM is vastly more efficient than multiple calls to DGEMV.  \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Abstract matrix multiplication with variables\r\n                \r\nI know about the ability of python to do matrix multiplications.\nUnfortunately I don't know how to do this abstractly? So not with \ndefinite numbers but with variables.\n\nExample:\n\n```\nM = ( 1   0 ) * ( 1   d )\n    ( a   c )   ( 0   1 )\n```\n\n\nIs there some way to define a,c and d, so that the matrix multiplication\ngives me \n\n```\n( 1   d       )\n( a   a*d + c )\n```\n\n\n?\n    ", "Answer": "\r\nUsing sympy you can do this:\n\n```\n>>> from sympy import *\n>>> var('a c d A B')\n(a, c, d, A, B)\n>>> A = Matrix([[1, 0], [a, c]])\n>>> A\nMatrix([\n[1, 0],\n[a, c]])\n>>> B = Matrix([[1, d], [0, 1]])\n>>> B\nMatrix([\n[1, d],\n[0, 1]])\n>>> M = A.multiply(B)\n>>> M\nMatrix([\n[1,       d],\n[a, a*d + c]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "What are the different types of algorithms for Matrix-Matrix multiplication/ Matrix-Vector multiplication [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is opinion-based. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it can be answered with facts and citations by editing this post.\r\n                \r\n                    \r\n                        Closed last year.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nWhat are the different types of algorithms for matrix-matrix multiplication and matrix-vector mutliplication.\n\nCannon's algorithm is one such algorithm for matrix-matrix multiplication. Is there any other algorithms.. \n\nWhich algorithm do you think is better???\n    ", "Answer": "\r\nThere is also Fox's algorithm like Cannon's.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication in hadoop\r\n                \r\nI try to build a code for page rank algorithm, and in that the main complexity is to solve matrix multiplication efficiently, but I didn't understand how this task be perform, I read some papers on that, but that is beyond of my range. I didn't understand the concept that he apply.\nSo, can you give me a concept behind mapper and reducer function for matrix multiplication. Thanks in advance.\n\nI read this link\n    ", "Answer": "\r\nThe idea is that you can break matrix multiplication into subproblems with something like the Strassen Algorithm and then send those subproblems to a bunch of different computers.  Once those subproblems are finished the summing together of the different subproblems into the matrix itsself can also be handled with.  The key to using Mapreduce is that all of the subproblems can basically be computed in parallel, which is... what Mapreduce is for.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Raspberry pi matrix multiplication [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is seeking recommendations for books, tools, software libraries, and more. It does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     We don’t allow questions seeking recommendations for books, tools, software libraries, and more. You can edit the question so it can be answered with facts and citations.\r\n                \r\n                    \r\n                        Closed 7 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nWhat matrix multiplication library would you recommend for Raspberry Pi 2?\n\nI think about BLAS or NumPy, What do you think?\n\nI'm wondering if there is an external hardware module for matrix multiplication available.\n\nThank you!\n    ", "Answer": "\r\nMathematica is part of the standard Raspbian distribution. It should be able to multiply matrices.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in tibble\r\n                \r\nI have a specific question about how to do matrix multiplication in a tibble.\nThe sample codes are:\nsuppose I havea tibble ```\nW```\n with dimension: ```\n100-by-10```\n:\n```\nW <- as_tibble( x=matrix( rnorm(1000,0,2) ,nrow=100,ncol=10,dimnames = list(NULL,c(\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\" ) ))) \n```\n\nand a known matrix ```\nR```\n with ```\ndim(R) = 5 ,11```\n.\nI want to extract a ```\n100-by-5```\n matrix from ```\nW```\n and pre-multiply\n```\nR <- matrix(runif(55, 1,20), nrow = 5, ncol=11)\n```\n\nand\n```\nW_use <- as.matrix(W %>% select(C2,C4,C6,C8,C10))\n```\n\nTheir product is\n```\nWR <- W_use %*% R\n```\n\nSince ```\ndim(WR)=(100,11)```\n, I can put it in the original tibble ```\nW```\n by\n```\nW_total <- W %>% add_column(WR)\n```\n\nMy concern is that though I can achieve this by a tedious process, it's proved to be slow, particularly the matrix multiplication.\nCan we use some smart ways to circumvent the matrix construction and multiplication and get the same tibble ```\nW_total```\n? Thanks.\n    ", "Answer": "\r\nIf we need to do this in a single chain\n```\nlibrary(dplyr)\nlibrary(magrittr)\nW1 <- W %>% \n      select(C2, C4, C6, C8, C10) %>%\n      as.matrix %>%\n      multiply_by_matrix(R) %>%\n      as_tibble %>%\n      bind_cols(W, .)\n```\n\n\nOr use ```\ncrossprod```\n\n```\nW %>% \n   select(C2, C4, C6, C8, C10) %>% \n   t %>% \n   crossprod(R) %>% \n   add_column(.)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matlab matrix multiplication\r\n                \r\nI have a question to do the following however i am having difficulties, i am unsure as were to start any help will be appreciated.\n\nWrite a program which takes two matrices from the user and performs matrix \nmultiplication. Do this using nested loops and scalar arithmetic only. \n\nYou MUST NOT \nuse MATLAB's in­built matrix multiplication functionality. You must also throw an \nappropriate error message if the user enters two matrices which cannot be multiplied\n    ", "Answer": "\r\nSay you have to matrices ```\nA```\n that is a ```\nnxp```\n and another matrix ```\nB```\n that is ```\npxm```\n, to perform matrix multiplication using only nested loops and scalar arithmetic you can use the following code:\n\n```\n[n,m] = size(A);\n[p,q] = size(B);\nC = zeros(n,p);\n\nif p~=m\n    error('Inner Matrix Dimensions Must Agree.')\nend\n\nfor k = 1:n\n    for j = 1:q\n        temp=0;\n        for i = 1:p\n            temp = temp+(A(k,i)*B(i,j));\n        end\n        C(k,j) = temp;\n    end\nend\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Result of matrix-multiplication is 'nan'\r\n                \r\nHere I have a two matrix-multiplications in my code. The first one works fine but the second one gives me 'nan' outputs.\n\nSigmoide:\n\n```\ndouble sigmoide(double value) {\n    return 1.0 / (1.0 + exp(-value));\n}\n```\n\n\nInitialize:\n\n```\ndouble LO = -0.5;\ndouble HI = 0.5;\n\ndouble input[50][2];                          \ndouble hiddenWeights[2][10];                   \ndouble outputWeights[11][1];                  \ndouble hiddenResults[50][11];                  \ndouble outputResults[50][1];                                     \n\nfor (int i = 0; i < 50; i++) {\n    input[i][0] = 1.0f;                       /// Bias\n    input[i][1] = (7.0f/50.0f) * (double)i;   /// Samples\n}\n\nfor (int i = 0; i < 50; i++) {\n    outputSetpoint[i][0] = sin((7.0f/50.0f) * (double)i);\n}\n```\n\n\nRandom values between -0.5 and 0.5:\n\n```\nfor (int i = 0; i < 2; i++) {\n    for (int j = 0; j < 10; j++) {\n        hiddenWeights[i][j] = LO + static_cast <float> (rand()) /( static_cast <float> (RAND_MAX/(HI-LO)));   \n    }\n}\n\nfor (int i = 0; i < 11; i++) {\n    for (int j = 0; j < 1; j++) {\n        outputWeights[i][j] = LO + static_cast <float> (rand()) /( static_cast <float> (RAND_MAX/(HI-LO))); \n    }\n}\n```\n\n\nMatrix-multiplication:\n\n```\nfor (int s = 0; s < 50; s++) {\n    for (int j = 0; j < 10; j++) {\n        for (int i = 0; i < 2; i++) {\n            // First matrix-multiplication\n            hiddenResults[s][j] += nexttowardf(input[s][i] * hiddenWeights[i][j], 0.0f);            \n        }\n        hiddenResults[s][10] = 1.0f;                                               \n        hiddenResults[s][j] = sigmoide(hiddenResults[s][j]);                      \n    }\n\n    for (int j = 0; j < 1; j++) {\n        for (int i = 0; i < 11; i++) {\n            // Second matrix-multiplication\n            outputResults[s][j] += hiddenResults[s][i] * outputWeights[i][j];   \n        }                                                                           \n        outputResults[s][j] = sigmoide(outputResults[s][j]);                    \n        error = outputSetpoint[s][j] - outputResults[s][j];\n    }\n\n    std::cout << outputResults[s][0] << std::endl;\n}\n```\n\n\nOutput:  \n\n```\nnan\n1\n0.287491\n0.432262\n0.293168\n0.336324\n0.283587\n0.282668\n1\n0.333261\nnan\n0.279217\nnan\n0.239026\n0\n0.338551\n0.274522\n0.209411\n0.24247\n0.273364\n0.179109\n0.199499\n0.271506\n1\nnan\nnan\nnan\nnan\n```\n\n    ", "Answer": "\r\nYou forgot to initialise ```\nhiddenResults```\n and ```\noutputResults```\n\n\nDo it:\n\n```\ndouble hiddenResults[50][11] = {0};\ndouble outputResults[50][1] = {0};\n```\n\n\nInitialise the other variables while you're at it.\nIt's a good habit to get into.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "F# Matrix Multiplication\r\n                \r\nI'm trying to multiply two matrices.\n\nI'm using transpose taken from this post: Help me to explain the F# Matrix transpose function\n\n```\nlet rec transpose = function\n| (_::_)::_ as M -> List.map List.head M :: transpose (List.map List.tail M)\n| _ -> []\n```\n\n\nI'm also using innerMult which multiplies every element of a two lists and then adds them.\n\n```\nlet rec innerMult u v =\nmatch u, v with \n| [x], [y] -> x*y     | u'::u, v'::v -> u'*v' + inner u v \n```\n\n\nSo using these two functions I want will try to multiply rows by columns. Of course I assume both matrices meet the conditions for multiplication to happen. That is, rows must equal columns. \n\nMatrix multiplication code:\n\n```\nlet multiply (xs, ys) = \nlet tl = transpose ys in \n    let rec mMult xs = \n    match xs, tl with\n    | x::xs, t::tl -> inner x t\n  mMult xs;;\n```\n\n\n\n  Test: multiply ([[1;2;3];[4;5;6]], [[0;1];[3;2];[1;2]]);; Output: >\n  val it : int = 9\n\n\nAt the moment it is missing recursion or List.map so that it actually does the matrix multiplication. I just don't see how to solve this. \n    ", "Answer": "\r\nIt seems like this ought to work:\n\n```\nlet multiply xs ys =\n    [for row in xs ->\n         [for col in transpose ys -> inner row col]]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Multidimensional Matrix Multiplication\r\n                \r\nI'm wondering if it is possible to perform a multidimensional matrix multiplication without resorting to a for-loop. Given the N-by-P matrix A and the N-by-M-by-P matrix B, I want to compute the M-dimensional vector y, defined element-wise as\n\n```\ny(j) = sum_(i = 1,...,N) sum_(k = 1,...,P) A(i,k)*B(i,j,k)\n```\n\n    ", "Answer": "\r\nYou can linearize ```\nA```\n into a row vector, then ```\nreshape```\n and ```\npermute```\n the array ```\nB```\n as a matrix, so that the desired result is just matrix multiplication:\n\n```\nM = 5;\nN = 6;\nP = 8;\nA = rand(N,P);\nB = rand(N,M,P);\nresult = A(:).'*reshape(permute(B, [1 3 2]), [], M);\n```\n\n\n\n\nOr ```\nreshape```\n matrix ```\nA```\n so that its dimensions are aligned with those of ```\nB```\n, use ```\nbsxfun```\n to multiply with singleton-expansion, and sum over the two desired dimensions:\n\n```\nresult = sum(sum(bsxfun(@times, reshape(A, N, 1, P), B), 1), 3);\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication C language\r\n                \r\nSo, I have problem with matrix multiplication. I have to store the values of a matrix in a file and after that multiply them. The problem occurs when I try to multiply 900x900 matrix: Segmentation fault (core dumped), but 800x800 works perfectly). there is part of my code: create file for storing:\n\n```\nFILE *A, *B;\nint num = atoi(argv[1]);\nfloat a[num][num];\nfloat b[num][num];\nA = fopen(argv[2],\"r\");\nB = fopen(argv[3],\"r\");\nfor (int i = 0; i < num; ++i)\n{\n    for (int j = 0; j < num; ++j)\n    {\n        fscanf(A,\"%f\",&a[i][j]);\n    }\n}\nfor (int i = 0; i < num; ++i)\n{\n    for (int j = 0; j < num; ++j)\n    {\n        fscanf(B,\"%f\",&b[i][j]);\n    }\n}\n```\n\n\nSo i didn't write function for matrix multiplication because it works\n    ", "Answer": "\r\nYour two ```\nfloat```\n variable-length arrays occupy 2*9002*4 bytes  - that is a little over 6Mb.  VLAs are typically created on the stack, the size of which will vary between systems and processes, but on a modern desktop system is typically perhaps 2 to 8 Mb.\n\nCreating an array that large on the stack is somewhat unreasonable, and failure unsurprising.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix-Vector and Matrix-Matrix multiplication using SSE\r\n                \r\nI need to write matrix-vector and matrix-matrix multiplication functions but I cannot wrap my head around SSE commands. \n\nThe dimensions of matrices and vectors are always multiples of 4.\n\nI managed to write the vector-vector multiplication function that looks like this:\n\n```\nvoid vector_multiplication_SSE(float* m, float* n, float* result, unsigned const int size)\n{\n    int i;\n\n    __declspec(align(16))__m128 *p_m = (__m128*)m;\n    __declspec(align(16))__m128 *p_n = (__m128*)n;\n    __declspec(align(16))__m128 *p_result = (__m128*)result;\n\n    for (i = 0; i < size / 4; ++i)\n        p_result[i] = _mm_mul_ps(p_m[i], p_n[i]);\n\n    // print the result\n    for (int i = 0; i < size; ++i)\n    {\n        if (i % 4 == 0) cout << endl;\n        cout << result[i] << '\\t';\n    }\n}\n```\n\n\nand now I'm trying to implement matrix-vector multiplication.\n\nHere's what I have so far:\n\n```\nvoid multiply_matrix_by_vector_SSE(float* m, float* v, float* result, unsigned const int vector_dims)\n{\n    int i, j;\n\n    __declspec(align(16))__m128 *p_m = (__m128*)m;\n    __declspec(align(16))__m128 *p_v = (__m128*)v;\n    __declspec(align(16))__m128 *p_result = (__m128*)result;\n\n    for (i = 0; i < vector_dims; i += 4)\n    {\n        __m128 tmp = _mm_load_ps(&result[i]);\n        __m128 p_m_tmp = _mm_load_ps(&m[i]);\n\n        tmp = _mm_add_ps(tmp, _mm_mul_ps(tmp, p_m_tmp));\n        _mm_store_ps(&result[i], tmp);\n\n        // another for loop here? \n    }\n\n    // print the result\n    for (int i = 0; i < vector_dims; ++i)\n    {\n        if (i % 4 == 0) cout << endl;\n        cout << result[i] << '\\t';\n    }\n}\n```\n\n\nThis function looks completely wrong. I mean not only it doesn't work correctly, but it also seems that I'm moving in the wrong direction.\n\n\n\nCould anyone help me with implementing vector-matrix and matrix-matrix multiplication? I'd really appreciate some piece of example code and a very detailed explanation\n\nUpdate\n\nHere's my attempt number 2:\n\nit fails with ```\nAccess reading violation```\n exception but still feels closer\n\n```\nvoid multiply_matrix_by_vector_SSE(float* m, float* v, float* result, unsigned const int vector_dims)\n{\n    int i, j;\n\n    __declspec(align(16))__m128 *p_m = (__m128*)m;\n    __declspec(align(16))__m128 *p_v = (__m128*)v;\n    __declspec(align(16))__m128 *p_result = (__m128*)result;\n\n    for (i = 0; i < vector_dims; ++i)\n    {\n        p_result[i] = _mm_mul_ps(_mm_load_ps(&m[i]), _mm_load_ps1(&v[i]));\n    }\n\n    // print the result\n    for (int i = 0; i < vector_dims; ++i)\n    {\n        if (i % 4 == 0) cout << endl;\n        cout << result[i] << '\\t';\n    }\n}\n```\n\n\nUpdate 2\n\n```\nvoid multiply_matrix_by_vector_SSE(float* m, float* v, float* result, unsigned const int vector_dims)\n{\n    int i, j;\n    __declspec(align(16))__m128 *p_m = (__m128*)m;\n    __declspec(align(16))__m128 *p_v = (__m128*)v;\n    __declspec(align(16))__m128 *p_result = (__m128*)result;\n\n    for (i = 0; i < vector_dims; ++i)\n    {\n        for (j = 0; j < vector_dims * vector_dims / 4; ++j)\n        {\n            p_result[i] = _mm_mul_ps(p_v[i], p_m[j]);\n        }\n    }\n\n    for (int i = 0; i < vector_dims; ++i)\n    {\n        if (i % 4 == 0) cout << endl;\n        cout << result[i] << '\\t';\n    }\n    cout << endl;\n}\n```\n\n    ", "Answer": "\r\nWithout any tricks or anything, a matrix-vector multiplication is just a bunch of dot products between the vector and a row of the matrix. Your code doesn't really have that structure. Writing it actually as dot products (not tested):\n\n```\nfor (int row = 0; row < nrows; ++row) {\n    __m128 acc = _mm_setzero_ps();\n    // I'm just going to assume the number of columns is a multiple of 4\n    for (int col = 0; col < ncols; col += 4) {\n        __m128 vec = _mm_load_ps(&v[col]);\n        // don't forget it's a matrix, do 2d addressing\n        __m128 mat = _mm_load_ps(&m[col + ncols * row]);\n        acc = _mm_add_ps(acc, _mm_mul_ps(mat, vec));\n    }\n    // now we have 4 floats in acc and they have to be summed\n    // can use two horizontal adds for this, they kind of suck but this\n    // isn't the inner loop anyway.\n    acc = _mm_hadd_ps(acc, acc);\n    acc = _mm_hadd_ps(acc, acc);\n    // store result, which is a single float\n    _mm_store_ss(&result[row], acc);\n}\n```\n\n\nThere are some obvious tricks, such as processing several rows at once, reusing the load from the vector, and creating several independent dependency chains so you can make better use of the throughput (see below). Also a really simple trick is using FMA for the mul/add combo, but support is not that widespread yet (it wasn't in 2015, but it is fairly widespread now in 2020).\n\nYou can build matrix-matrix multiplication from this (if you change the place the result goes), but that is not optimal (see further below).\n\n\n\nTaking four rows at once (not tested):\n\n```\nfor (int row = 0; row < nrows; row += 4) {\n    __m128 acc0 = _mm_setzero_ps();\n    __m128 acc1 = _mm_setzero_ps();\n    __m128 acc2 = _mm_setzero_ps();\n    __m128 acc3 = _mm_setzero_ps();\n    for (int col = 0; col < ncols; col += 4) {\n        __m128 vec = _mm_load_ps(&v[col]);\n        __m128 mat0 = _mm_load_ps(&m[col + ncols * row]);\n        __m128 mat1 = _mm_load_ps(&m[col + ncols * (row + 1)]);\n        __m128 mat2 = _mm_load_ps(&m[col + ncols * (row + 2)]);\n        __m128 mat3 = _mm_load_ps(&m[col + ncols * (row + 3)]);\n        acc0 = _mm_add_ps(acc0, _mm_mul_ps(mat0, vec));\n        acc1 = _mm_add_ps(acc1, _mm_mul_ps(mat1, vec));\n        acc2 = _mm_add_ps(acc2, _mm_mul_ps(mat2, vec));\n        acc3 = _mm_add_ps(acc3, _mm_mul_ps(mat3, vec));\n    }\n    acc0 = _mm_hadd_ps(acc0, acc1);\n    acc2 = _mm_hadd_ps(acc2, acc3);\n    acc0 = _mm_hadd_ps(acc0, acc2);\n    _mm_store_ps(&result[row], acc0);\n}\n```\n\n\nThere are only 5 loads per 4 FMAs now, versus 2 loads per 1 FMA in the version that wasn't row-unrolled. Also there are 4 independent FMAs, or add/mul pairs without FMA contraction, either way it increases the potential for pipelined/simultaneous execution. Actually you might want to unroll even more, for example Skylake can start 2 independent FMAs per cycle and they take 4 cycles to complete, so to completely occupy both FMA units you need 8 independent FMAs. As a bonus, those 3 horizontal adds in the end work out relatively nicely, for horizontal summation.\n\n\n\nThe different data layout initially seems like a disadvantage, it's no longer possible to simply do vector-loads from both the matrix and the vector and multiply them together (that would multiply a tiny row vector of the first matrix by a tiny row vector of the second matrix again, which is wrong). But full matrix-matrix multiplication can make use of the fact that it's essentially multiplying a matrix by lots of independent vectors, it's full of independent work to be done. The horizontal sums can be avoided easily too. So actually it's even more convenient than matrix-vector multiplication.\n\nThe key is taking a little column vector from matrix A and a little row vector from matrix B and multiplying them out into a small matrix. That may sound reversed compared to what you're used to, but doing it this way works out better with SIMD because the computations stay independent and horizontal-operation-free the whole time.\n\nFor example (not tested, assumes the matrixes have dimensions divisible by the unroll factors, requires x64 otherwise it runs out of registers)\n\n```\nfor (size_t i = 0; i < mat1rows; i += 4) {\n    for (size_t j = 0; j < mat2cols; j += 8) {\n        float* mat1ptr = &mat1[i * mat1cols];\n        __m256 sumA_1, sumB_1, sumA_2, sumB_2, sumA_3, sumB_3, sumA_4, sumB_4;\n        sumA_1 = _mm_setzero_ps();\n        sumB_1 = _mm_setzero_ps();\n        sumA_2 = _mm_setzero_ps();\n        sumB_2 = _mm_setzero_ps();\n        sumA_3 = _mm_setzero_ps();\n        sumB_3 = _mm_setzero_ps();\n        sumA_4 = _mm_setzero_ps();\n        sumB_4 = _mm_setzero_ps();\n\n        for (size_t k = 0; k < mat2rows; ++k) {\n            auto bc_mat1_1 = _mm_set1_ps(mat1ptr[0]);\n            auto vecA_mat2 = _mm_load_ps(mat2 + m2idx);\n            auto vecB_mat2 = _mm_load_ps(mat2 + m2idx + 4);\n            sumA_1 = _mm_add_ps(_mm_mul_ps(bc_mat1_1, vecA_mat2), sumA_1);\n            sumB_1 = _mm_add_ps(_mm_mul_ps(bc_mat1_1, vecB_mat2), sumB_1);\n            auto bc_mat1_2 = _mm_set1_ps(mat1ptr[N]);\n            sumA_2 = _mm_add_ps(_mm_mul_ps(bc_mat1_2, vecA_mat2), sumA_2);\n            sumB_2 = _mm_add_ps(_mm_mul_ps(bc_mat1_2, vecB_mat2), sumB_2);\n            auto bc_mat1_3 = _mm_set1_ps(mat1ptr[N * 2]);\n            sumA_3 = _mm_add_ps(_mm_mul_ps(bc_mat1_3, vecA_mat2), sumA_3);\n            sumB_3 = _mm_add_ps(_mm_mul_ps(bc_mat1_3, vecB_mat2), sumB_3);\n            auto bc_mat1_4 = _mm_set1_ps(mat1ptr[N * 3]);\n            sumA_4 = _mm_add_ps(_mm_mul_ps(bc_mat1_4, vecA_mat2), sumA_4);\n            sumB_4 = _mm_add_ps(_mm_mul_ps(bc_mat1_4, vecB_mat2), sumB_4);\n            m2idx += 8;\n            mat1ptr++;\n        }\n        _mm_store_ps(&result[i * mat2cols + j], sumA_1);\n        _mm_store_ps(&result[i * mat2cols + j + 4], sumB_1);\n        _mm_store_ps(&result[(i + 1) * mat2cols + j], sumA_2);\n        _mm_store_ps(&result[(i + 1) * mat2cols + j + 4], sumB_2);\n        _mm_store_ps(&result[(i + 2) * mat2cols + j], sumA_3);\n        _mm_store_ps(&result[(i + 2) * mat2cols + j + 4], sumB_3);\n        _mm_store_ps(&result[(i + 3) * mat2cols + j], sumA_4);\n        _mm_store_ps(&result[(i + 3) * mat2cols + j + 4], sumB_4);\n    }\n}\n```\n\n\nThe point of that code is that it's easy to arrange to computation to be very SIMD-friendly, with a lots of independent arithmetic to saturate the floating point units with, and at the same time use relatively few loads (which otherwise could become a bottleneck, even putting aside that they might miss L1 cache, just by there being too many of them).\n\nYou can even use this code, but it's not competitive with Intel MKL. Especially for medium or big matrixes, where tiling is extremely important. It's easy to upgrade this to AVX. It's not suitable for tiny matrixes at all, for example to multiply two 4x4 matrixes see Efficient 4x4 matrix multiplication.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication Error\r\n                \r\nI'm trying to use * to multiply 2 matrix but I got this error\n\nFor example\n\n```\na = [ 0 0 1 1 0\n      0 1 1 0 0 ]\n\nb = [ 1 1.5\n      0 1 ]\n```\n\n\n```\nb*a```\n gives me the result, but ```\na*b```\n gives me error \"Requested matrix multiplication requires arguments to be conformant.\"\n\nWhy is that?\n    ", "Answer": "\r\nBecause matrix multiplication is only defined if the number of columns in the matrix on the left of the multiplication is the same as the number of rows in the matrix on the right.  That is, for the expression\n\n```\nA * B\n```\n\n\nto be valid (either mathematically or Matlabilly) ```\nA```\n must be of dimensions ```\nm*n```\n and ```\nB```\n must be of dimensions ```\nn*k```\n, producing a result of dimensions ```\nm*k```\n.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Cuda matrix multiplication\r\n                \r\nI'm trying to write a matrix multiplication code in cuda, which is pretty similar to Nvidia's cuda programming guide, but it is not working. It is supposed to do C=alpha*A*B+beta*C , but for every A,B C remains unchanged.\n\n```\n__global__ void MatMulKernel(int m,int n,int k,double *A,double *B,double *C,double alpha,double beta)\n{\n    double Ctemp = 0.0;\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    int ind;\n    for (ind = 0; ind < k; ++ind)\n    {\n       Ctemp += A[row+ind*m]*B[ind+col*k];\n    }\n\n   C[row+m*col] = alpha*Ctemp+beta*C[row+m*col];\n//C[row+m*col] = Ctemp;\n   __syncthreads();\n}\n\nextern \"C\" void\nlocal_mm_cuda (const int m, const int n, const int k, const double alpha,\n  const double *A, const int lda, const double *B, const int ldb,\n  const double beta, double *C, const int ldc)\n{\n\n int row, col;\n\n  /* Verify the sizes of lda, ldb, and ldc */\n  assert (lda >= m);\n  assert (ldb >= k);\n  assert (ldc >= m);\n\n  // allocating memory for device array\n  double *dA,*dB,*dC;\n  size_t sizeA = sizeof(double)*m*k;\n  size_t sizeB = sizeof(double)*n*k;\n  size_t sizeC = sizeof(double)*m*n;\n\n  cudaMalloc((void**)&dA,sizeA);\n  cudaMalloc((void**)&dB,sizeB);\n  cudaMalloc((void**)&dC,sizeC);\n\n  cudaMemcpy(dA, A, sizeA, cudaMemcpyHostToDevice);\n  cudaMemcpy(dB, B, sizeB, cudaMemcpyHostToDevice);\n  cudaMemcpy(dC, C, sizeC, cudaMemcpyHostToDevice);\n\n  // calling matrix multiplication kernal\n  dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n  dim3 dimGrid( n/dimBlock.x, m/dimBlock.y);\n  MatMulKernel<<<dimGrid, dimBlock>>>(m,n,k,dA,dB,dC,alpha,beta);\n  cudaThreadSynchronize();\n\n  // saving C calculated back in C\n  cudaMemcpy(dC,C, sizeC,cudaMemcpyDeviceToHost);\n  cudaFree(dA);\n  cudaFree(dB);\n  cudaFree(dC);\n}\n```\n\n    ", "Answer": "\r\nTry to modify \n\n```\n\"dim3 dimGrid( n/dimBlock.x, m/dimBlock.y);\"\n```\n\n\nto\n\n```\n\"dim3 dimGrid( (n+dimBlock.x-1)/dimBlock.x, (m+dimBlock.y-1)/dimBlock.y); \"\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Cuda matrix multiplication\r\n                \r\nI'm trying to write a matrix multiplication code in cuda, which is pretty similar to Nvidia's cuda programming guide, but it is not working. It is supposed to do C=alpha*A*B+beta*C , but for every A,B C remains unchanged.\n\n```\n__global__ void MatMulKernel(int m,int n,int k,double *A,double *B,double *C,double alpha,double beta)\n{\n    double Ctemp = 0.0;\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    int ind;\n    for (ind = 0; ind < k; ++ind)\n    {\n       Ctemp += A[row+ind*m]*B[ind+col*k];\n    }\n\n   C[row+m*col] = alpha*Ctemp+beta*C[row+m*col];\n//C[row+m*col] = Ctemp;\n   __syncthreads();\n}\n\nextern \"C\" void\nlocal_mm_cuda (const int m, const int n, const int k, const double alpha,\n  const double *A, const int lda, const double *B, const int ldb,\n  const double beta, double *C, const int ldc)\n{\n\n int row, col;\n\n  /* Verify the sizes of lda, ldb, and ldc */\n  assert (lda >= m);\n  assert (ldb >= k);\n  assert (ldc >= m);\n\n  // allocating memory for device array\n  double *dA,*dB,*dC;\n  size_t sizeA = sizeof(double)*m*k;\n  size_t sizeB = sizeof(double)*n*k;\n  size_t sizeC = sizeof(double)*m*n;\n\n  cudaMalloc((void**)&dA,sizeA);\n  cudaMalloc((void**)&dB,sizeB);\n  cudaMalloc((void**)&dC,sizeC);\n\n  cudaMemcpy(dA, A, sizeA, cudaMemcpyHostToDevice);\n  cudaMemcpy(dB, B, sizeB, cudaMemcpyHostToDevice);\n  cudaMemcpy(dC, C, sizeC, cudaMemcpyHostToDevice);\n\n  // calling matrix multiplication kernal\n  dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n  dim3 dimGrid( n/dimBlock.x, m/dimBlock.y);\n  MatMulKernel<<<dimGrid, dimBlock>>>(m,n,k,dA,dB,dC,alpha,beta);\n  cudaThreadSynchronize();\n\n  // saving C calculated back in C\n  cudaMemcpy(dC,C, sizeC,cudaMemcpyDeviceToHost);\n  cudaFree(dA);\n  cudaFree(dB);\n  cudaFree(dC);\n}\n```\n\n    ", "Answer": "\r\nTry to modify \n\n```\n\"dim3 dimGrid( n/dimBlock.x, m/dimBlock.y);\"\n```\n\n\nto\n\n```\n\"dim3 dimGrid( (n+dimBlock.x-1)/dimBlock.x, (m+dimBlock.y-1)/dimBlock.y); \"\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication dimensions confusing\r\n                \r\nI am following this tutorial https://pytorch.org/tutorials/beginner/nlp/deep_learning_tutorial.html#example-logistic-regression-bag-of-words-classifier\n\n```\nnn.Linear(vocab_size, num_labels)```\n\nmeans that the matrix shape is ```\nnum_labels x vocab_size```\n\n\nbow_vector dimensions is ```\n1 x vocab_size```\n and input expected for nn.linear is ```\nbatch_size x features```\n\n\nNow, we are multiplying ```\nnum_labels x vocab_size```\n matrix by ```\n1 x vocab_size```\n. Thus, the dimensions don't match for matrix multiplication. What am I missing here? :thinking:\n\nhttps://discuss.pytorch.org/t/matrix-multiplication-dimentions-confusing/79376?u=abhigenie92\n    ", "Answer": "\r\nYou mis-understanding in ```\nnn.Linear```\n. Let me point it out for you a bit.\n\n```\nnn.Linear(vocab_size, num_labels)```\n doesn't mean that the matrix shape is ```\nnum_labels x vacab_size```\n.\n\nThe original is ```\nnn.Linear(input_dim, output_dim, bias=True)```\n. Let say you have 3 points in 3D space and you want to projects those points to 2D space. So you just create a Linear layer that can helps you do that => ```\nnn.Linear(3, 2, bias=True)```\n.\n\nExamples:\n\n```\nlinear_function = nn.Linear(3, 2, bias=True) # you have just created a function\na_3D_point = torch.Tensor([[1, 1, 1]])\na_2D_point = linear_function(a_3D_point)\n```\n\n\nBasically, ```\nnn.Linear()```\n just help you created a function that can do the projection. \n\nSo you may wonder how ```\nnn.Linear```\n can help you do the projection. Well, it pretty easy in math when the projection is just ```\ny = Wx + b```\n or ```\ny = Wx```\n (in case the bias=False) where ```\nW```\n is weight and ```\nb```\n is bias and both of them will be created randomly by ```\nnn.Linear```\n. Check it out by:\n\n```\nprint(list(linear_function.parameters()))  # Unchecked since I use my iPad to write this answer\n```\n\n\n================\n\nMapping to your case, the BowClassifier as my understanding it just try to classify the sentence into the finite classes. One of the easiest way to do is using one hot vector which has the shape of ```\nn x vocab```\n.\n\n```\nn```\n denotes that you have ```\nn```\n sentence, but vocab in the second dimension now plays the role of features that represents each sentense.\n\nYou now you want to classify n sentences into ```\nnum_labels```\n class, just do the projection.\n\n```\ninput = ...  # shape: [n x vocab]\nclassify_fn = nn.Linear(vocab, num_labels)\noutput = classify_fn(input)\n\n# sigmoid or softmax to get the probability here\n...\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "The openmp matrix multiplication\r\n                \r\nI try to write a Openmp based matrix multiplication code. The multiplication of matrix mm and matrix mmt is diagonal matrix and equal to one. I try normal calculation and Openmp. The normal result is correct, however the Openmp result is wrong. I think it should be relative to the Openmp utilization.\n```\nprogram main\nimplicit none\ndouble precision,dimension(0:8,0:8)::MM,MMT,MTEMP\n\nMM=reshape((/ 1 ,   1   ,   1   ,   1   ,   1   ,   1   ,   1   ,   1   ,   1   ,   &\n-4  ,   -1  ,   -1  ,   -1  ,   -1  ,   2   ,   2   ,   2   ,   2   ,   &\n4   ,   -2  ,   -2  ,   -2  ,   -2  ,   1   ,   1   ,   1   ,   1   ,   &\n0   ,   1   ,   0   ,   -1  ,   0   ,   1   ,   -1  ,   -1  ,   1   ,   &\n0   ,   -2  ,   0   ,   2   ,   0   ,   1   ,   -1  ,   -1  ,   1   ,   &\n0   ,   0   ,   1   ,   0   ,   -1  ,   1   ,   1   ,   -1  ,   -1  ,   &\n0   ,   0   ,   -2  ,   0   ,   2   ,   1   ,   1   ,   -1  ,   -1  ,   &\n0   ,   1   ,   -1  ,   1   ,   -1  ,   0   ,   0   ,   0   ,   0   ,   &\n0   ,   0   ,   0   ,   0   ,   0   ,   1   ,   -1  ,   1   ,   -1  /),shape(MM))\n\n\n\nMMT=1.d0/36.d0 * reshape  ((/ 4 ,   -4  ,   4   ,   0   ,   0   ,   0   ,   0   ,   0   ,   0   ,   &\n                4   ,   -1  ,   -2  ,   6   ,   -6  ,   0   ,   0   ,   9   ,   0   ,   &\n                4   ,   -1  ,   -2  ,   0   ,   0   ,   6   ,   -6  ,   -9  ,   0   ,   &\n                4   ,   -1  ,   -2  ,   -6  ,   6   ,   0   ,   0   ,   9   ,   0   ,   &\n                4   ,   -1  ,   -2  ,   0   ,   0   ,   -6  ,   6   ,   -9  ,   0   ,   &\n                4   ,   2   ,   1   ,   6   ,   3   ,   6   ,   3   ,   0   ,   9   ,   &\n                4   ,   2   ,   1   ,   -6  ,   -3  ,   6   ,   3   ,   0   ,   -9  ,   &\n                4   ,   2   ,   1   ,   -6  ,   -3  ,   -6  ,   -3  ,   0   ,   9   ,   &\n                4   ,   2   ,   1   ,   6   ,   3   ,   -6  ,   -3  ,   0   ,   -9  /),shape(MMT))\n\n!$OMP PARALLEL\n          call multi(mm,mmt,mtemp)\n\n                PRINT*,MTEMP\n!$OMP END PARALLEL\n\n\nendprogram main\n\nsubroutine multi(m1,m2,m3)\ndouble precision,dimension(0:8,0:8)::m1,m2,m3\ndouble precision,dimension(0:80)::mm1,mm2\nDOUBLE PRECISION::TEMP\ninteger::i,j,k\n!$OMP DO\ndo j=0,8\n    do i=0,8\n        mm1(j*9+i)=m1(i,j)\n        mm2(i*9+j)=m2(i,j)\n    enddo\nenddo\n!$OMP ENDDO\n!$OMP DO PRIVATE(TEMP,I,J,K)\ndo j=0,8\n    do i=0,8\n        temp=0\n        do k=0,8\n            temp=temp+mm1(j*9+k)*mm2(i*9+k)\n        enddo\n        m3(i,j)=temp\n    enddo\nenddo\n!$OMP ENDDO\nreturn\n\n\nendsubroutine\n```\n\nI give the normal version below, and if you compute this, the result is diagnonal 1 matrix.\n```\nprogram main\nimplicit none\ndouble precision,dimension(0:8,0:8)::MM,MMT,MTEMP\n\nMM=reshape((/ 1 ,   1   ,   1   ,   1   ,   1   ,   1   ,   1   ,   1   ,   1   ,   &\n-4  ,   -1  ,   -1  ,   -1  ,   -1  ,   2   ,   2   ,   2   ,   2   ,   &\n4   ,   -2  ,   -2  ,   -2  ,   -2  ,   1   ,   1   ,   1   ,   1   ,   &\n0   ,   1   ,   0   ,   -1  ,   0   ,   1   ,   -1  ,   -1  ,   1   ,   &\n0   ,   -2  ,   0   ,   2   ,   0   ,   1   ,   -1  ,   -1  ,   1   ,   &\n0   ,   0   ,   1   ,   0   ,   -1  ,   1   ,   1   ,   -1  ,   -1  ,   &\n0   ,   0   ,   -2  ,   0   ,   2   ,   1   ,   1   ,   -1  ,   -1  ,   &\n0   ,   1   ,   -1  ,   1   ,   -1  ,   0   ,   0   ,   0   ,   0   ,   &\n0   ,   0   ,   0   ,   0   ,   0   ,   1   ,   -1  ,   1   ,   -1  /),shape(MM))\n\n\n\nMMT=1.d0/36.d0 * reshape  ((/ 4 ,   -4  ,   4   ,   0   ,   0   ,   0   ,   0   ,   0   ,   0   ,   &\n                4   ,   -1  ,   -2  ,   6   ,   -6  ,   0   ,   0   ,   9   ,   0   ,   &\n                4   ,   -1  ,   -2  ,   0   ,   0   ,   6   ,   -6  ,   -9  ,   0   ,   &\n                4   ,   -1  ,   -2  ,   -6  ,   6   ,   0   ,   0   ,   9   ,   0   ,   &\n                4   ,   -1  ,   -2  ,   0   ,   0   ,   -6  ,   6   ,   -9  ,   0   ,   &\n                4   ,   2   ,   1   ,   6   ,   3   ,   6   ,   3   ,   0   ,   9   ,   &\n                4   ,   2   ,   1   ,   -6  ,   -3  ,   6   ,   3   ,   0   ,   -9  ,   &\n                4   ,   2   ,   1   ,   -6  ,   -3  ,   -6  ,   -3  ,   0   ,   9   ,   &\n                4   ,   2   ,   1   ,   6   ,   3   ,   -6  ,   -3  ,   0   ,   -9  /),shape(MMT))\n\n\n                call multi(mm,mmt,mtemp)\n\n                PRINT*,MTEMP\n\n\n\nendprogram main\n\nsubroutine multi(m1,m2,m3)\ndouble precision,dimension(0:8,0:8)::m1,m2,m3\ndouble precision,dimension(0:80)::mm1,mm2\nDOUBLE PRECISION::TEMP\ninteger::i,j,k\n\ndo j=0,8\n    do i=0,8\n        mm1(j*9+i)=m1(i,j)\n        mm2(i*9+j)=m2(i,j)\n    enddo\nenddo\n\n\ndo j=0,8\n    do i=0,8\n        temp=0\n        do k=0,8\n            temp=temp+mm1(j*9+k)*mm2(i*9+k)\n        enddo\n        m3(i,j)=temp\n    enddo\nenddo\n\nreturn\n\n\n  endsubroutine\n```\n\n    ", "Answer": "\r\nTo solve your problem one solution is to place the parallel region inside the ```\nmulti```\n subroutine. This code gives the same result as the serial one:\n```\nsubroutine multi(m1,m2,m3)\ndouble precision,dimension(0:8,0:8)::m1,m2,m3\ndouble precision,dimension(0:80)::mm1,mm2\nDOUBLE PRECISION::TEMP\ninteger::i,j,k\n!$OMP PARALLEL\n    !$OMP DO\n    do j=0,8\n        do i=0,8\n            mm1(j*9+i)=m1(i,j)\n            mm2(i*9+j)=m2(i,j)\n        enddo\n    enddo\n    !$OMP ENDDO\n    !$OMP DO PRIVATE(TEMP,I,J,K)\n    do j=0,8\n        do i=0,8\n            temp=0\n            do k=0,8\n                temp=temp+mm1(j*9+k)*mm2(i*9+k)\n            enddo\n            m3(i,j)=temp\n        enddo\n    enddo\n    !$OMP ENDDO\n!$OMP END PARALLEL\nreturn\n```\n\nNote that the workload is very small, so it may not be faster than the serial code. Note also that if you do not need ```\nmm1```\n and ```\nmm2```\n arrays later then you do not have to calculate them:\n```\nsubroutine multi(m1,m2,m3)\ndouble precision,dimension(0:8,0:8)::m1,m2,m3\nDOUBLE PRECISION::TEMP\ninteger::i,j,k\n!$OMP PARALLEL\n    !$OMP DO PRIVATE(TEMP,I,J,K)\n    do j=0,8\n        do i=0,8\n            temp=0\n            do k=0,8\n                temp=temp+m1(k,j)*m2(i,k)\n            enddo\n            m3(i,j)=temp\n        enddo\n    enddo\n    !$OMP ENDDO\n!$OMP END PARALLEL\nreturn\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Why is my program slow when looping over exactly 8192 elements?\r\n                \r\nHere is the extract from the program in question. The matrix ```\nimg[][]```\n has the size SIZE×SIZE, and is initialized at:\n\n```\nimg[j][i] = 2 * j + i```\n\n\nThen, you make a matrix ```\nres[][]```\n, and each field in here is made to be the average of the 9 fields around it in the img matrix. The border is left at 0 for simplicity.\n\n```\nfor(i=1;i<SIZE-1;i++) \n    for(j=1;j<SIZE-1;j++) {\n        res[j][i]=0;\n        for(k=-1;k<2;k++) \n            for(l=-1;l<2;l++) \n                res[j][i] += img[j+l][i+k];\n        res[j][i] /= 9;\n}\n```\n\n\nThat's all there's to the program. For completeness' sake, here is what comes before. No code comes after. As you can see, it's just initialization.\n\n```\n#define SIZE 8192\nfloat img[SIZE][SIZE]; // input image\nfloat res[SIZE][SIZE]; //result of mean filter\nint i,j,k,l;\nfor(i=0;i<SIZE;i++) \n    for(j=0;j<SIZE;j++) \n        img[j][i] = (2*j+i)%8196;\n```\n\n\nBasically, this program is slow when SIZE is a multiple of 2048, e.g. the execution times:\n\n```\nSIZE = 8191: 3.44 secs\nSIZE = 8192: 7.20 secs\nSIZE = 8193: 3.18 secs\n```\n\n\nThe compiler is GCC.\nFrom what I know, this is because of memory management, but I don't really know too much about that subject, which is why I'm asking here.\n\nAlso how to fix this would be nice, but if someone could explain these execution times I'd already be happy enough.\n\nI already know of malloc/free, but the problem is not amount of memory used, it's merely execution time, so I don't know how that would help.\n    ", "Answer": "\r\nThe difference is caused by the same super-alignment issue from the following related questions:\n\n\nWhy is transposing a matrix of 512x512 much slower than transposing a matrix of 513x513?\nMatrix multiplication: Small difference in matrix size, large difference in timings\n\n\nBut that's only because there's one other problem with the code.\n\nStarting from the original loop:\n\n```\nfor(i=1;i<SIZE-1;i++) \n    for(j=1;j<SIZE-1;j++) {\n        res[j][i]=0;\n        for(k=-1;k<2;k++) \n            for(l=-1;l<2;l++) \n                res[j][i] += img[j+l][i+k];\n        res[j][i] /= 9;\n}\n```\n\n\nFirst notice that the two inner loops are trivial. They can be unrolled as follows:\n\n```\nfor(i=1;i<SIZE-1;i++) {\n    for(j=1;j<SIZE-1;j++) {\n        res[j][i]=0;\n        res[j][i] += img[j-1][i-1];\n        res[j][i] += img[j  ][i-1];\n        res[j][i] += img[j+1][i-1];\n        res[j][i] += img[j-1][i  ];\n        res[j][i] += img[j  ][i  ];\n        res[j][i] += img[j+1][i  ];\n        res[j][i] += img[j-1][i+1];\n        res[j][i] += img[j  ][i+1];\n        res[j][i] += img[j+1][i+1];\n        res[j][i] /= 9;\n    }\n}\n```\n\n\nSo that leaves the two outer-loops that we're interested in.\n\nNow we can see the problem is the same in this question: Why does the order of the loops affect performance when iterating over a 2D array?\n\nYou are iterating the matrix column-wise instead of row-wise.\n\n\n\nTo solve this problem, you should interchange the two loops.\n\n```\nfor(j=1;j<SIZE-1;j++) {\n    for(i=1;i<SIZE-1;i++) {\n        res[j][i]=0;\n        res[j][i] += img[j-1][i-1];\n        res[j][i] += img[j  ][i-1];\n        res[j][i] += img[j+1][i-1];\n        res[j][i] += img[j-1][i  ];\n        res[j][i] += img[j  ][i  ];\n        res[j][i] += img[j+1][i  ];\n        res[j][i] += img[j-1][i+1];\n        res[j][i] += img[j  ][i+1];\n        res[j][i] += img[j+1][i+1];\n        res[j][i] /= 9;\n    }\n}\n```\n\n\nThis eliminates all the non-sequential access completely so you no longer get random slow-downs on large powers-of-two.\n\n\n\nCore i7 920 @ 3.5 GHz\n\nOriginal code:\n\n```\n8191: 1.499 seconds\n8192: 2.122 seconds\n8193: 1.582 seconds\n```\n\n\nInterchanged Outer-Loops:\n\n```\n8191: 0.376 seconds\n8192: 0.357 seconds\n8193: 0.351 seconds\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication TypeError\r\n                \r\nI'm attempting to write a backpropagation algorithm and I'm encountering an error when attempting to perform a matrix multiplication. \n\nI've created the following simple example to work with\n\n```\n# necessary functions for this example\ndef sigmoid(z):\n    return 1.0/(1.0+np.exp(-z))\n\ndef prime(z):\n    return sigmoid(z) * (1-sigmoid(z))\n\ndef cost_derivative(output_activations, y):\n    return (output_activations-y)\n\n# Mock weight and bias matrices\nweights = [np.array([[ 1, 0, 2], \n                     [2, -1, 0], \n                     [4, -1, 0], \n                     [1, 3, -2],\n                     [0, 0, -1]]), \n           np.array([2, 0, -1, -1, 2])]\n\nbiases = [np.array([-1, 2, 0, 0, 4]), np.array([-2])]\n\n# The mock training example\nq = [(np.array([1, -2, 3]), np.array([0])), \n     (np.array([2, -3, 5]), np.array([1])),\n     (np.array([3, 6, -1]), np.array([1])),\n     (np.array([4, -1, -1]), np.array([0]))]\n\nfor x, y in q:\n        activation = x\n        activations = [x]\n        zs = []\n        for w, b in zip(weights, biases): \n            z = np.dot(w, activation) + b\n            zs.append(z)\n            activation = sigmoid(z)\n            activations.append(activation)\n\ndelta = cost_derivative(activations[-1], y) * prime(zs[-1])\nprint(np.dot(np.transpose(weights[-1])), delta)\n```\n\n\nI get the following error:\n\n```\nTypeError: Required argument 'b' (pos 2) not found\n```\n\n\nI've printed the outputs of both the ```\nweights```\n transposed which is a 5x2 matrix and ```\ndelta```\n is a 2x1. The outputs are:\n\n```\nnp.transpose(weights[-1]) = [[ 2 -3]\n                             [ 0  2]\n                             [-1  0]\n                             [-1  1]\n                             [ 2 -1]]\n```\n\n\nand\n\n```\ndelta = [-0.14342712 -0.03761959]\n```\n\n\nso the multiplication should work and produce a 5x1 matrix\n    ", "Answer": "\r\nThere is a misplaced parenthesis on your last line. It should be\n\n```\nprint(np.dot(np.transpose(weights[-1]), delta))\n```\n\n\ninstead of\n\n```\nprint(np.dot(np.transpose(weights[-1])), delta)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "SSE matrix-matrix multiplication\r\n                \r\nI'm having trouble doing matrix-matrix multiplication with SSE in C.\n\nHere is what I got so far:\n\n```\n#define N 1000\n\nvoid matmulSSE(int mat1[N][N], int mat2[N][N], int result[N][N]) {\n  int i, j, k;\n  __m128i vA, vB, vR;\n\n  for(i = 0; i < N; ++i) {\n    for(j = 0; j < N; ++j) {\n        vR = _mm_setzero_si128();\n        for(k = 0; k < N; k += 4) {\n            //result[i][j] += mat1[i][k] * mat2[k][j];\n            vA = _mm_loadu_si128((__m128i*)&mat1[i][k]);\n            vB = _mm_loadu_si128((__m128i*)&mat2[k][j]); //how well does the k += 4 work here? Should it be unrolled?\n            vR = _mm_add_epi32(vR, _mm_mul_epi32(vA, vB));\n        }\n        vR = _mm_hadd_epi32(vR, vR);\n        vR = _mm_hadd_epi32(vR, vR);\n        result[i][j] += _mm_extract_epi32(vR, 0);\n    }\n  }\n}\n```\n\n\nI can't seem to make it give the correct results. Am I missing something?\nAnd searching dosent seem to help much - every result is either only doing 4x4 matrices, mat-vec or some special magic thats not very readable and hard to understand...\n    ", "Answer": "\r\nYou're right, your ```\nvB```\n is the problem.  You're loading 4 consecutive integers, but ```\nmat2[k+0..3][j]```\n aren't contiguous.  You're actually getting ```\nmat2[k][j+0..3]```\n.\n\n\n\nI forget what works well for matmul.  Sometimes it works well to produce 4 results in parallel, instead of doing a horizontal sum for every result.\n\nTransposing one of your input matrices works, and costs O(N^2).  It's worth it because it means the O(N^3) matmul can use sequential accesses, and your current loop structure becomes SIMD-friendly.\n\nThere are even better ways, such as transposing small blocks right before use, so they're still hot in L1 cache when you read them again.  Or looping over a destination row and adding in one result, instead of accumulating a full result for a single or small set of row*column dot products.  Cache blocking, aka loop tiling, is one key to good matmul performance.  See also What Every Programmer Should Know About Memory? which has a cache-blocked SIMD FP matmul example in an appendix without a transpose.\n\nMuch has been written about optimizing matrix multiplies, with SIMD and with cache-blocking.  I suggest you google it up.  Most if it is probably talking about FP, but it all applies to integer as well.\n\n(Except that SSE/AVX only has FMA for FP, not for 32-bit integers, and the 8 and 16-bit input PMADD instructions do horizontal adds of pairs.)\n\n\n\nActually I think you can produce 4 results in parallel here, if one input has been transposed already:\n\n```\nvoid matmulSSE(int mat1[N][N], int mat2[N][N], int result[N][N]) {\n\n  for(int i = 0; i < N; ++i) {\n    for(int j = 0; j < N; j+=4) {   // vectorize over this loop\n        __m128i vR = _mm_setzero_si128();\n        for(int k = 0; k < N; k++) {   // not this loop\n            //result[i][j] += mat1[i][k] * mat2[k][j];\n            __m128i vA = _mm_set1_epi32(mat1[i][k]);  // load+broadcast is much cheaper than MOVD + 3 inserts (or especially 4x insert, which your new code is doing)\n            __m128i vB = _mm_loadu_si128((__m128i*)&mat2[k][j]);  // mat2[k][j+0..3]\n            vR = _mm_add_epi32(vR, _mm_mullo_epi32(vA, vB));\n        }\n        _mm_storeu_si128((__m128i*)&result[i][j], vR));\n    }\n  }\n}\n```\n\n\nA broadcast-load (or separate load+broadcast without AVX) is still much cheaper than a gather.\n\nYour current code does the gather with 4 inserts, instead of breaking the dependency chain on the previous iteration's value by using a MOVD for the first element, so that's even worse.  But even the best gather of 4 scattered elements is pretty bad compared to a load + PUNPCKLDQ.  Not to mention that that makes your code need SSE4.1.\n\nAlthough it needs SSE4.1 anyway for ```\n_mm_mullo_epi32```\n instead of the widening PMULDQ (```\n_mm_mul_epi32```\n).\n\nNote that integer multiply throughput is generally worse than FP multiply, especially on Haswell and later.  FP FMA units only have 24-bit wide multipliers per 32-bit element (for FP mantissas) so using those for 32x32=>32-bit integer requires splitting into two uops.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication for certain matrix elements\r\n                \r\nI'm trying to update a list of regional supply with matrix multiplication.\nI have a list of regional supply and a origin destination matrix which represents transition probability between each regions.\nAnd I would like to get the In/Out list with matrix multiplication.\n```\nSupply = np.array([10, 20])\nOD_matrix = np.array([0.3,0.7,0.5,0.5]).reshape(2,2)\n\n          Destination\n               0    1\n          0 [[0.3, 0.7],\n   Origin 1  [0.5, 0.5]]\n\n```\n\nIn the above example there are two regions, region 1 and region 2 each with 10, 20 supply.\nThe matrix is a probability of transition between each region for example\nOD_matrix[0][1] of the matrix is the transition of supply from region 0 to region1.\nNow I can easily update the supply matrix with\n```\nSupply = np.dot(Supply,OD_matrix)\n```\n\nBut how can I create a list of In/Out of each region like\n```\nSupply [10,20]\nIn  [10, 7]\nOut [7 , 10]\nUpdated Supply [13,17]\n```\n\nIf I were to create the \"In\" list, I know that I should multiply the matrix while excluding the element whose origin and destination is itself, and then add them.\nHow should I computate this matrix multiplication without using a for loop in larger matrixes?\n    ", "Answer": "\r\nBy definition, to do matrix multiplication you do need for loops. There's just no way around it.\nHowever, you can actually do matrix multiplication is less than ```\nO(n^3)```\n time by using Strassen's Algorithm. You can look into it further in the link provided to see if that's truly more efficient and hence suitable for your case.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "custom matrix multiplication with numpy\r\n                \r\nI want a strange dot product for matrix multiplication in numpy.\nFor a line ```\n[1,2,3]```\n of matrix ```\nA```\n and a column ```\n[4,5,6]```\n for matrix ```\nB```\n, I wish to use the \"product\" ```\nmin(1+4, 2+5, 3+6)```\n for obtaining the matrix product ```\nAB```\n.\n    ", "Answer": "\r\n```\nIn [498]: A = np.arange(12).reshape(4,3)                                             \nIn [499]: B = np.arange(4,10).reshape(3,2)                                           \nIn [500]: A                                                                          \nOut[500]: \narray([[ 0,  1,  2],\n       [ 3,  4,  5],\n       [ 6,  7,  8],\n       [ 9, 10, 11]])\nIn [501]: B                                                                          \nOut[501]: \narray([[4, 5],\n       [6, 7],\n       [8, 9]])\n```\n\n\nReference iterative solution:\n\n```\nIn [504]: res = np.zeros((A.shape[0],B.shape[1]), A.dtype) \n     ...: for i,row in enumerate(A): \n     ...:     for j,col in enumerate(B.T): \n     ...:         res[i,j] = np.min(row+col) \n     ...:                                                                            \nIn [505]: res                                                                        \nOut[505]: \narray([[ 4,  5],\n       [ 7,  8],\n       [10, 11],\n       [13, 14]])\n```\n\n\nFaster version using broadcasting:\n\n```\nIn [506]: np.min(A[:,:,None]+B[None,:,:], axis=1)                                    \nOut[506]: \narray([[ 4,  5],\n       [ 7,  8],\n       [10, 11],\n       [13, 14]])\n```\n\n\n===\n\nDemonstrate the equivalence to a matrix product:\n\n```\nIn [507]: np.dot(A,B)                                                                \nOut[507]: \narray([[ 22,  25],\n       [ 76,  88],\n       [130, 151],\n       [184, 214]])\nIn [508]: np.sum(A[:,:,None]*B[None,:,:], axis=1)                                    \nOut[508]: \narray([[ 22,  25],\n       [ 76,  88],\n       [130, 151],\n       [184, 214]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Two matrix multiplication in OpenCL\r\n                \r\nSorry if I'm asking a really simple question, but I couldn't find any related answer on the net.\n\nI'm trying to perform two matrix multiplication on GPU using OpenCL, line R = ABC. They way I do, is by performing matrix multiplication on A and B, and then store the intermediate result (I) on the GPUs DRAM, and then do another matrix multiplication between I and C. My current kernel can also handle batches of matrices.\n\nHere is the code for my MatMul kernel (It is just a basic version, without optimizations):\n\n```\n__kernel void MatrixMultiplication2 (const __global float* A,\n                                     const __global float* B,\n                                     __global float* C,\n                                     const int A_height, const int A_width,\n                                     const int B_height, const int B_width,\n                                     const int C_height, const int C_width) {\n\n        const int row = get_global_id (0);\n        const int col = get_global_id (1);\n        const int imgID = get_global_id (2);\n\n        const int offsetA = A_height * A_width * imgID;\n        const int offsetB = B_height * B_width * imgID;\n        const int offsetC = C_height * C_width * imgID;\n\n        float acc = 0.0f;\n\n        for (int k = 0; k < A_width; k++) {\n                acc += A[row*A_width + k + offsetA] * B[k*B_width + col + offsetB];\n        }\n\n        C[row*C_width + col + offsetC] = acc;\n\n\n}\n```\n\n\nHere is also the related part in my host code for deploying matrix multiplications:\n\n```\nconst size_t GWS1[3] = {A_height, B_width, batch_size};\nconst size_t LWS1[3] = {32, 32, 1};\n\n\nconst size_t GWS2[3] = {A_height, C_width, batch_size};\nconst size_t LWS2[3] = {32, 32, 1};\n\nEvent evKernel1 (\"Kernel1\");\nEvent evKernel2 (\"Kernel2\");\n\nclFinish (queue);\n\nhigh_resolution_clock::time_point t1 = high_resolution_clock::now();\nerr = clEnqueueNDRangeKernel (queue,\n                              kernel1,\n                              3,\n                              NULL,\n                              GWS1,\n                              LWS1,\n                              0,\n                              NULL,\n                              &evKernel1.CLEvent());\n\nclFinish (queue);\nCL_CHECK_ERROR (err);\nerr = clFinish (queue);\nCL_CHECK_ERROR (err);\nerr = clWaitForEvents (1, &evKernel1.CLEvent());\nCL_CHECK_ERROR (err);\nevKernel1.FillTimingInfo ();\n\nerr = clEnqueueNDRangeKernel (queue,\n                              kernel2,\n                              3,\n                              NULL,\n                              GWS2,\n                              LWS2,\n                              0,\n                              NULL,\n                              &evKernel2.CLEvent());\n\nclFinish (queue);\nCL_CHECK_ERROR (err);\nerr =clFinish (queue);\nCL_CHECK_ERROR (err);\nerr = clWaitForEvents (1, &evKernel2.CLEvent());\nCL_CHECK_ERROR (err);\n\nhigh_resolution_clock::time_point t2 = high_resolution_clock::now();\n\nevKernel2.FillTimingInfo ();\n\nreadbackMemObject (queue, &mem_R, (int) sizeof (T), RSize, hostMem_R);\n```\n\n\nIs it the right way to do multi stage matrix multiplication on the GPU? I am deploying the first stage, and then wait until it finishes and then deploy the second one. The performance is really low in this scenario, and when I increase the batch size, it will decrease more. I just want to know if this is the normal way of doing sequential matrix multiplication or not.\n\nThanks,\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Awk Matrix multiplication\r\n                \r\nI'm trying to write an AWK command that allows me to perform matrix multiplication between two tab separated files. \n\nexample:\n\ncat m1\n\n```\n1 2 3 4\n5 6 7 8\n```\n\n\ncat m2\n\n```\n1 2\n3 4\n5 6\n7 8\n```\n\n\ndesired output:\n\n```\n 50  60\n114 140\n```\n\n    ", "Answer": "\r\nwithout any validation of the input files for the sizes.\n\nit will be easier to break into two scripts, one for transposing the second matrix and one to create a dot product of vectors.  Also to simply ```\nawk```\n code, you can resort to ```\njoin```\n.\n\n```\n$ awk '{m=NF/2; for(i=1;i<=m;i++) sum[NR] += $i*$(i+m)} \n   END {for(i=1;i<=NR;i++) \n          printf \"%s\", sum[i] (i==sqrt(NR)?ORS:OFS); \n        print \"\"}' <(join -j99 m1 <(transpose m2))\n```\n\n\nwhere ```\ntranspose```\n function is defined as\n\n```\n$ function transpose() { awk '{for(j=1;j<=NF;j++) a[NR,j]=$j}\n                          END {for(i=1;i<=NF;i++) \n                                 for(j=1;j<=NR;j++) \n                                   printf \"%s\",a[j,i] (j==NR?ORS:OFS)}' \"$1\"; }\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Complex matrix multiplication OpenCL\r\n                \r\ni’m a new programmer on opencl, i’ve to perform a multiplication of 2 complex matrix but i don’t know how to deal with complex matrix on opencl. please any help?  I aleady tried matrix multiplication  with normal numbers.\n    ", "Answer": "\r\nOne way, though probably not the most efficient, would be to regard your complex matrix, Z say as being two real matrices X (the real parts) and Y the imaginary parts,ie\n```\nX[i,j]= Real( Z[i,j]) Y[i,j] = Imag( Z[i,j])\n```\n\nIf you have another complex matrix W say, which is split as above into U and V then to multiply:\n```\nZ*W = (X*U-Y*V, X*V+Y*U)\n```\n\nwhere on the rhs we have real matrices and real matrix multiplication and addition.\nIn terms of multiplies and adds this will be the same amount of computation as doing the complex multiplications and additions (of the elements) directly. The inefficiency will come if you are given, and should return, arrays of complex numbers; then you have to split, as above the matrices you are going to multiply into real ones, and combine the product into complex array.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication using Mpi_Scatter and Mpi_Gather\r\n                \r\nI newbie to mpi programming. I was trying to write matrix multiplication. Went through the post MPI Matrix Multiplication with scatter gather about matrix multiplication using scatter and gather routine.\nI tried modifying the code available on above post as below...\n\n```\n#define N 4\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stddef.h>\n#include \"mpi.h\"\n\n\nvoid print_results(char *prompt, int a[N][N]);\n\nint main(int argc, char *argv[])\n{\n    int i, j, k, rank, size, tag = 99, blksz, sum = 0;\n    int a[N][N]={{1,2,3,4},{5,6,7,8},{9,1,2,3},{4,5,6,7,}};\n    int b[N][N]={{1,2,3,4},{5,6,7,8},{9,1,2,3},{4,5,6,7,}};\n    int c[N][N];\n    int aa[N],cc[N];\n\n    MPI_Init(&argc, &argv);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    //scatter rows of first matrix to different processes     \n    MPI_Scatter(a, N*N/size, MPI_INT, aa, N*N/size, MPI_INT,0,MPI_COMM_WORLD);\n\n    //broadcast second matrix to all processes\n    MPI_Bcast(b, N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\n    MPI_Barrier(MPI_COMM_WORLD);\n\n          //perform vector multiplication by all processes\n          for (i = 0; i < N; i++)\n            {\n                    for (j = 0; j < N; j++)\n                    {\n                            sum = sum + aa[j] * b[i][j];                \n                    }\n                    cc[i] = sum;\n                    sum = 0;\n            }\n\n    MPI_Gather(cc, N*N/size, MPI_INT, c, N*N/size, MPI_INT, 0, MPI_COMM_WORLD);\n\n    MPI_Barrier(MPI_COMM_WORLD);        \n    MPI_Finalize();\n    print_results(\"C = \", c);\n}\n\nvoid print_results(char *prompt, int a[N][N])\n{\n    int i, j;\n\n    printf (\"\\n\\n%s\\n\", prompt);\n    for (i = 0; i < N; i++) {\n            for (j = 0; j < N; j++) {\n                    printf(\" %d\", a[i][j]);\n            }\n            printf (\"\\n\");\n    }\n    printf (\"\\n\\n\");\n}\n```\n\n\nI ran above program as\n\n```\n$mpirun -np 4 ./a.out\n```\n\n\nFor above program I am getting following incorrect output..\n\n```\nC = \n 0 0 -562242168 32766\n 1 0 4197933 0\n -562242176 32766 0 0\n 4197856 0 4196672 0\n\nC = \n 0 0 -1064802792 32765\n 1 0 4197933 0\n -1064802800 32765 0 0\n 4197856 0 4196672 0\n\nC = \n 30 70 29 60\n 70 174 89 148\n 29 89 95 74\n 60 148 74 126\n\nC = \n 0 0 -1845552920 32765\n 1 0 4197933 0\n -1845552928 32765 0 0\n 4197856 0 4196672 0\n```\n\n\nI have following queries\n 1. Why result matrix C is getting printed by all processes. It is\n    supposed to be printed by only main process. \n 2. Why incorrect result is being printed?\n\nCorrections and help in this regard will be appreciated.\n    ", "Answer": "\r\nThe result matrix ```\nc```\n is getting printed by all processes because every process executes the function ```\nvoid print_results(char *prompt, int a[N][N])```\n. Since you are gathering at the process having rank 0, add a statement ```\nif (rank == 0)```\n before calling the ```\nprint_results(...)```\n function. Further, the result is incorrect because of a wrong loop logic in :\n\n```\n                for (j = 0; j < N; j++)\n                {\n                        sum = sum + aa[j] * b[i][j];                \n                }\n```\n\n\nThis should be : \n\n```\n                for (j = 0; j < N; j++)\n                {\n                        sum = sum + aa[j] * b[j][i];                \n                }\n```\n\n\nAlso there is no need to broadcast ```\nb```\n as all processes already already have a copy of it and you can avoid ```\nMPI_Barrier()```\n. The complete program then becomes :\n\n```\n#define N 4\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stddef.h>\n#include \"mpi.h\"\n\n\nvoid print_results(char *prompt, int a[N][N]);\n\nint main(int argc, char *argv[])\n{\n    int i, j, k, rank, size, tag = 99, blksz, sum = 0;\n    int a[N][N]={{1,2,3,4},{5,6,7,8},{9,1,2,3},{4,5,6,7,}};\n    int b[N][N]={{1,2,3,4},{5,6,7,8},{9,1,2,3},{4,5,6,7,}};\n    int c[N][N];\n    int aa[N],cc[N];\n\n    MPI_Init(&argc, &argv);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    //scatter rows of first matrix to different processes     \n    MPI_Scatter(a, N*N/size, MPI_INT, aa, N*N/size, MPI_INT,0,MPI_COMM_WORLD);\n\n    //broadcast second matrix to all processes\n    MPI_Bcast(b, N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\n    MPI_Barrier(MPI_COMM_WORLD);\n\n          //perform vector multiplication by all processes\n          for (i = 0; i < N; i++)\n            {\n                    for (j = 0; j < N; j++)\n                    {\n                            sum = sum + aa[j] * b[j][i];  //MISTAKE_WAS_HERE               \n                    }\n                    cc[i] = sum;\n                    sum = 0;\n            }\n\n    MPI_Gather(cc, N*N/size, MPI_INT, c, N*N/size, MPI_INT, 0, MPI_COMM_WORLD);\n\n    MPI_Barrier(MPI_COMM_WORLD);        \n    MPI_Finalize();\n    if (rank == 0)                         //I_ADDED_THIS\n        print_results(\"C = \", c);\n}\n\nvoid print_results(char *prompt, int a[N][N])\n{\n    int i, j;\n\n    printf (\"\\n\\n%s\\n\", prompt);\n    for (i = 0; i < N; i++) {\n            for (j = 0; j < N; j++) {\n                    printf(\" %d\", a[i][j]);\n            }\n            printf (\"\\n\");\n    }\n    printf (\"\\n\\n\");\n}\n```\n\n\nThen ```\nc =```\n\n\n```\nC = \n 54 37 47 57\n\n 130 93 119 145\n\n 44 41 56 71\n\n 111 79 101 123 \n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication optimization via matrix transpose\r\n                \r\nI am working on an assignment where I transpose a matrix to reduce cache misses for a matrix multiplication operation. From what I understand from a few classmates, I should get 8x improvement. However, I am only getting 2x ... what might I be doing wrong? \n\nFull Source on GitHub\n\n```\nvoid transpose(int size, matrix m) {\n    int i, j;\n    for (i = 0; i < size; i++) \n        for (j = 0; j < size; j++) \n            std::swap(m.element[i][j], m.element[j][i]);\n}\n\nvoid mm(matrix a, matrix b, matrix result) {\n    int i, j, k;\n    int size = a.size;\n    long long before, after;\n\n    before = wall_clock_time();\n    // Do the multiplication\n    transpose(size, b); // transpose the matrix to reduce cache miss\n    for (i = 0; i < size; i++)\n        for (j = 0; j < size; j++) {\n            int tmp = 0; // save memory writes\n            for(k = 0; k < size; k++)\n                tmp += a.element[i][k] * b.element[j][k];\n            result.element[i][j] = tmp;\n        }\n    after = wall_clock_time();\n    fprintf(stderr, \"Matrix multiplication took %1.2f seconds\\n\", ((float)(after - before))/1000000000);\n}\n```\n\n\nAm I doing things right so far? \n\nFYI: The next optimization I need to do is use SIMD/Intel SSE3\n    ", "Answer": "\r\n\n  Am I doing things right so far?\n\n\nNo. You have a problem with your transpose. You should have seen this problem before you started worrying about performance. When you are doing any kind of hacking around for optimizations it always a good idea to use the naive but suboptimal implementation as a test. An optimization that achieves a factor of 100 speedup is worthless if it doesn't yield the right answer.\n\nAnother optimization that will help is to pass by reference. You are passing copies. In fact, your ```\nmatrix result```\n may never get out because you are passing copies. Once again, you should have tested.\n\nYet another optimization that will help the speedup is to cache some pointers. This is still quite slow:\n\n```\nfor(k = 0; k < size; k++)\n    tmp += a.element[i][k] * b.element[j][k];\nresult.element[i][j] = tmp;\n```\n\n\nAn optimizer might see a way around the pointer problems, but probably not. At least not if you don't use the nonstandard ```\n__restrict__```\n keyword to tell the compiler that your matrices don't overlap. Cache pointers so you don't have to do ```\na.element[i]```\n, ```\nb.element[j]```\n, and ```\nresult.element[i]```\n. And it still might help to tell the compiler that these arrays don't overlap with the ```\n__restrict__```\n keyword.\n\nAddendum\nAfter looking over the code, it needs help. A minor comment first. You aren't writing C++. Your code is C with a tiny hint of C++. You're using ```\nstruct```\n rather than ```\nclass```\n, ```\nmalloc```\n rather than ```\nnew```\n, ```\ntypedef struct```\n rather than just ```\nstruct```\n, C headers rather than C++ headers.\n\nBecause of your implementation of your ```\nstruct matrix```\n, my comment on slowness due to copy constructors was incorrect. That it was incorrect is even worse! Using the implicitly-defined copy constructor in conjunction with classes or structs that contain naked pointers is playing with fire. You will get burned very badly if someone calls ```\nm(a, a, a_squared)```\n to get the square of matrix ```\na```\n. You will get burned even worse if some expects  ```\nm(a, a, a)```\n to do an in-place computation of ```\na```\n2.\n\nMathematically, your code only covers a tiny portion of the matrix multiplication problem. What if someone wants to multiply a 100x1000 matrix by a 1000x200 matrix? That's perfectly valid, but your code doesn't handle it because your code only works with square matrices. On the other hand, your code will let someone multiply a 100x100 matrix by a 200x200 matrix, which doesn't make a bit of sense.\n\nStructurally, your code has close to a 100% guarantee that it will be slow because of your use of ragged arrays. ```\nmalloc```\n can spritz the rows of your matrices all across memory. You'll get much better performance if the matrix is internally represented as a contiguous array but is accessed as if it were a NxM matrix. C++ provides some nice mechanisms for doing just that.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Cython: matrix multiplication\r\n                \r\nI have cythonized the following file that uses numpy's matrix multiplication:\n```\ndef cell(float[:, ::1] a, float[:, ::1] b):\n  c = a @ b\n  return c\n```\n\nHowever, when I call it with:\n```\nfrom matmul import cell\nimport numpy as np\n\n\na = np.zeros((1, 64), dtype=np.float32)\nb = np.zeros((64, 64), dtype=np.float32)\nc = cell(a, b)\n```\n\nI get the following error:\n\nTypeError: unsupported operand type(s) for @: _memoryviewslice and\n_memoryviewslice\n\nHow can I perform matrix multiplication with Cython?\nContext: the function \"cell\" is part of a code I wrote that performs a prediction by an LSTM network (I wrote it manually, without using PyTorch or Tensorflow, just NumPy). I need to speed up the code to be able to use the network in real-time.\n    ", "Answer": "\r\nIf that's all you're doing there's literally no point in adding the types for the argument of ```\ncell```\n - all you're doing is adding expensive type-checks for no reason. Cython can't make useful use of these types. Just leave ```\na```\n and ```\nb```\n untyped.\nIf you do actually need to fix memoryviews operations with Numpy whole-array operations the easiest solution is to call ```\nnp.asarray```\n\n```\ndef cell(float[:, ::1] a, float[:, ::1] b):\n  c = np.asarray(a) @ np.asarray(b)\n  return c\n```\n\nYou aren't getting any benefit from Cython here - it's just calling into the Numpy matrix multiply code. So only do this where you need to mix it with some operations where you do benefit from Cython.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication with template parameters in C++\r\n                \r\nI have a self-defined ```\nMatrix```\n class and want to overload operator ```\n*```\n to do matrix multiplication:\n\n```\ntemplate< int R, int C> \nclass Matrix{\n   int *_mat;\n   int _size;\npublic:\n   Matrix(){ _size = R*C; _mat = new int[_size]{0}; }\n   ~Matrix(){ delete []_mat; }\n   Matrix &operator=(const Matrix & m){/*...*/}\n   //...\n   template< int D2, int D1 > using matrix_t = int[D2][D1];\n   template<int R2, int C2>\n   Matrix<R,C2> operator*(const matrix_t<R2,C2> &mat)\n   {\n       Matrix<R,C2> result;\n       for(int r = 0; r < R; r++)\n       {\n           for(int c = 0; c < C2; c++)\n           {\n               for( int i; i < C; i++ ){\n                  /*do multiplication...\n                    result._mat[r*C2+c] = ...\n                  */\n               }\n           }\n       }\n       return result;\n   }      \n   //...\n}; \n```\n\n\nThen the problem comes with ```\nMatrix<R,C2> result```\n. The ```\nresult```\n becomes a outside object of the class. So I cannot access its private member using like ```\nresult._mat[r*C2+c]```\n. \n\nWhat is the solution( without changing access permission) to define my function of matrix multiplication in this class?  \n    ", "Answer": "\r\nYou could specify an operator so you can externally set the values of the matrix.  Note you won't be able to use ```\noperator []```\n - since you can only use that with one argument (ref C++ [] array operator with multiple arguments?)\n\n```\n   int& operator() (int row, int col) { \n     // todo: check array bounds\n     return _mat[C*row+col];\n   }\n```\n\n\nUsage:\n\n```\n result(r,c) = ...\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Parallel Matrix Multiplication\r\n                \r\nI wrote a simple  parallel matrix multiplication using ```\npar```\n and ```\npseq```\n.\n\nAfter running this program, none of the sparks converted (SPARKS: 20 (0 converted, 0 pruned)). \n\nI would like to hear your comment about improving this program.\n\nAlso about approaches for learning parallel programming in Haskell.\n\n```\nimport Data.List\nimport Control.Parallel\n\nparHelp :: ( Num a ) => [ a ] -> [ a ] -> a \nparHelp [] [] = 0\nparHelp ( x : xs ) ( y : ys ) = ret where \nret = par a ( pseq b ( a + b ) ) where \n        a = x * y \n        b = parHelp xs ys\n\nhelpMult :: ( Num a ) => [ a ] -> [ [ a ] ] -> [ a ]\nhelpMult _ [] = [] \nhelpMult x ( y : ys ) = ret where \n ret =  par a ( pseq b  ( a : b ) ) where \n   a = sum . zipWith ( *) x $ y  \n   b = helpMult x ys\n\nmult :: ( Num a ) => [ [ a ] ] -> [ [ a ] ] -> [ [ a ] ]\nmult [] _ = []  \nmult ( x : xs ) ys = ret where \n ret = par a ( pseq b  ( a : b ) ) where \n    a = helpMult x ys \n    b = mult xs ys\n\nmain = print $ mult [[1 .. 4 ] , [ 1 .. 4 ] , [ 1 .. 4 ] , [ 1 .. 4] ] ( transpose [[1 .. 4 ] , [ 1 .. 4 ] , [ 1 .. 4 ] , [ 1 .. 4] ])\n```\n\n    ", "Answer": "\r\nDid you try very large (at least 1000x1000) matrices? It is possible that the computation is too short to paralellize.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication MPI + OMP\r\n                \r\nI'm having a problem with my code for matrix multiplication using both MPI and OMP. Code is correctly compiled but it give me wrong result,values in matrix c(in matmul function) are to big and matrix C(in main) doesn't even get results from function matmul. If anyone knows how to fix it,please help.\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <mpi.h>\n\nint offset,rows,br_elemenata,cvor_id,cvor,ukupno;\nMPI_Status status;\n\ndouble gettime(void) {\n   struct timeval tv;\n   gettimeofday(&tv, NULL);\n   return tv.tv_sec + 1e-6 * tv.tv_usec;\n}\n\nvoid matfill(long N, double *mat, double val) {\n   long i, j;\n\n   for(i = 0; i < N; i ++)\n      for(j = 0; j < N; j ++)\n         mat[i * N + j] = val;\n}\n\nvoid matmul(long N, double *a, double *b, double *c) {\n   long i, j, k;\n\n  br_elemenata = N / ukupno;            //odredjujemo broj elemenata po cvoru\n\n  if (N % ukupno != 0) br_elemenata++;      //inkrementujemo broj elemenata po cvoru kako ne bismo neki izostavili\n\n  if (cvor == 0){\n    for (cvor_id=1;cvor_id<ukupno;cvor_id++){\n      offset = cvor_id * br_elemenata;\n      rows = N - offset;\n      if (rows > br_elemenata)\n    rows = br_elemenata;\n      // slanje podataka sa cvora 0 na ostale cvorove\n      MPI_Send(&offset, 1, MPI_INT, cvor_id, 0, MPI_COMM_WORLD);\n      MPI_Send(&rows, 1, MPI_INT, cvor_id, 0, MPI_COMM_WORLD);\n      MPI_Send(a+offset, rows*N, MPI_DOUBLE, cvor_id, 0, MPI_COMM_WORLD);\n      MPI_Send(b, N*N, MPI_DOUBLE, cvor_id, 0, MPI_COMM_WORLD);\n  }\n  offset = 0;\n  rows = br_elemenata;\n  } else {\n    // Primanje podataka sa cvora 0\n    MPI_Recv(&offset, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n    MPI_Recv(&rows, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n    MPI_Recv(a+offset, rows*N, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &status);\n    MPI_Recv(b, N*N, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &status);\n}\n\nMPI_Barrier(MPI_COMM_WORLD);\n\n#pragma omp parallel for shared(a,b,c) private(i,j,k)\n   for (i = offset; i < offset + rows; i ++)\n      for (j = 0; j < N; j ++)\n         for (k = 0; k < N; k ++)\n            c[i + j] += a[i + k] * b[k * N + j];\n  printf(\"Clan: %5.2f\\n\",c[i]);\n  if (cvor == 0) {\n    for (cvor_id = 1; cvor_id < ukupno; cvor_id++) {\n    MPI_Recv(&offset, 1, MPI_INT, cvor_id, 1, MPI_COMM_WORLD, &status);\n    MPI_Recv(&rows, 1, MPI_INT, cvor_id, 1, MPI_COMM_WORLD, &status);\n    MPI_Recv(c+offset, rows*N, MPI_DOUBLE, cvor_id, 1, MPI_COMM_WORLD, &status);\n    }\n  } else {\n    MPI_Send(&offset, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n    MPI_Send(&rows, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n    MPI_Send(c+offset, rows*N, MPI_DOUBLE, 0, 1, MPI_COMM_WORLD);\n  }  \n}\n\nint main(int argc, char **argv) {\n   long N;\n   double *A, *B, *C, t;\n\n\n   MPI_Init(&argc,&argv);       //Inicijalizacija MPI\n\n   MPI_Comm_size(MPI_COMM_WORLD,&ukupno);   //odredjujemo ukupan broj cvorova\n   MPI_Comm_rank(MPI_COMM_WORLD,&cvor);     //odredjuje redni broj cvora, nacin da se svaki cvor identifikuje u komunikaciji\n\n\n   if (argc!=2) {\n     if (cvor==0) printf(\"Morate unijeti dimenziju matrice!\");\n     MPI_Finalize();                        // ako ne postoji argument pri pozivu funkcije, zavrsiti program\n     return 1;\n   }\n\n   N = atoi(argv[1]);\n   A = (double *) malloc(N * N * sizeof(double));\n   B = (double *) malloc(N * N * sizeof(double));\n   C = (double *) malloc(N * N * sizeof(double));\n   matfill(N, A, 1.0);\n   matfill(N, B, 2.0);\n   matfill(N, C, 0.0);\n\n\n\n\n   t = gettime();\n   matmul(N, A, B, C);\n   t = gettime() - t;\n\n   // if (cvor == 0){\n      fprintf(stdout, \"%ld\\t%le\\t%le\\n\", N, t, (2 * N - 1) * N * N / t);\n      fflush(stdout);\n\n      printf(\"Clan: %f\\n\",C[6]);\n  //  }\n\n   free(A);\n   free(B);\n   free(C);\n\n   return EXIT_SUCCESS;\n}\n```\n\n\n\n    ", "Answer": "\r\nThe main issue is the ```\noffset```\n during communication operations. It should be ```\noffset*N```\n.\n\nCorrected code :\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <mpi.h>\n\nint offset,rows,br_elemenata,cvor_id,cvor,ukupno;\nMPI_Status status;\n\ndouble gettime(void) {\n    struct timeval tv;\n    gettimeofday(&tv, NULL);\n    return tv.tv_sec + 1e-6 * tv.tv_usec;\n}\n\nvoid matfill(long N, double *mat, double val) {\n    long i, j;\n\n    for(i = 0; i < N; i ++)\n        for(j = 0; j < N; j ++)\n            mat[i * N + j] = val;\n}\n\nvoid matprint(long N, double *mat) {\n    long i, j;\n\n    for(i = 0; i < N; i ++){\n        for(j = 0; j < N; j ++){\n            printf(\"%g \",mat[i*N+j]);\n        }\n        printf(\"\\n\");\n    }\n}\n\nvoid matdiag(long N, double *mat, double val) {\n    long i, j;\n\n    for(i = 0; i < N; i ++)\n        for(j = 0; j < N; j ++)\n            if(i==j){\n                mat[i * N + j] = (double)i;\n            }else{\n                mat[i * N + j] =0;\n            }\n}\n\nvoid matmul(long N, double *a, double *b, double *c) {\n    long i, j, k;\n\n    br_elemenata = N / ukupno;            //odredjujemo broj elemenata po cvoru\n\n    if (N % ukupno != 0) br_elemenata++;      //inkrementujemo broj elemenata po cvoru kako ne bismo neki izostavili\n\n    if (cvor == 0){\n        for (cvor_id=1;cvor_id<ukupno;cvor_id++){\n            offset = cvor_id * br_elemenata;\n            rows = N - offset;\n            if (rows > br_elemenata)\n                rows = br_elemenata;\n            // slanje podataka sa cvora 0 na ostale cvorove\n            MPI_Send(&offset, 1, MPI_INT, cvor_id, 0, MPI_COMM_WORLD);\n            MPI_Send(&rows, 1, MPI_INT, cvor_id, 1, MPI_COMM_WORLD);\n            MPI_Send(a+(offset*N), rows*N, MPI_DOUBLE, cvor_id, 2, MPI_COMM_WORLD);\n            MPI_Send(b, N*N, MPI_DOUBLE, cvor_id, 3, MPI_COMM_WORLD);\n        }\n        offset = 0;\n        rows = br_elemenata;\n    } else {\n        // Primanje podataka sa cvora 0\n        MPI_Recv(&offset, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n        MPI_Recv(&rows, 1, MPI_INT, 0, 1, MPI_COMM_WORLD, &status);\n        MPI_Recv(a+(offset*N), rows*N, MPI_DOUBLE, 0, 2, MPI_COMM_WORLD, &status);\n        MPI_Recv(b, N*N, MPI_DOUBLE, 0, 3, MPI_COMM_WORLD, &status);\n    }\n\n    MPI_Barrier(MPI_COMM_WORLD);\n\n#pragma omp parallel for shared(a,b,c) private(i,j,k)\n    for (i = offset; i < offset + rows; i ++)\n        for (j = 0; j < N; j ++)\n            for (k = 0; k < N; k ++)\n                c[i*N + j] += a[i*N + k] * b[k * N + j];\n    printf(\"Clan: %5.2f\\n\",c[i]);\n    if (cvor == 0) {\n        for (cvor_id = 1; cvor_id < ukupno; cvor_id++) {\n            MPI_Recv(&offset, 1, MPI_INT, cvor_id, 4, MPI_COMM_WORLD, &status);\n            MPI_Recv(&rows, 1, MPI_INT, cvor_id, 5, MPI_COMM_WORLD, &status);\n            MPI_Recv(c+(N*offset), rows*N, MPI_DOUBLE, cvor_id, 6, MPI_COMM_WORLD, &status);\n        }\n    } else {\n        MPI_Send(&offset, 1, MPI_INT, 0, 4, MPI_COMM_WORLD);\n        MPI_Send(&rows, 1, MPI_INT, 0, 5, MPI_COMM_WORLD);\n        MPI_Send(c+(N*offset), rows*N, MPI_DOUBLE, 0, 6, MPI_COMM_WORLD);\n    }  \n}\n\nint main(int argc, char **argv) {\n    long N;\n    double *A, *B, *C, t;\n\n\n    MPI_Init(&argc,&argv);       //Inicijalizacija MPI\n\n    MPI_Comm_size(MPI_COMM_WORLD,&ukupno);   //odredjujemo ukupan broj cvorova\n    MPI_Comm_rank(MPI_COMM_WORLD,&cvor);     //odredjuje redni broj cvora, nacin da se svaki cvor identifikuje u komunikaciji\n\n\n    if (argc!=2) {\n        if (cvor==0) printf(\"Morate unijeti dimenziju matrice!\");\n        MPI_Finalize();                        // ako ne postoji argument pri pozivu funkcije, zavrsiti program\n        return 1;\n    }\n\n    N = atoi(argv[1]);\n    A = (double *) malloc(N * N * sizeof(double));\n    B = (double *) malloc(N * N * sizeof(double));\n    C = (double *) malloc(N * N * sizeof(double));\n    matfill(N, A, 1.0);\n    matfill(N, B, 2.0);\n    matfill(N, C, 0.0);\n    matdiag(N,A, 1) ;\n\n\n\n\n    t = gettime();\n    matmul(N, A, B, C);\n    t = gettime() - t;\n\n    if (cvor == 0){\n        fprintf(stdout, \"%ld\\t%le\\t%le\\n\", N, t, (2 * N - 1) * N * N / t);\n        fflush(stdout);\n        printf(\"Clan: %f\\n\",C[6]);\n        printf(\"A\\n\");\n        matprint(N, A) ;\n        printf(\"B\\n\");\n        matprint(N, B) ;\n        printf(\"C\\n\");\n        matprint(N, C) ;\n\n    }\n\n\n    free(A);\n    free(B);\n    free(C);\n    MPI_Finalize();\n    return EXIT_SUCCESS;\n}\n```\n\n\nTo compile : ```\nmpicc main.c -o main```\n To run : ```\nmpirun -np 4 main```\n\n\nIf you wish to go further, you will be interested by the ```\nMPI_Bcast()```\n function, which sends the same thing to everyone. ```\nMPI_Scatter()```\n and ```\nMPI_Gather()```\n are helpful to distribute matrices or get it back on a given process.\n\nMoreover,  the ```\ndgemm()```\n function of BLAS may be used to speed up the computation on a given process.\n\nTo reduce the memory footprint, the allocated size of ```\nA```\n and ```\nC```\n may be decreased to account for ```\nbr_elemenata```\n (except on process 0)...and offsets will have to change...again !\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "JS Matrix Multiplication Issue\r\n                \r\nI'm having trouble with matrix multiplication code in JavaScript. If I run the function below with the following two matrices:\n\n```\nvar m1 = [ [ 1, 0, 0 ],\n  [ 0, 1, 0 ],\n  [ 1, 1, 0 ],\n  [ 0, 0, 1 ],\n  [ 1, 0, 1 ],\n  [ 0, 1, 1 ],\n  [ 1, 1, 1 ] ];\n\nvar m2 = [ [ '0', '1', '1', '0', '0', '1', '1' ] ];\n\nvar matrixMult = function (m1, m2) {\n    console.log(m1);\n    console.log(m2);\n    console.log(\"m1 length: %d, m2[0].length: %d\", m1.length, m2[0].length);\n    if (m1.length != m2[0].length) {\n            console.error(\"Incompatible matrix dimensions for multiplication.\");\n            return false;\n    }\n\n    var result = [];\n\n    for (var i = 0; i < m1[0].length; i++) {\n            result[i] = [];\n            for (var j = 0; j < m2.length; j++) {\n                    var sum = 0;\n                    for (var k = 0; k < m1.length; k++) {\n                            sum += m1[i][k] * m2[k][j];\n                    }\n                    result[i][j] = sum;\n            }\n    }\n    return result;\n}\n```\n\n\nI get this error:\n\n```\n/path/to/file.js:58\n                sum += m1[i][k] * m2[k][j];\n                                       ^\nTypeError: Cannot read property '0' of undefined\n    at matrixMult (...)\n```\n\n\nWhat's going wrong? Could the issue be that ```\nm2.length```\n is only 1?\n    ", "Answer": "\r\nThere is only a ```\nm2[0]```\n, but your inner ```\nfor```\n loop runs from ```\n0```\n to ```\nm1.length```\n, which is bigger than ```\n0```\n. So when it tries accessing ```\nm2[1]```\n it throws the error.\n\nAlso by following definition of matrix multiplication\n\n\n  Multiplication of two matrices is defined only if the number of columns of the left matrix is the same as the number of rows of the right matrix.\n\n\n(Source: Wikipedia)\n\nyou cannot multiply your sample matrixes, because ```\nm1```\n has 3 columns, but ```\nm2```\n has only one row.\n\nEDIT\n\nNow that I understood your question correctly, I wrote a little function that might help you out:\n\n```\nfunction multiplyMatrix(m1, m2) {\n    var result = [];\n    for(var j = 0; j < m2.length; j++) {\n        result[j] = [];\n        for(var k = 0; k < m1[0].length; k++) {\n            var sum = 0;\n            for(var i = 0; i < m1.length; i++) {\n                sum += m1[i][k] * m2[j][i];\n            }\n            result[j].push(sum);\n        }\n    }\n    return result;\n}\n\nmultiplyMatrix(m1, m2);\n\n// => [ [2, 4, 2] ]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Differences between matrix multiplication and array dot\r\n                \r\nI am new to Python. I have a trouble doing matrix multiplication. I have two lists:\n\n```\n      A =[3.0,3.0]    \n      # 1 by 2 matrix\n\n      B =[[ 50.33112583, -49.66887417],\n           [-49.66887417,  50.33112583]]\n      # 2 by 2 matrix \n\n      Result should be :\n      # 1 by 2 matrix\n      c = [1.9867549668874176, 1.986754966887446] \n\n\n      Right now I am doing:\n     >> A = numpy.matrix(A)\n     >> B = numpy.matrix(B)\n\n     >> C =A * B  \n     >> C\n        matrix([[ 1.98675497,  1.98675497]])\n\n     >>C.tolist()\n       [[1.9867549668874176, 1.986754966887446]]\n```\n\n\nIf I do dot product then, \n\n```\n    >>> B =numpy.array(B)\n    >>> B\n    array([[ 50.33112583, -49.66887417],\n   [-49.66887417,  50.33112583]])\n    >>> A = [ 3.,  3.]\n    >>> A =numpy.array(A)\n    >>> A\n      array([ 3.,  3.])\n    >>> C = numpy.dot(A,B)\n    >>> C\n    array([ 1.98675497,  1.98675497])\n    >>> C.tolist()\n    [1.9867549668874176, 1.986754966887446]\n```\n\n\nWhy I am getting two brackets when I use matrix multiplication?? Whether dot product and matrix multiplication are same here? Can some one explain me this??\n    ", "Answer": "\r\nWhen you use ```\nnp.matrix()```\n it is by definition a 2-D container and the operations must be performed between 2-D entities and will return 2-D entities:\n\n```\nnp.matrix([[1,2,3], [4,5,6]])*[[1], [2], [3]]\n#matrix([[14],\n#        [32]])\n\nnp.matrix([[1,2,3], [4,5,6]])*[1, 2, 3]\n#ValueError\n```\n\n\nWhen you use a ```\nnp.array()```\n in tha case of ```\ndot()```\n between two 2-D arrays the result is a 2-D array; while between a 2-D array and a 1-D array the result is a 1-D array:\n\n```\nnp.array([[1,2,3], [4,5,6]]).dot([[1], [2], [3]])\n#array([[14],\n#       [32]])\n\nnp.array([[1,2,3], [4,5,6]]).dot([1, 2, 3])\n#array([14, 32])\n```\n\n\nMore complex and flexible broadcasting rules for arrays are available when element-wise operations are desired. Here is how each row can be multiplied by a different scalar:\n\n```\nnp.array([[1,2,3], [4,5,6]])*[[1], [2]]\n#array([[ 1,  2,  3],\n#       [ 8, 10, 12]])\n```\n\n\nand how each column can be multiplied by a different scalar:\n\n```\nnp.array([[1,2,3], [4,5,6]])*[1, 2, 3]\n#array([[ 1,  4,  9],\n#       [ 4, 10, 18]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Boolean Matrix Multiplication in Matlab\r\n                \r\nDoes Matlab have a Boolean (sometimes called logical or binary) matrix multiplication function? I'm specifically talking about what's usually denoted by a circle with a dot in it to denote Boolean matrix multiplication:\n\n```\ncij = (ai1 & b1j) || (ai2 & b2j) || (ai3 & b3j)|| ... || (aik & bkj)\n```\n\n\nI have had a hard time locating one and am now assuming one does not exist. If that is the case, is there a quick way to write a .m file that will accomplish this task?\n\nAn example would be:\n\n```\n[1 1 1;                [1 0 1;      [1 1 1\n 1 0 1;   *circledot*   1 0 0;   =   1 1 1\n 1 0 0]                 0 1 0]       1 0 1]\n```\n\n    ", "Answer": "\r\nYou can just allow MATLAB to perform standard matrix multiplication and convert the result to ```\nlogical```\n:\n\n```\nb1 = [1,1,1;1,0,1;1,0,0]\nb2 = [1,0,1;1,0,0;0,1,0]\nbout = (b1*b2)>0 % or logical(b1*b2) as per natan's answer!\n\nbout =\n\n     1     1     1\n     1     1     1\n     1     0     1\n```\n\n\nHowever, if you want to faithfully perform the logical AND-OR operations of the Boolean matrix multiplication operator, you can do it with ```\nbsxfun```\n and ```\nany```\n as follows:\n\n```\nbout = any(bsxfun(@and,permute(b2,[3 2 1]),permute(b1,[1 3 2])),3);\n```\n\n\nThat pretty well obfuscates the process, but it follows the formula.\n\nQuick test data:  ```\nb1 = randi(2,M,N)-1; b2 = randi(2,N,M)-1;```\n.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to perform efficient sparse matrix multiplication by using tf.matmul?\r\n                \r\nI'm trying to perform a sparse matrix multiplication by using tf.matmul().\n\nHowever, the inference speed is much more slower than dense matrix multiplication.\n\nAccording to the description in tf.sparse_matmul() :\n\n\nThe breakeven for using this versus a dense matrix multiply on one platform was 30% zero values in the sparse matrix.\n\n\nThus , I make the sparse matrix with 7/8 zero values.\n\nHere is my code:\n\n```\nimport tensorflow as tf\nimport numpy as np\nimport time\na = tf.Variable(np.arange(1000).reshape(250,4) ,dtype=tf.float32) #dense matrix\nb = tf.Variable(np.array([0,0,0,0,0,0,0,1],dtype=np.float32).reshape(4,2),dtype=tf.float32) # sparse matrix\nc = tf.matmul(a,b,b_is_sparse=True) # do the sparse matrix multiplication\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    num_iteration = 5000\n    num_burnin = 50\n    duration = 0\n\n    for i in range(num_iteration+num_burnin):\n        startTime  = time.time()\n        result = sess.run(c)\n        endTime = time.time()\n        if i > num_burnin :\n            duration+= endTime-startTime\n\n   print(\" Average Inference Time = %.3f  ms\"%(duration*1000/num_iteration))\n```\n\n\nI set \"b_is_sparse=True\" to do a sparse matrix multiplication , and it takes about 0.380 ms on my GeForce GTX 960M.\n\nHowever , if I set \"b_is_sparse=False\" to do a dense matrix multiplication , it takes about 0.280 ms.\n\nI have tried to use tf.sparse_tensor_dense_matmul and tf.embedding_lookup_sparse to perform sparse matrix multiplication , but  the inference speed is still slower than dense matrix multiplication.\n\nIs there something wrong in my code or other way to perform sparse matrix multiplication ?\n\nAny advice will be greatly appreciated!!\n    ", "Answer": "\r\nThe relative performance depends on many factor. Sparse multiplication can be faster than dense multiplication with dense matrix (hopefully), but you are right that it can also be slower.\n\nFor one thing, it depends on the size of your matrix.\n\nHere is the result of the multiplication of two square matrices, one random and one filled with zeros, and recorded the computation time for dense and spare multiplication.\n\n\n\nAs you can see, even with a completely zero matrix, sparse multiplication can be slower than dense multiplication for smaller matrix size -- in fact almost three times slower for matrices about ```\n120x120```\n. In this experiment on my computer, sparse matrix multiplication starts taking over for sizes of about ```\n700x700```\n and ends up being about 2 times faster. Of course YMMV depending on your configuration.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Masked Matrix multiplication\r\n                \r\nI have a ```\nA = N x M```\n matrix and another array ```\nB = N x P x M```\n where P is typically ```\n9```\n or ```\n15```\n. For each vector ```\na```\n from ```\nA```\n, it has to be multiplied with each ```\npi```\n from ```\nB```\n of the same row, to get an output of dimensions ```\nN x P```\n.\nI am using numpy and Python and would be performing this operation on a GPU.\nFor a tiny example, let ```\nN```\n=```\n4```\n, ```\nM```\n=```\n5```\n, ```\nP```\n=```\n3```\n.\nLet A be:\n```\narray([[0.18503431, 0.2628188 , 0.26343728, 0.8356702 , 0.47581551],\n       [0.70827725, 0.04006919, 0.58975722, 0.90874113, 0.43946412],\n       [0.40669507, 0.63328008, 0.95832881, 0.59041436, 0.63578578],\n       [0.12129919, 0.74470057, 0.62271405, 0.97760796, 0.6499647 ]])\n```\n\nLet B be:\n```\narray([[[4.29031165e-01, 6.17324572e-01, 6.54726975e-02, 1.72218768e-02, 3.53970827e-01],\n        [3.38821841e-01, 3.80128792e-01, 7.70995505e-01, 7.38437494e-03, 5.87395036e-02],\n        [4.75661932e-01, 3.75617802e-01, 1.28564731e-01, 3.66302247e-01, 6.70953890e-01]],\n\n       [[8.96228996e-02, 1.67135584e-02, 4.56921778e-01, 8.25731354e-01, 7.66242539e-01],\n        [5.16651815e-01, 4.27179773e-01, 9.34673912e-01, 2.04687170e-01, 7.68417953e-01],\n        [5.90980849e-01, 5.03013376e-01, 8.41765736e-02, 8.08221224e-01, 7.76765422e-01]],\n\n       [[3.25802668e-01, 8.58148960e-01, 9.47505735e-01, 1.01405305e-01, 8.34114717e-01],\n        [1.65308159e-01, 9.74572631e-01, 2.69886016e-01, 7.44036253e-02, 4.73350521e-01],\n        [8.59030672e-01, 3.96972621e-01, 7.34687493e-01, 2.84647032e-02, 7.19723378e-01]],\n\n       [[1.35751242e-01, 1.74882898e-01, 5.48875709e-01, 7.33443675e-01, 4.05282650e-01],\n        [8.41298770e-01, 6.24323279e-01, 5.83482185e-01, 4.28514313e-01, 1.96797205e-01],\n        [7.93345700e-04, 3.01441721e-01, 7.59451146e-01, 9.09102382e-01, 7.11518948e-01]]])\n```\n\nThis is how I want my output to be:\n```\n[[np.dot(a[0], b[0][0]), np.dot(a[0], b[0][1]), np.dot(a[0], b[0][2])],\n[np.dot(a[1], b[1][0]), np.dot(a[1], b[1][1]), np.dot(a[1], b[1][2])],\n[np.dot(a[2], b[2][0]), np.dot(a[2], b[2][1]), np.dot(a[2], b[2][2])],\n[np.dot(a[3], b[3][0]), np.dot(a[3], b[3][1]), np.dot(a[3], b[3][2])]]\n```\n\nDoing this manually gives:\n```\n[[0.44169455751462816, 0.3998276862221848, 0.845960080871557],\n[1.4207326179275017, 1.4579799277670968, 1.564201768913105],\n[2.174162453912622, 1.287925491552765, 1.779226448174152],\n[1.4689343122491012, 1.4771555510001255, 2.0487088726424365]]\n```\n\nSince I want to do this on a GPU, this obviously calls for converting my problem into matrix multiplication (this is true if I dont use a GPU as well for that matter).\nBut I do not exactly know how to convert it to that.\nOne idea that I had was to reshape B to be ```\nQ x M```\n where ```\nQ=NxP```\n. And then perform some sort of sparse multiplication, where for every row ```\ni```\n of a boolean sparse matrix, I turn on ```\n(0:P) + P*i```\nth elements. (Drawing it out makes sense), however I certainly feel that there is a much more elegant way to do this as creating sparse matrices and performing the operations might take time, and that the sparsity of my matrix is not random at all.\nHow can I solve this elegantly.\nNote that I cannot do some operations such as broadcasting/repeating my ```\nA```\n matrix ```\nP```\n times and performing the huge matrix multiplication and picking out relevant values, since typically ```\nN```\n and ```\nM```\n will be quite huge (```\n2000```\nish and ```\n256```\n respectively), but ```\nP```\n will be quite small, hence doing a global matrix multiplication for all vectors means I will be doing >95% unnecessary computations!.\n    ", "Answer": "\r\nYou can use ```\neinsum```\n here to compute this efficiently.\n\n```\nnp.einsum('ij,ikj->ik', A, B) # or torch.einsum\n```\n\n\n```\n>>> np.allclose(np.einsum('ij,ikj->ik', A, B), manual)\nTrue\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication In C\r\n                \r\nI'm trying to solve a matrix multiplication problem with C. Matrix sizes given in problem (2x2)\nI wrote this code but it doesn't print result as I expect. I think I'm missing a point about rules of C.\n\nWhat is my mistake in this code ?\n\n```\n#include <stdio.h>\nint main() {\n    int matA[2][2]={0,1,2,3};\n    int matB[2][2]={0,1,2,3};\n    int matC[2][2];\n    int i, j, k;\n    for (i = 0; i < 2; i++) {\n        for(j = 0; j < 2; j++) {\n            for(k = 0; k < 2; k++) {\n                matC[i][j] += matA[i][k] * matB[k][j];\n            }\n            printf(\"%d\\n\",matC[i][j]);\n        } \n    }\n}\n```\n\n\nPrinting Result:\n\n```\n2 \n3 \n4195350\n11\n```\n\n    ", "Answer": "\r\nHere is the matrix multiplication code I use:\n\n```\nfor(i=0;i<M;i++){\n    for(j=0;j<K;j++){\n        matC[i][j]=0;\n        for(k=0;k<N;k++){\n            matC[i][j]+=matA[i][k]*matB[k][j];\n        }\n    }\n}\n```\n\n\nbig thing is setting the answer matrix to zero (as the rest have said without code).\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Python Matrix Multiplication,\r\n                \r\nI'm trying to create a python program to perform the strassen and regular matrix multiplication methods. However, when I try to run my strassen function with the randomly generated matrix created with the createRandom Matrix function, get this error:\n\n```\nTraceback (most recent call last):\n  File \"matrixMult.py\", line 106, in <module>\n    print strassen(c, d, 10)\n  File \"matrixMult.py\", line 77, in strassen\n    p1 = strassen(addMatrix(a11,a22), addMatrix(b11,b22), n/2)\n  File \"matrixMult.py\", line 78, in strassen\n    p2 = strassen(addMatrix(a21,a22), b11, n/2)\n  File \"matrixMult.py\", line 82, in strassen\n    p6 = strassen(subMatrix(a21,a11), addMatrix(b11,b12), n/2)\n  File \"matrixMult.py\", line 62, in subMatrix\n    c.append(a[i][j] - b[i][j]) \n  IndexError: list index out of range\n```\n\n\nHere's the code. I randomly create a 10x10 matrix, then try to perform Strassen with it, and I get the preceding error. However, when I use the simple 4x4 matrices I have defined at the end, strassen works fine, and it seems my random matrices are being generated without a problem, so I'm not sure where the issue is. Anyone have any ideas?\n\n```\nimport random\nimport time\n\nrandom.seed()\n\n\ndef createEmptyMatrix(x, y): # create empty matrix\n    matrix = [[0 for row in range(x)] for col in range(y)]\n    return matrix\n\ndef createRandomMatrix(size): # create matrix filled with random ints\n    matrix = []\n    matrix = [[random.randint(1,20) for row in range(size)] for col in range(10)]\n    return matrix\n\ndef regular(a, b): # standard O(n^3) matrix multiplication\n    c = createEmptyMatrix(len(a), len(b[0]))\n    for i in range(len(a)):\n        for j in range(len(b[0])):\n            for k in range(len(b)):\n                c[i][j] += a[i][k]*b[k][j]\n    return c\n\ndef split(matrix): # split matrix into quarters for strassen\n    a = matrix\n    b = matrix\n    c = matrix\n    d = matrix\n    while(len(a) > len(matrix)/2):\n        a = a[:len(a)/2]\n        b = b[:len(b)/2]\n        c = c[len(c)/2:]\n        d = d[len(d)/2:]\n    while(len(a[0]) > len(matrix[0])/2):\n        for i in range(len(a[0])/2):\n            a[i] = a[i][:len(a[i])/2]\n            b[i] = b[i][len(b[i])/2:]\n            c[i] = c[i][:len(c[i])/2]\n            d[i] = d[i][len(d[i])/2:]\n    return a,b,c,d\n\ndef addMatrix(a, b): # add 2 matrices\n    d = []\n    for i in range(len(a)):\n        c = []\n        for j in range(len(a[0])):\n            c.append(a[i][j] + b[i][j])\n        d.append(c)\n    return d\n\ndef subMatrix(a, b): # subtract 2 matrices\n    d = []\n    for i in range(len(a)):\n        c = []\n        for j in range(len(a[0])):\n            c.append(a[i][j] - b[i][j])\n        d.append(c)\n    return d\n\n\ndef strassen(a, b, n): # strassen matrix multiplication method\n    #base case\n    if n == 1:\n        d = [[0]]\n        d[0][0] = a[0][0] * b[0][0]\n        return d\n    else:\n        a11, a12, a21, a22 = split(a)\n        b11, b12, b21, b22 = split(b)\n\n        p1 = strassen(addMatrix(a11,a22), addMatrix(b11,b22), n/2)\n    p2 = strassen(addMatrix(a21,a22), b11, n/2)\n    p3 = strassen(a11, subMatrix(b12,b22), n/2)\n    p4 = strassen(a22, subMatrix(b21,b11), n/2)\n    p5 = strassen(addMatrix(a11,a12), b22, n/2)\n    p6 = strassen(subMatrix(a21,a11), addMatrix(b11,b12), n/2)\n    p7 = strassen(subMatrix(a12,a22), addMatrix(b21,b22), n/2)\n\n    c11 = addMatrix(subMatrix(addMatrix(p1, p4), p5), p7)\n    c12 = addMatrix(p3, p5)\n    c21 = addMatrix(p2, p4)\n    c22 = addMatrix(subMatrix(addMatrix(p1, p3), p2), p6)\n\n        c = createEmptyMatrix(len(c11)*2,len(c11)*2)\n\n    for i in range(len(c11)):\n            for j in range(len(c11)):\n                c[i][j]                   = c11[i][j]\n                c[i][j+len(c11)]          = c12[i][j]\n                c[i+len(c11)][j]          = c21[i][j]\n                c[i+len(c11)][j+len(c11)] = c22[i][j]\n\n        return c\n\na = [[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]]\nb = [[5,5,5,5],[6,6,6,6],[7,7,7,7],[8,8,8,8]]\nc = createRandomMatrix(10)\nd = createRandomMatrix(10)\nprint \"Strassen Outputs:\"\n#print strassen(c, d, 10)\nprint \"Should be:\"\nprint regular(c, d)\nprint c\nprint d\n\nprint a\nprint b\nprint strassen(a, b, 4)\n```\n\n    ", "Answer": "\r\nI would recommend using ```\nnumpy```\n, in which you can use matrices easily and all these functions already exist.\n\nIn the meantime, if you run into index errors in this function try adding something like an ```\nassert```\n:\n\n```\ndef subMatrix(a, b): # subtract 2 matrices\n    assert len(a) == len(b), \"Number of rows does not match!\"\n    assert len(a[0]) == len(b[0]), \"Number of columns does not match!\"\n    d = []\n    for i in range(len(a)):\n        c = []\n        for j in range(len(a[0])):\n            c.append(a[i][j] - b[i][j])\n        d.append(c)\n    return d\n```\n\n\nHowever you don't need to write this function at all:\n\n```\nimport numpy as np\na = np.matrix(np.random.randint(10, size=(3,3)))\nb = np.matrix(np.random.randint(10, size=(3,))).T\n\nc = a * b\nd = a - b\n\nprint a\n[[5 8 1]\n [7 6 1]\n [9 2 9]]\n\nprint b\n[[5]\n [2]\n [4]]\n\nprint c\n[[45]\n [51]\n [85]]\n\nprint d\n[[ 0  3 -4]\n [ 5  4 -1]\n [ 5 -2  5]]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Columnwise Matrix Multiplication\r\n                \r\nDo you know what is \"Columnwise Matrix Multiplication\"? I searched for it but couldn't find any explanation about the algorithm or a pseudo code.\n\nIt would be great if somebody explains that.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication using C++\r\n                \r\n(r1,c1) and (r2,c2) are number of Rows and columns of matrix a[][] and matrix b[][]\nmatrix c[][] is the matrix multiplication of a[][] and b[][]\nThe user enters the number of rows and columns of a[][] and b[][] and enters elements of both.\n\nthis is the output given by the complete program for specific a[][], b[][]\n\n\n  the expected output of the program for the same a[][] and b[][] is:\n  c[2][2]={{7,14},{17,34}}\n\n\nHowever, I cant seem to find the error in the logic.\n\nthe following part of the code is the logic to carry out the matrix multiplication \n\n```\nfor (i = 0; i < r1; i++) {\n  for (j = 0; j < c2; j++) {\n    c[i][j] = 0;\n    for (k = 0; k < c1; k++) {\n      c[i][j] += a[i][j] * b[k][j];\n    }\n  }\n}\nfor (i = 0; i < r1; i++) {\n  for (j = 0; j < c2; j++) {\n    printf(\"%d \", c[i][j]);\n  }\n  printf(\"\\n\");\n}     \n```\n\n    ", "Answer": "\r\nYou are doing math incorrectly.\n\nAccording to mat multiplication,\n\n\n\n```\nfor(i=0 ; i<r1 ; i++)\n{\n    for(j=0 ; j<c2 ; j++) \n    {\n\n        c[i][j]=0; \n        for(k=0 ; k<c1 ; k++)  \n        {\n            c[i][j]+=a[i][j]*b[k][j];\n                      //--^-- should be k \n        }\n    }\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication function?\r\n                \r\nHow do you write a matrix multiplication function? Takes two matrices outputs one.\nThe documentation on assemblyscript.org is pretty short, Float64Array though is a valid type among these but that's 1D so...\n    ", "Answer": "\r\nAssemblyScript's stdlib is modeled after JavaScript's stdlib, so there are no matrix operations.  However, here is a library that might work for you: https://github.com/JustinParratt/big-mult\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "modifying matrix multiplication in matlab\r\n                \r\nI would like to have MATLAB perform matrix multiplication, where all multiply operations are replace by plus operation.\n\nHere is an example:\n\n```\na = [3,4; 5,6];\nb = [1;2];\n\nc = modified_multiplication(a,b); %  = [3+1+4+2 ; 5+1+6+2] =  [10 , 14].\n```\n\n\nHow can I do this as efficient as the original * operation?\n    ", "Answer": "\r\nYour best bet is going to be to combine ```\nbsxfun```\n with ```\nsum```\n.\n\n```\nc = sum(bsxfun(@plus, a, b.'), 1);\n%   10  14\n```\n\n\nThe ```\nbsxfun```\n call adds the first entry of ```\nb```\n to all elements in the first row of ```\na```\n and the second entry of ```\nb```\n to all the elements in the second row of ```\na```\n, etc.. \n\n```\nbsxfun(@plus, a, b.')\n%   4   6\n%   6   8\n```\n\n\nThen the application of ```\nsum```\n, sums down the columns.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in R: requires numeric/complex matrix/vector arguments\r\n                \r\nI'm using the dataset ```\nBreastCancer```\n in the ```\nmlbench```\n package, and I am trying to do the following matrix multiplication as a part of logistic regression.\n\nI got the features in the first 10 columns, and create a vector of parameters called theta:\n\n```\nX <- BreastCancer[, 1:10]\ntheta <- data.frame(rep(1, 10))\n```\n\n\nThen I did the following matrix multiplication:\n\n```\nconstant <- as.matrix(X) %*% as.vector(theta[, 1])\n```\n\n\nHowever, I got the following error:\n\n```\nError in as.matrix(X) %*% as.vector(theta[, 1]) : \n  requires numeric/complex matrix/vector arguments\n```\n\n\nDo I need to cast the matrix to double using ```\nas.numeric(X)```\n first? Values in ```\nX```\n look like strings as they have double quotes.\n    ", "Answer": "\r\nMatrix-multiplication operators / functions like ```\n\"%*%\"```\n, ```\ncrossprod```\n, ```\ntcrossprod```\n expect matrices with \"numeric\", \"complex\" or \"logical\" mode. However, your matrix has \"character\" mode.\n```\nlibrary(mlbench)\ndata(BreastCancer)\nX <- as.matrix(BreastCancer[, 1:10])\nmode(X)\n#[1] \"character\"\n```\n\nYou might be surprised as the dataset seems to hold numeric data:\n```\nhead(BreastCancer[, 1:10])\n#       Id Cl.thickness Cell.size Cell.shape Marg.adhesion Epith.c.size\n#1 1000025            5         1          1             1            2\n#2 1002945            5         4          4             5            7\n#3 1015425            3         1          1             1            2\n#4 1016277            6         8          8             1            3\n#5 1017023            4         1          1             3            2\n#6 1017122            8        10         10             8            7\n#  Bare.nuclei Bl.cromatin Normal.nucleoli Mitoses\n#1           1           3               1       1\n#2          10           3               2       1\n#3           2           3               1       1\n#4           4           3               7       1\n#5           1           3               1       1\n#6          10           9               7       1\n```\n\nBut you are misinformed by the printing style. These columns are in fact characters or factors:\n```\nlapply(BreastCancer[, 1:10], class)\n#$Id\n#[1] \"character\"\n#\n#$Cl.thickness\n#[1] \"ordered\" \"factor\" \n#\n#$Cell.size\n#[1] \"ordered\" \"factor\" \n#\n#$Cell.shape\n#[1] \"ordered\" \"factor\" \n#\n#$Marg.adhesion\n#[1] \"ordered\" \"factor\" \n#\n#$Epith.c.size\n#[1] \"ordered\" \"factor\" \n#\n#$Bare.nuclei\n#[1] \"factor\"\n#\n#$Bl.cromatin\n#[1] \"factor\"\n#\n#$Normal.nucleoli\n#[1] \"factor\"\n#\n#$Mitoses\n#[1] \"factor\"\n```\n\nWhen you do ```\nas.matrix```\n, these columns are all coerced to \"character\" (see R: Why am I not getting type or class \"factor\" after converting columns to factor? for a thorough explanation).\nSo to do the matrix-multiplication, we need to correctly coerce these columns to \"numeric\".\n\n```\ndat <- BreastCancer[, 1:10]\n\n## character to numeric\ndat[[1]] <- as.numeric(dat[[1]])\n\n## factor to numeric\ndat[2:10] <- lapply( dat[2:10], function (x) as.numeric(levels(x))[x] )\n\n## get the matrix\nX <- data.matrix(dat)\nmode(X)\n#[1] \"numeric\"\n```\n\nNow you can do for example, a matrix-vector multiplication.\n```\n## some possible matrix-vector multiplications\nbeta <- runif(10)\nyhat <- X %*% beta\n\n## add prediction back to data frame\ndat$prediction <- yhat\n```\n\nHowever, I doubt this is the correct way to obtain predicted values for you logistic regression model as when you build your model with factors, the model matrix is not the above ```\nX```\n but a dummy matrix. I highly recommend you using ```\npredict```\n.\n\n\nThis line also worked for me: ```\nas.matrix(sapply(dat, as.numeric))```\n\n\nLooks like you were lucky. The dataset happens to have factor levels as same as numeric values. In general, converting a factor to numeric should use the method I did. Compare\n```\nf <- gl(4, 2, labels = c(12.3, 0.5, 2.9, -11.1))\n#[1] 12.3  12.3  0.5   0.5   2.9   2.9   -11.1 -11.1\n#Levels: 12.3 0.5 2.9 -11.1\n\nas.numeric(f)\n#[1] 1 1 2 2 3 3 4 4\n\nas.numeric(levels(f))[f]\n#[1] 12.3  12.3  0.5   0.5   2.9   2.9   -11.1 -11.1\n```\n\nThis is covered at the doc page ```\n?factor```\n.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "jblas 2-d matrix multiplication\r\n                \r\nI want to compute  2d matrix-matrix multiplication using the Jblas library. But I failed every time to compute. Please help me to do this by giving an example with data.\n    ", "Answer": "\r\nThat should be fairly straightforward, just make sure that your matrices have the right size:\n```\nDoubleMatrix matA = new DoubleMatrix(2, 2, 1, 2, 3, 4);\nDoubleMatrix matB = new DoubleMatrix(2, 2, 5, 6, 7, 8);\n\nDoubleMatrix res = matA.mmul(matB);\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Encryption by matrix multiplication\r\n                \r\nWorking on a college project for simple matrix multiplication based encryption.\n\nThe project outline is such;\n\n\n  text file to matrix multiplied by encryption key matrix=\n  Encrypted file. \n  \n  Encrypted file to matrix multiplied by inverse of key matrix\n  = Decrypted file.\n\n\nBut I want to go a bit further and be able to do any file (text, mp3, gif etc etc). \n\nI have been researching for hours trying to solve this problem and am starting to get a little frustrated. \n\nThe best way (and only) I can think of is for the program to read raw binary and perform encryption on that. \n\nSo--> questions:\n\n\nCan I extract raw binary from a file, put into matrix, perform\nmatrix multiplication and (essentially) write back binary to file?\nAlso what is the viability of such a method on different computers\nand platforms? ( I am thinking that maybe if I convert from binary\nto int and on decryption convert back, it might change-- different\nsize allocations on different computers etc?)\n\n\nAlso, I am welcome to opinion on better solutions\n\n---> But the basic algorithm should be based on matrix multiplication. \n\nMy code:\n\n```\nint writetomatrix(int current_variable)\n{\n    if (counter == 9){\n        counter=0;\n        b=0;\n        a=0;}\n\n    if (b==3) b=0;\n    if (a==3) {b++;\n                a=0;}\n    counter++;\n    B[a][b]=current_variable;\n    a++;\n\n}\n    int main () {\n        int *buffer= new int[1];\n        ifstream input;\n        input.open (\"input.txt\",ios::in|ios::binary);\n        input.read ((char*)&buffer, 1);\n        writetomatrix(buffer);\n    }\n```\n\n\nThe error I get:\n\n```\ninitializing argument 1 of ‘int writetomatrix(int)’\n```\n\n    ", "Answer": "\r\nYou can read the binary file using ```\nfread```\n to an array of char or of int. As long as byte order remains the same, you can read any file and write it back. You can do what you want with the bytes or words you read. You can use ```\nsizeof```\n to know the size of an int. On most platforms today it is 4 bytes.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to get element-wise matrix multiplication (Hadamard product) in numpy?\r\n                \r\nI have two matrices \n\n```\na = np.matrix([[1,2], [3,4]])\nb = np.matrix([[5,6], [7,8]])\n```\n\n\nand I want to get the element-wise product, ```\n[[1*5,2*6], [3*7,4*8]]```\n, equaling \n\n```\n[[5,12], [21,32]]```\n\n\nI have tried\n\n```\nprint(np.dot(a,b)) \n```\n\n\nand\n\n```\nprint(a*b)\n```\n\n\nbut both give the result\n\n```\n[[19 22], [43 50]]```\n\n\nwhich is the matrix product, not the element-wise product. How can I get the the element-wise product (aka Hadamard product) using built-in functions?\n    ", "Answer": "\r\nFor elementwise multiplication of ```\nmatrix```\n objects, you can use ```\nnumpy.multiply```\n:\n\n```\nimport numpy as np\na = np.array([[1,2],[3,4]])\nb = np.array([[5,6],[7,8]])\nnp.multiply(a,b)\n```\n\n\nResult \n\n```\narray([[ 5, 12],\n       [21, 32]])\n```\n\n\nHowever, you should really use ```\narray```\n instead of ```\nmatrix```\n. ```\nmatrix```\n objects have all sorts of horrible incompatibilities with regular ndarrays. With ndarrays, you can just use ```\n*```\n for elementwise multiplication:\n\n```\na * b\n```\n\n\nIf you're on Python 3.5+, you don't even lose the ability to perform matrix multiplication with an operator, because ```\n@```\n does matrix multiplication now:\n\n```\na @ b  # matrix multiplication\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Parallel Matrix Multiplication in MATLAB\r\n                \r\nIs there a relatively easy to implement or transparent way to multiply two large matrices in Matlab in parallel? \n\nIdeally, I would like to perform this parallel multiplication with at most a few lines of code, perhaps something like:\n\n```\n    C_1 = A*B        % normal\n    C_2 = pmult(A,B) % parallel\n    % C_1 and C_2 have the same entries\n```\n\n\nIf there is a way to easily do this paralell multiplication, can someone please point me to the code? If not, does anyone have any ideas on what they feel is the best way to implement a parallel matrix multiplication algorithm in Matlab?\n\nThanks in advance, awesome Stackoverflow community.\n\nEDIT -- \nI believe that part of the issue I was running into is that matrix multiplication for sparse matrices is not automatically parallelized; it is automatically parallelized for dense matrices. New question: can Matlab do sparse matrix multiplication in parallel? (CPU parallelization as I don't have CUDA enabled graphics cards)\n    ", "Answer": "\r\nMatlab probably already does this via its implicit multithreading support. See http://www.mathworks.com/support/solutions/en/data/1-4PG4AN/?solution=1-4PG4AN; the \"*\" operator. The trivially parallelizable operations are already done for you by Matlab; just run it on a multicore machine.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication C++\r\n                \r\nI am having some trouble multiplying matrices and printing the result out. My code is as follows:\n\n```\n#include <iostream>\nusing namespace std;\nint main() {\n    int matArow, matAcol, matBrow, matBcol, itervar1, itervar2, itervar3, value;\n    cin >> matArow >> matAcol;\n    int matA[matArow][matAcol];\n    for (itervar1 = 0; itervar1 < matArow; itervar1++) {\n        for (itervar2 = 0; itervar2 < matAcol; itervar2++) {\n            cin >> matA[itervar1][itervar2];\n        }\n    }\n    cin >> matBrow >> matBcol;\n    if (matBrow != matAcol) {\n        cout << \"Impossible\\n\";\n        return 0;\n    }\n    int matB[matBrow][matBcol];\n    for (itervar1 = 0; itervar1 < matBrow; itervar1++) {\n        for (itervar2 = 0; itervar2 < matBcol; itervar2++) {\n            cin >> matB[itervar1][itervar2];\n        }\n    }\n    int matC[matArow][matBcol];\n    for (itervar1 = 0; itervar1 < matArow; itervar1++) {\n        for (itervar2 = 0; itervar2 < matBcol; itervar2++) {\n            value = 0;\n            for (itervar3 = 0; itervar3 < matAcol; itervar3++) {\n                value += matA[itervar1][itervar3];\n                value += matB[itervar3][itervar2];\n            }\n            matC[itervar1][itervar2] = value;\n        }\n    }\n    for ( itervar1 = 0; itervar1 < matArow; itervar1++ ) {\n        for ( itervar2 = 0; itervar2 < matBcol; itervar2++ ) {\n            cout << matC[itervar1][itervar2] << ' ';\n        }\n        cout << endl;\n    }\n    return 0;\n}\n```\n\n\nThe code doesn't return any errors, but results in incorrect matrix multiplication. Any help would be greatly appreciated.\n    ", "Answer": "\r\n```\nvalue += matA[itervar1][itervar3]; \nvalue += matB[itervar3][itervar2];```\n\n\nShouldn't it be\n\n```\nvalue += matA[itervar1][itervar3] * matB[itervar3][itervar2];\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Replicating Matrix-Matrix Multiplication using Tensordot\r\n                \r\nIn ```\nPyKeops```\n package, there is no available formula for Matrix-Matrix multiplication. Instead, they have implemented something similar to ```\nnumpy.tensordot```\n. I have two matrices ```\nA,B```\n of size ```\nm x n```\n and ```\nn x n```\n. Is there any way to replicate ```\nA @ B```\n using ```\nnumpy.tensordot```\n.\n```\nimport numpy as np\nm,n = 10, 20\nA = np.random.random((m,n))\nB = np.random.random((n,n))\n\nresult1 = A @ B\nresult2 = np.tensordot(A,B,(1,1))\n\nprint(result1 == result2)\n\n# =======================\n# array([[False, False, False, False, False, False, False, False, \n# ....\n```\n\n    ", "Answer": "\r\nOkay I found an answer to this, we can fix this using the following parameters given to ```\ntensordot```\n:\n```\nimport numpy as np\nm,n = 10, 20\nA = np.random.random((m,n))\nB = np.random.random((n,n))\n\nresult1 = A @ B\nresult2 = np.tensordot(A,B,[(1,),(0,)])\n\nprint(result1 == result2)\n\n# =======================\n# array([[True,  True,  True,  True,  True,  True,  True,  True,  True, \n# ....\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "OpenMP for matrix multiplication\r\n                \r\nI am new to OpenMP and am trying desperately to learn. I have tried to write an example code in C++ in visual studio 2012 to implement matrix multiplication. I was hoping someone with OpenMP experience could take a look at this code and help me to obtain the ultimate speed / parallelization for this:\n\n```\n#include <iostream>\n#include <stdlib.h>\n#include <omp.h>\n#include <random>\nusing namespace std;\n\n#define NUM_THREADS 4\n\n// Program Variables\ndouble**        A;\ndouble**        B;\ndouble**        C;\ndouble          t_Start;\ndouble          t_Stop;\nint             Am;\nint             An;\nint             Bm;\nint             Bn;\n\n// Program Functions\nvoid            Get_Matrix();\nvoid            Mat_Mult_Serial();\nvoid            Mat_Mult_Parallel();\nvoid            Delete_Matrix();\n\n\nint main()\n{\n    printf(\"Matrix Multiplication Program\\n\\n\");\n    cout << \"Enter Size of Matrix A: \";\n    cin >> Am >> An;\n    cout << \"Enter Size of Matrix B: \";\n    cin >> Bm >> Bn;\n\n    Get_Matrix();\n    Mat_Mult_Serial();\n    Mat_Mult_Parallel();\n\n\n    system(\"pause\");\n    return 0;\n\n}\n\n\nvoid Get_Matrix()\n{\n    A = new double*[Am];\n    B = new double*[Bm];\n    C = new double*[Am];\n    for ( int i=0; i<Am; i++ ){A[i] = new double[An];}\n    for ( int i=0; i<Bm; i++ ){B[i] = new double[Bn];}\n    for ( int i=0; i<Am; i++ ){C[i] = new double[Bn]; }\n\n    for ( int i=0; i<Am; i++ )\n    {\n         for ( int j=0; j<An; j++ )\n         {\n             A[i][j]= rand() % 10 + 1;\n         }\n    }\n\n    for ( int i=0; i<Bm; i++ )\n    {\n        for ( int j=0; j<Bn; j++ )\n        {\n            B[i][j]= rand() % 10 + 1;\n        }\n    }\n    printf(\"Matrix Create Complete.\\n\");\n}\n\n\nvoid Mat_Mult_Serial()\n{\n    t_Start = omp_get_wtime();\n    for ( int i=0; i<Am; i++ )\n    {\n        for ( int j=0; j<Bn; j++ )\n        {\n            double temp = 0;\n            for ( int k=0; k<An; k++ )\n            {\n                temp += A[i][k]*B[k][j];\n            }\n        }\n    }\n    t_Stop = omp_get_wtime() - t_Start;\n    cout << \"Serial Multiplication Time: \" << t_Stop << \" seconds\" << endl;\n    }\n\n\nvoid Mat_Mult_Parallel()\n{\n    int i,j,k;\n    t_Start = omp_get_wtime();\n\n    omp_set_num_threads(NUM_THREADS);\n    #pragma omp parallel for private(i,j,k) schedule(dynamic)\n    for ( i=0; i<Am; i++ )\n    {\n        for ( j=0; j<Bn; j++ )\n        {\n            //double temp = 0;\n            for ( k=0; k<An; k++ )\n            {\n                C[i][j] += A[i][k]*B[k][j];\n            }\n        }\n    }\n\n    t_Stop = omp_get_wtime() - t_Start;\n    cout << \"Parallel Multiplication Time: \" << t_Stop << \" seconds.\" << endl;\n}\n\n\nvoid Delete_Matrix()\n{\n    for ( int i=0; i<Am; i++ ){ delete [] A[i]; }\n    for ( int i=0; i<Bm; i++ ){ delete [] B[i]; }\n    for ( int i=0; i<Am; i++ ){ delete [] C[i]; }\n\n    delete [] A;\n    delete [] B;\n    delete [] B;\n}\n```\n\n    ", "Answer": "\r\nMy examples are based on a matrix class I created for parallel teaching. If you are interested feel free to contact me.\nThere are several ways to speedup your matrix multiplication :\n\nStorage\n\nUse a one dimension array in row major order for accessing the element in a faster way.\nYou can access to A(i,j) with A[i * An + j]  \n\nUse loop invariant optimization\n\n```\nfor (int i = 0; i < m; i ++)\n    for (int j = 0; j < p; j ++)\n    {\n        Scalar sigma = C(i, j);\n        for (int k = 0; k < n; k ++)\n            sigma += (*this)(i, k) * B(k, j);\n        C(i, j) = sigma;\n    }\n```\n\n\nThis prevents to recompute C(i,j) several times in the most inner loop.\n\nChange loop order \"for k <-> for i\"\n\n```\nfor (int i = 0; i < m; i ++)\n    for (int k = 0; k < n; k ++)\n    {\n        Aik = (*this)(i, k);\n        for (int j = 0; j < p; j ++)\n            C(i, j) += Aik * B(k, j);\n    }\n```\n\n\nThis allows to play with spatial data locality \n\nUse loop blocking/tiling\n\n```\nfor(int ii = 0; ii < m; ii += block_size)\n    for(int jj = 0; jj < p; jj += block_size)\n        for(int kk = 0; kk < n; kk += block_size)\n            #pragma omp parallel for // I think this is the best place for this case\n            for(int i = ii; i < ii + block_size; i ++)\n                for(int k = kk; k < kk + block_size; k ++)\n                {\n                    Scalar Aik = (*this)(i, k);\n                    for(int j = jj; j < jj + block_size; j ++)\n                        C(i, j) +=  Aik * B(k, j);\n                }\n```\n\n\nThis can use better temporal data locality. The optimal block_size depends on your architecture and matrix size.\n\nThen parallelize !\n\nGenerally, the #pragma omp parallel for should be done a the most outter loop. Maybe using two parallel loop at the two first outter loops can give better results. It depends then on the architecture you use, the matrix size... You have to test !\nSince the matrix multiplication has a static workload I would use a static schedule.\n\nMoar optimization !\n\nYou can do loop nest optimization.\nYou can vectorize your code.\nYou can take look at how BLAS do it. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "MySQL matrix multiplication\r\n                \r\nI am trying to write matrix multiplication for MySQL and am kinda stuck: \n\nbasically, my matrices are stored in format\n[row#, column#, matrixID, value], so for example matrix [3 x 2] would be something like:\n\n```\n[row#, column#, matrixID, value]\n  1      1        mat01    1\n  1      2        mat01    2\n  1      3        mat01    3\n  2      1        mat01    4\n  2      2        mat01    5\n  2      3        mat01    6\n```\n\n\nbeing equivalent to: [[1 2 3],[4 5 6]]\n\nfollowing does calculation of single element of matrix1 * matrix2 quite well: \n\n```\n   SELECT SUM(row1.`val` * col2.`val`)\n   FROM matValues row1\n   INNER JOIN  `matValues` col2\n   WHERE row1.`row` = 1 AND row1.`mID`='matrix1' AND \n         col2.`mID`='matrix2' AND col2.`col` = 1 AND row1.col = col2.row\n```\n\n\nwrapping this into function and then using another function to iterate over row and column numbers might work, but I have problems with generating this set of numbers and iterating over them using SQL. \nAny advice / suggestions are welcome\n    ", "Answer": "\r\nTry:\n\n```\nselect m1.`row#`, m2.`column#`, sum(m1.value*m2.value) \nfrom matValues m1\njoin matValues m2 on m2.`row#` = m1.`column#` \nwhere m1.matrixID = 'mat01' and m2.matrixID = 'mat02'\ngroup by m1.`row#`, m2.`column#`\n```\n\n\nExample here.\n\n(Replace ```\n'mat01'```\n and ```\n'mat02'```\n with suitable ```\nmatrixID```\n values.)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Cublas matrix-matrix multiplication parameters\r\n                \r\nI'm trying to do a matrix-matrix multiplication using Cublas but it still not work and I don't figure out the problem.\nSince it is the first time I use Cublas I'm not sure that I set the right parameter, especially for the leading dimension\nFor example:\n```\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n#include \"cublas_v2.h\"\n#include <stdio.h>\n\nvoid mulWithCuda(double *c, const double *a, const double *b, unsigned int size);\n\nint main(){\n    const int arraySize = 9;\n    const double a[12] = { 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10, 11, 12 };\n    const double b[arraySize] = { 10, 20, 30, 40, 50, 60, 70, 80, 90 };\n    double c[12] = { 0 };\n\n    mulWithCuda(c, a, b, arraySize);\n\n    for (int i = 0; i < 4; i++) {\n        for (int j = 0; j < 3; j++) {\n            printf(\"%lf \", c[i * 3 + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n\nvoid mulWithCuda(double* c, const double* a, const double* b, unsigned int size){\n    double *dev_a = 0;\n    double *dev_b = 0;\n    double *dev_c = 0;\n\n    cudaMalloc((void**)&dev_c, 12 * sizeof(double));\n    cudaMalloc((void**)&dev_a, size * sizeof(double));\n    cudaMalloc((void**)&dev_b, 12 * sizeof(double));\n\n    cudaMemcpy(dev_a, a, 12 * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(dev_b, b, size * sizeof(double), cudaMemcpyHostToDevice);\n    \n    cublasHandle_t handle;\n    cublasCreate(&handle);\n\n    double alpha = 1.0;\n    double beta = 0;\n\n    cublasDgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, 4, 3, 3, &alpha, dev_a, 3, dev_b, 3, &beta, dev_c, 3);\n\n    cudaMemcpy(c, dev_c, 12 * sizeof(double), cudaMemcpyDeviceToHost);\n   \n    cublasDestroy(handle);\n\n    cudaFree(dev_c);\n    cudaFree(dev_a);\n    cudaFree(dev_b);\n}\n```\n\nThe two matrix used are:\n```\n1 2 3\n4 5 6\n7 8 9\n10 11 12\n\n\n10 20 30\n40 50 60\n70 80 90\n```\n\nwhile the output is:\n```\n ** On entry to DGEMM  parameter number 8 had an illegal value\n0.000000 0.000000 0.000000\n0.000000 0.000000 0.000000\n0.000000 0.000000 0.000000\n0.000000 0.000000 0.000000\n```\n\n    ", "Answer": "\r\nThere are 3 problems with your code.\n\nYou are not checking for CUDA errors or cuBLAS errors. CUDA error checking  is described here What is the canonical way to check for errors using the CUDA runtime API?\n\nWith proper error checking you will find that ```\ncudaMemcpy(dev_b, b, size * sizeof(double), cudaMemcpyHostToDevice);```\n fails because of illegal memory accesses. ```\ndev_a```\n and ```\ndev_b```\n have been allocated with the wrong size. It should be 12 for dev_a and size for dev_b .\n\nYou make wrong assumption about the memory layout of the matrix. cuBLAS uses a column-major storage format. https://docs.nvidia.com/cuda/cublas/index.html#data-layout\n\n\nThis means that the leading dimensions of A and C are 4, not 3. This also means that A and B are\n```\n1 5 9\n2 6 10\n3 7 11\n4 8 12\n\nand\n\n10 40 70\n20 50 80\n30 60 90\n\n,respectively\n```\n\nPrinting of C must also be changed to account for column-major format\nWorking code:\n```\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n#include \"cublas_v2.h\"\n#include <stdio.h>\n\nvoid mulWithCuda(double *c, const double *a, const double *b, unsigned int size);\n\nint main(){\n    const int arraySize = 9;\n    const double a[12] = { 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10, 11, 12 };\n    const double b[arraySize] = { 10, 20, 30, 40, 50, 60, 70, 80, 90 };\n    double c[12] = { 0 };\n\n    mulWithCuda(c, a, b, arraySize);\n\n    for (int i = 0; i < 4; i++) {\n        for (int j = 0; j < 3; j++) {\n            printf(\"%lf \", c[j * 4 + i]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n\nvoid mulWithCuda(double* c, const double* a, const double* b, unsigned int size){\n    double *dev_a = 0;\n    double *dev_b = 0;\n    double *dev_c = 0;\n\n    cudaMalloc((void**)&dev_c, 12 * sizeof(double));\n    cudaMalloc((void**)&dev_a, 12 * sizeof(double));\n    cudaMalloc((void**)&dev_b, size * sizeof(double));\n\n    cudaMemcpy(dev_a, a, 12 * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(dev_b, b, size * sizeof(double), cudaMemcpyHostToDevice);\n    \n    cublasHandle_t handle;\n    cublasCreate(&handle);\n\n    double alpha = 1.0;\n    double beta = 0;\n\n    cublasDgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, 4, 3, 3, &alpha, dev_a, 4, dev_b, 3, &beta, dev_c, 4);\n\n    cudaMemcpy(c, dev_c, 12 * sizeof(double), cudaMemcpyDeviceToHost);\n   \n    cublasDestroy(handle);\n\n    cudaFree(dev_c);\n    cudaFree(dev_a);\n    cudaFree(dev_b);\n}\n\n\n```\n\n```\nOutput\n380.000000 830.000000 1280.000000 \n440.000000 980.000000 1520.000000 \n500.000000 1130.000000 1760.000000 \n560.000000 1280.000000 2000.000000 \n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication explanation\r\n                \r\nWhen we multiply two matrices A of size m x k and B of size k x n we use the following code:\n\n```\n  #for resultant matrix rows\n  for i in range(m):\n    #for resultant matrix column\n    for j in range(n):\n      for l in range(k):\n        #A's row x B's columns\n        c[i][j]=c[i][j]+a[i][l]*b[l][j]\n```\n\n\nare my comments in the code right explanation of the loops? Is there a better explanation of the loops or is there a better thought process to code matrix multiplication?\n\nEDIT1: I am not looking for a better code. My question is about the thought process that goes in when we transform the math of matrix multiplicate into code.\n    ", "Answer": "\r\nYour code is correct but if you want to add detail comment/explanation like you ask for you can do so: \n\n```\n #for resultant matrix rows\n  for i in range(m):\n    #for resultant matrix column\n    for j in range(n):\n      #for each entry in resultant matrix we have k entries to sum\n      for l in range(k):\n        #where each i, j entry in the result matrix is given by multiplying the \n        #entries A[i][l] (across row i of A) by the entries B[l][j] (down \n        #column j of B), for l = 1, 2, ..., k, and summing the results over l:\n        c[i][j]=c[i][j]+a[i][l]*b[l][j]\n```\n\n\nEDIT: if you want a better explanation of the loop or thought process than take out ```\n#A's row x B's columns```\n comments.  and replace it with \"where each i, j entry in the result matrix is given by multiplying the entries A[i][l] (across row i of A) by the entries B[l][j] (down column j of B), for l = 1, 2, ..., k, and summing the results over \" also don't use ```\nl```\n as an iterator it looks like a ```\n1```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in numpy\r\n                \r\nI have 2 boolean matrices in numpy and am using the .dot() function to multiply them and the results I get is a boolean matrix.\n\nIs there a way to the get the sum of the product of the respective elements during the multiplication that I would get if I was doing matrix multiplication and the elements were either 1 or 0?\n\ni.e. the elements in the resulting matrix should either be 0 or non-zero integers.\n\nThanks in advance.\n    ", "Answer": "\r\nConvert to ```\nint```\n with ```\nastype```\n.\n\nDemo:\n\n```\n>>> import numpy as np\n>>> np.random.seed(5)\n>>> a = np.random.random([3,3]) > 0.5\n>>> b = np.random.random([3,3]) > 0.5\n```\n\n\nNow a, b are arrays of dtype ```\nbool```\n:\n\n```\n>>> a\narray([[False,  True, False],\n       [ True, False,  True],\n       [ True,  True, False]], dtype=bool)\n```\n\n\nMultiply them as integers:\n\n```\n>>> np.dot(a.astype(np.int), b.astype(np.int))\narray([[0, 0, 1],\n       [0, 0, 1],\n       [0, 0, 2]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication time complexity in MATLAB\r\n                \r\nDoes anyone know which algorithm MATLAB uses for matrix multiplication and what is its time complexity?\n    ", "Answer": "\r\nFor completeness -- as mentioned in this thread, Matlab uses the ```\nDGEMM```\n (Double GEneral Matrix Multiplication) routine from BLAS (Basic Linear Algebra Subprograms).\n\nNote that there is not one single implementation of BLAS - it is tuned for particular processor architectures. Therefore you cannot be absolutely certain which algorithm is being used on your machine without finding out which version of BLAS is in use.\n\nThe specification for BLAS specifies the inputs and output of each subroutine, and provides acceptable error bounds for the output of each subroutine. Implementations are free to use whatever algorithm they like, as long they follows the specification.\n\nThe reference implementation of BLAS uses a block matrix multiplication algorithm in ```\nDGEMM```\n that has time complexity O(n^3) for multiplying two n x n matrices. I think it's reasonable to assume that most implementations of BLAS will more or less follow the reference implementation.\n\nNote that it doesn't use the naive matrix multiplication algorithm\n\n```\nfor i = 1:N\n    for j = 1:N\n        for k = 1:N\n            c(i,j) = c(i,j) + a(i,k) * b(k,j);\n        end\n    end\nend\n```\n\n\nThis is because, typically, the entire matrix will not fit in local memory. If data is constantly being shifted into and out of local memory, the algorithm will slow down. The block matrix algorithm breaks the operation into small blocks, such that each block is small enough to fit into local memory, reducing the number of shifts into and out of memory.\n\nThere exist asymptotically faster matrix multiplication algorithms, eg the Strassen algorithm or the Coppersmith-Winograd algorithm which have a slightly faster rate than O(n^3). However, they are generally not cache aware and ignore locality - meaning that data continually needs to be shunted around in memory, so for most modern architectures the overall algorithm is actually slower than an optimized block matrix multiplication algorithm.\n\nWikipedia notes that the Strassen algorithm may provide speedups on a single core CPU for matrix sizes greater than several thousand, however the speedup is likely to be around 10% or so, and the developers of BLAS probably don't consider it worthwhile for this rare case (saying that, this paper from 1996 claims a speed increase of around 10% over ```\nDGEMM```\n for n above about 200 -- though I don't know how out of date that is). The Coppersmith-Winograd algorithm, on the other hand, \"only provides an advantage for matrices so large that they cannot be processed by modern hardware\".\n\nSo the answer is that Matlab uses a naive, but efficient and cache-aware algorithm to get its blazing fast matrix multiplication.\n\n\n\nI updated this answer by creating some videos that demonstrate the locality of the block matrix multiplication algorithm, compared to the naive algorithm. \n\nIn each of the following videos, we are visualizing the multiplication of two 8x8 matrices A and B to create the product C = A x B. The yellow highlight indicates which element in each of the matrices A, B and C is being processed at each step of the algorithm. You can see how the block matrix multiplication only works on small blocks of the matrix at a time, and re-uses each of those blocks multiple times, so that the number of times that data must be shifted in and out of local memory is minimized.\n\n\nSimple matrix multiplication \nBlock matrix multiplication, block size = 2\nBlock matrix multiplication, block size = 4\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication of an Eigen Matrix for a subset of columns\r\n                \r\nWhat is the fastest method for matrix multiplication of an ```\nEigen::Matrix```\n over a random set of column indices?\n```\nEigen::MatrixXd mat = Eigen::MatrixXd::Random(100, 1000);\n// vector of random indices (linspaced here for brevity)\nEigen::VectorXi idx = VectorXi::LinSpaced(8,1000,9);\n```\n\nI'm using RcppEigen and R, which is still on a 3.x version of Eigen (no support for ```\n()```\n with index arrays), and regardless, my understanding is that the ```\n()```\n operator still performs a deep copy.\nRight now I'm doing a deep copy and generating a new matrix with data only for columns in ```\nidx```\n:\n```\ntemplate <typename T>\ninline Eigen::Matrix<T, -1, -1> subset_cols(const Eigen::Matrix<T, -1, -1>& x, const std::vector<size_t>& cols) {\n    Eigen::Matrix<T, -1, -1> y(x.rows(), cols.size());\n    for (size_t i = 0; i < cols.size(); ++i)\n        y.col(i) = x.col(cols[i]);\n    return y;\n}\n```\n\nand then doing matrix multiplication:\n```\nEigen::MatrixXd sub_mat = subset_cols(mat, idx);\nEigen::MatrixXd a = sub_mat * sub_mat.transpose();\n```\n\n```\na```\n is what I want.\nThere must be some way to avoid a deep copy and instead use ```\nEigen::Map```\n?\nEdit 5/9/22:\nIn reply to @Markus, who proposed an approach using raw data access and ```\nEigen::Map```\n. The proposed solution is a bit slower than matrix multiplication of a deep copy.  Benchmarking here is done with Rcpp code and R:\n```\n//[[Rcpp::depends(RcppClock)]]\n#include <RcppClock.h>\n\n//[[Rcpp::export]]\nvoid bench(Eigen::MatrixXd mat, Eigen::VectorXi idx){\n  Rcpp::Clock clock;\n  size_t reps = 100;\n  while(reps-- > 0){\n    clock.tick(\"copy\");\n    Eigen::MatrixXd sub_mat = subset_cols(mat, idx);\n    Eigen::MatrixXd a = sub_mat * sub_mat.transpose();\n    clock.tock(\"copy\");\n    \n    clock.tick(\"map\");\n    double *b_raw = new double[mat.rows() * mat.rows()];\n    Eigen::Map<Eigen::MatrixXd> b(b_raw, mat.rows(), mat.rows());\n    subset_AAt(b_raw, mat, idx);\n    clock.tock(\"map\");\n  }\n  clock.stop(\"clock\");\n}\n```\n\nHere are three runs of a 100,000-column matrix with 100 rows. We are doing matrix multiplication on (1) a subset of 10 columns, (2) a subset of 1000 columns, and (3) a subset of 10000 columns.\nR:\n```\nbench(\n  matrix(runif(100000 * 100), 100, 100000), \n  sample(100000, 10) - 1)\n\n# Unit: microseconds \n# ticker   mean     sd   min    max neval\n#    copy  31.65  4.376 30.15  69.46   100\n#     map 113.46 21.355 68.54 166.29   100\n\nbench(\n  matrix(runif(100000 * 100), 100, 100000), \n  sample(100000, 1000) - 1)\n\n#  Unit: milliseconds \n#  ticker  mean     sd   min   max neval\n#    copy 2.361 0.5789 1.972  4.86   100\n#     map 9.495 2.4201 7.962 19.90   100\n\nbench(\n  matrix(runif(100000 * 100), 100, 100000), \n  sample(100000, 10000) - 1)\n\n#  Unit: milliseconds \n#  ticker   mean     sd    min   max neval\n#    copy  23.04  2.774  20.95  42.4   100\n#     map 378.14 19.424 351.56 492.0   100\n```\n\nI benchmarked on a few machines with similar results. Above results are from a good HPC node.\nEdit: 5/10/2022\nHere is a code snippet that performs matrix multiplication for a subset of columns as quickly as any code not directly using the Eigen BLAS:\n```\ntemplate <typename T>\nEigen::Matrix<T, -1, -1> subset_AAt(const Eigen::Matrix<T, -1, -1>& A, const Eigen::VectorXi& cols) {\n  const size_t n = A.rows();\n  Eigen::Matrix<T, -1, -1> AAt(n, n);\n  for (size_t k = 0; k < cols.size(); ++k) {\n    const T* A_data = A.data() + cols(k) * n;\n    for (size_t i = 0; i < n; ++i) {\n      T tmp_i = A_data[i];\n      for (size_t j = 0; j <= i; ++j) {\n        AAt(i * n + j) += tmp_i * A_data[j];\n      }\n    }\n  }\n  return AAt;\n}\n```\n\n    ", "Answer": "\r\nExploiting symmetry\nYou can exploit that the resulting matrix will be symmetric like so:\n```\nMat sub_mat = subset_cols(mat, idx); // From your original post\nMat a = Mat::Zero(numRows, numRows);\na.selfadjointView<Eigen::Lower>().rankUpdate(sub_mat); // (1)\na.triangularView<Eigen::Upper>() = a.transpose(); // (2)\n```\n\nLine ```\n(1)```\n will compute ```\na += sub_mat * sub_mat.transpose()```\n for the lower part only. ```\n(2)```\n will then write the lower part to the upper part. Also see the documentation (here and here).\nOf course, if you can live with only the lower part, step (2) can be omitted.\nFor a 100x100000 matrix ```\nmat```\n, I get a speed up of a factor of roughly\n\n~1.1x when taking 10 columns,\n~1.5x when taking 100 columns,\n~1.7x when taking 1000 columns\n\nboth on Windows using MSVC and on Linux using clang with full optimizations and AVX.\nEnabling parallelization\nAnother way to speed up the computation is to enable parallelization by compiling with OpenMP. Eigen takes care of the rest. The code above that exploits the symmetry does not benefit from it, however. But the original code\n```\nEigen::MatrixXd sub_mat = subset_cols(mat, idx);\nEigen::MatrixXd a = sub_mat * sub_mat.transpose();\n```\n\ndoes.\nFor a 100x100000 matrix ```\nmat```\n, using clang on Linux, running with 4 threads (on 4 real cores) and comparing to a single thread, I get a speed up of a factor of roughly\n\n~1.0x when taking 10 columns, i.e. no speed up at all\n~1.8x when taking 100 columns\n~2.0x when taking 1000 columns\n\nIn other words, 4 cores or more outperform the symmetric method shown above except for a very small number of columns. Using only 2 cores was always slower. Note that using SMT hurt the performance in my tests, sometimes notably.\nOther notes\nI already wrote this in the comment, but for the sake of completeness:\n```\nEigen::Map```\n will not work because the strides are non-equidistant. Using slicing gives me ~10% better performance than your copying method on Linux with clang and gcc, but somewhat worse on MSVC. Also, as you noted, it is not available on the 3.3 branch of Eigen. There is a custom way to mimic it, but it performed always worse in my tests.\nAlso, in my tests, it did not save any memory compared to the copying method.\nI think it is hard to beat the copying method itself regarding performance because the Eigen matrices are column major by default, meaning that copying a few columns is rather cheap. Moreover, without really knowing details, I suspect that Eigen can then throw the full might of its optimization on the full matrix to compute the product and transpose without having to deal with views or anything like this. This might give Eigen more chances for vectorization or cache locality.\nApart from this, not only optimizations should be turned on but also the highest possible instruction set should be used. Turning on AVX in my tests improved the performance by ~1.5x. Unfortunately, I cannot test AVX512.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication Floats\r\n                \r\nI have a list of constants represented by alpha1, a1 .... theta4.\n\nI can print correctly and read the individual matrices, however when i try matrix multiplication i receive error; \n\n```\nprint T1 * T2 * T3 * T4\nTypeError: can't multiply sequence by non-int of type 'list'\n```\n\n\nI believe it is something to do with multiplying floats.\n\n```\nfrom numpy import matrix\nimport math\n\ndef getTransformationMatrix( alpha, a, d, theta ):\n    transformationMatrix = matrix([[math.cos(theta),math.cos(alpha)*math.sin(theta),math.sin(alpha)*math.sin(theta) ,a*math.cos(theta)],  [math.sin(theta),math.cos(alpha)*math.sin(alpha)  ,-math.sin(alpha)*math.cos(theta),a*math.sin(theta)],[0,math.sin(alpha),math.cos(alpha),d],[0,0,0,1]])\n    return[transformationMatrix];\n\nT1 = getTransformationMatrix( alpha1, a1, d1, theta1)\nT2 = getTransformationMatrix( alpha2, a2, d2, theta2)\nT3 = getTransformationMatrix( alpha3, a3, d3, theta3)\nT4 = getTransformationMatrix( alpha4, a4, d4, theta4)\n\nprint T1 * T2 * T3 * T4\n```\n\n    ", "Answer": "\r\nYour ```\ngetTransformationMatrix```\n function returns a list while you would like it to return a matrix.\n\nI suspect you added those square brackets by mistake.\n\n```\ndef getTransformationMatrix( alpha, a, d, theta ):\n    transformationMatrix = matrix([[math.cos(theta),math.cos(alpha)*math.sin(theta),math.sin(alpha)*math.sin(theta) ,a*math.cos(theta)],  [math.sin(theta),math.cos(alpha)*math.sin(alpha)  ,-math.sin(alpha)*math.cos(theta),a*math.sin(theta)],[0,math.sin(alpha),math.cos(alpha),d],[0,0,0,1]])\n    return [transformationMatrix];\n```\n\n\nTry this:\n\n```\ndef getTransformationMatrix( alpha, a, d, theta ):\n    transformationMatrix = matrix([[math.cos(theta),math.cos(alpha)*math.sin(theta),math.sin(alpha)*math.sin(theta) ,a*math.cos(theta)],  [math.sin(theta),math.cos(alpha)*math.sin(alpha)  ,-math.sin(alpha)*math.cos(theta),a*math.sin(theta)],[0,math.sin(alpha),math.cos(alpha),d],[0,0,0,1]])\n    return transformationMatrix\n```\n\n\nSeeing this error\n\n```\nTypeError: can't multiply sequence by non-int of type 'list'\n```\n\n\nthe first thing to do is to print no only ```\nT1```\n, ```\nT2```\n, etc. but also ```\ntype(T1)```\n, etc.\n\nYou would see it is not what you expect.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Best Package for Sparse Matrix Multiplication [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     Questions asking us to recommend or find a tool, library or favorite off-site resource are off-topic for Stack Overflow as they tend to attract opinionated answers and spam. Instead, describe the problem and what has been done so far to solve it.\r\n                \r\n                    \r\n                        Closed 9 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI am looking for the best package for sparse matrix multiplication on single core solution.\nI am not looking for CUDA, MPI or OpenMP solutions.\n\nMy preference for languages in decreasing order : Matlab, Python, C/C++.\n\nMatlab has its own matrix multiplication function which can be used for sparse matrix multiplication. But are there any better package(s) available ?\n\nI have to multiply two large matrices which are in sparse format. \n\nEg., one matrix is 677000-by-48000 and another is 48000-by-8192. Here, n-by-d means n : # of rows, d : # of columns \n    ", "Answer": "\r\nI'm no expert for sparse matrices but I do know the renowned 'eigen' C++ library.\n\nThey have a tutorial on sparse matrices, reachable from the documentation page.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication results in fraction\r\n                \r\nRuby yields results in fraction for matrix inverse operation but not for matrix multiplication operation. E.g., below code:\n\n```\nrequire 'matrix'\n\n(Matrix[ [-1/2] ] * Matrix[ [1/2]])\n```\n\n\nyields ```\nMatrix[[0]]```\n instead of ```\nMatrix[[-1/4]]```\n. Why this behavior?\n    ", "Answer": "\r\nYour problem has been identified, but your real question has not been answered, namely, when multiplying matrix objects, when is an element of the product an integer, a rational number or a float?\n\nIf ```\na```\n and ```\nb```\n are matrix objects, each element of ```\na*b```\n will be:\n\n\nan integer if all elements of ```\na```\n and ```\nb```\n used in its calculation are integers;\na rational number if, among the elements of ```\na```\n and ```\nb```\n used in its calculation there is at least one rational number and the remainder are integers or rationals; and\na float if at least one of the elements of ```\na```\n and ```\nb```\n used in its calculation is a float.\n\n\nI will give a few examples, but first let's consider how Ruby expresses rational numbers. A rational number is a number that can be expressed as the ratio of two integers. For example, ```\n1.5```\n is a rational number since it can be expressed ```\n3/2```\n. We can't write it that way in Ruby, however, since ```\n3/2```\n will be replaced by ```\n1```\n, the result of integer division. Instead, we create an instance of the class Rational:\n\n```\nr = Rational(3,2)\n  #=> (3/2)\n```\n\n\nand use that in the calculations. (Note the parentheses in the return value.) We can extract its numerator and denominator, or convert it to an integer (rounding down or up) or a float:\n\n```\nr.numerator\n  #=> 3\nr.denominator\n  #=> 2\nr.to_i\n  #=> 1\nr.ceil\n  #=> 2\nr.to_f\n  #=> 1.5\n```\n\n\nNow let's look at some examples.\n\n```\nrequire 'matrix'\n\nMatrix[[Rational(-1,2)]] * Matrix[[Rational(1,2)]]\n  #=> Matrix[[(-1/4)]] \nMatrix[[-1]] * Matrix[[Rational(1,2)]]\n  # => Matrix[[(-1/2)]] \nMatrix[[-0.5]] * Matrix[[Rational(1,2)]]\n  #=> Matrix[[-0.25]]\nMatrix[[Rational(-1,2), Rational(1,2)]].transpose * Matrix[[Rational(1,2), 0.5]]\n  #=> Matrix[[(-1/4), -0.25], [(1/4), 0.25]] \n```\n\n\nNow let's consider the inverse of a matrix:\n\n```\nMatrix[[Rational(-1,2), 1],[2, Rational(2,3)]].inverse\n  #=> Matrix[[(-2/7), (3/7)], [(6/7), (3/14)]]\nMatrix[[Rational(-1,2), 1.0],[2, Rational(2,3)]].inverse\n  #=> Matrix[[-0.2857142857142857, 0.4285714285714286],\n  #          [0.8571428571428571, 0.21428571428571427]]\n```\n\n\nIn calculating the inverse of a matrix with ```\nn```\n rows and columns there are ```\nn```\n \"pivoting\" steps. If, as in my latter example, the matrix contains a mix of integers, rationals and floats, when each pivot operation is performed:\n\n\neach integer will be converted to a float if at least one float is used in its calculation, else it will be converted to a rational if at least one rational is used in its calculation; else it will remain an integer;\neach rational will be converted to a float if there is at least one float used in its calculation, else it will remain a rational; and\neach float will remain a float.\n\n\nAs \"once a float always a float\", it won't be long before all elements of the computed matrix are floats. (I believe it can be proven that the inverse will contain all floats if the original matrix contains at least one float.)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication MPI stop working\r\n                \r\nI am trying matrix multiplication using MPI. My problem is that when I run my code, it prints the message ```\nARRAY C (C=AxB)```\n and it stops working. Can anyone help me with that?\nThat's my code.\n\n```\n#include \"mpi.h\"\n#include <stdio.h>\n#include <stdlib.h>\n\n\nint main(int argc, char *argv[]){\nfloat **A,**B,**C;\nint rownumA,colnumA,c,i,j,k,rank,size,nrank,srowA,srowB,smul,node,node1,temp,rrowA,sender;\nint rownumB,colnumB,c1,rc;\nMPI_Status stat;\nMPI_Init(&argc,&argv);\nMPI_Comm_rank(MPI_COMM_WORLD,&rank);\nMPI_Comm_size(MPI_COMM_WORLD,&size);\nif (size < 2 ) {\n  printf(\"Error\\n\");\n  MPI_Abort(MPI_COMM_WORLD, rc);\n  exit(1);\n  }\nnrank=rank-1;\nif (rank == 0) \n{\n\n//READ AND FILL FIRST ARRAY\nFILE *fp;\n\ncolnumA=rownumA=0;\nfp=fopen(\"g.txt\",\"r\");\nif (fp==NULL) exit(1);\n\n//count rows and lines of 2d array\nwhile ((c = getc(fp)) != EOF)\n    {\n       if (c==' ')\n            colnumA++;\n\n        if (c == '\\n')\n            rownumA++;\n    }\n    colnumA=(colnumA/rownumA)+1;\nfclose(fp);\n// end count\n\n//create dynamic array\nA =(float **) malloc(rownumA*sizeof(float*));\nfor(i=0; i<rownumA; i++){\n    A[i]= (float *)malloc(colnumA*sizeof(float));\n}\n\n\n//Fill 2d array from file\nfp=fopen(\"g.txt\",\"r\");\n\nfor (i=0;i<rownumA; i++){\n        for(j=0; j<colnumA; j++){\n            fscanf(fp,\"%f\",&A[i][j]);\n\n\n\n        }\n}\n//end add\nfclose(fp);\n\n\n\n//READ AND FILL ARRAY B\n\nFILE *fp1;\ncolnumB=rownumB=0;\nfp1=fopen(\"h.txt\",\"r\");\nif (fp1==NULL) exit(1);\n\n//count rows and lines of 2d array\nwhile ((c1 = getc(fp1)) != EOF)\n    {\n       if (c1==' ')\n            colnumB++;\n\n        if (c1 == '\\n')\n            rownumB++;\n    }\n    colnumB=(colnumB/rownumB)+1;\nfclose(fp1);\n// end count\n\n//create dynamic array\nB =(float **) malloc(rownumB*sizeof(float *));\nfor(i=0; i<rownumB; i++){\n    B[i]= (float *)malloc(colnumB*sizeof(float));\n}\n\n\n//Fill 2d array from file\nfp1=fopen(\"h.txt\",\"r\");\n\nfor (i=0;i<rownumB; i++){\n        for(j=0; j<colnumB; j++){\n            fscanf(fp1,\"%f\",&B[i][j]);\n\n\n\n        }\n}\n//end add\nfclose(fp1);\n\n\nif (colnumA != rownumB ){\n    printf(\"\\n Error cant mult!\\n\");\n    exit(1);\n}\n\n\n//create dynamic array\nC = (float **)malloc(rownumA*sizeof(float *));\nfor(i=0; i<colnumB; i++){\n    C[i]= (float *)malloc(colnumB*sizeof(float));\n}\n//Init C with 0\nfor (i=0;i<rownumA; i++){\n        for(j=0; j<colnumB; j++){\n                C[i][j]=0;\n        }\n}\nsrowA=rownumA/nrank;\nrrowA=rownumA%nrank;\nsmul=0;\n\nfor (node=1; node<=nrank; node++)\n    {\n        if (node<=rrowA)\n            temp=srowA+1;\n        else\n            temp=srowA;\n\n    MPI_Send(&smul,1,MPI_INT,node,1,MPI_COMM_WORLD);\n    MPI_Send(&temp,1,MPI_INT,node,1,MPI_COMM_WORLD);\n    MPI_Send(&colnumA,1,MPI_INT,node,1,MPI_COMM_WORLD);\n    MPI_Send(&colnumB,1,MPI_INT,node,1,MPI_COMM_WORLD);\n    MPI_Send(&A[smul][0],temp*colnumA,MPI_DOUBLE,node,1,MPI_COMM_WORLD);\n    MPI_Send(&B,colnumA*colnumB,MPI_DOUBLE,node,1,MPI_COMM_WORLD);\n    MPI_Send(&rownumA,1,MPI_INT,node,1,MPI_COMM_WORLD);\n    smul=smul+temp;     \n\n    }\n\n    //receive results\n    for (node1=1; node1<nrank; node1++)\n    {\n        sender=node1;\n        MPI_Recv(&smul,1,MPI_INT,sender,2,MPI_COMM_WORLD,&stat);\n        MPI_Recv(&temp,1,MPI_INT,sender,2,MPI_COMM_WORLD,&stat);\n        MPI_Recv(&C[smul][0],temp*colnumB,MPI_DOUBLE,sender,2,MPI_COMM_WORLD,&stat);\n\n    }\n\n    //print results\n    //Print at file C array\n    FILE *fpr;\n    fpr=fopen(\"results.txt\",\"w\");\n    if (fpr == NULL) exit(1);\n    printf(\"\\n\\n /// ARRAY C (C=AxB) /// \\n \\n \\n\");\n    for (i=0;i<rownumA; i++){\n            for(j=0; j<colnumB; j++){\n                fprintf(fpr,\"%0.3f \",C[i][j]);\n            }\n            fprintf(fpr,\"\\n\");\n}\nfclose(fpr);\n\n\n} //end master\n\nif (rank>0)\n    {\n            MPI_Recv(&smul,1,MPI_INT,0,1,MPI_COMM_WORLD,&stat);\n            MPI_Recv(&temp,1,MPI_INT,0,1,MPI_COMM_WORLD,&stat);\n            MPI_Recv(&colnumA,1,MPI_INT,0,1,MPI_COMM_WORLD,&stat);\n            MPI_Recv(&colnumB,1,MPI_INT,0,1,MPI_COMM_WORLD,&stat);\n            MPI_Recv(&A,temp*colnumA,MPI_DOUBLE,0,1,MPI_COMM_WORLD,&stat);\n            MPI_Recv(&B,colnumA*colnumB,MPI_DOUBLE,0,1,MPI_COMM_WORLD,&stat);\n            MPI_Recv(&rownumA,1,MPI_INT,0,1,MPI_COMM_WORLD,&stat);\n\n        for(k=0; j<colnumB ; k++)\n    for(i=0; i<temp; i++)\n    for(j=0; j<colnumA; j++)\n    {\n        C[i][k]+=A[i][j]*B[j][k];\n    }\n\n    //send results\n        MPI_Send(&smul, 1,MPI_INT,0,2,MPI_COMM_WORLD);\n        MPI_Send(&temp,1,MPI_INT,0,2,MPI_COMM_WORLD);\n        MPI_Send(&C,temp*colnumB,MPI_DOUBLE,0,2,MPI_COMM_WORLD);\n    }\n\n  MPI_Finalize();  \n}\n```\n\n    ", "Answer": "\r\nHere\n\n```\n//create dynamic array\nC = (float **)malloc(rownumA*sizeof(float *));\nfor(i=0; i<colnumB; i++){\n    C[i]= (float *)malloc(colnumB*sizeof(float));\n}\n```\n\n\nthe upper bound of the ```\nfor```\n loop should be ```\nrownumA```\n.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Implementation of convolution matrix-matrix multiplication in Caffe\r\n                \r\nI have read that Caffe implements convolution operation as a matrix-matrix multiplication. I have unsuccesfully been plowing through the Caffe source code. Where can I find the implementation and the use of the multiplication in the forward step?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Spark Matrix multiplication with python\r\n                \r\nI am trying to do matrix multiplication using Apache Spark and Python.\n\nHere is my data\n\n```\nfrom pyspark.mllib.linalg.distributed import RowMatrix\n```\n\n\nMy RDD of vectors\n\n```\nrows_1 = sc.parallelize([[1, 2], [4, 5], [7, 8]])\nrows_2 = sc.parallelize([[1, 2], [4, 5]])\n```\n\n\nMy maxtrix\n\n```\nmat1 = RowMatrix(rows_1)\nmat2 = RowMatrix(rows_2)\n```\n\n\nI would like to do something like this:  \n\n```\nmat = mat1 * mat2\n```\n\n\nI wrote a function to process the matrix multiplication but I'm afraid to have a long processing time. Here is my function:                                     \n\n```\ndef matrix_multiply(df1, df2):\n    nb_row = df1.count()    \n    mat=[]\n    for i in range(0, nb_row):\n        row=list(df1.filter(df1['index']==i).take(1)[0])\n        row_out = []\n        for r in range(0, len(row)):\n            r_value = 0\n            col = df2.select(df2[list_col[r]]).collect()\n            col = [list(c)[0] for c in col]\n            for c in range(0, len(col)): \n                r_value += row[c] * col[c]\n            row_out.append(r_value)            \n        mat.append(row_out)\n    return mat \n```\n\n\nMy function make a lot of spark actions (take, collect, etc.). Does the function will take a lot of processing time?\nIf someone have another idea it will be helpful for me.\n    ", "Answer": "\r\nYou cannot. Since ```\nRowMatrix```\n has no meaningful row indices it cannot be used for multiplications. Even ignoring that the only distributed matrix which supports multiplication with another distributed structure is ```\nBlockMatrix```\n.\n\n```\nfrom pyspark.mllib.linalg.distributed import *\n\ndef as_block_matrix(rdd, rowsPerBlock=1024, colsPerBlock=1024):\n    return IndexedRowMatrix(\n        rdd.zipWithIndex().map(lambda xi: IndexedRow(xi[1], xi[0]))\n    ).toBlockMatrix(rowsPerBlock, colsPerBlock)\n\nas_block_matrix(rows_1).multiply(as_block_matrix(rows_2))\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "iPhone matrix multiplication and inversion\r\n                \r\nI'm trying to apply a Kalman filter to the data coming out from the iPhone accelerometer. I need to perform matrix multiplication and inversion as fast as possible, so I was curious about the possibility of using the GPU to perform these two tasks. As of now I found only one reference for the matrix multiplication:\n\n```\nfloat mBone01[16] = { ... }\nfloat mBone02[16] = { ... }\nfloat mResult[16];\n\nglMatrixMode  ( GL_MODELVIEW );\nglLoadIdentity( );\nglLoadMatrix  ( mBone01 );\nglMultMatrix  ( mBone02 );\nglGetMatrix   ( GL_MODELVIEW, mResult );\n```\n\n\neven tough the user is not really sure about the fact that this multiplication is performed inside the GPU. Do you have any hint on how to do (if possible) the same for the inversion?\n\nThank you all!\n    ", "Answer": "\r\nAs Kornel (and the OpenGL FAQ) already said, OpenGL does not provide an implementation of a matrix inversion.\nThis thread has some C++ implementations, that should work with the iPhone SDK.\nAlso, by calling the OpenGL API your code is not running on the GPU.\nTo use the GPU of the iPhone, you have to use OpenGL ES 2.0, which currently is only available on the following models:\n\n\niPhone 3GS\nnew iPod touch 32GB\nnew iPod touch 64GB\n\n\nApple has a sample project, that makes use of OpenGL ES 2.0 and shaders:\nhttp://developer.apple.com/iphone/library/samplecode/GLES2Sample/index.html\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication Algorithm Complexity [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        matrix multiplication algorithm time complexity\r\n                            \r\n                                (5 answers)\r\n                            \r\n                    \r\n                Closed 2 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI have this Java code for matrix multiplication:\n```\ndouble[][] product(double[][] x, double[][] y) {\n    double[][] z = new double[x.length][y[0].length];\n    for (int i = 0; i < x.length; i++) {\n        for (int j = 0; j < y[0].length; j++) {\n            double sum = 0.0;\n            for (int k = 0; k < x[0].length; k++) {\n                sum += x[i][k]*y[k][j];\n            }\n            z[i][j] = sum;\n        }\n    }\n    return z;\n}\n```\n\nWhat is the time complexity of this algorithm ?\nCan I say it is O(n^3) ?\n    ", "Answer": "\r\nYes I think it is O(n^3) since you have three loops inside each other\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication apache pig\r\n                \r\nI am trying to perform matrix multiplication in pig latin. Here's my attempt so far:\n\n```\nmatrix1 = LOAD 'mat1' AS (row,col,value);\nmatrix2 = LOAD 'mat2' AS (row,col,value);\n\nmult_mat = COGROUP matrix1 BY row, matrix2 BY col;\nmult_mat = FOREACH mult_mat {\n    A = COGROUP matrix1 BY col, matrix2 BY row;\n    B = FOREACH A GENERATE group AS col, matrix1.value*matrix2.value AS prod;\n    GENERATE group AS row, B.col AS col, SUM(B.prod) AS value;}\n```\n\n\nHowever, this doesn't work. I get stopped at\n\n```\nA = COGROUP matrix1...\n```\n\n\nwith \n\n```\nERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: <line 14, column 37>  mismatched input 'matrix1' expecting LEFT_PAREN\n```\n\n    ", "Answer": "\r\nAfter some playing around, I figured it out:\n\n```\nmatrix1 = LOAD 'mat1' AS (row,col,value);\nmatrix2 = LOAD 'mat2' AS (row,col,value);\n\nA = JOIN matrix1 BY column FULL OUTER, matrix2 BY row;\n\nB = FOREACH A GENERATE matrix1::row AS m1r, matrix2::column AS m2c, (matrix1::value)*(matrix2::value) AS value;\n\nC = GROUP B BY (m1r, m2c);\n\nmultiplied_matrices = FOREACH C GENERATE group.$0 as row, group.$1 as column, SUM(B.value) AS val;\n```\n\n\nMultiplied matrices should return the product of matrix1*matrix2 in the same format that the 2 matrices were entered, (row, col, value).\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication of 10000 X 10000\r\n                \r\nI need to perform a Matrix multiplication of two matrices of dimension 10,000 X 10,000, each element is randomly generated from range 1 to 10,000. I need to do it with threads (25 threads) and without threads and compare the time.\nI am using a simple Matrix multiplication algorithm O(n3).\nThe program without threads has been executing forever (more than a day)  and the threaded version aborts when I try to run it.\nIt works fine for 1000 X 1000 Matrix\nI compiled it using ```\nCC prog.cc -lpthread -lposix4```\n on my university server\nHere's the non-threaded version\n```\n/*\nCompiler: Unix Server \n\nThis program performs matrix multiplication of two 10000*10000 matrices without threads\nThe purpose of the program is to demonstrate the performance gain using threads \nagainst not using threads to perform the same computation on different data.\n*/\n\n    #include <pthread.h>\n    #include <iostream.h>\n    #include <semaphore.h>\n    #include <unistd.h>\n    #include<math.h>\n    \n    int main()\n    {\n        double **A;//Matrix A\n        double **B;//Matrix B\n        double **C;//Output Matrix C\n        const int MATRIX_DIMENSION = 5000;\n    \n        //Assign Matrix A first dimension\n        //-----------------------------------------------------------\n        A = new double*[MATRIX_DIMENSION];\n        //Assign second dimension\n        for(int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            A[i] = new double[MATRIX_DIMENSION];\n        }\n        //Assign Matrix B first dimension\n        B = new double*[MATRIX_DIMENSION];\n        //Assign second dimension\n        for(int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            B[i] = new double[MATRIX_DIMENSION];\n        }\n        //Assign Matrix C first dimension\n        C = new double*[MATRIX_DIMENSION];\n        //Assign second dimension\n        for(int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            C[i] = new double[MATRIX_DIMENSION];\n        }\n        //-----------------------------------------------------------\n        \n        //Generate random numbers for matrices A and B and assign C to 0\n        for(int i=0;i<MATRIX_DIMENSION;i++)\n        {\n            for(int j=0;j<MATRIX_DIMENSION;j++)\n            {\n                A[i][j] = rand() % 10000;\n                B[i][j] = rand() % 10000;\n                C[i][j] = 0; // initialize C to zero\n            }\n        }\n        //-----------------------------------------------------------\n        //Do the matrix multiplication\n                                                                                                                                                                                                                                            \n        for(int i=0;i<MATRIX_DIMENSION;i++)\n        {\n            for(int j=0 ;j<MATRIX_DIMENSION; j++)\n            {\n                for(int k=0;k<MATRIX_DIMENSION;k++)\n                {\n                    C[i][j]+=A[i][k]*B[k][j];\n                }\n            }                                                                                                                                                                                                                                                                                                                                           \n        }                               \n        \n        //-----------------------------------------------------------\n        //delete the dynamic memory of A\n        for (int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            delete[] A[i];\n        }\n        delete[] A;\n        //delete the dynamic memory of B\n        for (int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            delete[] B[i];\n        }\n        delete[] B;\n        //delete the dynamic memory of C\n        for (int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            delete[] C[i];\n        }\n        delete[] C;\n        //-----------------------------------------------------------\n        return(0);\n    }\n```\n\nHere's the threaded version\n```\n/*\nName: \nCompiler: Unix Server \n\nThis program performs matrix multiplication of two 10000*10000 matrices without threads\nThe purpose of the program is to demonstrate the performance gain using threads \nagainst not using threads to perform the same computation on different data.\n*/\n\n    #include <pthread.h>\n    #include <iostream.h>\n    #include <semaphore.h>\n    #include <unistd.h>\n    #include<math.h>\n    \n    //Global variables\n        double **A;//Matrix A\n        double **B;//Matrix B\n        double **C;//Output Matrix C\n        const int MATRIX_DIMENSION = 10000; //We need a 10000 X 10000 Matrix\n        const int NUM_THREADS = 25; // One thread completes 1/25th of the work\n        const int THREAD_DIMENSION = MATRIX_DIMENSION / NUM_THREADS; //Array that each thread will operate on\n        pthread_t * thread[NUM_THREADS];\n        \n        /***************************************************************************\n        Function that does matrix multiplication of 1/25th of the whole matrix,\n        The division is done by dividing the Matrix into row's all 1/25 of the total matrix\n        Each row of Matrix A operates on all the columns of Matrix B to get corresponding elements of Matrix C\n        Parameter : arg, this is used as and index for which part of the Matrix this particular thread operates on\n        Return type: void\n        ****************************************************************************/\n    void *MatrixMul (void * arg)\n    {\n        int index;\n        index = (int) arg;\n        int operation_Lower_Limit = ((index+1) * THREAD_DIMENSION) - THREAD_DIMENSION  ; //Multiplication starting row\n        int operation_Upper_Limit = ((index+1) * THREAD_DIMENSION) - 1; //Multiplication ending row\n        \n        for(int i=operation_Lower_Limit;i<=operation_Upper_Limit;i++) //only 1/25th of Matrix A is used\n        {\n            for(int j=0 ;j<MATRIX_DIMENSION; j++) // The whole B matrix is used\n            {\n                for(int k=0;k<MATRIX_DIMENSION;k++)\n                {\n                    C[i][j]+=A[i][k]*B[k][j];\n                }\n            }                                                                                                                                                                                                                                                                                                                                           \n        }\n        return NULL;\n    }\n    \n    int main()\n    {\n        \n        srand(time(0));\n        //Assign memory for threads\n        for(int i=0;i < NUM_THREADS;i++)\n        {\n        thread[i] = new pthread_t;\n        }\n    \n        //Assign Matrix A first dimension\n        //-----------------------------------------------------------\n        A = new double*[MATRIX_DIMENSION];\n        //Assign second dimension\n        for(int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            A[i] = new double[MATRIX_DIMENSION];\n        }\n        //Assign Matrix B first dimension\n        B = new double*[MATRIX_DIMENSION];\n        //Assign second dimension\n        for(int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            B[i] = new double[MATRIX_DIMENSION];\n        }\n        //Assign Matrix C first dimension\n        C = new double*[MATRIX_DIMENSION];\n        //Assign second dimension\n        for(int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            C[i] = new double[MATRIX_DIMENSION];\n        }\n        //-----------------------------------------------------------\n        \n        \n        \n        //Generate random numbers for matrices A and B and assign C to 0\n        for(int i=0;i<MATRIX_DIMENSION;i++)\n        {\n            for(int j=0;j<MATRIX_DIMENSION;j++)\n            {\n                A[i][j] = rand() % 10000;\n                B[i][j] = rand() % 10000;\n                C[i][j] = 0; // initialize C to zero\n            }\n        }\n        //-----------------------------------------------------------\n        //Do the matrix multiplication\n        \n        for(int i=0;i<NUM_THREADS;i++)\n        {\n        pthread_create( thread[ i ], NULL, (MatrixMul), (void *) (i) );\n        }\n            \n        \n        //wait for all the threads to complete execution\n        for(int i=0;i<NUM_THREADS;i++)\n        {\n        pthread_join(*thread[i],NULL);\n        }\n        \n        //-----------------------------------------------------------\n        //delete the dynamic memory of A\n        for (int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            delete[] A[i];\n        }\n        delete[] A;\n        //delete the dynamic memory of B\n        for (int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            delete[] B[i];\n        }\n        delete[] B;\n        //delete the dynamic memory of C\n        for (int i = 0; i < MATRIX_DIMENSION; i++)\n        {\n            delete[] C[i];\n        }\n        delete[] C;\n        //-----------------------------------------------------------\n        return(0);\n    }\n```\n\n    ", "Answer": "\r\nIs your program running out of memory? If so could you perhaps free up some of the memory as you are performing the multiplication?\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "fast large matrix multiplication in R\r\n                \r\nI have two matrices in R that I want to multiply:\n\n```\na = matrix(rnorm(20*10000, mean=0, sd=5), 20, 10000)\nb = matrix(rnorm(20*10000, mean=0, sd=5), 20, 10000)\nt(a)%*%b\n```\n\n\nGiven that the dimension in larger this matrix multiplication takes a lot of time, is there a specific way to make computations faster ? And are there any build in functions in R to make such multiplications faster?\n    ", "Answer": "\r\nThere are many ways to approach this depending upon your code, effort, and hardware.\n\n\nUse the 'best' function for the job\n\n\nThe simplest is to use ```\ncrossprod```\n which is the same as ```\nt(a)%*% b```\n (Note - this will only be a small increase in speed)\n\n```\ncrossprod(a,b) \n```\n\n\n\nUse Rcpp (and likely RcppEigen/RcppArmadillo).\n\n\nC++ will likely greater increase the speed of your code.  Using linear algebra libraries will likely also help this further (hence Eigen and Armadillo).  This however assumes you are willing to write some C++.   \n\n\nUse a better backend\n\n\nAfter this point you are looking at BLAS backends such as OpenBLAS, Atlas, etc.  Hooking these up to R varies depending upon your OS.  It is quite easy if you are using a Debian system like Ubuntu.  You can find a demo here.  These can sometimes be leveraged further by libraries such as Armadillo and Eigen.\n\n\nGPU Computing\n\n\nIf you have a GPU (e.g. AMD, NVIDIA, etc.) you can leverage the many cores within to greatly speed up your computations.  There are a few that could be useful including gpuR, gputools, and gmatrix \n\nEDIT - to address @jenesaiquoi comment on benefit of Rcpp\n\ntest.cpp\n\n```\n// [[Rcpp::depends(RcppArmadillo, RcppEigen)]]\n\n#include <RcppArmadillo.h>\n#include <RcppEigen.h>\n\n// [[Rcpp::export]]\nSEXP armaMatMult(arma::mat A, arma::mat B){\n    arma::mat C = A * B;\n\n    return Rcpp::wrap(C);\n}\n\n// [[Rcpp::export]]\nSEXP eigenMatMult(Eigen::MatrixXd A, Eigen::MatrixXd B){\n    Eigen::MatrixXd C = A * B;\n\n    return Rcpp::wrap(C);\n}\n\n// [[Rcpp::export]]\nSEXP eigenMapMatMult(const Eigen::Map<Eigen::MatrixXd> A, Eigen::Map<Eigen::MatrixXd> B){\n    Eigen::MatrixXd C = A * B;\n\n    return Rcpp::wrap(C);\n}\n```\n\n\ntest.R\n\n```\nlibrary(Rcpp)\n\nA <- matrix(rnorm(10000), 100, 100)\nB <- matrix(rnorm(10000), 100, 100)\n\nlibrary(microbenchmark)\nsourceCpp(\"test.cpp\")\nmicrobenchmark(A%*%B, armaMatMult(A, B), eigenMatMult(A, B), eigenMapMatMult(A, B))\n\nUnit: microseconds\n                  expr     min       lq     mean   median       uq      max neval\n               A %*% B 885.846 892.1035 933.7457 901.1010 938.9255 1411.647   100\n     armaMatMult(A, B) 846.688 857.6320 915.0717 866.2265 893.7790 1421.557   100\n    eigenMatMult(A, B) 205.978 208.1295 233.1882 217.0310 229.4730  369.369   100\n eigenMapMatMult(A, B) 192.366 194.9835 207.1035 197.5405 205.2550  366.945   100\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Testing GPU with tensorflow matrix multiplication\r\n                \r\nAs many machine learning algorithms rely to matrix multiplication(or at least can be implemented using matrix multiplication) to test my GPU is I plan to create matrices a , b , multiply them and record time it takes for computation to complete.\n\nHere is code that will generate two matrices of dimensions 300000,20000 and multiply them :\n\n```\nimport tensorflow as tf\nimport numpy as np\n\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\n\n#a = np.array([[1, 2, 3], [4, 5, 6]])\n#b = np.array([1, 2, 3])\n\na = np.random.rand(300000,20000)\nb = np.random.rand(300000,20000)\n\nprintln(\"Init complete\");\n\nresult = tf.mul(a , b)\nv = sess.run(result) \n\nprint(v)\n```\n\n\nIs this a sufficient test to compare performance of GPU's ? What other factors should I consider ?\n    ", "Answer": "\r\nHere's an example of a matmul benchmark which avoids common pitfalls, and matches the official 11 TFLOP mark on Titan X Pascal.\n\n```\nimport os\nimport sys\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\nimport tensorflow as tf\nimport time\n\nn = 8192\ndtype = tf.float32\nwith tf.device(\"/gpu:0\"):\n    matrix1 = tf.Variable(tf.ones((n, n), dtype=dtype))\n    matrix2 = tf.Variable(tf.ones((n, n), dtype=dtype))\n    product = tf.matmul(matrix1, matrix2)\n\n\n# avoid optimizing away redundant nodes\nconfig = tf.ConfigProto(graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)))\nsess = tf.Session(config=config)\n\nsess.run(tf.global_variables_initializer())\niters = 10\n\n# pre-warming\nsess.run(product.op)\n\nstart = time.time()\nfor i in range(iters):\n  sess.run(product.op)\nend = time.time()\nops = n**3 + (n-1)*n**2 # n^2*(n-1) additions, n^3 multiplications\nelapsed = (end - start)\nrate = iters*ops/elapsed/10**9\nprint('\\n %d x %d matmul took: %.2f sec, %.2f G ops/sec' % (n, n,\n                                                            elapsed/iters,\n                                                            rate,))\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Numpy time-dependent 2D matrix multiplication\r\n                \r\nI am looking for an efficient way to perform a matrix multiplication (dot product) of two time-dependent 2D matrices to end up with one time-dependent 2D matrix.\n\nFor example:\n\n```\na = np.zeros([7200,13,4])\nb = np.zeros([7200,4,7])\n```\n\n\nAnd I want to end up with\n\n```\nc = np.zeros([7200,13,7])\n```\n\n\nI already found np.tensordot, however this yields me a 4D matrix instead of a 3D matrix. Also other numpy functions did not yield me the required shape. So I wonder if there is any way to perform this matrix multiplication without the use of for-loops?\n\nBest regards,\n\nTimothy Van Daele\n    ", "Answer": "\r\nI just digged a little bit deeper and I found the numpy function einsum. This gives a lot of freedom for doing vector multiplications.\n\n```\na = np.zeros([7200,13,4])\nb = np.zeros([7200,4,7])\n\nc = np.einsum('ijk,ikl->ijl',a,b) \nc.shape (7200, 13, 7)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Asserting constraint on matrix multiplication\r\n                \r\nI am trying to evaluate resultant matrix by asserting constraint on matrix multiplication using z3py API. The following method works for matrix addition. Following is the code, which have 3 matrices: x, y, and sol. \nsol is the addition of x and y (sol==x+y), I am interested to restrict the values of resultant matrix (sol) to zero, and check which unknown values in \"x\" and \"y\" yield resultant matrix to be zero. Following is the list comprehension approach for addition.\n\n```\nfrom z3 import*\n\nx = [ [Real(\"x_%s_%s\" %(i+1, j+1))  for j in range(2) ] for i in range(2)]\ny = [ [Real(\"y_%s_%s\" %(i+1, j+1))  for j in range(2) ] for i in range(2)]\nsol = [ [Real(\"sol_%s_%s\" %(i+1, j+1))  for j in range(2) ] for i in range(2)]\naddition = [sol[i][j]==x[i][j]+y[i][j]   for i in range(2) for j in range(2) ]\n\n\ns = Solver()\n\ns.add(addition)\ns.add(x[0][0]>=0)\ns.add(x[0][1]>=0)\ns.add(x[1][0]>=0)\ns.add(x[1][1]>=1)\n\ns.add(And(y[0][0]>=0, y[0][0]<=2))\ns.add(And(y[0][1]>=0, y[0][0]<=2))\ns.add(And(y[1][0]>=0, y[0][0]<=2))\ns.add(And(y[1][1]>=0, y[0][0]<=2))\n\ns.add(sol[0][0]==0)\ns.add(sol[0][1]==0)\ns.add(sol[1][0]==0)\ns.add(sol[1][1]==0)\n\n\nif s.check()==sat:\n    m =s.model()\n    print  SAT,'\\n', m\n    result=[[ m.evaluate(sol[i][j]) for i in range (2)] for j in range (2)]\n    print result\nif (s.check()==unsat):\n    print \"UNSAT, no model exists\"\n```\n\n\nNow, is there any way in list comprehension through which I can assert matrix multiplication? (sol==x*y)...?\n    ", "Answer": "\r\nNo, Z3 does not have a built-in function for matrix multiplication. It can still be done in the straightforward way, but the constraints may become quite big. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "numpy matrix multiplication\r\n                \r\nI am trying to figure out how to do a kind of scalar matrix multiplication in numpy.\n\nI have \n\n```\na = array(((1,2,3),(4,5,6)))\nb = array((11,12))\n```\n\n\nand i want to do \n\n```\na op b\n```\n\n\nto result in\n\n```\narray(((1*11,2*11,3*11),(4*12,5*12,6*12))\n```\n\n\nright now I am using the following expression\n\nc= a * array((b, b, b)).transpose()\n\nIt seems like there must be a more efficient way of doing this though\n    ", "Answer": "\r\nTaking advantage of broadcasting:\n\n```\n(a.T * b).T\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "MPI matrix-matrix multiplication\r\n                \r\nIm currently trying to implement a matrix-matrix multiplication using C. I have the following code\n\n```\nfor(index=0; index<p; index++) \n    {\n        /* calculate the partial sum for matC given the row band of A and\n         B */\n        for (i=0; i<n/p; i++) \n            for (j=0; j<n; j++) \n                for (k=0; k<n; k++) \n                    storage_matC[i*n+j] += storage_matA[i*n+k]*storage_matB[k*n+j];\n\n        if(index < p-1) \n        {\n            /* mpi send storage_matB to the next process (id+1)%p */\n            MPI_Send(storage_matB, n, MPI_FLOAT, (id+1)%p, 0, MPI_COMM_WORLD); \n            /* mpi receive storage_matB from the previous process */\n            MPI_Recv(&storage_matB, n, MPI_FLOAT, id, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n        }\n    }\n```\n\n\nI need to be able to send the matrix_b used in the current process, and then receive it in the current process from the previous process. My program just hangs there and i have to terminate it.\nCan someone shed me some light on how to approach this problem...\n\nThank you so much for your time, your help is greatly appreciate it! \n    ", "Answer": "\r\nFrom MPI_Send docs:\n\n\n  This routine may block until the message is received by the destination process.\n\n\nand this is what is tripping you up. Everyone is trying to send, but no-one is listening since everyone is trying to send, so everyone keeps waiting for someone to shut up and listen, but no-one ever does, and everyone is wondering what the hell everyone else is doing. :P\n\nOne method I can see for this is to stagger the communication. For example, assuming an even number of slices, first all the even processes send while all the odd processes listen; then the odd processes send, and the even processes listen.\n\nEDIT: \"How can I do that?\" Pretty much as I have explained. Instead of your \"send then recv\", do something like this:\n\n```\nodd_ring = p % 2\n\n// first trip: evens send, odds receive\nif (id % 2) recv();\nelse if (!odd_ring || id != p - 1) send();\n\n// second trip: odds send, evens receive\nif (id % 2) send();\nelse if (!odd_ring || id) recv();\n\n// only when we have odd number of processes -\n// collecting stragglers: last sends to first\nif (odd_ring)\n  if (id == p - 1) send();\n  else if (!id) recv();\n```\n\n\nHaven't tested, so there might be bugs, but in essence that's how I'd implement it.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Binary Matrix Multiplication in Java\r\n                \r\nI want to do binary matrix multiplication in Java. Is there any class or jar available for doing this?\n    ", "Answer": "\r\nThe following java package may be helpful http://math.nist.gov/javanumerics/jama/\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication giving NA\r\n                \r\nI'm attempting to do simple matrix multiplication, that has never given me this issue before. \n\nI have an X matrix (nxfe) and a matrix of observations, y (nx1). For the purposes of this example lets just say \n\n```\nX <- matrix(c(1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1), nrow=4)\ny <- matrix(c(1, 2, 3, 4), nrow=4)\n```\n\n\nsimple code for this multiplication is \n\n```\nXt <- t(X)\nXy <- Xt%*%y\n```\n\n\nhowever, when I do this, I get a matrix of NA's (nx1). \n\nThis has never happened before. I have checked and there are appropriate values in all my matrices. Any help would be appreciated. \n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Scipy gives wrong result for matrix multiplication\r\n                \r\nI am using ```\nscipy```\n to do matrix multiplication of sparse matrix. For some reason, ```\n.power()```\n method doesn't work for sparse matrix. I have checked it using three methods:\n\nHere's my code:\n\n```\nimport scipy as sp\nimport scipy.sparse \n```\n\n\nMethod1: Plain matrix multiplication\n\n```\nrow = np.array([0, 3, 1, 0])\ncol = np.array([0, 3, 1, 2])\ndata = np.array([4, 5, 7, 9])\nP1 = sp.sparse.coo_matrix((data, (row, col)), shape=(4, 4))\n#Method 1\nP1.power(4).todense() #gives wrong result\n```\n\n\nResult:\n\n```\nmatrix([[ 256,    0, 6561,    0],  #6561 isn't right\n        [   0, 2401,    0,    0],\n        [   0,    0,    0,    0],\n        [   0,    0,    0,  625]], dtype=int32)\n```\n\n\nMethod 2:\n\n```\nP = P1.copy()\n#calculate ^4\nfor loop in range(2):\n    P = P.dot(P)\nP.todense()\n```\n\n\nOutput\n\n```\nmatrix([[ 256,    0,  576,    0],\n        [   0, 2401,    0,    0],\n        [   0,    0,    0,    0],\n        [   0,    0,    0,  625]], dtype=int32)\n```\n\n\nMethod3\n\n```\nP1.dot(P1).dot(P1).dot(P1).todense()\n```\n\n\nOutput:\n\n```\nmatrix([[ 256,    0,  576,    0],\n        [   0, 2401,    0,    0],\n        [   0,    0,    0,    0],\n        [   0,    0,    0,  625]], dtype=int32)\n```\n\n\nMethod 4:\n\nOne can check the result at this website (symbolab.com) \n\n\n\nOther threads on this topic (Element-wise power of scipy.sparse matrix, Matrix power for sparse matrix in python), focus on how to do matrix multiplication. I'd appreciate any help.\n    ", "Answer": "\r\nYou could use ```\n**```\n notation:\n\n```\n(P1**4).todense()\n```\n\n\nResult:\n\n```\n[[ 256    0  576    0]\n [   0 2401    0    0]\n [   0    0    0    0]\n [   0    0    0  625]]\n```\n\n\nEDIT: Regarding why ```\n.power()```\n doesn't return the expected result:\n\n— as Zinki mentioned in their comment:\n\n\n  ```\np.power(2)```\n is \"element-wise power\". ```\n9**4```\n = ```\n6561```\n.\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "PyOpenCL Matrix multiplication\r\n                \r\nI have this code for matrix multiplication using pyopenCL.\nMy problem is that the result is wrong in some matrices, and I dont understand why.\nAfter some research i think its related with global size of something like that but i dont understand how to set that values.\n\nFor example:\n\nmatrices using numpy dtype = float32\n\nmatrix 1:\n\n```\n[[ 0.99114645  0.09327769  0.90075564  0.8913309 ]\n[ 0.59739089  0.13906649  0.94246316  0.65673178]\n[ 0.24535166  0.68942326  0.41361505  0.5789603 ]\n[ 0.31962237  0.17714553  0.49025267  0.21861202]]\n```\n\n\nmatrix2:\n\n```\n[[ 0.41509482  0.82779616  0.74143827  0.37681136]\n[ 0.88058949  0.01039944  0.4342753   0.45752665]\n[ 0.60375261  0.21243185  0.88312167  0.97394323]\n[ 0.60855824  0.69482827  0.61627114  0.57155776]]\n```\n\n\nexpected result:\n\n```\n[[ 1.57981943  1.63210835  2.12016045  1.80288424]\n[ 1.3391085   1.15248911  1.7403561   1.58199609]\n[ 1.31099532  0.70041376  1.20338154  1.14162762]\n[ 0.71769556  0.52246746  0.88158722  0.8039138 ]]\n```\n\n\nscript result:\n\n```\n[[ 1.20828819  0.73175305  1.64546931  1.42526579]\n[ 1.13179159  0.46403384  1.20692348  1.14317513]\n[ 1.25328159  0.86723316  1.58679342  1.40186214]\n[ 1.35214019  0.6795128   1.73811913  1.48048854]]\n```\n\n\nscript:\n\n```\ndef openCL_multiplication(matrix1, matrix2, res):\n\nimport pyopencl as cl\nimport numpy as np\nimport numpy.linalg as la\n\nctx = cl.create_some_context()\nqueue = cl.CommandQueue(ctx)\n\nmf = cl.mem_flags\na_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=matrix1)\nb_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=matrix2)\ndest_buf = cl.Buffer(ctx, mf.WRITE_ONLY, matrix1.nbytes )\n\n\nprg = cl.Program(ctx, \"\"\"\n    __kernel void multiplymatrices(const unsigned int size, __global float * matrix1, __global float * matrix2, __global float * res) {\n\n    int i = get_global_id(1); \n    int j = get_global_id(0);\n\n    res[i + size * j] = 0;\n\n    for (int k = 0; k < size; k++)\n    {\n        res[i + size * j] += matrix1[i + size * k] * matrix2[k + size * j];\n    }\n\n    }\n    \"\"\").build()\n\nt0 = datetime.datetime.now()\n\nprg.multiplymatrices(queue, matrix1.shape, None,np.int32(len(matrix1)) ,a_buf, b_buf, dest_buf)\n\nfinal_matrix = np.empty_like(matrix1)\ncl.enqueue_copy(queue, final_matrix , dest_buf)\n\nprint  final_matrix\n\n\ndelta_t = datetime.datetime.now() - t0\nprint 'OpenCL Multiplication: ' + str(delta_t)\n\nreturn final_matrix\n```\n\n\nThank you!\n    ", "Answer": "\r\nWell, I think the kernel does all right.\nI can even call script result correct. It all depends on how you treat your matrices :-)\nIf you want your expected result. I'd change this:\n\n```\nres[i + size * j] += matrix1[i + size * k] * matrix2[k + size * j];\n```\n\n\nto this:\n\n```\nres[i + size * j] += matrix1[k + size * i] * matrix2[j + size * k];\n```\n\n\nHope this helps.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Armadillo - matrix multiplication error\r\n                \r\nI'm trying to do simply matrix multiplication using Armadillo:\n\n```\nmat33 MatA, MatB, MatC;\n\nMatA = MatB * MatC;\n```\n\n\nand this error occurs:\n\n```\n C:\\...SFunction.cpp:21: error: C2666: 'arma::Mat<eT>::operator =' : 3 overloads have similar conversions\n    with\n    [\n        eT=double\n    ]\n    c:\\...\\include\\armadillo\\armadillo_bits/Mat_bones.hpp(724): could be 'const arma::Mat<eT> &arma::Mat<eT>::fixed<fixed_n_rows,fixed_n_cols>::operator =(const arma::Mat<eT>::fixed<fixed_n_rows,fixed_n_cols> &)'\n    with\n    [\n        eT=double,\n        fixed_n_rows=3,\n        fixed_n_cols=3\n    ]\n    c:\\...\\include\\armadillo\\armadillo_bits/Mat_bones.hpp(82): or       'const arma::Mat<eT> &arma::Mat<eT>::operator =(const arma::Mat<eT> &)'\n    with\n    [\n        eT=double\n    ]\n    c:\\...\\include\\armadillo\\armadillo_bits/Mat_meat.hpp(4652): or       'const arma::Mat<eT> &arma::Mat<eT>::operator =<arma::mat33,arma::mat33,arma::glue_times>(const arma::Glue<T1,T2,glue_type> &)'\n    with\n    [\n        eT=double,\n        T1=arma::mat33,\n        T2=arma::mat33,\n        glue_type=arma::glue_times\n    ]\n    while trying to match the argument list '(arma::mat33, const arma::Glue<T1,T2,glue_type>)'\n    with\n    [\n        T1=arma::mat33,\n        T2=arma::mat33,\n        glue_type=arma::glue_times\n    ]\n```\n\n\nHowever, when I change code to this:\n\n```\nmat33 MatA, MatB, MatC;\n\nMatA = mat33(MatB * MatC);\n```\n\n\neverything is fine. It is a proper way to do matrix multipication and save the result to other matrix? Or there is another, simpler way?\n    ", "Answer": "\r\nWhy are you using the mat33 (fixed size)?\n\nYou could use the plain mat class. And in this case the multiplication is seamless\n\n```\nmat MatA(3,3), MatB(3,3), MatC(3,3); //or MatC;\n// fill MatA, MatB\nMatC = MatA * MatB\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to optimize matrix multiplication operation [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        Optimized matrix multiplication in C\r\n                            \r\n                                (14 answers)\r\n                            \r\n                    \r\n                Closed 4 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI need to perform a lot of matrix operations in my application. The most time consuming is matrix multiplication. I implemented it this way\n\n```\ntemplate<typename T>\nMatrix<T> Matrix<T>::operator * (Matrix& matrix)\n{\n\n\n    Matrix<T> multipliedMatrix = Matrix<T>(this->rows,matrix.GetColumns(),0);\n\n    for (int i=0;i<this->rows;i++)\n    {\n        for (int j=0;j<matrix.GetColumns();j++)\n        {\n            multipliedMatrix.datavector.at(i).at(j) = 0;\n            for (int k=0;k<this->columns ;k++)\n            {\n                multipliedMatrix.datavector.at(i).at(j) +=  datavector.at(i).at(k) * matrix.datavector.at(k).at(j);\n            }\n            //cout<<(*multipliedMatrix)[i][j]<<endl;\n        }\n    }\n    return multipliedMatrix;\n}\n```\n\n\nIs there any way to write it in a better way?? So far matrix multiplication operations take most of time in my application. Maybe is there good/fast library for doing this kind of stuff ?? \nHowever I rather can't use libraries which uses graphic card for mathematical operations, because of the fact that I work on laptop with integrated graphic card.\n    ", "Answer": "\r\nEigen is by far one of the fastest, if not the fastest, linear algebra libraries out there.  It is well written and it is of high quality.  Also, it uses expression template which makes writing code that is more readable.  Version 3 just released uses OpenMP for data parallelism.  \n\n```\n#include <iostream>\n#include <Eigen/Dense>\n\nusing Eigen::MatrixXd;\n\nint main()\n{\n  MatrixXd m(2,2);\n  m(0,0) = 3;\n  m(1,0) = 2.5;\n  m(0,1) = -1;\n  m(1,1) = m(1,0) + m(0,1);\n  std::cout << m << std::endl;\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "2d transformation,matrix multiplication\r\n                \r\nI'm trying to implement 2d transformation using opengl. so i created a matrix multiplication function. and separate functions for translation,rotation and scaling which call the matm,ie.matrix multiplication function.\nI'm creating a matrix of my vertices and passing them top the functions. I'm passing double pointers. But I'm getting segmentation fault. \n\n```\n#include<GL/glut.h>\n#include<stdlib.h>\n#include<math.h>\n#include<unistd.h>\n#define PI 3.14159265\n\nvoid matm(int** a,int** b)\n{\n   int i,j,k;\n   if(b[0][0]==100)\n      glFlush();\n   sleep(3);\n   int **c=(int**)malloc(3*sizeof(int*));\n   for(i=0;i<3;i++)\n   {\n      c[i]=(int*)malloc(sizeof(int));\n      k=0;\n      for(j=0;j<3;j++)\n      {\n         c[i][0]+=a[i][j]*b[k++][0];\n      }\n   }\n   b=c;\n}\n\nvoid translation(int** a,int tx,int ty)\n{\n   int t[3][3]={{1,0,tx}, {0,1,ty},{0,0,1}};\n   if(a[0][0]==100)\n      sleep(3);\n   matm(t,a);\n}\n\nvoid scaling(int** a,int sx,int sy)\n{\n   int t[3][3]={{sx,0,0}, {0,sy,0},{0,0,1}};\n   matm(t,a);\n}\n\nvoid rotation(int** a,int t)\n{\n   int si,co;\n   int val = PI / 180;\n   si=sin(t*val);\n   co=cos(t*val);\n\n   int ti[3][3]={{co,-si,0}, {si,co,0},{0,0,1}};\n   matm(ti,a);\n}\n\nvoid myinit()\n{\n   glClearColor(1.0,1.0,1.0,0.0);\n   gluOrtho2D(0,600,0,400);\n}\n\nvoid mydisplay()\n{\n   {\n      glClear(GL_COLOR_BUFFER_BIT);\n      glColor3f(1.0,0.0,0.0);\n      glBegin(GL_POLYGON);\n      glVertex2i(100,10);\n      glVertex2i(300,10);\n      glVertex2i(300,200);\n      glVertex2i(100,200);\n      glEnd();\n\n      int x1[3][1]={{100},{10},{1}};\n      int x2[3][1]={{300},{10},{1}};\n      int x3[3][1]={{300},{200},{1}};\n      int x4[3][1]={{100},{200},{1}};\n      glClear(GL_COLOR_BUFFER_BIT);\n      translation(x1,5,5);\n      translation(x2,5,5);\n      translation(x3,5,5);\n      translation(x4,5,5);\n      int a1,a2,a3,a4,b1,b2,b3,b4;\n      a1=x1[0][0];\n      b1=x1[1][0];\n      a2=x2[0][0];\n      b2=x2[1][0];\n      a3=x3[0][0];\n      b3=x3[1][0];\n      a4=x4[0][0];\n      b4=x4[1][0];\n      glBegin(GL_POLYGON);\n      glVertex2i(a1,b1);\n      glVertex2i(a2,b2);\n      glVertex2i(a3,b3);\n      glVertex2i(a4,b4);\n      glEnd();\n      glFlush();\n   }\n}\n\nint main(int argc,char** args)\n{\n   glutInit(&argc,args);\n   glutInitDisplayMode(GLUT_SINGLE|GLUT_RGB);\n   glutInitWindowSize(640,480);\n   glutInitWindowPosition(0,0);\n   glutCreateWindow(\"Hello\");\n   myinit();\n   glutDisplayFunc(mydisplay);\n   glutMainLoop();\n   return 0;\n}\n```\n\n    ", "Answer": "\r\nYou have lots of places in your code where you pass a 2D array to a function whose signature expects a type ```\nint**```\n. I am surprised your compiler does not report those as errors.\n\nAn array declared as:\n\n```\nint a[3][3];\n```\n\n\ndoes not decay to type ```\nint**```\n. It decays to type ```\nint (*)[3]```\n.\n\nWhen I compile the following program:\n\n```\nvoid translation(int** a,int tx,int ty)\n{\n}\n\nint main(int argc,char** args)\n{\n   int a[3][3];\n   translation(a, 10, 2);\n\n   return 0;\n}\n```\n\n\nI get the following error message using gcc 4.8.4.\n\n```\nsocc.cc: In function ‘int main(int, char**)’:\nsocc.cc:8:28: error: cannot convert ‘int (*)[3]’ to ‘int**’ for argument ‘1’ to ‘void translation(int**, int, int)’\n        translation(a, 10, 2);\n                            ^\nmake: *** [socc] Error 1\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "broadcasting for matrix multiplication\r\n                \r\nConsider the following\n```\nnp.random.seed(2)\n\nresult = SC @ x\n```\n\nSC is ```\nnn x nn```\n and x is ```\nnn x ns```\n.\nnow consider we have a 3D SCs ```\nns x nn x nn```\n.\n```\nns = 4\nnn = 2\n\nSCs = np.random.rand(ns, nn, nn)\nx = np.random.rand(nn, ns)\n\ndef matmul3d(a, b):\n    ns, nn, nn = a.shape\n    assert(b.shape == (nn, ns))\n    \n    results = np.zeros((nn, ns))\n    for i in range(ns):\n        results[:, i] = a[i, :, :] @ b[:, i]\n    return results\n```\n\n```\narray([[0.385428  , 0.22932766, 0.36791082, 0.06029485],\n       [0.68934311, 0.14157493, 0.75236553, 0.09049892]])\n```\n\nsimply use matrix multiplication, the diagonal is the result:\n```\nresults = a @ b\n\narray([[[0.385428  , 0.21717737, 0.38019609, 0.0372277 ],\n        [0.68934311, 0.30008412, 0.65169432, 0.0858002 ]],\n\n       [[0.52588409, 0.22932766, 0.4972909 , 0.06536792],\n        [0.48764911, 0.14157493, 0.43837138, 0.07607813]],\n\n       [[0.39071113, 0.1655206 , 0.36791082, 0.04962322],\n        [0.79777992, 0.34153306, 0.75236553, 0.10054907]],\n\n       [[0.37441129, 0.10004409, 0.33380446, 0.06029485],\n        [0.5542946 , 0.14242876, 0.4923592 , 0.09049892]]])\n\n```\n\nIs there any broadcasting for this to remove the loop?\n    ", "Answer": "\r\nYou can do it via ```\neinsum```\n, you basically just have to provide the array signature:\n```\nnp.einsum('ijk,ki->ji', a, b)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Numpy 3D Matrix Multiplication (Same Dimensions)\r\n                \r\nI am trying to multiply two 3D matrices with the same dimensions (MxNxD). I know in 2D matrix multiplication, I can just transpose one and do the matrix multiplication. Is there a similar approach for this with 3D matrices? I'm not really sure how I can multiply the two. I don't really understand how np.einsum works or how I could use it.\n    ", "Answer": "\r\nYou need to specify what you want the \"multiplication\" to do. One possible approach is:\n```\nimport numpy as np\n\nM = 10\nN = 20\nD = 30\n\nA = np.random.rand(M, N, D)\nB = np.random.rand(M, N, D)\n\nC = np.einsum('ijk,ijk->ij', A, B)\nprint(C.shape) # (10, 20)\n```\n\nBut you can do many more, for example:\n```\nC = np.einsum('ijk,ijk->jk', A, B)\nprint(C.shape) # (20, 30)\n\nC = np.einsum('ijk,ijk->ik', A, B)\nprint(C.shape) # (10, 30)\n```\n\nOr simply element-wise multiplication:\n```\nC = np.einsum('ijk,ijk->ijk', A, B)\nprint(C.shape) # (10, 20, 30)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Why is this naive matrix multiplication faster than base R's?\r\n                \r\nIn R, matrix multiplication is very optimized, i.e. is really just a call to BLAS/LAPACK. However, I'm surprised this very naive C++ code for matrix-vector multiplication seems reliably 30% faster. \n\n```\n library(Rcpp)\n\n # Simple C++ code for matrix multiplication\n mm_code = \n \"NumericVector my_mm(NumericMatrix m, NumericVector v){\n   int nRow = m.rows();\n   int nCol = m.cols();\n   NumericVector ans(nRow);\n   double v_j;\n   for(int j = 0; j < nCol; j++){\n     v_j = v[j];\n     for(int i = 0; i < nRow; i++){\n       ans[i] += m(i,j) * v_j;\n     }\n   }\n   return(ans);\n }\n \"\n # Compiling\n my_mm = cppFunction(code = mm_code)\n\n # Simulating data to use\n nRow = 10^4\n nCol = 10^4\n\n m = matrix(rnorm(nRow * nCol), nrow = nRow)\n v = rnorm(nCol)\n\n system.time(my_ans <- my_mm(m, v))\n#>    user  system elapsed \n#>   0.103   0.001   0.103 \n system.time(r_ans <- m %*% v)\n#>   user  system elapsed \n#>  0.154   0.001   0.154 \n\n # Double checking answer is correct\n max(abs(my_ans - r_ans))\n #> [1] 0\n```\n\n\nDoes base R's ```\n%*%```\n perform some type of data check that I'm skipping over?\n\nEDIT:\n\nAfter understanding what's going on (thanks SO!), it's worth noting that this is a worst case scenario for R's ```\n%*%```\n, i.e. matrix by vector. For example, @RalfStubner pointed out that using an RcppArmadillo implementation of a matrix-vector multiply is even faster than the naive implementation that I demonstrated, implying considerable faster than base R, but is virtually identical to base R's ```\n%*%```\n for matrix-matrix multiply (when both matrices are large and square):\n\n```\n arma_code <- \n   \"arma::mat arma_mm(const arma::mat& m, const arma::mat& m2) {\n return m * m2;\n };\"\n arma_mm = cppFunction(code = arma_code, depends = \"RcppArmadillo\")\n\n nRow = 10^3 \n nCol = 10^3\n\n mat1 = matrix(rnorm(nRow * nCol), \n               nrow = nRow)\n mat2 = matrix(rnorm(nRow * nCol), \n               nrow = nRow)\n\n system.time(arma_mm(mat1, mat2))\n#>   user  system elapsed \n#>   0.798   0.008   0.814 \n system.time(mat1 %*% mat2)\n#>   user  system elapsed \n#>   0.807   0.005   0.822  \n```\n\n\nSo R's current (v3.5.0) ```\n%*%```\n is near optimal for matrix-matrix, but could be significantly sped up for matrix-vector if you're okay skipping the checking.\n    ", "Answer": "\r\nA quick glance in ```\nnames.c```\n (here in particular) points you to ```\ndo_matprod```\n, the C function that is called by ```\n%*%```\n and which is found in the file ```\narray.c```\n. (Interestingly, it turns out, that both ```\ncrossprod```\n and ```\ntcrossprod```\n dispatch to that same function as well). Here is a link to the code of ```\ndo_matprod```\n.\n\nScrolling through the function, you can see that it takes care of a number of things your naive implementation does not, including:\n\n\nKeeps row and column names, where that makes sense.\nAllows for dispatch to alternative S4 methods when the two objects being operated on by a call to ```\n%*%```\n are of classes for which such methods have been provided. (That's what's happening in this portion of the function.) \nHandles both real and complex matrices.\nImplements a series of rules for how to handle multiplication of a matrix and a matrix, a vector and a matrix, a matrix and a vector, and a vector and a vector. (Recall that under cross-multiplication in R, a vector on the LHS is treated as a row vector, whereas on the RHS, it is treated as a column vector; this is the code that makes that so.)\n\n\nNear the end of the function, it dispatches to either of ```\nmatprod```\n or or ```\ncmatprod```\n. Interestingly (to me at least), in the case of real matrices, if either matrix might contain ```\nNaN```\n or ```\nInf```\n values, then ```\nmatprod```\n dispatches (here) to a function called ```\nsimple_matprod```\n which is about as simple and straightforward as your own. Otherwise, it dispatches to one of a couple of BLAS Fortran routines which, presumably are faster, if uniformly 'well-behaved' matrix elements can be guaranteed.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Error using simple matrix multiplication\r\n                \r\nI stumbled upon an error during a simple multiplication that rather surprised me. What is happening here, I always assumed ```\n*```\n was only for matrix multiplication.\n\n```\nx = 2;\ny = zeros(1,4);\ny(1) = 1 *x;\ny(2) = x* 1;\ny(3) = (x *1);\ny(4) = x *1;\ny\nx *1\n```\n\n\nWill give the following output:\n\n```\ny =\n\n     2     2     2     1\n\nError: \"x\" was previously used as a variable,\nconflicting with its use here as the name of a function or command.\nSee MATLAB Programming, \"How MATLAB Recognizes Function Calls That Use Command Syntax\" for details.\n```\n\n\nDoes anyone understand what is going on here? Of course I verified that ```\nx```\n is not a function.\n    ", "Answer": "\r\nIt depends on the spacing. See also here for a longer explanation and some examples of when  you could have genuine ambiguity, but basically the first three of these will work as you expected, and the last will assume you are trying to call a function x with input *1:\n\n```\nx*1  \nx * 1 \nx* 1\nx *1\n```\n\n\nThis doesn't happen if you assign the output to some variable, regardless of spacing: \n\n```\ny(2) = x *1\nz = x *1\nx = x *1\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in R, strange results [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        Why are these numbers not equal?\r\n                            \r\n                                (6 answers)\r\n                            \r\n                    \r\n                Closed 9 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nWhile checking some matrix multiplication operations, I came across a strange behavior. I get different results when I perform the multiplication \"by hand\" (using the product and the sum) and when using the matrix multiplication operator %*%. \n\n```\nc <- 1:10\na <- 100^(0:9)\np1 <- sum(a*c)\np2 <- a%*%c\np1==p2\n      [,1]\n[1,] FALSE\np1-p2\n      [,1]\n[1,] -2048\n```\n\n\nHowever, when I use any other value for a (e.g., a <- 101^0:9) , I do get the same results:\n\n```\nc <- 1:10\na <- 101^(0:9)\np1 <- sum(a*c)\np2 <- a%*%c\np1==p2\n      [,1]\n[1,] TRUE\np1-p2\n      [,1]\n[1,] 0\n```\n\n\nAny idea why this is happening?\n\nThank you,\nPedro\n    ", "Answer": "\r\n```\n%*%```\n does compute its results in a slightly different way, which means that different rounding errors occur at different places, leading to a different overall result.\n\nI'm just guessing, but I believe that this might be due to ```\nsum```\n keeping its accumulator in a machine floating point register, which has 80 bit extended precision on Intel architectures. If you want to know for certain, you'd have to look at the assembly code of R.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Fast Matrix Multiplication\r\n                \r\nI have an interview test where I have to implement a fast matrix multiplication with a given matrix multiplication algorithm.\n\nI have to implement it on any platform with any compiler I want. The task says:\n\n•PC implementation should be ready for SIMD optimization.\n• Design a rational interface to the data processing module.\n• Write portable ANSIC code where it doesn't degrade the efficiency. Don’t use assembler.\n• Think about the number of operations, complexity of the operations. Care about things like function call overhead, loop overhead, memory access time and cache performance\n\nShould I implement this on a platform like raspberry pi? Or on a CPU+DSP or ARM+NEON or CPU+GPU simulator? Or just give the code?\n\nThank you\n    ", "Answer": "\r\nThere a whole theory about Instruction level parallelism, thread level parallelism, Cache utilization and what not used in speeding up matrix multiplication.\n\nI can point you, first to learn how the CPU cache works. When a block is loaded into cache, how it is mapped to to cache index, when a block is evicted etc. Consult a book on Computer architecture, or Wikipedia.\n\nThen I can point you to the blocking matrix multiplication algorithm.\n\nAnd last there is the BLAS specification and OpenBLAS as the fastest implementation for CPUs.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Static Matrix multiplication to dynamic matrix in c\r\n                \r\nI need to build program that make Matrix multiplication.\nWhen i have 2 Static matrix, and the function return pointer to the new dynamic matrix.\n\nMy problem is make the multiplication right when I'm moving the matrix into a function.\n\nMain is:\n\n```\n    int f_matrix[EX2_SIZE][EX2_SIZE] = { {1,2,3}, {1,4,7},{1,5,9} };\nint s_matrix[EX2_SIZE][EX2_SIZE] = { {9,8,7},{4,5,6},{0,9,6} };\nint m1_rows = EX2_SIZE, m1_cols = EX2_SIZE; \nint m2_rows = EX2_SIZE, m2_cols = EX2_SIZE; //For tester can change easily\nint **new_matrix;\n\nif (m1_rows != m2_rows || m1_cols != m2_cols) return 0;  //For multiplying must be equal matrix !!\n\nnew_matrix = multiplying(f_matrix, s_matrix, m1_rows, m1_cols);\nprint_mtrx(new_matrix, m1_rows, m1_cols);\nfree_mtrx(new_matrix, m1_cols);\n```\n\n\nThe problem is in the \"multiplying\" function, and here is it:\n\n```\nint multiplying(int **A, int **B, int rows, int cols) {\nint **C;\nint i,j;\nC = (int**)malloc(sizeof(int*)*rows);\nfor (i = 0; i < cols; i++) {\n    C[i] = (int*)malloc(sizeof(int)*cols);\n        for (j = 0; j < cols; j++)\n            C[i][j] = (A[i][j]) * (B[i][j]);\n}\n\nreturn C;\n}\n```\n\n\nTHX\n    ", "Answer": "\r\nAssuming C99 (or C11 and the implementation does not define ```\n__STDC_NO_VLA__```\n), then the simplest approach is use variable length arrays (VLAs) and to have the calling code allocate the space for the result matrix too.  To multiply two matrices, ```\nA[M][N]```\n and ```\nB[P][Q]```\n in that order, the values of ```\nN```\n and ```\nP```\n must be equal and the result matrix is ```\nC[M][Q]```\n.\n\n```\n#include <stdio.h>\n\nstatic\nvoid matrix_multiply(int A_rows, int A_cols, int B_cols,\n                     int A[A_rows][A_cols],\n                     int B[A_cols][B_cols],\n                     int C[A_rows][B_cols])\n{\n    for (int i = 0; i < A_rows; i++)\n    {\n         for (int j = 0; j < B_cols; j++)\n         {\n              int sum = 0;\n              for (int k = 0; k < A_cols; k++)\n                  sum += A[i][k] * B[k][j];\n              C[i][j] = sum;\n         }\n    }\n}\n\nstatic void print_matrix(const char *tag, int w, int N, int M, int matrix[N][M])\n{\n    printf(\"%s (%dx%d):\\n\", tag, N, M);\n    for (int i = 0; i < N; i++)\n    {\n         for (int j = 0; j < M; j++)\n             printf(\"%*d\", w, matrix[i][j]);\n         putchar('\\n');\n    }\n}\n\nint main(void)\n{\n    int A[3][4] =\n    {\n        { 41, 76, 70, 42, },\n        { 70, 62, 77, 74, },\n        { 49, 55, 43, 65, },\n    };\n    int B[4][5] =\n    {\n        { 73, 33, 42, 72, 65, },\n        { 69, 30, 83, 83, 64, },\n        { 90, 74, 84, 51, 23, },\n        { 62, 45, 84, 46, 43, },\n    };\n    int C[3][5];\n    print_matrix(\"A\", 3, 3, 4, A);\n    print_matrix(\"B\", 3, 4, 5, B);\n    matrix_multiply(3, 4, 5, A, B, C);\n    print_matrix(\"C\", 6, 3, 5, C);\n    return 0;\n}\n```\n\n\nOutput:\n\n```\nA (3x4):\n 41 76 70 42\n 70 62 77 74\n 49 55 43 65\nB (4x5):\n 73 33 42 72 65\n 69 30 83 83 64\n 90 74 84 51 23\n 62 45 84 46 43\nC (3x5):\n 17141 10703 17438 14762 10945\n 20906 13198 20770 17517 13471\n 15272  9374 15695 13276 10489\n```\n\n\nIf you want to do dynamic memory allocation, then I think you have to pass a pointer to a pointer to a VLA array to the function to get the value returned.  That leads to code like this, which is very similar to the previous code — except for the (unchecked) memory allocation.  Note that because this uses ```\nstatic_assert```\n, it is a C11 program, not a C99 program.\n\n```\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#ifdef __STDC_NO_VLA__      // C11\nstatic_assert(0, \"No VLA support\");\n#endif\n\nstatic void matrix_multiply(int A_rows, int A_cols, int B_cols,\n                            int A[A_rows][A_cols], int B[A_cols][B_cols],\n                            int (**C)[B_cols])\n{\n    (*C) = malloc(sizeof(int [A_rows][B_cols]));  // XXX: Check memory allocation!\n    for (int i = 0; i < A_rows; i++)\n    {\n         for (int j = 0; j < B_cols; j++)\n         {\n              int sum = 0;\n              for (int k = 0; k < A_cols; k++)\n                  sum += A[i][k] * B[k][j];\n              (*C)[i][j] = sum;\n         }\n    }\n}\n\nstatic void print_matrix(const char *tag, int w, int N, int M, int matrix[N][M])\n{\n    printf(\"%s (%dx%d):\\n\", tag, N, M);\n    for (int i = 0; i < N; i++)\n    {\n         for (int j = 0; j < M; j++)\n             printf(\"%*d\", w, matrix[i][j]);\n         putchar('\\n');\n    }\n}\n\nint main(void)\n{\n    enum { N = 3, M = 4, P = 4, Q = 5 };\n    int A[N][M] =\n    {\n        { 41, 76, 70, 42, },\n        { 70, 62, 77, 74, },\n        { 49, 55, 43, 65, },\n    };\n    int B[P][Q] =\n    {\n        { 73, 33, 42, 72, 65, },\n        { 69, 30, 83, 83, 64, },\n        { 90, 74, 84, 51, 23, },\n        { 62, 45, 84, 46, 43, },\n    };\n    static_assert(M == P, \"Matrix dimensions are mismatched\");\n    int (*C)[Q];\n    print_matrix(\"A\", 3, N, M, A);\n    print_matrix(\"B\", 3, P, Q, B);\n    matrix_multiply(N, M, Q, A, B, &C);\n    print_matrix(\"C\", 6, N, Q, C);\n    free(C);\n    return 0;\n}\n```\n\n\nThis produces the same output as before, of course.\n\n\n\nAnalyzing original code\n\nHere's a fixed variant of your original code.\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n\nstatic void free_mtrx(int **mtrx, int rows)\n{\n    for (int i = 0; i < rows; i++)\n        free(mtrx[i]);\n    free(mtrx);\n}\n\nstatic int **multiplying_1(int **A, int **B, int rows, int cols)\n{\n    int **C;\n    C = (int **)malloc(sizeof(int *) * rows);\n    for (int i = 0; i < cols; i++)\n    {\n        C[i] = (int *)malloc(sizeof(int) * cols);\n        for (int j = 0; j < cols; j++)\n            C[i][j] = (A[i][j]) * (B[i][j]);\n    }\n    return C;\n}\n\nstatic void print_mtrx(const char *tag, int w, int N, int M, int **matrix)\n{\n    printf(\"%s (%dx%d):\\n\", tag, N, M);\n    for (int i = 0; i < N; i++)\n    {\n        for (int j = 0; j < M; j++)\n            printf(\"%*d\", w, matrix[i][j]);\n        putchar('\\n');\n    }\n}\n\nint main(void)\n{\n    enum { EX2_SIZE = 3, EX3_SIZE = 3 };\n    int f_matrix[EX2_SIZE][EX2_SIZE] = { {1, 2, 3}, {1, 4, 7}, {1, 5, 9} };\n    int s_matrix[EX2_SIZE][EX2_SIZE] = { {9, 8, 7}, {4, 5, 6}, {0, 9, 6} };\n    int m1_rows = EX2_SIZE, m1_cols = EX2_SIZE;\n    int m2_rows = EX2_SIZE, m2_cols = EX2_SIZE; // For tester can change easily\n    int *f[] = { &f_matrix[0][0], &f_matrix[1][0], &f_matrix[2][0] };\n    int *s[] = { &s_matrix[0][0], &s_matrix[1][0], &s_matrix[2][0] };\n    int **new_matrix;\n\n    if (m1_rows != m2_rows || m1_cols != m2_cols)\n        return 0;\n\n    print_mtrx(\"F\", 3, EX2_SIZE, EX2_SIZE, f);\n    print_mtrx(\"S\", 3, EX3_SIZE, EX3_SIZE, s);\n\n    new_matrix = multiplying(f, s, m1_rows, m1_cols);\n    print_mtrx(\"R\", 3, m1_rows, m1_cols, new_matrix);\n    free_mtrx(new_matrix, m1_cols);\n\n    return 0;\n}\n```\n\n\nGranted, the 'matrix multiplication' algorithm isn't the conventional mathematical one; that's not a major issue.  The key point is that ```\nint **matrix```\n is not the same as ```\nint matrix[N][M]```\n.  The latter consists solely of integer values; the former is an array of pointers, each of which points to a series of integer values.  With the prototype for ```\nmultiplying()```\n in scope, the compiler complained about your original calls.  I manufactured the array of pointers from the arrays of integers when creating the matrices ```\nf```\n and ```\ns```\n from ```\nf_matrix```\n and ```\ns_matrix```\n.  Note that the body of the ```\nprint_mtrx()```\n function is identical to the body of the ```\nprint_matrix()```\n functions in the previous two programs.  However, the code generated is not the same because the argument lists use two different, incompatible types for the matrix argument.  Valgrind gives this program a clean bill of health.\n\nOutput:\n\n```\nF (3x3):\n  1  2  3\n  1  4  7\n  1  5  9\nS (3x3):\n  9  8  7\n  4  5  6\n  0  9  6\nR (3x3):\n  9 16 21\n  4 20 42\n  0 45 54\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Segmentation Fault During Matrix Multiplication\r\n                \r\nI am new to C coding, and am trying to implement standard matrix multiplication. My code works fine for square matrices, but refuses to accept a column vector. Here is my attempt at the code. Any help would be much appreciated.\n```\n//---------------------------------------IMPORTING NECESSARY C PACKAGES AND DEFINING EXECUTION CONSTANTS-------------------------------------------//\n#include <stdio.h> // Standard input output library\n#include <math.h> // Mathematical function library\n#include <stdlib.h> // General purpose standard library\n\n#define true 1\n#define false 0\ntypedef long double numeric; // Using the long double datatype to avoid overflows during computations\n//-------------------------------------------------------------------------------------------------------------------------------------------------//\n\n//----------------------------------------------------------------FUNCTION DECLERATION-------------------------------------------------------------//\nnumeric **create_matrix(int x, int y); // To dynamically allocate memory and create a matrix\nvoid input_matrix(numeric **matrix, int m, int n); // To accept a matrix\nvoid print_matrix(numeric **l, int x, int y); // To print a matrix\nnumeric **standard_matrix_multiplication(int m, int n, int l); // To multiply two matrices\n//-------------------------------------------------------------------------------------------------------------------------------------------------//\n\n//------------------------------------------------------------------DRIVER CODE--------------------------------------------------------------------//\nint main(int argc, char *argv[]) {\n  int m, n, l; int choice;\n  printf(\"Enter the matrix operation to be performed using the corresponding index number.\\n\");\n  printf(\"\\n\");\n  printf(\"1.\\tMatrix Multiplication\");\n  printf(\"\\n\");\n  scanf(\"%d\", &choice);\n\n  switch(choice) {\n    case 1 :\n    printf(\"Enter the number of rows in the first matrix\\n\");\n    scanf(\"%d\", &m);\n    printf(\"Enter the number of columns in the first matrix\\n\");\n    scanf(\"%d\", &n);\n    printf(\"Enter the number of columns in the second matrix\\n\");\n    scanf(\"%d\", &l);\n    printf(\"Enter both matrices.\\n\");\n    numeric **matrix_x;\n    matrix_x = create_matrix(m, l);\n    matrix_x = standard_matrix_multiplication(m, n, l);\n    print_matrix(matrix_x, m, l);\n    break;\n  }\n}\n//-------------------------------------------------------------------------------------------------------------------------------------------------//\n\n//----------------------------------------------------------MATRIX MULTIPLICATION IMPLEMENTATIONS--------------------------------------------------//\nnumeric **standard_matrix_multiplication(int m, int n, int l) {\n  numeric **matrix_a; numeric **matrix_b; numeric **matrix_k;\n  matrix_a = create_matrix(m, n);\n  matrix_b = create_matrix(n, l);\n  matrix_k = create_matrix(m, l);\n  input_matrix(matrix_a, m, n);\n  print_matrix(matrix_a, m, n);\n  input_matrix(matrix_b, n, l);\n  for(int i = 0; i < m; i++) {\n    for (int j = 0; j < n; j ++) {\n      for (int k = 0; k < l; k++) {\n        matrix_k[i][j] += matrix_a[i][k] * matrix_b[k][j];\n      }\n    }\n  }\n  return matrix_k;\n}\n//-------------------------------------------------------------------------------------------------------------------------------------------------//\n\n//---------------------------------------------------------------HELPER FUNCTIONS------------------------------------------------------------------//\nnumeric **create_matrix(int x, int y) {\n  numeric **matrix = (numeric**)malloc(x * sizeof(numeric*)); // Dynamically creating an array of pointers\n  for (int i = 0; i < y; i++) {\n    matrix[i] = (numeric*)malloc(y * sizeof(numeric)); // Dynamically allocating memory for each columns of the matrix\n  }\n  return matrix;\n}\n\nvoid input_matrix(numeric **matrix, int m, int n) {\n  printf(\"Enter the elements of the matrix, row wise.\\n\"); // Instructing the user on matrix entry\n  printf(\"For example, to enter the matrix\\n\");\n  printf(\"\\t\\t1\\t2\\n\");\n  printf(\"\\t\\t3\\t4\\n\");\n  printf(\"enter 1, 2, 3, and 4 in that order.\\n\");\n\n  for (int i = 0; i < m; i++) { // Iterating through the rows and columns of the matrix\n    for (int j = 0; j < n; j++) {\n      scanf(\"%Lf\", &matrix[i][j]); // Accepting each element\n    }\n  }\n}\n\nvoid print_matrix(numeric **l, int x, int y) { // To print a matrix\n    for (int i = 0; i < x; i++) {\n        for (int j = 0; j < y; j++) {\n            printf(\"%0.10Lf\\t\", l[i][j]); // Printing numeric type values\n        }\n    printf(\"\\n\");\n    }\n  printf(\"\\n\");\n}\n\n```\n\nAs of now, I have only written one switch case, and that is for matrix multiplication. So I chose 1. I gave 2, 1, 2 as my inputs for the number of rows in the first matrix, number of columns in the first matrix, and number of columns in the second matrix respectively. I have given a print statement in line 52, and it isn't executing it for the above input, giving a segmentation fault instead. Could someone please help me out?\n    ", "Answer": "\r\nYes there are some issues with your code that gives segfault error during runtime.\nThe Matrix multiplication logic part of the code needs to be corrected as follows\n```\nfor(int i = 0; i < m; i++) {\nfor (int j = 0; j < l; j ++) {\n  for (int k = 0; k < n; k++) {\n    matrix_k[i][j] += matrix_a[i][k] * matrix_b[k][j];\n```\n\nbecause k should iterate till the no of columns in 1st matrix which is n but not till l.\nAnd there is a slight correction needed in create_matrix function.\nYou use y (i.e. no of columns in the matrix) in your for instead of x (no of rows in matrix).\nIf x < y, you end up outside of the memory you allocated.\nIf x > y, you end up with uninitialized pointers.\nSo change it as follows\n```\nfor (int i = 0; i < x; i++) {\nmatrix[i] = (numeric*)malloc(y * sizeof(numeric)); \n```\n\nAfter these corrections try executing the code, you should get the expected results without any segfault errors\nHere is the complete working code\n```\n#include <stdio.h> // Standard input output library\n#include <math.h> // Mathematical function library\n#include <stdlib.h> // General purpose standard library\n\n#define true 1\n#define false 0\ntypedef long double numeric; // Using the long double datatype to avoid overflows during computations\n//-------------------------------------------------------------------------------------------------------------------------------------------------//\n\n//----------------------------------------------------------------FUNCTION DECLERATION-------------------------------------------------------------//\nnumeric **create_matrix(int x, int y); // To dynamically allocate memory and create a matrix\nvoid input_matrix(numeric **matrix, int m, int n); // To accept a matrix\nvoid print_matrix(numeric **l, int x, int y); // To print a matrix\nnumeric **standard_matrix_multiplication(int m, int n, int l); // To multiply two matrices\n//-------------------------------------------------------------------------------------------------------------------------------------------------//\n\n//------------------------------------------------------------------DRIVER CODE--------------------------------------------------------------------//\nint main(int argc, char *argv[]) {\n  int m, n, l; int choice;\n  printf(\"Enter the matrix operation to be performed using the corresponding index number.\\n\");\n  printf(\"\\n\");\n  printf(\"1.\\tMatrix Multiplication\");\n  printf(\"\\n\");\n  scanf(\"%d\", &choice);\n\n  switch(choice) {\n    case 1 :\n    printf(\"Enter the number of rows in the first matrix\\n\");\n    scanf(\"%d\", &m);\n    printf(\"Enter the number of columns in the first matrix\\n\");\n    scanf(\"%d\", &n);\n    printf(\"Enter the number of columns in the second matrix\\n\");\n    scanf(\"%d\", &l);\n    printf(\"Enter both matrices.\\n\");\n    numeric **matrix_x;\n    matrix_x = create_matrix(m, l);\n    matrix_x = standard_matrix_multiplication(m, n, l);\n    print_matrix(matrix_x, m, l);\n    break;\n  }\n}\n//-------------------------------------------------------------------------------------------------------------------------------------------------//\n\n//----------------------------------------------------------MATRIX MULTIPLICATION IMPLEMENTATIONS--------------------------------------------------//\nnumeric **standard_matrix_multiplication(int m, int n, int l) {\n  numeric **matrix_a; numeric **matrix_b; numeric **matrix_k;\n  matrix_a = create_matrix(m, n);\n  matrix_b = create_matrix(n, l);\n  matrix_k = create_matrix(m, l);\n  input_matrix(matrix_a, m, n);\n  print_matrix(matrix_a, m, n);\n  input_matrix(matrix_b, n, l);\n  //print_matrix(matrix_b, n, l);\n  for(int i = 0; i < m; i++) {\n    for (int j = 0; j < l; j ++) {\n      for (int k = 0; k < n; k++) {\n        matrix_k[i][j] += matrix_a[i][k] * matrix_b[k][j];\n\n      }\n    }\n  }\n  return matrix_k;\n}\n//-------------------------------------------------------------------------------------------------------------------------------------------------//\n\n//---------------------------------------------------------------HELPER FUNCTIONS------------------------------------------------------------------//\nnumeric **create_matrix(int x, int y) {\n  numeric **matrix = (numeric**)malloc(x * sizeof(numeric*)); // Dynamically creating an array of pointers\n  for (int i = 0; i < x; i++) {\n    matrix[i] = (numeric*)malloc(y * sizeof(numeric)); // Dynamically allocating memory for each columns of the matrix\n  }\n  return matrix;\n}\n\nvoid input_matrix(numeric **matrix, int m, int n) {\n  printf(\"Enter the elements of the matrix, row wise.\\n\"); // Instructing the user on matrix entry\n  printf(\"For example, to enter the matrix\\n\");\n  printf(\"\\t\\t1\\t2\\n\");\n  printf(\"\\t\\t3\\t4\\n\");\n  printf(\"enter 1, 2, 3, and 4 in that order.\\n\");\n\n  for (int i = 0; i < m; i++) { // Iterating through the rows and columns of the matrix\n    for (int j = 0; j < n; j++) {\n      scanf(\"%Lf\", &matrix[i][j]); // Accepting each element\n    }\n  }\n}\n\nvoid print_matrix(numeric **l, int x, int y) { // To print a matrix\n    for (int i = 0; i < x; i++) {\n        for (int j = 0; j < y; j++) {\n            printf(\"%0.10Lf\\t\", l[i][j]); // Printing numeric type values\n        }\n    printf(\"\\n\");\n    }\n  printf(\"\\n\");\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Random matrix multiplication [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is not reproducible or was caused by typos. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question was caused by a typo or a problem that can no longer be reproduced. While similar questions may be on-topic here, this one was resolved in a way less likely to help future readers.\r\n                \r\n                    \r\n                        Closed 10 months ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI need to create at least 2 matrix 4x4, multiplicate them and display the result, but I'm getting this thing as as result img\nI'm creating matrix a[i][j] and matrix b[k][l], and trying to pass the result to a new matrix called c[i][j]\nBesides that, I need to make 2 kinds of matrix multiplication, one like this, and another one like this\nCan you please please please help? Code below\n```\n#include<iostream>\n#include<stdlib.h>\n#include<time.h>\nusing namespace std;\n\nint matriz1() {\n    int a[4][4], i, j;\n    for (i = 0; i < 4; ++i)\n    {\n        for (j = 0; j < 4; ++j)\n        {\n            a[i][j] = rand() % 100 + 1;\n        }\n    }\n\n    for (i = 0; i < 4; ++i)\n    {\n        for (j = 0; j < 4; ++j)\n            std::cout << a[i][j] << '\\t';\n        std::cout << '\\n';\n\n    }\n    std::cout << '\\n';\n    std::cout << \"x\" << std::endl;\n    std::cout << '\\n';\n    std::cout << \"Matriz 2:\" << std::endl;\n\n    int b[4][4], k, l;\n    for (k = 0; k < 4; ++k)\n    {\n        for (l = 0; l < 4; ++l)\n        {\n            b[k][l] = rand() % 100 + 1;\n        }\n    }\n\n    for (k = 0; k < 4; ++k)\n    {\n        for (l = 0; l < 4; ++l)\n\n            std::cout << b[k][l] << '\\t';\n        std::cout << '\\n';\n    }\n\n    std::cout << '\\n';\n    int c[4][4], m, n, x;\n   \n \n        for (i = 0; i < 4; i++) {\n            for (j = 0; j < 4; j++) {\n                for (k = 0; k < 4; k++) {\n                    c[i][j] += a[i][k] * b[k][j];\n                }\n            }\n        }\n        cout << \" RESULTADO!!!!!!!!!!!!!!!!!!!!!!\" << endl;\n        for (i = 0; i < 4; i++) {\n            for (j = 0; j < 4; j++) {\n                cout << c[i][j] << \"\\t\";\n            }\n            cout << \"\\n\";\n        }\n        return 0;\n    }\n\n\nint main()\n{\n\n    srand(time(0));\n\n    std::cout << \"Matriz 1:\" << std::endl;\n    std::cout << matriz1() << std::endl;\n\n}\n```\n\nSOLVED IN THE COMMENTS! Stop disliking my post its my first post\n    ", "Answer": "\r\nYou do this:\n```\nc[i][j] += a[i][k] * b[k][j];\n```\n\nbut you never initialized ```\nc```\n array, it contains random values, likely something like\n0xCDCDCDCD (-842150451). Initialize it like this:\n```\nint c[4][4] = {}\n```\n\nYou have repeated code, so consider to break it up in functions, e.g. you can initialize matrices as functions and  output one as another. THat would make  code more readable  and easier to find errors.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Is numpy matrix multiplication same as Linear Algebra matrix multiplication?\r\n                \r\nAs we know that In Linear Algebra it is mandatory to multiply a vector by matrix or multiply two matrices, the number of rows of one matrix or vector must be equal to the number of columns in other vector or matrix.\nwhile i was working in ```\nnumpy```\n python and it is giving me a different result.\nHere is my code and it works.\n```\nnp.array([1,2]) * np.array([[1],[2],[3]])\n```\n\n\nso is there any difference between ```\nnumpy```\n vector to matrix\nmatlication vs linear algebra vector to matrix multiplication.\n\n    ", "Answer": "\r\nuse numpy np.dot(a,b)\nUse the following code and you will get error you want.\n```\nnp.dot(np.array([1,2]) ,  np.array([[1],[2],[3]]))\n```\n\nBecuase ```\n*,+,-,/```\n works element-wise on arrays.\n\nIf either a or b is 0-D (scalar), it is equivalent to multiply and\nusing numpy.multiply(a, b) or a * b is preferred.\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Multithreading on numpy/pandas matrix multiplication?\r\n                \r\nI really want to know how to utilize multi-core processing for matrix multiplication on numpy/pandas.\n\nWhat I'm trying is here:\n\n```\nM = pd.DataFrame(...) # super high dimensional square matrix.\nA = M.T.dot(M) \n```\n\n\nThis takes huge processing time because of many sums of products, and I think it's straightforward to use multithreading for huge matrix multiplication. So, I was googling carefully, but I can't find how to do that on numpy/pandas. Do I need to write multi thread code manually with some python built-in threading library?\n    ", "Answer": "\r\nIn NumPy, multithreaded matrix multiplication can be achieved with a multithreaded implementation of BLAS, the Basic Linear Algebra Subroutines. You need to:\n\n\nHave such a BLAS implementation; OpenBLAS, ATLAS and MKL all include multithreaded matrix multiplication.\nHave a NumPy compiled to use such an implementation.\nMake sure the matrices you're multiplying both have a ```\ndtype```\n of ```\nfloat32```\n or ```\nfloat64```\n (and meet certain alignment restrictions; I recommend using NumPy 1.7.1 or later where these have been relaxed).\n\n\nA few caveats apply:\n\n\nOlder versions of OpenBLAS, when compiled with GCC, runs into trouble in programs that use ```\nmultiprocessing```\n, which includes most applications that use ```\njoblib```\n. In particular, they will hang. The reason is a bug (or lack of a feature) in GCC. A patch has been submitted but not included in the mainline sources yet.\nThe ATLAS packages you find in a typical Linux distro may or may not be compiled to use multithreading.\n\n\nAs for Pandas: I'm not sure how it does dot products. Convert to NumPy arrays and back to be sure.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Pthreads matrix multiplication error\r\n                \r\nI want to use pthreads on my existing serial matrix multiplication code. My goal is to achieve better execution time using pthreads, simply to achieve speed-up. But at that point I'm stuck. My original serial code, works just fine, and I finish 1000x1000 square matrix multiplication in about 15 seconds. But when I execute my current pthreads program, I get a segmentation fault. Here is my code:\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\nint SIZE, NTHREADS;\nint **A, **B, **C;\n\nvoid init()\n{\n    int i, j;\n\n    A = (int**)malloc(SIZE * sizeof(int *));\n    for(i = 0; i < SIZE; i++)\n        A[i] = malloc(SIZE * sizeof(int));\n\n    B = (int**)malloc(SIZE * sizeof(int *));\n    for(i = 0; i < SIZE; i++)\n        B[i] = malloc(SIZE * sizeof(int));\n\n    C = (int**)malloc(SIZE * sizeof(int *));\n    for(i = 0; i < SIZE; i++)\n        C[i] = malloc(SIZE * sizeof(int));\n\n    srand(time(NULL));\n\n    for(i = 0; i < SIZE; i++) {\n        for(j = 0; j < SIZE; j++) {\n            A[i][j] = rand()%100;\n            B[i][j] = rand()%100;\n        }\n    }\n}\n\nvoid mm(int tid)\n{\n    int i, j, k;\n    int start = tid * SIZE/NTHREADS;\n    int end = (tid+1) * (SIZE/NTHREADS) - 1;\n\n    for(i = start; i <= end; i++) {\n        for(j = 0; j < SIZE; j++) {\n            C[i][j] = 0;\n            for(k = 0; k < SIZE; k++) {\n                C[i][j] += A[i][k] * B[k][j];\n            }\n        }\n    }\n}\n\nvoid *worker(void *arg)\n{\n    int tid = *((int *) arg);\n    mm(tid);\n}\n\nint main(int argc, char* argv[])\n{\n    pthread_t* threads;\n    int rc, i;\n\n    if(argc != 3)\n    {\n        printf(\"Usage: %s <size_of_square_matrix> <number_of_threads>\\n\", argv[0]);\n        exit(1);\n    }\n\n    SIZE = atoi(argv[1]);\n    NTHREADS = atoi(argv[2]);\n    init();\n    threads = (pthread_t*)malloc(NTHREADS * sizeof(pthread_t));\n\n    clock_t begin, end;\n    double time_spent;\n\n\n    begin = clock();\n\n    for(i = 0; i < NTHREADS; i++) {\n        rc = pthread_create(&threads[i], NULL, worker, (void *)i);\n        assert(rc == 0);\n    }\n\n    for(i = 0; i < NTHREADS; i++) {\n        rc = pthread_join(threads[i], NULL);\n        assert(rc == 0);\n    } \n\n    end = clock();\n\n    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n    printf(\"Elapsed time: %.2lf seconds.\\n\", time_spent);\n\n    for(i = 0; i < SIZE; i++)\n        free((void *)A[i]);\n    free((void *)A);\n\n    for(i = 0; i < SIZE; i++)\n        free((void *)B[i]);\n    free((void *)B);\n\n    for(i = 0; i < SIZE; i++)\n        free((void *)C[i]);\n    free((void *)C);\n\n    free(threads);\n\n    return 0;\n}\n```\n\n\nIf someone could help me make my pthreads program run, and achieve some speed-up I would be glad.\n    ", "Answer": "\r\nWith your current code, you should retrieve the index using\n\n```\nint tid = (int)arg;\n```\n\n\n(Your code is effectively treating the loop counter as an address then dereferencing addresses at or around 0.  These addresses may not be readable by your process and/or won't be suitably aligned, hence the seg fault)\n\nThe above change might get things working for you but note that passing an ```\nint```\n as a ```\nvoid*```\n isn't completely correct.  It relies on ```\nsizeof(int) <= sizeof(void*)```\n which is likely but not guaranteed to be true.  If you cared about this, you could either allocate memory for the data you pass to each thread instead or pass the address of ```\ni```\n and include synchronisation to ensure that you wait after each ```\npthread_create```\n call until the thread has been scheduled and has read its arg.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Scipy optimization with matrix multiplication\r\n                \r\nI've tried to use ```\nspicy.optimize.minimize```\n to solve a matrix multiplication optimization problem, however, the result gives me a dimension error, can someone help me with it?\n\n```\nimport numpy as np\nfrom scipy.optimize import minimize\n\n# define known variables, mu, sigma, rf\nmu = np.matrix([[0.12], \n                [0.08], \n                [0.05]])\n\nsigma = np.matrix([[0.5, 0.05, 0.03],\n                   [0.05, 0.4, 0.01],\n                   [0.03, 0.01, 0.2]])\n\nrf = 0.02\n\ndef objective_fun(x):\n'''\nThis is the objective function\n'''\n    s = np.sqrt(x.T * sigma * x)/(mu.T * x - rf)\n    return s\n\ndef constraint(x):\n    con = 1 \n    for i in np.arange(0,3):\n        con = con - x[i] \n    return con\n\n# set up the boundaries for x\nbound_i = (0, np.Inf)\nbnds = (bound_i, bound_i, bound_i)\n\n#set up the constraints for x\ncon = {'type':'eq', 'fun':constraint}\n\n# initial guess for variable x\nx = np.matrix([[0.5],\n               [0.3],\n               [0.2]])\n\nsol = minimize(objective_fun, x, method = 'SLSQP', bounds = bnds, constraints = con)\n```\n\n\nThe error gives me:\n\n```\nValueError                                Traceback (most recent call last)\n<ipython-input-31-b8901077b164> in <module>\n----> 1 sol = minimize(objective_fun, x, method = 'SLSQP', bounds = bnds, constraints = con)\n\ne:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py in minimize(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\n    606     elif meth == 'slsqp':\n    607         return _minimize_slsqp(fun, x0, args, jac, bounds,\n--> 608                                constraints, callback=callback, **options)\n    609     elif meth == 'trust-constr':\n    610         return _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\ne:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py in _minimize_slsqp(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, **unknown_options)\n    397 \n    398             # Compute objective function\n--> 399             fx = func(x)\n    400             try:\n    401                 fx = float(np.asarray(fx))\n\ne:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py in function_wrapper(*wrapper_args)\n    324     def function_wrapper(*wrapper_args):\n    325         ncalls[0] += 1\n--> 326         return function(*(wrapper_args + args))\n    327 \n    328     return ncalls, function_wrapper\n\n<ipython-input-28-b1fb2386a380> in objective_fun(x)\n      3     This is the objective function\n      4     '''\n----> 5     s = np.sqrt(x.T * sigma * x)/(mu.T * x - rf)\n      6     return s\n\ne:\\Anaconda3\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py in __mul__(self, other)\n    218         if isinstance(other, (N.ndarray, list, tuple)) :\n    219             # This promotes 1-D vectors to row vectors\n--> 220             return N.dot(self, asmatrix(other))\n    221         if isscalar(other) or not hasattr(other, '__rmul__') :\n    222             return N.dot(self, other)\n\nValueError: shapes (1,3) and (1,3) not aligned: 3 (dim 1) != 1 (dim 0)\n```\n\n\nHowever, I tried individually every function I wrote, they all have no errors in the end, like, if after defining the x matrix as shown in the code, I simply run ```\nobjective_fun(x)```\n in the console, and I immediately get an answer:\n\n```\noptimize_fun(x)\nmatrix([[5.90897598]])\n```\n\n\nThat means that my function can do the matrix multiplication correctly, so what is wrong with the code here?\n    ", "Answer": "\r\nThe docs for ```\nminimize()```\n says that ```\nx0```\n should be an ```\n(n,)```\n shaped array, but you are trying to treat it like a ```\n(3,1)```\n array. I'm not sure on the inner workings of ```\nminimize()```\n but I suspect when it steps over different values of the fit parameters it converts to the format that it thinks it wants. Anyways, the following minor corrections make it so the code works.\n\n```\nimport numpy as np\nfrom scipy.optimize import minimize\n\n# define known variables, mu, sigma, rf\nmu = np.matrix([[0.12], \n                [0.08], \n                [0.05]])\n\nsigma = np.matrix([[0.5, 0.05, 0.03],\n                   [0.05, 0.4, 0.01],\n                   [0.03, 0.01, 0.2]])\n\nrf = 0.02\n\ndef objective_fun(x):\n  '''\n  This is the objective function\n  '''\n  x = np.expand_dims(x, 1) # convert the (3,) shape to (3,1). Then we can do our normal matrix math on it\n  s = np.sqrt(x.T * sigma * x)/(mu.T * x - rf) # Transposes so the shapes are correct\n  return s\n\ndef constraint(x):\n  con = 1 \n  for i in np.arange(0,3):\n      con = con - x[i] \n  return con\n\n# set up the boundaries for x\nbound_i = (0, np.Inf)\nbnds = (bound_i, bound_i, bound_i)\n\n#set up the constraints for x\ncon = {'type':'eq', 'fun':constraint}\n\n# initial guess for variable x\n\nx = np.array([0.5, 0.3, 0.2]) # Defining the initial guess as an (3,) array)\n\nsol = minimize(objective_fun, x, method = 'SLSQP', bounds = bnds, constraints = con)\nprint(sol) # and the solution looks reasonable\n```\n\n\nOutput\n\n```\n     fun: 5.86953830952583\n     jac: array([-1.70555401, -1.70578796, -1.70573896])\n message: 'Optimization terminated successfully.'\n    nfev: 32\n     nit: 6\n    njev: 6\n  status: 0\n success: True\n       x: array([0.42809911, 0.29522438, 0.27667651])\n```\n\n\nTake a look at the comments I put in for an explanation on what you need to do. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication isn't working\r\n                \r\nI'm having trouble with matrix multiplication. LMatrix has the dimensions 381 by 381, and directEffects1 has the dimensions 381x 1.Both are data frames. When I type up \n\n```\n  writeData(wb2, sheet=1, as.matrix(LMatrix)%*%as.matrix(directEffects1)[,1], startCol = 9,startRow = 1,colNames = T, rowNames = FALSE)\n```\n\n\nI get a 1 row, 381 column vector with just 1s and 0s, and not the products of the matrix multiplication. Also, I need to write as.matrix(directEffects1)[,1] and not as.matrix(directEffects1), or else I will receive the message:\n\n```\n %*%: non-conformable arguments\n```\n\n\nAny advice on what I should do? I want the 381x1 product of the two variables. \n    ", "Answer": "\r\nI am not sure where you're going wrong. I worked up an example using randomly generated data and got a sensible answer:\n\n```\nlibrary(openxlsx)\nlibrary(Matrix)\n\n# Using rnorm and runif to generate random data\nLMatrix = as.data.frame(matrix(rnorm(381*381), nrow=381, ncol=381))\ndirectEffects1 = as.data.frame(matrix(runif(381), nrow=381, ncol=1))\nwb2 <- createWorkbook()\naddWorksheet(wb2, \"Matrix\")\n\nwriteData(wb2, sheet=1, \n          as.matrix(LMatrix)%*%as.matrix(directEffects1)[,1], \n          startCol = 9,\n          startRow = 1,\n          colNames = T, \n          rowNames = FALSE)\n\nsaveWorkbook(wb2, file = 'C:/test.xlsx')\n```\n\n\nWhich gives a 381 row x 1 column Excel file. Perhaps this code (which isn't really an answer, admittedly) can get you started figuring out what part of your code or data is messing you up?\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication with Numpy Arrays\r\n                \r\n```\nA = np.random.randint(0, 50, size=(128,128))\nB = np.random.randint(0, 50, size=(128,128))\n```\n\nI have those arrays. I would like to do matrix multiplication in several ways.\n\nRow by Column\nRow by Row\nColumn by Column\nBlock by Block.\n\nI know 1 & 2.\nFor number 1, I use np.matmul(A,B)\nnumber 2, I use np.multiply(A,B)\nI'm not sure how to execute number 3 and 4. How we do matrix multiplication Column by Column and Block by Block.\nThank you\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication of a ndarray\r\n                \r\nI have a matrix, for instance, ```\nA = np.array([[1,0],[0,1]])```\n and ndarray of the form ```\nB = np.array([[1,2],[3,4],[5,6]])```\n. I want a matrix multiplication of each array of the array ```\nB```\n by the matrix ```\nA```\n.\nI did a for cycle, like this\n```\nC = []\nfor b in B:\n    C.append(np.matmul(A,b))\nC=np.array(C)\n```\n\nout[]:\n```\narray([[1, 2],\n   [3, 4],\n   [5, 6]])\n```\n\nBut I know that this for cycle is time consuming. Is there a better way to do it?\n    ", "Answer": "\r\nWhen you do funny things with matrix multiplication dimensions, ```\neinsum```\n can help clarify what's going on.\n```\nIn [40]: np.einsum('ij,kj->ki',A,B)\nOut[40]: \narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n```\n\nHere we are doing the sum-of-products on the ```\nj```\n dimension, and putting ```\nB's```\n first dimension first in the result.  Ordinary matmul would be ```\nij,jk->ik```\n.  From that we can see the need for the two transposes in the other answer.\n```\n(A@B.T).T\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "What is the best matrix multiplication algorithm? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is opinion-based. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it can be answered with facts and citations by editing this post.\r\n                \r\n                    \r\n                        Closed 7 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nWhat is the best matrix multiplication algorithm? What means 'the best'for me? It means the fastest and ready for todays machines.\n\nPlease give links to pseudocode if you can.\n    ", "Answer": "\r\nBLAS is the best ready-to-use efficient matrix multiplication library. There are many different implementation. Here is a benchmark I made for some implementations on a MacBook Pro with dual-core Intel Core 2 Duo 2.66 GHz :\n\n\ngotoBLAS2 (open-source) : https://www.tacc.utexas.edu/research-development/tacc-software/gotoblas2\nATLAS (open-source) : http://math-atlas.sourceforge.net/\nAccelerate.framework (Apple) : http://developer.apple.com/performance/accelerateframework.html\na non-optimized, but portable, implementation that I called 'vanilla' (from the GSL)\n\n\n\n\nThere are also other commercial implementations that I didn't test here :\n\n\nMKL (Intel) : http://software.intel.com/en-us/articles/intel-mkl/\nACML (AMD) : http://developer.amd.com/cpu/Libraries/acml/Pages/default.aspx\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Practical applications of Matrix multiplication in Hadoop\r\n                \r\nRecently, while learning Hadoop I encountered the problem of Matrix multiplication through Hadoop. Although I understood the idea, but just wanted to know if there are any practical situations where Matrix multiplication in Hadoop has an applications?\n\nThanks \n    ", "Answer": "\r\nThis question intrigued me as I like maths. I suspect that it would mostly be scientific or mathematical datasets and problems that would benefit from matrix multiplication and manipulation. Have a look here for to get a feel for the type of applications that might need this: http://grids.ucs.indiana.edu/ptliupages/publications/DryadReport.pdf\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Pthreads matrix multiplication error\r\n                \r\nI want to use pthreads on my existing serial matrix multiplication code. My goal is to achieve better execution time using pthreads, simply to achieve speed-up. But at that point I'm stuck. My original serial code, works just fine, and I finish 1000x1000 square matrix multiplication in about 15 seconds. But when I execute my current pthreads program, I get a segmentation fault. Here is my code:\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\nint SIZE, NTHREADS;\nint **A, **B, **C;\n\nvoid init()\n{\n    int i, j;\n\n    A = (int**)malloc(SIZE * sizeof(int *));\n    for(i = 0; i < SIZE; i++)\n        A[i] = malloc(SIZE * sizeof(int));\n\n    B = (int**)malloc(SIZE * sizeof(int *));\n    for(i = 0; i < SIZE; i++)\n        B[i] = malloc(SIZE * sizeof(int));\n\n    C = (int**)malloc(SIZE * sizeof(int *));\n    for(i = 0; i < SIZE; i++)\n        C[i] = malloc(SIZE * sizeof(int));\n\n    srand(time(NULL));\n\n    for(i = 0; i < SIZE; i++) {\n        for(j = 0; j < SIZE; j++) {\n            A[i][j] = rand()%100;\n            B[i][j] = rand()%100;\n        }\n    }\n}\n\nvoid mm(int tid)\n{\n    int i, j, k;\n    int start = tid * SIZE/NTHREADS;\n    int end = (tid+1) * (SIZE/NTHREADS) - 1;\n\n    for(i = start; i <= end; i++) {\n        for(j = 0; j < SIZE; j++) {\n            C[i][j] = 0;\n            for(k = 0; k < SIZE; k++) {\n                C[i][j] += A[i][k] * B[k][j];\n            }\n        }\n    }\n}\n\nvoid *worker(void *arg)\n{\n    int tid = *((int *) arg);\n    mm(tid);\n}\n\nint main(int argc, char* argv[])\n{\n    pthread_t* threads;\n    int rc, i;\n\n    if(argc != 3)\n    {\n        printf(\"Usage: %s <size_of_square_matrix> <number_of_threads>\\n\", argv[0]);\n        exit(1);\n    }\n\n    SIZE = atoi(argv[1]);\n    NTHREADS = atoi(argv[2]);\n    init();\n    threads = (pthread_t*)malloc(NTHREADS * sizeof(pthread_t));\n\n    clock_t begin, end;\n    double time_spent;\n\n\n    begin = clock();\n\n    for(i = 0; i < NTHREADS; i++) {\n        rc = pthread_create(&threads[i], NULL, worker, (void *)i);\n        assert(rc == 0);\n    }\n\n    for(i = 0; i < NTHREADS; i++) {\n        rc = pthread_join(threads[i], NULL);\n        assert(rc == 0);\n    } \n\n    end = clock();\n\n    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n    printf(\"Elapsed time: %.2lf seconds.\\n\", time_spent);\n\n    for(i = 0; i < SIZE; i++)\n        free((void *)A[i]);\n    free((void *)A);\n\n    for(i = 0; i < SIZE; i++)\n        free((void *)B[i]);\n    free((void *)B);\n\n    for(i = 0; i < SIZE; i++)\n        free((void *)C[i]);\n    free((void *)C);\n\n    free(threads);\n\n    return 0;\n}\n```\n\n\nIf someone could help me make my pthreads program run, and achieve some speed-up I would be glad.\n    ", "Answer": "\r\nWith your current code, you should retrieve the index using\n\n```\nint tid = (int)arg;\n```\n\n\n(Your code is effectively treating the loop counter as an address then dereferencing addresses at or around 0.  These addresses may not be readable by your process and/or won't be suitably aligned, hence the seg fault)\n\nThe above change might get things working for you but note that passing an ```\nint```\n as a ```\nvoid*```\n isn't completely correct.  It relies on ```\nsizeof(int) <= sizeof(void*)```\n which is likely but not guaranteed to be true.  If you cared about this, you could either allocate memory for the data you pass to each thread instead or pass the address of ```\ni```\n and include synchronisation to ensure that you wait after each ```\npthread_create```\n call until the thread has been scheduled and has read its arg.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Why can Matrix Matrix Multiplication achieve better performance than Matrix Vector Multiplication?\r\n                \r\nAccording to some high performance computing books, some authors claim that the matrix-matrix multiplication can achieve better performance than matrix-vector multiplicatino in terms of the memory bandwidth. It seems that the matrix-matrix multiplication processes O(N^3) computation operations and O(N^2) data transfer operations. I do not know why we can have tremendous optimization potential in such case.\n\nFor example, if I want to compute the result of ABy, where A and B are n x n matrixes and y is a n x 1 vector. There are two ways that I can get the final result. First of all, I can compute the A*B first and get another new n by n matrix. After that, I can do the multiplication between matrix and vector. On the other hand, I can do two times matrix-vector multiplication. Which one is better?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Multiply Rectangular Matrices in CUDA\r\n                \r\nIn this homework i need to complete the code to multiply two rectangle matrices using CUDA C. After I completed the code, I submitted and the solution was correct for the data set when the matrices were square, while the result wasn't matching the expected value when the matrices were not square.\n\nHere is the code after I added the missing parts:  \n\n```\n#include    <wb.h>\n\n#define wbCheck(stmt) do {                             \\\n    cudaError_t err = stmt;                            \\\n    if (err != cudaSuccess) {                          \\\n        wbLog(ERROR, \"Failed to run stmt \", #stmt);    \\\n        return -1;                                     \\\n    }                                                  \\\n} while(0)\n\n// Compute C = A * B\n__global__ void matrixMultiply(float * A, float * B, float * C,\n               int numARows, int numAColumns,\n               int numBRows, int numBColumns,\n               int numCRows, int numCColumns) {\n   //@@ Insert code to implement matrix multiplication here\n   int Row = blockIdx.y * blockDim.y + threadIdx.y;\n   int Col = blockIdx.x * blockDim.x + threadIdx.x;\n   if (numAColumns != numBRows) return ;\n   if ((Row < numARows) && (Col < numBColumns)){\n       float Cvalue = 0;\n       for (int k = 0 ; k < numAColumns ; ++k )\n       Cvalue += A[Row*numAColumns + k] * B[k * numBRows + Col];\n       C[Row*numAColumns + Col] = Cvalue;\n     }\n\n    }\n\n\n\nint main(int argc, char ** argv) {\n   wbArg_t args;\n   float * hostA; // The A matrix\n   float * hostB; // The B matrix\n   float * hostC; // The output C matrix\n   float * deviceA;\n   float * deviceB;\n   float * deviceC;\n   int numARows; // number of rows in the matrix A\n   int numAColumns; // number of columns in the matrix A\n   int numBRows; // number of rows in the matrix B\n   int numBColumns; // number of columns in the matrix B\n   int numCRows; // number of rows in the matrix C (you have to set this)\n   int numCColumns; // number of columns in the matrix C (you have to set this)\n\n   args = wbArg_read(argc, argv);\n\n   wbTime_start(Generic, \"Importing data and creating memory on host\");\n   hostA = (float *) wbImport(wbArg_getInputFile(args, 0), &numARows, &numAColumns);\n   hostB = (float *) wbImport(wbArg_getInputFile(args, 1), &numBRows, &numBColumns);\n   //@@ Set numCRows and numCColumns  \n   numCRows = 0;\n   numCColumns = 0;\n   numCRows = numARows;\n   numCColumns = numBColumns;  \n   //@@ Allocate the hostC matrix\n   hostC = (float*) malloc(sizeof(float)*numCRows*numCColumns);  \n   wbTime_stop(Generic, \"Importing data and creating memory on host\");\n\n   wbLog(TRACE, \"The dimensions of A are \", numARows, \" x \", numAColumns);\n   wbLog(TRACE, \"The dimensions of B are \", numBRows, \" x \", numBColumns);\n\n   wbTime_start(GPU, \"Allocating GPU memory.\");\n   //@@ Allocate GPU memory here\n   cudaMalloc((void**)&deviceA ,sizeof(float)*numARows*numAColumns );\n   cudaMalloc((void**)&deviceB , sizeof(float)*numBRows*numBColumns);\n   cudaMalloc((void**)&deviceC , sizeof(float)*numCRows*numCColumns);  \n\n   wbTime_stop(GPU, \"Allocating GPU memory.\");\n\n   wbTime_start(GPU, \"Copying input memory to the GPU.\");\n   //@@ Copy memory to the GPU here\n\n   cudaMemcpy(deviceA, hostA, sizeof(float)*numARows*numAColumns, cudaMemcpyHostToDevice);\n   cudaMemcpy(deviceB, hostB, sizeof(float)*numBRows*numBColumns, cudaMemcpyHostToDevice);\n   wbTime_stop(GPU, \"Copying input memory to the GPU.\");\n\n   //@@ Initialize the grid and block dimensions here\n\n   dim3 DimGrid(numARows / 8 , numBColumns / 8, 1);\n   dim3 DimBlock(8 , 8, 1);\n\n   wbTime_start(Compute, \"Performing CUDA computation\");\n\n   //@@ Launch the GPU Kernel here\n   matrixMultiply<<<DimGrid , DimBlock>>>(deviceA , deviceB , deviceC , numARows , numAColumns, numBRows ,numBColumns , numCRows , numCColumns);  \n\n   cudaThreadSynchronize();\n   wbTime_stop(Compute, \"Performing CUDA computation\");\n\n   wbTime_start(Copy, \"Copying output memory to the CPU\");\n   //@@ Copy the GPU memory back to the CPU here\n   cudaMemcpy(hostC, deviceC, sizeof(float)*numCRows*numCColumns , cudaMemcpyDeviceToHost);  \n\n   wbTime_stop(Copy, \"Copying output memory to the CPU\");\n\n   wbTime_start(GPU, \"Freeing GPU Memory\");\n   //@@ Free the GPU memory here\n\n   cudaFree(deviceA);\n   cudaFree(deviceB);\n   cudaFree(deviceC);\n   wbTime_stop(GPU, \"Freeing GPU Memory\");\n\n   wbSolution(args, hostC, numCRows, numCColumns);\n\n   free(hostA);\n   free(hostB);\n   free(hostC);\n\n   return 0;\n}\n```\n\n\nI hope you can help me to find which part is incorrect.  \n    ", "Answer": "\r\nAfter the help of Ira, Ahmad, ram, and Oli Fly, I got the correct answer as follows:  \n\n```\n#include    <wb.h>\n\n#define wbCheck(stmt) do {                                 \\\n        cudaError_t err = stmt;                            \\\n        if (err != cudaSuccess) {                          \\\n            wbLog(ERROR, \"Failed to run stmt \", #stmt);    \\\n            return -1;                                     \\\n        }                                                  \\\n    } while(0)\n\n// Compute C = A * B\n__global__ void matrixMultiply(float * A, float * B, float * C,\n                   int numARows, int numAColumns,\n                   int numBRows, int numBColumns,\n                   int numCRows, int numCColumns) {\n    //@@ Insert code to implement matrix multiplication here\n    int Row = blockIdx.y * blockDim.y + threadIdx.y;\n    int Col = blockIdx.x * blockDim.x + threadIdx.x;\n    if (numAColumns != numBRows) return;\n    if ((Row < numARows) && (Col < numBColumns)){\n    float Cvalue = 0;\n    for (int k = 0; k < numAColumns; ++k)\n    Cvalue += A[Row*numAColumns + k] * B[k * numBColumns + Col];\n    C[Row*numCColumns + Col] = Cvalue;\n  }\n\n}\n\nint main(int argc, char ** argv) {\n    wbArg_t args;\n    float * hostA; // The A matrix\n    float * hostB; // The B matrix\n    float * hostC; // The output C matrix\n    float * deviceA;\n    float * deviceB;\n    float * deviceC;\n    int numARows; // number of rows in the matrix A\n    int numAColumns; // number of columns in the matrix A\n    int numBRows; // number of rows in the matrix B\n    int numBColumns; // number of columns in the matrix B\n    int numCRows; // number of rows in the matrix C (you have to set this)\n    int numCColumns; // number of columns in the matrix C (you have to set this)\n\n    args = wbArg_read(argc, argv);\n\n    wbTime_start(Generic, \"Importing data and creating memory on host\");\n    hostA = (float *) wbImport(wbArg_getInputFile(args, 0), &numARows, &numAColumns);\n    hostB = (float *) wbImport(wbArg_getInputFile(args, 1), &numBRows, &numBColumns);\n    //@@ Set numCRows and numCColumns  \n    numCRows = 0;\n    numCColumns = 0;\n    numCRows = numARows;\n    numCColumns = numBColumns;  \n    //@@ Allocate the hostC matrix\n    hostC = (float*) malloc(sizeof(float)*numCRows*numCColumns);  \n    wbTime_stop(Generic, \"Importing data and creating memory on host\");\n\n    wbLog(TRACE, \"The dimensions of A are \", numARows, \" x \", numAColumns);\n    wbLog(TRACE, \"The dimensions of B are \", numBRows, \" x \", numBColumns);\n\n    wbTime_start(GPU, \"Allocating GPU memory.\");\n    //@@ Allocate GPU memory here\n    cudaMalloc((void**)&deviceA ,sizeof(float)*numARows*numAColumns );\n    cudaMalloc((void**)&deviceB , sizeof(float)*numBRows*numBColumns);\n    cudaMalloc((void**)&deviceC , sizeof(float)*numCRows*numCColumns);  \n\n    wbTime_stop(GPU, \"Allocating GPU memory.\");\n\n    wbTime_start(GPU, \"Copying input memory to the GPU.\");\n    //@@ Copy memory to the GPU here\n\n    cudaMemcpy(deviceA, hostA, sizeof(float)*numARows*numAColumns, cudaMemcpyHostToDevice);\n    cudaMemcpy(deviceB, hostB, sizeof(float)*numBRows*numBColumns, cudaMemcpyHostToDevice);\n    wbTime_stop(GPU, \"Copying input memory to the GPU.\");\n\n    //@@ Initialize the grid and block dimensions here\n\n    dim3 DimGrid((numCColumns - 1) / 8 + 1, (numCRows - 1) / 8 + 1, 1);\n    dim3 DimBlock(8 , 8, 1);\n\n    wbTime_start(Compute, \"Performing CUDA computation\");\n\n    //@@ Launch the GPU Kernel here\n    matrixMultiply<<<DimGrid , DimBlock>>>(deviceA , deviceB , deviceC , numARows , numAColumns, numBRows ,numBColumns , numCRows , numCColumns);  \n\n    cudaThreadSynchronize();\n    wbTime_stop(Compute, \"Performing CUDA computation\");\n\n    wbTime_start(Copy, \"Copying output memory to the CPU\");\n    //@@ Copy the GPU memory back to the CPU here\n    cudaMemcpy(hostC, deviceC, sizeof(float)*numCRows*numCColumns , cudaMemcpyDeviceToHost);  \n\n    wbTime_stop(Copy, \"Copying output memory to the CPU\");\n\n    wbTime_start(GPU, \"Freeing GPU Memory\");\n    //@@ Free the GPU memory here\n\n    cudaFree(deviceA);\n    cudaFree(deviceB);\n    cudaFree(deviceC);\n    wbTime_stop(GPU, \"Freeing GPU Memory\");\n\n    wbSolution(args, hostC, numCRows, numCColumns);\n\n    free(hostA);\n    free(hostB);\n    free(hostC);\n\n    return 0;\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Do inner workings of Matlab do Full Matrix Multiplication when Matrix Multiplication is Argument for Trace?\r\n                \r\nDoes Matlab do a full matrix multiplication when a matrix multiplication is given as an argument to the trace function?\n\nFor example, in the code below, does A*B actually happen, or are the columns of B dotted with the rows of A, then summed? Or does something else happen?\n\n```\nA = [2,2;2,2];\nB = eye(2);\nf = trace(A*B);\n```\n\n    ", "Answer": "\r\nYes, MATLAB calculates the product, but you can avoid it!\n\nFirst, let's see what MATLAB does if you do ```\nf = trace(A*B)```\n:\n\nI think the picture from my Performance monitor says it all really. The first bump is when I created a large ```\nA = 2*ones(n)```\n, the second, very little bump is for the creation of ```\nB = eye(n)```\n, and the last bump is where ```\nf = trace(A*B)```\n is calculated. \n\n\n\nNow, let's see that you get if you do it manually:\n\nIf you do it manually, you can save a lot of memory, and it's much faster. \n\n```\ntic\nn = 6e3;          \nA = rand(n);\nB = rand(n);\n\nf = trace(A*B);\n\ntoc\npause(10)\n\ntic\nC(n) = 0;\nfor ii = 1:n\nC(ii) = sum(A(ii,:)*B(:,ii));\nend\ng = sum(C);\n\ntoc\n\nabs(f-g) < 1e-10\n\nElapsed time is 11.982804 seconds.\nElapsed time is 0.540285 seconds.\n\nans =\n\n     1\n```\n\n\n\n\nNow, as you asked about in the comments: \"Is this still true if you use it in a function where optimization can kick in?\"\n\nThis depends on what you mean here, but as a quick example:\n\nCalculating ```\nx = inv(A)*b```\n can be done in a few different ways. If you do:\n\n```\nx = A\\b; \n```\n\n\nMATLAB will chose an algorithm that's best suited for your particular matrix/vector. There are many different alternatives here, depending on the structure of the matrix: is it triangular, hermatian, sparse...? Often it's a upper/lower triangulation. I can pretty much guarantee you that you can't write a code in MATLAB that can outperform MATLABs builtin functions here.\n\nHowever, if you calculate the same thing this way:\n\n```\nx = inv(A)*b;\n```\n\n\nMATLAB will actually calculate the inverse of ```\nA```\n, then multiply it by ```\nb```\n, even though the inverse is not stored in the workspace afterwards. This is much slower, and can also be inaccurate. (In the ```\nA\\b```\n approach, MATLAB will, if necessary create a permutation matrix to ensure numerical stability.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in Objective-C\r\n                \r\nThese are some code that I carried in my project to do matrix computing.\nThey are two class methods and one instance method that for create matrices and do the matrix multiplication operation.\nThe method for matrics multiplication doesn't work well, the result from it is wrong.\n\n```\n+ (NSMutableArray *)arrayOfWidth:(NSInteger)width andHeight:(NSInteger)height {\n    return [[self alloc] initWithWidth:width andHeight:height];\n}\n\n- (id)initWithWidth:(NSInteger)width andHeight:(NSInteger)height {\n    if((self = [self initWithCapacity:height])) {\n        for(int i = 0; i < height; i++) {\n            NSMutableArray *inner = [[NSMutableArray alloc] initWithCapacity:width];\n            [self addObject:inner];\n        }\n    }\n    return self;\n}\n\n+ (NSMutableArray *)matrixA:(NSMutableArray *)matrixA multiplyMatrixB:(NSMutableArray *)matrixB {\n    int aRow = [matrixA count];\n    int aColumn = [[matrixA objectAtIndex:0] count];\n    int bRow = [matrixB count];\n    int bColumn = [[matrixB objectAtIndex:0] count];\n    NSMutableArray *newArray = [NSMutableArray arrayOfWidth:aRow andHeight:bColumn];\n\n    for (int i = 0; i < aRow; i++) {\n        for (int j = 0; j < bColumn; j++) {\n            double sum = 0.0;\n            for (int k = 0; k < aColumn; k++) {\n                NSMutableArray *innerA = [matrixA objectAtIndex:i];\n                double numA = [[innerA objectAtIndex:k] doubleValue];\n                NSMutableArray * innerB = [matrixB objectAtIndex:k];\n                double numB = [[innerB objectAtIndex:j] doubleValue];\n                sum += numA * numB; \n            }\n            NSNumber *result = [NSNumber numberWithDouble:sum];\n            [[newArray objectAtIndex:i] insertObject:result atIndex:j];\n        }\n    }\n    return newArray;\n}\n```\n\n\nIs there something wrong with the code?\nAnd how can I fix it?\n\n\n\n```\n    //First, I create a array to hold the numbers\n    NSNumber *num11 = [NSNumber numberWithDouble:-2.0];\n    NSNumber *num12 = [NSNumber numberWithDouble:1.0];\n    NSNumber *num13 = [NSNumber numberWithDouble:-1.0];\n    NSNumber *num14 = [NSNumber numberWithDouble:2.0];\n    NSNumber *num21 = [NSNumber numberWithDouble:-7.0];\n    NSNumber *num22 = [NSNumber numberWithDouble:0.0];\n    NSNumber *num23 = [NSNumber numberWithDouble:-1.0];\n    NSNumber *num24 = [NSNumber numberWithDouble:-4.0];\n    NSNumber *num31 = [NSNumber numberWithDouble:-2.0];\n    NSNumber *num32 = [NSNumber numberWithDouble:-1.0];\n    NSNumber *num33 = [NSNumber numberWithDouble:0.0];\n    NSNumber *num34 = [NSNumber numberWithDouble:-2.0];\n    NSNumber *num41 = [NSNumber numberWithDouble:-3.0];\n    NSNumber *num42 = [NSNumber numberWithDouble:-2.0];\n    NSNumber *num43 = [NSNumber numberWithDouble:0.0];\n    NSNumber *num44 = [NSNumber numberWithDouble:-3.0];\n\n    NSMutableArray *temp = [NSMutableArray arrayWithObjects:num11, num12, num13, num14, num21, num22, num23, num24, num31, num32, num33, num34, num41, num42, num43, num44, nil];\n\n    //Second, I create the matrix and get the elements from that array \n    for (int i = 0; i < 4; i++) {\n        for (int j = 0; j < 4; j++) {\n            double c = [[temp objectAtIndex:4*i+j] doubleValue];\n            NSNumber *object = [NSNumber numberWithDouble:c];\n            [[matrix objectAtIndex:i] insertObject:object atIndex:j];\n        }\n    }\n\n    //Then, I do the multiplication for matrix and itself\n    NSMutableArray *multiMatrix = [NSMutableArray matrixA:matrix multiplyMatrixB:matrix];\n\n    //get all the elements from the multiMatrix\n    double m11 = [[[multiMatrix objectAtIndex:0] objectAtIndex:0] doubleValue];\n    double m12 = [[[multiMatrix objectAtIndex:0] objectAtIndex:1] doubleValue];\n    double m13 = [[[multiMatrix objectAtIndex:0] objectAtIndex:2] doubleValue];\n    double m14 = [[[multiMatrix objectAtIndex:0] objectAtIndex:3] doubleValue];\n\n    double m21 = [[[multiMatrix objectAtIndex:1] objectAtIndex:0] doubleValue];\n    double m22 = [[[multiMatrix objectAtIndex:1] objectAtIndex:1] doubleValue];\n    double m23 = [[[multiMatrix objectAtIndex:1] objectAtIndex:2] doubleValue];\n    double m24 = [[[multiMatrix objectAtIndex:1] objectAtIndex:3] doubleValue];\n\n    double m31 = [[[multiMatrix objectAtIndex:2] objectAtIndex:0] doubleValue];\n    double m32 = [[[multiMatrix objectAtIndex:2] objectAtIndex:1] doubleValue];\n    double m33 = [[[multiMatrix objectAtIndex:2] objectAtIndex:2] doubleValue];\n    double m34 = [[[multiMatrix objectAtIndex:2] objectAtIndex:3] doubleValue];\n\n    double m41 = [[[multiMatrix objectAtIndex:3] objectAtIndex:0] doubleValue];\n    double m42 = [[[multiMatrix objectAtIndex:3] objectAtIndex:1] doubleValue];\n    double m43 = [[[multiMatrix objectAtIndex:3] objectAtIndex:2] doubleValue];\n    double m44 = [[[multiMatrix objectAtIndex:3] objectAtIndex:3] doubleValue];\n\n    //Or you can use the NSLog to check the result \n    NSString *lineOne = [NSString stringWithFormat:@\"%f, %f, %f, %f\", m11, m12, m13, m14];\n    NSString *lineTwo= [NSString stringWithFormat:@\"%f, %f, %f, %f\", m21, m22, m23, m24];\n    NSString *lineThree = [NSString stringWithFormat:@\"%f, %f, %f, %f\", m31, m32, m33, m34];\n    NSString *lineFour = [NSString stringWithFormat:@\"%f, %f, %f, %f\", m41, m42, m43, m44];\n```\n\n\n@rooftop, that's all the code \n    ", "Answer": "\r\nIf you're on iOS you might want to consider the matrix routines in GLKit\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Cannon's algorithm of matrix multiplication\r\n                \r\nI try to implement the Cannon's algorithm of matrix multiplication.\nI read description on the wikipedia that provides next pseudocode:\n\n```\n   row i of matrix a is circularly shifted by i elements to the left.\n   col j of matrix b is circularly shifted by j elements up.\n   Repeat n times:\n       p[i][j] multiplies its two entries and adds to running total.\n       circular shift each row of a 1 element left\n       circular shift each col of b 1 element up\n```\n\n\nand I implemented it on the C# next way: \n\n```\n    public static void ShiftLeft(int[][] matrix, int i, int count)\n    {\n        int ind = 0;\n        while (ind < count)\n        {\n            int temp = matrix[i][0];\n            int indl = matrix[i].Length - 1;\n            for (int j = 0; j < indl; j++)\n                matrix[i][j] = matrix[i][j + 1];\n            matrix[i][indl] = temp;\n            ind++;\n        }\n    }\n    public static void ShiftUp(int[][] matrix, int j, int count)\n    {\n        int ind = 0;\n        while (ind < count)\n        {\n            int temp = matrix[0][j];\n            int indl = matrix.Length - 1;\n            for (int i = 0; i < indl; i++)\n                matrix[i][j] = matrix[i + 1][j];\n            matrix[indl][j] = temp;\n            ind++;\n        }\n    }\n\n    public static int[][] Cannon(int[][] A, int[][] B)\n    {\n        int[][] C = new int[A.Length][];\n        for (int i = 0; i < C.Length; i++)\n            C[i] = new int[A.Length];\n        for (int i = 0; i < A.Length; i++)\n            ShiftLeft(A, i, i);\n\n        for (int i = 0; i < B.Length; i++)\n            ShiftUp(B, i, i);\n\n        for (int k = 0; k < A.Length; k++)\n        {\n            for (int i = 0; i < A.Length; i++)\n            {\n                for (int j = 0; j < B.Length; j++)\n                {\n                    var m = (i + j + k) % A.Length;\n                    C[i][j] += A[i][m] * B[m][j];\n                    ShiftLeft(A, i, 1);\n                    ShiftUp(B, j, 1);\n                }\n\n            }\n        };\n\n        return C;\n\n    }\n```\n\n\nthis code return correct result, but do it very slowly. Much slowly even than naive algorithm of matrix multiplication.\n\nFor matrix 200x200 I got that result:\n\n```\n00:00:00.0490432 //naive algorithm\n00:00:07.1397479 //Cannon's algorithm\n```\n\n\nWhat I am doing wrong?\n\n\n\nEdit\n\nThanks SergeySlepov, it was bad attempt to do it parallel. When I back to sequential implementation I got next result:\n\n```\nCount       Naive               Cannon's\n\n200    00:00:00.0492098    00:00:08.0465076\n\n250    00:00:00.0908136    00:00:22.3891375\n\n300    00:00:00.1477764    00:00:58.0640621\n\n350    00:00:00.2639114    00:01:51.5545524\n\n400    00:00:00.4323984    00:04:50.7260942\n```\n\n\nokay, it's not a parallel implementation, but how can I do it correctly? \n    ", "Answer": "\r\nCannon's algorithm was built for a 'Distributed Memory Machine' (a grid of processors, each with its own memory). This is very different to the hardware you're running it on (a few processors with shared memory) and that is why you're not seeing any increase in performance. \n\nThe 'circular shifts' in the pseudocode that you quoted actually mimic data transfers between processors. After the initial matrix 'skewing', each processor in the grid keeps track of three numbers (a, b and c) and executes pseudocode similar to this:\n\n```\nc += a * b;\npass 'a' to the processor to your left (wrapping around)\npass 'b' to the processor to 'above' you (wrapping around)\nwait for the next iteration of k\n```\n\n\nWe could mimic this behaviour on a PC using NxN threads but the overhead of context switching (or spawning ```\nTask```\ns) would kill all the joy. To make the most of a PC's 4 (or so) CPUs we could make the loop over ```\ni```\n parallel. The loop over ```\nk```\n needs to be sequential (unlike your solution), otherwise you might face racing conditions as each iteration of ```\nk```\n modifies the matrices A, B and C. In a 'distributed memory machine' race conditions are not a problem as processors do not share any memory.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication behavior in NumPy\r\n                \r\nHave the following:\n\n```\nIn [14]: A = array([[1, 1], [3, 2], [-4, 1]])\n\nIn [15]: A\nOut[15]:\narray([[ 1,  1],\n       [ 3,  2],\n       [-4,  1]])\n\nIn [16]: x = array([1, 1])\n\nIn [17]: x\nOut[17]: array([1, 1])\n\nIn [18]: dot(A, x)\nOut[18]: array([ 2,  5, -3])\n```\n\n\nI was expecting a column, because dot() function is described as an ordinary matrix multiplication.\n\nWhy does it return a row instead? This behaviour seems very discouraging. \n    ", "Answer": "\r\n```\nx```\n a 1D vector, and as such has no notion of whether it's a row vector or a column vector. Same goes for the result of ```\ndot(A, x)```\n.\n\nTurn ```\nx```\n into a 2D array, and all will be well:\n\n```\nIn [7]: x = array([[1], [1]])\n\nIn [8]: x\nOut[8]: \narray([[1],\n       [1]])\n\nIn [9]: dot(A, x)\nOut[9]: \narray([[ 2],\n       [ 5],\n       [-3]])\n```\n\n\nFinally, if you prefer to use more natural matrix notation, convert ```\nA```\n to ```\nnumpy.matrix```\n:\n\n```\nIn [10]: A = matrix(A)\n\nIn [11]: A * x\nOut[11]: \nmatrix([[ 2],\n        [ 5],\n        [-3]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Large matrix multiplication on gpu\r\n                \r\nI need to implement a matrix multiplication on GPU with CUDA for large matrices. Size of each matrix alone is bigger than the GPU memory. So I think I need an algorithm to do that efficiently. I went around the internet but couldn't find any. Can anyone give me the name or link of such algorithms.\n    ", "Answer": "\r\nThere isn't really a formal algorithm for this; in general, these sorts of linear algebra operations where the whole problem isn't stored in memory simultaneously are referred to as \"out of core\" operations.\n\nTo solve it, you don't need a particularly elaborate algorithm, just the CUBLAS library and a pencil and paper. For example, you can decompose the matrix product like this:\n\n \n\nwhich gives you four independent sub-matrix multiplication operations. These can be calculated using four calls to CUBLAS gemm using very straightforward host code. You can extend the idea to as many sub-matrices as are required to match the problem size and your GPU capacity. The same principle can also be used to implement matrix multiplication problems on multiple GPUs (see this question for an example).\n\nIn the alternative, you can find a working implementation of this precise idea in the Harvard developed SciGPU-GEMM codebase and in the HPL-CUDA linpack implementation (disclaimer: I am affiliated with the latter codebase).\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "c# 10000 x 10000 matrix multiplication\r\n                \r\nI need to perform a Matrix multiplication of two matrices with dimension 10,000 x 10,000. I am using simple array multiplication, and it takes more than 2 hours to complete the calculation. I need to reduce the times to complete the multiplication.\n```\n Double[,] array1 = new double [10000, 10000];\n Double[,] array2 = new double [10000, 10000];\n Random randNum = new Random();\n\n for (int i = 0; i < array1.GetLength(0); i++)\n {\n     for (int j = 0; j < array1.GetLength(1); j++)\n     {\n         array1[i, j] = randNum.Next(1, 10);\n     }\n }\n\n for (int i = 0; i < array2.GetLength(0); i++)\n {\n     for (int j = 0; j < array2.GetLength(1); j++)\n     {\n         array2[i, j] = randNum.Next(1, 10);\n     }\n }\n\nDouble [,] mt = mMat(array1,array2);\n\npublic static double[,] mMat(double[,] A, double[,] B)\n{\n\n    int aRows = A.GetLength(0);\n    int aColumns = A.GetLength(1);\n    int bRows = B.GetLength(0);\n    int bColumns = B.GetLength(1);\n\n    if (aColumns != bRows)\n    {\n\n        throw new ArgumentException(\"A:Rows: \" + aColumns + \" did not match B:Columns \" + bRows + \".\");\n    }\n\n    double[,] C = new double[aRows, bColumns];\n\n    for (int i = 0; i < aRows; i++)\n    { // aRow\n        for (int j = 0; j < bColumns; j++)\n        { // bColumn\n            for (int k = 0; k < aColumns; k++)\n            { // aColumn\n                C[i, j] += A[i, k] * B[k, j];\n            }\n        }\n    }\n\n    return C;\n}\n```\n\nI am newbie in programming world and need to do task to perform large matrix multiplication\n    ", "Answer": "\r\nI recently did the same thing for a C# benchmark, and here are a few tips to make it run  faster.  The C# version runs in about 1 minute and 15 seconds on an 8 core laptop.\n\nCalculate the transpose of B before beginning the matrix multiplication because accessing the matrix in row order is MUCH faster than column order.  Scott Meyers did a talk about CPU caches that explains why row order traversal is faster.\n\nMake the outer loop a Parallel.For loop.  The link also has some examples that use matrix multiplication.\n\nUse the Vector class to take advantage of SIMD.\n\nConsider using float instead of double unless you really need the extra precision.\n\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "fast matrix multiplication in Matlab\r\n                \r\nI need to make a matrix/vector multiplication in Matlab of very large sizes: \"A\" is an 655360 by 5 real-valued matrix that are not necessarily sparse and \"B\" is a 655360 by 1 real-valued vector. My question is how to compute: B'*A efficiently.\n\nI have notice a slight time improvement by computing A'*B instead, which gives a column vector. But still it is quite slow (I need to perform this operation several times in the program).\n\nWith a little bit search I found an interesting Matlab toolbox MTIMESX by James Tursa, which I hoped would improve the above matrix multiplication performance. After several trials, I can only have very marginal gains over the Matlab native matrix multiplication.\n\nAny suggestions about how should I rewrite A'*B so that the operation is more efficient? Thanks.\n    ", "Answer": "\r\nMatlab's raison d'etre is doing matrix computations. I would be fairly surprised if you could significantly outperform its built-in matrix multiplication with hand-crafted tools. First of all, you should make sure your multiplication can actually be performed significantly faster. You could do this by implementing a similar multiplication in C++ with Eigen.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "tensorflow matrix multiplication with batching and broadcasting\r\n                \r\nI can use ```\ntf.matmul(A, B)```\n to do batch matrix multiplication when:\n\n\n```\nA.shape == (..., a, b)```\n and \n```\nB.shape == (..., b, c)```\n,\n\n\nwhere the ```\n...```\n are the same.\n\nBut I want an additional broadcasting:\n\n\n```\nA.shape == (a, b, 2, d)```\n and\n```\nB.shape == (a, 1, d, c)```\n\n```\nresult.shape == (a, b, 2, c)```\n\n\n\nI expect the result to be ```\na x b```\n batches of matrix multiplication between ```\n(2, d)```\n and ```\n(d, c)```\n.\n\nHow to do this?\n\n\n\nTest code:\n\n```\nimport tensorflow as tf\nimport numpy as np\n\na = 3\nb = 4\nc = 5\nd = 6\n\nx_shape = (a, b, 2, d)\ny_shape = (a, d, c)\nz_shape = (a, b, 2, c)\n\nx = np.random.uniform(0, 1, x_shape)\ny = np.random.uniform(0, 1, y_shape)\nz = np.empty(z_shape)\n\nwith tf.Session() as sess:\n    for i in range(b):\n        x_now = x[:, i, :, :]\n        z[:, i, :, :] = sess.run(\n            tf.matmul(x_now, y)\n        )\n\nprint(z)\n```\n\n    ", "Answer": "\r\n```\ntf.einsum```\n - a generalized contraction between tensors of arbitrary dimension, would be your friend in such a problem. See tf documentation here.\n\nThere is a great tutorial on stackoverflow: (Understanding NumPy's einsum).\n\n```\n\nimport tensorflow as tf\nimport numpy as np\n\na = 3\nb = 4\nc = 5\nd = 6\n\nx_shape = (a, b, 2, d)\ny_shape = (a, d, c)\nz_shape = (a, b, 2, c)\n\nx = tf.constant(np.random.uniform(0, 1, x_shape))\ny = tf.constant(np.random.uniform(0, 1, y_shape))\nz = tf.constant(np.empty(z_shape))\n\nv = tf.einsum('abzd,adc->abzc', x, y)\nprint z.shape, v.shape\n\nwith tf.Session() as sess:\n  print sess.run(v)\n\n\nRESULT:\n\n(3, 4, 2, 5) (3, 4, 2, 5)\n[[[[ 1.8353901   1.29175219  1.49873967  1.78156638  0.79548786]\n   [ 2.32836196  2.01395003  1.53038244  2.51846521  1.65700572]]\n\n  [[ 1.76139921  1.78029925  1.22302866  2.18659201  1.51694413]\n   [ 2.32021949  1.98895703  1.7098903   2.21515966  1.33412172]]\n\n  [[ 2.13246675  1.63539287  1.64610271  2.16745158  1.02269943]\n   [ 1.75559616  1.6715972   1.26049591  2.14399714  1.34957603]]\n\n  [[ 1.80167636  1.91194534  1.3438773   1.9659323   1.25718317]\n   [ 1.4379158   1.31033243  0.71024123  1.62527415  1.31030634]]]\n\n\n [[[ 2.04902039  1.59019464  1.32415689  1.59438659  2.02918951]\n   [ 2.23684642  1.27256603  1.63474052  1.73646679  2.42958829]]\n  ....\n  ....\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication in C - Problem with inputs\r\n                \r\nI've written a program which carries out matrix multiplication using functions. The function which i presume is wrong is as follows:\n```\nvoid obtainMatrixElems(int mtrx[][10], int row_elems, int col_elems){\n    printf(\"Kindly enter matrix elements: \\n\");\n\n    for(int x = 0; x < row_elems; x++){\n        for(int y = 0; y < col_elems; y++){\n            printf(\"Enter element at position %d,%d: \\n\", x+1, y+1);\n            scanf(\"&d\", &mtrx[x][y]);\n        }\n    }\n}\n```\n\n    ", "Answer": "\r\nIt seems you are missing a \"+\" at ```\nmultAns[x][y] = matrix1[x][y] * matrix2[x][y];```\n.\nIt should rather be:\n```\n// Also note the change variables used for referencing cells ...\nmultAns[x][y] += matrix1[x][z] * matrix2[z][y];\n```\n\nIn case your last operation result is ```\n0```\n then this explains why you get a 0 matrix..\nEDIT:\nThe sign is one of the problems .. There is also something wrong with the way you get input from the user.\n```\n    for(int x = 0; x < row_elems; x++){\n        for(int y = 0; y < col_elems; y++){\n            printf(\"Enter element at position %d,%d: \\n\", x+1, y+1);\n            // Note the change of \"&\" to \"%\" and the extra sequence\n            // \"\\r\\n\" which expects the user to press ENTER (i.e.:\n            // new line) between input cells\n            rc = scanf(\"%d\\r\\n\", &mtrx[x][y]);\n            if (rc != 1) {\n                printf(\"ERROR: scanf did not proceed as expected\\r\\n\");\n            }\n        }\n    }\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "c# 10000 x 10000 matrix multiplication\r\n                \r\nI need to perform a Matrix multiplication of two matrices with dimension 10,000 x 10,000. I am using simple array multiplication, and it takes more than 2 hours to complete the calculation. I need to reduce the times to complete the multiplication.\n```\n Double[,] array1 = new double [10000, 10000];\n Double[,] array2 = new double [10000, 10000];\n Random randNum = new Random();\n\n for (int i = 0; i < array1.GetLength(0); i++)\n {\n     for (int j = 0; j < array1.GetLength(1); j++)\n     {\n         array1[i, j] = randNum.Next(1, 10);\n     }\n }\n\n for (int i = 0; i < array2.GetLength(0); i++)\n {\n     for (int j = 0; j < array2.GetLength(1); j++)\n     {\n         array2[i, j] = randNum.Next(1, 10);\n     }\n }\n\nDouble [,] mt = mMat(array1,array2);\n\npublic static double[,] mMat(double[,] A, double[,] B)\n{\n\n    int aRows = A.GetLength(0);\n    int aColumns = A.GetLength(1);\n    int bRows = B.GetLength(0);\n    int bColumns = B.GetLength(1);\n\n    if (aColumns != bRows)\n    {\n\n        throw new ArgumentException(\"A:Rows: \" + aColumns + \" did not match B:Columns \" + bRows + \".\");\n    }\n\n    double[,] C = new double[aRows, bColumns];\n\n    for (int i = 0; i < aRows; i++)\n    { // aRow\n        for (int j = 0; j < bColumns; j++)\n        { // bColumn\n            for (int k = 0; k < aColumns; k++)\n            { // aColumn\n                C[i, j] += A[i, k] * B[k, j];\n            }\n        }\n    }\n\n    return C;\n}\n```\n\nI am newbie in programming world and need to do task to perform large matrix multiplication\n    ", "Answer": "\r\nI recently did the same thing for a C# benchmark, and here are a few tips to make it run  faster.  The C# version runs in about 1 minute and 15 seconds on an 8 core laptop.\n\nCalculate the transpose of B before beginning the matrix multiplication because accessing the matrix in row order is MUCH faster than column order.  Scott Meyers did a talk about CPU caches that explains why row order traversal is faster.\n\nMake the outer loop a Parallel.For loop.  The link also has some examples that use matrix multiplication.\n\nUse the Vector class to take advantage of SIMD.\n\nConsider using float instead of double unless you really need the extra precision.\n\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in C with unknown sizes\r\n                \r\nAs a C newbie I am struggeling with matrix multiplication in C. The problem is, that the multiplication should be flexible and the rows, cols are not known before.\nThe dimensions, matrices and results for different matrix multiplications are all defined in an header file however I would like to have an matrix multiplication function that works for all of them.\nUp to now I have:\n```\nvoid matrix_multiply(int rows1, int cols1,  int cols2, float matrix1[rows1][cols1], const float matrix2[cols1][cols2], float result[rows1][cols2])\n{\n  for (int i = 0; i < rows1; i++)\n  {\n    for (int j = 0; j < cols2; j++)\n    {\n      result[i][j] = 0;\n      for (int k = 0; k < cols1; k++)\n      {\n        result[i][j] += matrix1[i][k] * matrix2[k][j];\n      }\n    }\n  }\n}\n```\n\nMy local compiler accepts that. However when I try with other compilers at godbolt the compiler may return an error. It seems to compile with gcc and clang however with others I get errors:\nx86 msvc v19.27:\n```\n<source>(2): error C2057: expected constant expression\n<source>(2): error C2466: cannot allocate an array of constant size 0\n<source>(2): error C2087: 'matrix1': missing subscript\n<source>(2): error C2087: 'matrix2': missing subscript\n<source>(2): error C2087: 'result': missing subscript\n```\n\nIs there a way to programm a matrix multiplication function that works for every compiler?\n    ", "Answer": "\r\nI don't know why your code works, it should fail on every C compiler.\nThere can be at most one variable dimension size.\nYou have two option:\nChange 2d-array into array of arrays:\n```\nvoid matrix_multiply(\n        int rows1, int cols1, int cols2,\n        const float *matrix1[],\n        const float *matrix2[],\n              float *result[])\n```\n\nOr, just use 1-dimensional row-major array. For example:\n```\n// 2-dimensional array\nint x[ROWS][COLS];\n\n// can be replaced by\nint y[ROWS*COLS];\n\n// where element\nx[r][c];\n\n// corresponds to\ny[r*COLS+c];\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication insider a data.table\r\n                \r\nI need to do matrix multiplication inside a data.table. Like this\n```\nDT1 <- data.table( x = rnorm(100), y = rnorm(100))\n\nDT2 <- data.table(z = rt(100,3))\n\nDT3 <- data.table::data.table( a = list(DT1,DT2))\n\n```\n\nIn a simple ```\nDT1```\n, I know by using\n```\nDT1[, x %*% t(x)]\n```\n\ncan ouput a matrix.\nHowever, when ```\nDT1,DT2```\n are wrapped in ```\nDT3```\n, if I want to compute ```\nx %*% t(z)```\n, how can I do it? Thanks\n    ", "Answer": "\r\nPerhaps you can try ```\nMap```\n + ```\ntcrossprod```\n within ```\nDT3```\n like below\n```\nDT3[, do.call(tcrossprod, Map(`[[`, a, c(\"x\", \"z\")))]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "OpenCL matrix multiplication\r\n                \r\nI'm a beginner in OpenCL. And I've been trying to write a matrix multiplication code. \nIt works fine only it gives garbage value as the output for C array. I'm unable to fix the error. \nAny help will be much appreciated.\n\nHere's is the host and kernel code.\n\n```\n#include <CL/cl.h>\n#include <iostream>\n#include <cstdio>\n#include <fstream>\n#include <stdlib.h>\n#include <assert.h>\n#include <string.h>\n\nusing namespace std;\n#define SUCCESS 0\n#define FAILURE 1\n\n// Function to convert file name into a string\nint convertToString(const char *filename, std::string &s)\n{\n    size_t size;\n    char *str;\n    std::fstream f(filename, (std::fstream::in | std::fstream::binary));\n\n    if (f.is_open())\n    {\n        size_t fileSize;\n        f.seekg(0, std::fstream::end);\n        size = fileSize = (size_t)f.tellg();\n        f.seekg(0, std::fstream::beg);\n        str = new char[size + 1];\n        if (!str)\n        {\n            f.close();\n            return 0;\n        }\n\n        f.read(str, fileSize);\n        f.close();\n        str[size] = '\\0';\n        s = str;\n        delete[] str;\n        return 0;\n    }\n    cout << \"Error: failed to open file\\n:\" << filename << endl;\n    return FAILURE;\n}\n\nint main()\n{\n    cl_uint status;\n    cl_int *error;\n    int A[9] = {1, 1, 1, 1, 1, 1, 1, 1, 1};\n    int B[9] = {2, 2, 2, 2, 2, 2, 2, 2, 2};\n    int C[9] = {0, 0, 0, 0, 0, 0, 0, 0, 0};\n    // Setting up platforms\n    cl_platform_id platform = NULL;\n    cl_uint numPlatforms = 0;\n    // Getting no of platforms\n    status = clGetPlatformIDs(0, NULL, &numPlatforms);\n    if (status != CL_SUCCESS)\n    {\n        cout << \"\\nUnable to query platforms\";\n        return 0;\n    }\n\n    // Get the platform\n    if (numPlatforms > 0)\n    {\n            cl_platform_id*platforms=\n                  cl_platform_id*)malloc(numPlatforms*sizeof(cl_platform_id));\n            status = clGetPlatformIDs(numPlatforms, platforms, NULL);\n            platform = platforms[0];\n            free(platforms);\n    }\n\n    cl_uint numDevices = 0;\n    cl_device_id *devices = NULL;\n    status =\n        clGetDeviceIDs(platform, CL_DEVICE_TYPE_GPU, 0, devices, &numDevices);\n\n    if (numDevices == 0)\n    {\n        cout << \"No GPU device available! Choosing CPU.\\n\";\n        status = clGetDeviceIDs(platform, CL_DEVICE_TYPE_CPU, 0, devices,\n                                &numDevices);\n        devices = (cl_device_id *)malloc(numDevices * sizeof(cl_device_id));\n        status = clGetDeviceIDs(platform, CL_DEVICE_TYPE_CPU, numDevices,\n                                devices, NULL);\n    }\n\n    else\n    {\n        devices = (cl_device_id *)malloc(numDevices * sizeof(cl_device_id));\n        status = clGetDeviceIDs(platform, CL_DEVICE_TYPE_GPU, numDevices,\n                                devices, NULL);\n        if (status == 0)\n        {\n            cout << \"Device error!\";\n            return 0;\n        }\n    }\n\n    // Creating contexts\n\n    cl_context context =\n        clCreateContext(NULL, 1, devices, NULL, NULL, (cl_int *)status);\n\n    if (status != CL_SUCCESS)\n    {\n        cout << status;\n    }\n\n    // Creating command queues\n    cl_command_queue command =\n        clCreateCommandQueue(context, devices[0], 0, NULL);\n    //  if(error!=CL_SUCCESS)\n    //{\n    //  cout<<error;\n    //}\n\n    // Creating buffers\n    cl_mem bufferA = clCreateBuffer(context, CL_MEM_READ_ONLY,\n                                    3 * 3 * sizeof(int), NULL, NULL);\n    cl_mem bufferB = clCreateBuffer(context, CL_MEM_READ_ONLY,\n                                    3 * 3 * sizeof(int), NULL, NULL);\n    cl_mem bufferC = clCreateBuffer(context, CL_MEM_WRITE_ONLY,\n                                    3 * 3 * sizeof(int), NULL, NULL);\n\n    status = clEnqueueWriteBuffer(command, bufferA, CL_TRUE, 0, 9 * sizeof(int),\n                                  (void *)A, 0, NULL, NULL);\n    status = clEnqueueWriteBuffer(command, bufferB, CL_TRUE, 0, 9 * sizeof(int),\n                                  (void *)B, 0, NULL, NULL);\n    // status=clEnqueueReadBuffer(command,bufferA,CL_TRUE,0,9*sizeof(int),(void*)C,0,NULL,NULL);\n\n    const char *filename = \"kernel.cl\";\n    string sourceStr;\n    status = convertToString(filename, sourceStr);\n    const char *source = sourceStr.c_str();\n    size_t sourceSize[] = {strlen(source)};\n    cl_program program =\n        clCreateProgramWithSource(context, 1, &source, sourceSize, NULL);\n\n    status = clBuildProgram(program, numDevices, 0, NULL, NULL, NULL);\n    cl_kernel myKernel = clCreateKernel(program, \"multiply\", NULL);\n\n    // Setting kernel arguments\n    clSetKernelArg(myKernel, 0, sizeof(cl_mem), &bufferC);\n    clSetKernelArg(myKernel, 1, sizeof(cl_mem), &bufferA);\n    clSetKernelArg(myKernel, 2, sizeof(cl_mem), &bufferB);\n\n    size_t localws[2] = {9, 9};\n    size_t globalws[2] = {3, 3};\n\n    status = clEnqueueNDRangeKernel(command, myKernel, 2, NULL, globalws,\n                                    localws, 0, NULL, NULL);\n    status = clEnqueueReadBuffer(command, bufferC, CL_TRUE, 0, 9 * sizeof(int),\n                                 (void *)C, 0, NULL, NULL);\n\n    for (int i = 0; i < 9; i++) cout << C[i] << \" \";\n    status = clReleaseKernel(myKernel);  // Release kernel.\n    status = clReleaseProgram(program);  // Release program object.\n    status = clReleaseMemObject(bufferA);  // Release mem object.\n    status = clReleaseMemObject(bufferB);\n    status = clReleaseMemObject(bufferC);\n    status = clReleaseCommandQueue(command);  // Release  Command queue.\n    status = clReleaseContext(context);  // Release context.\n}\n```\n\n\nKernel code: \n\n```\n__kernel void multiply(_global int outputC, _global int inputA,\n                       _global int inputB)\n{\n    int row = get_global_id(0);\n    int col = get_global_id(1);\n\n    int sum = 0;\n    for (int i = 0; i < 3; i++)\n        sum += inputA[row * 3 + 1] * inputB[i * 3 + col];\n\n    outputC[row + 3 + col] = sum;\n}\n```\n\n    ", "Answer": "\r\nAs already  pointed out by @Marco13 the kernel suffers from quite a few issues.\n\nWhen running this kernel through a tool like clcc you can see that there are a number of compilation errors to begin with:\n\n```\n> clcc matmul.cl \n\"/tmp/OCLu7FyFF.cl\", line 1: error: identifier \"_global\" is undefined\n  __kernel void multiply(_global int outputC, _global int inputA,\n                         ^\n\n\"/tmp/OCLu7FyFF.cl\", line 1: error: invalid combination of type specifiers\n  __kernel void multiply(_global int outputC, _global int inputA,\n                                 ^\n\n\"/tmp/OCLu7FyFF.cl\", line 1: error: identifier \"_global\" is undefined\n  __kernel void multiply(_global int outputC, _global int inputA,\n                                              ^\n\n\"/tmp/OCLu7FyFF.cl\", line 1: error: invalid combination of type specifiers\n  __kernel void multiply(_global int outputC, _global int inputA,\n                                                      ^\n\n\"/tmp/OCLu7FyFF.cl\", line 2: error: identifier \"_global\" is undefined\n                         _global int inputB)\n                         ^\n\n\"/tmp/OCLu7FyFF.cl\", line 2: error: invalid combination of type specifiers\n                         _global int inputB)\n                                 ^\n\n6 errors detected in the compilation of \"/tmp/OCLu7FyFF.cl\".\n```\n\n\nA tool like ```\nclcc```\n is very useful for catching errors early on. Most vendors also have their own version of a standalone kernel compiler/checker: e.g. Intel has its Kernel Builder, AMD's CodeXL contains a static kernel analyzer. Another option is to retrieve kernel compilation errors right from your host code, by calling ```\nclGetProgramBuildInfo```\n to retrieve the compiler output, after ```\nclBuildProgram```\n returned ```\nCL_BUILD_PROGRAM_FAILURE```\n.\n\nOnce these compilation errors are fixed, it looks like your kernel is still not doing what you expect: as noted, the inputs and outputs should be pointers, as you will be passing buffers to the kernel. Also, the indexing of your input and output arrays is incorrect: In the for-loop ```\ninputA[row * 3 + 1]```\n should be ```\ninputA[row * 3 + i]```\n (```\ni```\n instead of ```\n1```\n). When saving the result to ```\noutputC```\n, I would expect ```\noutputC[row * 3 + col]```\n (```\nrow * 3```\n) instead of ```\nrow + 3```\n).\n\nI haven't looked in detail at the host code, but I would at least make sure, especially when just starting out with OpenCL, to always check every return code and error. This will save you a lot of time and frustration.\n\nFinally, if you want a quick jump-start to learning OpenCL with a hands-on approach, I would strongly recommend going through the open source Hands-on OpenCL training by Simon McIntosh-Smith and Tom Deakin. It doesn't take very long, is quite pragmatic and provides lots of useful insights. Optimizing matrix multiplication is one of the use cases that is shown step-by-step.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication from the data frame in R\r\n                \r\nI'm studying matrix multiplication in R. I want to do matrix multiplication from the data frame.\nLet's say I have ```\ndf```\n and ```\nbeta```\n as follows:\n```\ndf <- data.frame(one = c(1,1,1,1,1),\n                 x1=c(21,34,24,35,42),\n                 x2=c(32,24,13,21,35))\nbeta<-c(1,2,2)\n```\n\n```\ndf```\n is a 5 by 3 matrix and ```\nbeta```\n is 3 by 1 matrix. I want to multiply ```\nbeta```\n to ```\ndf```\n to get a 5 by 1 column matrix. Usually, using the standard multiplication, the code should be\n```\ndf%*%beta \n```\n\nI want to do this multiplication and also give it a column name ```\ndf_beta```\n.\nBut since there are variable names on each column, this matrix multiplication doesn't work. How to do this?\n    ", "Answer": "\r\n```\n\"%*%\"```\n has no \"data.frame\" method. This is reasonable because there is no guarantee that all columns in a data frame are numeric.\nTo get a result, you need ```\nas.matrix(df) %*% beta```\n. But you take full responsibility to ensure the type conversion gives correct result (watch out for potential character matrix, for which I had a discussion here: Matrix multiplication in R: requires numeric/complex matrix/vector arguments).\nOnce it executes correctly, to store the result in a new column, use\n```\ndf$df_beta <- c(as.matrix(df) %*% beta)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in GSL-GNU\r\n                \r\nKindly tell me the function of matrix multiplication in GSL library. I have searched a lot but I am not be able to fine it. If any one know about that function kindly answer. Thanks in advance.\n    ", "Answer": "\r\nI think you'll want to use the ```\ngemm```\n family of functions, such as ```\ngsl_blas_sgemm()```\n.  Just set the scalars to one and the added matrix to zero.  An example is here.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Strassen Matrix Multiplication -- close, but still with bugs\r\n                \r\nI'm trying to implement Strassen Matrix multiplication in Python. I've got it working somewhat. Here's my code:\n\n```\na = [[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]]\nb = [[5,5,5,5],[6,6,6,6],[7,7,7,7],[8,8,8,8]]\n\ndef new_m(p, q): # create a matrix filled with 0s\n    matrix = [[0 for row in range(p)] for col in range(q)]\n    return matrix\n\ndef straight(a, b): # multiply the two matrices\n    if len(a[0]) != len(b): # if # of col != # of rows:\n        return \"Matrices are not m*n and n*p\"\n    else:\n        p_matrix = new_m(len(a), len(b[0]))\n        for i in range(len(a)):\n            for j in range(len(b[0])):\n                for k in range(len(b)):\n                    p_matrix[i][j] += a[i][k]*b[k][j]\n    return p_matrix\n\ndef split(matrix): # split matrix into quarters \n    a = matrix\n    b = matrix\n    c = matrix\n    d = matrix\n    while(len(a) > len(matrix)/2):\n        a = a[:len(a)//2]\n        b = b[:len(b)//2]\n        c = c[len(c)//2:]\n        d = d[len(d)//2:]\n    while(len(a[0]) > len(matrix[0])/2):\n        for i in range(len(a[0])//2):\n            a[i] = a[i][:len(a[i])//2]\n            b[i] = b[i][len(b[i])//2:]\n            c[i] = c[i][:len(c[i])//2]\n            d[i] = d[i][len(d[i])//2:]\n    return a,b,c,d\n\ndef add_m(a, b):\n    if type(a) == int:\n        d = a + b\n    else:\n        d = []\n        for i in range(len(a)):\n            c = []\n            for j in range(len(a[0])):\n                c.append(a[i][j] + b[i][j])\n            d.append(c)\n    return d\n\ndef sub_m(a, b):\n    if type(a) == int:\n        d = a - b\n    else:\n        d = []\n        for i in range(len(a)):\n            c = []\n            for j in range(len(a[0])):\n                c.append(a[i][j] - b[i][j])\n            d.append(c)\n    return d\n\n\ndef strassen(a, b, q):\n    # base case: 1x1 matrix\n    if q == 1:\n        d = [[0]]\n        d[0][0] = a[0][0] * b[0][0]\n        return d\n    else:\n        #split matrices into quarters\n        a11, a12, a21, a22 = split(a)\n        b11, b12, b21, b22 = split(b)\n\n        # p1 = (a11+a22) * (b11+b22)\n        p1 = strassen(add_m(a11,a22), add_m(b11,b22), q/2)\n\n        # p2 = (a21+a22) * b11\n        p2 = strassen(add_m(a21,a22), b11, q/2)\n\n        # p3 = a11 * (b12-b22)\n        p3 = strassen(a11, sub_m(b12,b22), q/2)\n\n        # p4 = a22 * (b12-b11)\n        p4 = strassen(a22, sub_m(b12,b11), q/2)\n\n        # p5 = (a11+a12) * b22\n        p5 = strassen(add_m(a11,a12), b22, q/2)\n\n        # p6 = (a21-a11) * (b11+b12)\n        p6 = strassen(sub_m(a21,a11), add_m(b11,b12), q/2)\n\n        # p7 = (a12-a22) * (b21+b22)\n        p7 = strassen(sub_m(a12,a22), add_m(b21,b22), q/2)\n\n\n        # c11 = p1 + p4 - p5 + p7\n        c11 = add_m(sub_m(add_m(p1, p4), p5), p7)\n\n        # c12 = p3 + p5\n        c12 = add_m(p3, p5)\n\n        # c21 = p2 + p4\n        c21 = add_m(p2, p4)\n\n        # c22 = p1 + p3 - p2 + p6\n        c22 = add_m(sub_m(add_m(p1, p3), p2), p6)\n\n        c = new_m(len(c11)*2,len(c11)*2)\n        for i in range(len(c11)):\n            for j in range(len(c11)):\n                c[i][j]                   = c11[i][j]\n                c[i][j+len(c11)]          = c12[i][j]\n                c[i+len(c11)][j]          = c21[i][j]\n                c[i+len(c11)][j+len(c11)] = c22[i][j]\n\n        return c\n\nprint \"Strassen Outputs:\"\nprint strassen(a, b, 4)\nprint \"Should be:\"\nprint straight(a, b)\n```\n\n\nI included straight matrix multiplication for reference to the proper desired output. Basically this happens:\n\nStrassen Outputs:\n\n```\n[[10, 14, 22, 26], [32, 36, 48, 52], [58, 66, 70, 78], [80, 88, 96, 104]]\n```\n\n\nShould be:\n\n```\n[[26, 26, 26, 26], [52, 52, 52, 52], [78, 78, 78, 78], [104, 104, 104, 104]]\n```\n\n\nI'm not sure what the source of the problem is, which means I can't solve it!\n    ", "Answer": "\r\nShouldn't this:\n\n```\n# p4 = a22 * (b12-b11)\np4 = strassen(a22, sub_m(b12,b11), q/2)\n```\n\n\nbe:\n\n```\n# p4 = a22 * (b21-b11)\np4 = strassen(a22, sub_m(b21,b11), q/2)\n```\n\n\ninstead?\n\n```\n~/coding$ python -i strass.py\nStrassen Outputs:\n[[26, 26, 26, 26], [52, 52, 52, 52], [78, 78, 78, 78], [104, 104, 104, 104]]\nShould be:\n[[26, 26, 26, 26], [52, 52, 52, 52], [78, 78, 78, 78], [104, 104, 104, 104]]\n>>> import numpy\n>>> def check():\n...     for i in range(100):\n...         a = numpy.random.randint(0, 10,size=(4,4)).tolist()\n...         b = numpy.random.randint(0, 10,size=(4,4)).tolist()\n...         assert strassen(a,b,4) == straight(a,b)\n...         assert (numpy.array(strassen(a,b,4)) == numpy.dot(a,b)).all()\n...     print 'hooray!'\n... \n>>> check()\nhooray!\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication using numpy array\r\n                \r\nI am trying to do a linear regression using Matrix multiplication. \n\n```\nX```\n is the feature matrix, and I have 100 data points. As per the normal equation, the dot product of ```\nX```\n and of the transpose of ```\nX```\n is required. \n\nHaving added a column of ones as required, the shape of ```\nX```\n is ```\n100×2```\n while for the transpose of ```\nX```\n it is ```\n2×100```\n.\n\nHowever, when I am doing the dot product, the result (which is given in the book) comes accordingly, a ```\n2×2```\n matrix. Shouldn't it be a ```\n100×100```\n matrix as per laws of matrix multiplication using dot product?\n\nConceptually, where am I going wrong?\n    ", "Answer": "\r\nYou are feeding them in the wrong order\n\nInstead of feeding ```\n(100,2) * (2,100)```\n, you are feeding ```\n(2,100) * (100,2)```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Overload matrix multiplication for S3 class in R\r\n                \r\nHow to I overload the matrix multiplication operator in ```\nR```\n? I have been able to do it with most other operators (using Ops), but with matrix operations I get this error:\n\n```\nrequires numeric/complex matrix/vector arguments\n```\n\n\nHere is a minimum working example:\n\n```\nspeed = function(x){\n    structure(list(y = x),\n              class = \"speed\")\n}\n\nm = matrix(c(1,2,3,4), ncol = 2)\ns = speed(m)\n\n# Addition works fine\n`+.speed` = function(e1, e2){ e1$y + e2 }\n\ns + 10\n\n# But matrix multiplication doesn't\n`%*%.speed` = function(e1, e2){ e1$y %*% e2 }\n\ns %*% c(1,2)\n```\n\n    ", "Answer": "\r\nI think this is because the ```\n%*%```\n is not an S3 generic function by default. You can get around this by making this so.\n\n```\n`%*%.default` = .Primitive(\"%*%\") # assign default as current definition\n`%*%` = function(x,...){ #make S3\n  UseMethod(\"%*%\",x)\n}\n`%*%.speed` = function(e1, e2){ e1$y %*% e2 } # define for speed\n\ns %*% c(1,2)\n     [,1]\n[1,]    7\n[2,]   10\n```\n\n\nYou could view Hadley's book if you wanted additional info on this here\n\nEdited in light of comment below.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Pandas force matrix multiplication\r\n                \r\nI would like to force matrix multiplication \"orientation\" using Python Pandas, both between DataFrames against DataFrames, Dataframes against Series and Series against Series.\n\nAs an example, I tried the following code:\n\n```\nt = pandas.Series([1, 2])\nprint(t.T.dot(t))\n```\n\n\nWhich outputs: 5\n\nBut I expect this:\n\n```\n[1 2\n 2 4]\n```\n\n\nPandas is great, but this inability to do matrix multiplications the way I want is what is the most frustrating, so any help would be greatly appreciated.\n\nPS: I know Pandas tries to implicitly use index to find the right way to compute the matrix product, but it seems this behavior can't be switched off!\n    ", "Answer": "\r\nHere:\n\n```\nIn [1]: import pandas\n\nIn [2]: t = pandas.Series([1, 2])\n\nIn [3]: np.outer(t, t)\nOut[3]:\narray([[1, 2],\n       [2, 4]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication using different classes - Java\r\n                \r\nI have this assignment for my class where I have to create a Matrix Multiplication program. Here's the condition:\n\nImplement two types of algorithms for multiplying two n × n matrices. Assume n is a power of 2:\n\n\nThe straight-forward O(n^3) matrix multiplication algorithm.\nStrassen’s matrix multiplication algorithm.\n\n\nEvaluate your different algorithms, and write a short report. Create test matrices for different values of n (4, 10, 20,100). Generate matrices using random numbers. Compute the running time of your algorithms. Your report should include the running times and conclusions.\n\nHere's my code so far:\n\n```\npublic class MatrixMultiplication \n{\n    public static void main(String[] args) \n    {\n       Random rand = new Random();\n       int rows = rand.nextInt(7) + 2;\n       int columns = rand.nextInt(7) + 2;\n\n       System.out.println(\"The matrix has \" + rows + \" randomized rows\");\n       System.out.println(\"The matrix has \" + columns + \" randomized column\");\n\n       System.out.println();\n\n       double[][] a = new double[rows][columns];\n       double[][] b = new double[columns][rows];\n\n       System.out.println(\"The first matrix has the values: \");\n       Matrix m1 = new Matrix(a);\n\n       System.out.println(\"---------------------------------\");\n       System.out.println(\"The second matrix has the values: \");\n       Matrix m2 = new Matrix(b);\n\n       System.out.println();\n\n       Matrix productRegular = m1.multiply(m2);\n\n    }\n}\n```\n\n\nAnd here's my other class:\n\n```\nimport java.util.Random;\n\nclass Matrix \n{ \n    double[][] arrayA;\n    double[][] arrayB;\n\n    private Matrix(double[][] a, double[][] b)\n    {\n        arrayA = a;\n        arrayB = b;\n    }\n\n    public Matrix(double[][] array) //Create matrix values\n    {\n        Random rand = new Random();\n\n        for(int i = 0; i < array.length; i++)\n        {\n            for(int j = 0; j < array[i].length; j++)\n            {\n                array[i][j] = rand.nextInt(10);\n                System.out.print(array[i][j] + \" | \");\n            }\n            System.out.println();\n        }\n    }\n\n\n\n    public double multiply(double[][] a, double[][] b)\n    {\n        double[][] c = new double[a.length][b[0].length];\n\n        System.out.println(\"Product of A and B is\");\n        for(int i = 0; i < a.length; i++)\n        {\n            for(int j = 0; j < b[0].length; j++)\n            {\n                for(int k = 0; k < a[0].length; k++)\n                {\n                    c[i][j] += a[i][k] * b[k][j];\n                    System.out.println(c[i][j] + \" | \");\n                }\n            }\n            System.out.println();\n        }\n\n        return c;\n    }\n}\n```\n\n\nI know I have to pass an object/Matrix for the multiply method, but how would I do that?  There are other concerns in my code, but I want to focus on passing objects right now. \n    ", "Answer": "\r\nLet's take a deep look to your code:\n\n\nWhy do you have two double[][] inside the Matrix class? A Matrix is just one bidimensional array. You should delete the arrayB\n\n```\ndouble[][] arrayA;\n```\n\n\n\n\n```\ndouble[][] arrayB;\n```\n\n\n\nWhat's the point of the private constructor? For you, it is useless right now.\n\n\n```\nprivate Matrix(double[][] a, double[][] b)\n{\n    arrayA = a;\n    arrayB = b;\n}\n```\n\n\n\n\n\n\nIn the public constructor, you are printing a Matrix, but you are not saving anywhere.\n\n```\npublic Matrix(double[][] array) //Create matrix values\n{\n    Random rand = new Random();\n\n    for(int i = 0; i < array.length; i++)\n    {\n        for(int j = 0; j < array[i].length; j++)\n        {\n            array[i][j] = rand.nextInt(10);\n            System.out.print(array[i][j] + \" | \");\n        }\n        System.out.println();\n    }\n```\n\n\n\n\n```\n    arrayA = array;\n```\n\n\n\n\n```\n}\n```\n\n\n\nAnyway, I think it would be much better to make 2 constructors \n\n```\n    public Matrix(double[][] array) //you just pass an array created outside the class\n    {\n        arrayA = array;\n    }\n\n    public Matrix(int rows, int columns) //Create matrix values\n    {\n        double[][] array = new double [rows][columns];\n        Random rand = new Random();\n\n        for(int i = 0; i < array.length; i++)\n        {\n            for(int j = 0; j < array[i].length; j++)\n            {\n                array[i][j] = rand.nextInt(10);\n                System.out.print(array[i][j] + \" | \");\n            }\n            System.out.println();\n        }\n        arrayA = array;\n    }\n```\n\n\n\nWhy your multiply method have 2 parameters? As it is inside the class Matrix (that have a double[][]variable). You only need a parameter (I think it is better to your example to have a Matrix parameter instead of a double[][]parameter and return also a Matrix). \nI don't like printing when you are creating or multiplying. It's much better to create a method to print the Matrix, and calling it when you want to print them.\n\n\nSo....the final code would be something like this:\n\nMain\n        public class MatrixMultiplication \n        {\n            public static void main(String[] args) \n            {\n               Random rand = new Random();\n               int rows = rand.nextInt(7) + 2;\n               int columns = rand.nextInt(7) + 2;\n\n```\n           System.out.println(\"The matrix has \" + rows + \" randomized rows\");\n           System.out.println(\"The matrix has \" + columns + \" randomized column\");\n\n           System.out.println();\n\n           System.out.println(\"The first matrix has the values: \");\n           Matrix m1 = new Matrix(rows,columns);\n           m1.print();\n           System.out.println(\"---------------------------------\");\n           System.out.println(\"The second matrix has the values: \");\n           Matrix m2 = new Matrix(columns, rows);\n\n           m2.print();\n           System.out.println();\n           System.out.println(\"Product of A and B is\");\n           Matrix productRegular = m1.multiply(m2);\n           productRegular.print();\n        }\n    }\n```\n\n\nMatrix Class\n\n```\n    import java.util.Random;\n\n    class Matrix \n    { \n        double[][] arrayA;\n\n        public Matrix(double[][] array) //Create matrix values\n        {\n            arrayA=array;\n        }\n\n        public Matrix(int rows, int columns) //Create matrix values\n        {\n            double[][]array= new double[rows][columns];\n            Random rand = new Random();\n\n            for(int i = 0; i < array.length; i++)\n            {\n                for(int j = 0; j < array[i].length; j++)\n                {\n                    array[i][j] = rand.nextInt(10);\n                }\n            }\n            arrayA=array;\n        }\n\n        public Matrix multiply(Matrix m)\n        {\n            double[][]b=m.arrayA;\n            double[][] c = new double[arrayA.length][b[0].length];\n\n            for(int i = 0; i < arrayA.length; i++)\n            {\n                for(int j = 0; j < b[0].length; j++)\n                {\n                    for(int k = 0; k < arrayA[0].length; k++)\n                    {\n                        c[i][j] += arrayA[i][k] * b[k][j];\n                    }\n                }\n            }\n\n            return new Matrix(c);\n        }\n\n\n        public void print(){\n            for(int i=0;i<arrayA.length;i++){\n                for(int j=0;j<arrayA[0].length;j++){\n                    System.out.print(arrayA[i][j] + \" | \");\n                }\n                System.out.println();\n            }\n        }\n    }\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Inaccuracies in matrix multiplication- C\r\n                \r\nI'm doing a DS project in C.\nI've been struggling with a matrix multiplication function:\n```\nvoid mat_mult(double **mat1, double **mat2, double **res, int n) {\n    int i, j, k;\n    \n    for (i = 0; i < n; i++) {\n        \n        for (j = 0; j < n; j++) {\n            assert(res[i][j] == 0);\n            for (k = 0; k < n; k++)\n                res[i][j] += mat1[i][k] * mat2[k][j];;\n        }\n    }\n} \n```\n\nThe matrices I'm trying to multiply are:\n```\n0.00000000, 0.00007291, 0.00000000 \n0.00007291, 0.00000000, 0.00000001 \n0.00000000, 0.00000001, 0.00000000\n```\n\nand:\n```\n117.11258762, 0.00000000, 0.00000000 \n0.00000000, 117.10123871, 0.00000000 \n0.00000000, 0.00000000, 8087.59220061\n```\n\nThe result is:\n```\n0.00000000, 0.00853872, 0.00000007 \n0.00853790, 0.00000000, 0.00000172 \n0.00000467, 0.00011897, 0.00000000 \n```\n\nAnd not:\n```\n0.00000000 0.00853868 0.00000000\n0.00853785 0.00000000 0.00000117\n0.00000000 0.00008088 0.00000000\n```\n\nSo, the inaccuracies are very small but could be significant. Does anyone have an idea on how to solve or what to look for in trying to solve this?\n***Edit- generating code ***\n```\nint main(){\nint i,j;\nint dim=3;\nint n=3;\ndouble* a;\ndouble** wam_res, **ddg_res, **lnorm_res, **test_res;\ndouble** vecs;\nvecs= (double**)calloc(n, sizeof(double*));\nassert(vecs!=NULL);\n\nfor(i=0; i<n; i++)\n{\n    a= (double*)calloc(dim,sizeof(double));\n    assert(a!=NULL);\n    for(j=0; j<dim; j++)\n    {\n        a[j]= rand() %50;\n    }\n    vecs[i]= a;\n    \n}\nwam_res= wam(vecs,dim,n);\nprintf(\"%s\",\"wam:\\n\");\nprint_matrix(wam_res, n);\nddg_res= ddg(wam_res, n);\nprintf(\"%s\",\"ddg:\\n\");\nprint_sym_mat(ddg_res, n); \n\nlnorm_res= lnorm(ddg_res, wam_res, n);\nprintf(\"%s\",\"lnorm:\\n\"); }\n\n\ndouble** wam(double** vecs, int dim, int n) {\n /*Calculating wam for the given set of vectors- n vectors of dimension dim */\ndouble** res;\nint i,j, curr_index=0;\ndouble norm;\nres= (double**)calloc(n, sizeof(double*));\nfor(i=0; i< n; i++)\n{\n    res[i]= (double*)calloc(n, sizeof(double));\n\n    /*For vector i, calculating wij for all 0<=j<n*/\n    for(j=0; j<n; j++)\n    {\n        if(i!=j)\n\n        {\n            \n            norm= l2_norm2vec(*(vecs+i),*(vecs+j),dim); /* function for l2 norm */\n            \n            res[i][j]= exp((-1*norm/2));\n            \n            curr_index++;\n        }\n        else\n        {\n            /* no self loops */\n            res[i][j]=0;\n        }\n    }\n}\nreturn res; }\n\ndouble** ddg(double** wam, int n) {\nint i, j; \ndouble** res;\ndouble d=0; \nres= (double**)calloc(n*n, sizeof(double*)); /* a n*n array with just 0s */\nfor(i=0; i<n; i++)\n{\n    res[i]= (double*)calloc(n, sizeof(double));\n    for(j=0; j<n; j++)\n    {\n        d+=wam[i][j];\n    }\n    res[i][i]= 1/sqrt(d);\n    d=0;\n\n}\nreturn res; }\n\ndouble** lnorm(double** ddg, double** wam,  int n) {\ndouble** res, **tmp;\nint i;\nres= (double**)calloc(n, sizeof(double));\ntmp= (double**)calloc(n, sizeof(double));\nfor(i=0; i<n; i++)\n{\n    res[i]= (double*)calloc(n, sizeof(double));\n    tmp[i]= (double*)calloc(n, sizeof(double));\n}\n\nmat_mult(ddg,wam, res, n);\nprintf(\"%s\", \"step 1 results: \\n\");\nprint_sym_mat(res,n); /* errors happened here */\nmat_mult(copyMatrix(res,n), ddg,tmp,n);  /*copyMatrix- simple loop to allocate an identical matrix */\nres= copyMatrix(tmp,n);\nprintf(\"%s\", \"step 2 results: \\n\");\nprint_sym_mat(res,n); /* errors happened here too */\nmat_subI(res,n); \nprintf(\"%s\", \"step 3 results: \\n\");\nprint_sym_mat(res,n);\nreturn res; }\n```\n\nThe main function that calls the matrix multiplication is lnorm, that appears at the end of the code. It receives two vector calculations for different graph representations\n    ", "Answer": "\r\nInaccuracies are not to blame here: the second matrix is a diagonal matrix so the matrix multiplication involves a single multiplication per element of the resulting matrix. Your code outputs only 8 decimal places, whereas the values have more data.\nHere is a modified version of the code that compiles and outputs the posted results, exhibiting the issue: the values in the matrices are rounded to 8 decimal places, which is a significant difference for some of the elements:\n```\n#include <assert.h>\n#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ndouble **wam(double **vecs, int dim, int n);\ndouble **ddg(double **wam, int n);\ndouble **lnorm(double **ddg, double **wam, int n);\n\ndouble l2_norm2vec(double *vec1, double *vec2, int n) {\n    double res = 0;\n    for (int i = 0; i < n; i++) {\n        double d = vec2[i] - vec1[i];\n        res += d * d;\n    }\n    return sqrt(res);\n}\n\n#define print_sym_mat print_matrix\n\ndouble **copyMatrix(double **res, int n) {\n    double **mat = malloc(sizeof(*mat) * n);\n    for (int i = 0; i < n; i++) {\n        mat[i] = malloc(sizeof(*mat[i]) * n);\n        for (int j = 0; j < n; j++) {\n            mat[i][j] = res[i][j];\n        }\n    }\n    return mat;\n}\n\ndouble **mat_subI(double **mat, int n) {\n    for (int i = 0; i < n; i++) {\n        mat[i][i] -= 1;\n    }\n    return mat;\n}\n\nvoid mat_mult(double **mat1, double **mat2, double **res, int n) {\n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            res[i][j] = 0;\n            for (int k = 0; k < n; k++)\n                res[i][j] += mat1[i][k] * mat2[k][j];\n        }\n    }\n}\n\nvoid print_matrix(double **mat, int n) {\n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            printf(\"%19.15f,\", mat[i][j]);\n        }\n        printf(\"\\n\");\n    }\n    printf(\"\\n\");\n}\n\nint main() {\n    int i, j;\n    int dim = 3;\n    int n = 3;\n    double *a;\n    double **wam_res, **ddg_res, **lnorm_res;\n    double **vecs;\n    vecs = (double**)calloc(n, sizeof(double*));\n    assert(vecs != NULL);\n\n    for (i = 0; i < n; i++) {\n        a = (double*)calloc(dim, sizeof(double));\n        assert(a != NULL);\n        for (j = 0; j < dim; j++) {\n            a[j] = rand() % 50;\n        }\n        vecs[i] = a;\n    }\n    wam_res = wam(vecs, dim, n);\n    printf(\"%s\", \"wam:\\n\");\n    print_matrix(wam_res, n);\n    ddg_res = ddg(wam_res, n);\n    printf(\"%s\", \"ddg:\\n\");\n    print_sym_mat(ddg_res, n);\n\n    lnorm_res = lnorm(ddg_res, wam_res, n);\n    printf(\"%s\", \"lnorm:\\n\");\n    print_matrix(lnorm_res, n);\n    return 0;\n}\n\ndouble **wam(double **vecs, int dim, int n) {\n    /* Calculating wam for the given set of vectors- n vectors of dimension dim */\n    double **res;\n    int i, j, curr_index = 0;\n    double norm;\n    res = (double **)calloc(n, sizeof(double*));\n    for (i = 0; i < n; i++) {\n        res[i] = (double*)calloc(n, sizeof(double));\n\n        /*For vector i, calculating wij for all 0<=j<n*/\n        for (j = 0; j < n; j++) {\n            if (i != j) {\n                norm = l2_norm2vec(*(vecs+i), *(vecs+j), dim); /* function for l2 norm */\n                res[i][j] = exp((-1 * norm / 2));\n                curr_index++;\n            } else {\n                /* no self loops */\n                res[i][j] = 0;\n            }\n        }\n    }\n    return res;\n}\n\ndouble **ddg(double **wam, int n) {\n    int i, j;\n    double **res;\n    double d = 0;\n    res = (double**)calloc(n*n, sizeof(double*)); /* a n*n array with just 0s */\n    for (i = 0; i < n; i++) {\n        res[i] = (double*)calloc(n, sizeof(double));\n        for (j = 0; j < n; j++)  {\n            d += wam[i][j];\n        }\n        res[i][i] = 1 / sqrt(d);\n        d = 0;\n    }\n    return res;\n}\n\ndouble **lnorm(double **ddg, double **wam, int n) {\n    double **res, **tmp;\n    int i;\n    res = (double**)calloc(n, sizeof(double));\n    tmp = (double**)calloc(n, sizeof(double));\n    for (i = 0; i < n; i++) {\n        res[i] = (double*)calloc(n, sizeof(double));\n        tmp[i] = (double*)calloc(n, sizeof(double));\n    }\n\n    mat_mult(ddg,wam, res, n);\n    printf(\"%s\", \"step 1 results: \\n\");\n    print_sym_mat(res, n); /* errors happened here */\n    mat_mult(copyMatrix(res, n), ddg, tmp, n);  /*copyMatrix- simple loop to allocate an identical matrix */\n    res = copyMatrix(tmp, n);\n    printf(\"%s\", \"step 2 results: \\n\");\n    print_sym_mat(res, n); /* errors happened here too */\n    mat_subI(res, n);\n    printf(\"%s\", \"step 3 results: \\n\");\n    print_sym_mat(res, n);\n    return res;\n}\n```\n\nOutput with 8 decimal places:\n```\nwam:\n  0.00000000,  0.00007291,  0.00000000,\n  0.00007291,  0.00000000,  0.00000001,\n  0.00000000,  0.00000001,  0.00000000,\n\nddg:\n117.11258762,  0.00000000,  0.00000000,\n  0.00000000,117.10123871,  0.00000000,\n  0.00000000,  0.00000000,8087.59220061,\n\nstep 1 results:\n  0.00000000,  0.00853872,  0.00000007,\n  0.00853790,  0.00000000,  0.00000172,\n  0.00000467,  0.00011897,  0.00000000,\n\nstep 2 results:\n  0.00000000,  0.99989517,  0.00054713,\n  0.99989517,  0.00000000,  0.01393205,\n  0.00054713,  0.01393205,  0.00000000,\n\nstep 3 results:\n -1.00000000,  0.99989517,  0.00054713,\n  0.99989517, -1.00000000,  0.01393205,\n  0.00054713,  0.01393205, -1.00000000,\n\nlnorm:\n -1.00000000,  0.99989517,  0.00054713,\n  0.99989517, -1.00000000,  0.01393205,\n  0.00054713,  0.01393205, -1.00000000,\n```\n\nWith more places, it appears the coefficients in ```\nwam```\n are quite different from ```\n0.00000001```\n:\n```\nwam:\n  0.000000000000000,  0.000072910387337,  0.000000000577653,\n  0.000072910387337,  0.000000000000000,  0.000000014710728,\n  0.000000000577653,  0.000000014710728,  0.000000000000000,\n\nddg:\n117.112587619035523,  0.000000000000000,  0.000000000000000,\n  0.000000000000000,117.101238706028283,  0.000000000000000,\n  0.000000000000000,  0.000000000000000,8087.592200608456551,\n\nstep 1 results:\n  0.000000000000000,  0.008538724125301,  0.000000067650464,\n  0.008537896671658,  0.000000000000000,  0.000001722644500,\n  0.000004671823707,  0.000118974371006,  0.000000000000000,\n\nstep 2 results:\n  0.000000000000000,  0.999895172041842,  0.000547129363250,\n  0.999895172041842,  0.000000000000000,  0.013932046219111,\n  0.000547129363250,  0.013932046219111,  0.000000000000000,\n\nstep 3 results:\n -1.000000000000000,  0.999895172041842,  0.000547129363250,\n  0.999895172041842, -1.000000000000000,  0.013932046219111,\n  0.000547129363250,  0.013932046219111, -1.000000000000000,\n\nlnorm:\n -1.000000000000000,  0.999895172041842,  0.000547129363250,\n  0.999895172041842, -1.000000000000000,  0.013932046219111,\n  0.000547129363250,  0.013932046219111, -1.000000000000000,\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "OpenCV matrix multiplication assertion\r\n                \r\nI'm getting\n\n```\nOpenCV Error: Assertion failed (type == B.type() && (type == CV_32FC1 || type == CV_64FC1 || type == CV_32FC2 || type == CV_64FC2)) in gemm, file /build/buildd\n/opencv-2.4.9+dfsg/modules/core/src/matmul.cpp, line 711\nterminate called after throwing an instance of 'cv::Exception'\n  what():  /build/buildd/opencv-2.4.9+dfsg/modules/core/src/matmul.cpp:711: error: (-215) type == B.type() && (type == CV_32FC1 || type == CV_64FC1 || type == \nCV_32FC2 || type == CV_64FC2) in function gemm\n```\n\n\nI'd like to know where in the docs it's mentioned matrix multiplication is supported solely for floating point matrices? I could only find people telling this in SO, but nothing so far comparable to a standard documentation.\n    ", "Answer": "\r\nYou didn't mentioned the operator you are using but you can try mat1.mul(mat2), mat1*mat2, multiply(mat1, mat2, dst) or do:\n\n```\nmat1.convertTo(mat1, CV_32FC1);\nmat2.convertTo(mat2, CV_32FC1);\n```\n\n\nand if needed:\n\n```\nmat1.convertTo(mat1, CV_8UC1);\nmat2.convertTo(mat2, CV_8UC1);\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Pandas: Matrix Multiplication\r\n                \r\nI am attempting to find the best method for matrix multiplication using pandas.  Suppose I want to do a simple exercise: xyx' ...[1x5][5x5][5x1]'.\n\n```\nin:\n\nydates = pd.date_range('20170101',periods=5)\ny = pd.DataFrame(np.identity(5),index=['f','o','b','a','r'],columns=['f','o','b','a','r'])\nxdata = list(range(1,6))\nx = pd.DataFrame(xdata,index=['f','o','b','a','r'])\nx.loc['o'] = np.nan\nmm = x.T.dot(y)*x.T  \n\n\n\nout: \n\n        f   o   b   a   r\n    0 NaN NaN NaN NaN NaN\n```\n\n\nI would expect to get: \n\n```\n     0\nf  1.0\no  NaN\nb  3.0\na  4.0\nr  5.0\n```\n\n\nMy questions are: \n\n1) How do I align these? Is there a better way than doing the double transpose?\n\n2) Is there a way to account for nans?\n\n2) Is there a more efficient way to do matrix algebra using python/pandas?\n    ", "Answer": "\r\n```\nnumpy```\nhas several functions that handle matrix products - ```\nnp.dot```\n, ```\nnp.einsum```\n and ```\nnp.matmul```\n (and the ```\n@```\n operator).  ```\n*```\n is defined as element wise multiplication (except for ```\nnp.matrix```\n class).  All are optimized for speed.  But they also propagate ```\nnan```\n.\n\nUsing numpy arrays instead of pandas:\n\n```\nIn [314]: y = np.eye(5)\nIn [316]: y\nOut[316]: \narray([[ 1.,  0.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  0.,  1.]])\n```\n\n\nTo do transpose on ```\nx```\n we need to make it 2d; and to assign ```\nnan```\n it has to be float.\n\n```\nIn [320]: x = np.arange(1,6).astype(float).reshape(1,5)\nIn [321]: x[0,1]=np.nan\nIn [322]: x\nOut[322]: array([[  1.,  nan,   3.,   4.,   5.]])\nIn [323]: x.T       # column vector\nOut[323]: \narray([[  1.],\n       [ nan],\n       [  3.],\n       [  4.],\n       [  5.]])\nIn [324]: np.dot(y, x.T)\nOut[324]: \narray([[ nan],\n       [ nan],\n       [ nan],\n       [ nan],\n       [ nan]])\n```\n\n\nWhy this ```\ndot```\n result?  It multiplies each row of ```\ny```\n by the column of ```\nx.T```\n, and sums the values.  Because of the ```\nnan```\n one of those products for each row of ```\ny```\n is ```\n1*nan```\n or ```\n0*nan```\n; any product or sum involving ```\nnan```\n produces ```\nnan```\n, to the result is all ```\nnan```\n.\n\nI suspect you were hoping that ```\n0*nan == 0```\n.  Like:\n\n```\nIn [329]: x[0,1]=100\nIn [330]: np.dot(y, x.T)\nOut[330]: \narray([[   1.],\n       [ 100.],\n       [   3.],\n       [   4.],\n       [   5.]])\n```\n\n\nThere are some ```\nnumpy```\n functions that skip ```\nnan```\n. ```\nnp.dot```\n isn't one of them.\n\n```\nIn [333]: x[0,1]=np.nan\nIn [336]: y*x\nOut[336]: \narray([[  1.,  nan,   0.,   0.,   0.],\n       [  0.,  nan,   0.,   0.,   0.],\n       [  0.,  nan,   3.,   0.,   0.],\n       [  0.,  nan,   0.,   4.,   0.],\n       [  0.,  nan,   0.,   0.,   5.]])\nIn [339]: np.nansum(y*x, axis=1, keepdims=True)\nOut[339]: \narray([[ 1.],\n       [ 0.],\n       [ 3.],\n       [ 4.],\n       [ 5.]])\n```\n\n\nThis sort of works.  It skipped the ```\nnan```\n when summing across rows; but the 2nd value is 0, not ```\nnan```\n.\n\n\n\nThe ```\nnp.nan...```\n functions work by temporarily replacing the ```\nnan```\n with something innocuous like 0 or 1.  I could do that in your case with:\n\n```\nIn [369]: x\nOut[369]: array([[  1.,  nan,   3.,   4.,   5.]])\nIn [370]: x1, mask = np.lib.nanfunctions._replace_nan(x.T,1)\nIn [371]: x1\nOut[371]: \narray([[ 1.],\n       [ 1.],\n       [ 3.],\n       [ 4.],\n       [ 5.]])\nIn [372]: mask\nOut[372]: \narray([[False],\n       [ True],\n       [False],\n       [False],\n       [False]], dtype=bool)\nIn [373]: x2 = np.dot(y, x1)\nIn [374]: x2[mask] = np.nan\nIn [375]: x2\nOut[375]: \narray([[  1.],\n       [ nan],\n       [  3.],\n       [  4.],\n       [  5.]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Incorrect dimensions for matrix multiplication\r\n                \r\nI just want to make some predictions using these calculations but I'm getting this error: Error using  *  Incorrect dimensions for matrix multiplication. Check that the number of columns in the first matrix matches the number of rows in the second matrix. To operate on each element of the matrix individually, use TIMES (.*) for elementwise multiplication.\nError in main (line 64) r=(pn')*(best);\nthe dataset\nMain driver\n```\nclear; clc;\n%load dataset\n\nds = load('ex1data1.txt');\n\n%split x/y\n\n\n\nx = ds(:,1); % Examples\ny = ds(:,2);\nn=1;\nm=length(y);\nformat long;\nb1 = x\\y;  %intercept\n    \n    %plot lineer regression \n    % Top plot\nyCalc1 = b1*x;\nax1 = nexttile;\nscatter(ax1,x,y,'o');\nhold on\nplot(ax1,x,yCalc1);\ntitle(ax1,'Linear Regression Relation Between Profit & Truck')\nax1.FontSize = 14;\nax1.XColor = 'red';\nylabel('profit of a food truck');\nxlabel('population of a city');\ngrid on\n\n\n\n%normalise\n[x,maxs,mins]=normalize(x);\n\n\n%add column with ones - help hyphothesizs\nxo=[ones(m,1),x];\n\n%gradient descent\nrepeat=1500;\nlrate=0.01;\nthetas=zeros(2,1);\n[best,costs] = gradientDescent(repeat,lrate,thetas,xo,y,m);\n\n\n% plot 𝑱(𝜽) vs iteration\n\n\nax2 = nexttile;\nscatter(ax2,costs,1:repeat)\ntitle(ax2,' 𝑱(𝜽) vs iteration')\ngrid(ax2,'on')\nylabel('Iteration');\nxlabel('J(𝜽)');\n\n\n%prediction\n\n\np=[7;7];\npn=(p-maxs')./(maxs'-mins');\npn = [1;pn];\nr=(pn')*(best);\n```\n\nGradient Descent\n```\nfunction [thetas,costs] = gradientDescent(repeat,lrate,thetas,xo,y,m)\n    costs = zeros(repeat,1);\n    for r = 1:repeat\n        hc=xo*thetas - y;\n        tempintercept=sum(hc.*xo);\n        thetas = thetas - (lrate * (1/m)) * tempintercept';\n        costs(r)=cost(thetas,xo,y);\n    end\nend\n```\n\nNormalize\n```\nfunction [x,maxs,mins] = normalize (x)\n    \n    x=(x-max(x))./(max(x)/min(x));\n    maxs=max(x);\n    mins=min(x);\nend\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Inaccuracies in matrix multiplication- C\r\n                \r\nI'm doing a DS project in C.\nI've been struggling with a matrix multiplication function:\n```\nvoid mat_mult(double **mat1, double **mat2, double **res, int n) {\n    int i, j, k;\n    \n    for (i = 0; i < n; i++) {\n        \n        for (j = 0; j < n; j++) {\n            assert(res[i][j] == 0);\n            for (k = 0; k < n; k++)\n                res[i][j] += mat1[i][k] * mat2[k][j];;\n        }\n    }\n} \n```\n\nThe matrices I'm trying to multiply are:\n```\n0.00000000, 0.00007291, 0.00000000 \n0.00007291, 0.00000000, 0.00000001 \n0.00000000, 0.00000001, 0.00000000\n```\n\nand:\n```\n117.11258762, 0.00000000, 0.00000000 \n0.00000000, 117.10123871, 0.00000000 \n0.00000000, 0.00000000, 8087.59220061\n```\n\nThe result is:\n```\n0.00000000, 0.00853872, 0.00000007 \n0.00853790, 0.00000000, 0.00000172 \n0.00000467, 0.00011897, 0.00000000 \n```\n\nAnd not:\n```\n0.00000000 0.00853868 0.00000000\n0.00853785 0.00000000 0.00000117\n0.00000000 0.00008088 0.00000000\n```\n\nSo, the inaccuracies are very small but could be significant. Does anyone have an idea on how to solve or what to look for in trying to solve this?\n***Edit- generating code ***\n```\nint main(){\nint i,j;\nint dim=3;\nint n=3;\ndouble* a;\ndouble** wam_res, **ddg_res, **lnorm_res, **test_res;\ndouble** vecs;\nvecs= (double**)calloc(n, sizeof(double*));\nassert(vecs!=NULL);\n\nfor(i=0; i<n; i++)\n{\n    a= (double*)calloc(dim,sizeof(double));\n    assert(a!=NULL);\n    for(j=0; j<dim; j++)\n    {\n        a[j]= rand() %50;\n    }\n    vecs[i]= a;\n    \n}\nwam_res= wam(vecs,dim,n);\nprintf(\"%s\",\"wam:\\n\");\nprint_matrix(wam_res, n);\nddg_res= ddg(wam_res, n);\nprintf(\"%s\",\"ddg:\\n\");\nprint_sym_mat(ddg_res, n); \n\nlnorm_res= lnorm(ddg_res, wam_res, n);\nprintf(\"%s\",\"lnorm:\\n\"); }\n\n\ndouble** wam(double** vecs, int dim, int n) {\n /*Calculating wam for the given set of vectors- n vectors of dimension dim */\ndouble** res;\nint i,j, curr_index=0;\ndouble norm;\nres= (double**)calloc(n, sizeof(double*));\nfor(i=0; i< n; i++)\n{\n    res[i]= (double*)calloc(n, sizeof(double));\n\n    /*For vector i, calculating wij for all 0<=j<n*/\n    for(j=0; j<n; j++)\n    {\n        if(i!=j)\n\n        {\n            \n            norm= l2_norm2vec(*(vecs+i),*(vecs+j),dim); /* function for l2 norm */\n            \n            res[i][j]= exp((-1*norm/2));\n            \n            curr_index++;\n        }\n        else\n        {\n            /* no self loops */\n            res[i][j]=0;\n        }\n    }\n}\nreturn res; }\n\ndouble** ddg(double** wam, int n) {\nint i, j; \ndouble** res;\ndouble d=0; \nres= (double**)calloc(n*n, sizeof(double*)); /* a n*n array with just 0s */\nfor(i=0; i<n; i++)\n{\n    res[i]= (double*)calloc(n, sizeof(double));\n    for(j=0; j<n; j++)\n    {\n        d+=wam[i][j];\n    }\n    res[i][i]= 1/sqrt(d);\n    d=0;\n\n}\nreturn res; }\n\ndouble** lnorm(double** ddg, double** wam,  int n) {\ndouble** res, **tmp;\nint i;\nres= (double**)calloc(n, sizeof(double));\ntmp= (double**)calloc(n, sizeof(double));\nfor(i=0; i<n; i++)\n{\n    res[i]= (double*)calloc(n, sizeof(double));\n    tmp[i]= (double*)calloc(n, sizeof(double));\n}\n\nmat_mult(ddg,wam, res, n);\nprintf(\"%s\", \"step 1 results: \\n\");\nprint_sym_mat(res,n); /* errors happened here */\nmat_mult(copyMatrix(res,n), ddg,tmp,n);  /*copyMatrix- simple loop to allocate an identical matrix */\nres= copyMatrix(tmp,n);\nprintf(\"%s\", \"step 2 results: \\n\");\nprint_sym_mat(res,n); /* errors happened here too */\nmat_subI(res,n); \nprintf(\"%s\", \"step 3 results: \\n\");\nprint_sym_mat(res,n);\nreturn res; }\n```\n\nThe main function that calls the matrix multiplication is lnorm, that appears at the end of the code. It receives two vector calculations for different graph representations\n    ", "Answer": "\r\nInaccuracies are not to blame here: the second matrix is a diagonal matrix so the matrix multiplication involves a single multiplication per element of the resulting matrix. Your code outputs only 8 decimal places, whereas the values have more data.\nHere is a modified version of the code that compiles and outputs the posted results, exhibiting the issue: the values in the matrices are rounded to 8 decimal places, which is a significant difference for some of the elements:\n```\n#include <assert.h>\n#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ndouble **wam(double **vecs, int dim, int n);\ndouble **ddg(double **wam, int n);\ndouble **lnorm(double **ddg, double **wam, int n);\n\ndouble l2_norm2vec(double *vec1, double *vec2, int n) {\n    double res = 0;\n    for (int i = 0; i < n; i++) {\n        double d = vec2[i] - vec1[i];\n        res += d * d;\n    }\n    return sqrt(res);\n}\n\n#define print_sym_mat print_matrix\n\ndouble **copyMatrix(double **res, int n) {\n    double **mat = malloc(sizeof(*mat) * n);\n    for (int i = 0; i < n; i++) {\n        mat[i] = malloc(sizeof(*mat[i]) * n);\n        for (int j = 0; j < n; j++) {\n            mat[i][j] = res[i][j];\n        }\n    }\n    return mat;\n}\n\ndouble **mat_subI(double **mat, int n) {\n    for (int i = 0; i < n; i++) {\n        mat[i][i] -= 1;\n    }\n    return mat;\n}\n\nvoid mat_mult(double **mat1, double **mat2, double **res, int n) {\n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            res[i][j] = 0;\n            for (int k = 0; k < n; k++)\n                res[i][j] += mat1[i][k] * mat2[k][j];\n        }\n    }\n}\n\nvoid print_matrix(double **mat, int n) {\n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            printf(\"%19.15f,\", mat[i][j]);\n        }\n        printf(\"\\n\");\n    }\n    printf(\"\\n\");\n}\n\nint main() {\n    int i, j;\n    int dim = 3;\n    int n = 3;\n    double *a;\n    double **wam_res, **ddg_res, **lnorm_res;\n    double **vecs;\n    vecs = (double**)calloc(n, sizeof(double*));\n    assert(vecs != NULL);\n\n    for (i = 0; i < n; i++) {\n        a = (double*)calloc(dim, sizeof(double));\n        assert(a != NULL);\n        for (j = 0; j < dim; j++) {\n            a[j] = rand() % 50;\n        }\n        vecs[i] = a;\n    }\n    wam_res = wam(vecs, dim, n);\n    printf(\"%s\", \"wam:\\n\");\n    print_matrix(wam_res, n);\n    ddg_res = ddg(wam_res, n);\n    printf(\"%s\", \"ddg:\\n\");\n    print_sym_mat(ddg_res, n);\n\n    lnorm_res = lnorm(ddg_res, wam_res, n);\n    printf(\"%s\", \"lnorm:\\n\");\n    print_matrix(lnorm_res, n);\n    return 0;\n}\n\ndouble **wam(double **vecs, int dim, int n) {\n    /* Calculating wam for the given set of vectors- n vectors of dimension dim */\n    double **res;\n    int i, j, curr_index = 0;\n    double norm;\n    res = (double **)calloc(n, sizeof(double*));\n    for (i = 0; i < n; i++) {\n        res[i] = (double*)calloc(n, sizeof(double));\n\n        /*For vector i, calculating wij for all 0<=j<n*/\n        for (j = 0; j < n; j++) {\n            if (i != j) {\n                norm = l2_norm2vec(*(vecs+i), *(vecs+j), dim); /* function for l2 norm */\n                res[i][j] = exp((-1 * norm / 2));\n                curr_index++;\n            } else {\n                /* no self loops */\n                res[i][j] = 0;\n            }\n        }\n    }\n    return res;\n}\n\ndouble **ddg(double **wam, int n) {\n    int i, j;\n    double **res;\n    double d = 0;\n    res = (double**)calloc(n*n, sizeof(double*)); /* a n*n array with just 0s */\n    for (i = 0; i < n; i++) {\n        res[i] = (double*)calloc(n, sizeof(double));\n        for (j = 0; j < n; j++)  {\n            d += wam[i][j];\n        }\n        res[i][i] = 1 / sqrt(d);\n        d = 0;\n    }\n    return res;\n}\n\ndouble **lnorm(double **ddg, double **wam, int n) {\n    double **res, **tmp;\n    int i;\n    res = (double**)calloc(n, sizeof(double));\n    tmp = (double**)calloc(n, sizeof(double));\n    for (i = 0; i < n; i++) {\n        res[i] = (double*)calloc(n, sizeof(double));\n        tmp[i] = (double*)calloc(n, sizeof(double));\n    }\n\n    mat_mult(ddg,wam, res, n);\n    printf(\"%s\", \"step 1 results: \\n\");\n    print_sym_mat(res, n); /* errors happened here */\n    mat_mult(copyMatrix(res, n), ddg, tmp, n);  /*copyMatrix- simple loop to allocate an identical matrix */\n    res = copyMatrix(tmp, n);\n    printf(\"%s\", \"step 2 results: \\n\");\n    print_sym_mat(res, n); /* errors happened here too */\n    mat_subI(res, n);\n    printf(\"%s\", \"step 3 results: \\n\");\n    print_sym_mat(res, n);\n    return res;\n}\n```\n\nOutput with 8 decimal places:\n```\nwam:\n  0.00000000,  0.00007291,  0.00000000,\n  0.00007291,  0.00000000,  0.00000001,\n  0.00000000,  0.00000001,  0.00000000,\n\nddg:\n117.11258762,  0.00000000,  0.00000000,\n  0.00000000,117.10123871,  0.00000000,\n  0.00000000,  0.00000000,8087.59220061,\n\nstep 1 results:\n  0.00000000,  0.00853872,  0.00000007,\n  0.00853790,  0.00000000,  0.00000172,\n  0.00000467,  0.00011897,  0.00000000,\n\nstep 2 results:\n  0.00000000,  0.99989517,  0.00054713,\n  0.99989517,  0.00000000,  0.01393205,\n  0.00054713,  0.01393205,  0.00000000,\n\nstep 3 results:\n -1.00000000,  0.99989517,  0.00054713,\n  0.99989517, -1.00000000,  0.01393205,\n  0.00054713,  0.01393205, -1.00000000,\n\nlnorm:\n -1.00000000,  0.99989517,  0.00054713,\n  0.99989517, -1.00000000,  0.01393205,\n  0.00054713,  0.01393205, -1.00000000,\n```\n\nWith more places, it appears the coefficients in ```\nwam```\n are quite different from ```\n0.00000001```\n:\n```\nwam:\n  0.000000000000000,  0.000072910387337,  0.000000000577653,\n  0.000072910387337,  0.000000000000000,  0.000000014710728,\n  0.000000000577653,  0.000000014710728,  0.000000000000000,\n\nddg:\n117.112587619035523,  0.000000000000000,  0.000000000000000,\n  0.000000000000000,117.101238706028283,  0.000000000000000,\n  0.000000000000000,  0.000000000000000,8087.592200608456551,\n\nstep 1 results:\n  0.000000000000000,  0.008538724125301,  0.000000067650464,\n  0.008537896671658,  0.000000000000000,  0.000001722644500,\n  0.000004671823707,  0.000118974371006,  0.000000000000000,\n\nstep 2 results:\n  0.000000000000000,  0.999895172041842,  0.000547129363250,\n  0.999895172041842,  0.000000000000000,  0.013932046219111,\n  0.000547129363250,  0.013932046219111,  0.000000000000000,\n\nstep 3 results:\n -1.000000000000000,  0.999895172041842,  0.000547129363250,\n  0.999895172041842, -1.000000000000000,  0.013932046219111,\n  0.000547129363250,  0.013932046219111, -1.000000000000000,\n\nlnorm:\n -1.000000000000000,  0.999895172041842,  0.000547129363250,\n  0.999895172041842, -1.000000000000000,  0.013932046219111,\n  0.000547129363250,  0.013932046219111, -1.000000000000000,\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Pandas: Matrix Multiplication\r\n                \r\nI am attempting to find the best method for matrix multiplication using pandas.  Suppose I want to do a simple exercise: xyx' ...[1x5][5x5][5x1]'.\n\n```\nin:\n\nydates = pd.date_range('20170101',periods=5)\ny = pd.DataFrame(np.identity(5),index=['f','o','b','a','r'],columns=['f','o','b','a','r'])\nxdata = list(range(1,6))\nx = pd.DataFrame(xdata,index=['f','o','b','a','r'])\nx.loc['o'] = np.nan\nmm = x.T.dot(y)*x.T  \n\n\n\nout: \n\n        f   o   b   a   r\n    0 NaN NaN NaN NaN NaN\n```\n\n\nI would expect to get: \n\n```\n     0\nf  1.0\no  NaN\nb  3.0\na  4.0\nr  5.0\n```\n\n\nMy questions are: \n\n1) How do I align these? Is there a better way than doing the double transpose?\n\n2) Is there a way to account for nans?\n\n2) Is there a more efficient way to do matrix algebra using python/pandas?\n    ", "Answer": "\r\n```\nnumpy```\nhas several functions that handle matrix products - ```\nnp.dot```\n, ```\nnp.einsum```\n and ```\nnp.matmul```\n (and the ```\n@```\n operator).  ```\n*```\n is defined as element wise multiplication (except for ```\nnp.matrix```\n class).  All are optimized for speed.  But they also propagate ```\nnan```\n.\n\nUsing numpy arrays instead of pandas:\n\n```\nIn [314]: y = np.eye(5)\nIn [316]: y\nOut[316]: \narray([[ 1.,  0.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  0.,  1.]])\n```\n\n\nTo do transpose on ```\nx```\n we need to make it 2d; and to assign ```\nnan```\n it has to be float.\n\n```\nIn [320]: x = np.arange(1,6).astype(float).reshape(1,5)\nIn [321]: x[0,1]=np.nan\nIn [322]: x\nOut[322]: array([[  1.,  nan,   3.,   4.,   5.]])\nIn [323]: x.T       # column vector\nOut[323]: \narray([[  1.],\n       [ nan],\n       [  3.],\n       [  4.],\n       [  5.]])\nIn [324]: np.dot(y, x.T)\nOut[324]: \narray([[ nan],\n       [ nan],\n       [ nan],\n       [ nan],\n       [ nan]])\n```\n\n\nWhy this ```\ndot```\n result?  It multiplies each row of ```\ny```\n by the column of ```\nx.T```\n, and sums the values.  Because of the ```\nnan```\n one of those products for each row of ```\ny```\n is ```\n1*nan```\n or ```\n0*nan```\n; any product or sum involving ```\nnan```\n produces ```\nnan```\n, to the result is all ```\nnan```\n.\n\nI suspect you were hoping that ```\n0*nan == 0```\n.  Like:\n\n```\nIn [329]: x[0,1]=100\nIn [330]: np.dot(y, x.T)\nOut[330]: \narray([[   1.],\n       [ 100.],\n       [   3.],\n       [   4.],\n       [   5.]])\n```\n\n\nThere are some ```\nnumpy```\n functions that skip ```\nnan```\n. ```\nnp.dot```\n isn't one of them.\n\n```\nIn [333]: x[0,1]=np.nan\nIn [336]: y*x\nOut[336]: \narray([[  1.,  nan,   0.,   0.,   0.],\n       [  0.,  nan,   0.,   0.,   0.],\n       [  0.,  nan,   3.,   0.,   0.],\n       [  0.,  nan,   0.,   4.,   0.],\n       [  0.,  nan,   0.,   0.,   5.]])\nIn [339]: np.nansum(y*x, axis=1, keepdims=True)\nOut[339]: \narray([[ 1.],\n       [ 0.],\n       [ 3.],\n       [ 4.],\n       [ 5.]])\n```\n\n\nThis sort of works.  It skipped the ```\nnan```\n when summing across rows; but the 2nd value is 0, not ```\nnan```\n.\n\n\n\nThe ```\nnp.nan...```\n functions work by temporarily replacing the ```\nnan```\n with something innocuous like 0 or 1.  I could do that in your case with:\n\n```\nIn [369]: x\nOut[369]: array([[  1.,  nan,   3.,   4.,   5.]])\nIn [370]: x1, mask = np.lib.nanfunctions._replace_nan(x.T,1)\nIn [371]: x1\nOut[371]: \narray([[ 1.],\n       [ 1.],\n       [ 3.],\n       [ 4.],\n       [ 5.]])\nIn [372]: mask\nOut[372]: \narray([[False],\n       [ True],\n       [False],\n       [False],\n       [False]], dtype=bool)\nIn [373]: x2 = np.dot(y, x1)\nIn [374]: x2[mask] = np.nan\nIn [375]: x2\nOut[375]: \narray([[  1.],\n       [ nan],\n       [  3.],\n       [  4.],\n       [  5.]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "3d Matrix multiplication in numpy\r\n                \r\nI am using numpy to perform matrix multiplication, and I cannot figure out how to leverage numpy for 3d matrix multiplication.\nSay I have a 3x3 matrix, a, and I multiply it by a 3x1 vector, b. This will give a 3x1 vector, c.\nThis is done in numpy with:\n```\n# (3, 3) * (3, 1) -> (3, 1)\nc = np.matmul(a, b)\n```\n\nOk, so now I want to perform a similar operation on a 3d matrix that is essentially 2500 3x3 matrices. Right now I am doing something to the effect of:\n```\n# (2500, 3, 3) * (2500, 3, 1) -> list of (3, 1) vectors with length 2500\nC = [np.matmul(a, b) for a, b in zip(A, B)]\n```\n\nwhich returns a list of (3, 1) vectors.\nI would rather NOT loop and instead fully leverage numpy's vectorization and matrix/tensor products. Is there some operation so I can do...\n```\n# (2500, 3, 3) * (2500, 3, 1) -> (2500, 3, 1)\nnp.<function>(A, B, <args>)\n```\n\nI've seen stuff about using np.tensordot, but I don't know how to set axes.\n```\nnp.tensordot(A, B, axes=???)\n```\n\n    ", "Answer": "\r\nFor array of dimension 3 (or, a rank-3 tensor) that you have, you can use ```\nnp.einsum```\n doc for more complex matrix multiplications. In your particular case, you can use the following\n```\n>>> import numpy as np\n>>> x = np.random.randint(0, 3, (3, 3, 3))  # shape (3, 3, 3)\n>>> y = np.random.randint(0, 3, (3, 3, 3))  # shape (3, 3, 3)\n>>> np.einsum('ijk,ikl->ijl', x, y)  # still shape (3, 3, 3)\n```\n\nIn particular, the ```\neinsum```\n expression ```\n'ijk,ikl->ijl'```\n means for each ```\ni```\nth matrix, do a regular matrix multiplication ```\njk,kl->jl```\n and put the result in the ```\ni```\nth entry in the resulting tensor (ndarray). A more general form of this process could be\n```\nnp.einsum('...jk,...kl->...jl', x, y)\n```\n\nwhere you can have arbitrary number of dimensions in front of each tensor (ndarray) that you have.\nSee the following for a complete example:\n```\n>>> import numpy as np\n>>> x = np.random.randint(0, 3, (3, 3, 3))  # shape (3, 3, 3)\n>>> x\narray([[[0, 0, 1],\n        [2, 2, 1],\n        [2, 1, 1]],\n\n       [[2, 0, 2],\n        [2, 2, 1],\n        [2, 2, 2]],\n\n       [[2, 2, 2],\n        [1, 1, 2],\n        [0, 2, 2]]])\n>>> y = np.random.randint(0, 3, (3, 3, 3))  # shape (3, 3, 3)\n>>> y\narray([[[0, 0, 1],\n        [2, 1, 0],\n        [0, 0, 2]],\n\n       [[1, 2, 0],\n        [2, 0, 1],\n        [2, 2, 1]],\n\n       [[0, 2, 1],\n        [0, 1, 0],\n        [0, 2, 1]]])\n>>> np.einsum('ijk,ikl->ijl', x, y)\narray([[[ 0,  0,  2],\n        [ 4,  2,  4],\n        [ 2,  1,  4]],\n\n       [[ 6,  8,  2],\n        [ 8,  6,  3],\n        [10,  8,  4]],\n\n       [[ 0, 10,  4],\n        [ 0,  7,  3],\n        [ 0,  6,  2]]])\n>>> np.einsum('...ij,...jk->...ik', x, y)\narray([[[ 0,  0,  2],\n        [ 4,  2,  4],\n        [ 2,  1,  4]],\n\n       [[ 6,  8,  2],\n        [ 8,  6,  3],\n        [10,  8,  4]],\n\n       [[ 0, 10,  4],\n        [ 0,  7,  3],\n        [ 0,  6,  2]]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "java.lang.ArrayIndexOutOfBoundsException in matrix multiplication\r\n                \r\nI'm multiplying  ```\nMatrix1[10][2] * Matrix2[2][20]```\n but every time my class tries to multiplies , always throws me the same exception as the mentioned title. But when i put in rows less than the number in columns on matrix 1 and  columns less than  number on rows on matrix two, it performs the matrix multiplication without problem  this is my class for Multiplication \n\n```\npublic class MatrixCompute extends RecursiveAction \n{ \n\n    private CreateMatrix a,b;\n    private  CreateMatrix c;\n    private int row; \n\n\n    MatrixCompute(CreateMatrix a , CreateMatrix b ,CreateMatrix c )\n    {       \n        this(a , b ,c,-1);\n    }\n    MatrixCompute(CreateMatrix a, CreateMatrix b, CreateMatrix c, int row)\n    {\n            if (a.getCols() != b.getRow()) \n            {\n                throw new IllegalArgumentException(\"rows/columns mismatch\");\n            }\n            this.a = a;\n            this.b = b;\n            this.c = c;\n            this.row = row;\n    }   \n\n    @Override\n    public void compute() \n    {\n        if (row == -1)\n        {\n         List<MatrixCompute> tasks = new ArrayList<>();\n         for (int row = 0; row < a.getRow(); row++)\n         {\n                    tasks.add(new MatrixCompute(a, b, c, row));\n         }\n         invokeAll(tasks);\n       } \n       else\n       {\n          multiplyRowByColumn(a, b, c, row);\n       }\n    }\n\n        void multiplyRowByColumn(CreateMatrix a, CreateMatrix b, CreateMatrix c, int row) {\n             for (int j = 0; j < b.getCols(); j++) {\n                    for (int k = 0; k < a.getCols(); k++) {\n                        c.setValue(row, j, (int)(c.getValue(row, j) +  a.getValue(row, k)* b.getValue(k, j)));\n                    }\n                }\n        }\n\n}\n```\n\n\nand the class for wrapping a matrix: \n\n```\npublic class CreateMatrix \n{\n    private int[][] matrix; \n\n\n    public CreateMatrix (int row, int col )\n    {\n        matrix = new int[row][col]; \n    }\n\n    public void fillMatrix()\n    {\n        for(int i = 0; i < matrix.length; i++)\n        {\n            for(int j = 0; j < matrix[i].length ;j++ )\n            {\n                 Random r = new Random();\n                matrix[i][j] = r.nextInt() * 5;\n            }   \n        }\n\n    }\n\n\n\n    public int getCols()\n    {\n        return matrix[0].length;\n    }\n    public int getRow()\n    {\n       return matrix.length;\n    }\n\n\n     int getValue(int row, int col)\n     {\n            return matrix[row][col];\n     }\n\n    void setValue(int row, int col, int value)\n    {\n            matrix[row][col] = value;\n     }\n}\n```\n\n\nhere is the statment where the operation is being executed : \n\n```\n result = new CreateMatrix(row, col);\n                     ForkJoinPool pool = new ForkJoinPool();\n                     pool.invoke(new MatrixCompute(container[0], container[1], result));\n```\n\n\nand  here where the matrix are being decalred: \n\n```\nCreateMatrix matrix1 =  new CreateMatrix(Integer.parseInt(txtfil.getText()), Integer.parseInt(txtcol.getText()));\n                            container[0] = matrix1;\n                            container[0].fillMatrix();\n\n                            CreateMatrix matrix2 =  new CreateMatrix(Integer.parseInt(txrow.getText()), Integer.parseInt(txtcol2.getText()));\n                            container[1] = matrix2;\n```\n\n\nan finally the size of matrix result is declared by ```\ntxrow.getText()```\n and ```\ntxtcol.getText()```\n\n\nso since the only exception on multiplying matrix must be the columns on matrix one must be the same as row in Matrix2, so why is throwing me exception with greatest values in Matrix1's rows and Matrix2's colums   \n    ", "Answer": "\r\nFirst, a bit of Math. We know that An,m * Bm,p = Cn,p. Which means that for each cell in the row i column j in C, we have:\n\n\n\nSo to get C we have to:\n\n```\nint[][] matrixA = new int[n][m];\nint[][] matrixB = new int[m][p];\n\n//You could check if the matrixes above can multiply, by throwing an \n//exception if it does not.\n\nint[][] matrixC = new int[n][p];\n\nfor ( int i = 0 ; i < n ; i++ ) {\n    for ( int j = 0 ; j < p ; j++ ) {\n        for ( int k = 0 ; k < m ; k++ ) {\n            matrixC[i][j] += matrixA[i][k]*matrixB[k][j];\n        }\n    }\n}\n```\n\n\nEDIT: The reason your code throws an ArrayIndexOutOfBoundsException exception, it's because you are trying iterate beside the bounds of an array, which means you are trying to access, per example, in a Matrix1[10][2] you are trying to read the value on Matrix1[11][3], which it does not exist.\n\nYou code is a bit confusing, so I just put a bit of math to help you understand a better, cleaner and simpler way.\n\nI hope I have helped.\n\nHave a nice day.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication by loops\r\n                \r\nThis is the template and initialization of variables.\n```\n#include <stdio.h>\nint main()\n{\n    int k=0,m=0,l=0,s=0; \n    int a[k][m],a1[m][l],c[k][l];\n```\n\nInputting the matrix dimensions and entering the elements individually\n```\n//Inputting the matrices...\n\nprintf(\"Enter the dimension of first matrix (row and column)>> \\n\");\nscanf(\"%d%d\",&k,&m);\nprintf(\"Enter the dimension of second matrix (row and column)>> \\n\");\nscanf(\"%d%d\",&k,&m);\nprintf(\"First matrix elements are inputted from below >> \\n\");\nfor (int i = 0; i < k ; i++)\n{\n    for (int j = 0; j < m; j++)\n    {\n        printf(\"a[%d][%d]>> \",i,j);\n        scanf(\"%d\",&a[i][j]);\n    }\n    printf(\"\\n\");\n}\n```\n\nInputting the second matrix\n```\nprintf(\"Second matrix elements are inputted from below >> \\n\");\nfor (int i = 0; i < m ; i++)\n{\n    for (int j = 0; j < l; j++)\n    {\n        printf(\"a[%d][%d]>> \",i,j);\n        scanf(\"%d\",&a[i][j]);\n    }\n    printf(\"\\n\");\n}\n```\n\nHere's the logic for matrix multiplication\n```\n//Logic for the matrix multiplication\n\nfor (int i = 0; i < k; i++)\n{\n    for (int j = 0; j < l; j++)\n    {\n        s=0;\n        for (int jj = 0; jj < m; jj++)\n        {\n            s+=a[i][jj]*a1[jj][j];\n        }\n        c[i][j]=s;\n    }\n}\n```\n\nPrinting the multiplied matrix\n```\n//for outputting the matrix\n                                                \nfor (int i = 0; i < k ; i++)\n{\n    for (int j = 0; j < l; j++)\n    {\n        printf(\"a[%d][%d] = %d\",k,l,c[k][l]);\n        \n    }\n    printf(\"\\n\");\n}\nreturn 0;\n```\n\nRespected experienced coders please help me out in this one. I am stuck for a while now.\nI inputted two matrices of order [k][m] and [m][l]. I then multiplied them by this logic.\nAnd then I simply printed the final matrix c[k][l] by some nested loops.\nPlease kindly help me.\nThe output of the following code in an online compiler\nEnter the dimension of first matrix (row and column)>>\n2 2\nEnter the dimension of second matrix (row and column)>>\n2 2\nFirst matrix elements are inputted from below >>\na[0][0]>> 2\na0>> 2\na[1][0]>> 2\na1>> 2\nSecond matrix elements are inputted from below >>\nonlinegdb compiler\n    ", "Answer": "\r\nThere are multiple problems:\n\nThe matrix arrays must be defined after the values of their dimensions have been read. As posted, the behavior is undefined because the dimensions are ```\n0```\n.\n\nthe dimensions of the second matrix are input with ```\nscanf(\"%d%d\", &k, &m);```\n into ```\nk```\n and ```\nm```\n instead of ```\nm```\n and ```\nl```\n.  The first dimension should actually be either assumed to be the same as the second dimension of the first matrix or checked.\n\nthe input loop for the second matrix stores the values into ```\na```\n instead of ```\na1```\n: a typical cut and paste bug.\n\nThe printing statement ```\nprintf(\"a[%d][%d] = %d\",k,l,c[k][l]);```\n is incorrect: the index variables are ```\ni```\n and ```\nj```\n, so the statement should be:\n```\n  printf(\"a[%d][%d] = %d\\n\", i, j, c[i][j]);\n```\n\n\n\nHere is a modified version:\n```\n#include <stdio.h>\n\nint main() {\n    int k, m, m1, l; \n\n    //Inputting the matrices...\n    printf(\"Enter the dimensions of first matrix (rows and columns)>> \\n\");\n    if (scanf(\"%d%d\", &k, &m) != 2)\n        return 1;\n    printf(\"Enter the dimensions of second matrix (rows and columns)>> \\n\");\n    if (scanf(\"%d%d\", &m1, &l) != 2)\n        return 1;\n\n    if (k <= 0 || m <= 0 || m != m1 || l <= 0) {\n        printf(\"incompatible dimensions\\n\";\n        return 1;\n    }\n    int a[k][m], a1[m][l], c[k][l];\n\n    printf(\"First matrix elements are inputted from below >> \\n\");\n    for (int i = 0; i < k; i++) {\n        for (int j = 0; j < m; j++) {\n            printf(\"a[%d][%d]>> \", i, j);\n            if (scanf(\"%d\", &a[i][j]) != 1)\n                return 1;\n        }\n        printf(\"\\n\");\n    }\n\n    printf(\"Second matrix elements are inputted from below >> \\n\");\n    for (int i = 0; i < m; i++) {\n        for (int j = 0; j < l; j++) {\n            printf(\"a1[%d][%d]>> \", i, j);\n            if (scanf(\"%d\", &a1[i][j]) != 1)\n                return 1;\n        }\n        printf(\"\\n\");\n    }\n\n    //Logic for the matrix multiplication\n    for (int i = 0; i < k; i++) {\n        for (int j = 0; j < l; j++) {\n            int s = 0;\n            for (int jj = 0; jj < m; jj++) {\n                s += a[i][jj] * a1[jj][j];\n            }\n            c[i][j] = s;\n        }\n    }\n\n    //for outputting the matrix\n    for (int i = 0; i < k; i++) {\n        for (int j = 0; j < l; j++) {\n            printf(\" %d\", c[i][j]);\n        }\n        printf(\"\\n\");\n    }\n    return 0;\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Dense vector on sparse matrix multiplication in tensorflow\r\n                \r\nWhat is proper way of dense vector on sparse matrix multiplication in tensorflow?\n\nAccording to documentation tf.matmul support sparse matrix multiplication, so do I need to use tf.sparse_matmul? (And also tf.sparse_tensor_dense_matmul exist, so in which cases each of them should be used?)\n\nAlso do I need to convert my sparse matrix to tf.SparseTensor ? Also it not obvious what tf.convert_to_tensor_or_sparse_tensor is doing and how to convert dense numpy matrix or scipy sparse matrix for tensorflow suitable input.\n\nHere what I have tried(timing are for CPU):\n\n```\nimport numpy as np\nimport tensorflow as tf\n\nnp.random.seed(2018)\n\n# Parameters\nn = 10*1000\nm = 4*1000\np = 0.1\n\n%%time\n\n# Data preparation\ndense_vector = np.random.rand(1,n).astype(np.float32)\nprint('dense_vector.shape', dense_vector.shape)\n#print('dense_vector:')\n#print(dense_vector)\n\ndense_matrix = np.random.rand(n*m)\nidx = np.random.choice(range(n*m), int((1.0-p)*n*m), replace=False)\ndense_matrix[idx] = 0.0\ndense_matrix = dense_matrix.reshape(n,m).astype(np.float32)\nprint('dense_matrix.shape', dense_matrix.shape)\n#print('dense_matrix:')\n#print(dense_matrix)\n\ndense_vector.shape (1, 10000)\ndense_matrix.shape (10000, 4000)\nCPU times: user 9.8 s, sys: 2.38 s, total: 12.2 s\nWall time: 12.2 s\n\n%%time\n\n# Dense vector on dense matrix multiplication using numpy\n\nres = dense_vector @ dense_matrix\nprint('res.shape', res.shape)\n#print('res:')\n#print(res)\n\n%%time\n\n# Dense vector on dense matrix multiplication using tensorflow tf.matmul V1\n\ndense_vector_tf = tf.convert_to_tensor(dense_vector, np.float32)\ndense_matrix_tf = tf.convert_to_tensor(dense_matrix, np.float32)\nres_tf = tf.matmul(dense_vector_tf, dense_matrix_tf)\n\nwith tf.Session() as sess:\n    res = sess.run(res_tf)\n    print('res.shape', res.shape)\n    #print('res:')\n    #print(res)\n\nres.shape (1, 4000)\nCPU times: user 1.88 s, sys: 1.82 s, total: 3.7 s\nWall time: 3.54 s\n\n%%time\n\n# Dense vector on dense matrix multiplication using tensorflow tf.matmul V2\n\ndense_vector_tf = tf.convert_to_tensor(dense_vector, np.float32)\ndense_matrix_tf = tf.convert_to_tensor(dense_matrix, np.float32)\nres_tf = tf.matmul(dense_vector_tf, dense_matrix_tf,\n                   a_is_sparse=False,\n                   b_is_sparse=True)\n\nwith tf.Session() as sess:\n    res = sess.run(res_tf)\n    print('res.shape', res.shape)\n    #print('res:')\n    #print(res)\n\nres.shape (1, 4000)\nCPU times: user 4.91 s, sys: 4.28 s, total: 9.19 s\nWall time: 9.07 s\n\n%%time\n\n# Dense vector on sparse matrix multiplication using tensorflow tf.sparse_matmul V1\n\ndense_vector_tf = tf.convert_to_tensor(dense_vector, np.float32)\ndense_matrix_tf = tf.convert_to_tensor(dense_matrix, np.float32)\nres_tf = tf.sparse_matmul(dense_vector_tf, dense_matrix_tf,\n                         a_is_sparse=False,\n                         b_is_sparse=True)\n\nwith tf.Session() as sess:\n    res = sess.run(res_tf)\n    print('res.shape', res.shape)\n    #print('res:')\n    #print(res)\n\nres.shape (1, 4000)\nCPU times: user 4.82 s, sys: 4.18 s, total: 8.99 s\nWall time: 9 s\n\n%%time\n\n# Dense vector on sparse matrix multiplication using tensorflow tf.sparse_matmul V2\n\ndense_vector_tf = tf.convert_to_tensor(dense_vector, np.float32)\ndense_matrix_tf = tf.convert_to_tensor_or_sparse_tensor(dense_matrix, np.float32)\nres_tf = tf.sparse_matmul(dense_vector_tf, dense_matrix_tf,\n                         a_is_sparse=False,\n                         b_is_sparse=True)\n\nwith tf.Session() as sess:\n    res = sess.run(res_tf)\n    print('res.shape', res.shape)\n    #print('res:')\n    #print(res)\n\nres.shape (1, 4000)\nCPU times: user 5.07 s, sys: 4.53 s, total: 9.6 s\nWall time: 9.61 s\n```\n\n\nAlso I can't see any improvement using sparse matrices, what I'm doing wrong?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Numpy array and matrix multiplication\r\n                \r\nI am trying to get rid of the for loop and instead do an array-matrix multiplication to decrease the processing time when the ```\nweights```\n array is very large:\n\n\n```\nimport numpy as np\nsequence = [np.random.random(10), np.random.random(10), np.random.random(10)]\n\nweights = np.array([[0.1,0.3,0.6],[0.5,0.2,0.3],[0.1,0.8,0.1]])\nCov_matrix = np.matrix(np.cov(sequence))\nresults = []\nfor w in weights:\n    result = np.matrix(w)*Cov_matrix*np.matrix(w).T\n    results.append(result.A)\n```\n\n\nWhere: \n\n```\nCov_matrix```\n is a ```\n3x3```\n matrix \n```\nweights```\n is an array of ```\nn```\n lenght with ```\nn```\n ```\n1x3```\n matrices in it.\n\nIs there a way to multiply/map ```\nweights```\n to ```\nCov_matrix```\n and bypass the for loop? I am not very familiar with all the numpy functions.\n    ", "Answer": "\r\nI'd like to reiterate what's already been said in another answer: the ```\nnp.matrix```\n class has much more disadvantages than advantages these days, and I suggest moving to the use of the ```\nnp.array```\n class alone. Matrix multiplication of arrays can be easily written using the ```\n@```\n operator, so the notation is in most cases as elegant as for the ```\nmatrix```\n class (and arrays don't have several restrictions that matrices do).\n\nWith that out of the way, what you need can be done in terms of a call to ```\nnp.einsum```\n. We need to contract certain indices of three matrices while keeping one index alone in two matrices. That is, we want to perform ```\nw_{ij} * Cov_{jk} * w.T_{ki}```\n with a summation over ```\nj```\n, ```\nk```\n, giving us an array with ```\ni```\n indices. The following call to ```\neinsum```\n will do:\n\n```\nres = np.einsum('ij,jk,ik->i', weights, Cov_matrix, weights)\n```\n\n\nNote that the above will give you a single 1d array, whereas you originally had a list of arrays with shape ```\n(1,1)```\n. I suspect the above result will even make more sense. Also, note that I omitted the transpose in the second ```\nweights```\n argument, and this is why the corresponding summation indices appear as ```\nik```\n rather than ```\nki```\n. This should be marginally faster.\n\nTo prove that the above gives the same result:\n\n```\nIn [8]: results # original\nOut[8]: [array([[0.02803215]]), array([[0.02280609]]), array([[0.0318784]])]\n\nIn [9]: res # einsum\nOut[9]: array([0.02803215, 0.02280609, 0.0318784 ])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to get faster code than numpy.dot for matrix multiplication?\r\n                \r\nHere Matrix multiplication using hdf5 I use hdf5 (pytables) for big matrix multiplication, but I was suprised because using hdf5 it works even faster then using plain numpy.dot and store matrices in RAM, what is the reason of this behavior?\n\nAnd maybe there is some faster function for matrix multiplication in python, because I still use numpy.dot for small block matrix multiplication.\n\nhere is some code:\n\nAssume matrices can fit in RAM: test on matrix 10*1000 x 1000.\n\nUsing default numpy(I think no BLAS lib).\nPlain numpy arrays are in RAM: time 9.48\n\nIf A,B in RAM, C on disk: time 1.48\n\nIf A,B,C on disk: time 372.25\n\nIf I use numpy with MKL results are: 0.15,0.45,43.5.\n\nResults looks reasonable, but I still don't understand why in 1st case block multiplication is faster(when we store A,B in RAM).\n\n```\nn_row=1000\nn_col=1000\nn_batch=10\n\ndef test_plain_numpy():\n    A=np.random.rand(n_row,n_col)# float by default?\n    B=np.random.rand(n_col,n_row)\n    t0= time.time()\n    res= np.dot(A,B)\n    print (time.time()-t0)\n\n#A,B in RAM, C on disk\ndef test_hdf5_ram():\n    rows = n_row\n    cols = n_col\n    batches = n_batch\n\n    #using numpy array\n    A=np.random.rand(n_row,n_col)\n    B=np.random.rand(n_col,n_row)\n\n    #settings for all hdf5 files\n    atom = tables.Float32Atom() #if store uint8 less memory?\n    filters = tables.Filters(complevel=9, complib='blosc') # tune parameters\n    Nchunk = 128  # ?\n    chunkshape = (Nchunk, Nchunk)\n    chunk_multiple = 1\n    block_size = chunk_multiple * Nchunk\n\n    #using hdf5\n    fileName_C = 'CArray_C.h5'\n    shape = (A.shape[0], B.shape[1])\n\n    h5f_C = tables.open_file(fileName_C, 'w')\n    C = h5f_C.create_carray(h5f_C.root, 'CArray', atom, shape, chunkshape=chunkshape, filters=filters)\n\n    sz= block_size\n\n    t0= time.time()\n    for i in range(0, A.shape[0], sz):\n        for j in range(0, B.shape[1], sz):\n            for k in range(0, A.shape[1], sz):\n                C[i:i+sz,j:j+sz] += np.dot(A[i:i+sz,k:k+sz],B[k:k+sz,j:j+sz])\n    print (time.time()-t0)\n\n    h5f_C.close()\ndef test_hdf5_disk():\n    rows = n_row\n    cols = n_col\n    batches = n_batch\n\n    #settings for all hdf5 files\n    atom = tables.Float32Atom() #if store uint8 less memory?\n    filters = tables.Filters(complevel=9, complib='blosc') # tune parameters\n    Nchunk = 128  # ?\n    chunkshape = (Nchunk, Nchunk)\n    chunk_multiple = 1\n    block_size = chunk_multiple * Nchunk\n\n\n    fileName_A = 'carray_A.h5'\n    shape_A = (n_row*n_batch, n_col)  # predefined size\n\n    h5f_A = tables.open_file(fileName_A, 'w')\n    A = h5f_A.create_carray(h5f_A.root, 'CArray', atom, shape_A, chunkshape=chunkshape, filters=filters)\n\n    for i in range(batches):\n        data = np.random.rand(n_row, n_col)\n        A[i*n_row:(i+1)*n_row]= data[:]\n\n    rows = n_col\n    cols = n_row\n    batches = n_batch\n\n    fileName_B = 'carray_B.h5'\n    shape_B = (rows, cols*batches)  # predefined size\n\n    h5f_B = tables.open_file(fileName_B, 'w')\n    B = h5f_B.create_carray(h5f_B.root, 'CArray', atom, shape_B, chunkshape=chunkshape, filters=filters)\n\n    sz= rows/batches\n    for i in range(batches):\n        data = np.random.rand(sz, cols*batches)\n        B[i*sz:(i+1)*sz]= data[:]\n\n\n    fileName_C = 'CArray_C.h5'\n    shape = (A.shape[0], B.shape[1])\n\n    h5f_C = tables.open_file(fileName_C, 'w')\n    C = h5f_C.create_carray(h5f_C.root, 'CArray', atom, shape, chunkshape=chunkshape, filters=filters)\n\n    sz= block_size\n\n    t0= time.time()\n    for i in range(0, A.shape[0], sz):\n        for j in range(0, B.shape[1], sz):\n            for k in range(0, A.shape[1], sz):\n                C[i:i+sz,j:j+sz] += np.dot(A[i:i+sz,k:k+sz],B[k:k+sz,j:j+sz])\n    print (time.time()-t0)\n\n    h5f_A.close()\n    h5f_B.close()\n    h5f_C.close()\n```\n\n    ", "Answer": "\r\n```\nnp.dot```\n dispatches to BLAS when\n\n\nNumPy has been compiled to use BLAS,\na BLAS implementation is available at run-time,\nyour data has one of the dtypes ```\nfloat32```\n, ```\nfloat64```\n, ```\ncomplex32```\n or ```\ncomplex64```\n, and\nthe data is suitably aligned in memory.\n\n\nOtherwise, it defaults to using its own, slow, matrix multiplication routine.\n\nChecking your BLAS linkage is described here. In short, check whether there's a file ```\n_dotblas.so```\n or similar in your NumPy installation. When there is, check which BLAS library it's linked against; the reference BLAS is slow, ATLAS is fast, OpenBLAS and vendor-specific versions such as Intel MKL are even faster. Watch out with multithreaded BLAS implementations as they don't play nicely with Python's ```\nmultiprocessing```\n.\n\nNext, check your data alignment by inspecting the ```\nflags```\n of your arrays. In versions of NumPy before 1.7.2, both arguments to ```\nnp.dot```\n should be C-ordered. In NumPy >= 1.7.2, this doesn't matter as much anymore as special cases for Fortran arrays have been introduced.\n\n```\n>>> X = np.random.randn(10, 4)\n>>> Y = np.random.randn(7, 4).T\n>>> X.flags\n  C_CONTIGUOUS : True\n  F_CONTIGUOUS : False\n  OWNDATA : True\n  WRITEABLE : True\n  ALIGNED : True\n  UPDATEIFCOPY : False\n>>> Y.flags\n  C_CONTIGUOUS : False\n  F_CONTIGUOUS : True\n  OWNDATA : False\n  WRITEABLE : True\n  ALIGNED : True\n  UPDATEIFCOPY : False\n```\n\n\nIf your NumPy is not linked against BLAS, either (easy) re-install it, or (hard) use the BLAS ```\ngemm```\n (generalized matrix multiply) function from SciPy:\n\n```\n>>> from scipy.linalg import get_blas_funcs\n>>> gemm = get_blas_funcs(\"gemm\", [X, Y])\n>>> np.all(gemm(1, X, Y) == np.dot(X, Y))\nTrue\n```\n\n\nThis looks easy, but it does hardly any error checking, so you must really know what you're doing.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication for sparse matrices in Python\r\n                \r\nI want to multiply a sparse matrix A, with a matrix B which has 0, -1, or 1 as elements. To reduce the complexity of the matrix multiplication, I can ignore items if they are 0, or go ahead and add the column without multiplication if the item is 1, or subs. if it's -1. The discussion about this is here:\n\nRandom projection algorithm pseudo code\n\nNow I can go ahead and implement this trick but I wonder if I use Numpy's multiplication functions it'll be faster.\n\nDoes anyone knows if they optimised matrix multiplication for such matrices? Or can you suggest something to speed this process up since I have a matrix 300000x1000.\n    ", "Answer": "\r\nHave you looked at ```\nscipy.sparse```\n?  There's no point in re-inventing the wheel, here.  Sparse matricies are a fairly standard thing.  \n\n(In the example, I'm using a ```\n300000x4```\n matrix for easier printing after the multiplication. A ```\n300000x1000```\n matrix shouldn't be any problem, though.  This will be much faster than multiplying two dense arrays, assuming you have a majority of ```\n0```\n elements.)\n\n```\nimport scipy.sparse\nimport numpy as np\n\n# Make the result reproducible...\nnp.random.seed(1977)\n\ndef generate_random_sparse_array(nrows, ncols, numdense):\n    \"\"\"Generate a random sparse array with -1 or 1 in the non-zero portions\"\"\"\n    i = np.random.randint(0, nrows-1, numdense)\n    j = np.random.randint(0, ncols-1, numdense)\n    data = np.random.random(numdense)\n    data[data <= 0.5] = -1\n    data[data > 0.5] = 1\n    ij = np.vstack((i,j))\n    return scipy.sparse.coo_matrix((data, ij), shape=(nrows, ncols))\n\nA = generate_random_sparse_array(4, 300000, 1000)\nB = generate_random_sparse_array(300000, 5, 1000)\n\nC = A * B\n\nprint C.todense()\n```\n\n\nThis yields:\n\n```\n[[ 0.  1.  0.  0.  0.]\n [ 0.  2. -1.  0.  0.]\n [ 1. -1.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.]]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "OpenCV Mats of Type Float and Matrix Multiplication\r\n                \r\nIn OpenCV, why are the types for matrix multiplication (gemm, not mul) restricted to floats (CV_32FC1, CV_64FC1, etc.)? Are there other ways to perform matrix multiplication with other types in OpenCV?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "4D matrix multiplication\r\n                \r\nI have been failing to find a good way to write the below for loops using numpy. The way it is written right now is of course very inefficient and is just unfeasible for my real data (shape 512*8*8*512) but I am just failing to effectively use the built in matrix multiplication functions.\n\n```\nimport numpy as np\n#Create pseudo weights, biases, input\nweights = np.random.rand(10, 8, 8, 10)\nbiases = np.random.rand(10)\npseudo_input = np.random.rand(10, 8, 8)\noutput_loops = np.zeros((weights.shape[0],))\n\nfor n in range(10):\n    output_loops[n] += biases[n]\n    for x in range(8):\n        for y in range(8):\n            for f in range(10):\n                output_loops[n] += weights[f, x, y, n] * pseudo_input[f,x,y]\n```\n\n    ", "Answer": "\r\nSimply port the relevant iterators into the ```\neinsum```\n string notation in ```\nnp.einsum```\n -\n\n```\nnp.einsum('fxyn,fxy->n', weights, pseudo_input) + biases\n```\n\n\nWe can also use ```\nnp.tensordot```\n -\n\n```\nnp.tensordot(weights, pseudo_input, axes=((0,1,2),(0,1,2))) + biases\n```\n\n\nUsing the trusty ```\nnp.dot```\n with some additional reshaping to bring the shapes to ```\n2D```\n and ```\n1D```\n -\n\n```\npseudo_input.ravel().dot(weights.reshape(-1,weights.shape[-1])) + biases\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Blocked Matrix Multiplication\r\n                \r\nI am trying to create a function that performs blocked matrix multiplication in AllegroCL, but I keep getting array-index errors. I believe it is due to the indicies being 0-19 for a side of a 20 x 20 block matrix, but I'm unsure of how to fix it. \n\nError: Array index 20 too big for dimension 20 while accessing\n       #.\n[condition type: type-error]\n\nAny help or direction is much appreciated. Below is my code thus far.\n\n```\n(defun bmmul (A B)\n  (let* ((m (car (array-dimensions A)))\n         (n (cadr (array-dimensions A)))\n         (l (cadr (array-dimensions B)))\n         (u 0)\n         (C (make-array `(,m ,l) :initial-element 0)))\n    (loop for p from 0 to (- m n) do\n          (loop for i from (+ 0 1) to n do\n                (setf u (aref C i 0))\n                (loop for k from p to (- (+ p n) 1) do\n                      (setf u (* (aref A i k) (aref B k 0))))\n                (setf (aref C i 0) u)))\n    C))\n```\n\n    ", "Answer": "\r\nIn general, when looping over an array index, you go ```\n:from 0 :below n```\n, where ```\nn```\n is the array dimension, so when the dimension is 20, the index goes from 0 up to and including 19.\n\nAnother problem seems to be that in the innermost loop, you want to ```\nincf```\n, not ```\nsetf```\n.  You also do not need a temporary variable (```\nu```\n) there, just ```\nincf```\n the array cell directly.\n\nFinally, I do not feel that you structured your loops correctly, I do not expect to see a hardcoded ```\n0```\n index there.  The innermost loop body should look like ```\n(incf (aref c i j) (* (aref a i k) (aref b k j)))```\n, regardless of whether you do ordinary or blocked multiplication.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Program with threads for matrix multiplication\r\n                \r\nI'm trying to create a Java program with threads for matrix multiplication. This is the source code:\n```\nimport java.util.Random;\n\npublic class MatrixTest {\n    //Creating the matrix\n    static int[][] mat = new int[3][3];\n    static int[][] mat2 = new int[3][3];\n    static int[][] result = new int[3][3];\n\n    public static void main(String[] args) {\n        //Creating the object of random class\n        Random rand = new Random();\n\n        //Filling first matrix with random values\n        for (int i = 0; i < mat.length; i++) {\n            for (int j = 0; j < mat[i].length; j++) {\n                mat[i][j] = rand.nextInt(10);\n            }\n        }\n\n        //Filling second matrix with random values\n        for (int i = 0; i < mat2.length; i++) {\n            for (int j = 0; j < mat2[i].length; j++) {\n                mat2[i][j] = rand.nextInt(10);\n            }\n        }\n\n        try {\n            //Object of multiply Class\n            Multiply multiply = new Multiply(3, 3);\n\n            //Threads\n            MatrixMultiplier thread1 = new MatrixMultiplier(multiply);\n            MatrixMultiplier thread2 = new MatrixMultiplier(multiply);\n            MatrixMultiplier thread3 = new MatrixMultiplier(multiply);\n\n            //Implementing threads\n            Thread th1 = new Thread(thread1);\n            Thread th2 = new Thread(thread2);\n            Thread th3 = new Thread(thread3);\n\n            //Starting threads\n            th1.start();\n            th2.start();\n            th3.start();\n\n            th1.join();\n            th2.join();\n            th3.join();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n\n        //Printing the result\n        System.out.println(\"\\n\\nResult:\");\n        for (int i = 0; i < result.length; i++) {\n            for (int j = 0; j < result[i].length; j++) {\n                System.out.print(result[i][j] + \" \");\n            }\n            System.out.println();\n        }\n    }//End main\n}//End Class\n\n//Multiply Class\nclass Multiply extends MatrixTest {\n    private int i;\n    private int j;\n    private int chance;\n\n    public Multiply(int i, int j) {\n        this.i = i;\n        this.j = j;\n        chance = 0;\n    }\n\n    //Matrix Multiplication Function\n    public synchronized void multiplyMatrix() {\n        int sum = 0;\n        int a = 0;\n        for (a = 0; a < i; a++) {\n            sum = 0;\n            for (int b = 0; b < j; b++) {\n                sum = sum + mat[chance][b] * mat2[b][a];\n            }\n            result[chance][a] = sum;\n        }\n\n        if (chance >= i)\n            return;\n        chance++;\n    }\n}//End multiply class\n\n//Thread Class\nclass MatrixMultiplier implements Runnable {\n    private final Multiply mul;\n\n    public MatrixMultiplier(Multiply mul) {\n        this.mul = mul;\n    }\n\n    @Override\n    public void run() {\n        mul.multiplyMatrix();\n    }\n}\n```\n\nI just tried on Eclipse and it works, but now I want to create another version of that program in which, I use one thread for each cell that I'll have on the result matrix. For example I've got two 3x3 matrices. So the result matrix will be 3x3. Then, I want to use 9 threads to calculate each one of the 9 cells of the result matrix.\nCan anyone help me?\n    ", "Answer": "\r\nYou can create ```\nn```\n Threads as follows (Note: ```\nnumberOfThreads```\n is the number of threads that you want to create. This will be the number of cells):\n\n```\nList<Thread> threads = new ArrayList<>(numberOfThreads);\n\nfor (int x = 0; x < numberOfThreads; x++) {\n   Thread t = new Thread(new MatrixMultiplier(multiply));\n   t.start();\n   threads.add(t);\n}\n\nfor (Thread t : threads) {\n   t.join();\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Subtract like Matrix Multiplication in tensorflow\r\n                \r\nThis is my first post I usually found all my answers in the archives, but having a hard time with this one, thanks for the help!\n\nI have two matrix A and B.  Performing a matrix multiplication operation is trivial using tf.matmult.  But I want to do matrix subtract similar to how matrix multiplication works. Eg if I have.\n\n```\nA = tf.constant([[1, 1, 1, 2, 3, 1],[1,2,3,4,5,6],[4,3,2,1,6,5]])\nB = tf.constant([[1,3,1],[2,1,1]])\n\n#B*A\nX = tf.matmult(B,A)\n>>>X = [[8,10,12,15,24,24],[7,7,7,9,17,13]]\n```\n\n\nWhat I want to do is do a similar operation like matmult, but instead of multiply I want subtract and square. Eg...\n\nfor x11, where the subscript 11 is row 1, column 1 of matrix X.\n\n= (-b11 + a11)2 + (-b12 + a21)2 + (-b13 + a31)2\n\nand\n\nx12 = (-b11 + a12)2 + (-b12 + a22)2 + (-b13 + a32)2\n\nand so on similar to how matrix multiplication works.  \n\nSo if we take matrix A and B above and perform the operation described above (call it matmultsubtract), we get,\n\ntf.matmultsubtract(B,A) gives:\n\n[[(-1+1)2+(-3+1)2+(-1+4)2, (-1+1)2+(-3+2)2+(-1+3)2,...],\n\n[(-2+1)2+(-1+1)2+(-1+4)2, (-2+1)2+(-1+2)2+(-1+3)2, ...]]\n\nThis isn't that hard if working with numpy arrays (you can use two nested for loops) by iterating manually rather than np.matmult, but tensorflow has a problem with for loops and I'm not sure how to do it.\n\nThanks for the help.\n    ", "Answer": "\r\nTrying a vectorization operation that may not be taken as matrix subtract.\n\n```\n# shape=(2,3,6)\nB_new = tf.tile(tf.expand_dims(B,axis=-1),multiples=[1,1,A.shape[1]])\n# shape=(2,3,6)\nA_new = tf.tile(tf.expand_dims(A,axis=0),multiples=[B.shape[0],1,1])\n# shape=(2,6)\nresult = tf.reduce_sum(tf.square(A_new - B_new),axis=1)\nwith tf.Session() as sess:\n    print(sess.run(result))\n\n[[13  5  1  2 33 25]\n [10  6  6  9 42 42]]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Rowwise matrix multiplication in R\r\n                \r\nI have a matrix with the dimension of 100 million records and 100 columns.\n\nNow I want to multiply that matrix by rowwise.\n\nMy sample code for matrix multiplication is\n\n```\ndf<-as.matrix(mtcars)\nresult<-apply(df,1,prod)\n```\n\n\nThe above syntax is very slow in my case.\n\nI tried rowprods function in Rfast package.\n\n```\nresult<-rowprods(mtcars)\n```\n\n\nBut the above function giving me space issues.\n\nNOTE: I have 8 GB ram in my system.\n    ", "Answer": "\r\nIf you have a matrix that is too large to fit in memory, you can use package bigstatsr (disclaimer: I'm the author) to use data stored on your disk (instead of the RAM). Using function ```\nbig_apply```\n enables you to apply standard R functions on data blocks (and to combine them).\n\n```\nlibrary(bigstatsr)\nfbm <- FBM(10e6, 100)\n# inialize with random numbers\nsystem.time(\n  big_apply(fbm, a.FUN = function(X, ind) {\n    print(min(ind))\n    X[, ind] <- rnorm(nrow(X) * length(ind))\n    NULL\n  }, a.combine = 'c')\n) # 78 sec\n\n# compute row prods, possibly in parallel\nsystem.time(\n  prods <- big_apply(fbm, a.FUN = function(X, ind) {\n    print(min(ind))\n    matrixStats::rowProds(X[ind, ])\n  }, a.combine = 'c', ind = rows_along(fbm),\n  block.size = 100e3, ncores = nb_cores())  \n) # 22 sec with 1 core and 18 sec with 6 cores\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Subtract like Matrix Multiplication in tensorflow\r\n                \r\nThis is my first post I usually found all my answers in the archives, but having a hard time with this one, thanks for the help!\n\nI have two matrix A and B.  Performing a matrix multiplication operation is trivial using tf.matmult.  But I want to do matrix subtract similar to how matrix multiplication works. Eg if I have.\n\n```\nA = tf.constant([[1, 1, 1, 2, 3, 1],[1,2,3,4,5,6],[4,3,2,1,6,5]])\nB = tf.constant([[1,3,1],[2,1,1]])\n\n#B*A\nX = tf.matmult(B,A)\n>>>X = [[8,10,12,15,24,24],[7,7,7,9,17,13]]\n```\n\n\nWhat I want to do is do a similar operation like matmult, but instead of multiply I want subtract and square. Eg...\n\nfor x11, where the subscript 11 is row 1, column 1 of matrix X.\n\n= (-b11 + a11)2 + (-b12 + a21)2 + (-b13 + a31)2\n\nand\n\nx12 = (-b11 + a12)2 + (-b12 + a22)2 + (-b13 + a32)2\n\nand so on similar to how matrix multiplication works.  \n\nSo if we take matrix A and B above and perform the operation described above (call it matmultsubtract), we get,\n\ntf.matmultsubtract(B,A) gives:\n\n[[(-1+1)2+(-3+1)2+(-1+4)2, (-1+1)2+(-3+2)2+(-1+3)2,...],\n\n[(-2+1)2+(-1+1)2+(-1+4)2, (-2+1)2+(-1+2)2+(-1+3)2, ...]]\n\nThis isn't that hard if working with numpy arrays (you can use two nested for loops) by iterating manually rather than np.matmult, but tensorflow has a problem with for loops and I'm not sure how to do it.\n\nThanks for the help.\n    ", "Answer": "\r\nTrying a vectorization operation that may not be taken as matrix subtract.\n\n```\n# shape=(2,3,6)\nB_new = tf.tile(tf.expand_dims(B,axis=-1),multiples=[1,1,A.shape[1]])\n# shape=(2,3,6)\nA_new = tf.tile(tf.expand_dims(A,axis=0),multiples=[B.shape[0],1,1])\n# shape=(2,6)\nresult = tf.reduce_sum(tf.square(A_new - B_new),axis=1)\nwith tf.Session() as sess:\n    print(sess.run(result))\n\n[[13  5  1  2 33 25]\n [10  6  6  9 42 42]]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Ocaml matrix multiplication [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs debugging details. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     Edit the question to include desired behavior, a specific problem or error, and the shortest code necessary to reproduce the problem. This will help others answer the question.\r\n                \r\n                    \r\n                        Closed 2 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nhello i am trying to learn ocaml by myself and i am implementing matrix multiplication of list of lists, but i have no clue on how to do it. i am trying to do it without any list functions but it seems like most solutions i have come across use list.map.\nthis is how i implemented add\n```\n\n  let rec m_row r1 r2 =\n    match r1,r2 with\n      _ -> [] \n    | r1s :: r1',  r2s :: r2' -> r1s + r2s :: m_row r1' r2'\n                   \n\n  let rec m_add x y =\n    match x,y with\n     _ -> []\n    | xs :: x', ys :: y' -> m_row xs ys :: m_add x' y'\n    \n```\n\n    ", "Answer": "\r\nYou have to split your task into small subtasks and then combine them to get the final program. But before starting coding we have to understand the problem. We represent a matrix as a collection of rows, e.g., a matrix with M rows and N columns is represented as,\n```\n[[a11; ...; a1N];\n [a21; ...; a2N];\n       ...\n [aM1; ...; aMN]]\n```\n\nGiven some PxQ matrix B,\n```\n[[b11; ...; b1Q];\n [b21; ...; b2Q];\n       ...\n [bP1; ...; bPQ]]\n```\n\nwe would like to form an MxQ matrix C that is the multiplication of matrices A and B,\n```\n[[c11; ...; c1Q];\n [c21; ...; c2Q];\n       ...\n [cM1; ...; cMQ]]\n```\n\nwhere each element cIJ of the matrix is a cartesian product of row I of the matrix A and column J of the matrix B.\nWe can conclude that we will need the following primitives to solve our task.\n\n```\nval transpose : matrix -> matrix```\n the function that will take a list of rows and return a list of columns of that matrix. We will need this because we need to iterate over columns of matrix B.\n\n```\nval product : vector -> vector -> scalar```\n that we will use to take a row of matrix A and a column of matrix B to obtain an element of matrix C. The product of ```\n[x1; ...; xS]```\n and ```\n[y1; ...; yS]```\n is a scalar equal to ```\nx1 * y1 + ... + xS * yS```\n\n\n\nNote that I introduce type aliases here, e.g., we can define them as\n```\ntype scalar = int\ntype vector = scalar list\ntype matrix = vector list\n```\n\nNow we are getting close to the final matrix multiplication procedure. To get a row of the matrix C, we need to iterate over columns of B' (where B' is a transposed matrix B), e.g., ```\nmap (product row) columns```\n, where ```\ncolumns```\n is a list of column vectors, which is essentially our matrix B'. Therefore our final matrix C is,\n```\n[map (product r1) columns;\n map (product r2) columns;\n ....\n map (product rM) columns]\n```\n\nwhich, is a mapping of rows of the matrix A (which is essentially the representation of our matrix A),\n```\nlet mul matA matB = \n  let columns = transpose matB in\n  map (fun row -> map (product row) columns) matA\n```\n\nwhere ```\nmap f [x1; ...; xM]```\n is defined as ```\n[f x1; ...; f xM]```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Theano matrix multiplication of 2d matrix to give 3d matrix\r\n                \r\nI want to do exactly what the following question is trying to do in numpy:\nNumpy matrix multiplication of 2d matrix to give 3d matrix\n\nI have written the following code (as per the suggestion for numpy case), assuming that broadcast works in theano as well: \n\n```\ny = T.dmatrix('y')\nx = T.dmatrix('x')\nz = x[...,None]*y[:,None,:]\n```\n\n\nBut it is throwing following error:\n\n```\nAsTensorError: ('Cannot convert Ellipsis to TensorType', <type 'ellipsis'>)\n```\n\n    ", "Answer": "\r\nAs per @Divakar s comment, change it to\n\n```\nx[:,:,None] * y[:,None,:]\n```\n\n\nJust posting it as an answer so that people know there's an answer to this.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "MPI Matrix Multiplication Using Scatter and Gather\r\n                \r\nI'm trying to calculate matrix multiplication using MPI ```\nScatter()```\n and ```\nGather()```\n functions and I want to be able to choose the matrix size without having to change the amount of processes used.\n\nI've gone through the posts of MPI Matrix Multiplication with scatter gather and matrix multiplication using Mpi_Scatter and Mpi_Gather but they both use methods that don't work when a larger matrix size is defined, but only when the matrix size is the same as the processes/node size.\n\nMy code with an example matrix size of 8:\n\n```\n#define MAT_SIZE 8\n\nvoid initialiseMatricies(float a[][MAT_SIZE], float b[][MAT_SIZE], float c[][MAT_SIZE])\n{\n    int num = 11;\n    for (int i = 0; i < MAT_SIZE; i++)\n    {\n        for (int j = 0; j < MAT_SIZE; j++)\n        {\n            a[i][j] = num;\n            b[i][j] = num+1;\n            c[i][j] = 0;\n        }\n        num++;\n    }\n}\n\nint main(int argc, char **argv)\n{   \n    // MPI Variables\n    int rank, size;\n\n    // Create the main matrices with the predefined size\n    float matrixA[MAT_SIZE][MAT_SIZE];\n    float matrixB[MAT_SIZE][MAT_SIZE];\n    float matrixC[MAT_SIZE][MAT_SIZE];\n\n    // Create the separate arrays for storing the scattered rows from the main matrices\n    float matrixARows[MAT_SIZE];\n    float matrixCRows[MAT_SIZE];\n\n    // Initialise the matrices\n    initialiseMatricies(matrixA, matrixB, matrixC);\n\n    // Start the MPI parallel sequence\n    MPI_Init(&argc, &argv);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int count = MAT_SIZE * MAT_SIZE / (size * (MAT_SIZE / size));\n\n    // Scatter rows of first matrix to different processes\n    MPI_Scatter(matrixA, count, MPI_INT, matrixARows, count, MPI_INT, 0, MPI_COMM_WORLD);\n\n    // Broadcast second matrix to all processes\n    MPI_Bcast(matrixB, MAT_SIZE * MAT_SIZE, MPI_INT, 0, MPI_COMM_WORLD);\n\n    MPI_Barrier(MPI_COMM_WORLD);\n\n    // Matrix Multiplication\n    int sum = 0;\n    for (int i = 0; i < MAT_SIZE; i++)\n    {\n        for (int j = 0; j < MAT_SIZE; j++)\n        {\n            sum += matARows[j] * matB[j][i];\n        }\n        matCRows[i] = sum;\n    }\n\n    // Gather the row sums from the buffer and put it in matrix C\n    MPI_Gather(matrixCRows, count, MPI_INT, matrixC, count, MPI_INT, 0, MPI_COMM_WORLD);\n\n    MPI_Barrier(MPI_COMM_WORLD);\n\n    MPI_Finalize();\n\n    // if it's on the master node\n    if (rank == 0)\n        printResults(matrixA, matrixB, matrixC, calcTime);\n\n    return 0;\n}\n```\n\n\nOutput:\n\n```\n1364 2728 4092 5456 6820 8184 9548 10912 \n1488 2976 4464 5952 7440 8928 10416 11904 \n1612 3224 4836 6448 8060 9672 11284 12896 \n1736 3472 5208 6944 8680 10416 12152 13888 \n0 0 0 0 0 0 0 0 \n0 0 0 0 0 0 0 0 \n0 0 0 0 0 0 0 0 \n0 0 0 0 0 0 0 0 \n```\n\n\nThe output is correct and if I set the number of processes to 8 (same as matrix size) then the whole matrix is correctly calculated but I don't want to have to do that. I believe my issue stems from the count inside ```\nScatter()```\n and ```\nGather()```\n. If I set the count to:\n\n```\nint count = MAT_SIZE * MAT_SIZE / size;\n```\n\n\nThen the output becomes:\n\n```\n1364 2728 4092 5456 6820 8184 9548 10912 \n-1.07374e+08 -1.07374e+08 11 11 11 11 11 11 \n1612 3224 4836 6448 8060 9672 11284 12896 \n-1.07374e+08 -1.07374e+08 13 13 13 13 13 13 \n1860 3720 5580 7440 9300 11160 13020 14880 \n-1.07374e+08 -1.07374e+08 15 15 15 15 15 15 \n2108 4216 6324 8432 10540 12648 14756 16864 \n-1.07374e+08 -1.07374e+08 17 17 17 17 17 17 \n```\n\n\nBecause the count essentially goes from 8 (previous) to 16, and gives me a Debug Error for each process saying \n\n\n  \"Run-Time Check Failure #2 - Stack around the variable 'matrixC' was corrupted\"\n\n\nI've been changing this count formula around for a couple days now and still can't figure it out. I've tried changing my matrix multiplication start and end iterations but can't figure it out through that either.\n    ", "Answer": "\r\nThe allow for setting a larger matrix size, the separate arrays should be 2D arrays with the 1st dimension set as the size of the segment based on the number of tasks/processes:\n\n```\nfloat matrixARows[MAT_SIZE/size][MAT_SIZE];\nfloat matrixCRows[MAT_SIZE/size][MAT_SIZE];\n```\n\n\nCount should be:\n\n```\nint count = MAT_SIZE * MAT_SIZE / size;\n```\n\n\nAnd the matrix multiplication changed to:\n\n```\nint sum = 0;\nfor (int k = 0; k < MAT_SIZE/size; k++)\n{\n    for (int i = 0; i < MAT_SIZE; i++)\n    {\n        for (int j = 0; j < MAT_SIZE; j++)\n        {\n            sum += matARows[k][j] * matB[j][i];\n        }\n        matCRows[k][i] = sum;\n        sum = 0;\n    }\n}\n```\n\n\nNote: The matrix size must be divisible by the number of tasks/processes. E.g. if using 4 tasks, matrix size must be 4, 8, 16, 32, 64, 128 etc...\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "C++ matrix multiplication\r\n                \r\nI would like to create a matrix multiplication by a vector algorithm using  registers (of the information in the row-by-row). Open outer loop 4 times\nI have problem with \nvoid matvec_XMM(double* a, double* x, double* y, int n, int lb)\nfunction which return bad result\nIt is algorithm wchich I must use :\n\n```\ni = 1,n,4\n   r0 = r1 = r2 = r3 = 0\n   j = 1,n,8\n      r0 = r0 + aij * xj + ai,j+1 * xj+1 + … + ai,j+7 * xj+7\n      r1 = r1 + ai+1,j * xj + ai+1,j+1 * xj+1 + … + ai+1,j+7 * xj+7\n      r2 = r2 + ai+2,j * xj + ai+2,j+1 * xj+1 + … + ai+2,j+7 * xj+7\n      r3 = r3 + ai+3,j * xj + ai+3,j+1 * xj+1 + … + ai+3,j+7 * xj+7\n   end j\n   yi = r0; yi+1 = r1; yi+2 = r2; yi+3 = r3; \nend i\n```\n\n\nIt is ma code : \n\n```\n#include \"stdafx.h\"\n#include <iostream>\n#include \"mvec.h\"\n#include <emmintrin.h>\n\nusing namespace std;\n\nvoid mult_naive(double *a, double *x, double *y, int n)\n{\n    int i, j, ij;\n    double register reg;\n\n    for(i=0, ij=0; i<n; ++i)\n    {\n        reg = 0;\n\n        for(j=0; j<n; ++j, ++ij)\n        {\n            reg += a[ij]*x[j];\n        }\n\n        y[i] = reg;\n    }\n}\n\nvoid matvec_XMM(double* a, double* x, double* y, int n, int lb)\n{\nint i, j;\n\nmemset((void *)y, 0, n*sizeof(double));\ndouble res0[2];\ndouble res1[2];\ndouble res2[2];\ndouble res3[2];\n\n__m128d ry0, ry1, ry2, ry3, ra0, rx0;\ndouble *ptr_a, *ptr_x, *ptr_y;\nconst int nr = 4;\n\nptr_a = a;\n\nfor (i = 0; i < n; i+=nr)   \n{\n    ry0 = _mm_setzero_pd();\n    ry1 = _mm_setzero_pd();\n    ry2 = _mm_setzero_pd();\n    ry3 = _mm_setzero_pd(); \n\n    ptr_y = &y[i];\n    ptr_x = x;\n\n    for (j = 0; j<n; j+=lb)\n    {\n\n        _mm_prefetch((const char *)(ptr_a + lb*nr), _MM_HINT_NTA); \n        _mm_prefetch((const char *)(ptr_x + lb), _MM_HINT_T0);\n\n        //----1\n        rx0 = _mm_load_pd(ptr_x);       \n        ra0 = _mm_load_pd(ptr_a);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry0 = _mm_add_pd(ry0, ra0);\n\n        ra0 = _mm_load_pd(ptr_a + 2); \n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry1 = _mm_add_pd(ry1, ra0);\n\n        ra0 = _mm_load_pd(ptr_a + 4);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry2 = _mm_add_pd(ry2, ra0);\n\n        ra0 = _mm_load_pd(ptr_a + 6);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry3 = _mm_add_pd(ry3, ra0);\n\n            //----2\n        rx0 = _mm_load_pd(ptr_x + 2);   \n        ra0 = _mm_load_pd(ptr_a + 8);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry0 = _mm_add_pd(ry0, ra0);\n\n        ra0 = _mm_load_pd(ptr_a + 10);  \n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry1 = _mm_add_pd(ry1, ra0);\n\n        ra0 = _mm_load_pd(ptr_a + 12);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry2 = _mm_add_pd(ry2, ra0);\n\n        ra0 = _mm_load_pd(ptr_a + 14);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry3 = _mm_add_pd(ry3, ra0);\n\n        //----3\n        rx0 = _mm_load_pd(ptr_x + 4);       \n        ra0 = _mm_load_pd(ptr_a + 16);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry0 = _mm_add_pd(ry0, ra0);\n\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry1 = _mm_add_pd(ry1, ra0);\n\n        ra0 = _mm_load_pd(ptr_a + 20);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry2 = _mm_add_pd(ry2, ra0);\n\n        ra0 = _mm_load_pd(ptr_a + 22);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry3 = _mm_add_pd(ry3, ra0);\n\n        //----4\n        rx0 = _mm_load_pd(ptr_x + 6);       \n        ra0 = _mm_load_pd(ptr_a + 24);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry0 = _mm_add_pd(ry0, ra0);\n\n        ra0 = _mm_load_pd(ptr_a + 26);  \n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry1 = _mm_add_pd(ry1, ra0);\n\n        ra0 = _mm_load_pd(ptr_a + 28);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry2 = _mm_add_pd(ry2, ra0);\n\n        ra0 = _mm_load_pd(ptr_a + 30);\n        ra0 = _mm_mul_pd(ra0, rx0);\n        ry3 = _mm_add_pd(ry3, ra0);\n\n        ptr_a += lb*nr;\n        ptr_x += lb;\n    }\n\n    _mm_store_pd(res0, ry0);\n    *ptr_y = res0[0] + res0[1];\n\n    _mm_store_pd(res1, ry1);\n    *(ptr_y + 1) = res1[0] + res1[1];\n\n    _mm_store_pd(res2, ry2);\n    *(ptr_y + 2)= res2[0] + res2[1];\n\n    _mm_store_pd(res3, ry3);\n    *(ptr_y + 3) = res3[0] + res3[1];\n\n}\n}\n\n\n\n#include \"stdafx.h\"\n#include <iostream>\n#include <cmath>\n#include \"windows.h\"\n#include \"mvec.h\"\n\nusing namespace std;\n\n\nint main(int argc, char* argv[])\n{\n    double *a, *x, *y, *z;\n    int n;\n    DWORD tstart;\n    const int lb = 8;\n    double elaps_time;\n    cout << \"Program Mat_Vect: performance y = y +A*x\\n\";\n\n#ifdef _DEBUG\n    cout << \"DEBUG version\\n\";\n#else\n    cout << \"RELEASE version\\n\";\n#endif\n\n    cout << \"Input dimension\\n\";\n    cin >> n;\n\n    n = n/lb;\n    n = lb*n;\n\n    try\n    {\n        a = new double [n*n];\n        x = new double [n+1];\n        y = new double [n];\n        z = new double [n];\n    }\n    catch(bad_alloc aa)\n    {\n        cout << \"memory allocation error\" << endl;\n        system(\"pause\");\n        exit(1);\n    }\n\n    memset((void *)a, 0, _msize((void *)a));\n    memset((void *)x, 0, _msize((void *)x));\n    memset((void *)y, 0, _msize((void *)y));\n\n    cout << \"start\\n\";\n\n    prepare(a, x, n);\n\n    //-------------------------naive algorithm-----------------------//\n    cout << \"naive algorithm: \\n\";\n    tstart = GetTickCount();\n    mult_naive(a, x, z, n);\n    elaps_time = (double)(GetTickCount()-tstart)/1000.0;\n    cout << \"naive algorithm: \" << elaps_time << \" sec\" << endl;\n\n    //-------------------------algorithm which uses XMM registers-----------------------//\n    delete [] a;\n    delete [] x;\n    a = (double *)_aligned_malloc(n*n*sizeof(double), 16);\n    x = (double *)_aligned_malloc(n*sizeof(double), 16);\n    if(!a || !x)\n    {\n        cout << \"memory allocation error\" << endl;\n        system(\"pause\");\n        exit(1);\n    }\n    cout << \"algorithm which uses XMM: \\n\";\n    prepare(a, x, n);\n    tstart = GetTickCount();\n    matvec_XMM(a, x, y, n, lb);\n    elaps_time = (double)(GetTickCount()-tstart)/1000.0;\n    check(y, z, n);\n    cout << \"algorithm which uses XMM: \" << elaps_time << \" sec\" << endl;\n\n    delete [] y;\n    delete [] z;\n    _aligned_free(a);\n    _aligned_free(x);\n\n    system(\"pause\");\n    return 0;\n}\n\n\nvoid check(double *y, double *z, int n)\n{\n    int i;\n    for(i=0; i<n; i++)\n    {\n        if(fabs(z[i] - y[i]) > 1.0e-9)\n        {\n            cout << \"error\\n\";\n            return;\n        }\n    }\n\n    cout << \"OK\\n\";\n}\n\nvoid prepare(double *a, double *x, int n)\n{\n    int i, j, ij;\n\n    for(i=0, ij=0; i<n; i++)\n    {\n        for(j=0; j<n; j++, ij++)\n        {\n            if(i == j)\n                a[ij] = 10.0;\n            else\n                a[ij] = (double)(i+1);\n        }\n\n        x[i] = 1.0;\n    }\n}\n```\n\n    ", "Answer": "\r\nI found the solution\n\n```\nvoid matvec_XMM(double* a, double* x, double* y, int n, int lb)\n{\n    int i, j;\n\n    memset((void *)y, 0, n*sizeof(double));\n    __declspec(align(16)) double res0[2];\n    __declspec(align(16)) double res1[2];\n    __declspec(align(16)) double res2[2];\n    __declspec(align(16)) double res3[2];\n\n    __m128d ry0, ry1, ry2, ry3, ra0, ra1, ra2, ra3, rx0;\n    double *ptr_a1, *ptr_a2, *ptr_a3, *ptr_a4, *ptr_x, *ptr_y;\n    const int nr = 4;\n\n    for (i = 0; i < n; i+=nr)\n    {\n        ry0 = _mm_setzero_pd();\n        ry1 = _mm_setzero_pd();\n        ry2 = _mm_setzero_pd();\n        ry3 = _mm_setzero_pd();\n\n        ptr_y = &y[i];\n\n        for (j = 0; j<n; j+=lb)\n        {\n            ptr_a1 = &a[i * n + j];\n            ptr_a2 = &a[(i + 1) * n + j];\n            ptr_a3 = &a[(i + 2) * n + j];\n            ptr_a4 = &a[(i + 3) * n + j];\n            ptr_x = &x[j];\n\n            _mm_prefetch((const char *)(ptr_a1 + lb), _MM_HINT_NTA);\n            _mm_prefetch((const char *)(ptr_a2 + lb), _MM_HINT_NTA);\n            _mm_prefetch((const char *)(ptr_a3 + lb), _MM_HINT_NTA);\n            _mm_prefetch((const char *)(ptr_a4 + lb), _MM_HINT_NTA);\n            _mm_prefetch((const char *)(ptr_x + lb), _MM_HINT_T0);\n\n            //-------------------------------------1\n            rx0 = _mm_load_pd(ptr_x);\n\n            ra0 = _mm_load_pd(ptr_a1);\n            ra1 = _mm_load_pd(ptr_a2);\n            ra2 = _mm_load_pd(ptr_a3);\n            ra3 = _mm_load_pd(ptr_a4);\n\n            ra0 = _mm_mul_pd(ra0, rx0);\n            ra1 = _mm_mul_pd(ra1, rx0);\n            ra2 = _mm_mul_pd(ra2, rx0);\n            ra3 = _mm_mul_pd(ra3, rx0);\n\n            ry0 = _mm_add_pd(ry0, ra0);\n            ry1 = _mm_add_pd(ry1, ra1);\n            ry2 = _mm_add_pd(ry2, ra2);\n            ry3 = _mm_add_pd(ry3, ra3);\n\n            //------------------------------------2\n            rx0 = _mm_load_pd(ptr_x + 2);\n\n            ra0 = _mm_load_pd(ptr_a1 + 2);\n            ra1 = _mm_load_pd(ptr_a2 + 2);\n            ra2 = _mm_load_pd(ptr_a3 + 2);\n            ra3 = _mm_load_pd(ptr_a4 + 2);\n\n            ra0 = _mm_mul_pd(ra0, rx0);\n            ra1 = _mm_mul_pd(ra1, rx0);\n            ra2 = _mm_mul_pd(ra2, rx0);\n            ra3 = _mm_mul_pd(ra3, rx0);\n\n            ry0 = _mm_add_pd(ry0, ra0);\n            ry1 = _mm_add_pd(ry1, ra1);\n            ry2 = _mm_add_pd(ry2, ra2);\n            ry3 = _mm_add_pd(ry3, ra3);\n\n            //-----------------------------------3\n            rx0 = _mm_load_pd(ptr_x + 4);\n\n            ra0 = _mm_load_pd(ptr_a1 + 4);\n            ra1 = _mm_load_pd(ptr_a2 + 4);\n            ra2 = _mm_load_pd(ptr_a3 + 4);\n            ra3 = _mm_load_pd(ptr_a4 + 4);\n\n            ra0 = _mm_mul_pd(ra0, rx0);\n            ra1 = _mm_mul_pd(ra1, rx0);\n            ra2 = _mm_mul_pd(ra2, rx0);\n            ra3 = _mm_mul_pd(ra3, rx0);\n\n            ry0 = _mm_add_pd(ry0, ra0);\n            ry1 = _mm_add_pd(ry1, ra1);\n            ry2 = _mm_add_pd(ry2, ra2);\n            ry3 = _mm_add_pd(ry3, ra3);\n\n            //----------------------------------4\n            rx0 = _mm_load_pd(ptr_x + 6);\n\n            ra0 = _mm_load_pd(ptr_a1 + 6);\n            ra1 = _mm_load_pd(ptr_a2 + 6);\n            ra2 = _mm_load_pd(ptr_a3 + 6);\n            ra3 = _mm_load_pd(ptr_a4 + 6);\n\n            ra0 = _mm_mul_pd(ra0, rx0);\n            ra1 = _mm_mul_pd(ra1, rx0);\n            ra2 = _mm_mul_pd(ra2, rx0);\n            ra3 = _mm_mul_pd(ra3, rx0);\n\n            ry0 = _mm_add_pd(ry0, ra0);\n            ry1 = _mm_add_pd(ry1, ra1);\n            ry2 = _mm_add_pd(ry2, ra2);\n            ry3 = _mm_add_pd(ry3, ra3);\n        }\n\n        _mm_store_pd(res0, ry0);\n        *ptr_y = res0[0] + res0[1];\n\n        _mm_store_pd(res1, ry1);\n        *(ptr_y + 1) = res1[0] + res1[1];\n\n        _mm_store_pd(res2, ry2);\n        *(ptr_y + 2) = res2[0] + res2[1];\n\n        _mm_store_pd(res3, ry3);\n        *(ptr_y + 3) = res3[0] + res3[1];\n    }\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication using Pig Latin\r\n                \r\nI'm trying to perform a matrix multiplication on a simple 3 X 3 matrix using Pig. I'm neither unable to perform transpose nor group according to the row.\n\nCan someone help me on this please.\n\nExample\n\nMatrix A: \n\n```\n2  2  2 \n2  2  2\n2  2  2\n```\n\n\nMatrix B:\n\n```\n1  1  1\n1  1  1    \n1  1  1\n```\n\n\nThanks in advance !\n    ", "Answer": "\r\nAssuming your matrices are stored as \"row, column, value\", you can check  this\n\nAlso if you have a txt file for the same, you can load that by:\n\n```\nE = LOAD 'matrix1.txt' USING PigStorage(',') AS (row:chararray, col:chararray, val:float);\n```\n\n\nOR\n\n```\nE = LOAD 'M-matrix-small.txt' USING PigStorage(',') AS (row, col, val);\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication on hadoop\r\n                \r\nI'm looking for the best and easy way of matrix multiplication on hadoop java. Meanwhile I looked at this link http://www.norstad.org/matrix-multiply/index.html but I felt tough to understand it. \n\nOverall: I've two files matrixA(m x n) and matrixB(n x m). I want matrixC(m x m) by multiplying A and B. I'll pass above two files to mapreduce program.\n\nPlease help me.. \n    ", "Answer": "\r\nCould you reprocess the matrix two files as:\n\n```\n System.out.println( column + \" , \" + row + \"\\t\" + value );\n```\n\n\nI am thinking that you can map over both by outputting:\n\n```\ncontext.write( new Text( column + \" , \" + row ), new IntWritable( value ) );\n```\n\n\nthen reduce with an iterator and just multiply the values.\n\n```\nfor( int val: value ) {\n    int result *= val;\n}\n\ncontext.write( key, new IntWritable( result ));\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Objective C - Matrix Multiplication Slow Performance\r\n                \r\nI have 2 2-D NSMutableArrays and I am trying to do some basic matrix multiplication.  I have my generic formula code below, but its performance is exceptionally slow (as expected).  I have done lots of googling and have not found any easy nor easy to understand formulas to change up the code for performance enhancement.  Can anyone point me in the right direction of a straightforward formula/tutorial/example of how to get better performance than 0(n^3) with matrix multiplication in Objective C.\n\n```\n+ (NSMutableArray*)multiply:(NSMutableArray*)a1 withArray:(NSMutableArray*)a2\n{\n    if([[a1 objectAtIndex: 0] count] != [a2 count])\n    {\n        NSLog(@\"Multiplicaton error!\");\n        return NULL;\n    }\n\n    int a1_rowNum = [a1 count];\n    int a2_rowNum = [a2 count];\n    int a2_colNum = [[a2 objectAtIndex:0] count];\n    NSMutableArray *result = [NSMutableArray arrayWithCapacity:a1_rowNum];\n    for (int i = 0; i < a1_rowNum; i++) {\n        NSMutableArray *tempRow = [NSMutableArray arrayWithCapacity:a2_colNum];\n        for (int j = 0; j < a2_colNum; j++) {\n            double tempTotal = 0;\n            for (int k = 0; k < a2_rowNum; k++) {\n                double temp1 = [[[a1 objectAtIndex:i] objectAtIndex:k] doubleValue];\n                double temp2 = [[[a2 objectAtIndex:k] objectAtIndex:j] doubleValue];\n                tempTotal += temp1 * temp2;\n            }\n             //Stored as a string because I upload it to an online database for storage.\n            [tempRow addObject:[NSString stringWithFormat:@\"%f\",tempTotal]];\n        }\n        [result addObject:tempRow];\n    }\n    return result;\n}\n```\n\n    ", "Answer": "\r\nIt will be much faster if you Write it in C.\n\n\n\n```\ndouble[]```\n will be ridiculously fast compared to an ```\nNSArray```\n of ```\nNSNumber```\ns for this task. you'll have good cache coherency, minimal instructions, no need to go through the runtime or allocate in order to write or read an element. no need to perform reference count cycling on each element…\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in knitr code chunk\r\n                \r\nWhen I include an inline code trunk using ```\n\\Sexpr{}```\n, the matrix multiplication symbole ```\n%*%```\n is interpreted as Latex commenting. How to get around this?\n    ", "Answer": "\r\nThis seems like a reasonable concern, but it doesn't happen to me (with R-devel/3.1.0, knitr 1.5). Also, logically it seems as though it shouldn't happen since the contents of code chunks are evaluated before LaTeX sees the file. Reproducible example please?\n\n(As shown below, you can get into trouble if you try hard enough, but generally I think you shouldn't.)\n\nIf ```\ntexmult.Rnw```\n is this:\n\n```\n\\documentclass{article}\n\\pagestyle{empty}\n\\begin{document}\n\nhello\n\n<<>>=\nm <- matrix(1:4,nrow=1)\nx <- 1:4\n@\n\nThe result is \\Sexpr{m %*% x}\n\nThis is a bad thing: \\Sexpr{\"%*%\"} and then more stuff\n\n\\end{document}\n```\n\n\nThen ```\nlibrary(knitr); knit2pdf(\"texmult.Rnw\")```\n gives me\n\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Sparse matrix multiplication with NA\r\n                \r\nPerforming matrix multiplication on sparse matrices in R gives a different result as the same operation performed on dense forms of the same matrices if there are ```\nNA```\n's in the data.\n\nSome data to demonstrate on:\n\n```\nlibrary(Matrix)\nset.seed(123)\nm1  <- Matrix(data=sample(c(0,0,0,0,0,1,2,NA),25, T), ncol = 5, nrow = 5, sparse = F)\nm2  <- Matrix(data=sample(c(0,0,0,0,0,1,2,NA),25, T), ncol = 5, nrow = 5, sparse = F)\nsm1 <- Matrix(m1, sparse = T)\nsm2 <- Matrix(m2, sparse = T)\n```\n\n\nNow if we do \n\n```\nm1 %*% m2\n\n# 5 x 5 Matrix of class \"dgeMatrix\"\n#      [,1] [,2] [,3] [,4] [,5]\n# [1,]   NA   NA   NA   NA   NA\n# [2,]    2   NA    0    0    2\n# [3,]   NA   NA   NA   NA   NA\n# [4,]   NA   NA   NA   NA   NA\n# [5,]   NA   NA   NA   NA   NA\n```\n\n\nwe get a different result to \n\n```\nsm1 %*% sm2\n\n# 5 x 5 sparse Matrix of class \"dgCMatrix\"\n#                  \n# [1,]  . NA  . . NA\n# [2,]  2 NA  . .  2\n# [3,]  . NA NA .  2\n# [4,] NA NA  . . NA\n# [5,] NA NA  . .  2\n```\n\n\nThe cause of this seems to be that while ```\n0 * NA```\n returns ```\nNA```\n,  a zero (or missing location) in a sparse matrix returns zero when multiplied by NA.\n\nWe can see this behaviour in \n\n```\n0 %*% NA\n     [,1]\n[1,]   NA\n\nMatrix(data=0, sparse=T) %*% NA\n1 x 1 Matrix of class \"dgeMatrix\"\n     [,1]\n[1,]    0\n```\n\n\nIs there any way to get sparse matrix multiplication to always yield the same result as dense matrix multiplication when there can be NA's in the data (other than, of course, converting to their dense forms, which defeats the object of using sparse matrices in the first place)?\n\nUpdate\n\nComments suggest that different people are seeing a variety of different behaviours.   I have tested on 64-bit Linux (kubuntu 16.04), R 3.2.3, Matrix 1.2-3, and on R 3.3.1, Matrix 1.2-6.\n\nThe following all give the same result for me:\n\n```\nm1 %*% m2\nas.matrix(m1) %*% as.matrix(m2)\nas.matrix(sm1) %*% as.matrix(sm2)\n```\n\n\nWhereas \n\n```\nsm1 %*% sm2\n```\n\n\ngives different value, as shown above. Similar discrepancies are seen when matrices contain ```\nInf```\n or ```\nNaN```\n.\n\n-\n\nHowever, slightly different behaviour was seen by @user20650, who reports in the comments that they also see varying results on Ubuntu 14.04 (x32), Matrix v1.2-6, R v3.3.1, but in different combinations to me. In their case,```\nm1 %*% m2```\n, and ```\nsm1 %*% sm2```\n both give same answer as i had for ```\nsm1 %*% sm2```\n. But, ```\nas.matrix(m1) %*% as.matrix(m2)```\n and ```\nas.matrix(sm1) %*% as.matrix(sm2)```\n both give the result that I get for ```\nm1 %*% m2```\n.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to perform Vector-Matrix Multiplication with BLAS ?\r\n                \r\nBLAS defines the GEMV (Matrix-Vector Multiplication) level-2 operation. How to use a BLAS Library to perform Vector-Matrix Multiplication ? \n\nIt's probably obvious, but I don't see how to use BLAS operation for this multiplication. I would have expected a GEVM operation. \n    ", "Answer": "\r\nThe Matrix-Vector multiplication of a (M x N) Matrix with a (N x 1) Vector will result an (M x 1) Vector. In short ```\na*A(MxN)*X(Nx1) + b*Y(Mx1) -> Y(Mx1)```\n. Of course you can use ```\nINCX```\n and ```\nINCY```\n when your vector is included in a matrix.\n\nIn order to define a Vector-Matrix multiplication The Vector should be transposed. i.e. ```\na*X(1xM)*A(MxN) + b*Y(1xN) -> Y(1xN)```\n. Basically you do not have a vector but a single row matrix. \n\nStarting from this point there are two possibilities.\n\nEither use level-3 \"GEMM\"\n\n```\n?gemm(transa, transb, m, n, k, alpha, a, lda, b, ldb, beta, c, ldc)\n```\n\n\nusing\n\n```\n?gemm('N', 'N', 1, N, M, a, X, 1, A, M, b, Y, 1)\n```\n\n\nOr do some more math. Considering that ```\n(X*A)^T = A^T * X^T```\n the row matrix ```\nX```\n is converted to vector X^T(MX1). Also ```\nY```\n transpose is vector ```\nY^T(Nx1)```\n. Of course memory-wise both ```\nX```\n and ```\nX^T```\n are store with the same way, sequentially. This means you can use again ```\nGEMV```\n using transpose matrix ```\nA```\n\n\n```\n?gemv('T', M, N, a, A, M, X, 1, b, Y, 1)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication Matlab vs Mathematica [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs debugging details. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     Edit the question to include desired behavior, a specific problem or error, and the shortest code necessary to reproduce the problem. This will help others answer the question.\r\n                \r\n                    \r\n                        Closed 7 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI am trying to identify if Mathematica is as efficient as Matlab in matrix multiplication. \nfor example    20000x20000   by 20000x20000\ntakes 60 sec in Matlab\n     300 sec in Mathematica\n\nDo I need to do anything, i.e., turn on parallel computing in Mathematica? \n    ", "Answer": "\r\nI don't think that you will ever get Mathematica to be as fast as Matlab when it comes to dealing with matrices. I actually had to write a Matlab code a while ago that would get data from Mathematica, do some simple operations on the matrices and then feed them back to Mathematica, because doing it within Mathematica itself was taking forever.\n\nMatlab was especially designed to deal with matrices fast, and that's what it does. It's definitely not true of Mathematica, which works beautifully for symbolic calculations but doesn't deal with large datasets/matrices very well.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication returning wrong matrix python parallel\r\n                \r\nI have a school project, where I have to do some python parallel function. One of them is matrix multiplication(I cannot use numpy). I tried to do it in multithreading, but it was too slow and I was recommented to do it in multiprocessing. It is much faster, but there is one problem. I get the right matrix only when I use one process. Can anyone help? Here is the code:\n\n```\nimport numpy as np\nimport time\nimport multiprocessing.dummy as mp\n\nmin = -10\nmax = 10\nn = 10\nx = ((np.random.rand(n, n) * (max - min) ) + min).astype('int')\ny = ((np.random.rand(n, n) * (max - min) ) + min).astype('int')\n\nz = [[0 for i in range(n)] for j in range(n)]\njump = 0\n\ndef matrixMult(start):\n    for i in range(start, start + jump):\n        print(\"HEJ\")\n        for k in range(n):\n            for j in range(n):\n                z[i][j] += x[i][k] * y[k][j]\n\ndef multPrepare(x, y, i):\n    pool = mp.Pool(i)\n    pool.map(matrixMult, range(0, n, jump))\n    return z\n\nif __name__ == '__main__':\n\n    i = 1\n    while i < 5:\n        start_time = time.time()\n        jump = int(round(n / i))\n        z = multPrepare(x, y, i)\n        print(\"number of cores: \" + str(i) + \", TIME: \"+ str(time.time()-start_time) + \" seconds\")\n        i += 1\n\n    print(z)\n    print(z == x.dot(y))\n```\n\n\nThe result matrix is only right when i = 1.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "In place matrix multiplication numpy\r\n                \r\nI have a list of point arrays, and as I iterate through it I want to do in-place matrix multiplication i.e. I want the result stored in the same matrix.\n\nThe code is essentially:\n\n```\nfor p in p_list:\n    # R is a 3x3 matrix\n    p[:,:] = np.matmul(R,p)\n```\n\n\nThis code shows no error but the result is incorrect, as if the multiplication is performed in the arrays and substituted as calculated, so it creates a wrong output matrix. Removing [:,:] give a correct multiplication.\n\n1) Why does this happen exactly?\n2) The main reason I used [:,:] is to make sure the result is stored back in the list p_list. Is there a correct way to do that (without using an intermediate variable)? \n    ", "Answer": "\r\n```\nmatmul```\n accepts an out parameter\n\nIf ```\np_list```\n is an ```\nndarray```\n, with shape ```\nN, 3```\n, then you can achieve the entire multiplication in one ```\nmatmul```\n:\n\n```\nnp.matmul(p_list, R.T, out=p_list)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "parallel sparse matrix multiplication\r\n                \r\nFor sparse matrix multiplication, it is less efficiency than dense one mainly because more time is spent on locating and seeking elements in memory rather than CPU computation.\n\nI am using matlab, and here, I need to do a very sparse matrix multiplication with a dense one, i.e. S times D where S is sparse and D is dense. \n\nThen, my questions are that \n\n\nif D has k columns, and do S times D(:,k) in parallel for each k, will it be faster than matlab default routine S times D?\nif so, is it better for me to write .mex files, and do multi-threads computation in them?\n\n\nThanks very much~\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Getting exception error when trying matrix multiplication\r\n                \r\nCode works fine when both matrices have same number of rows and columns. like for eg. 3x3 and 3x3 matrix multiplication works fine.\nGetting below error when trying to multiply matrices with different sizes.  Tried multiplying a 2x3 matrix and a 3x4 matrix and got error.\n```\n**Exception in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1\n    at arrayprac.ArrayPrac.main(ArrayPrac.java:85)\n38C:\\Users\\a807771\\AppData\\Local\\NetBeans\\Cache\\17\\executor-snippets\\run.xml:111: The following error occurred while executing this line:\nC:\\Users\\a807771\\AppData\\Local\\NetBeans\\Cache\\17\\executor-snippets\\run.xml:68: Java returned: 1\nBUILD FAILED (total time: 12 seconds)**\n```\n\n```\npackage arrayprac;\nimport java.util.Scanner;\n\npublic class ArrayPrac {\n \n    public static void main(String[] args) {\n        \n     System.out.println(\"Enter number of rows for matrix 1: \");\n     int row1,col1,row2,col2;\n     Scanner sc=new Scanner(System.in);\n     row1=sc.nextInt();\n     System.out.println(\"Enter number of Columns for matrix 1: \");\n     col1=sc.nextInt();\n     System.out.println(\"Enter number of rows for matrix 2: \");\n     row2=sc.nextInt();\n     System.out.println(\"Enter number of Columns for matrix 2: \");\n     col2=sc.nextInt(); \n     int a[][]=new int[row1][col1];\n     int b[][]=new int[row2][col2];\n     for(int i=0;i<row1;i++)\n     {\n         for(int j=0;j<col1;j++)\n         {\n             System.out.println(\"Enter element for 1st matrix: \");\n             a[i][j]=sc.nextInt();\n         }\n        \n     }\n     for(int i=0;i<row2;i++)\n     {\n         for(int j=0;j<col2;j++)\n         {\n             System.out.println(\"Enter element for 2nd matrix: \");\n             b[i][j]=sc.nextInt();\n         }\n        \n     }\n     System.out.println(\"Below is the 1st matrix: \\n\");\n     for(int i=0;i<row1;i++)\n     {\n         for(int j=0;j<col1;j++)\n         {\n             System.out.print(a[i][j]);\n             \n         }\n        System.out.println(\"\");\n     }\n     \n     System.out.println(\"Below is the 2nd matrix: \\n\");\n     for(int i=0;i<row2;i++)\n     {\n         for(int j=0;j<col2;j++)\n         {\n             System.out.print(b[i][j]);\n             \n         }\n        System.out.println(\"\");\n     }\n     \n     if(col1!=row2)\n     {\n         System.out.println(\"Matrix multiplication impossible!\");\n         System.exit(0);\n     }\n     else{\n         int c[][]=new int[row1][col2];\n         \n         for(int i=0;i<row1;i++)\n         {\n             for(int j=0;j<col2;j++)\n             {\n                 c[i][j]=0;\n                 for(int k=0;k<row2;k++)\n                 {\n                     c[i][j]=c[i][j]+a[i][k]*b[k][j];\n                 }\n             }\n         }\n         \n     System.out.println(\"Below is the result matrix: \\n\");\n     for(int i=0;i<col1;i++)\n     {\n         for(int j=0;j<row2;j++)\n         {\n             System.out.print(c[i][j]);\n             \n         }\n        System.out.println(\"\");\n     }\n     }   \n     \n    }\n    \n}\n```\n\nCode works fine when both matrices have same number of rows and columns. like for eg. 3x3 and 3x3 matrix multiplication works fine.\nGetting error when trying to multiply matrices with different sizes. Tried multiplying a 2x3 matrix and a 3x4 matrix and got error.\n    ", "Answer": "\r\nThe iteration bounds in the double for loop for printing the new matrix should match the previous for loops for multiplication. I think this correction in your code will make it work.\n```\nfor(int i=0;i<row1;i++)//Here\n        {\n            for(int j=0;j<col2;j++)//And here\n            {\n                System.out.print(c[i][j]);\n\n            }\n            System.out.println(\"\");\n        }\n```\n\nGenerally speaking, in situations like this it will help if you set breakpoints in the lines where the problem is and then using the debugger.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication returning wrong matrix python parallel\r\n                \r\nI have a school project, where I have to do some python parallel function. One of them is matrix multiplication(I cannot use numpy). I tried to do it in multithreading, but it was too slow and I was recommented to do it in multiprocessing. It is much faster, but there is one problem. I get the right matrix only when I use one process. Can anyone help? Here is the code:\n\n```\nimport numpy as np\nimport time\nimport multiprocessing.dummy as mp\n\nmin = -10\nmax = 10\nn = 10\nx = ((np.random.rand(n, n) * (max - min) ) + min).astype('int')\ny = ((np.random.rand(n, n) * (max - min) ) + min).astype('int')\n\nz = [[0 for i in range(n)] for j in range(n)]\njump = 0\n\ndef matrixMult(start):\n    for i in range(start, start + jump):\n        print(\"HEJ\")\n        for k in range(n):\n            for j in range(n):\n                z[i][j] += x[i][k] * y[k][j]\n\ndef multPrepare(x, y, i):\n    pool = mp.Pool(i)\n    pool.map(matrixMult, range(0, n, jump))\n    return z\n\nif __name__ == '__main__':\n\n    i = 1\n    while i < 5:\n        start_time = time.time()\n        jump = int(round(n / i))\n        z = multPrepare(x, y, i)\n        print(\"number of cores: \" + str(i) + \", TIME: \"+ str(time.time()-start_time) + \" seconds\")\n        i += 1\n\n    print(z)\n    print(z == x.dot(y))\n```\n\n\nThe result matrix is only right when i = 1.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication using pointers\r\n                \r\nI was learning to implement dimensional arrays with the help of Pointers, stumbled upon a program - Multiplication of Matrices, but with pointers. I've understood the Matrix multiplication program without using pointers. It comes like this:\n\n```\nfor(i=0; i<r1; ++i)\nfor(j=0; j<c2; ++j)\nfor(k=0; k<c1; ++k)\n    mult[i][j]+=a[i][k]*b[k][j];\n```\n\n\nUsing Pointers, the code is like this:\n\n```\nfor(i=0;i<r1;i++)    \nfor(j=0;j<c2;j++)    \nfor(k=0;k<c1;k++)    \n    *(*(c+i)+j)+=*(*(a+i)+j)*(*(*(b+k)+j));\n```\n\n\nI don't get the above piece of code, what exactly are they Dereferencing and which asterisk represents Multiplication?\n\nSorry for my ignorance, Thanks in advance (:\n    ", "Answer": "\r\nAll these matrices are two level arrays and consist of an array of pointers to arrays of values. This makes it a bit ugly to do it in the latter way.\n\nFirst you need to find the pointer to the array you want. That's the first derefence ```\n*(c+i)```\n. Then you add to this the item you want from that array and dereference again, so it becomes ```\n*(*(c+i)+j)```\n. That's all it takes.\n\nNow the only actual multiplication is the asterisk between the closing and opening braces:\n\n```\n *(*(c+i)+j)+=*(*(a+i)+j)  *  (*(*(b+k)+j));\n                           ^ this\n```\n\n\nIf that code looks ugly to you, I can tell you something that will help: you can use the first type code with pointers too. ```\nc[i]```\n is exactly the same as ```\n*(c+i)```\n. So just use\n\n```\nc[i][j] += a[i][j] * b[k][j];\n```\n\n\nand your life will be at least 7.935% better, guaranteed.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication in Python 3\r\n                \r\nI am trying to create several functions for Linear Algebra and was completely stuck on matrix multiplication. Below is my working solution, but is there possibly a cleaner solution?\n```\ndef matrix_multiplication(a, b):\n     # Transpose matrix b\n     bT = list(zip(*b))\n\n     # Multiply the two\n     return [[sum([a[ai][j] * bT[bTi][j] for j in range(len(a[ai]))]) for bTi in range(len(bT))] for ai in range(len(a))]\n```\n\n    ", "Answer": "\r\nFirstof all, I would only recommend creating a linear algebra library from scratch, if you want to use it for learning purposes. Otherwise you should use numpy.linalg or something similar.\nAssuming, you want to do this from scratch, I reccommend to go with object oriented programming approach. This would mean creating your own matrix class.\nYou can try something similar to this blog: https://towardsdatascience.com/how-to-build-a-matrix-module-from-scratch-a4f35ec28b56\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Finding Essential matrix (Matrix Multiplication Error)\r\n                \r\nI am trying to do 3D reconstruction using opencv and I am pretty much following all the steps from the book :\nOpenCV 2 Computer Vision Application Programming Cookbook by Robert Laganière. \n\nMy problem comes when trying to find the Essential Matrix. I do it this way : \n\n```\n  Mat fundemental= ransacTest(symMatches,keypoints1, keypoints2, outmatches);\n //ransacTest function by Computer Vision Application Programming Cookbook \n\n cout<<endl<<fundemental<<endl;\n\n Mat  K=m_camera_data->get_K();\n //get_K() function defined previously \n cout<<K<<endl;\n\n cout<<\"K.T\"<<K.t()<<endl;\n\n Mat_<double>  E = K.t() *fundemental* K; // Error   \n```\n\n\nThe functions ransacTest and get_K() have been defined previously and they seem to work fine. My fundamental matrix is the following \n\n```\n-7.65924601845777e-006   0.0052097327886         -0.179203748284864\n-0.005202223611495075    -8.913278071309e-006    -0.5024237005766097\n0.1843335279902164       0.4908219843516384       1\n```\n\n\nMy K matrix is the following \n\n```\n 382.5   0    160\n\n 0       0    120\n\n 0       0     1\n```\n\n\nThe transpose of K is done correctly.\nThe problem comes when I try to obtain the Essential matrix E. I get this error when running the program \n\"OpenCV Error: Assertion failed (type == B<> && > in unknown function, file .. ....\\src\\opencv\\modules\\core\\src\\matmul.cpp, line 711\"\n\nI looked it up and I found a similar problem in this question Opencv Matrix multiplication\n but I tried to do what the answer said ( change the matrix  types) and I still got the same error.\n\nI have also tried to use Gemm to  do matrix multiplication  but the same error appears.\n\nI could really use some help!Thanks in advance.\n    ", "Answer": "\r\nThat sounds like if the type of ```\nK```\n is not double (CV_64F); probably it is float (CV_32F). Check that ```\nK.type() == CV_64F```\n.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Memory management for Strassen's matrix multiplication\r\n                \r\nAs a part of an assignment, I am trying to find out the crossover point for Strassen's matrix multiplication and naive multiplication algorithms. But for the same, I am unable to proceed when matrix becomes 256x256. Can someone please suggest me the appropriate memory management technique to be able to handle larger inputs.\n\nThe code is in C as follows:\n\n```\n#include<stdio.h>\n#include<stdlib.h>\n#include<math.h>\n#include<time.h>\n\nvoid strassenMul(double* X, double* Y, double* Z, int m);\nvoid matMul(double* A, double* B, double* C, int n);\nvoid matAdd(double* A, double* B, double* C, int m);\nvoid matSub(double* A, double* B, double* C, int m);\n\nint idx = 0;\n\nint main()\n{\n    int N;\n    int count = 0;\n    int i, j;\n    clock_t start, end;\n    double elapsed;\n\n    int total = 15;\n    double tnaive[total];\n    double tstrassen[total];\n    printf(\"-------------------------------------------------------------------------\\n\\n\");\n    for (count = 0; count < total; count++)\n    {\n        N = pow(2, count);\n        printf(\"Matrix size = %2d\\t\",N);\n        double X[N][N], Y[N][N], Z[N][N], W[N][N];\n        srand(time(NULL));\n        for (i = 0; i < N; i++)\n        {\n            for (j = 0; j < N; j++)\n            {\n                X[i][j] = rand()/(RAND_MAX + 1.);\n                Y[i][j] = rand()/(RAND_MAX + 1.);\n            }\n        }\n        start = clock();\n        matMul((double *)X, (double *)Y, (double *)W, N);\n        end = clock();\n        elapsed = ((double) (end - start))*100/ CLOCKS_PER_SEC;\n        tnaive[count] = elapsed;\n        printf(\"naive = %5.4f\\t\\t\",tnaive[count]);\n\n        start = clock();\n        strassenMul((double *)X, (double *)Y, (double *)Z, N);\n        end = clock();\n        elapsed = ((double) (end - start))*100/ CLOCKS_PER_SEC;\n        tstrassen[count] = elapsed;\n        printf(\"strassen = %5.4f\\n\",tstrassen[count]);\n    }\n    printf(\"-------------------------------------------------------------------\\n\\n\\n\");\n\n    while (tnaive[idx+1] <= tstrassen[idx+1] && idx < 14) idx++;\n\n    printf(\"Optimum input size to switch from normal multiplication to Strassen's is above %d\\n\\n\", idx);\n\n    printf(\"Please enter the size of array as a power of 2\\n\");\n    scanf(\"%d\",&N);\n    double A[N][N], B[N][N], C[N][N];\n    srand(time(NULL));\n    for (i = 0; i < N; i++)\n    {\n        for (j = 0; j < N; j++)\n        {\n            A[i][j] = rand()/(RAND_MAX + 1.);\n            B[i][j] = rand()/(RAND_MAX + 1.);\n        }\n    }\n\nprintf(\"------------------- Input Matrices A and B ---------------------------\\n\\n\");\n    for (i = 0; i < N; i++)\n    {\n        for (j = 0; j < N; j++)\n            printf(\"%5.4f  \",A[i][j]);\n        printf(\"\\n\");\n    }\n    printf(\"\\n\");\n\n    for (i = 0; i < N; i++)\n    {\n        for (j = 0; j < N; j++)\n            printf(\"%5.4f  \",B[i][j]);\n        printf(\"\\n\");\n    }\n    printf(\"\\n------- Output matrix by Strassen's method after optimization -----------\\n\\n\");\n\n    strassenMul((double *)A, (double *)B, (double *)C, N);\n\n    for (i = 0; i < N; i++)\n    {\n        for (j = 0; j < N; j++)\n            printf(\"%5.4f  \",C[i][j]);\n        printf(\"\\n\");\n    }\n    return(0);\n}\n\nvoid strassenMul(double *X, double *Y, double *Z, int m)\n{\n    if (m <= idx)\n    {\n        matMul((double *)X, (double *)Y, (double *)Z, m);\n        return;\n    }\n    if (m == 1)\n    {\n        *Z = *X * *Y;\n        return;\n    }\n    int row = 0, col = 0;\n    int n = m/2;\n    int i = 0, j = 0;\n    double x11[n][n], x12[n][n], x21[n][n], x22[n][n];\n    double y11[n][n], y12[n][n], y21[n][n], y22[n][n];\n    double P1[n][n], P2[n][n], P3[n][n], P4[n][n], P5[n][n], P6[n][n], P7[n][n];\n    double C11[n][n], C12[n][n], C21[n][n], C22[n][n];\n    double S1[n][n], S2[n][n], S3[n][n], S4[n][n], S5[n][n], S6[n][n], S7[n][n];\n    double S8[n][n], S9[n][n], S10[n][n], S11[n][n], S12[n][n], S13[n][n], S14[n][n];\n\n    for (row = 0, i = 0; row < n; row++, i++)\n    {\n        for (col = 0, j = 0; col < n; col++, j++)\n        {\n            x11[i][j] = *((X+row*m)+col);\n            y11[i][j] = *((Y+row*m)+col);\n        }\n        for (col = n, j = 0; col < m; col++, j++)\n        {\n            x12[i][j] = *((X+row*m)+col);\n            y12[i][j] = *((Y+row*m)+col);\n        }\n    }\n\n    for (row = n, i = 0; row < m; row++, i++)\n    {\n        for (col = 0, j = 0; col < n; col++, j++)\n        {\n            x21[i][j] = *((X+row*m)+col);\n            y21[i][j] = *((Y+row*m)+col);\n        }\n        for (col = n, j = 0; col < m; col++, j++)\n        {\n            x22[i][j] = *((X+row*m)+col);\n            y22[i][j] = *((Y+row*m)+col);\n        }\n    }\n\n    // Calculating P1\n    matAdd((double *)x11, (double *)x22, (double *)S1, n);\n    matAdd((double *)y11, (double *)y22, (double *)S2, n);\n    strassenMul((double *)S1, (double *)S2, (double *)P1, n);\n\n    // Calculating P2\n    matAdd((double *)x21, (double *)x22, (double *)S3, n);\n    strassenMul((double *)S3, (double *)y11, (double *)P2, n);\n\n    // Calculating P3\n    matSub((double *)y12, (double *)y22, (double *)S4, n);\n    strassenMul((double *)x11, (double *)S4, (double *)P3, n);\n\n    // Calculating P4\n    matSub((double *)y21, (double *)y11, (double *)S5, n);\n    strassenMul((double *)x22, (double *)S5, (double *)P4, n);\n\n    // Calculating P5\n    matAdd((double *)x11, (double *)x12, (double *)S6, n);\n    strassenMul((double *)S6, (double *)y22, (double *)P5, n);\n\n    // Calculating P6\n    matSub((double *)x21, (double *)x11, (double *)S7, n);\n    matAdd((double *)y11, (double *)y12, (double *)S8, n);\n    strassenMul((double *)S7, (double *)S8, (double *)P6, n);\n\n    // Calculating P7\n    matSub((double *)x12, (double *)x22, (double *)S9, n);\n    matAdd((double *)y21, (double *)y22, (double *)S10, n);\n    strassenMul((double *)S9, (double *)S10, (double *)P7, n);\n\n    // Calculating C11\n    matAdd((double *)P1, (double *)P4, (double *)S11, n);\n    matSub((double *)S11, (double *)P5, (double *)S12, n);\n    matAdd((double *)S12, (double *)P7, (double *)C11, n);\n\n    // Calculating C12\n    matAdd((double *)P3, (double *)P5, (double *)C12, n);\n\n    // Calculating C21\n    matAdd((double *)P2, (double *)P4, (double *)C21, n);\n\n    // Calculating C22\n    matAdd((double *)P1, (double *)P3, (double *)S13, n);\n    matSub((double *)S13, (double *)P2, (double *)S14, n);\n    matAdd((double *)S14, (double *)P6, (double *)C22, n);\n\n    for (row = 0, i = 0; row < n; row++, i++)\n    {\n        for (col = 0, j = 0; col < n; col++, j++)\n            *((Z+row*m)+col) = C11[i][j];\n        for (col = n, j = 0; col < m; col++, j++)\n            *((Z+row*m)+col) = C12[i][j];\n    }\n    for (row = n, i = 0; row < m; row++, i++)\n    {\n        for (col = 0, j = 0; col < n; col++, j++)\n            *((Z+row*m)+col) = C21[i][j];\n        for (col = n, j = 0; col < m; col++, j++)\n            *((Z+row*m)+col) = C22[i][j];\n    }\n}\n\nvoid matMul(double *A, double *B, double *C, int n)\n{\n    int i = 0, j = 0, k = 0, row = 0, col = 0;\n    double sum;\n    for (i = 0; i < n; i++)\n    {\n        for (j = 0; j < n; j++)\n        {\n            sum = 0.0;\n            for (k = 0; k < n; k++)\n            {\n                sum += *((A+i*n)+k) * *((B+k*n)+j);\n            }\n            *((C+i*n)+j) = sum;\n        }\n    }\n}\n\nvoid matAdd(double *A, double *B, double *C, int m)\n{\n    int row = 0, col = 0;\n    for (row = 0; row < m; row++)\n        for (col = 0; col < m; col++)\n            *((C+row*m)+col) = *((A+row*m)+col) + *((B+row*m)+col);\n}\n\nvoid matSub(double *A, double *B, double *C, int m)\n{\n    int row = 0, col = 0;\n    for (row = 0; row < m; row++)\n        for (col = 0; col < m; col++)\n            *((C+row*m)+col) = *((A+row*m)+col) - *((B+row*m)+col);\n}\n```\n\n\nAdded later If I try using malloc statements for memory assignment, the code is as follows. But the problem is that it stops after the naive matrix multiplication method and does not even proceed to the Strassen's method for N=1. It shows a prompt to close the program.\n\n```\nfor (count = 0; count < total; count++)\n{\n    N = pow(2, count);\n    printf(\"Matrix size = %2d\\t\",N);\n    //double X[N][N], Y[N][N], Z[N][N], W[N][N];\n    double **X, **Y, **Z, **W;\n    X = malloc(N * sizeof(double*));\n    if (X == NULL){\n        perror(\"Failed malloc() in X\");\n        return 1;\n    }\n    Y = malloc(N * sizeof(double*));\n            if (Y == NULL){\n                perror(\"Failed malloc() in Y\");\n                return 1;\n    }\n    Z = malloc(N * sizeof(double*));\n            if (Z == NULL){\n                perror(\"Failed malloc() in Z\");\n                return 1;\n    }\n    W = malloc(N * sizeof(double*));\n            if (W == NULL){\n                perror(\"Failed malloc() in W\");\n                return 1;\n    }\n    for (j = 0; j < N; j++)\n    {\n        X[j] = malloc(N * sizeof(double*));\n        if (X[j] == NULL){\n            perror(\"Failed malloc() in X[j]\");\n            return 1;\n        }\n        Y[j] = malloc(N * sizeof(double*));\n                    if (Y[j] == NULL){\n                        perror(\"Failed malloc() in Y[j]\");\n                        return 1;\n        }\n        Z[j] = malloc(N * sizeof(double*));\n                    if (Z[j] == NULL){\n                        perror(\"Failed malloc() in Z[j]\");\n                        return 1;\n        }\n        W[j] = malloc(N * sizeof(double*));\n                    if (W[j] == NULL){\n                        perror(\"Failed malloc() in W[j]\");\n                        return 1;\n        }\n    }\n    srand(time(NULL));\n    for (i = 0; i < N; i++)\n    {\n        for (j = 0; j < N; j++)\n        {\n            X[i][j] = rand()/(RAND_MAX + 1.);\n            Y[i][j] = rand()/(RAND_MAX + 1.);\n        }\n    }\n    start = clock();\n    matMul((double *)X, (double *)Y, (double *)W, N);\n    end = clock();\n    elapsed = ((double) (end - start))*100/ CLOCKS_PER_SEC;\n    tnaive[count] = elapsed;\n    printf(\"naive = %5.4f\\t\\t\",tnaive[count]);\n\n    start = clock();\n    strassenMul((double *)X, (double *)Y, (double *)Z, N);\n    end = clock();\n    elapsed = ((double) (end - start))*100/ CLOCKS_PER_SEC;\n    tstrassen[count] = elapsed;\n    for (j = 0; j < N; j++)\n    {\n        free(X[j]);\n        free(Y[j]);\n        free(Z[j]);\n        free(W[j]);\n    }\n\n    free(X); free(Y); free(Z); free(W);\n\n    printf(\"strassen = %5.4f\\n\",tstrassen[count]);\n}\n```\n\n    ", "Answer": "\r\nI have re-written the answer. My previous answer which allocated memory row by row won't work, because OP has cast the 2-D arrays to 1-D arrays when passed to the functions. Here is my re-write of the code with some simplifications, such as keeping all the matrix arrays 1-dimensional.\n\nI am unsure exactly what Strassen's method does, although the recursion halves the matrix dimensions. So I do wonder if the intention was to use ```\nrow*2```\n and ```\ncol*2```\n when accessing the arrays passed.\n\nI hope the techniques are useful to you - even that it works! All the matrix arrays are now on the heap.\n\n```\n#include<stdio.h>\n#include<stdlib.h>\n#include<math.h>\n#include<time.h>\n\n#define total   4       //15\n\nvoid strassenMul(double* X, double* Y, double* Z, int m);\nvoid matMul(double* A, double* B, double* C, int n);\nvoid matAdd(double* A, double* B, double* C, int m);\nvoid matSub(double* A, double* B, double* C, int m);\n\nenum array { x11, x12, x21, x22, y11, y12, y21, y22,\n    P1, P2, P3, P4, P5, P6, P7, C11, C12, C21, C22,\n    S1, S2, S3, S4, S5, S6, S7, S8, S9, S10, S11, S12, S13, S14, arrs };\n\nint idx = 0;\n\nint main()\n{\n    int N;\n    int count = 0;\n    int i, j;\n    clock_t start, end;\n    double elapsed;\n\n    double tnaive[total];\n    double tstrassen[total];\n    double *X, *Y, *Z, *W, *A, *B, *C;\n\n    printf(\"-------------------------------------------------------------------------\\n\\n\");\n    for (count = 0; count < total; count++)\n    {\n        N = (int)pow(2, count);\n        printf(\"Matrix size = %2d\\t\",N);\n        X = malloc(N*N*sizeof(double));\n        Y = malloc(N*N*sizeof(double));\n        Z = malloc(N*N*sizeof(double));\n        W = malloc(N*N*sizeof(double));\n        if (X==NULL || Y==NULL || Z==NULL || W==NULL) {\n            printf(\"Out of memory (1)\\n\");\n            return 1;\n        }\n        srand((unsigned)time(NULL));\n        for (i=0; i<N*N; i++)\n        {\n            X[i] = rand()/(RAND_MAX + 1.);\n            Y[i] = rand()/(RAND_MAX + 1.);\n        }\n        start = clock();\n        matMul(X, Y, W, N);\n        end = clock();\n        elapsed = ((double) (end - start))*100/ CLOCKS_PER_SEC;\n        tnaive[count] = elapsed;\n        printf(\"naive = %5.4f\\t\\t\",tnaive[count]);\n\n        start = clock();\n        strassenMul(X, Y, Z, N);\n        free(W); \n        free(Z); \n        free(Y); \n        free(X); \n        end = clock();\n        elapsed = ((double) (end - start))*100/ CLOCKS_PER_SEC;\n        tstrassen[count] = elapsed;\n        printf(\"strassen = %5.4f\\n\",tstrassen[count]);\n    }\n    printf(\"-------------------------------------------------------------------\\n\\n\\n\");\n\n    while (tnaive[idx+1] <= tstrassen[idx+1] && idx < 14) idx++;\n\n    printf(\"Optimum input size to switch from normal multiplication to Strassen's is above %d\\n\\n\", idx);\n\n    printf(\"Please enter the size of array as a power of 2\\n\");\n    scanf(\"%d\",&N);\n    A = malloc(N*N*sizeof(double));\n    B = malloc(N*N*sizeof(double));\n    C = malloc(N*N*sizeof(double));\n    if (A==NULL || B==NULL || C==NULL) {\n        printf(\"Out of memory (2)\\n\");\n        return 1;\n    }\n    srand((unsigned)time(NULL));\n    for (i=0; i<N*N; i++)\n    {\n        A[i] = rand()/(RAND_MAX + 1.);\n        B[i] = rand()/(RAND_MAX + 1.);\n    }\n\n    printf(\"------------------- Input Matrices A and B ---------------------------\\n\\n\");\n    for (i = 0; i < N; i++)\n    {\n        for (j = 0; j < N; j++)\n            printf(\"%5.4f  \",A[i*N+j]);\n        printf(\"\\n\");\n    }\n    printf(\"\\n\");\n\n    for (i = 0; i < N; i++)\n    {\n        for (j = 0; j < N; j++)\n            printf(\"%5.4f  \",B[i*N+j]);\n        printf(\"\\n\");\n    }\n    printf(\"\\n------- Output matrix by Strassen's method after optimization -----------\\n\\n\");\n\n    strassenMul(A, B, C, N);\n\n    for (i = 0; i < N; i++)\n    {\n        for (j = 0; j < N; j++)\n            printf(\"%5.4f  \",C[i*N+j]);\n        printf(\"\\n\");\n    }\n    free(C); \n    free(B); \n    free(A); \n    return(0);\n}\n\nvoid strassenMul(double *X, double *Y, double *Z, int m)\n{\n    int row = 0, col = 0;\n    int n = m/2;\n    int i = 0, j = 0;\n    double *arr[arrs];                      // each matrix mem ptr\n\n    if (m <= idx)\n    {\n        matMul(X, Y, Z, m);\n        return;\n    }\n    if (m == 1)\n    {\n        *Z = *X * *Y;\n        return;\n    }\n\n    for (i=0; i<arrs; i++) {                // memory for arrays\n        arr[i] = malloc(n*n*sizeof(double));\n        if (arr[i] == NULL) {\n            printf(\"Out of memory (1)\\n\");\n            exit (1);                       // brutal\n        }\n    }\n\n    for (row = 0, i = 0; row < n; row++, i++)\n    {\n        for (col = 0, j = 0; col < n; col++, j++)\n        {\n            arr[x11][i*n+j] = X[row*m+col];\n            arr[y11][i*n+j] = Y[row*m+col];\n        }\n        for (col = n, j = 0; col < m; col++, j++)\n        {\n            arr[x12][i*n+j] = X[row*m+col];\n            arr[y12][i*n+j] = Y[row*m+col];\n        }\n    }\n\n    for (row = n, i = 0; row < m; row++, i++)\n    {\n        for (col = 0, j = 0; col < n; col++, j++)\n        {\n            arr[x21][i*n+j] = X[row*m+col];\n            arr[y21][i*n+j] = Y[row*m+col];\n        }\n        for (col = n, j = 0; col < m; col++, j++)\n        {\n            arr[x22][i*n+j] = X[row*m+col];\n            arr[y22][i*n+j] = Y[row*m+col];\n        }\n    }\n\n    // Calculating P1\n    matAdd(arr[x11], arr[x22], arr[S1], n);\n    matAdd(arr[y11], arr[y22], arr[S2], n);\n    strassenMul(arr[S1], arr[S2], arr[P1], n);\n\n    // Calculating P2\n    matAdd(arr[x21], arr[x22], arr[S3], n);\n    strassenMul(arr[S3], arr[y11], arr[P2], n);\n\n    // Calculating P3\n    matSub(arr[y12], arr[y22], arr[S4], n);\n    strassenMul(arr[x11], arr[S4], arr[P3], n);\n\n    // Calculating P4\n    matSub(arr[y21], arr[y11], arr[S5], n);\n    strassenMul(arr[x22], arr[S5], arr[P4], n);\n\n    // Calculating P5\n    matAdd(arr[x11], arr[x12], arr[S6], n);\n    strassenMul(arr[S6], arr[y22], arr[P5], n);\n\n    // Calculating P6\n    matSub(arr[x21], arr[x11], arr[S7], n);\n    matAdd(arr[y11], arr[y12], arr[S8], n);\n    strassenMul(arr[S7], arr[S8], arr[P6], n);\n\n    // Calculating P7\n    matSub(arr[x12], arr[x22], arr[S9], n);\n    matAdd(arr[y21], arr[y22], arr[S10], n);\n    strassenMul(arr[S9], arr[S10], arr[P7], n);\n\n    // Calculating C11\n    matAdd(arr[P1], arr[P4], arr[S11], n);\n    matSub(arr[S11], arr[P5], arr[S12], n);\n    matAdd(arr[S12], arr[P7], arr[C11], n);\n\n    // Calculating C12\n    matAdd(arr[P3], arr[P5], arr[C12], n);\n\n    // Calculating C21\n    matAdd(arr[P2], arr[P4], arr[C21], n);\n\n    // Calculating C22\n    matAdd(arr[P1], arr[P3], arr[S13], n);\n    matSub(arr[S13], arr[P2], arr[S14], n);\n    matAdd(arr[S14], arr[P6], arr[C22], n);\n\n    for (row = 0, i = 0; row < n; row++, i++)\n    {\n        for (col = 0, j = 0; col < n; col++, j++)\n            Z[row*m+col] = arr[C11][i*n+j];\n        for (col = n, j = 0; col < m; col++, j++)\n            Z[row*m+col] = arr[C12][i*n+j];\n    }\n    for (row = n, i = 0; row < m; row++, i++)\n    {\n        for (col = 0, j = 0; col < n; col++, j++)\n            Z[row*m+col] = arr[C21][i*n+j];\n        for (col = n, j = 0; col < m; col++, j++)\n            Z[row*m+col] = arr[C22][i*n+j];\n    }\n\n    for (i=0; i<arrs; i++)\n        free (arr[i]);\n}\n\nvoid matMul(double *A, double *B, double *C, int n)\n{\n    int i = 0, j = 0, k = 0, row = 0, col = 0;\n    double sum;\n    for (i = 0; i < n; i++)\n    {\n        for (j = 0; j < n; j++)\n        {\n            sum = 0.0;\n            for (k = 0; k < n; k++)\n            {\n                sum += A[i*n+k] * B[k*n+j];\n            }\n            C[i*n+j] = sum;\n        }\n    }\n}\n\nvoid matAdd(double *A, double *B, double *C, int m)\n{\n    int row = 0, col = 0;\n    for (row = 0; row < m; row++)\n        for (col = 0; col < m; col++)\n            C[row*m+col] = A[row*m+col] + B[row*m+col];\n}\n\nvoid matSub(double *A, double *B, double *C, int m)\n{\n    int row = 0, col = 0;\n    for (row = 0; row < m; row++)\n        for (col = 0; col < m; col++)\n            C[row*m+col] = A[row*m+col] - B[row*m+col];\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "how to overload Times and Plus for matrix multiplication in mathematica\r\n                \r\nI want to overload ```\nTimes```\n and ```\nPlus```\n for matrix multiplication in mathematica, for example, let ```\nTimes```\n be ```\nBitAnd```\n, and Plus be ```\nBitOr```\n, then do the matrix multiplication.\n\nIs there anyway to do this in a simple way, without rewriting my own matrix multiplication?\n\nThanks.\n    ", "Answer": "\r\nThe question is what you want to alter - the behavior of ```\nTimes```\n and ```\nPlus```\n, or ```\nDot```\n. Generally, ```\nBlock```\n trick is often the simplest way. In this case, since ```\nDot```\n does not call high-level ```\nPlus```\n or ```\nTimes```\n, you can do:\n\n```\nmat1 = {{1,2},{3,4}};\nmat2= {{5,6},{7,8}};\nBlock[{Dot = Inner[BitAnd,#1,#2,BitOr]&},\n  mat1.mat2]\n\n{{3,0},{5,2}}\n```\n\n\nBut note that this is effectively re-implementing the matrix multiplication (using ```\nInner```\n) - there is no other way since ```\nDot```\n is implemented internally and does not use ```\nPlus```\n or ```\nTimes```\n.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication optimization\r\n                \r\nI am performing a series of matrix multiplications with fairly large matrices. To run through all of these operations takes a long time, and I need my program to do this in a large loop. I was wondering if anyone has any ideas to speed this up? I just started using Eigen, so I have very limited knowledge.\n\nI was using ROOT-cern's built in TMatrix class, but the speed for performing the matrix operations is very poor. I set up some diagonal matrices using Eigen with the hope that it handled the multiplication operation in a more optimal way. It may, but I cannot really see the performance difference.\n\n```\n// setup matrices\nint size = 8000;\n\nEigen::MatrixXf a(size*2,size);\n\n// fill matrix a....\n\nEigen::MatrixXf r(2*size,2*size); // diagonal matrix of row sums of a\n\n// fill matrix r\n\nEigen::MatrixXf c(size,size); // diagonal matrix of col sums of a\n\n// fill matrix c\n\n// transpose a in place\na.transposeInPlace();\n\nEigen::MatrixXf c_dia;\nc_dia = c.diagonal().asDiagonal();\n\nEigen::MatrixXf r_dia;\nr_dia = r.diagonal().asDiagonal();\n\n// calc car\nEigen::MatrixXf car;\ncar = c_dia*a*r_dia;\n```\n\n    ", "Answer": "\r\nYou are doing way too much work here. If you have diagonal matrices, only store the diagonal (and directly use that for products). Once you store a diagonal matrix in a square matrix, the information of the structure is lost to Eigen.\n\nAlso, you don't need to store the transposed variant of ```\na```\n, just use ```\na.transpose()```\n inside a product (that is only a minor issue here ...)\n\n```\n// setup matrices\nint size = 8000;\n\nEigen::MatrixXf a(size*2,size);\n\n// fill matrix a....\na.setRandom();\n\nEigen::VectorXf r = a.rowwise().sum(); // diagonal matrix of row sums of a\nEigen::VectorXf c = a.colwise().sum(); // diagonal matrix of col sums of a\n\nEigen::MatrixXf car = c.asDiagonal() * a.transpose() * r.asDiagonal();\n```\n\n\nFinally, of course make sure to compile with optimization enabled, and enable vectorization if available (with gcc or clang compile with ```\n-O2 -march=native```\n).\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Increasing the Data Locality in Matrix Multiplication\r\n                \r\nIn matrix multiplication we do something like this\n\n```\n for (i = 0; i < N; i = i + 1)\n   for (j = 0; j < N; j = j + 1)\n      A[i*N + j] = (double) random() / SOME_NUMBER;     \n\n for (i = 0; i < N; i = i + 1)\n    for (j = 0; j < N; j = j + 1)\n       B[i*N + j] = (double) random() / SOME_NUMBER;\n\n\n for (i = 0; i < N; i = i + 1)\n    for (j = 0; j < N; j = j + 1)\n       for (k = 0; k < N; k = k + 1)\n            C[i*N + j] = C[i*N + j] + A[i*N + k]*B[k*N + j];\n```\n\n\nHow can we increase the locality of data to optimize the multiplication loop\n    ", "Answer": "\r\nStore B in transposed form: \n\n```\nB[j*N + i] = ramdom() / SOME_NUMBER;\n```\n\n\nYou'll also have to access the transposed array in that order:\n\n```\nC[i*N + j] = C[i*N + j] + A[i*N + k]*B[j*N + k];\n```\n\n\nIf that's not possible, rewrite the multiplication to loop on j first, then rewrite the first product of column j of B (with row 0 of A) to extract the elements of B[*;j] into a sequential N-vector, and use that sequential copy throughout the rest of the products for that column. \n\nThe idea is to get the columns of B into consecutive memory words.  The transpose does that, very naturally, but it may not be practical to keep in that format.  (For example, if B is later multiplied on the right, then the original order works better.  The second suggestion keeps a copy of one column into an array of consecutive words, while computing an one sum of products to make full use of the memory reads on that copy.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "compute only diagonals of matrix multiplication in R\r\n                \r\nI need only the diagonal elements from a matrix multiplication:\n\n,\n\nin R. As Z is huge I want to avoid the full out multiplication....\n\n```\nZ <- matrix(c(1,1,1,2,3,4), ncol = 2)\nZ\n#     [,1] [,2]\n#[1,]    1    2\n#[2,]    1    3\n#[3,]    1    4\n\nX <- matrix(c(10,-5,-5,20), ncol = 2)\nX\n#     [,1] [,2]\n#[1,]   10   -5\n#[2,]   -5   20\n\nZ %*% D %*% t(Z)\n#     [,1] [,2] [,3]\n#[1,]   70  105  140\n#[2,]  105  160  215\n#[3,]  140  215  290\n\ndiag(Z %*% D %*% t(Z))\n#[1]  70 160 290\n```\n\n\nX is always a small square matrix (2x2 , 3x3 or 4x4), where Z will have the number of columns equal to the dimension of X. Is there a function available to do this?\n    ", "Answer": "\r\nI don't think you can avoid the first matrix multiplication (i.e. ```\nZX```\n), but you can the second one, which is the expensive one:\n\n```\nrowSums((Z %*% X) * Z)\n# [1]  70 160 290\n```\n\n\nThe second multiplication is NOT a matrix multiply.  This is much faster:\n\n```\nlibrary(microbenchmark)\nset.seed(1)\nX <- matrix(c(10,-5,-5,20), ncol = 2)\nZ <- matrix(sample(1:1000), ncol=2)    # made Z a little bigger    \n\nmicrobenchmark(\n  res.new <- rowSums((Z %*% X) * Z),   # this solution\n  res.old <- diag(Z %*% X %*% t(Z))    # original method\n)\n# Unit: microseconds\n#                               expr     min      lq       mean   median        uq       max neval\n#  res.new <- rowSums((Z %*% X) * Z)  20.956  23.233   34.77693  29.6150   44.0025    67.852   100\n#  res.old <- diag(Z %*% X %*% t(Z)) 571.214 699.247 1761.08885 760.4295 1188.4485 47488.543   100     \n\nall.equal(res.new, res.old)\n# [1] TRUE\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication Error in Java\r\n                \r\ni search the net and there is a lot of error like mine. But i cant find the exact solution for matrix multiplication. I use below code for it. i have a lot of matrix multiplication. First i get tranpose of matris A which is ATP. then multiply with P like\n\nn1=ATP*P;\n\nthen multiply n1 with A.\n\nN1=n1*A;\n\nWhen using below code i get right solution i check it with matlab. but multiplication of n1 and A gives error. \n\nP matrix like P={{100,0,0,0...}{0,100,0,0...},......{...0,0,100}}\n\nWhat is the problem?\n\nThanks a lot.\n\n```\n public static double[][] multiply(double[][] a, double[][] b) {\n\n    int rowsa = a.length;\n    int columnsa = a[0].length;\n    int rowsb = b.length;\n    int columnsb = b[0].length;\n    double c[][] = new double[rowsa][columnsb];\n\n    try {\n\n        if (columnsa == rowsb) {\n\n            for (int ii = 0; ii < rowsa; ii++) {\n                for (int jj = 0; jj < columnsb; jj++) {\n                    c[ii][jj] = 0;\n                    for (int kk = 0; kk < rowsb; kk++) {\n                        c[ii][jj] += a[ii][kk] * b[kk][jj];\n                    }\n                }\n            }\n\n        } else {\n\n        }\n    } catch (Exception e) {\n        System.out.println(\"Matris is empty\");\n    }\n\n    return c;\n}\n```\n\n\nI call the code like \n\n```\n        double ATP[][] = transpose(A);\n        double n1[][] = multiply(ATP, PP);\n        double N1[][] = multiply(n1, A);\n        double n2[][] = multiply(n1, ll);\n        double N11[][] = inverse(N1);\n        double kats[][] = multiply(N11, n2);\n```\n\n\ni cant give values of A because it is changeable i read time and according to time i calculate tle elements of matrix. Every step add a row to A matrix.it starts with A(4,56)and continue like A(5,56)\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Efficient complex matrix-matrix multiplication: matrix shapes and memory\r\n                \r\nIn my code the deepest loop level contains a BLAS routine for matrix-matrix multiplication. Since this operation is the most expensive operation (regarding computation time) I would like to know what is important to make a matrix-matrix multiplication with complex matrix elements as fast as possible?\n\nI use Fortran with ScaLAPACK. I will use the CGEMM routine.\n\nI have the following specific questions:\n\n\nIs it important how the matrices are stored in memory? At the moment, I work with a three dimensional arrays where one index is fixed in each loop cycle such that the three-dimensional arrays reduces to two-dimensional matrices. But I have the feeling that this is innefficient since then the matrix elements aren't physically close together in memory. So, is it better to copy my matrix elemts into a temporary two-dimensional array to pass it to CGEMM?\nIn Fortran the first array index is the fastest index. Is there an optimal way how the arrays (matrices) should be shaped in order to achieve fast matrix multiplications? For example I have to perform matrix multiplications A*B where A is a complex 200x4000 matrix and B is a complex 4000x50 matrix. So should I better create A as a 4000x200 array since then the \"large\" index is the fastes index? Of course then I have to tell CGEMM that A needs to be transposed in order to obtain correct results.\nAre there any well know pitfalls in unsing BLAS routines for matrix-matrix multiplications? I know this is a very general question, but maybe someone knows a good document where some DOs and DONTs are summarized.\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Sparse matrix-matrix multiplication in CUDA using cuSPARSE\r\n                \r\nI'm benchmarking the sparse matrix-matrix multiplication on Nvidia K40 using ```\ncuSPARSE```\n library.\nI'm creating my own sparse matrix in ```\nCSR```\n format and I'm using the ```\ncusparseXcsrgemmNnz```\n routine of the ```\ncuSPARSE```\n library.\nHowever, as I increase the data size, an error occurs when calling ```\ncusparseXcsrgemmNnz```\n, i.e ```\nCUSPARSE_STATUS_SUCCESS```\n is not returned.\nAlso a ```\ncudaMemcpy```\n fails and ```\nCUDA_SUCCESS```\n is not returned.\nThe code works fine for ```\n8 x 8```\n and ```\n16 x 16```\n matrices. However, from ```\n32 x 32```\n on, this error is observed.\n\nEdit: I'm receiving ```\nCUSPARSE_STATUS_EXECUTION_FAILED```\n from ```\ncusparseXcsrgemmNnz```\n for the third matrix size. The execution happens correctly for the first two matrix sizes. \n\n```\n#include <cusparse_v2.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n\n// error check macros\n#define CUSPARSE_CHECK(x) {cusparseStatus_t _c=x; if (_c != CUSPARSE_STATUS_SUCCESS) {printf(\"cusparse fail: %d, line: %d\\n\", (int)_c, __LINE__); exit(-1);}}\n\n#define cudaCheckErrors(msg) \\\ndo { \\\n    cudaError_t __err = cudaGetLastError(); \\\n    if (__err != cudaSuccess) { \\\n        fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", \\\n            msg, cudaGetErrorString(__err), \\\n            __FILE__, __LINE__); \\\n        fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n        exit(1); \\\n    } \\\n} while (0)\n\n\ndouble timerval()\n{\n    struct timeval st;\n    gettimeofday(&st, NULL);\n    return (st.tv_sec+st.tv_usec*1e-6);\n}\n\n// perform sparse-matrix multiplication C=AxB\nint main(){ \ndouble avg_time = 0, s_time, e_time;\n\ncusparseStatus_t stat;\ncusparseHandle_t hndl;\ncusparseMatDescr_t descrA, descrB, descrC;\nint *csrRowPtrA, *csrRowPtrB, *csrRowPtrC, *csrColIndA, *csrColIndB, *csrColIndC;\nint *h_csrRowPtrA, *h_csrRowPtrB, *h_csrRowPtrC, *h_csrColIndA, *h_csrColIndB, *h_csrColIndC,*pos;\nfloat *csrValA, *csrValB, *csrValC, *h_csrValA, *h_csrValB, *h_csrValC;\nint nnzA, nnzB, nnzC;\nint m=4,n,k,loop;\nint i,j;\nint iterations;\nfor (iterations=0;iterations<10;iterations++)\n{\n    m *=2;\n    n = m;\n    k = m;\n    //density of the sparse matrix to be created. Assume 5% density.\n    double dense_const = 0.05;\n    int temp5, temp6,temp3,temp4;\n    int density=(m*n)*(dense_const);\n    nnzA = density;\n    nnzB = density;\n    h_csrRowPtrA = (int *)malloc((m+1)*sizeof(int));\n    h_csrRowPtrB = (int *)malloc((n+1)*sizeof(int));\n    h_csrColIndA = (int *)malloc(density*sizeof(int));\n    h_csrColIndB = (int *)malloc(density*sizeof(int));\n    h_csrValA  = (float *)malloc(density*sizeof(float));\n    h_csrValB  = (float *)malloc(density*sizeof(float));\n    if ((h_csrRowPtrA == NULL) || (h_csrRowPtrB == NULL) || (h_csrColIndA == NULL) || (h_csrColIndB == NULL) || (h_csrValA == NULL) || (h_csrValB == NULL))\n    {printf(\"malloc fail\\n\"); return -1;}\n\n    //position array for random initialisation of positions in input matrix\n    pos= (int *)calloc((m*n), sizeof(int));\n    int temp,temp1;\n\n    //  printf(\"the density is %d\\n\",density);\n    //  printf(\"check 1:\\n\");\n\n    //randomly initialise positions\n    for(i=0;i<density;i++)\n    {\n        temp1=rand()%(m*n);\n        pos[i]=temp1;\n\n    }\n    //  printf(\"check 2:\\n\");\n\n    //sort the 'pos' array\n    for (i = 0 ; i < density; i++) {\n        int d = i;\n        int t;\n\n        while ( d > 0 && pos[d] < pos[d-1]) {\n            t          = pos[d];\n            pos[d]   = pos[d-1];\n            pos[d-1] = t;        \n            d--;\n        }\n    }\n    // initialise with non zero elements and extract column and row ptr vector\n    j=1;\n    //ja[0]=1;\n\n    int p=0;\n    int f=0;\n\n    for(i = 0; i < density; i++)\n    {\n        temp=pos[i];\n         h_csrValA[f] = rand();\n         h_csrValB[f] = rand();\n         h_csrColIndA[f] = temp%m;\n         h_csrColIndB[f] = temp%m;\n        f++;\n        p++;\n        temp5= pos[i];\n        temp6=pos[i+1];\n        temp3=temp5-(temp5%m);\n        temp4=temp6-(temp6%m);\n\n        if(!(temp3== temp4))\n        {   \n            if((temp3+m==temp6))\n            {}\n            else    \n            {   \n                h_csrRowPtrA[j]=p;\n                h_csrRowPtrB[j]=p;\n                j++;\n            }\n\n        }       \n    }\n\n    // transfer data to device\n\n    cudaMalloc(&csrRowPtrA, (m+1)*sizeof(int));\n    cudaMalloc(&csrRowPtrB, (n+1)*sizeof(int));\n    cudaMalloc(&csrColIndA, density*sizeof(int));\n    cudaMalloc(&csrColIndB, density*sizeof(int));\n    cudaMalloc(&csrValA, density*sizeof(float));\n    cudaMalloc(&csrValB, density*sizeof(float));\n    cudaCheckErrors(\"cudaMalloc fail\");\n    cudaMemcpy(csrRowPtrA, h_csrRowPtrA, (m+1)*sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(csrRowPtrB, h_csrRowPtrB, (n+1)*sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(csrColIndA, h_csrColIndA, density*sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(csrColIndB, h_csrColIndB, density*sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(csrValA, h_csrValA, density*sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(csrValB, h_csrValB, density*sizeof(float), cudaMemcpyHostToDevice);\n    cudaCheckErrors(\"cudaMemcpy fail\");\n\n    // set cusparse matrix types\n    CUSPARSE_CHECK(cusparseCreate(&hndl));\n    stat = cusparseCreateMatDescr(&descrA);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseCreateMatDescr(&descrB);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseCreateMatDescr(&descrC);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatType(descrA, CUSPARSE_MATRIX_TYPE_GENERAL);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatType(descrB, CUSPARSE_MATRIX_TYPE_GENERAL);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatType(descrC, CUSPARSE_MATRIX_TYPE_GENERAL);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatIndexBase(descrA, CUSPARSE_INDEX_BASE_ZERO);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatIndexBase(descrB, CUSPARSE_INDEX_BASE_ZERO);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatIndexBase(descrC, CUSPARSE_INDEX_BASE_ZERO);\n    CUSPARSE_CHECK(stat);\n    cusparseOperation_t transA = CUSPARSE_OPERATION_NON_TRANSPOSE;\n    cusparseOperation_t transB = CUSPARSE_OPERATION_NON_TRANSPOSE;\n\n    // figure out size of C\n    int baseC;\n    // nnzTotalDevHostPtr points to host memory\n    int *nnzTotalDevHostPtr = &nnzC;\n    stat = cusparseSetPointerMode(hndl, CUSPARSE_POINTER_MODE_HOST);\n    CUSPARSE_CHECK(stat);\n    cudaMalloc((void**)&csrRowPtrC, sizeof(int)*(m+1));\n    cudaCheckErrors(\"cudaMalloc fail\");\n\n    s_time=timerval();\n\n    stat = cusparseXcsrgemmNnz(hndl, transA, transB, m, n, k,\n    descrA, nnzA, csrRowPtrA, csrColIndA,\n    descrB, nnzB, csrRowPtrB, csrColIndB,\n    descrC, csrRowPtrC, nnzTotalDevHostPtr );\n    CUSPARSE_CHECK(stat);\n    if (NULL != nnzTotalDevHostPtr){\n    nnzC = *nnzTotalDevHostPtr;}\n    else{\n    cudaMemcpy(&nnzC, csrRowPtrC+m, sizeof(int), cudaMemcpyDeviceToHost);\n    cudaMemcpy(&baseC, csrRowPtrC, sizeof(int), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy fail\");\n    nnzC -= baseC;}\n    cudaMalloc((void**)&csrColIndC, sizeof(int)*nnzC);\n    cudaMalloc((void**)&csrValC, sizeof(float)*nnzC);\n    cudaCheckErrors(\"cudaMalloc fail\");\n    // perform multiplication C = A*B\n\n    for(loop=0;loop<1000;loop++)\n    {\n        stat = cusparseScsrgemm(hndl, transA, transB, m, n, k,\n        descrA, nnzA,\n        csrValA, csrRowPtrA, csrColIndA,\n        descrB, nnzB,\n        csrValB, csrRowPtrB, csrColIndB,\n        descrC,\n        csrValC, csrRowPtrC, csrColIndC);\n        CUSPARSE_CHECK(stat);\n    }\n\n    e_time=timerval();\n\n    avg_time=avg_time/1000;\n    // copy result (C) back to host\n    h_csrRowPtrC = (int *)malloc((m+1)*sizeof(int));\n    h_csrColIndC = (int *)malloc(nnzC *sizeof(int));\n    h_csrValC  = (float *)malloc(nnzC *sizeof(float));\n    if ((h_csrRowPtrC == NULL) || (h_csrColIndC == NULL) || (h_csrValC == NULL))\n    {printf(\"malloc fail\\n\"); return -1;}\n    cudaMemcpy(h_csrRowPtrC, csrRowPtrC, (m+1)*sizeof(int), cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_csrColIndC, csrColIndC,  nnzC*sizeof(int), cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_csrValC, csrValC, nnzC*sizeof(float), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy fail\");\n\n    printf (\"\\n Input size: %d x %d ,Time: %lf and density is %d \\n\", m,n, avg_time, density); \n\n    cudaFree(csrRowPtrC);\n    cudaFree(csrColIndC);\n    cudaFree(csrValC);\n\n    cudaFree(csrRowPtrA);\n    cudaFree(csrColIndA);\n    cudaFree(csrValA);\n\n    cudaFree(csrRowPtrB);\n    cudaFree(csrColIndB);\n    cudaFree(csrValB);\n\n    free(h_csrRowPtrC);\n    free(h_csrColIndC);\n    free(h_csrValC);\n\n    free(h_csrRowPtrA);\n    free(h_csrColIndA);\n    free(h_csrValA);\n\n    free(h_csrRowPtrB);\n    free(h_csrColIndB);\n    free(h_csrValB);\n}\nreturn 0;\n```\n\n\n}\n    ", "Answer": "\r\nIt seems that you lifted some of this code from here\n\nAs indicated in that posting:\n\n\n  a failure in ```\ncusparseXcsrgemmNnz```\n could indicate an underlying problem in CSR matrix formatting.\n\n\nI'm quite sure that is the problem here.  Your process for generating a properly formatted CSR matrix is broken.\n\nTo prove this, add the following code immediately before the indicated comment in your posted code:\n\n```\nprintf(\"A RowPtrs: \\n\");\nfor (int i = 0; i < m+1; i++) printf(\"%d \", h_csrRowPtrA[i]);\nprintf(\"\\nA ColInds: \\n\");\nfor (int i = 0; i < nnzA; i++) printf(\"%d \", h_csrColIndA[i]);\nprintf(\"\\nB RowPtrs: \\n\");\nfor (int i = 0; i < n+1; i++) printf(\"%d \", h_csrRowPtrB[i]);\nprintf(\"\\nB ColInds: \\n\");\nfor (int i = 0; i < nnzB; i++) printf(\"%d \", h_csrColIndB[i]);\nprintf(\"\\n\");\n\n    // add the above code before this comment:\n    // transfer data to device\n```\n\n\nWhen I do that, recompile, and run, I get output that looks like this:\n\n```\n$ ./t730\nA RowPtrs:\n0 1 2 3 0 0 0 0 0\nA ColInds:\n6 7 1\nB RowPtrs:\n0 1 2 3 0 0 0 0 0\nB ColInds:\n6 7 1\n\n Input size: 8 x 8 ,Time: 0.000000 and density is 3\nA RowPtrs:\n0 1 2 3 4 5 6 8 9 12 959542853 1886614883 1702064737 1299346243 1918980205 1232301409 1766154068\nA ColInds:\n11 6 4 12 11 10 2 13 3 2 8 11\nB RowPtrs:\n-1688500168 1 2 3 4 5 6 8 9 12 0 0 0 0 0 0 0\nB ColInds:\n11 6 4 12 11 10 2 13 3 2 8 11\ncusparse fail: 6, line: 193\n```\n\n\nWe see that the first set of CSR-formatted ```\nA```\n and ```\nB```\n matrices up to and including the line that starts with ```\nInput size: 8 x 8...```\n seems to complete without error however the formatting is in fact broken.  Empty rows do not have their row pointer starting at zero (row pointers are not allowed to move backward), they have their row pointer starting at the last populated row (so that the number of nonzero elements per row is equal to the current row pointer minus the previous row pointer), and the last value in the row pointer sequence points to one element beyond the last element in the matrix (i.e. the last value in the CSR row-pointer array is nnz, the number of non-zero elements).\n\nThe next set of A and B matrices (corresponding to the 16x16 pass) are clearly broken.  At a minimum, you have row pointers in both the A and B CSR formatted matrices that are clearly out-of-range.\n\nYour code for creating CSR matrices is just broken.  I suggest you study CSR matrices and create a tool for validating any matrices that you are going to create randomly in this fashion.  CUSP has matrix validation functions, and I am sure there are other CSR matrix format validation functions you could use.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Sparse matrix-matrix multiplication in CUDA using cuSPARSE\r\n                \r\nI'm benchmarking the sparse matrix-matrix multiplication on Nvidia K40 using ```\ncuSPARSE```\n library.\nI'm creating my own sparse matrix in ```\nCSR```\n format and I'm using the ```\ncusparseXcsrgemmNnz```\n routine of the ```\ncuSPARSE```\n library.\nHowever, as I increase the data size, an error occurs when calling ```\ncusparseXcsrgemmNnz```\n, i.e ```\nCUSPARSE_STATUS_SUCCESS```\n is not returned.\nAlso a ```\ncudaMemcpy```\n fails and ```\nCUDA_SUCCESS```\n is not returned.\nThe code works fine for ```\n8 x 8```\n and ```\n16 x 16```\n matrices. However, from ```\n32 x 32```\n on, this error is observed.\n\nEdit: I'm receiving ```\nCUSPARSE_STATUS_EXECUTION_FAILED```\n from ```\ncusparseXcsrgemmNnz```\n for the third matrix size. The execution happens correctly for the first two matrix sizes. \n\n```\n#include <cusparse_v2.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n\n// error check macros\n#define CUSPARSE_CHECK(x) {cusparseStatus_t _c=x; if (_c != CUSPARSE_STATUS_SUCCESS) {printf(\"cusparse fail: %d, line: %d\\n\", (int)_c, __LINE__); exit(-1);}}\n\n#define cudaCheckErrors(msg) \\\ndo { \\\n    cudaError_t __err = cudaGetLastError(); \\\n    if (__err != cudaSuccess) { \\\n        fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", \\\n            msg, cudaGetErrorString(__err), \\\n            __FILE__, __LINE__); \\\n        fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n        exit(1); \\\n    } \\\n} while (0)\n\n\ndouble timerval()\n{\n    struct timeval st;\n    gettimeofday(&st, NULL);\n    return (st.tv_sec+st.tv_usec*1e-6);\n}\n\n// perform sparse-matrix multiplication C=AxB\nint main(){ \ndouble avg_time = 0, s_time, e_time;\n\ncusparseStatus_t stat;\ncusparseHandle_t hndl;\ncusparseMatDescr_t descrA, descrB, descrC;\nint *csrRowPtrA, *csrRowPtrB, *csrRowPtrC, *csrColIndA, *csrColIndB, *csrColIndC;\nint *h_csrRowPtrA, *h_csrRowPtrB, *h_csrRowPtrC, *h_csrColIndA, *h_csrColIndB, *h_csrColIndC,*pos;\nfloat *csrValA, *csrValB, *csrValC, *h_csrValA, *h_csrValB, *h_csrValC;\nint nnzA, nnzB, nnzC;\nint m=4,n,k,loop;\nint i,j;\nint iterations;\nfor (iterations=0;iterations<10;iterations++)\n{\n    m *=2;\n    n = m;\n    k = m;\n    //density of the sparse matrix to be created. Assume 5% density.\n    double dense_const = 0.05;\n    int temp5, temp6,temp3,temp4;\n    int density=(m*n)*(dense_const);\n    nnzA = density;\n    nnzB = density;\n    h_csrRowPtrA = (int *)malloc((m+1)*sizeof(int));\n    h_csrRowPtrB = (int *)malloc((n+1)*sizeof(int));\n    h_csrColIndA = (int *)malloc(density*sizeof(int));\n    h_csrColIndB = (int *)malloc(density*sizeof(int));\n    h_csrValA  = (float *)malloc(density*sizeof(float));\n    h_csrValB  = (float *)malloc(density*sizeof(float));\n    if ((h_csrRowPtrA == NULL) || (h_csrRowPtrB == NULL) || (h_csrColIndA == NULL) || (h_csrColIndB == NULL) || (h_csrValA == NULL) || (h_csrValB == NULL))\n    {printf(\"malloc fail\\n\"); return -1;}\n\n    //position array for random initialisation of positions in input matrix\n    pos= (int *)calloc((m*n), sizeof(int));\n    int temp,temp1;\n\n    //  printf(\"the density is %d\\n\",density);\n    //  printf(\"check 1:\\n\");\n\n    //randomly initialise positions\n    for(i=0;i<density;i++)\n    {\n        temp1=rand()%(m*n);\n        pos[i]=temp1;\n\n    }\n    //  printf(\"check 2:\\n\");\n\n    //sort the 'pos' array\n    for (i = 0 ; i < density; i++) {\n        int d = i;\n        int t;\n\n        while ( d > 0 && pos[d] < pos[d-1]) {\n            t          = pos[d];\n            pos[d]   = pos[d-1];\n            pos[d-1] = t;        \n            d--;\n        }\n    }\n    // initialise with non zero elements and extract column and row ptr vector\n    j=1;\n    //ja[0]=1;\n\n    int p=0;\n    int f=0;\n\n    for(i = 0; i < density; i++)\n    {\n        temp=pos[i];\n         h_csrValA[f] = rand();\n         h_csrValB[f] = rand();\n         h_csrColIndA[f] = temp%m;\n         h_csrColIndB[f] = temp%m;\n        f++;\n        p++;\n        temp5= pos[i];\n        temp6=pos[i+1];\n        temp3=temp5-(temp5%m);\n        temp4=temp6-(temp6%m);\n\n        if(!(temp3== temp4))\n        {   \n            if((temp3+m==temp6))\n            {}\n            else    \n            {   \n                h_csrRowPtrA[j]=p;\n                h_csrRowPtrB[j]=p;\n                j++;\n            }\n\n        }       \n    }\n\n    // transfer data to device\n\n    cudaMalloc(&csrRowPtrA, (m+1)*sizeof(int));\n    cudaMalloc(&csrRowPtrB, (n+1)*sizeof(int));\n    cudaMalloc(&csrColIndA, density*sizeof(int));\n    cudaMalloc(&csrColIndB, density*sizeof(int));\n    cudaMalloc(&csrValA, density*sizeof(float));\n    cudaMalloc(&csrValB, density*sizeof(float));\n    cudaCheckErrors(\"cudaMalloc fail\");\n    cudaMemcpy(csrRowPtrA, h_csrRowPtrA, (m+1)*sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(csrRowPtrB, h_csrRowPtrB, (n+1)*sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(csrColIndA, h_csrColIndA, density*sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(csrColIndB, h_csrColIndB, density*sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(csrValA, h_csrValA, density*sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(csrValB, h_csrValB, density*sizeof(float), cudaMemcpyHostToDevice);\n    cudaCheckErrors(\"cudaMemcpy fail\");\n\n    // set cusparse matrix types\n    CUSPARSE_CHECK(cusparseCreate(&hndl));\n    stat = cusparseCreateMatDescr(&descrA);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseCreateMatDescr(&descrB);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseCreateMatDescr(&descrC);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatType(descrA, CUSPARSE_MATRIX_TYPE_GENERAL);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatType(descrB, CUSPARSE_MATRIX_TYPE_GENERAL);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatType(descrC, CUSPARSE_MATRIX_TYPE_GENERAL);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatIndexBase(descrA, CUSPARSE_INDEX_BASE_ZERO);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatIndexBase(descrB, CUSPARSE_INDEX_BASE_ZERO);\n    CUSPARSE_CHECK(stat);\n    stat = cusparseSetMatIndexBase(descrC, CUSPARSE_INDEX_BASE_ZERO);\n    CUSPARSE_CHECK(stat);\n    cusparseOperation_t transA = CUSPARSE_OPERATION_NON_TRANSPOSE;\n    cusparseOperation_t transB = CUSPARSE_OPERATION_NON_TRANSPOSE;\n\n    // figure out size of C\n    int baseC;\n    // nnzTotalDevHostPtr points to host memory\n    int *nnzTotalDevHostPtr = &nnzC;\n    stat = cusparseSetPointerMode(hndl, CUSPARSE_POINTER_MODE_HOST);\n    CUSPARSE_CHECK(stat);\n    cudaMalloc((void**)&csrRowPtrC, sizeof(int)*(m+1));\n    cudaCheckErrors(\"cudaMalloc fail\");\n\n    s_time=timerval();\n\n    stat = cusparseXcsrgemmNnz(hndl, transA, transB, m, n, k,\n    descrA, nnzA, csrRowPtrA, csrColIndA,\n    descrB, nnzB, csrRowPtrB, csrColIndB,\n    descrC, csrRowPtrC, nnzTotalDevHostPtr );\n    CUSPARSE_CHECK(stat);\n    if (NULL != nnzTotalDevHostPtr){\n    nnzC = *nnzTotalDevHostPtr;}\n    else{\n    cudaMemcpy(&nnzC, csrRowPtrC+m, sizeof(int), cudaMemcpyDeviceToHost);\n    cudaMemcpy(&baseC, csrRowPtrC, sizeof(int), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy fail\");\n    nnzC -= baseC;}\n    cudaMalloc((void**)&csrColIndC, sizeof(int)*nnzC);\n    cudaMalloc((void**)&csrValC, sizeof(float)*nnzC);\n    cudaCheckErrors(\"cudaMalloc fail\");\n    // perform multiplication C = A*B\n\n    for(loop=0;loop<1000;loop++)\n    {\n        stat = cusparseScsrgemm(hndl, transA, transB, m, n, k,\n        descrA, nnzA,\n        csrValA, csrRowPtrA, csrColIndA,\n        descrB, nnzB,\n        csrValB, csrRowPtrB, csrColIndB,\n        descrC,\n        csrValC, csrRowPtrC, csrColIndC);\n        CUSPARSE_CHECK(stat);\n    }\n\n    e_time=timerval();\n\n    avg_time=avg_time/1000;\n    // copy result (C) back to host\n    h_csrRowPtrC = (int *)malloc((m+1)*sizeof(int));\n    h_csrColIndC = (int *)malloc(nnzC *sizeof(int));\n    h_csrValC  = (float *)malloc(nnzC *sizeof(float));\n    if ((h_csrRowPtrC == NULL) || (h_csrColIndC == NULL) || (h_csrValC == NULL))\n    {printf(\"malloc fail\\n\"); return -1;}\n    cudaMemcpy(h_csrRowPtrC, csrRowPtrC, (m+1)*sizeof(int), cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_csrColIndC, csrColIndC,  nnzC*sizeof(int), cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_csrValC, csrValC, nnzC*sizeof(float), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy fail\");\n\n    printf (\"\\n Input size: %d x %d ,Time: %lf and density is %d \\n\", m,n, avg_time, density); \n\n    cudaFree(csrRowPtrC);\n    cudaFree(csrColIndC);\n    cudaFree(csrValC);\n\n    cudaFree(csrRowPtrA);\n    cudaFree(csrColIndA);\n    cudaFree(csrValA);\n\n    cudaFree(csrRowPtrB);\n    cudaFree(csrColIndB);\n    cudaFree(csrValB);\n\n    free(h_csrRowPtrC);\n    free(h_csrColIndC);\n    free(h_csrValC);\n\n    free(h_csrRowPtrA);\n    free(h_csrColIndA);\n    free(h_csrValA);\n\n    free(h_csrRowPtrB);\n    free(h_csrColIndB);\n    free(h_csrValB);\n}\nreturn 0;\n```\n\n\n}\n    ", "Answer": "\r\nIt seems that you lifted some of this code from here\n\nAs indicated in that posting:\n\n\n  a failure in ```\ncusparseXcsrgemmNnz```\n could indicate an underlying problem in CSR matrix formatting.\n\n\nI'm quite sure that is the problem here.  Your process for generating a properly formatted CSR matrix is broken.\n\nTo prove this, add the following code immediately before the indicated comment in your posted code:\n\n```\nprintf(\"A RowPtrs: \\n\");\nfor (int i = 0; i < m+1; i++) printf(\"%d \", h_csrRowPtrA[i]);\nprintf(\"\\nA ColInds: \\n\");\nfor (int i = 0; i < nnzA; i++) printf(\"%d \", h_csrColIndA[i]);\nprintf(\"\\nB RowPtrs: \\n\");\nfor (int i = 0; i < n+1; i++) printf(\"%d \", h_csrRowPtrB[i]);\nprintf(\"\\nB ColInds: \\n\");\nfor (int i = 0; i < nnzB; i++) printf(\"%d \", h_csrColIndB[i]);\nprintf(\"\\n\");\n\n    // add the above code before this comment:\n    // transfer data to device\n```\n\n\nWhen I do that, recompile, and run, I get output that looks like this:\n\n```\n$ ./t730\nA RowPtrs:\n0 1 2 3 0 0 0 0 0\nA ColInds:\n6 7 1\nB RowPtrs:\n0 1 2 3 0 0 0 0 0\nB ColInds:\n6 7 1\n\n Input size: 8 x 8 ,Time: 0.000000 and density is 3\nA RowPtrs:\n0 1 2 3 4 5 6 8 9 12 959542853 1886614883 1702064737 1299346243 1918980205 1232301409 1766154068\nA ColInds:\n11 6 4 12 11 10 2 13 3 2 8 11\nB RowPtrs:\n-1688500168 1 2 3 4 5 6 8 9 12 0 0 0 0 0 0 0\nB ColInds:\n11 6 4 12 11 10 2 13 3 2 8 11\ncusparse fail: 6, line: 193\n```\n\n\nWe see that the first set of CSR-formatted ```\nA```\n and ```\nB```\n matrices up to and including the line that starts with ```\nInput size: 8 x 8...```\n seems to complete without error however the formatting is in fact broken.  Empty rows do not have their row pointer starting at zero (row pointers are not allowed to move backward), they have their row pointer starting at the last populated row (so that the number of nonzero elements per row is equal to the current row pointer minus the previous row pointer), and the last value in the row pointer sequence points to one element beyond the last element in the matrix (i.e. the last value in the CSR row-pointer array is nnz, the number of non-zero elements).\n\nThe next set of A and B matrices (corresponding to the 16x16 pass) are clearly broken.  At a minimum, you have row pointers in both the A and B CSR formatted matrices that are clearly out-of-range.\n\nYour code for creating CSR matrices is just broken.  I suggest you study CSR matrices and create a tool for validating any matrices that you are going to create randomly in this fashion.  CUSP has matrix validation functions, and I am sure there are other CSR matrix format validation functions you could use.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "MPI matrix multiplication\r\n                \r\nI'm trying to make an MPI matrix multiplication program but the scatter function doesn't seem to be working for me. Only one row is getting scattered and the rest of the cores receive garbage value.\n\nAlso when calling the display_matrix() function before I MPI_Init() seems to be running 4 threads instead of 1 (I have quad core CPU). Why is this happening even before initialisation?\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include<mpi.h>\n\nint **matrix_generator(int row,int col);\nint **multiply_matrices(int **matrix_A,int **matrix_B,int rowsA, int colsA,int rowsB,int colsB);\nvoid display_matrix(int **matrixA,int rows,int cols);\n\nvoid main(int argc,char *argv[])\n{\n    srand(time(0));\n\n    int **matrix_A,**matrix_B,**matrix_result,*scattered_matrix,*gathered_matrix, rowsA,colsA,rowsB,colsB,world_rank,world_size,i,j;\n\n    rowsA = atoi(argv[1]);\n    colsA = atoi(argv[2]);\n    rowsB = atoi(argv[3]);\n    colsB = atoi(argv[4]);\n\n    scattered_matrix = (int *)malloc(sizeof(int) * rowsA*colsA/4); \n\n    if (argc != 5)\n    {\n        fprintf(stderr,\"Usage: mpirun -np <No. of processors> ./a.out <Rows A> <Columns A> <Rows B> <Columns B>\\n\");\n        exit(-1);\n    }\n    else if(colsA != rowsB)\n    {\n        printf(\"Check the dimensions of the matrices!\\n\\n\");\n    }\n\n    matrix_A = matrix_generator(rowsA,colsA);\n    matrix_B = matrix_generator(rowsB,colsB);\n\n    display_matrix(matrix_A,rowsA,colsA);\n\n    MPI_Init(&argc, &argv);\n\n    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\n    MPI_Scatter(matrix_A, rowsA*colsA/4, MPI_INT, scattered_matrix, rowsA*colsA/4, MPI_INT, 0, MPI_COMM_WORLD);\n\n    for(i=0;i<world_size;i++)\n    {  \n        printf(\"Scattering data %d from root to: %d \\n\",scattered_matrix[i],world_rank);\n    }\n\n    MPI_Barrier(MPI_COMM_WORLD);\n\n    MPI_Finalize();\n}\n\nint **matrix_generator(int row, int col)\n{\n    int i, j, **intMatrix;\n\n    intMatrix = (int **)malloc(sizeof(int *) * row); \n\n    for (i = 0; i < row; i++)\n    {\n        intMatrix[i] = (int *)malloc(sizeof(int *) * col);\n        for (j = 0;j<col;j++)\n        {\n            intMatrix[i][j]=rand()%10;\n        }\n    }\n    return intMatrix;\n}\n\nvoid display_matrix(int **matrix, int rows,int cols)\n{\n    int i,j;\n    for (i = 0; i < rows; i = i + 1)\n    {\n        for (j = 0; j < cols; j = j + 1)\n            printf(\"%d \",matrix[i][j]);\n        printf(\"\\n\");\n    }\n}\n```\n\n    ", "Answer": "\r\nThe main issue is your matrices are not allocated in contiguous memory (see the comment section for a link)\n\nThe MPI standard does not specify what happens before an app invokes ```\nMPI_Init()```\n.\n\nThe two main MPI implementations choose to spawn all the tasks when ```\nmpirun```\n is invoked (that means there are 4 independent processes first, and they \"join\" into a single MPI job when they all call ```\nMPI_Init()```\n).\nThat being said, once upon a time, a vendor chose to have ```\nmpirun```\n start a single MPI task, and they use their own remote-fork when ```\nMPI_Init()```\n is called.\n\nBottom line, if you want to write portable code, do as less as possible (and never print anything) before ```\nMPI_Init()```\n is called.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Trouble with matrix multiplication model\r\n                \r\nFor the past few hours I have been trying to build a C++ module that, upon requesting the input of the user on the size and contents of 2 matrices (restricted to ones that can be multiplied together), then proceeds to multiply them together and return the values of a third answer matrix. While the matrix input commands seem to work based on thorough testing, I can't seem to get a correct answer from my multiplication command, despite going through each step of the algorithm and how it corresponds to actual matrix multiplication. The first value of the answer matrix is correct, and then all succeeding values are incorrect by some factor. Does anyone have any insight as to what could be going wrong?\n```\n#include <iostream>\n#include <cmath>\nusing namespace std;\n\nint r, c, a1, a2, b1, b2;  //defines row and column indices\ndouble m[1][1], m2[1][1], a[1][1];   //initializes matrices\ndouble b;\nint inflag = true;  \nint repflag = false;\n\nvoid defmatrix() {  //Defines the matrix size of the first inputted matrix\n    cout << \"Matrix Rows: \";\n    cin >> r;\n    cout << \"Matrix Columns: \";\n    cin >> c;\n    \n}\n\nvoid fillmatrix() {  //Fills the matrix with automatic or user-inputted values\n    if (inflag == true) {\n        for (int i = 0; i < r; i++) {\n            for (int j = 0; j < c; j++) {\n               cout << \"Number in row \" << i + 1 << \" and column \" << j + 1 << \": \";\n               cin >> b;\n               m[i][j] = b;\n            }\n        }\n    } else {\n        for (int i = 0; i < r; i++) {\n            for (int j = 0; j < c; j++) {\n               m[i][j] = 1;\n            }\n        }\n    }\n    for (int i = 0; i < r; i++) {\n        for (int j = 0; j < c; j++) {\n           cout << m[i][j] << \"   \";\n        }\n    }\n}\n\nvoid matrixmult() {  //Multiplication function for matrix math\n    if (repflag == false) { \n        cout << \"\\n\" << \"Your second matrix will have \" << c << \" rows\" << \"\\n\";\n        b1 = c;\n        a1 = r;\n        r = c; \n        cout << \"Second matrix columns: \";\n        cin >> c;\n        a2 = c;\n        double m2[r][c] = {};\n        if (inflag == true) {\n            for (int i = 0; i < r; i++) {\n                for (int j = 0; j < c; j++) {\n                    cout << \"Number in row \" << i + 1 << \" and column \" << j + 1 << \": \";\n                    cin >> b;\n                    m2[i][j] = b;\n                }\n            }\n        } else {\n            for (int i = 0; i < r; i++) {\n                for (int j = 0; j < c; j++) {\n                   m2[i][j] = 1;\n                }\n            }\n        }\n        a[a1][a2];\n        for (int i = 0; i < a1; i++) {\n            for (int j = 0; j < a2; j++) {\n                b = 0;\n                for (int d = 0; d < b1; d++) {\n                    b = b + (m[i][d] * m2[d][j]);\n                }\n                a[i][j] = b;\n            }\n        }\n        for (int i = 0; i < a1; i++) {\n            for (int j = 0; j < a2; j++) {\n                cout << a[i][j] << \"    \";\n            }\n        }\n    } \n}\n\nint main() {  //main file\n    defmatrix();\n    double m[r][c] = {};\n    fillmatrix();\n    matrixmult();\n}\n```\n\nThanks in advance!\n    ", "Answer": "\r\nThere is a problem in almost every line. It is easier to point out the good parts. The central ```\nfor```\n loop that calculates the matrix product seems OK. Most everything else needs to be thrown out and rewritten. This includes all declarations and all function interfaces.\nHere's how I would start writing the program.\n```\nint main()\n{\n    int rows;\n    int cols;\n    int common_size; // columns in the matrix A and rows in the matrix B\n\n    std::cout << \"Enter number of rows in the result : \";\n    std::cin  >> rows;\n    std::cout << \"Enter number of columns in the result : \";\n    std::cin  >> cols;\n    std::cout << \"Enter the common size : \";\n    std::cin  >> common_size;\n```\n\nNow we need to declare the matrices, but here comes a problem. One would naïvely want to write something like\n```\n    int a[rows][common_size], b[common_size][cols], c[rows][cols];\n```\n\nbut alas, this is not legal C++. This declaration may work with your compiler, or it may not. There are several ways to declare the matrices correctly. The simplest one is to reserve a fixed amount of memory for each one, and just use a portion:\n```\n    int a[10][10], b[10][10], c[10][10];\n```\n\nNaturally you need to check that the sizes provided by the user do not exceed 10.\nAnother method is to use the C++ version of variable length array, called [vector]. The declaration of ```\na```\n will look something like this:\n```\n    std::vector<std::vector<int>> a(rows, std::vector<int>(common_size));\n```\n\nWith the second method, there is no real limitation on the matrix sizes.\nNeither method is adequate for any real software, but they are enough to complete your C++ exercise. Real software uses more advanced C++ concepts like classes to define matrices. Just something to be aware of.\nI will not continue writing it at the same level of detail. This is your task. I will just show what the rest of ```\nmain```\n could look like.\n```\n    input_matrix(a, rows, common_size);\n    input_matrix(b, common_size, cols);\n    multiply_matrices(a, b, c, rows, common_size, cols);\n    print_matrix(c, rows, cols);\n```\n\nNote function calls using arguments. Implement these functions, and you are good to go. Note, if you choose vectors, you will need to pass some arguments by reference. In this case you could also write the functions this way:\n```\n    input_matrix(a);\n    input_matrix(b);\n    c = multiply_matrices(a, b);\n    print_matrix(c);\n```\n\nbut this is a talk for another day.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Efficient complex matrix-matrix multiplication: matrix shapes and memory\r\n                \r\nIn my code the deepest loop level contains a BLAS routine for matrix-matrix multiplication. Since this operation is the most expensive operation (regarding computation time) I would like to know what is important to make a matrix-matrix multiplication with complex matrix elements as fast as possible?\n\nI use Fortran with ScaLAPACK. I will use the CGEMM routine.\n\nI have the following specific questions:\n\n\nIs it important how the matrices are stored in memory? At the moment, I work with a three dimensional arrays where one index is fixed in each loop cycle such that the three-dimensional arrays reduces to two-dimensional matrices. But I have the feeling that this is innefficient since then the matrix elements aren't physically close together in memory. So, is it better to copy my matrix elemts into a temporary two-dimensional array to pass it to CGEMM?\nIn Fortran the first array index is the fastest index. Is there an optimal way how the arrays (matrices) should be shaped in order to achieve fast matrix multiplications? For example I have to perform matrix multiplications A*B where A is a complex 200x4000 matrix and B is a complex 4000x50 matrix. So should I better create A as a 4000x200 array since then the \"large\" index is the fastes index? Of course then I have to tell CGEMM that A needs to be transposed in order to obtain correct results.\nAre there any well know pitfalls in unsing BLAS routines for matrix-matrix multiplications? I know this is a very general question, but maybe someone knows a good document where some DOs and DONTs are summarized.\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "glibc detected error in matrix multiplication\r\n                \r\nI wrote a simple C++ code for matrix multiplication. The code is giving a glib c error. It is a simple matrix multiplication code to multiply two matrices. \n\n```\n#include <iostream>\n using std::cerr;\n using std::cout;\n using std::endl;\n#include<stdio.h>\n#include <string.h>\n using std::string;\n#include <fstream>\nusing std::ifstream;\nusing std::ofstream;\n#include<stdlib.h>\n#include<cmath>\n#include<math.h>\n#include<algorithm>\n#include<cstdlib>\n#include<ctime>\n#include <vector>\nusing namespace std;\n\nint main()\n{ \nint i,j,k;\nvector<int> mult;\nvector<float> dist_shell;\nstd::string skip;\nstd::string empty_line;\nstd::string num_elements[3];\nint cluster_num;\nvector<int> inter_type; //Interaction type (2-2body;3-3body etc.)\nint c_mult;\nfloat c_dist_shell;\nint c_inter_type; // c stands for cin type variables frm reading file \nfloat unit_cell[3][3];\nfloat factor;\nint l,m,n;\nfloat sum;\n\nifstream poscar(\"POSCAR\");\n\n\nfloat unit_cell[3][3];\n\n    int total_atom=32;\n    float frac[total_atom][3];\n    float real_pos[total_atom][3];\n    for (int count=0;count<total_atom;count++)\n        {\n    poscar>>frac[count][1]>>frac[count][2]>>frac[count][3]>>true_false[count][1]>>true_false[count][2]>>true_false[count][3];\n                }     \n        for (l=0;l<total_atom;l++)\n                {\n                for (m=0;m<3;m++)\n                    {\n                        sum=0;\n                    for (n=0;n<3;n++)\n                        {\n                            sum+=frac[l][n]*unit_cell[n][m];\n                        }\n                    real_pos[l][m]=sum;\n                    }\n                }\n\nreturn 0;\n}\n```\n\n\nMy error is:\n\n```\n*** glibc detected *** ./a.out: free(): invalid pointer: 0x00002aaaaadb8b88 ***\n======= Backtrace: =========\n/lib64/libc.so.6[0x2aaaab0b676e]\n/lib64/libc.so.6(__libc_free+0x6c)[0x2aaaab0b7ebc]\n/usr/intel/pkgs/gcc/4.2.2/lib64/libstdc++.so.6(_ZNSs7reserveEm+0x9e)[0x2aaaaac657fe]\n/usr/intel/pkgs/gcc/4.2.2/lib64/libstdc++.so.6(_ZNSs6appendEPKcm+0x66)[0x2aaaaac659c6]\n/usr/intel/pkgs/gcc/4.2.2/lib64/libstdc++.so.6(_ZStrsIcSt11char_traitsIcESaIcEERSt13basic_ist\nreamIT_T0_ES7_RSbIS4_S5_T1_E+0x1a9)[0x2aaaaac3fdb9]\n./a.out[0x4022ec]\n/lib64/libc.so.6(__libc_start_main+0xf4)[0x2aaaab068304]\n./a.out(__gxx_personality_v0+0x69)[0x401019]\n======= Memory map: ========\n00400000-00405000 r-xp 00000000 00:109 14247450                          /nfs/site/disks/summ\ner11/counting/counting_main/a.out\n00505000-00506000 rw-p 00005000 00:109 14247450                          /nfs/site/disks/summ\ner11/counting/counting_main/a.out\n00506000-00527000 rw-p 00506000 00:00 0                                  [heap]\n2aaaaaaab000-2aaaaaac6000 r-xp 00000000 68:02 80782                      /lib64/ld-2.4.so\n2aaaaaac6000-2aaaaaac7000 r-xp 2aaaaaac6000 00:00 0 \n2aaaaaac7000-2aaaaaac9000 rw-p 2aaaaaac7000 00:00 0 \n2aaaaabc6000-2aaaaabc8000 rw-p 0001b000 68:02 80782                      /lib64/ld-2.4.so\n2aaaaabc8000-2aaaaacb0000 r-xp 00000000 00:18 2295681                    /nfs/sc/itools/em64t\n_SLES10/pkgs/gcc/4.2.2/lib64/libstdc++.so.6.0.9\n2aaaaacb0000-2aaaaadaf000 ---p 000e8000 00:18 2295681                    /nfs/sc/itools/em64t\n_SLES10/pkgs/gcc/4.2.2/lib64/libstdc++.so.6.0.9\n2aaaaadaf000-2aaaaadb6000 r--p 000e7000 00:18 2295681                    /nfs/sc/itools/em64t\n_SLES10/pkgs/gcc/4.2.2/lib64/libstdc++.so.6.0.9\n2aaaaadb6000-2aaaaadb8000 rw-p 000ee000 00:18 2295681                    /nfs/sc/itools/em64t\n_SLES10/pkgs/gcc/4.2.2/lib64/libstdc++.so.6.0.9\n2aaaaadb8000-2aaaaadcd000 rw-p 2aaaaadb8000 00:00 0 \n2aaaaade8000-2aaaaae3c000 r-xp 00000000 68:02 80502                      /lib64/libm-2.4.so\n2aaaaae3c000-2aaaaaf3b000 ---p 00054000 68:02 80502                      /lib64/libm-2.4.so\n2aaaaaf3b000-2aaaaaf3d000 rw-p 00053000 68:02 80502                      /lib64/libm-2.4.so\n2aaaaaf3d000-2aaaaaf3e000 rw-p 2aaaaaf3d000 00:00 0 \n2aaaaaf3e000-2aaaaaf4b000 r-xp 00000000 00:18 1094438                    /nfs/sc/itools/em64t\n_SLES10/pkgs/gcc/4.2.2/lib64/libgcc_s.so.1\n2aaaaaf4b000-2aaaab04a000 ---p 0000d000 00:18 1094438                    /nfs/sc/itools/em64t\n_SLES10/pkgs/gcc/4.2.2/lib64/libgcc_s.so.1\n2aaaab04a000-2aaaab04b000 rw-p 0000c000 00:18 1094438                    /nfs/sc/itools/em64t\n_SLES10/pkgs/gcc/4.2.2/lib64/libgcc_s.so.1\n2aaaab04b000-2aaaab182000 r-xp 00000000 68:02 80494                      /lib64/libc-2.4.so\n2aaaab182000-2aaaab282000 ---p 00137000 68:02 80494                      /lib64/libc-2.4.so\n2aaaab282000-2aaaab285000 r--p 00137000 68:02 80494                      /lib64/libc-2.4.so\n2aaaab285000-2aaaab287000 rw-p 0013a000 68:02 80494                      /lib64/libc-2.4.so\n2aaaab287000-2aaaab28e000 rw-p 2Abort\n```\n\n\nI am trying to figure out if there is an error in another part of my code. Changing datatypes also did not help. Thanks to everyone who can help me with spotting the error.\nThanks.\n    ", "Answer": "\r\nThe solution was that while reading some lines from a file, getline sometimes reads end of the line and not the next line. So it is important to check what exactly the line skipping part contains. That has led to this error in the end. The error was not a part of this code.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "C++, overload * for matrix multiplication\r\n                \r\nI'm having a great deal of trouble trying to overload the multiplication operator * for matrix multiplication. I've defined a matrix class\n\n```\n#ifndef MMATRIX_H\n#define MMATRIX_H\n#include <vector>\n#include <cmath>\n\n// Class that represents a mathematical matrix\nclass MMatrix\n{\npublic:\n// constructors\nMMatrix() : nRows(0), nCols(0) {}\nMMatrix(int n, int m, double x = 0) : nRows(n), nCols(m), A(n * m, x)\n{}\n\n// set all matrix entries equal to a double\nMMatrix &operator=(double x)\n{\n    for (int i = 0; i < nRows * nCols; i++) \n        A[i] = x;\nreturn *this;\n}\n\n// access element, indexed by (row, column) [rvalue]\ndouble operator()(int i, int j) const\n{\n    return A[j + i * nCols];\n}\n\n// access element, indexed by (row, column) [lvalue]\ndouble &operator()(int i, int j)\n{\n    return A[j + i * nCols];\n}\n\n\n// size of matrix\nint Rows() const { return nRows; }\nint Cols() const { return nCols; }\n\n// operator overload for matrix * vector. Definition (prototype) of member class\nMVector operator*(const MMatrix& A);\n\nprivate:\nunsigned int nRows, nCols;\nstd::vector<double> A;\n};\n#endif\n```\n\n\nAnd here is my attempted operator overload\n\n```\ninline MMatrix operator*(const MMatrix& A, const MMatrix& B)\n{\nMMatrix m(A), c(m.Rows(),m.Cols(),0.0);\nfor (int i=0; i<m.Rows(); i++)\n{\n    for (int j=0; j<m.Cols(); j++)\n    {\n        for (int k=0; k<m.Cols(); k++)\n        {\n            c(i,j)+=m(i,k)*B(k,j);\n        }\n    }\n}\nreturn c;\n\n}\n```\n\n\nI'm sure that there is nothing wrong with the actual multiplication of elements. \n\nThe error that I get is from my main .cpp file where I have tried to multiply two matrices together C=A*B; and I get this error,\n\nerror: no match for 'operator=' (operand types are 'MMatrix' and 'MVector') \n    ", "Answer": "\r\nThere are 2 ways to overload ```\noperator*```\n:\n\n```\nMMatrix MMatrix::operator*(MMatrix); //or const& or whatever you like\nMMatrix operator*(MMatrix, MMatrix);\n```\n\n\nThese are both valid, but different with slightly different semantics.\n\nFor your definition to match your declaration change the definition to:\n\n```\nMMatrix MMatrix::operator*(const MMatrix & A)\n{\n    //The two matrices to multiple are (*this) and A\n    MMatrix c(Rows(),A.Cols(),0.0);\n    for (int i=0; i < Rows(); i++)\n    {\n        for (int j=0; j < A.Cols(); j++)\n        {\n            for (int k=0; k < Cols(); k++)\n            {\n                c(i,j) += (*this)(i,k)*A(k,j);\n            }\n        }\n    }\n    return c;\n}\n```\n\n\nAs for the error you're seeing, it seems in your class you declared the operator to take a matrix and return a vector.  You probably meant to return a matrix instead.  The error is telling you that you can't assign a ```\nMVector```\n to a ```\nMMatrix```\n.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Trainable Matrix multiplication Layer\r\n                \r\nI'm trying to build a (custom) trainable matrix-multiplication layer in TensorFlow, but things aren't working out...  More precisely, my model should look like this:\n```\nx -> A(x) x\n```\n\nwhere A(x) is a feed-forward network with values in the n x n matrix (and thus depends on the input x) and A(x) is matrix by vector multiplication.\nHere's what I've coded-up:\n```\nclass custom_layer(tf.keras.layers.Layer):\n    \n    def __init__(self, units=16, input_dim=32):\n        super(custom_layer, self).__init__()\n        self.units = units\n    \n    def build(self, input_shape):\n        self.Tw1 = self.add_weight(name='Weights_1 ',\n                                    shape=(input_shape[-1], input_shape[-1]),\n                                    initializer='GlorotUniform',\n                                    trainable=True)\n        \n        self.Tw2 = self.add_weight(name='Weights_2 ',\n                                    shape=(input_shape[-1], (self.units)**2),\n                                    initializer='GlorotUniform',\n                                    trainable=True)\n        \n        self.Tb = self.add_weight(name='basies',\n                                    shape=(input_shape[-1],),\n                                    initializer='GlorotUniform',#Previously 'ones'\n                                    trainable=True)\n\n        \n    def call(self, input):\n        # Build Vector-Valued Feed-Forward Network\n        ffNN = tf.matmul(input, self.Tw1) + self.Tb\n        ffNN = tf.nn.relu(ffNN)\n        ffNN = tf.matmul(ffNN, self.Tw2) \n    \n        \n        # Map to Matrix\n        ffNN = tf.reshape(ffNN, [self.units,self.units])\n\n        # Multiply Matrix-Valued function with input data\n        x_out = tf.matmul(ffNN,input)\n        \n        # Return Output\n        return x_out\n```\n\nNow I build the model:\n```\ninput_layer = tf.keras.Input(shape=[2])\noutput_layer  = custom_layer(2)(input_layer)\nmodel = tf.keras.Model(inputs=[input_layer], outputs=[output_layer])\n\n# Compile Model\n#----------------#\n# Define Optimizer\noptimizer_on = tf.keras.optimizers.SGD(learning_rate=10**(-1))\n# Compile\nmodel.compile(loss = 'mse',\n                optimizer = optimizer_on,\n                metrics = ['mse'])\n\n# Fit Model\n#----------------#\nmodel.fit(data_x, data_y, epochs=(10**1), verbose=0)\n```\n\nand then I get this error message:\n```\nInvalidArgumentError:  Input to reshape is a tensor with 128 values, but the requested shape has 4\n     [[node model_62/reconfiguration_unit_70/Reshape (defined at <ipython-input-176-0b494fa3fc75>:46) ]] [Op:__inference_distributed_function_175181]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_62/reconfiguration_unit_70/Reshape:\n model_62/reconfiguration_unit_70/MatMul_1 (defined at <ipython-input-176-0b494fa3fc75>:41)\n\nFunction call stack:\ndistributed_function\n```\n\nThoughts:\nIt seems like something is wrong with the network dimensions but I can't figure what/how to repair it...\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication using pthreads\r\n                \r\nI am trying to do matrix multiplication using pthreads and creating one thread for each computation of each row instead of each element. Suppose there are two matrices \nA[M][K],B[K][N] . Where am I going wrong ?\n\n```\nint A[M][K];\nint B[K][N];\nint C[][];\n\nvoid *runner (void *param);\n\n\nstruct v\n{\nint i;\n int j;\n};\n\npthread_t tid[M];\n\nfor (i = 0; i < M; i++) // It should create M threads \n{\n    struct v *data = (struct v *) malloc (sizeof (struct v));\n    data->i = i;\n    data->j = j;\n    pthread_create (&tid[count], &attr, runner, data);\n    pthread_join (tid[count], NULL);\n    count++;\n}\n\nrunner (void *param) //\n{\n    struct v *test;\n    int t = 0;\n    test = (struct v *) param;\n\n    for (t = 0; t < K; t++)  // I want to compute it for a row instead of an element \n    {\n        C[test->i][test->j] = C[test->i][test->j] + A[test->i][t] * B[t][test->j];\n    }\n    pthread_exit (0);\n}\n```\n\n    ", "Answer": "\r\nFirst, get rid of data->j. If you are computing entire rows the row index is the only thing your thread needs. Right now your runner(..) computes a single element. You have to iterate over all row elements computing them one by one.\nSecond, do not join a thread right after it is created. This way you have only one thread running at a time. Start joining threads when all threads have been created.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication error and ggplot output\r\n                \r\nim trying to make matrix multiplication performing a principal component analysis and use ggplot to show the result\n\n```\npca_model <- tbl(sc, \"naflights\") %>%\nselect(air_time, distance, dep_time) %>%\nml_pca()\nprint(pca_model)\n\n# Explained variance:\n#\n#         PC1          PC2          PC3 \n# 0.6975982637 0.3021978609 0.0002038754 \n# \n# Rotation:\n#                  PC1         PC2           PC3\n# air_time -0.12514862 0.001940123 -0.9921361086\n# distance -0.99200200 0.016312867  0.1251636066\n# dep_time  0.01642742 0.999865054 -0.0001169274\n\nD <- as.matrix(naflights[1:3])\nE <- as.matrix(pca_model$components)\n\n# Error in array(x, c(length(x), 1L), if (!is.null(names(x))) list(names(x),  : \n#  'data' must be of a vector type, was 'NULL'\n```\n\n\ni have tried:\n\n```\nD <- as.matrix(flights[4, 15, 16])\nE <- as.matrix(pca_model$components)\nError in array(x, c(length(x), 1L), if (!is.null(names(x))) list(names(x),  : \n  'data' must be of a vector type, was 'NULL'\nloadings_pca <- tidy(pca_model)\nloadings_pca\n# A tibble: 3 x 4\n  features     PC1     PC2       PC3\n  <chr>      <dbl>   <dbl>     <dbl>\n1 air_time -0.125  0.00194 -0.992   \n2 distance -0.992  0.0163   0.125   \n3 dep_time  0.0164 1.000   -0.000117\nE <- as.matrix(loadings_pca[2:4])\nP <- D %*% E\nError in D %*% E : non-conformable arguments\nmode(D)\n[1] \"numeric\"\n mode(E)\n[1] \"numeric\"\n```\n\n\nI have tried this approach but still getting error : non-conformable arguments.\nAnyone can help me with the issue?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication in c code\r\n                \r\nI have a code needs to do some matrix multiplication like\n\n```\n    ML2=ML+uMc+c1+c2\n    MC2=v*ML+(u*v+1)*Mc+c2\n```\n\n\nWhere ML is MXM matrix of\n\n```\n    ML=[1 1 1 1....1;2 2 2 2...2......;M M M.....M]\n    MC=[1 2 3 4 ...M;1 2 3 4...M......;1 2 3.....M]\n```\n\n\nu,v,c1 and c2 are constant of 8 bit.\n\nI want to find the values of ML2,MC2 in fast execution time using any fast library\n    ", "Answer": "\r\nYou did not state the platform you want this for but for matrix operations nothing is faster than the Intel Math Kernel Library for Intel CPUs\n\nhttp://software.intel.com/en-us/intel-mkl\n\nThis gets as close as I have seen to the peak flops possible on the CPU.  MKL, however, is expensive and closed source.  If you want a good open sourced and free alternative then check out Eigen.  This uses C++ but I don't know if you're really restricted to C only code.  Eigen also works well on other hardware such as AMD (Intel cripples it's library on AMD CPUs) and ARM.\n\nhttp://eigen.tuxfamily.org/index.php?title=3.0\n\nA third option to write one yourself.  After a few weeks of effort it should not be too difficult to beat Eigen with AVX and OpenMP (Eigen only supports SSE) but it's highly unlikely you will beat MKL.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Parallel matrix multiplication in Python\r\n                \r\nI am trying to do a matrix multiplication using multiple processes in python. My solution is slow and for matrices 2000*2000 its not working at all (it is stuck). Can someone please suggest me how to divide matrix to send it to processes? I am lost\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication with Prolog\r\n                \r\nI have to write a predicate the predicate ```\nproduct/3```\n which receives two matrix and returns the matrix multiplication of them if possible or fail otherwise. (This means if the matrices fullfill the requirement ```\n[n x p] [p x y]```\n, then return the multiplication with dimensions ```\n[n x y]```\n)\n\nExample:\n\n```\nproduct(M1, M2, R)\n    ?- product([[1,2],[3,4],[5,6]], [[1,1,1],[1,1,1]], M).\n    M = [[3, 3, 3], [7, 7, 7], [11, 11, 11]];\n    No\n```\n\n\nFor this I have two codes that index the nth row on a matrix ```\nrowI```\n and that index the nth column ```\ncolumnI```\n (I explain how they work in the code below).\n\n```\n%Predicate: rowI(M, I, RI)\n%Input      rowI([[1,2],[3,4],[5,6]], 2, RI).\n%           RI = [3,4];\n\nrowI([H|_],1,H):-!.\nrowI([_|T],I,X) :-\n    I1 is I-1,\n    rowI(T,I1,X).\n\n%        columnJ(M, J, CJ)\n%Input   columnJ([[1,2],[3,4],[5,6]], 1, CJ).\n%        CJ = [1,3,5];\n\ncolumnJ([],_,[]).\ncolumnJ([H|T], I, [R|X]):-\n    rowI(H, I, R), \n    columnJ(T,I,X).\n\n\nproduct([H|T], M2, [R|X]):-\n\n    columnJ(M2, C, Z),\n    mult(H, Z , X),\n    product(T, M2 , X).\n```\n\n\nI was thinking somehow by grabbing the head of the ```\nM1```\n (which will be each row) and then multiplied for each column in ```\nM2```\n and after adding the multiplication this list will be the new row. So (C would have to be a counter starting from 1 to the length of ```\nM2```\nand then ```\nmult```\n I was just thinking on having it multiplying the lists. (mult is not defined at this point, just a guess).\n\nHere I am trying to explain the way I am thinking it.. but there may be a simplier way. What do you think?\n    ", "Answer": "\r\nCompact code (with the help of higher order constructs maplist and foldl).\nI left on purpose the expressions unevaluated, so the result could be reused in more general context:\n\n```\n:- module(matrix_multiply,\n    [matrix_multiply/3\n    ,dot_product/3\n    ]).\n:- use_module(library(clpfd), [transpose/2]).\n\n%%  matrix_multiply(+X,+Y,-M) is det.\n%\n%   X(N*P),Y(P*M),M(N*M)\n%\nmatrix_multiply(X,Y,M) :-\n    transpose(Y,T),\n    maplist(row_multiply(T),X,M).\n\nrow_multiply(T,X,M) :-\n    maplist(dot_product(X),T,M).\n\ndot_product([X|Xs],[T|Ts],M) :-\n    foldl(mul,Xs,Ts,X*T,M).\nmul(X,T,M,M+X*T).\n```\n\n\nedit\n\nusage (save in a file named matrix_multiply.pl):\n\n```\n?- [matrix_multiply].\n?- matrix_multiply([[1,2],[3,4],[5,6]], [[1,1,1],[1,1,1]],R),maplist(maplist(is),C,R).\nR = [[1*1+2*1, 1*1+2*1, 1*1+2*1], [3*1+4*1, 3*1+4*1, 3*1+4*1], [5*1+6*1, 5*1+6*1, 5*1+6*1]],\nC = [[3, 3, 3], [7, 7, 7], [11, 11, 11]].\n```\n\n\nThe numeric evaluation is explicitly requested by ```\n,maplist(maplist(is),C,R)```\n.\nR holds the symbolic expressions, C the values.\n\nedit\n\nJust to note that dependency from clpfd:transpose is easy to remove: here is an alternative 'one-liner' definition based on nth/3 and library(yall)\n\n```\nmat_transpose([R1|Rs],T) :- findall(V,(\n    nth1(Col,R1,_),\n    maplist({Col}/[R,C]>>nth1(Col,R,C),[R1|Rs],V)),T).\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication using matrix template library (MTL 2)\r\n                \r\nKindly give me some hint of matrix multiplication using MTL 2. Or any ref. or link for the documentation of MTL 2.\n    ", "Answer": "\r\nWe're not supposed to post just links, but here you go. There is a choice of documentation in the sidebar of that page.\n\nhttp://www.osl.iu.edu/research/mtl/\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Eigen3 matrix multiplication performance\r\n                \r\nNote: I've posted this also on Eigen forum here\n\nI want to premultiply 3xN matrices by a 3x3 matrix, i.e., to transform 3D points, like \n    p_dest = T * p_source\n\nafter initializing the matrices:\n\n```\nEigen::Matrix<double, 3, Eigen::Dynamic> points = Eigen::Matrix<double, 3, Eigen::Dynamic>::Random(3, NUMCOLS);\nEigen::Matrix<double, 3, Eigen::Dynamic> dest = Eigen::Matrix<double, 3, Eigen::Dynamic>(3, NUMCOLS);\nint NT = 100;\n```\n\n\nI have evaluated this two versions\n\n```\n// eigen direct multiplication\nfor (int i = 0; i < NT; i++){\n  Eigen::Matrix3d T = Eigen::Matrix3d::Random();\n  dest.noalias() = T * points;\n}\n```\n\n\nand \n\n```\n// col multiplication\nfor (int i = 0; i < NT; i++){\n  Eigen::Matrix3d T = Eigen::Matrix3d::Random();\n  for (int c = 0; c < points.cols(); c++){\n    dest.col(c) = T * points.col(c);\n  }\n}\n```\n\n\nthe NT repetition are done just to compute average time\n\nI am surprised the the column by column multiplication is about 4/5 time faster than the direct multiplication\n(and the direct multiplication is even slower if I do not use the ```\n.noalias()```\n, but this is fine since it is doing a temporary copy)\nI've tried to change NUMCOLS from 0 to 1000000 and the relation is linear.\n\nI'm using Visual Studio 2013 and compiling in release\n\nThe next figure shows on X the number of columns of the matrix and in Y the avg time for a single operation, in blue the col by col multiplication, in red the matrix multiplication\n\n\n\nAny suggestion why this happens?\n    ", "Answer": "\r\nShort answer\n\nYou're timing the lazy (and therefore lack of) evaluation in the col multiplication version, vs. the lazy (but evaluated) evaluation in the direct version.\n\nLong answer\n\nInstead of code snippets, let's look at a full MCVE. First, \"you're\" version:\n\n```\nvoid ColMult(Matrix3Xd& dest, Matrix3Xd& points)\n{\n    Eigen::Matrix3d T = Eigen::Matrix3d::Random();\n    for (int c = 0; c < points.cols(); c++){\n        dest.col(c) = T * points.col(c);\n    }\n}\n\nvoid EigenDirect(Matrix3Xd& dest, Matrix3Xd& points)\n{\n    Eigen::Matrix3d T = Eigen::Matrix3d::Random();\n    dest.noalias() = T * points;\n}\n\nint main(int argc, char *argv[])\n{\n    srand(time(NULL));\n\n    int NUMCOLS = 100000 + rand();\n\n    Matrix3Xd points = Matrix3Xd::Random(3, NUMCOLS);\n    Matrix3Xd dest   = Matrix3Xd(3, NUMCOLS);\n    Matrix3Xd dest2  = Matrix3Xd(3, NUMCOLS);\n    int NT = 200;\n    // eigen direct multiplication\n    auto beg1 = std::chrono::high_resolution_clock::now();\n    for (int i = 0; i < NT; i++)\n    {\n        EigenDirect(dest, points);\n    }\n    auto end1 = std::chrono::high_resolution_clock::now();\n\n    std::chrono::duration<double> elapsed_seconds = end1-beg1;\n\n    // col multiplication\n    auto beg2 = std::chrono::high_resolution_clock::now();\n    for(int i = 0; i < NT; i++)\n    {\n        ColMult(dest2, points);\n    }\n\n    auto end2 = std::chrono::high_resolution_clock::now();\n\n    std::chrono::duration<double> elapsed_seconds2 = end2-beg2;\n    std::cout << \"Direct time: \" << elapsed_seconds.count() << \"\\n\";\n    std::cout << \"Col time: \" << elapsed_seconds2.count() << \"\\n\";\n\n    std::cout << \"Eigen speedup: \" << elapsed_seconds2.count() / elapsed_seconds.count() << \"\\n\\n\";\n    return 0;\n}\n```\n\n\nWith this code (and SSE turned on), I get:\n\n```\nDirect time: 0.449301\nCol time: 0.10107\nEigen speedup: 0.224949\n```\n\n\nSame 4-5 slowdown you complained of. Why?!?! Before we get to the answer, let's modify the code a bit so that the ```\ndest```\n matrix is sent to an ```\nostream```\n. Add ```\nstd::ostream outPut(0);```\n to the beginning of ```\nmain()```\n and before ending the timers add ```\noutPut << dest << \"\\n\\n\";```\n and ```\noutPut << dest2 << \"\\n\\n\";```\n. The ```\nstd::ostream outPut(0);```\n doesn't output anything (I'm pretty sure the badbit is set), but it does cause Eigens ```\noperator<<```\n to be called, which forces the evaluation of the matrix.\n\nNOTE: if we used ```\noutPut << dest(1,1)```\n then ```\ndest```\n would be evaluated only enough to output the single element in the col multiplication method.\n\nWe then get\n\n```\nDirect time: 0.447298\nCol time: 0.681456\nEigen speedup: 1.52349\n```\n\n\nas a result as expected. Note that the Eigen direct method took the exact(ish) same time (meaning the evaluation took place even without the added ```\nostream```\n), whereas the col method all of the sudden took much longer.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "parallelizing matrix multiplication through threading and SIMD\r\n                \r\nI am trying to speed up matrix multiplication on multicore architecture. For this end, I try to use threads and SIMD at the same time. But my results are not good. I test speed up over sequential matrix multiplication:\n\n```\nvoid sequentialMatMul(void* params)\n{\n    cout << \"SequentialMatMul started.\";\n    int i, j, k;\n    for (i = 0; i < N; i++)\n    {\n        for (k = 0; k < N; k++)\n        {\n            for (j = 0; j < N; j++)\n            {\n                X[i][j] += A[i][k] * B[k][j];\n            }\n        }\n    }\n    cout << \"\\nSequentialMatMul finished.\";\n}\n```\n\n\nI tried to add threading and SIMD to matrix multiplication as follows:\n\n```\nvoid threadedSIMDMatMul(void* params)\n{\n    bounds *args = (bounds*)params;\n    int lowerBound = args->lowerBound;\n    int upperBound = args->upperBound;\n    int idx = args->idx;\n\n    int i, j, k;\n    for (i = lowerBound; i <upperBound; i++)\n    {\n        for (k = 0; k < N; k++)\n        {\n            for (j = 0; j < N; j+=4)\n            {\n                mmx1 = _mm_loadu_ps(&X[i][j]);\n                mmx2 = _mm_load_ps1(&A[i][k]);\n                mmx3 = _mm_loadu_ps(&B[k][j]);\n                mmx4 = _mm_mul_ps(mmx2, mmx3);\n                mmx0 = _mm_add_ps(mmx1, mmx4);\n                _mm_storeu_ps(&X[i][j], mmx0);\n            }\n        }\n    }\n    _endthread();\n}\n```\n\n\nAnd the following section is used for calculating lowerbound and upperbound of each thread:\n\n```\nbounds arg[CORES];\nfor (int part = 0; part < CORES; part++)\n{\n    arg[part].idx = part;\n    arg[part].lowerBound = (N / CORES)*part;\n    arg[part].upperBound = (N / CORES)*(part + 1);\n}\n```\n\n\nAnd finally threaded SIMD version is called like this:\n\n```\nHANDLE  handle[CORES];      \nfor (int part = 0; part < CORES; part++)\n{\n    handle[part] = (HANDLE)_beginthread(threadedSIMDMatMul, 0, (void*)&arg[part]);\n}\nfor (int part = 0; part < CORES; part++)\n{\nWaitForSingleObject(handle[part], INFINITE);\n}\n```\n\n\nThe result is as follows:\nTest 1:\n\n```\n// arrays are defined as follow\nfloat A[N][N];\nfloat B[N][N];\nfloat X[N][N];\nN=2048\nCore=1//just one thread\n```\n\n\nSequential time: 11129ms\n\nThreaded SIMD matmul time: 14650ms\n\nSpeed up=0.75x\n\nTest 2:\n\n```\n//defined arrays as follow\nfloat **A = (float**)_aligned_malloc(N* sizeof(float), 16);\nfloat **B = (float**)_aligned_malloc(N* sizeof(float), 16);\nfloat **X = (float**)_aligned_malloc(N* sizeof(float), 16);\nfor (int k = 0; k < N; k++)\n{\n    A[k] = (float*)malloc(cols * sizeof(float));\n    B[k] = (float*)malloc(cols * sizeof(float));\n    X[k] = (float*)malloc(cols * sizeof(float));\n}\nN=2048\nCore=1//just one thread\n```\n\n\nSequential time: 15907ms\n\nThreaded SIMD matmul time: 18578ms\n\nSpeed up=0.85x\n\nTest 3:\n\n```\n//defined arrays as follow\nfloat A[N][N];\nfloat B[N][N];\nfloat X[N][N];\nN=2048\nCore=2\n```\n\n\nSequential time: 10855ms\n\nThreaded SIMD matmul time: 27967ms\n\nSpeed up=0.38x\n\nTest 4:\n\n```\n//defined arrays as follow\nfloat **A = (float**)_aligned_malloc(N* sizeof(float), 16);\nfloat **B = (float**)_aligned_malloc(N* sizeof(float), 16);\nfloat **X = (float**)_aligned_malloc(N* sizeof(float), 16);\nfor (int k = 0; k < N; k++)\n{\n    A[k] = (float*)malloc(cols * sizeof(float));\n    B[k] = (float*)malloc(cols * sizeof(float));\n    X[k] = (float*)malloc(cols * sizeof(float));\n}\nN=2048\nCore=2\n```\n\n\nSequential time: 16579ms\n\nThreaded SIMD matmul time: 30160ms\n\nSpeed up=0.51x\n\nMy question: why I don’t get speed up?\n    ", "Answer": "\r\nHere are the times I get building on your algorithm on my four core i7 IVB processor.\n\n```\nsequential:         3.42 s\n4 threads:          0.97 s\n4 threads + SSE:    0.86 s\n```\n\n\nHere are the times on a 2 core P9600 @2.53 GHz which is similar to the OP's E2200 @2.2 GHz\n\n```\nsequential: time    6.52 s\n2 threads: time     3.66 s\n2 threads + SSE:    3.75 s\n```\n\n\nI used OpenMP because it makes this easy.  Each thread in OpenMP runs over effectively\n\n```\nlowerBound = N*part/CORES;\nupperBound = N*(part + 1)/CORES;\n```\n\n\n(note that that is slightly different than your definition. Your definition can give the wrong result due to rounding for some values of ```\nN```\n since you divide by ```\nCORES```\n first.)\n\nAs to the SIMD version. It's not much faster probably due it being memory bandwidth bound . It's probably not really faster because GCC already vectroizes the loop.  \n\nThe most optimal solution is much more complicated. You need to use loop tiling and reorder the elements within tiles to get the optimal performance. I don't have time to do that today.\n\nHere is the code I used:\n\n```\n//c99 -O3 -fopenmp -Wall foo.c\n#include <stdio.h>\n#include <string.h>\n#include <x86intrin.h>\n#include <omp.h>\n\nvoid gemm(float * restrict a, float * restrict b, float * restrict c, int n) {\n    for(int i=0; i<n; i++) {\n        for(int k=0; k<n; k++) {\n            for(int j=0; j<n; j++) {\n                c[i*n+j] += a[i*n+k]*b[k*n+j];\n            }\n        }\n    }\n}\n\nvoid gemm_tlp(float * restrict a, float * restrict b, float * restrict c, int n) {\n    #pragma omp parallel for\n    for(int i=0; i<n; i++) {\n        for(int k=0; k<n; k++) {\n            for(int j=0; j<n; j++) {\n                c[i*n+j] += a[i*n+k]*b[k*n+j];\n            }\n        }\n    }\n}   \n\nvoid gemm_tlp_simd(float * restrict a, float * restrict b, float * restrict c, int n) {\n    #pragma omp parallel for\n    for(int i=0; i<n; i++) {\n        for(int k=0; k<n; k++) {\n            __m128 a4 = _mm_set1_ps(a[i*n+k]);\n            for(int j=0; j<n; j+=4) {\n                __m128 c4 = _mm_load_ps(&c[i*n+j]);\n                __m128 b4 = _mm_load_ps(&b[k*n+j]);\n                c4 = _mm_add_ps(_mm_mul_ps(a4,b4),c4);\n                _mm_store_ps(&c[i*n+j], c4);\n            }\n        }\n    }\n}\n\nint main(void) {\n    int n = 2048;\n    float *a = _mm_malloc(n*n * sizeof *a, 64);\n    float *b = _mm_malloc(n*n * sizeof *b, 64);\n    float *c1 = _mm_malloc(n*n * sizeof *c1, 64);\n    float *c2 = _mm_malloc(n*n * sizeof *c2, 64);\n    float *c3 = _mm_malloc(n*n * sizeof *c2, 64);\n    for(int i=0; i<n*n; i++) a[i] = 1.0*i;\n    for(int i=0; i<n*n; i++) b[i] = 1.0*i;\n    memset(c1, 0, n*n * sizeof *c1);\n    memset(c2, 0, n*n * sizeof *c2);\n    memset(c3, 0, n*n * sizeof *c3);\n    double dtime;\n\n    dtime = -omp_get_wtime();\n    gemm(a,b,c1,n);\n    dtime += omp_get_wtime();\n    printf(\"time %f\\n\", dtime);\n\n    dtime = -omp_get_wtime();\n    gemm_tlp(a,b,c2,n);\n    dtime += omp_get_wtime();\n    printf(\"time %f\\n\", dtime);\n\n    dtime = -omp_get_wtime();\n    gemm_tlp_simd(a,b,c3,n);\n    dtime += omp_get_wtime();\n    printf(\"time %f\\n\", dtime);\n    printf(\"error %d\\n\", memcmp(c1,c2, n*n*sizeof *c1));\n    printf(\"error %d\\n\", memcmp(c1,c3, n*n*sizeof *c1));\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication in c code\r\n                \r\nI have a code needs to do some matrix multiplication like\n\n```\n    ML2=ML+uMc+c1+c2\n    MC2=v*ML+(u*v+1)*Mc+c2\n```\n\n\nWhere ML is MXM matrix of\n\n```\n    ML=[1 1 1 1....1;2 2 2 2...2......;M M M.....M]\n    MC=[1 2 3 4 ...M;1 2 3 4...M......;1 2 3.....M]\n```\n\n\nu,v,c1 and c2 are constant of 8 bit.\n\nI want to find the values of ML2,MC2 in fast execution time using any fast library\n    ", "Answer": "\r\nYou did not state the platform you want this for but for matrix operations nothing is faster than the Intel Math Kernel Library for Intel CPUs\n\nhttp://software.intel.com/en-us/intel-mkl\n\nThis gets as close as I have seen to the peak flops possible on the CPU.  MKL, however, is expensive and closed source.  If you want a good open sourced and free alternative then check out Eigen.  This uses C++ but I don't know if you're really restricted to C only code.  Eigen also works well on other hardware such as AMD (Intel cripples it's library on AMD CPUs) and ARM.\n\nhttp://eigen.tuxfamily.org/index.php?title=3.0\n\nA third option to write one yourself.  After a few weeks of effort it should not be too difficult to beat Eigen with AVX and OpenMP (Eigen only supports SSE) but it's highly unlikely you will beat MKL.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Multi-threaded matrix multiplication\r\n                \r\nI've coded a multi-threaded matrix multiplication. I believe my approach is right, but I'm not 100% sure. In respect to the threads, I don't understand why I can't just run a ```\n(new MatrixThread(...)).start()```\n instead of using an ```\nExecutorService```\n.\n\nAdditionally, when I benchmark the multithreaded approach versus the classical approach, the classical is much faster...\n\nWhat am I doing wrong?\n\nMatrix Class:\n\n```\nimport java.util.*;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.TimeUnit;\n\nclass Matrix\n{\n   private int dimension;\n   private int[][] template;\n\n   public Matrix(int dimension)\n   {\n      this.template = new int[dimension][dimension];\n      this.dimension = template.length;\n   }\n\n   public Matrix(int[][] array) \n   {\n      this.dimension = array.length;\n      this.template = array;      \n   }\n\n   public int getMatrixDimension() { return this.dimension; }\n\n   public int[][] getArray() { return this.template; }\n\n   public void fillMatrix()\n   {\n      Random randomNumber = new Random();\n      for(int i = 0; i < dimension; i++)\n      {\n         for(int j = 0; j < dimension; j++)\n         {\n            template[i][j] = randomNumber.nextInt(10) + 1;\n         }\n      }\n   }\n\n   @Override\n   public String toString()\n   {\n      String retString = \"\";\n      for(int i = 0; i < this.getMatrixDimension(); i++)\n      {\n         for(int j = 0; j < this.getMatrixDimension(); j++)\n         {\n            retString += \" \" + this.getArray()[i][j];\n         }\n         retString += \"\\n\";\n      }\n      return retString;\n   }\n\n   public static Matrix classicalMultiplication(Matrix a, Matrix b)\n   {      \n      int[][] result = new int[a.dimension][b.dimension];\n      for(int i = 0; i < a.dimension; i++)\n      {\n         for(int j = 0; j < b.dimension; j++)\n         {\n            for(int k = 0; k < b.dimension; k++)\n            {\n               result[i][j] += a.template[i][k] * b.template[k][j];\n            }\n         }\n      }\n      return new Matrix(result);\n   }\n\n   public Matrix multiply(Matrix multiplier) throws InterruptedException\n   {\n      Matrix result = new Matrix(dimension);\n      ExecutorService es = Executors.newFixedThreadPool(dimension*dimension);\n      for(int currRow = 0; currRow < multiplier.dimension; currRow++)\n      {\n         for(int currCol = 0; currCol < multiplier.dimension; currCol++)\n         {            \n            //(new MatrixThread(this, multiplier, currRow, currCol, result)).start();            \n            es.execute(new MatrixThread(this, multiplier, currRow, currCol, result));\n         }\n      }\n      es.shutdown();\n      es.awaitTermination(2, TimeUnit.DAYS);\n      return result;\n   }\n\n   private class MatrixThread extends Thread\n   {\n      private Matrix a, b, result;\n      private int row, col;      \n\n      private MatrixThread(Matrix a, Matrix b, int row, int col, Matrix result)\n      {         \n         this.a = a;\n         this.b = b;\n         this.row = row;\n         this.col = col;\n         this.result = result;\n      }\n\n      @Override\n      public void run()\n      {\n         int cellResult = 0;\n         for (int i = 0; i < a.getMatrixDimension(); i++)\n            cellResult += a.template[row][i] * b.template[i][col];\n\n         result.template[row][col] = cellResult;\n      }\n   }\n} \n```\n\n\nMain class:\n\n```\nimport java.util.Scanner;\n\npublic class MatrixDriver\n{\n   private static final Scanner kb = new Scanner(System.in);\n\n   public static void main(String[] args) throws InterruptedException\n   {      \n      Matrix first, second;\n      long timeLastChanged,timeNow;\n      double elapsedTime;\n\n      System.out.print(\"Enter value of n (must be a power of 2):\");\n      int n = kb.nextInt();\n\n      first = new Matrix(n);\n      first.fillMatrix();      \n      second = new Matrix(n);\n      second.fillMatrix();\n\n      timeLastChanged = System.currentTimeMillis();\n      //System.out.println(\"Product of the two using threads:\\n\" +\n                                                        first.multiply(second);\n      timeNow = System.currentTimeMillis();\n      elapsedTime = (timeNow - timeLastChanged)/1000.0;\n      System.out.println(\"Threaded took \"+elapsedTime+\" seconds\");\n\n      timeLastChanged = System.currentTimeMillis();\n      //System.out.println(\"Product of the two using classical:\\n\" +\n                                  Matrix.classicalMultiplication(first,second);\n      timeNow = System.currentTimeMillis();\n      elapsedTime = (timeNow - timeLastChanged)/1000.0;\n      System.out.println(\"Classical took \"+elapsedTime+\" seconds\");\n   }\n} \n```\n\n\nP.S. Please let me know if any further clarification is needed.\n    ", "Answer": "\r\nThere is a bunch of overhead involved in creating threads, even when using an ExecutorService.  I suspect the reason why you're multithreaded approach is so slow is that you're spending 99% creating a new thread and only 1%, or less, doing the actual math.\n\nTypically, to solve this problem you'd batch a whole bunch of operations together and run those on a single thread.  I'm not 100% how to do that in this case, but I suggest breaking your matrix into smaller chunks (say, 10 smaller matrices) and run those on threads, instead of running each cell in its own thread.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Use of semaphores for matrix multiplication\r\n                \r\nWould I need semaphores to synchronize processes in matrix multiplication using multiple processes when processes are dealing with different rows . Would it still create race codition?\n    ", "Answer": "\r\nIf different threads are dealing with different rows, then there shouldn't be any danger of two threads accessing the same memory location, so there shouldn't be a reason to worry about race conditions.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication Issues in C\r\n                \r\nI'm making a matrix multiplication calculator in C. When I run it, spews out many numbers and results in this: \n\n```\n57736 segmentation fault\n```\n\n\nWhere did I write wrong? Here is the code I wrote:\n\n```\nint Mtx1row, Mtx1col, Mtx2row, Mtx2col, c, d, e;\nint first[10][10], second[10][10], mult[10][10];\n```\n\n\nGet 1st Matrix row and col\n\n```\n  printf(\"First Matrix: # of row and col?\\n\");\n  scanf(\"%d%d\", &Mtx1row, &Mtx1col);\n```\n\n\nGet 2nd Matrix row and col\n\n```\n  printf(\"Second Matrix: # of row and col?\\n\");\n  scanf(\"%d%d\", &Mtx2row, &Mtx2col);\n```\n\n\nCompare 1st Matrix col vs 2nd Matrix row\n\n```\n  if (Mtx1col != Mtx2row){\n    printf(\"Mtx1col != Mtx2row (x _ x)\\n\");\n    return 1;\n  }\n```\n\n\nGet elements of first matrix\n\n```\n  printf(\"Enter elements of First Matrix: \\n\");\n  for (c = 0; c < Mtx1row; c++)\n  for (d = 0; d < Mtx1col; d++)\n  {\n    printf(\"\\tEnter element %d%d: \", c+1, d+1);\n    scanf(\"%d\", &first[c][d]);\n  }\n```\n\n\nGet elements of second matrix\n\n```\nprintf(\"Enter elements of Second Matrix: \\n\");\n  for (c = 0; c < Mtx2row; c++)\n  for (d = 0; d < Mtx2col; d++)\n  {\n    printf(\"\\tEnter element %d%d: \", c+1, d+1);\n    scanf(\"%d\", &second[c][d]);\n  }\n```\n\n\nMultiply Matrix 1 and 2 and store into Matrix Product\n\n```\n  for (c=0; c < Mtx2row; c++){\n    for (d=0; d < Mtx2col; d++){\n      for (e=0; e < Mtx1col; e++){\n        mult[c][d] += first[c][d] * second[d][e];\n      }\n    }\n  }\n```\n\n    ", "Answer": "\r\nTwo matrices could be multiplied if an only if\n\n```\n#columns of the first matrix = #rows of the second matrix.\n```\n\n\nSo you need to check this before creating the 2D arrays themselves.\n\n```\nif(Mtx1col == Mtx2row){\n  //proceed creating the matrices\n  int first[Mtx1row][Mtx1col], second[Mtx2row][Mtx2col];\n  int mult[Mtx1row][Mtx2col]; // The resulting matrix is Mtx1row * Mtx2col\n  // You have variable length arrays(VLAs) above.\n}\nelse{\n// put the f/b code here\n}\n```\n\n\nNote\n\n\n  Under C11, VLAs are an optional feature rather than a mandatory feature,\n  as they were under C99.\n  The term variable in variable-length array does not mean that you can\n  modify the length of the array after you create it. Once created, a\n  VLA keeps the same size. What the term variable does mean is that you\n  can use a variable when specifying the array dimensions when first\n  creating the array.\n\n\n\n\n The above excerpt is from Stephen Prata's C++ Primer Plus 6th edition\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "What is Chain Matrix Multiplication?\r\n                \r\nI am trying to understand what is a chain matrix multiplication and how it is different from a regular multiplication. I have checked several sourcers yet all seem to be very academically explained for me to understand.\n\nI guess it is a form of dynamic programming algorithm to achieve the operation in an optimised way but I didn't go any further.\n\nThanks\n    ", "Answer": "\r\nChain multiplication is just series of multiplications. A * B * C * D . Originally it has nothing about programming and dynamic programming. But there is nice rule (associative law) A * (B * C) = (A * B) * C, but the computational cost of these expressions are different. So there is a task of optimal brackets distribution. it was intro. now read wiki.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Python Matrix Multiplication vs BLAS\r\n                \r\nWhat method underlies numpy's matrix multiplication?  My understanding is that it uses BLAS, but I get very different runtimes when I perform a matrix multiplication in a Jupyter notebook vs a direct call to blas::gemm in c++.  For example, this code:\n\n```\nimport numpy\nimport time\n\nN = 1000\nmat = numpy.random.rand(N, N)\nstart = time.perf_counter()\nm = mat@mat\nprint(time.perf_counter()-start)\n```\n\n\nGives a runtime of about 0.25 sec on my laptop.  This code:\n\n```\n    float *A_ = new float[n*n], *C_ = new float[n*n];\n\n    for (long i = 0; i < n*n; i++)\n        A_[i] = 1.1;  \n\n    const char tran = 'N';  float alpha = 1, beta = 0;\n    st = clock();  \n    blas::gemm(&tran, &tran, &n, &n, &n, &alpha, A_, &n, A_, &n, &beta, C_, &n);\n    fn = clock();\n    cout << float(fn-st)/float(CLOCKS_PER_SEC) << endl;\n\n```\n\n\ntakes about 0.85 sec to run.  So, I'm guessing numpy is using something else besides blas::gemm.  Does anyone know what it's using under the hood?  Thanks in advance.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "I am trying to make matrix multiplication code in php but instead of matrix multiplication it happens just simple multiplication with row and column\r\n                \r\nI want to do matrix multiplication using array in PHP I have trying to do same but instead of matrix multiplication it just happening Simple multiplication as per output please help me to resolve it.\n\nHere is my code:\n\n```\n<?php\n$a1 = Array('0' => Array('0' => 1,'1' => 2),'1' => Array('0' => 4,'1' => 5));\n\n$a2 = Array('0' => Array('0' => 7,'1' => 5),'1' => Array('0' => 3,'1' => 2));\n\n$sumArray = array();\n\n$result = array();\nfor($i=0; $i<=1; $i++)\n{\n    for($j=0; $j<=1; $j++)\n    {\n        $result[$i][$j] = $a1[$i][$j] * $a2[$i][$j];\n    }\n}\necho \"<pre/>\";\nprint_r($result);\n?>\n```\n\n\nOutput:\n\narray image\n    ", "Answer": "\r\n```\n<?php\n\n\n\n$a = Array('0' => Array('0' => 1,'1' => 2),'1' => Array('0' => 4,'1' => 5));\n\n\n$b = Array('0' => Array('0' => 7,'1' => 5),'1' => Array('0' => 3,'1' => 2));\n\n$sumArray = array();\n\n$c = array();\n\nfor($i=0;$i<2;$i++) {\n for($j=0;$j<2;$j++) \n { \n    $c[$i][$j]=0; \n    for($k=0;$k<2;$k++) \n        { $c[$i][$j]=$c[$i][$j]+($a[$i][$k]*$b[$k][$j]); \n    } \n} \n} \n\n\necho \"<pre/>\";\nprint_r($c);\n?>\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Non Square Matrix Multiplication in Opencl\r\n                \r\nI want to do matrix multiplication with 2 non square matrices,(2000,100), (100,100), I try to use block submatrix as in the Nvidia example, but the result is wrong, I found a solved method here.\nNon Square Matrix Multiplication in CUDA\nit uses zero padding, so I change block size to 16, but it's a wrong work group size, \nI use pyopencl and can't use Blas and so on.\n    ", "Answer": "\r\nOne of the best presentations I have seen on the topic to date was at AFDS 2011.\n\nPDF presentation.\n\nVideo (stream)\n\nVideo (download)\n\nTheir matrices were huge --Linpack-sized-- and non-square. You can scale their main GPU  kernel's block size down from 1024 to something smaller (32,64,128?) to better solve your problem, as possibly even fit into LDS on your hardware. The presenters used the CPU to process the irregular dimensioned areas that were untouched by the GPU.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication mapreduce\r\n                \r\nI'm working on the matrix multiplication using mapreduce. I built a jar file using the code below. the code works perfectly fine with smaller matrices but when the files becomes large the mapping phase will stop at 67% then it will give me this errors below:\n```\nJava.Lang.ArrayIndexOutOfBoundsException: 2\n    at MatrixMult$mapper.map(MatrixMult.java:44)\n    at Matrix$mapper.map(MatrixMult.java:1)\n    at org.apache.hadoop.mapreduce.mapper.run(Mapper.java:145)\n    at org.apache.hadoop.mapred.Maptask.runNewMapper(mapTask.java:793)\n    at org.apache.hadoop.mapred.maptask.run(maptask.java:341)\n    at org.apache.hadoop.mapred.yarnChild$2.run(YarnChild.java:164)\n    at java.security.accesscontroller.dopriviledged(Native Method)\n    at javax.security.auth.subject.doAs(Subject.Java:415)\n    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)\n    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n```\n\nmapreduce worked when I used a smaller matrix. I will post the code for mapper and reducer below:\n```\npublic class Map\n  extends org.apache.hadoop.mapreduce.Mapper<LongWritable, Text, Text, Text> {\n        @Override\n        public void map(LongWritable key, Text value, Context context)\n                        throws IOException, InterruptedException {\n                Configuration conf = context.getConfiguration();\n                int m = Integer.parseInt(conf.get(\"m\"));\n                int p = Integer.parseInt(conf.get(\"p\"));\n                String line = value.toString();\n                // (M, i, j, Mij);\n                String[] indicesAndValue = line.split(\",\");\n                Text outputKey = new Text();\n                Text outputValue = new Text();\n                if (indicesAndValue[0].equals(\"M\")) {\n                        for (int k = 0; k < p; k++) {\n                                outputKey.set(indicesAndValue[1] + \",\" + k);\n                                // outputKey.set(i,k);\n                                outputValue.set(indicesAndValue[0] + \",\" + indicesAndValue[2]\n                                                + \",\" + indicesAndValue[3]);\n                                // outputValue.set(M,j,Mij);\n                                context.write(outputKey, outputValue);\n                        }\n                } else {\n                        // (N, j, k, Njk);\n                        for (int i = 0; i < m; i++) {\n                                outputKey.set(i + \",\" + indicesAndValue[2]);\n                                outputValue.set(\"N,\" + indicesAndValue[1] + \",\"\n                                                + indicesAndValue[3]);\n                                context.write(outputKey, outputValue);\n                        }\n                }\n        }\n}\n\n\n\n\npublic class Reduce\n  extends org.apache.hadoop.mapreduce.Reducer<Text, Text, Text, Text> {\n        @Override\n        public void reduce(Text key, Iterable<Text> values, Context context)\n                        throws IOException, InterruptedException {\n                String[] value;\n                //key=(i,k),\n                //Values = [(M/N,j,V/W),..]\n                HashMap<Integer, Float> hashA = new HashMap<Integer, Float>();\n                HashMap<Integer, Float> hashB = new HashMap<Integer, Float>();\n                for (Text val : values) {\n                        value = val.toString().split(\",\");\n                        if (value[0].equals(\"M\")) {\n                                hashA.put(Integer.parseInt(value[1]), Float.parseFloat(value[2]));\n                        } else {\n                                hashB.put(Integer.parseInt(value[1]), Float.parseFloat(value[2]));\n                        }\n                }\n                int n = Integer.parseInt(context.getConfiguration().get(\"n\"));\n                float result = 0.0f;\n                float m_ij;\n                float n_jk;\n                for (int j = 0; j < n; j++) {\n                        m_ij = hashA.containsKey(j) ? hashA.get(j) : 0.0f;\n                        n_jk = hashB.containsKey(j) ? hashB.get(j) : 0.0f;\n                        result += m_ij * n_jk;\n                }\n                if (result != 0.0f) {\n                        context.write(null,\n                                        new Text(key.toString() + \",\" + Float.toString(result)));\n                }\n        }\n}\n\n\n\npublic class MatrixMultiply {\n\n    public static void main(String[] args) throws Exception {\n        if (args.length != 2) {\n            System.err.println(\"Usage: MatrixMultiply <in_dir> <out_dir>\");\n            System.exit(2);\n        }\n        Configuration conf = new Configuration();\n        // M is an m-by-n matrix; N is an n-by-p matrix.\n        conf.set(\"m\", \"1000\");\n        conf.set(\"n\", \"100\");\n        conf.set(\"p\", \"1000\");\n        @SuppressWarnings(\"deprecation\")\n                Job job = new Job(conf, \"MatrixMultiply\");\n        job.setJarByClass(MatrixMultiply.class);\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(Text.class);\n\n        job.setMapperClass(Map.class);\n        job.setReducerClass(Reduce.class);\n\n        job.setInputFormatClass(TextInputFormat.class);\n        job.setOutputFormatClass(TextOutputFormat.class);\n\n        FileInputFormat.addInputPath(job, new Path(args[0]));\n        FileOutputFormat.setOutputPath(job, new Path(args[1]));\n\n        job.waitForCompletion(true);\n    }\n}\n```\n\nI'm not quite sure where the error is coming from but I know whenever I use a large file I run into this issue\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "2D matrix multiplication in c\r\n                \r\nI have written a code in C language for matrix multiplication. There is no error, but the desired output is not coming, which part of my code is wrong or had I miss something.\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n\nint main() {\n    int r1, c1, r2, c2;\n    int a[r1][c1];\n    int b[r2][c2];\n    int c[r1][c2];\n    int i, j;\n    printf(\"enter row1 and col1:\\n\");\n    scanf(\"%d%d\", &r1, &c1);\n    printf(\"enter row2 and col2:\\n\");\n    scanf(\"%d%d\", &r2, &c2);\n    if (c1 == r2) {\n        printf(\"enter element of 1st matrix:\");\n        for (i = 0; i < r1; i++) {\n            for (j = 0; j < c1; j++) {\n                scanf(\"%d\", &a[i][j]);\n            }\n        }\n        printf(\"\\n-----------------\");\n        printf(\"enter element of 2nd matrix:\");\n        for (i = 0; i < r2; i++) {\n            for (j = 0; j < c2; j++) {\n                scanf(\"%d\", &b[i][j]);\n            }\n        }\n    \n        printf(\"the resultant matrix is:\\n\");\n        for (i = 0; i < r1; i++) {\n            for (j = 0; j < c2; j++) {\n                c[i][j] += a[i][j] * b[j][i];\n            }\n        }\n        for (i = 0; i < r1; i++) {\n            for (j = 0; j < c2; j++) {\n                printf(\"%d\\t\", c[i][j]);\n            }\n            printf(\"\\n\\n\");\n        }\n    }\n    return 0;\n}\n```\n\n    ", "Answer": "\r\nThere are multiple problems in the code:\n\nthe arrays ```\nint a[r1][c1];```\n, ```\nint b[r2][c2];```\n, ```\nint c[r1][c2];```\n are defined before ```\nr1```\n and ```\nc1```\n have been read from the user: the code has potential undefined behavior as ```\nr1```\n and ```\nc1```\n are uninitialized, thus have indeterminate values: the allocation of the arrays may fail or cause undefined behavior if the sizes happen to be negative and accessing them with index values iterating up to different boundary values entered by the user will have undefined behavior.\n\nyou verify that the number of columns of ```\na```\n is equal to the number of rows of ```\nb```\n, but you should also check that all dimensions are positive to avoid potential undefined behavior.\n\nDefining the matrices as variable length arrays with automatic storage is risky: large sizes may cause a stack overflow.  Allocating the matrices from the heap is recommended.\n\nthe multiplication algorithm is incorrect: you must implement a triple loop and initialize the target element at ```\nc1[i][j]```\n before the inner loop.\n\n\nHere is a modified version:\n```\n#include <stdio.h>\n#include <stdlib.h>\n\nint main() {\n    int r1, c1, r2, c2;\n    printf(\"enter row1 and col1:\\n\");\n    if (scanf(\"%d%d\", &r1, &c1) != 2)\n        return 1;\n    printf(\"enter row2 and col2:\\n\");\n    if (scanf(\"%d%d\", &r2, &c2) != 2)\n        return 1;\n    if (r1 <= 0 || c1 <= 0 || r2 <= 0 || c2 <= 0 || c1 != r2) {\n        printf(\"invalid matrix sizes\\n\");\n        return 1;\n    } else {\n#if !defined ALLOCATE_MATRICES_FROM_THE_HEAP\n        // if the dimensions are small, you can define the matrices as\n        int a[r1][c1], b[r2][c2], c[r1][c2];\n#else\n        // for large sizes, you can allocate the matrices from the heap this way:\n        int (*a)[c1] = calloc(sizeof(*a), r1);\n        int (*b)[c2] = calloc(sizeof(*b), r2);\n        int (*c)[c2] = calloc(sizeof(*c), r1);\n        if (a == NULL || b == NULL || c == NULL) {\n            printf(\"out of memory\\n\");\n            return 1;\n        }\n#endif\n        printf(\"enter elements of 1st matrix:\");\n        for (int i = 0; i < r1; i++) {\n            for (int j = 0; j < c1; j++) {\n                a[i][j] = 0;\n                scanf(\"%d\", &a[i][j]);\n            }\n        }\n        printf(\"\\n-----------------\");\n        printf(\"enter elements of 2nd matrix:\");\n        for (int i = 0; i < r2; i++) {\n            for (int j = 0; j < c2; j++) {\n                b[i][j] = 0;\n                scanf(\"%d\", &b[i][j]);\n            }\n        }\n    \n        printf(\"the resultant matrix is:\\n\");\n        for (int i = 0; i < r1; i++) {\n            for (int j = 0; j < c2; j++) {\n                int v = 0;\n                for (int k = 0; k < c1; k++) {\n                    v += a[i][k] * b[k][j];\n                }\n                c[i][j] = v;\n            }\n        }\n        for (int i = 0; i < r1; i++) {\n            for (int j = 0; j < c2; j++) {\n                printf(\"%5d\\t\", c[i][j]);\n            }\n            printf(\"\\n\\n\");\n        }\n#if defined ALLOCATE_MATRICES_FROM_THE_HEAP\n        free(a);\n        free(b);\n        free(c);\n#endif\n        return 0;\n    }\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Gpu copy bottleneck(fluctuation) during matrix multiplication\r\n                \r\nI am trying to train my updated model with pytorch. It has 6 conv layers and 6 conv transpose layers and the kernels for these layers are made by matrix multiplication. It shows the amazing fluctuation of GPU performance during training like the image below.\n\nI think there are some issues for gpu copy...\nMy prior model has a similar structure to the current model and I use the same dataset and data loader. However, it shows good and stable GPU performance.\nIn my opinion, the only difference is matrix multiplication.\nI tried to use several matrix multiplication methods, but every method shows poor gpu-util.\n\neinsum\n\n```\nkernel = torch.einsum('in,km,blnm,ol->biok', Q, R, phi, P)\n```\n\n\nmatmul\n\n```\nkernel = torch.matmul(phi, R.T)\nkernel = torch.matmul(kernel.transpose(2, 3), Q.T)\nkernel = torch.matmul(kernel.transpose(1, 3), P.T).transpose(2, 3)\n```\n\nP.S. I want the kernel to be contiguous because my memory of GPU is insufficient.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "error in matrix multiplication using pointer\r\n                \r\nI am trying to do the matrix multiplication optimization as given here:\n\n```\nfor(i=0;i<n;i++)\n{\n    for(k=0;k<n;k++)\n    {\n        for(j=0;j<n;j++)\n            C[i][j]+=A[i][k]*B[k][j];\n     }\n}\n```\n\n\nI am trying to implement the above functionality using pointers for matrices instead of static arrays:\n\n```\nint *A,*B,*C;\n\n   A= (int*)malloc(sizeof(int*)*(n * n));\n   B= (int*)malloc(sizeof(int*)*(n * n));\n   C= (int*)malloc(sizeof(int*)*(n * n));\n\n    for ( i = 0 ; i < n ; i++ )\n    {\n      for ( k = 0 ; k < n ; k++ )\n      {  sum=0;\n        for ( j = 0 ;  j< n ; j++ )\n        {\n           double c =A[i*n + k];                              \n           double d =B[k*n + j];\n           sum+=c*d;                             \n    }\n      C[i*n + j] =sum;\n      }\n\n\n    }\n```\n\n\nBut the answers are not coming same as the above code snippet.\n I am running this code in Linux ubuntu 12.04. please help resolve this issue . Is ther any logical error?\n\nUPDATE\n\nconsider the following example: \n\n```\nmatrix A\n\n1  1\n\n1  1\n\n\n\nmatrix B\n\n1   1\n\n1   1\n```\n\n\nand expected output matrix is \n\n```\n  matrix C \n\n  2    2 \n\n  2    2\n```\n\n\nbut for matrix multiplication optimization using pointers as shown above, output is different\n\n```\n   matrix C\n\n   0    0 \n\n   7    9\n```\n\n    ", "Answer": "\r\n```\nsum=0;\nfor ( j = 0 ;  j< n ; j++ )\n{\n    double c =A[i*n + k];\n    double d =B[k*n + j];\n    sum+=c*d;\n}\nC[i*n + j] =sum;\n```\n\n\nyour code has  two problems.\n\n\nthat plus the sum is wrong. (logic error)\n```\ni*n + j```\n when j is loop over, always n(2).\n\n\nshould be to\n\n```\nfor ( i = 0 ; i < n ; i++ ){\n    for ( k = 0 ; k < n ; k++ ){\n        for ( j = 0 ;  j< n ; j++ ){\n            C[i*n + j] +=A[i*n + k]*B[k*n + j];//C initialized by 0\n        }\n    }\n}\n```\n\n\nalso should be\n\n```\nA= (int*)malloc(sizeof(int)*(n * n));//not sizeof(int*)\nB= (int*)malloc(sizeof(int)*(n * n));\nC= (int*)calloc(n*n, sizeof(int));\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication function C++\r\n                \r\nI seem to have an issue with my matrix multiplication function.\n\nWhen I run the program I just get an n x n  matrix with all of the values the same, as some wired double value, e.g 21312e-2\nHere is my function code:\n\n```\nvoid Multiply(int i, int j, double mat1[10][10], double mat2[10][10]) {\n\n\ndouble mat3[10][10];\nfor (int r = 0; r < i; r++) {\n    for (int c = 0; c < j; c++) {\n        for (int in = 0; in < i; in++) {\n            mat3[r][c] += mat1[r][in] * mat2[in][c];\n        }\n        cout << mat3[r][c] << \"  \";\n    }\n    cout << \"\\n\";\n}\n```\n\n\n}\n\nmat1 and mat 2 are read into the program in the main thread using the function read:\n\n```\nvoid read_matrix(int m, int n, double mat[10][10])\n{\n    int i, j;\n    for (i = 0; i<m; ++i)\n        for (j = 0; j<n; ++j)\n            cin >> mat[i][j];\n}\n```\n\n\nEdit:Main Code\n\n```\nint main()\n{\n    int i1, i2, j1, j2;\n    double mat1[10][10], mat2[10][10], mat3[10][10];\n\n    scanf_s(\"%d %d\\n\", &i1, &j1, mat1);\n\n\n    read_matrix(i1, j1, mat1);\n\n    scanf_s(\"%d %d\\n\", &i2, &j2, mat2);\n\n    read_matrix(i2, j2, mat2);\n\n    printf(\"%d x %d matrix\\n\", i1, j1);\n    print_matrix(i1, j1, mat1);\n    printf(\"\\n%d x %d matrix\\n\", i2, j2);\n    print_matrix(i2, j2, mat2);\n\n    Multiply(i1, j2, mat1, mat2);\n    system(\"pause\");\n    return 0;\n}\n```\n\n    ", "Answer": "\r\nYou need to fill ```\nmat3```\n with a zero value before adding to it. \n\nSimplest way is to use:\n\n```\ndouble mat3[10][10] = {};\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Fastest way to compute matrix multiplication\r\n                \r\nI compute the matrix multiplication as follows:\n\n```\n    import numpy as np\n    A=np.random.randn(1,3000,30000)\n    B=np.random.randn(50,1,30000)\n    C=A*B\n```\n\n\nThe computation of ```\nC```\n takes about 10 minutes. How could I improve this?\n\n```\n    In [4]: timeit A*B\n    1 loops, best of 3: 1min 59s per loop\n```\n\n\nUpdate\n\n    ", "Answer": "\r\nIt seems your main bottleneck is RAM size. The result of your computation is 36 GB in size, making your operating system write data to swap. You may try to use dask to do out of core computation and directly stream the result to a HDF5 file:\n\n```\nimport dask\nimport dask.array\n\nA = dask.array.random.random((1, 3000, 300000), chunks=1024)\nB = dask.array.random.random((50, 1, 300000), chunks=1024)\n\nC = A * B\n\ndask.array.to_hdf5('myfile.hdf5', '/C', C)\n```\n\n\nmake sure to install\n\n```\npip install dask[array]\npip instal h5py\n```\n\n\nThis probably won't speed up your computation as you are still I/O bound (still writing to harddisk), but at least it will make the computation manageable and keep your computer responsive.\n\nAnother solution would be to manually slice the operation, if you don't need all of ```\nC```\n for future computations:\n\n```\nfor i in B.shape[0]:\n    C = A * B[i, ...]  # do not save this result but rather use and discard it immediately\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Gpu copy bottleneck(fluctuation) during matrix multiplication\r\n                \r\nI am trying to train my updated model with pytorch. It has 6 conv layers and 6 conv transpose layers and the kernels for these layers are made by matrix multiplication. It shows the amazing fluctuation of GPU performance during training like the image below.\n\nI think there are some issues for gpu copy...\nMy prior model has a similar structure to the current model and I use the same dataset and data loader. However, it shows good and stable GPU performance.\nIn my opinion, the only difference is matrix multiplication.\nI tried to use several matrix multiplication methods, but every method shows poor gpu-util.\n\neinsum\n\n```\nkernel = torch.einsum('in,km,blnm,ol->biok', Q, R, phi, P)\n```\n\n\nmatmul\n\n```\nkernel = torch.matmul(phi, R.T)\nkernel = torch.matmul(kernel.transpose(2, 3), Q.T)\nkernel = torch.matmul(kernel.transpose(1, 3), P.T).transpose(2, 3)\n```\n\nP.S. I want the kernel to be contiguous because my memory of GPU is insufficient.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication function C++\r\n                \r\nI seem to have an issue with my matrix multiplication function.\n\nWhen I run the program I just get an n x n  matrix with all of the values the same, as some wired double value, e.g 21312e-2\nHere is my function code:\n\n```\nvoid Multiply(int i, int j, double mat1[10][10], double mat2[10][10]) {\n\n\ndouble mat3[10][10];\nfor (int r = 0; r < i; r++) {\n    for (int c = 0; c < j; c++) {\n        for (int in = 0; in < i; in++) {\n            mat3[r][c] += mat1[r][in] * mat2[in][c];\n        }\n        cout << mat3[r][c] << \"  \";\n    }\n    cout << \"\\n\";\n}\n```\n\n\n}\n\nmat1 and mat 2 are read into the program in the main thread using the function read:\n\n```\nvoid read_matrix(int m, int n, double mat[10][10])\n{\n    int i, j;\n    for (i = 0; i<m; ++i)\n        for (j = 0; j<n; ++j)\n            cin >> mat[i][j];\n}\n```\n\n\nEdit:Main Code\n\n```\nint main()\n{\n    int i1, i2, j1, j2;\n    double mat1[10][10], mat2[10][10], mat3[10][10];\n\n    scanf_s(\"%d %d\\n\", &i1, &j1, mat1);\n\n\n    read_matrix(i1, j1, mat1);\n\n    scanf_s(\"%d %d\\n\", &i2, &j2, mat2);\n\n    read_matrix(i2, j2, mat2);\n\n    printf(\"%d x %d matrix\\n\", i1, j1);\n    print_matrix(i1, j1, mat1);\n    printf(\"\\n%d x %d matrix\\n\", i2, j2);\n    print_matrix(i2, j2, mat2);\n\n    Multiply(i1, j2, mat1, mat2);\n    system(\"pause\");\n    return 0;\n}\n```\n\n    ", "Answer": "\r\nYou need to fill ```\nmat3```\n with a zero value before adding to it. \n\nSimplest way is to use:\n\n```\ndouble mat3[10][10] = {};\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Multithreaded matrix multiplication [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs to be more focused. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\r\n                \r\n                    \r\n                        Closed 7 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI recently started lerning multithreading in java. Since I'm writing a program for numerical calculations at my University, i decided to make some first attempts by programming multithreaded matrix multiplication.\n\nThis is my code. Please keep in mind that this was just made as a first attempt and is not very clean.\n\n```\n    public class MultithreadingTest{\n\n        public static void main(String[] args) {\n            // TODO Auto-generated method stub\n            double[][] matrix1 = randomSquareMatrix(2000);\n            double[][] matrix2 = randomSquareMatrix(2000);\n\n            matrixMultiplication(matrix1,matrix2,true);\n            matrixMultiplicationSingleThread(matrix1, matrix2);\n            try {\n                matrixMultiplicationParallel(matrix1,matrix2, true);\n            } catch (InterruptedException | ExecutionException e) {\n                // TODO Auto-generated catch block\n                e.printStackTrace();\n            }\n            try {\n                matrixMultiplicationParallel2(matrix1,matrix2, true);\n            } catch (InterruptedException | ExecutionException e) {\n                // TODO Auto-generated catch block\n                e.printStackTrace();\n            }\n\n        }\n\n        public static double[][] randomSquareMatrix(int n){\n            double[][] mat = new double[n][n];\n            Random rand = new Random();\n            for(int i=0; i<n; i++) for(int j=0; j<n; j++) mat[i][j]=rand.nextInt(10);\n            return mat;\n        }\n        public static void printSquareMat(double[][] mat){\n            int n=mat.length;\n            for(int i=0; i<n; i++){ for(int j=0; j<n; j++) System.out.print(mat[i][j]+\" \"); System.out.print(\"\\n\");}\n            System.out.print(\"\\n\");\n        }\n\n        public static void average(double[][] matrix)\n        {\n            int n=matrix.length;\n            double sum=0;\n            for(int i=0; i<n; i++) for(int j=0; j<n; j++) sum+=matrix[i][j];\n\n            System.out.println(\"Average of all Elements of Matrix : \"+(sum/(n*n)));\n        }\n\n        public static void matrixMultiplication(double[][] matrix1, double[][] matrix2, boolean printMatrix){\n\n            int n=matrix1.length;\n            double[][] resultMatrix = new double[n][n];\n\n            double startTime = System.currentTimeMillis();\n\n            for(int i=0; i<n; i++)for(int j=0; j<n; j++)for(int k=0; k<n; k++) resultMatrix[i][j]+=matrix1[i][k]*matrix2[k][j];\n\n\n            if (printMatrix && n<=5)for(int i=0; i<n; i++){for(int j=0; j<n; j++) System.out.print(resultMatrix[i][j]+\" \");System.out.print(\"\\n\"); }\n\n            System.out.print(\"\\n\");\n            System.out.println(((System.currentTimeMillis()-startTime)/1000)+\n                    \" seconds for matrix of size \"+n+\" in main thread.\");\n            average(resultMatrix);\n        }\n\n        public static void matrixMultiplicationSingleThread(double[][] m1, double[][] m2)\n        {\n            int n=m1.length;\n            double startTime = System.currentTimeMillis();\n            Thread t = new Thread(new multiSingle(m1,m2));\n            t.start();\n            try {\n                t.join();\n            } catch (InterruptedException e) {\n                // TODO Auto-generated catch block\n                System.out.println(\"Error\");\n                e.printStackTrace();\n            }\n            System.out.print(\"\\n\");\n            System.out.println(((System.currentTimeMillis()-startTime)/1000)+\n                    \" seconds for matrix of size \"+n+\" in external Thread.\");\n\n        }\n\n        public static void matrixMultiplicationParallel(double[][] matrix1, double[][] matrix2, boolean printMatrix) throws InterruptedException, ExecutionException{\n\n            int n=matrix1.length;\n            double[][] resultMatrix=new double[n][n];\n            double tmp;\n            ExecutorService exe = Executors.newFixedThreadPool(2);\n            Future<Double>[][] result = new Future[n][n];\n            double startTime = System.currentTimeMillis();\n            for(int i=0; i<n; i++)\n            {\n                for(int j=0; j<=i; j++)\n                {\n                    tmp=matrix2[i][j];\n                    matrix2[i][j]=matrix2[j][i];\n                    matrix2[j][i]=tmp;\n                }\n            }\n\n            for(int i=0; i<n; i++)\n            {\n                for(int j=0; j<n; j++)\n                {\n                    result[i][j] = exe.submit(new multi(matrix1[i],matrix2[j]));\n                }\n            }\n\n            exe.shutdown();\n            exe.awaitTermination(1, TimeUnit.DAYS);\n\n            for(int i=0; i<n; i++)\n            {\n                for(int j=0; j<n; j++)\n                {\n                    resultMatrix[i][j] = result[i][j].get();\n                }\n            }\n            for(int i=0; i<n; i++)\n            {\n                for(int j=0; j<=i; j++)\n                {\n                    tmp=matrix2[i][j];\n                    matrix2[i][j]=matrix2[j][i];\n                    matrix2[j][i]=tmp;\n                }\n            }\n            if (printMatrix && n<=5)for(int i=0; i<n; i++){for(int j=0; j<n; j++) System.out.print(resultMatrix[i][j]+\" \");System.out.print(\"\\n\"); }\n\n            System.out.print(\"\\n\");\n            System.out.println(((System.currentTimeMillis()-startTime)/1000)+\n                    \" seconds for matrix of size \"+n+\" multithreaded with algorithm 1.\");\n            average(resultMatrix);\n        }\n\n        public static void matrixMultiplicationParallel2(double[][] matrix1, double[][] matrix2, boolean printMatrix) throws InterruptedException, ExecutionException{\n\n            int n=matrix1.length;\n            double[][] resultMatrix=new double[n][n];\n            double tmp;\n            ExecutorService exe = Executors.newFixedThreadPool(2);\n            Future<Double>[][] result = new Future[n][n];\n            double startTime = System.currentTimeMillis();\n\n\n            for(int i=0; i<n; i++)\n            {\n                for(int j=0; j<n; j++)\n                {\n                    result[i][j] = exe.submit(new multi2(i,j,matrix1,matrix2));\n                }\n            }\n\n            exe.shutdown();\n\n            exe.awaitTermination(1, TimeUnit.DAYS);\n\n\n            for(int i=0; i<n; i++)\n            {\n                for(int j=0; j<n; j++)\n                {\n                    resultMatrix[i][j] = result[i][j].get();\n                }\n            }\n\n            if (printMatrix && n<=5)for(int i=0; i<n; i++){for(int j=0; j<n; j++) System.out.print(resultMatrix[i][j]+\" \");System.out.print(\"\\n\"); }\n\n            System.out.print(\"\\n\");\n            System.out.println(((System.currentTimeMillis()-startTime)/1000)+\n                    \" seconds for matrix of size \"+n+\" multithreaded with algorithm 2.\");\n            average(resultMatrix);\n        }\n\n        public static class multi implements Callable<Double>{\n\n            multi(double[] vec1, double[] vec2){\n                this.vec1=vec1; this.vec2=vec2;\n            }\n            double result;\n            double[] vec1, vec2;\n\n            @Override\n            public Double call() {\n                result=0;\n                for(int i=0; i<vec1.length; i++) result+=vec1[i]*vec2[i];\n                return result;\n            }\n        }\n\n        public static class multi2 implements Callable<Double>{\n\n            multi2(int a, int b, double[][] vec1, double[][] vec2){\n                this.a=a; this.b=b; this.vec1=vec1; this.vec2=vec2;\n            }\n            int a,b;\n            double result;\n            double[][] vec1, vec2;\n\n            @Override\n            public Double call() {\n                result=0;\n                for(int i=0; i<vec1.length; i++) result+=vec1[a][i]*vec2[i][b];\n                return result;\n            }\n        }\n\n        public static class multiSingle implements Runnable{\n\n            double[][] matrix1, matrix2;\n\n            multiSingle(double[][] m1, double[][] m2){\n                matrix1=m1;\n                matrix2=m2;\n            }\n            public static void matrixMultiplication(double[][] matrix1, double[][] matrix2, boolean printMatrix){\n\n                int n=matrix1.length;\n                double[][] resultMatrix = new double[n][n];\n\n                for(int i=0; i<n; i++)for(int j=0; j<n; j++)for(int k=0; k<n; k++) resultMatrix[i][j]+=matrix1[i][k]*matrix2[k][j];\n\n                MultithreadingTest.average(resultMatrix);\n            }\n\n            @Override\n            public void run() {\n                matrixMultiplication(matrix1, matrix2, false);\n            }\n        }\n\n    }\n```\n\n\nI have two general questions to multithreading, i hope it's ok not opening a new topic for this.\n\n\nIs there a way to write the code without additional classes for the threads that implement runnable or callable? I looked at approaches using anonymous inner classes and lambdas, but as far as I have fount information I can't pass parameters to the threads this way since run() and call() don't take any, that is, unless the parameters are final. But assuming I write a class for matrix operations, I would prefer not to write an additinal class for every operation I want to run in a thread.\nAssuming my class does many multithreaded operations, creating a new thread pool and shutting it down in every method would waste a lot of resources, I guess. So I would like to create a thread pool as member ob my class, instantiating it when needed and using invokeAll. But what happens if my object is deleted? Will I get problems since I never shut down the thread pool? In C++ I would use a destructor for this. Or does the gc take care of everything in this case?\n\n\nNow concering my code directly:\n\nI implemented matrix multiplication in four different ways, as method running in my main thread, as method running in a new thread, but still not multithreaded ( to ensure there would not be any background taks in my main thread slowing it down ) , and two different ways of multithreaded matrix multiplication. The first version transposes the second matrix, submits the multiplication as vector-vector-multiplication and transposes the matrix back to its original form. The second version takes the matrices directly and additinaly takes two indices to define the row and column of the matrices for vector-vector-multiplication.\n\nFor all versions I measured the time needed for multiplication and calculated the average value af the resulting matrices to see whether the reults are the same.\n\nI've run this code on two computers, both the same JVM and both Windows 10. The first is my Laptop, i5 5th generation, 2,6 Ghz dual core, and the second one in my Desktop PC, i5 4th generation, 4,2 Ghz quad core.\n\nI expected my Desktop-PC to be much faster. I also expected the multithreaded versions to take about half/quarter the time of the signle threaded version, but still more since there is additional work for creating the threads etc. And last, i expected the second multithreaded version, which does not transpose one matrix twice, to be faster, since there are less operations.\n\nAfter running the code I'm a little confused about the results, i hope someone can explain it to me:\n\nFor both single threaded methods my Laptop needs roughly 340s (for a matrix size of 3000). So i assume there are no expensive background tasks done in my main thread. My Desktop Pc on the other hand need 440s. Now the question is, why is my Laptop, which is defenitely slower, that much faster? Even if the fifth generation is faster than the 4th generation, since my Desktop PC runs at 1.6 times my Laptop's speed i would still expect it to be faster. The difference between those generations is unlikely that big.\n\nFor the multithreaded methods my Laptop need roughly 34s. If the multithreading would be perfect, then it should not take less than half. Why is it on two threads ten times faster? The same goes for my Desktop PC. Using four threads the multiplication is done in 16s instead of 440s. This is like my Desktop Pc is working with the same speed as my Laptop, just on four instead of two threads.\n\nNow for the comparison between the two multithreaded methods, the version which transposes one matrix twice takes roughly 34s on my Laptop, the version which takes the matrices directly takes roughly 200s. That sounds realistic, since it's more than half of the single threaded method. But why is it that much slower than the first version? I would assume that transposing a matrix twice would be slower than the additional time to get the matrix elements? Is there something i'm missing or is working with a matrix really that much slower than working with a vector?\n\nI hope someone can answer these questions. Sorry for writing such a long post.\n\nYours sincerely\nThorsten\n    ", "Answer": "\r\nThe answer to the big mystery this this:  The time required to do the matrix multiplication is dominated by the time spent moving data from RAM to the CPU cache.  You may have 4 cores, but you only have 1 RAM bus, so you won't get any benefit by using more cores (multithreading) if they all block each other waiting for memory access.\n\nThe first experiment you should try is this:  Write the single-threaded version using the matrix transpose and vector multiplication.  You will find that it is MUCH faster -- probably about as fast as the multithreaded version with the transpose.\n\nThe reason why the original single-threaded version is so slow, is because it has to load a cache block for every cell in the column being multiplied.  If you use the matrix transpose, then all those cells are sequential in memory, and loading one block gets you a bunch of them.\n\nSo, if you want to optimize matrix multiplication, FIRST optimize memory access for cache efficiency, THEN divide the work up between a few threads -- no more than twice as many threads as you have cores.  Anything more just wastes time and resources with context switches, etc.\n\nregarding your other questions:\n\n1) It's convenient to use lambdas that capture variables from the scope that creates them, like:\n\n```\nfor(int i=0; i<n; i++)\n{\n    for(int j=0; j<n; j++)\n    {\n        final double[] v1 = matrix1[i];\n        final double[] v2 = matrix2[j];\n        result[i][j] = exe.submit(() -> vecdot(v1,v2));\n    }\n}\n```\n\n\n2)  The GC will take care of it.  You don't need to explicitly shut down the thread pool to free any resources.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "\"Vectorized\" matrix multiplication\r\n                \r\nSuppose I have two matrices x and y, both with dimensions 100x2.  I would like to create a list such that for each row of x and y, I have the matrix t(x) %*% y.  For example, via a for loop:\n\n```\nx = matrix(rnorm(10), nrow = 5)\ny = matrix(rnorm(10), nrow = 5)\nmyList = list()\nfor(i in 1:5){\n    myList[[i]] = t(x[i, , drop = FALSE]) %*% y[i, ]\n}\n```\n\n\nIs there a more efficient way to do this calculation?  I've tried to figure out how to express this a matrix multiplication but have had no luck.  I've also considered mapply, but it seems as if I'd need to convert x and y to lists of vectors instead of matrices to use mapply, and I'm skeptical that that is the correct approach either.\n    ", "Answer": "\r\nOne way with ```\nMap```\n\n\n```\nMap(function(x,y) matrix(x,ncol=1)%*%y ,\n               split(x, row(x)), split(y, row(y))) \n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "cuda matrix multiplication size\r\n                \r\ni am new to cuda c..i wrote a basic matrix multiplication programme using shared memory..but the problem is i cannot increase the matrix size beyond 288 and if i does so i get stack overflow error..i have nvidia gtx 480 gpu..could anyone pls tell me how to increase the size and what mistakes i'm doing\n\n```\n#define tile_width 16\n#define width 288\nvoid mat_mul_kernel1(int *a,int *b,int *c)\n{\n    int row= blockIdx.y*blockDim.y + threadIdx.y;\n    int col= blockIdx.x*blockDim.x + threadIdx.x;\n    int pvalue=0;\n    __shared__ int sha[tile_width*tile_width];\n    __shared__ int shb[tile_width*tile_width];\n\n    for (int m=0;m<width/tile_width;m++)\n    {\n        sha[threadIdx.y*tile_width+threadIdx.x]=a[row*width+(m*tile_width)+threadIdx.x];\n        shb[threadIdx.y*tile_width+threadIdx.x]=b[(m*tile_width+threadIdx.y)*width+col];\n        __syncthreads();\n        for (int k=0;k<tile_width;k++)\n            pvalue+=sha[threadIdx.y*tile_width+k]*shb[k*tile_width+threadIdx.x];\n        __syncthreads();\n    }\n\n    c[row*width+col]=pvalue;\n}\nint main()\n{\n    int a[width*width],b[width*width],c[width*width];\n    int *deva,*devb,*devc;\n    float etime;\n    for (int i=0;i<width;i++)\n    {\n        for(int j=0;j<width;j++)\n        {\n            a[i*width+j]=1;\n            b[i*width+j]=1;\n        }\n    }\n    cudaEvent_t start,stop;\n    cudaEventCreate(&start);\n    cudaEventCreate(&stop);\n    dim3 dimGrid((int)(width)/tile_width,(int)(width)/tile_width);\n    dim3 dimBlock(tile_width,tile_width);\n    cudaError_t error;\n    error=cudaMalloc((void**)&deva,width*width*sizeof(int));\n    if(error!= cudaSuccess)\n    {\n        printf(\"error at a allocation\");\n        exit(EXIT_FAILURE);\n    }\n    error=cudaMemcpy(deva,a,width*width*sizeof(int),cudaMemcpyHostToDevice);\n    if(error!= cudaSuccess)\n    {\n        printf(\"error at a copying\");\n        exit(EXIT_FAILURE);\n    }\n    error=cudaMalloc((void**)&devb,width*width*sizeof(int));\n    if(error!= cudaSuccess)\n    {\n        printf(\"error at b allocation\");\n        exit(EXIT_FAILURE);\n    }\n    error=cudaMemcpy(devb,b,width*width*sizeof(int),cudaMemcpyHostToDevice);\n    if(error!= cudaSuccess)\n    {\n        printf(\"error at b copying\");\n        exit(EXIT_FAILURE);\n    }\n    error=cudaMalloc((void**)&devc,width*width*sizeof(int));\n    if(error!= cudaSuccess)\n    {\n        printf(\"error at c allocation\");\n        exit(EXIT_FAILURE);\n    }\n    cudaEventRecord(start,0);\n    mat_mul_kernel1<<<dimGrid,dimBlock,tile_width*tile_width*sizeof(int)>>>(deva,devb,devc);\n    cudaEventRecord(stop,0);\n    cudaEventSynchronize(stop);\n    cudaEventElapsedTime(&etime,start,stop);\n    error=cudaMemcpy(c,devc,width*width*sizeof(int),cudaMemcpyDeviceToHost);\n    if(error!= cudaSuccess)\n    {\n        printf(\"error at c copying\");\n        //exit(EXIT_FAILURE);\n    }\n    cudaFree(deva);\n    cudaFree(devb);\n    cudaFree(devc);\n    printf(\"ElapsedTime %f milliseconds\",etime);\n}\n```\n\n    ", "Answer": "\r\nThe problem you see has nothing to do with CUDA. The problems are your arrays a, b, c. They are allocated on the stack. They have a size of ```\n288 x 288 x siezof(int) x 3```\n what leads to 972kB (```\nsizeof(int) = 4 byte```\n). So I asume your hitting the standard maximum stack size, which lies, as far as I know, arround 1MB. \n\nTry to allocate your arrays dynamically on the heap\n\n```\nint* a = (int*) malloc(width * width * sizeof(int));\n```\n\n\nand free the memory at the end \n\n```\nfree(a);\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "vectorizations of matrix multiplication\r\n                \r\nI have many 3*2 matrices(A1,A2,A3..), and each of the 3*2 is a draw. In the case two draws, we have a 3*4 ( we horizontally stack each draw of A1,A2). Clearly, it is easier for me to draw the 3*4 matrix (A) as a larger matrices once instead of draw a 3*2 over and over again.\n\nBut I need to perform a matrix multiplication for each draw(each A1,A2...) to a matrix B. Say A1*B, and A2*B ...AN*B\n\n```\n#each draw of the 3*2 matrix\nA1 = np.array([[ 0,  1],\n              [ 4,  5],\n              [ 8,  9]])\n\nA2 = np.array([[ 2,  3],\n              [ 6,  7],\n              [ 10, 11]])\n\n# A is [A1,A2]\n# Easier to draw A once for all  (the larger matrix)\nA = np.array([[ 0,  1,  2,  3],\n              [ 4,  5,  6,  7],\n              [ 8,  9, 10, 11]])\n\nb = np.array([[ 0,  1],\n              [ 4,  5]\n              ])\n\ndesired output\narray([[ 4,  5, 12, 17],\n       [20, 29, 28, 41],\n       [36, 53, 44, 65]])\n```\n\n    ", "Answer": "\r\nYou can reshape matrix A to 2 columns so that it is conformable to ```\nb```\n, do the matrix multiplication, and then reshape it back:\n\n```\nnp.dot(A.reshape(-1, 2), b).reshape(3, -1)\n\n#array([[ 4,  5, 12, 17],\n#       [20, 29, 28, 41],\n#       [36, 53, 44, 65]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Block Matrix Multiplication [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs debugging details. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     Edit the question to include desired behavior, a specific problem or error, and the shortest code necessary to reproduce the problem. This will help others answer the question.\r\n                \r\n                    \r\n                        Closed 7 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI want to perform a block matrix multiplication(Divide a matirix into multiple sxs matrices and multiply the corresponding blocks). I have written the code as following the sample code of architecture book of Hennesy:  \n\n```\nfor(int jj=0;jj<=(n/s);jj += s){\n            for(int kk=1;kk<=(n/s);kk += s){\n                    for(int i=1;i<=(n/s);i++){\n                            for(int j = jj; j<=((jj+s-1)>(n/s)?(n/s):(jj+s-1)); j++){\n                                    temp = 0;\n                                    for(int k = kk; k<=((kk+s-1)>(n/s)?(n/s):(kk+s-1)); k++){\n                                            temp += b[i][k]*a[k][j];\n                                    }\n                                    c[j][i] += temp;\n                            }\n                    }\n            }\n    }  \n```\n\n\nHere, nxn is the size of original matrix. a, b matrices are of same size. I am dividing a,b matrices into blocks of size sxs. In my program, i have given block size to be 4. I put all elements of a, b as 5, a constant and n = 1000. However, i am getting wrong values in my result. Am i doing something wrong here? Stuck on this from past 2 hours. Can you guys please help if possible. The reference code in book is like this:  \n\n```\nfor (jj = 0; jj <= size; jj += N) {\n    for (kk = 1; kk <= size; kk += N) {\n        for (i = 1; i <= size; i++) {\n            for (j = jj; j <= findMin(jj+N-1, size); j++) {\n                temp = 0;\n                for (k = kk; k <= findMin(kk+N-1, size); k++) {\n                    temp += B[i][k] * A[j][k];\n                }\n                C[j][i] += temp;\n            }\n        }\n     }\n}  \n```\n\n\nHere, s=N and size = n/s  \n    ", "Answer": "\r\n```\nfor(int jj=0;jj<N;jj+= s){\n        for(int kk=0;kk<N;kk+= s){\n                for(int i=0;i<N;i++){\n                        for(int j = jj; j<((jj+s)>N?N:(jj+s)); j++){\n                                temp = 0;\n                                for(int k = kk; k<((kk+s)>N?N:(kk+s)); k++){\n                                        temp += a[i][k]*b[k][j];\n                                }\n                                c[i][j] += temp;\n                        }\n                }\n        }\n}\n```\n\n\nAxB\nsize is N\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "batching matrix multiplication for Eigen Tensors\r\n                \r\nI would like to batch matrix multiplication by taking slices of large tensors.\nSay I have A of shape [N, 1, 4], B of shape [N, 4, 4]. I would like to first slice them along batch dimension, getting [b, 1, 4], and [b, 4, 4] which is not necessarily contiguous, but getting results of shape [b, 4] by doing matrix multiplication in batches. Is there a way to do that using Eigen?\n    ", "Answer": "\r\nI'm not sure if this is an efficient way to perform  batch matrix multiplication for Eigen Tensors but one solution might be mapping tensor pages as matrices and performing general matrix multiplication:\n```\n#include <Eigen/Dense>\n#include <unsupported/Eigen/CXX11/Tensor>\n\ntypedef Eigen::Tensor<double, 3> Tensor3d;\n\ninline void batchedTensorMultiplication(const Tensor3d& A, const Tensor3d& B, const std::vector<int>& batchIndices, Tensor3d& C)\n{\n    Eigen::DenseIndex memStepA = A.dimension(0) * A.dimension(1);\n    Eigen::DenseIndex memStepB = B.dimension(0) * B.dimension(1);\n    Eigen::DenseIndex memStepC = C.dimension(0) * C.dimension(1);\n    int outputBatchIndex = 0;\n\n    for (int batchIndex : batchIndices)\n    {\n        Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>> pageA(A.data() + batchIndex * memStepA, A.dimension(0), A.dimension(1));\n        Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>> pageB(B.data() + batchIndex * memStepB, B.dimension(0), B.dimension(1));\n        Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>> pageC(C.data() + outputBatchIndex * memStepC, C.dimension(0), C.dimension(1));\n\n        outputBatchIndex++;\n\n        pageC.noalias() = pageA * pageB;\n    }\n}\n\nint main() \n{\n    constexpr int N = 50;\n    std::vector<int> batchIndices = { 0,1,2,3,4,9,10,11,12,13 };\n\n    Tensor3d A(1, 4, N), B(4, 4, N), C(1, 4, (int)batchIndices.size());\n\n    batchedTensorMultiplication(A, B, batchIndices, C);\n\n    return 0;\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "MPI.NET C# matrix multiplication\r\n                \r\nI learn MPI.NET library and have a hard task. I need to multiply two matrixes using MPI. I understood that I should send rows and cols to processes and then after calculating show the result matrix. I've seen lots of examples and realizations on C and C++.\n\nBut their MPI_Send and MPI_Receive functions differ from C# MPI.NET ```\nSend(int value, int dest, int tag)```\n and ```\nReceive(int source, int tag, out int value)```\n functions. So, additionally, I cannot entirely comprehend meanings of MPI_Scatter and MPI_Gather functions (I thought it is necessary to use in this matrixes multiplication).\n\nHere is a link to C and C++ example realization of matrixes multiplication via MPI: https://computing.llnl.gov/tutorials/mpi/samples/C/mpi_mm.c\n\nAnd here is my wrong code:\n\n```\nenter code herepublic class Multiplicator\n{\n    private const int Root = 0;\n\n    const int FROM_MASTER = 2;\n\n    const int FROM_WORKER = 2;\n\n    public int N { get { return n; } }\n\n    public double[,] A { get { return a; } }\n    public double[,] B { get { return b; } }\n\n    public bool IsMaster { get; private set; }\n\n    private int n;\n\n    private double[,] a;\n\n    private double[,] b;\n\n    private double[,] c;\n\n    public void SetMatrixes(double[,] a, double[,] b, int nn) //initializing matrixes\n    {\n        n = nn;\n        this.a = a;\n        this.b = b;\n    }\n\n    public void Solve(MPI.Intracommunicator mpi)\n    {\n        IsMaster = mpi.Rank == 0; // proccess with rank 0            \n\n        int numtasks,              /* number of tasks in partition */\n            taskid,                /* a task identifier */\n            numworkers,            /* number of worker tasks */\n            source,                /* task id of message source */\n            dest,                  /* task id of message destination */\n            mtype,                 /* message type */\n            rows,                  /* rows of matrix A sent to each worker */\n            averow, extra, offset, /* used to determine rows sent to each worker */\n            i, j, k, rc;           /* misc */\n\n        numworkers = mpi.Size - 1;\n\n        if (IsMaster) //если ранг = 0\n        {\n            /* Send matrix data to the worker tasks */\n            averow = N / numworkers;\n            extra = N % numworkers;\n            offset = 0;\n            mtype = FROM_MASTER;\n            for (dest = 1; dest <= numworkers; dest++)\n            {\n                rows = (dest <= extra) ? averow + 1 : averow;\n                Console.WriteLine(\"Sending {0} rows to task {1} offset={2}\\n\", rows, dest, offset);\n                mpi.Send(offset, dest, mtype);\n                mpi.Send(rows, dest, mtype);\n                mpi.Send(a[offset, 0], dest, mtype);\n                mpi.Send(b, dest, mtype);\n                offset = offset + rows;\n            }\n\n            /* Receive results from worker tasks */\n            mtype = FROM_WORKER;\n            for (i = 1; i <= numworkers; i++)\n            {\n                source = i;\n                mpi.Receive(source, mtype, out offset);\n                mpi.Receive(source, mtype, out rows);\n                mpi.Receive(source, mtype, out c[offset, 0]);\n                Console.WriteLine(\"Received results from task \\n\", source);\n            }\n\n            /* Print results */\n            Console.WriteLine(\"******************************************************\\n\");\n            Console.WriteLine(\"Result Matrix:\\n\");\n            for (i = 0; i < N; i++)\n            {\n                Console.WriteLine(\"\\n\");\n                for (j = 0; j < N; j++)\n                    Console.Write(string.Format(\"{0} \", c[i, j]));\n            }\n            Console.WriteLine(\"\\n******************************************************\\n\");\n\n        }\n        if (!IsMaster)\n        {\n            mtype = FROM_MASTER;\n            mpi.Receive<int>(0, mtype);\n            mpi.Receive(0, mtype, out rows);\n            mpi.Receive(0, mtype, out a);\n            mpi.Receive(0, mtype, out b);\n\n            for (k = 0; k < N; k++)\n                for (i = 0; i < rows; i++)\n                {\n                    c[i,k] = 0.0;\n                    for (j = 0; j < N; j++)\n                        c[i,k] = c[i,k] + a[i,j] * b[j,k];\n                }\n            mtype = FROM_WORKER;\n            offset = 0;\n            mpi.Send(offset, 0, mtype);\n            mpi.Send(rows, 0, mtype);\n            mpi.Send(c, 0, mtype);\n        }\n\n    }\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication Using SSE\r\n                \r\nI am trying to get a working example of multiplying 2 matrix using SIMD because i need to compare the time of the algorithm with a \"normal\" one.\nHere is why i tried doing Efficient 4x4 matrix multiplication (C vs assembly) .\n\n```\n#include <xmmintrin.h>\n#include <stdio.h>\n\n\nvoid M4x4_SSE(float *A, float *B, float *C) {\n    __m128 row1 = _mm_load_ps(&B[0]);\n    __m128 row2 = _mm_load_ps(&B[4]);\n    __m128 row3 = _mm_load_ps(&B[8]);\n    __m128 row4 = _mm_load_ps(&B[12]);\n    for(int i=0; i<4; i++) {\n        __m128 brod1 = _mm_set1_ps(A[4*i + 0]);\n        __m128 brod2 = _mm_set1_ps(A[4*i + 1]);\n        __m128 brod3 = _mm_set1_ps(A[4*i + 2]);\n        __m128 brod4 = _mm_set1_ps(A[4*i + 3]);\n        __m128 row = _mm_add_ps(\n                    _mm_add_ps(\n                        _mm_mul_ps(brod1, row1),\n                        _mm_mul_ps(brod2, row2)),\n                    _mm_add_ps(\n                        _mm_mul_ps(brod3, row3),\n                        _mm_mul_ps(brod4, row4)));\n        _mm_store_ps(&C[4*i], row);\n    }\n}\n\n\nint main(){\n\n  float A[4] __attribute__((aligned(16))) = {1,2,3,4};\n  float B[4] __attribute__((aligned(16))) = {5,6,7,8};\n  float C[4] __attribute__((aligned(16)));\n\n  M4x4_SSE(A,B,C);\n\n}\n```\n\n\nI am not familiar with c or c++ so it has been difficult, i get:\n\n```\n*** stack smashing detected ***: ./prueba terminated\nAborted (core dumped)\n```\n\n\nwhen i run my program. I need to scale to a 500x500 matrix at least.\nThanks\n    ", "Answer": "\r\nThe arrays you declare in ```\nmain```\n have 4 elements each, but your multiplication code reads and writes 16 elements each.  Writing past the allocated space (elements 4 and later, in the second iteration of your ```\ni```\n loop) will clobber the stack resulting in the error you see.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication in javascript\r\n                \r\nI have encountered an issue with my project which is to do with matrix multiplication. I have to multiply two matrices together, one which I have made and one that is a parameter. However,it has to pass a jasmine test and currently it does not pass due to an NaN error. Any help would be greatly appreciated. Thanks.\nMy matrix code:\n\n```\nclass Matrix {\n  constructor(pX0, pX1, pX2, pY0, pY1, pY2, pZ0, pZ1, pZ2) {\n    this.Matrix = [\n      [pX0, pX1, pX2],\n      [pY0, pY1, pY2],\n      [pZ0, pZ1, pZ2]\n    ];\n  }\n  getX0() {\n    return this.mX0;\n  }\n  setX0(pX0) {\n    this.mX0 = pX0;\n  }\n  getX1() {\n    return this.mX1;\n  }\n  setX1(pX1) {\n    this.mX1 = pX1;\n  }\n  getX2() {\n    return this.mX2;\n  }\n  setX2(pX2) {\n    this.mX2 = pX2;\n  }\n  getY0() {\n    return this.mY0;\n  }\n  setY0(pY0) {\n    this.mY0 = pY0;\n  }\n  getY1() {\n    return this.mY1;\n  }\n  setY1(pY1) {\n    this.mY1 = pY1;\n  }\n  getY2() {\n    return this.mY2;\n  }\n  setY2(pY2) {\n    this.mY2 = pY2;\n  }\n  getZ0() {\n    return this.mZ0;\n  }\n  setZ0(pZ0) {\n    this.mZ0 = pZ0;\n  }\n  getZ1() {\n    return this.mZ1;\n  }\n  setZ1(pZ1) {\n    this.mZ1 = pZ1;\n  }\n  getZ2() {\n    return this.mZ2;\n  }\n  setZ2(pZ2) {\n    this.mZ2 = pZ2;\n  }\n  getElement(pRow, pColumn) {\n    return this.Matrix[pRow][pColumn];\n  }\n  static createIdentity() {\n    return new Matrix(1, 0, 0, 0, 1, 0, 0, 0, 1);\n  }\n  static createTranslation(pTranslationVector) {\n    return new Matrix(1, 0, pTranslationVector.getX(), 0, 1, pTranslationVector.getY(), 0, 0, 1);\n  }\n  static createScale(pScaleVector) {\n    return new Matrix(pScaleVector.getX(), 0, 0, 0, pScaleVector.getY(), 0, 0, 0, 1);\n  }\n  static createRotation(pRotationScalar) {\n    return new Matrix(Math.cos(pRotationScalar), -Math.sin(pRotationScalar), 0, Math.sin(pRotationScalar), Math.cos(pRotationScalar), 0, 0, 0, 1);\n  }\n  multiply(pMatrix) {\n    return new Matrix(this.getX0 * pMatrix.getX0, this.getX1 * pMatrix.getY0, this.getX2 * pMatrix.getZ0, this.getY0 * pMatrix.getX1, this.getY1 * pMatrix.getY1, this.getY2 * pMatrix.getZ1, this.getZ0 * pMatrix.getX2, this.getZ1 * pMatrix.getY2, this.getZ2 * pMatrix.getZ2);\n  }\n```\n\n\nThe test it has to pass:\n\n```\ndescribe(\"Multiply\", function() {\nvar rotation, scaleVector, translationVector, translationMatrix,\n  scaleMatrix, rotationMatrix, scaleXTranslationMatrix, translationXScaleMatrix,\n  chainedMatrix;\nrotation = Math.PI / 2;\nrotationMatrix = Matrix.createRotation(rotation);\nscaleVector = new Vector(2, 2, 1);\nscaleMatrix = Matrix.createScale(scaleVector);\ntranslationVector = new Vector(10, 20, 1);\ntranslationMatrix = Matrix.createTranslation(translationVector);\n\ndescribe(\"Scale X Translate\", function() {\n  scaleXTranslationMatrix = scaleMatrix.multiply(translationMatrix);\n  it(\"Element (0,0) Set\", function() {\n    expect(scaleXTranslationMatrix.getElement(0, 0)).toEqual(2);\n  });\n\n  it(\"Element (0,1) Set\", function() {\n    expect(scaleXTranslationMatrix.getElement(0, 1)).toEqual(0);\n  });\n\n  it(\"Element (0,2) Set\", function() {\n    expect(scaleXTranslationMatrix.getElement(0, 2)).toEqual(20);\n  });\n\n  it(\"Element (1,0) Set\", function() {\n    expect(scaleXTranslationMatrix.getElement(1, 0)).toEqual(0);\n  });\n\n  it(\"Element (1,1) Set\", function() {\n    expect(scaleXTranslationMatrix.getElement(1, 1)).toEqual(2);\n  });\n\n  it(\"Element (1,2) Set\", function() {\n    expect(scaleXTranslationMatrix.getElement(1, 2)).toEqual(40);\n  });\n\n  it(\"Element (2,0) Set\", function() {\n    expect(scaleXTranslationMatrix.getElement(2, 0)).toEqual(0);\n  });\n\n  it(\"Element (2,1) Set\", function() {\n    expect(scaleXTranslationMatrix.getElement(2, 1)).toEqual(0);\n  });\n\n  it(\"Element (2,2) Set\", function() {\n    expect(scaleXTranslationMatrix.getElement(2, 2)).toEqual(1);\n  });\n});\n\ndescribe(\"Translate X Scale\", function() {\n  translationXScaleMatrix = translationMatrix.multiply(scaleMatrix);\n  it(\"Element (0,0) Set\", function() {\n    expect(translationXScaleMatrix.getElement(0, 0)).toEqual(2);\n  });\n\n  it(\"Element (0,1) Set\", function() {\n    expect(translationXScaleMatrix.getElement(0, 1)).toEqual(0);\n  });\n\n  it(\"Element (0,2) Set\", function() {\n    expect(translationXScaleMatrix.getElement(0, 2)).toEqual(10);\n  });\n\n  it(\"Element (1,0) Set\", function() {\n    expect(translationXScaleMatrix.getElement(1, 0)).toEqual(0);\n  });\n\n  it(\"Element (1,1) Set\", function() {\n    expect(translationXScaleMatrix.getElement(1, 1)).toEqual(2);\n  });\n\n  it(\"Element (1,2) Set\", function() {\n    expect(translationXScaleMatrix.getElement(1, 2)).toEqual(20);\n  });\n\n  it(\"Element (2,0) Set\", function() {\n    expect(translationXScaleMatrix.getElement(2, 0)).toEqual(0);\n  });\n\n  it(\"Element (2,1) Set\", function() {\n    expect(translationXScaleMatrix.getElement(2, 1)).toEqual(0);\n  });\n\n  it(\"Element (2,2) Set\", function() {\n    expect(translationXScaleMatrix.getElement(2, 2)).toEqual(1);\n  });\n});\n\ndescribe(\"Chaining\", function() {\n  var cosAngle, sinAngle;\n  cosAngle = Math.cos(Math.PI / 2);\n  sinAngle = Math.sin(Math.PI / 2);\n  chainedMatrix =\n    translationMatrix.multiply(scaleMatrix).multiply(rotationMatrix);\n  it(\"Element (0,0) Set\", function() {\n    expect(chainedMatrix.getElement(0, 0)).toEqual(2 * cosAngle);\n  });\n\n  it(\"Element (0,1) Set\", function() {\n    expect(chainedMatrix.getElement(0, 1)).toEqual(2 * -sinAngle);\n  });\n\n  it(\"Element (0,2) Set\", function() {\n    expect(chainedMatrix.getElement(0, 2)).toEqual(10);\n  });\n\n  it(\"Element (1,0) Set\", function() {\n    expect(chainedMatrix.getElement(1, 0)).toEqual(2 * sinAngle);\n  });\n\n  it(\"Element (1,1) Set\", function() {\n    expect(chainedMatrix.getElement(1, 1)).toEqual(2 * cosAngle);\n  });\n\n  it(\"Element (1,2) Set\", function() {\n    expect(chainedMatrix.getElement(1, 2)).toEqual(20);\n  });\n\n  it(\"Element (2,0) Set\", function() {\n    expect(chainedMatrix.getElement(2, 0)).toEqual(0);\n  });\n\n  it(\"Element (2,1) Set\", function() {\n    expect(chainedMatrix.getElement(2, 1)).toEqual(0);\n  });\n\n  it(\"Element (2,2) Set\", function() {\n    expect(chainedMatrix.getElement(2, 2)).toEqual(1);\n  });\n});\n\n});\n\n});\n```\n\n\nI'm out of ideas so any form of help would be great, thanks.\n    ", "Answer": "\r\nYour ```\nmultiply```\n method tries to multiply functions, not numbers:\n\n```\nmultiply(pMatrix) {\n  return new Matrix(\n    this.getX0 * pMatrix.getX0,\n    this.getX1 * pMatrix.getY0,\n    this.getX2 * pMatrix.getZ0,\n    this.getY0 * pMatrix.getX1,\n    this.getY1 * pMatrix.getY1,\n    this.getY2 * pMatrix.getZ1,\n    this.getZ0 * pMatrix.getX2,\n    this.getZ1 * pMatrix.getY2,\n    this.getZ2 * pMatrix.getZ2\n  );\n}\n```\n\n\nThat's the reason why you get ```\nNaN```\n as a result. Either change the code to multiply the numeric values or call the getter functions:\n\n```\nmultiply(pMatrix) {\n  return new Matrix(\n    this.getX0() * pMatrix.getX0(),\n    this.getX1() * pMatrix.getY0(),\n    this.getX2() * pMatrix.getZ0(),\n    this.getY0() * pMatrix.getX1(),\n    this.getY1() * pMatrix.getY1(),\n    this.getY2() * pMatrix.getZ1(),\n    this.getZ0() * pMatrix.getX2(),\n    this.getZ1() * pMatrix.getY2(),\n    this.getZ2() * pMatrix.getZ2()\n  );\n}\n```\n\n\n\n\nEDIT:\n\nYou also have update those getter functions as well, because they try to grab properties which aren't defined. For example, ```\ngetX0()```\n returns ```\nthis.mX0```\n internally. But ```\nthis.mX0```\n is never set and therefor returns ```\nundefined```\n.\n\nChange your getter functions like so:\n\n```\n...\ngetX0: function () {\n  return this.getElement(0, 0);\n}\n...\n```\n\n\nYou have to do this for each getter. The other solution would be to call the corresponding setter functions inside the constructor:\n\n```\nclass Matrix {\n  constructor(pX0, pX1, pX2, pY0, pY1, pY2, pZ0, pZ1, pZ2) {\n    this.Matrix = [\n      [pX0, pX1, pX2],\n      [pY0, pY1, pY2],\n      [pZ0, pZ1, pZ2]\n    ];\n\n    this.setX0(pX0);\n    this.setX1(pX1);\n    // ...\n    this.setZ2(pZ2);\n  }\n  // ...\n}\n```\n\n\nHere is a \"fixed\" version of your ```\nMatrix```\n class:\n\n\r\n\r\n```\nclass Matrix {\r\n  constructor(pX0, pX1, pX2, pY0, pY1, pY2, pZ0, pZ1, pZ2) {\r\n    this.__matrix = [\r\n      [pX0, pX1, pX2],\r\n      [pY0, pY1, pY2],\r\n      [pZ0, pZ1, pZ2]\r\n    ];\r\n  }\r\n  getX0() {\r\n    return this.getElement(0, 0);\r\n  }\r\n  setX0(pX0) {\r\n    return this.setElement(0, 0, pX0);\r\n  }\r\n  getX1() {\r\n    return this.getElement(0, 1);\r\n  }\r\n  setX1(pX1) {\r\n    return this.setElement(0, 1, pX1);\r\n  }\r\n  getX2() {\r\n    return this.getElement(0, 2);\r\n  }\r\n  setX2(pX2) {\r\n    return this.setElement(0, 2, pX2);\r\n  }\r\n  getY0() {\r\n    return this.getElement(1, 0);\r\n  }\r\n  setY0(pY0) {\r\n    return this.setElement(1, 0, pY0);\r\n  }\r\n  getY1() {\r\n    return this.getElement(1, 1);\r\n  }\r\n  setY1(pY1) {\r\n    return this.setElement(1, 1, pY1);\r\n  }\r\n  getY2() {\r\n    return this.getElement(1, 2);\r\n  }\r\n  setY2(pY2) {\r\n    return this.setElement(1, 2, pY2);\r\n  }\r\n  getZ0() {\r\n    return this.getElement(2, 0);\r\n  }\r\n  setZ0(pZ0) {\r\n    return this.setElement(2, 0, pZ0);\r\n  }\r\n  getZ1() {\r\n    return this.getElement(2, 1);\r\n  }\r\n  setZ1(pZ1) {\r\n    return this.setElement(2, 1, pZ1);\r\n  }\r\n  getZ2() {\r\n    return this.getElement(2, 2);\r\n  }\r\n  setZ2(pZ2) {\r\n    return this.setElement(2, 2, pZ2);\r\n  }\r\n  getElement(pRow, pColumn) {\r\n    return this.__matrix[pRow][pColumn];\r\n  }\r\n  setElement(pRow, pColumn, value) {\r\n    this.__matrix[pRow][pColumn] = value;\r\n    return this;\r\n  }\r\n  toString() {\r\n    return `Matrix([${this.__matrix.reduce((acc, row) => acc + '[' + row.join(',') + ']', '')}])`;\r\n  }\r\n  static createIdentity() {\r\n    return new Matrix(1, 0, 0, 0, 1, 0, 0, 0, 1);\r\n  }\r\n  static isIdentity(pMatrix) {\r\n    return Matrix.prototype.isPrototypeOf(pMatrix) &&\r\n           pMatrix.__matrix[0][0] === 1 &&\r\n           pMatrix.__matrix[0][1] === 0 &&\r\n           pMatrix.__matrix[0][2] === 0 &&\r\n           pMatrix.__matrix[1][0] === 0 &&\r\n           pMatrix.__matrix[1][1] === 1 &&\r\n           pMatrix.__matrix[1][2] === 0 &&\r\n           pMatrix.__matrix[2][0] === 0 &&\r\n           pMatrix.__matrix[2][1] === 0 &&\r\n           pMatrix.__matrix[2][2] === 1;\r\n  }\r\n  static createTranslation(pTranslationVector) {\r\n    return new Matrix(\r\n      1,\r\n      0,\r\n      pTranslationVector.getX(),\r\n      0,\r\n      1,\r\n      pTranslationVector.getY(),\r\n      0,\r\n      0,\r\n      1\r\n    );\r\n  }\r\n  static createScale(pScaleVector) {\r\n    return new Matrix(\r\n      pScaleVector.getX(),\r\n      0,\r\n      0,\r\n      0,\r\n      pScaleVector.getY(),\r\n      0,\r\n      0,\r\n      0,\r\n      1\r\n    );\r\n  }\r\n  static createRotation(pRotationScalar) {\r\n    return new Matrix(\r\n      Math.cos(pRotationScalar),\r\n      -Math.sin(pRotationScalar),\r\n      0,\r\n      Math.sin(pRotationScalar),\r\n      Math.cos(pRotationScalar),\r\n      0,\r\n      0,\r\n      0,\r\n      1\r\n    );\r\n  }\r\n  multiply(pMatrix) {\r\n    return new Matrix(\r\n      this.getX0() * pMatrix.getX0(),\r\n      this.getX1() * pMatrix.getY0(),\r\n      this.getX2() * pMatrix.getZ0(),\r\n      this.getY0() * pMatrix.getX1(),\r\n      this.getY1() * pMatrix.getY1(),\r\n      this.getY2() * pMatrix.getZ1(),\r\n      this.getZ0() * pMatrix.getX2(),\r\n      this.getZ1() * pMatrix.getY2(),\r\n      this.getZ2() * pMatrix.getZ2()\r\n    );\r\n  }\r\n}\r\n\r\n\r\n\r\n// TEST\r\nlet m1 = new Matrix(1, 0, 0, 0, 1, 0, 0, 0, 1);\r\nlet m2 = Matrix.createIdentity();\r\n\r\nlet m3 = m1.multiply(m2); // should give us identity again\r\n\r\nconsole.log(Matrix.isIdentity(m3)); // should log true\r\nconsole.log(m3.toString());```\n\r\n\r\n\r\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Graphics matrix by matrix multiplication necessary for transformations?\r\n                \r\nI've been dabbling in OpenGL and DirectX for the past while, and I've noticed that all transformations are done by doing matrix by matrix and matrix by vector multiplication. I think we can all admit that especially matrix by matrix multiplication is not intuitive, and when I learned that matrix by matrix multiplication involved 64 multiplications and 48 additions, I wasn't so hard on myself for not understanding them well.\n\nAnyway, I know that matrix and vector multiplication on modern systems is done with SIMD or SSE instructions, reducing the number of operations (or calculations), but many calculations I've seen programmers make seem unnecessary.\n\nFor example if you have a vertex you want to transform, lets just say we want to rotate 45 degrees and then translate (5, 5, 5) locally, the typical way I've seen is the following:\n\n1: Get the identity matrix.\n\n2: Multiply the identity matrix by the rotation matrix.\n\n3: Multiply the resulting matrix by the translation matrix (order matters).\n\n4: Multiply the resulting matrix by the point/vector you want to transform.\n\nIf I wanted to translate an object in a certain direction, instead of multiplying its matrix by \n\n```\n{ 1  0  0  translationX }\n{ 0  1  0  translationY }\n{ 0  0  1  translationZ }\n{ 0  0  0      1        }\n```\n\n\n...couldn't I just add the translations to the appropriate matrix indices, ie., matrix[3][0] += translationX;\n\nThe difference is 3 additions instead of 64 multiplications and 48 additions.\n\nLikewise, say I wanted to translate locally, and not in world space, say for example down an object's right vector, then I could multiply the translation vector by the upperleft part of the object's world or model matrix, getting the object's local right vector? That would only be 3x3 matrix times a vector?\n\nSo yeah, I've been thinking about this for a while, and I was just wondering if these big matrix by matrix multiplications are entirely unnecessary, at least for some things. Also, I'm aware that scaling adds some complexities, and haven't got my head around the concept of matrices that well yet.\n    ", "Answer": "\r\n\n  think we can all admit that especially matrix by matrix multiplication is not intuitive\n\n\nI completely disagree. First and foremost, when thinking about linear transformations it doesn't make sense to think of matrices to be \"2D arrays of numbers\". The proper way to think of matrices is as operators in a very general way.\n\n\n  Anyway, I know that matrix and vector multiplication on modern systems is done with SIMD or SSE instructions, reducing the number of operations (or calculations), but many calculations I've seen programmers make seem unnecessary.\n\n\nThe rules of matrix multiplication and their necessity are fully determined by the rules of linear algebra. You start out with certain elementary rules how transformations of vectors from one space to another shall behave and from there the rules of matrix multiplication rise.\n\nImportant is, that when chaining up a series of transformations the end result can be coalesced into one single matrix. That's the beauty of these things. No matter how convoluted and complex your transformation setup is, one single matrix does the job. Matrices give you the oppertunity for precomputation!\n\n\n  ...couldn't I just add the translations to the appropriate matrix indices, ie., matrix[3][0] += translationX;\n\n\nNot in general. Only if the upper left part is a identity transformation. The moment that part is non-identity, the translation gets modified by that as well.\n\nI suggest you write out per hand the result\n\n```\nM = rot((0,0,1), 90°) · translate(1, 2, 3)\n```\n\n\nhint\n\n```\n                    |  0 -1  0  0 |\nrot((0,0,1), 90°) = |  1  0  0  0 |\n                    |  0  0  1  0 |\n                    |  0  0  0  1 |\n```\n\n\n\n  So yeah, I've been thinking about this for a while, and I was just wondering if these big matrix by matrix multiplications are entirely unnecessary, at least for some things.\n\n\nThe funny thing is, that once you hit a certain depth of transformation levels matrices quickly win out over chaining individual base vector operations.\n\nBut here's the thing: Don't think of matrices as 2D arrays of numbers. That's just a way to write down linear transformations.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How does BLAS get such extreme performance?\r\n                \r\nOut of curiosity I decided to benchmark my own matrix multiplication function versus the BLAS implementation... I was to say the least surprised at the result:\n\n\n  Custom Implementation, 10 trials of\n  1000x1000 matrix multiplication:\n\n```\nTook: 15.76542 seconds.\n```\n\n  \n  BLAS Implementation, 10 trials of\n  1000x1000 matrix multiplication:\n\n```\nTook: 1.32432 seconds.\n```\n\n\n\nThis is using single precision floating point numbers.\n\nMy Implementation:\n\n```\ntemplate<class ValT>\nvoid mmult(const ValT* A, int ADim1, int ADim2, const ValT* B, int BDim1, int BDim2, ValT* C)\n{\n    if ( ADim2!=BDim1 )\n        throw std::runtime_error(\"Error sizes off\");\n\n    memset((void*)C,0,sizeof(ValT)*ADim1*BDim2);\n    int cc2,cc1,cr1;\n    for ( cc2=0 ; cc2<BDim2 ; ++cc2 )\n        for ( cc1=0 ; cc1<ADim2 ; ++cc1 )\n            for ( cr1=0 ; cr1<ADim1 ; ++cr1 )\n                C[cc2*ADim2+cr1] += A[cc1*ADim1+cr1]*B[cc2*BDim1+cc1];\n}\n```\n\n\nI have two questions:\n\n\nGiven that a matrix-matrix multiplication say: nxm * mxn requires n*n*m multiplications, so in the case above 1000^3 or 1e9 operations. How is it possible on my 2.6Ghz processor for BLAS to do 10*1e9 operations in 1.32 seconds? Even if multiplcations were a single operation  and there was nothing else being done, it should take ~4 seconds.\nWhy is my implementation so much slower?\n\n    ", "Answer": "\r\nA good starting point is the great book The Science of Programming Matrix Computations by Robert A. van de Geijn and Enrique S. Quintana-Ortí.  They provide a free download version.\nBLAS is divided into three levels:\n\nLevel 1 defines a set of linear algebra functions that operate on vectors only.  These functions benefit from vectorization (e.g. from using SIMD such as SSE).\n\nLevel 2 functions are matrix-vector operations, e.g. some matrix-vector product.  These functions could be implemented in terms of Level 1 functions.  However, you can boost the performance of these functions if you can provide a dedicated implementation that makes use of some multiprocessor architecture with shared memory.\n\nLevel 3 functions are operations like the matrix-matrix product.  Again you could implement them in terms of Level 2 functions.  But Level 3 functions perform O(N^3) operations on O(N^2) data.  So if your platform has a cache hierarchy then you can boost performance if you provide a dedicated implementation that is cache optimized/cache friendly.  This is nicely described in the book.  The main boost of Level 3 functions comes from cache optimization.  This boost significantly exceeds the second boost from parallelism and other hardware optimizations.\n\n\nBy the way, most (or even all) of the high performance BLAS implementations are NOT implemented in Fortran.  ATLAS is implemented in C.  GotoBLAS/OpenBLAS is implemented in C and its performance-critical parts in Assembler.  Only the reference implementation of BLAS is implemented in Fortran.  However, all these BLAS implementations provide a Fortran interface such that it can be linked against LAPACK (LAPACK gains all its performance from BLAS).\nOptimized compilers play a minor role in this respect (and for GotoBLAS/OpenBLAS the compiler does not matter at all).\nIMHO no BLAS implementation uses algorithms like the Coppersmith–Winograd algorithm or the Strassen algorithm.  The likely reasons are:\n\nMaybe it's not possible to provide a cache-optimized implementation of these algorithms (i.e. you would lose more than you would win)\nThese algorithms are numerically not stable.  As BLAS is the computational kernel of LAPACK this is a no-go.\nAlthough these algorithms have a nice time complexity on paper, the Big O notation hides a large constant, so it only starts to become viable for extremely large matrices.\n\nEdit/Update:\nThe new and groundbreaking papers for this topic are the BLIS papers. They are exceptionally well written.   For my lecture \"Software Basics for High Performance Computing\" I implemented the matrix-matrix product following their paper.  Actually I implemented several variants of the matrix-matrix product.  The simplest variant is entirely written in plain C and has less than 450 lines of code.  All the other variants merely optimize the loops\n```\n    for (l=0; l<MR*NR; ++l) {\n        AB[l] = 0;\n    }\n    for (l=0; l<kc; ++l) {\n        for (j=0; j<NR; ++j) {\n            for (i=0; i<MR; ++i) {\n                AB[i+j*MR] += A[i]*B[j];\n            }\n        }\n        A += MR;\n        B += NR;\n    }\n```\n\nThe overall performance of the matrix-matrix product only depends on these loops.  About 99.9% of the time is spent here.  In the other variants I used intrinsics and assembler code to improve the performance.  You can see the tutorial going through all the variants here:\nulmBLAS: Tutorial on GEMM (Matrix-Matrix Product)\nTogether with the BLIS papers it becomes fairly easy to understand how libraries like Intel MKL can gain such performance. And why it does not matter whether you use row or column major storage!\nThe final benchmarks are here (we called our project ulmBLAS):\nBenchmarks for ulmBLAS, BLIS, MKL, openBLAS and Eigen\nAnother Edit/Update:\nI also wrote some tutorials on how BLAS is used for numerical linear algebra problems like solving a system of linear equations:\nHigh Performance LU Factorization\n(This LU factorization is for example used by Matlab for solving a system of linear equations.)\nI hope to find time to extend the tutorial to describe and demonstrate how to realise a highly scalable parallel implementation of the LU factorization like in PLASMA.\nOk, here you go: Coding a Cache Optimized Parallel LU Factorization\nP.S.:  I also did make some experiments on improving the performance of uBLAS.  It actually is pretty simple to boost (yeah, play on words :) ) the performance of uBLAS:\nExperiments on uBLAS.\nHere a similar project with BLAZE:\nExperiments on BLAZE.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Why is boosts matrix multiplication slower than mine?\r\n                \r\nI have implemented one matrix multiplication with ```\nboost::numeric::ublas::matrix```\n (see my full, working boost code)\n\n```\nResult result = read ();\n\nboost::numeric::ublas::matrix<int> C;\nC = boost::numeric::ublas::prod(result.A, result.B);\n```\n\n\nand another one with the standard algorithm (see full standard code):\n\n```\nvector< vector<int> > ijkalgorithm(vector< vector<int> > A, \n                                    vector< vector<int> > B) {\n    int n = A.size();\n\n    // initialise C with 0s\n    vector<int> tmp(n, 0);\n    vector< vector<int> > C(n, tmp);\n\n    for (int i = 0; i < n; i++) {\n        for (int k = 0; k < n; k++) {\n            for (int j = 0; j < n; j++) {\n                C[i][j] += A[i][k] * B[k][j];\n            }\n        }\n    }\n    return C;\n}\n```\n\n\nThis is how I test the speed:\n\n```\ntime boostImplementation.out > boostResult.txt\ndiff boostResult.txt correctResult.txt\n\ntime simpleImplementation.out > simpleResult.txt\ndiff simpleResult.txt correctResult.txt\n```\n\n\nBoth programs read a hard-coded textfile which contains two 2000 x 2000 matrices.\nBoth programs were compiled with these flags:\n\n```\ng++ -std=c++98 -Wall -O3 -g $(PROBLEM).cpp -o $(PROBLEM).out -pedantic\n```\n\n\nI got 15 seconds for my implementation and over 4 minutes for the boost-implementation!\n\nedit: After compiling it with \n\n```\ng++ -std=c++98 -Wall -pedantic -O3 -D NDEBUG -DBOOST_UBLAS_NDEBUG library-boost.cpp -o library-boost.out\n```\n\n\nI got 28.19 seconds for the ikj-algorithm and 60.99 seconds for Boost. So Boost is still considerably slower.\n\nWhy is boost so much slower than my implementation?\n    ", "Answer": "\r\nSlower performance of the uBLAS version can be partly explained by debugging features of the latter as was pointed out by TJD.\n\nHere's the time taken by the uBLAS version with debugging on:\n\n```\nreal    0m19.966s\nuser    0m19.809s\nsys     0m0.112s\n```\n\n\nHere's the time taken by the uBLAS version with debugging off (```\n-DNDEBUG -DBOOST_UBLAS_NDEBUG```\n compiler flags added):\n\n```\nreal    0m7.061s\nuser    0m6.936s\nsys     0m0.096s\n```\n\n\nSo with debugging off, uBLAS version is almost 3 times faster.\n\nRemaining performance difference can be explained by quoting the following section of uBLAS FAQ \"Why is uBLAS so much slower than (atlas-)BLAS\":\n\n\n  An important design goal of ublas is to be as general as possible.\n\n\nThis generality almost always comes with a cost. In particular the ```\nprod```\n function template can handle different types of matrices, such as sparse or triangular ones. Fortunately uBLAS provides alternatives optimized for dense matrix multiplication, in particular, axpy_prod and ```\nblock_prod```\n. Here are the results of comparing different methods:\n\n```\nijkalgorithm   prod   axpy_prod  block_prod\n   1.335       7.061    1.330       1.278\n```\n\n\nAs you can see both ```\naxpy_prod```\n and ```\nblock_prod```\n are somewhat faster than your implementation. Measuring just the computation time without I/O, removing unnecessary copying and careful choice of the block size for ```\nblock_prod```\n (I used 64) can make the difference more profound.\n\nSee also uBLAS FAQ and Effective uBlas and general code optimization.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication using CUDA + MPI\r\n                \r\nI'm doing a research about gpu in cluster environments using mpi to communicate.\nIn order to compare speed up, I think in create:  \n\nA Multiplication of matrix just for GPU, ok.\nNow just CPU MatrixMulti, ok.\nBut I can't find a nice implementation of CUDA + MPI matrix multiplication. \n\nAnyone have some hint about where I can fin this? Or suggest one implementation.\n    ", "Answer": "\r\nThe MTL4 Matrix Template Library can be a great starting point. Right now MTL4 has multi-core,  DMM, and we are almost done with a full GPU implementation. Peter and I have been talking about distributed GPU algorithms, but since our focus is driven by PDE solvers for the moment, distributed GPU algorithms are difficult to make competitive against robust DMM.\n\nHowever, I am working on a new geophysics/medical imaging solver set that is more conducive for distributed GPU computes as the data sets are more modest and the video capabilities of the GPU are beneficial. \n\nTo get started, take a look at the MTL4 tutorial\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Is it possible to compute large matrix multiplication, using Renderscript?\r\n                \r\nI need to compute matrix(large scale) multiplication quickly on Android. \n\nIs it possible to compute large matrix multiplication, using Renderscript?\n\nI heard that we can do GPGPU using Renderscript on Android\n\nHowever, I cannot find any example for large matrix multiplication.\n\nActually, I tried to do matrix multiplication, using rsMatrixMultiply function, but it just multiply the 4x4 matrix with a vector of size 3.\n\nI have no idea to multiply 'matrics of arbitrary size'.\nIf it is possible, can you introduce some examples?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Faster Matrix Multiplication in C#\r\n                \r\nI have as small c# project that involves matrices.  I am processing large amounts of data by splitting it into n-length chunks, treating the chucks as vectors, and multiplying by a Vandermonde** matrix.  The problem is, depending on the conditions, the size of the chucks and corresponding Vandermonde** matrix can vary.  I have a general solution which is easy to read, but way too slow:\n\n```\n    public byte[] addBlockRedundancy(byte[] data) {\n        if (data.Length!=numGood) D.error(\"Expecting data to be just \"+numGood+\" bytes long\");\n\n        aMatrix d=aMatrix.newColumnMatrix(this.mod, data);\n        var r=vandermonde.multiplyBy(d);\n        return r.ToByteArray();\n    }//method\n```\n\n\nThis can process about 1/4 megabytes per second on my i5 U470 @ 1.33GHz.  I can make this faster by manually inlining the matrix multiplication:\n\n```\n        int o=0;\n        int d=0;\n        for (d=0; d<data.Length-numGood; d+=numGood) {\n            for (int r=0; r<numGood+numRedundant; r++) {\n                Byte value=0;\n                for (int c=0; c<numGood; c++) {\n                    value=mod.Add(value, mod.Multiply(vandermonde.get(r, c), data[d+c]));\n                }//for\n                output[r][o]=value;\n            }//for\n            o++;\n        }//for\n```\n\n\nThis can process about 1 meg a second. \n\n(Please note the \"mod\" is performing operations over GF(2^8) modulo my favorite irreducible polynomial.)\n\nI know this can get a lot faster:  After all, the Vandermonde** matrix is mostly zeros.  I should be able to make a routine, or find a routine, that can take my matrix and return a optimized method which will effectively multiply vectors by the given matrix, but faster.  Then, when I give this routine a 5x5 Vandermonde matrix (the identity matrix), there is simply no arithmetic to perform, and the original data is just copied.\n\n** Please note:  What I use the term \"Vandermonde\", I actually mean an Identity matrix with some number of rows from the Vandermonde matrix appended (see comments). This matrix is wonderful because of all the zeros, and because if you remove enough rows (of your choosing) to make it square, it is an invertible matrix.  And, of course, I would like to use this same routine to convert any one of those inverted matrices into an optimized series of instructions.  \n\nHow can I make this matrix multiplication faster? \n\nThanks!\n\n(edited to correct my mistake with Vandermonde matrix)\n    ", "Answer": "\r\nMaybe you can define a matrix interface and build implementations at runtime using Reflection.Emit.\n\n```\nIMatrix m = MatrixGenerator.CreateMatrix(data);\n\nm.multiplyBy(...)\n```\n\n\nHere, ```\nMatrixGenerator.CreateMatrix```\n will create a tailored IMatrix implementation, with full loop unrolling, and further code pruning (0 cell, identity, etc). ```\nMatrixGenerator.CreateMatrix```\n may cache matrices to avoid recreating it later for the same set of data.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication in MPI\r\n                \r\nI'm trying to create a simple Matrix Multiplication program with MPI, using 1, 2, 4 or 8 processors. My code works for 1 (in which case it only does normal matrix multiplication, I mean, there's no work to split up if you only run on one rank anyway). It also works on 2 and 4 processors. However, when I try using 8 processors (-n 8 on the command line when running the program that is), I don't get the proper value on all places in the matrix c.\n\nHere are examples: If SIZE = 8 (That is, a and b and c are all 8x8 matrices), the resulting matrix is as following:\n\n```\n   8.00   8.00   8.00   8.00   8.00   8.00   8.00   8.00\n   8.00   8.00   8.00   8.00   8.00   8.00   8.00   8.00\n   8.00   8.00   8.00   8.00   8.00   8.00   8.00   8.00\n   8.00   8.00   8.00   8.00   8.00   8.00   8.00   8.00\n  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00\n  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00\n  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00\n   0.00   0.00  16.00  16.00  16.00  16.00  16.00  16.00\n```\n\n\nAnd if SIZE = 16:\n\n```\n  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00\n  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00\n  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00\n  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00\n  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00\n  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00\n  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00\n  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00  16.00\n  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00\n  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00\n  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00\n  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00\n  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00\n  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00\n   0.00   0.00   0.00   0.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00\n  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00  32.00\n```\n\n\nAs you can see, zeroes pop up in the lower left. Something that Rank 7 is doing is resulting in those coordinates becoming 0.\n\nI've been staring myself dead at my code now, and I feel like I just need another pair of eyes on them. As far as I can tell, all the sends and receives work properly, all the different tasks gets the value they're supposed to. From what testing I've done, no task actually gives any place in the c matrix a value of 0. I don't know why it happens, how, or what I can do to fix it.\n\nHere is the code:\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <mpi.h>\n\n#define SIZE 16 /*assumption: SIZE a multiple of number of nodes*/\n#define FROM_MASTER 1/*setting a message type*/\n#define FROM_WORKER 2/*setting a message type*/\n#define DEBUG 1/*1 = debug on, 0 = debug off*/\n\nMPI_Status status;\n\nstatic double a[SIZE][SIZE];\nstatic double b[SIZE][SIZE];\nstatic double c[SIZE][SIZE];\nstatic double b_to_trans[SIZE][SIZE];\nstatic void init_matrix(void)\n{\n    int i, j;\n    for (i = 0; i < SIZE; i++)\n    {\n        for (j = 0; j < SIZE; j++) {\n            a[i][j] = 1.0;\n            if(i >= SIZE/2) a[i][j] = 2.0;\n            b_to_trans[i][j] = 1.0;\n            if(j >= SIZE/2) b[i][j] = 2.0;\n//          c[i][j] = 1.0;\n        }\n    }\n}\n\nstatic void print_matrix(void)\n{\n    int i, j;\n    for(i = 0; i < SIZE; i++) {\n        for(j = 0; j < SIZE; j++) {\n            printf(\"%7.2f\", c[i][j]);\n        }\n    printf(\"\\n\");\n    }\n}\n\nstatic void transpose_matrix()\n{\n    int i, j;\n    for(i = 0; i<SIZE; i++)\n        for(j = 0; j<SIZE;j++)\n            b[i][j] = b_to_trans[j][i];\n}\n\nint main(int argc, char **argv)\n{\n    int myrank, nproc;\n    int rows; /*amount of work per node (rows per worker)*/\n    int mtype; /*message type: send/recv between master and workers*/\n    int dest, src, offseta, offsetb;\n    int runthrough, runmod;\n    double start_time, end_time;\n    int i, j, k, l;\n\n    MPI_Init(&argc, &argv);\n    MPI_Comm_size(MPI_COMM_WORLD, &nproc);\n    MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n    rows = SIZE/nproc;\n    mtype = FROM_MASTER;\n\n    if (myrank == 0) {\n        /*Initialization*/\n        printf(\"SIZE = %d, number of nodes = %d\\n\", SIZE, nproc);\n        init_matrix();\n        transpose_matrix();\n        start_time = MPI_Wtime();\n\n        if(nproc == 1) { /*In case we only run on one processor, the master will simply do a regular matrix-matrix multiplacation.*/\n            for(i = 0; i < SIZE; i++) {\n                for(j = 0; j < SIZE; j++) {\n                    for(k = 0; k < SIZE; k++)\n                        c[i][j] = c[i][j] + a[i][k]*b[j][k];\n                }\n            }\n            end_time = MPI_Wtime();\n            if(DEBUG) /*Prints the resulting matrix c*/\n                print_matrix();\n            printf(\"Execution time on %2d nodes: %f\\n\", nproc, end_time-start_time);\n        }\n        else {\n\n            for(l = 0; l < nproc; l++){\n                offsetb = rows*l;\n                offseta = rows;\n                mtype = FROM_MASTER;\n\n                for(dest = 1; dest < nproc; dest++){\n                    MPI_Send(&offseta, 1, MPI_INT, dest, mtype, MPI_COMM_WORLD);\n                    MPI_Send(&offsetb, 1, MPI_INT, dest, mtype, MPI_COMM_WORLD);\n                    MPI_Send(&rows, 1, MPI_INT, dest, mtype, MPI_COMM_WORLD);\n                    MPI_Send(&a[offseta][0], rows*SIZE, MPI_DOUBLE, dest, mtype, MPI_COMM_WORLD);\n                    MPI_Send(&b[offsetb][0], rows*SIZE, MPI_DOUBLE, dest, mtype, MPI_COMM_WORLD);\n                    offseta += rows;\n                    offsetb = (offsetb+rows)%SIZE;\n                }\n\n                offseta = rows;\n                offsetb = rows*l;\n                //printf(\"Rank: %d, offseta: %d, offsetb: %d\\n\", myrank, offseta, offsetb);\n                //printf(\"Offseta: %d\\n\", offseta);\n                //printf(\"Offsetb: %d\\n\", offsetb);\n                for(i = 0; i < offseta; i++) {\n                    for(j = offsetb; j < offsetb+rows; j++) {\n                            for(k = 0; k < SIZE; k++){\n                                c[i][j] = c[i][j] + a[i][k]*b[j][k];\n                        }\n                    }\n                }\n                mtype = FROM_WORKER;\n                for(src = 1; src < nproc; src++){\n                    MPI_Recv(&offseta, 1, MPI_INT, src, mtype, MPI_COMM_WORLD, &status);\n                    MPI_Recv(&offsetb, 1, MPI_INT, src, mtype, MPI_COMM_WORLD, &status);\n                    MPI_Recv(&rows, 1, MPI_INT, src, mtype, MPI_COMM_WORLD, &status);\n                    for(i = 0; i < rows; i++) {\n                        MPI_Recv(&c[offseta+i][offsetb], offseta, MPI_DOUBLE, src, mtype, MPI_COMM_WORLD, &status); /*returns answer c(1,1)*/\n                    }\n                }\n            }\n\n\n            end_time = MPI_Wtime();\n            if(DEBUG) /*Prints the resulting matrix c*/\n                print_matrix();\n            printf(\"Execution time on %2d nodes: %f\\n\", nproc, end_time-start_time);\n        }\n    }\n    else{\n        if(nproc > 1) {\n            for(l = 0; l < nproc; l++){\n                mtype = FROM_MASTER;\n                MPI_Recv(&offseta, 1, MPI_INT, 0, mtype, MPI_COMM_WORLD, &status);\n                MPI_Recv(&offsetb, 1, MPI_INT, 0, mtype, MPI_COMM_WORLD, &status);\n                MPI_Recv(&rows, 1, MPI_INT, 0, mtype, MPI_COMM_WORLD, &status);\n                MPI_Recv(&a[offseta][0], rows*SIZE, MPI_DOUBLE, 0, mtype, MPI_COMM_WORLD, &status);\n                MPI_Recv(&b[offsetb][0], rows*SIZE, MPI_DOUBLE, 0, mtype, MPI_COMM_WORLD, &status);\n\n                for(i = offseta; i < offseta+rows; i++) {\n                    for(j = offsetb; j < offsetb+rows; j++) {\n                        for(k = 0; k < SIZE; k++){\n                            c[i][j] = c[i][j] + a[i][k]*b[j][k];\n                        }\n                    }\n                }\n\n                mtype = FROM_WORKER;\n                MPI_Send(&offseta, 1, MPI_INT, 0, mtype, MPI_COMM_WORLD);\n                MPI_Send(&offsetb, 1, MPI_INT, 0, mtype, MPI_COMM_WORLD);\n                MPI_Send(&rows, 1, MPI_INT, 0, mtype, MPI_COMM_WORLD);\n                for(i = 0; i < rows; i++){\n                    MPI_Send(&c[offseta+i][offsetb], offseta, MPI_DOUBLE, 0, mtype, MPI_COMM_WORLD);\n                }\n            }\n        }\n    }\n    MPI_Finalize();\n    return 0;\n}\n```\n\n\nAny advice would be helpful, thank you on beforehand.\n    ", "Answer": "\r\nThis is not a definite answer but should certainly help you in debugging.\n\nI made a test by adding the following code to right after where master receives final data from workers. Out of bunch of outputs, I show only important ones. Note that, ```\nj+count```\n never exceeds ```\nSIZE```\n except for the case when number of processors is 8. This is important because you write to non-allocated memory.\n\n```\nfor(i = 0; i < rows; i++) {\n    MPI_Recv(&c[offseta+i][offsetb], offseta, MPI_DOUBLE, src, mtype, MPI_COMM_WORLD, &status);\n    // I added the following for debugging.            \n    if (src == nproc-1)\n    {\n        printf(\"src = %i\\n\", src);\n        printf(\"i = %i\\n\", offseta+i);\n        printf(\"j = %i\\n\", offsetb);\n        printf(\"count = %i\\n\", offseta);\n    }\n}\n```\n\n\nnp = 2\n\n```\nsrc = 1\ni = 15\nj = 8\ncount = 8\n```\n\n\nnp = 4\n\n```\nsrc = 3\ni = 15\nj = 4\ncount = 12\n```\n\n\nnp = 8\n\n```\nsrc = 7\ni = 15\nj = 10\ncount = 14\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication using hdf5\r\n                \r\nI'm trying to multiplicate 2 big matrices with memory limit using hdf5 (pytables)\nbut function numpy.dot seems to give me error:\n\n\n  Valueerror: array is too big\n\n\nI need to do matrix multiplication by myself maybe blockwise or there is some another python function similar to numpy.dot?\n\n```\nimport numpy as np\nimport time\nimport tables\nimport cProfile\nimport numexpr as ne\n\nn_row=10000\nn_col=100\nn_batch=10\n\nrows = n_row\ncols = n_col\nbatches = n_batch\n\natom = tables.UInt8Atom()  #?\nfilters = tables.Filters(complevel=9, complib='blosc') # tune parameters\n\nfileName_a = 'C:\\carray_a.h5'\nshape_a = (rows*batches, cols)  # predefined size\n\nh5f_a = tables.open_file(fileName_a, 'w')\nca_a = h5f_a.create_carray(h5f_a.root, 'carray', atom, shape_a, filters=filters)\n\nfor i in range(batches):\n    data = np.random.rand(rows,cols)\n    ca_a[i*rows:(i+1)*rows]= data[:]\n#h5f_0.close()\n\n\nrows = n_col\ncols = n_row\nbatches = n_batch\n\nfileName_b = 'C:\\carray_b.h5'\nshape_b = (rows, cols*batches)  # predefined size\n\nh5f_b = tables.open_file(fileName_b, 'w')\nca_b = h5f_b.create_carray(h5f_b.root, 'carray', atom, shape_b, filters=filters)\n\n#need to batch by cols\nsz= rows/batches\nfor i in range(batches):\n    data = np.random.rand(sz, cols*batches)\n    ca_b[i*sz:(i+1)*sz]= data[:]\n#h5f_1.close()\n\nrows = n_batch*n_row\ncols = n_batch*n_row\n\nfileName_c = 'C:\\carray_c.h5'\nshape_c = (rows, cols)  # predefined size\n\nh5f_c = tables.open_file(fileName_c, 'w')\nca_c = h5f_c.create_carray(h5f_c.root, 'carray', atom, shape_c, filters=filters)\n\n\na= h5f_a.root.carray#[:]\nb= h5f_b.root.carray#[:]\nc= h5f_c.root.carray\n\nt0= time.time()\nc= np.dot(a,b) #error if aray is big\nprint (time.time()-t0)\n```\n\n\nUpdate: so here is the code.It's interesting but using hdf5 it works even faster.\n\n```\nimport numpy as np\nimport tables\nimport time\n\nsz= 100 #chunk size\nn_row=10000 #m\nn_col=1000 #n\n\n#for arbitrary size\nA=np.random.rand(n_row,n_col)\nB=np.random.rand(n_col,n_row)\n# A=np.random.randint(5, size=(n_row,n_col))\n# B=np.random.randint(5, size=(n_col,n_row))\n\n#using numpy array\n#C= np.zeros((n_row,n_row))\n\n#using hdf5\nfileName_C = 'CArray_C.h5'\natom = tables.Float32Atom()\nshape = (A.shape[0], B.shape[1])\nNchunk = 128  # ?\nchunkshape = (Nchunk, Nchunk)\nchunk_multiple = 1\nblock_size = chunk_multiple * Nchunk\nh5f_C = tables.open_file(fileName_C, 'w')\nC = h5f_C.create_carray(h5f_C.root, 'CArray', atom, shape, chunkshape=chunkshape)\n\nsz= block_size\n\nt0= time.time()\nfor i in range(0, A.shape[0], sz):\n    for j in range(0, B.shape[1], sz):\n        for k in range(0, A.shape[1], sz):\n            C[i:i+sz,j:j+sz] += np.dot(A[i:i+sz,k:k+sz],B[k:k+sz,j:j+sz])\nprint (time.time()-t0)\n\nt0= time.time()\nres= np.dot(A,B)\nprint (time.time()-t0)\n\nprint (C== res)\n\nh5f_C.close()\n```\n\n    ", "Answer": "\r\nI don't know of a np.dot that work without loading into memory.  I think blocking would work pretty well.  Create a an output array (called \"c\" below) as pytables CArray and fill in blocks.  You should choose the chunkshape when you create it to match your blocking scheme.  Something like\n\n```\natom = tables.Float32Atom() # you have UInt8Atom() above.  do you mean that?\nshape = (a.shape[0], b.shape[1])\n\n# you can vary block_size and chunkshape independently, but I would\n# aim to have block_size an integer multiple of chunkshape\n# your mileage may vary and depends on the array size and how you'll\n# access it in the future.\n\nNchunk = 128  # ?\nchunkshape = (Nchunk, Nchunk)\nchunk_multiple = 1\nblock_size = chunk_multiple * Nchunk\nc = h5f.create_carray(h5.root, 'c', atom, shape, chunkshape=chunkshape)\n\nfor i_start in range(0, a.shape[0], block_size):\n    for j_start in range(0, b.shape[1], block_size):\n        for k_start in range(0, a.shape[1], block_size):\n            c[i_start:i_start+block_size, j_start:j_start + block_size] += \\ \n                    np.dot(a[i_start:i_start + block_size, k_start:k_start + block_size],\n                           b[k_start:k_start + block_size, j_start:j_start + block_size]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Python - Numpy matrix multiplication\r\n                \r\nI am trying to optimize (memorywise the multiplication of X and its transpose X'\n\nDoes anyone know if numpys matrix multiplication takes into consideration that X' is just the transpose of X. What I mean is that if it detects this and therfore does not create the object X' but just works on the cols/rows of X to produce the product? Thank you for any help on this!\n\nJ.\n    ", "Answer": "\r\nIn numpy convention, the transpose of ```\nX```\n is represented by```\nX.T```\n and you're in luck, ```\nX.T```\n is just a view of the original array ```\nX```\n, meaning that no copy is done.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Why is matrix multiplication with Numba slow?\r\n                \r\nI try to find an explanation why my matrix multiplication with Numba is much slower than using NumPy's dot function. Although I am using the most basic code for writing a matrix multiplication function with Numba, I don't think that the significantly slower performance is due to the algorithm. For simplicity, I consider two k x k square matrices, A and B. My code reads\n```\n1     @njit('f8[:,:](f8[:,:], f8[:,:])')\n2     def numba_dot(A, B):\n3\n4         k=A.shape[1]\n5         C = np.zeros((k, k))\n6\n7         for i in range(k):\n8             for j in range(k):\n9\n10                 tmp = 0.\n11                for l in range(k):\n12                    tmp += A[i, l] * B[l, j]\n13     \n14                C[i, j] = tmp\n15\n16         return C\n```\n\nRunning this code repeatedly with two random matrices 1000 x 1000 Matrices, it typically takes at least about 1.5 seconds to finish.\nOn the other hand, if I don't update the matrix C, i.e. if I drop line 14, or replace it for the sake of a test by for example the following line:\n```\n14                C[i, j] = i * j\n```\n\nthe code finishes in about 1-5 ms. Compared to that, NumPy's dot function requires for this matrix multiplication around 10 ms.\nWhat is the reason behind the discrepancy of the running times between the above code for the matrix multiplication and this small variation? Is there a way to store the value of the variable tmp in C[i, j] without deteriorating the performance of the code so significantly?\n    ", "Answer": "\r\nThe native ```\nNumPy```\n implementation works with vectorized operations.  If your CPU supports these, the processing is much faster.  Current microprocessors have on-chip matrix multiplication, which pipelines the data transfers and vector operations.\nYour implementation performs k^3 loop iterations; a billion of anything will take some non-trivial time.\nYour code specifies that you want to perform each cell-by-cell operation in isolation, a billion distinct operations instead of roughly 5k operations done in parallel and pipelined.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication performance improvement\r\n                \r\nI have got some unclear questions for the following matrix multiplication algorithm.\n\n\n\n1) Why does the inner for-loop (line 6) do not use a “parallel for” construct?\n\n2) Can we further improve the performance of the inner loop computation (lines 6-7) by some form of parallelism?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication using two classes\r\n                \r\nSo in my Computer Science class we are going over Matrix Multiplication and I got a little stuck. We are to multiply to matrices that are varying in dimensions. Here is the first class and I need help figuring out how to print my results after the for-loops are complete.\n```\npublic class Main {\n    public static void main(String[] args) {\n        int[][] a = {{1, 2, -2, 0}, {-3, 4, 7, 2}, {6, 0, 3, 1}};\n        int[][] b = {{-1, 3}, {0, 9}, {1, -11}, {4, -5}};\n        int[][] c = MatrixMult.mult(a, b);\n\n        for (int r = 0; r < a.length; r++) {\n            for (int c = 0; c < b[0].length; r++) {\n                //where the results are printed\n            }\n        }\n    }\n}\n```\n\nThen this is the other class which has the Matrix Multiplication function in it. I couldn't figure out what to put after the ```\nsum+=```\n to finish the loops and return ans.\n```\npublic class MatrixMult {\n    public static int[][] mult(int[][] a, int[][] b) {\n        int cRows = a.length;\n        int cCols = b[0].length;\n        int[][] ans = new int[cRows][cCols];\n\n        for (int r = 0; i < cRows; r++) {\n            for (int c = 0; j < cCols; c++) {\n                int sum = 0;\n                for (int r1 = 0; int r1 < a[0].length; r1++) {\n                    sum += // I'm not sure what I put here\n                }\n            }\n        }\n        return ans;\n    }\n}\n```\n\nThe output after all is finished should be:\n```\n-3 43\n18 -60\n1 -20\n```\n\n    ", "Answer": "\r\nI will give you a hint.\nWhen multiplying matrices ```\nA * B = C```\n, you are iterating rows of ```\nA```\n (variable ```\ni```\n) and columns of ```\nB```\n (variable ```\nj```\n). ```\nC[i][j]```\n is equal to:\n```\n(A[i][0] * B[0][j]) + (A[i][1] * B[1][j]) + (A[i][2] * B[2][j]) + ...\n```\n\nYou add the values in brackets to your sum, and then assign it to ```\nC[i][j]```\n.\nTry to figure it out by examining this pattern.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Parallel matrix multiplication in java\r\n                \r\nI am trying to implement matrix multiplication with multiple threads. Everything seems to work correctly, however, it work much slower than the usual algorithm. Here is my code\n```\npublic class Main {\n    private static int nRows = 500; //number of rows and columns in matrices\n    private static int[][] matrix1 = new int[nRows][nRows]; //first matrix for multiplication\n    private static int[][] matrix2 = new int[nRows][nRows]; //second matrix for multiplication\n    private static int[][] result1 = new int[nRows][nRows]; //result from linear matrix multiplication\n    private static int[][] result2 = new int[nRows][nRows]; //result from parallel matrix multiplication\n\n    private static Thread[][] pool = new Thread[nRows][nRows]; //array of threads\n\n    //method used for transposing a matrix to get its column easily\n    public static int[][] transpose(int[][] matrix) {\n        int[][] newMatrix = new int[matrix[0].length][matrix.length];\n        for (int i = 0; i < matrix[0].length; i++) {\n            for (int j = 0; j < matrix.length; j++) {\n                newMatrix[i][j] = matrix[j][i];\n            }\n        }\n        return newMatrix;\n    }\n\n    public static void main(String[] args) {\n        //initializing input matrices (setting all elements = 1)\n        for (int i = 0; i < nRows; i++) {\n            for (int j = 0; j < nRows; j++) {\n                matrix1[i][j] = 1;\n                matrix2[i][j] = 1;\n            }\n        }\n\n        long start;\n        long end;\n\n        System.out.println(\"Linear algorithm\");\n        start = System.currentTimeMillis();\n\n        //linear multiplication algorithm\n        for (int i = 0; i < nRows; i++) {\n            for (int j = 0; j < nRows; j++) {\n                int temp = 0;\n                for (int k = 0; k < nRows; k++) {\n                    temp += matrix1[i][k] * matrix2[k][j];\n                }\n                result1[i][j] = temp;\n            }\n        }\n\n        //show result\n//        for(int i=0;i<nRows;i++){\n//            for(int j=0;j<nRows;j++){\n//                System.out.print(result1[i][j] + \" \");\n//            }\n//            System.out.println();\n//        }\n\n        end = System.currentTimeMillis();\n        System.out.println(\"Time with linear algorithm: \" + (end - start));\n\n        //--------------------\n\n        System.out.println(\"Parallel algorithm\");\n        start = System.currentTimeMillis();\n\n        int[][] matrix3 = transpose(matrix2); //get a transpose copy of second matrix\n\n        for (int i = 0; i < nRows; i++) {\n            for (int j = 0; j < nRows; j++) {\n                pool[i][j] = new myThread(matrix1[i], matrix3[j], i, j); //creating a thread for each element\n                pool[i][j].start(); //starting a thread\n            }\n        }\n\n        for (int i = 0; i < nRows; i++) {\n            for (int j = 0; j < nRows; j++) {\n                try {\n                    pool[i][j].join(); //waiting for the thread to finish its job\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n\n        //show the result\n//        for(int i=0;i<nRows;i++){\n//            for(int j=0;j<nRows;j++){\n//                System.out.print(result2[i][j] + \" \");\n//            }\n//            System.out.println();\n//        }\n\n        end = System.currentTimeMillis();\n        System.out.println(\"Time with parallel algorithm: \" + (end - start));\n    }\n\n    //class, where parallel multiplication is implemented\n    private static class myThread extends Thread {\n        private int[] row = new int[nRows]; //row for multiplication\n        private int[] col = new int[nRows]; //column for multiplication\n        private int i;  //row index of the element in resulting matrix\n        private int j; //column index of the element in resulting matrix\n\n        //constructor\n        public myThread(int[] r, int[] c, int i, int j) {\n            row = r;\n            col = c;\n            this.i = i;\n            this.j = j;\n        }\n\n        public void run() {\n            int temp = 0;\n            for (int k = 0; k < nRows; k++) {\n                temp += row[k] * col[k]; //getting the element by multiplying row and column of two matrices\n            }\n            result2[i][j] = temp; //writing the resulting element to the resulting matrix\n        }\n    }\n}\n```\n\nHere, I create a new thread for each element in the resulting matrix. I than write these threads to an array, start them and, finally, wait for them to finish working. I've seen some realizations, where the whole input matrix (both of them) would be given as parameters to the thread. My task is, however, to come up with an algorithm, where only one row and one column (that are necessary for this particular element) are given.\nAfter measuring the time elapsed I get following results\n```\nLinear algorithm\nTime with linear algorithm: 557\nParallel algorithm\nTime with parallel algorithm: 38262\n```\n\nWhat am I doing wrong? Thanks in advance!\n    ", "Answer": "\r\nThe code you've written will work fine on a GPU where the concept of threads is very different and the overhead is basically zero. On CPU-based systems, spawning threads is an exceptionally slow operation and it only makes sense if you can amortise this overhead over a lot of computational work.\n\nHere is some general advice that will help you write better parallel algorithms for CPUs:\n\n\nWith computationally heavy tasks, use as many threads as there are physical execution units (cores). SMT techniques such as HyperThreading do not help much unless there is a lot of memory latency. For small matrices that fit in the L1 and L2 CPU caches, the latency is very low and there is nothing to gain from SMT. When more than one thread share the same core, the OS has to context switch between the two, which adds overhead and may trash the cache.\nKeep parallelisation granularity as coarse as possible so to maximise the work per thread. Instead of having one row x column operation per thread, have each thread operate on contiguous blocks of rows / columns. You can try and only parallelise the outer loop, i.e., only over the rows of the first matrix.\nKeep the number of threads dependent on the hardware properties (number of cores) and independent of the problem size. Spawning a separate thread for each row and column scales the overhead linearly with the problem size, which is really bad from performance point of view.\nAvoid false sharing. This happens when two or more threads running on different cores write to memory locations that fall in the same cache line. When one thread updates the cache of its core, the change propagates and invalidates the caches of the other cores that have the same cache line, forcing them to refetch the data. In your case, 16 consecutive values of ```\nresult2```\n fall in the same cache line (cache lines on x86 and ARM are 64 bytes long, ```\nint```\n is 4 bytes) and are written by 16 different threads. The use of a temporary summation variable alleviates this problem somehow--it is much more severe when false sharing happens repeatedly in an inner(-most) loop.\nUse thread pools for repeated tasks when the number of work items exceeds the number of threads and each thread will get work multiple times. In your case, you give each thread a single work item, so this is not really pooling.\n\n\nIn summary, start as many threads as physical cores and have them work on big contiguous chunks of the input matrices.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Recursive Matrix Multiplication algorithm failing to calculate\r\n                \r\nWe were given an assignment to use dynamic programming to code a program in C++ for matrix multiplication.  He told us to use recursion and gave us a custom written matrix class.  I wrote the following recursive algorithm, however I am getting an error when I run that says \n\n```\nObject& Matrix<Object>::at(uint, uint) [with Object = unsigned int, uint = unsigned     int]: Assertions 'row < rows && col < cols' failed.```\n\n\nAny ideas as to why this is happening?  I included his matrix class and my recursive matrix multiplication method below.  \n\n```\n#ifndef MATRIX_H\n#define MATRIX_H\n\n#include <cassert>\ntypedef unsigned int uint;\n\ntemplate <class Object>\nclass Matrix\n{\npublic:\n    Matrix( uint rows, uint cols );\n    Object & at( uint row, uint col );\n    const Object & at( uint row, uint col ) const;\n    ~Matrix();\n    Matrix( const Matrix<Object> & m ); // Copy constructor\n    Matrix & operator= ( const Matrix<Object> & m );   // Assignment operator\n    uint numrows() const;\n    uint numcols() const;\n\nprivate:\n    uint rows;\n    uint cols;\n    Object* data;\n};\n\ntemplate <class Object>\nMatrix<Object>::Matrix( uint rows, uint cols )\n: rows( rows ), cols( cols )\n{\n    assert( rows > 0 && cols > 0 );\n    data = new Object[ rows * cols ];\n}\n\ntemplate <class Object>\nMatrix<Object>::~Matrix()\n{\n    delete[] data;\n}\n\ntemplate <class Object>\nObject & Matrix<Object>::at( uint row, uint col )\n{\n    assert( row < rows && col < cols );\n    return data[ cols * row + col ];\n}\n\ntemplate <class Object>\nconst Object & Matrix<Object>::at( uint row, uint col ) const\n{\n    assert( row < rows && col < cols );\n    return data[ cols * row + col ];\n}\n\ntemplate <class Object>\nuint Matrix<Object>::numrows() const\n{\n    return rows;\n}\n\ntemplate <class Object>\nuint Matrix<Object>::numcols() const\n{\n    return cols;\n}\n\nint minmult( Matrix<uint> & P,\n         Matrix<uint> & M,\n         const vector<uint> & d,\n         uint i,\n         uint j )\n{\n\n\nif( M.at(i,j) != INF )\n{\n    return M.at(i,j);               //already has been defined\n}\nelse if( i == j )\n{\n    M.at(i,j) = 0;                  //base case\n}\nelse\n{\n    //M.at(i,j) = UINT_MAX;         //initialize to infinity\n    for( uint k = i; k <= j-1; k++)\n    {\n        uint ops = minmult(P, M, d, i, k)\n            + minmult(P, M, d, k+1, j)\n            + d.at(i-1)*d.at(k)*d.at(j);\n        if( ops < M.at(i,j))\n        {\n            M.at(i,j) = ops;        \n            P.at(i,j) = k;          \n        }\n    }\n}\nreturn M.at(i,j);                  //returns the final cost\n}\n```\n\n    ", "Answer": "\r\nThe error seems to be quite clear, you are calling the ```\nat```\n method and passing values for ```\nrow```\n and ```\ncol```\n that are not smaller than the number of rows and columns... which is evident in the code:\n\n```\nuint i = M.numcols();\nuint j = M.numrows();\nif(i == j) {\n    M.at(i,j) = 0;    // i == numcols() thus !(i<numcols()) \n                      // j == numrows() thus !(j<numrows())\n```\n\n\nAssuming that you intended on calling ```\nM.at(j,i)```\n, that is, since the arguments to ```\nat```\n are ```\nrows```\n and ```\ncols```\n and not the other way around...\n\nOther than that, your recursion step is wrong, since the next step in the recursion does not have a smaller problem than the original (it is actually of exactly the same size, since ```\nminmult(M,P,d)```\n calls ```\nminmult(M,P,d)```\n. Once you fix the assert, this will kick you in the form of a Stack Overflow.\n\nFinally, it is not clear what the intention of the code is, you should take the time to solve the problem with pen and paper, and then map the solution to your programming language of choice.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Issue with numpy matrix multiplication\r\n                \r\nI'm trying to multiply two matrices of dimensions (17,2) by transposing one of the matrices\n\nHere is example p1\n\n```\n    p1 = [[ 0.15520622 -0.92034567]\n [ 0.43294367 -1.05921439]\n [ 0.7569707  -1.15179354]\n [ 1.08099772 -1.15179354]\n [ 1.35873517 -0.96663524]\n [-1.51121847 -0.64260822]\n [-1.32606018 -0.87405609]\n [-1.00203315 -0.96663524]\n [-0.67800613 -0.96663524]\n [-0.3539791  -0.87405609]\n [ 0.89583942  1.02381648]\n [ 0.66439155  1.3478435 ]\n [ 0.3866541   1.48671223]\n [ 0.15520622  1.5330018 ]\n [-0.07624165  1.5330018 ]\n [-0.3539791   1.44042265]\n [-0.58542698  1.20897478]]\n```\n\n\nhere is another example matrix p2\n\n```\n p2 = [[ 0.20932473 -0.90029958]\n [ 0.53753779 -1.03849455]\n [ 0.88302521 -1.10759204]\n [ 1.24578701 -1.02122018]\n [ 1.47035383 -0.77937898]\n [-1.46628927 -0.69300713]\n [-1.29354556 -0.9521227 ]\n [-0.96533251 -1.03849455]\n [-0.63711946 -1.00394581]\n [-0.3089064  -0.90029958]\n [ 0.86575084  1.06897874]\n [ 0.55481216  1.37991742]\n [ 0.26114785  1.50083802]\n [ 0.03658102  1.51811239]\n [-0.1879858   1.50083802]\n [-0.46437574  1.37991742]\n [-0.74076568  1.08625311]]\n```\n\n\nI'm trying to multiply them using numpy\n\n```\nimport numpy\n\nprint(p1.T * p2)\n```\n\n\nBut I'm getting the following error\n\n```\noperands could not be broadcast together with shapes (2,17) (17,2) \n```\n\n\nThis is the expected matrix multiplication output\n\n```\n[[11.58117944  2.21072324]\n [-0.51754442 22.28728876]]\n```\n\n\nWhere exactly am I going wrong\n    ", "Answer": "\r\nMatrix multiplication is done with ```\nnp.dot(p1.T,p2)```\n, because \n```\nA * B```\n means matrix elements-wise multiply.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication error after loop in c language\r\n                \r\nI have an assignment where i have to make a matrix multiplication program more efficient \nso i wrote a method called multiply matrix but after i actually do the matrix multiplication in a loop the final product matrix is all zero but, if i check while in the loop its not zero \n\n```\nint** multiply_matrices(int** matrix1, int** matrix2, int m1, int n1, int m2, int n2) {\nif(n1 != m2) {\n    printf(\"error\\n\");\n    return NULL;\n}\n\nint i = 0;\nint j = 0;\nint k = 0;\nint** product = (int**) malloc(m1 * sizeof(int*));\n\n\n\nfor(i = 0; i<m1; i++){\n    product[i] = (int*) malloc(n2 * sizeof(int));\n    for(j = 0; j<n1; j++){\n        product[i][j] = 0;\n    }\n}\n*\nfor(i = 0; i < m1; i ++) {\n    product[i] = (int*) malloc(n2 * sizeof(int));\n    int chg = 0;\n\n     while(j<n2){\n\n\n        if(k == n1 ){\n            //chg = 0;\n            k = 0;\n            //printf(\"%d\\n\", j);\n            j++;\n        }\n\n             product[i][j]  += matrix1[i][k] * matrix2[k][j];\n\n            printf(\"%d \\n\", product[i][j]);\n        k++;\n        chg = 1;\n\n    }\n}\n\nreturn product;\n```\n\n\n}\n    ", "Answer": "\r\nTwo errors I found:\n\nYou aren't resetting ```\nj = 0```\n in the outer multiplication loop. This leads to it only completing one row, if it enters the inner loop at all, as its value remains equal to ```\nn1```\n after the allocation loop. This is most likely why it is returning all zeros for you.\n\nSecond, you should reset k in the outer loop as well. When the condition ```\nj<n2```\n is broken, ```\ni```\n increments but ```\nk```\n remains the same value as when the last loop ended. \n\nI also do not know what the point of the chg variable is as is it doing nothing.\n\nAnd, as TrustworthySystems said, only allocate memory once or you will have leaks. Here is the correct function:\n\n```\nint** multiply_matrices(int** matrix1, int** matrix2, int m1, int n1, int m2, int n2) {\nif(n1 != m2) {\n    printf(\"error\\n\");\n    return NULL;\n}\n\nint i = 0;\nint j = 0;\nint k = 0;\nint** product = (int**) malloc(m1 * sizeof(int*));\n\n\n\nfor(i = 0; i<m1; i++){\n    product[i] = (int*) malloc(n2 * sizeof(int));\n    for(j = 0; j<n1; j++){\n        product[i][j] = 0;\n    }\n}\n\nfor(i = 0; i < m1; i++) {\n    int chg = 0;\n    j = 0;\n    k = 0;\n\n    while(j<n2){\n        if(k == n1 ){\n            k = 0;\n            j++;\n        }\n        product[i][j]  += matrix1[i][k] * matrix2[k][j];\n        k++;\n        chg = 1;\n\n    }\n}\nreturn product;\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Correct way to perform matrix multiplication\r\n                \r\nI have the simple matrix and would like to multiply D on E but I'm getting an error:\n\n```\nD <- data.frame(X = c(1,1,-1,1), Y = c(1,-1,1,1), Z = c(1,1,1,-1))\nE <- data.frame(X = c(-1,0,1), Y = c(-1,1,0), Z = c(1,1,1))\nP <- D %*% E\n```\n\n\n\n  Error in D %*% E : requires numeric/complex matrix/vector arguments\n\n\nHow do I overcome the error? It's  simple 3x4 and 3x3 matrix multiplication. Thank you for your support!\n    ", "Answer": "\r\nYou have to transform the data frames into matrices:\n\n```\nD <- as.matrix(data.frame(X = c(1,1,-1,1), Y = c(1,-1,1,1), Z = c(1,1,1,-1)))\nE <- as.matrix(data.frame(X = c(-1,0,1), Y = c(-1,1,0), Z = c(1,1,1)))\nP <- D %*% E\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication in Python Language\r\n                \r\nI'm trying to do a Matrix multiplication using nested while loops for the given hard coded matrices...\n\nThe correct answer for this should be [[6,12], [15,30], [24,48]]\n\nbut the output of my code is [[6,12], [6,12], [6,12]]\n\nwhat should I do?\n\n```\na=[[1,2,3],[4,5,6],[7,8,9]]\nb=[[1,2],[1,2],[1,2]]\nc=[]\n\ncola=len(a)\nrowa=len(a[0])\ncolb=len(b)\nrowb=len(b[0])\nr,s,t,u,sum = 0,0,0,0,0\n\nc=[([0]*rowb)]*cola\n\nprint c\n\n\nwhile s<cola:\n    while u<rowb:  \n        while t<colb:\n            d=a[s][t]*b[t][r]\n            sum+=d\n            t+=1\n\n        c[s][r]=sum\n        sum=0\n        u+=1\n        t=0\n        r+=1\n\n    r=0    \n    s+=1\n\nprint c\n```\n\n    ", "Answer": "\r\nWhen you do - \n\n```\nc=[([0]*rowb)]*cola\n```\n\n\nYou are just copying the inner list ```\ncola```\n times, this is shallow copying, hence each inner list is a reference to the same object , hence when you change an element inside one of the inner lists, it affects all of the inner lists. Instead of that, try using list comprehension to create the ```\nc```\n list.\n\nExample - \n\n```\nc = [[0 for _ in range(rowb)] for _ in range(cola)]\n```\n\n\nAlso, another small issue in your logic, you are using ```\nr```\n to denote the elements from ```\nb```\n , but in the while loop you are checking against - ```\nu```\n , you should check against ```\nr```\n . Example -\n\n```\nwhile s<cola:\n    while r<rowb: \n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Vector-matrix & matrix-matrix multiplication using SSE for any size of input matrix and vector\r\n                \r\nI am trying to do Vector-matrix multiplication as well as matrix-matrix multiplication using SSE Intrinsic but I get an error saying \"Segmentation Fault\", if I try to do for anything except multiples of 4. not able to figure out why, it don't work for anything else.?  Please suggest changes so that it works for anysize of input.?\n\nFollowing is my implementation:  \n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <malloc.h>\n#include <xmmintrin.h>\n#include <time.h>\n#include <omp.h>  \n\n/*****************************************************\nthe following function generates a \"size\"-element vector\nand a \"size x size\" matrix\n ****************************************************/\nvoid matrix_vector_gen(int size, float *matrix, float *vector){\n    int i;\n    for (i = 0; i < size*size; i++){\n        vector[i] = i*1.2f + 1;//((float)rand())/65535.0f;\n        printf(\"%f \\n \", vector[i]);\n    }\n    for (i = 0; i < size*size; i++){\n        matrix[i] = i*1.3f + 1;//((float)rand())/5307.0f;\n        printf(\"%f \\n \", matrix[i]);\n    }\n}\n\n/****************************************************\nthe following function calculate the below equation\n   vector_out = vector_in x matrix_in\n ***************************************************/\nvoid matrix_mult_sq(int size, float *vector_in,\n               float *matrix_in, float *vector_out){\n    int i, j, k;\n    for (i = 0; i < size; i++)\n    {\n        for (j = 0; j < size; j++)\n        {\n            vector_out[size*i + j] = 0.0;\n            for (k = 0; k < size; k++)\n                vector_out[size*i + j] += vector_in[size*i + k] * matrix_in[size*k + j];\n        }\n    }\n}\n\nvoid matrix_mult_sse(int size, float *vector_in,\n    float *matrix_in, float *vector_out){\n    __m128 a_line, b_line, r_line;\n    int i, j, k, l;\n    for (k = 0; k < size; k++)\n    {\n\n        for (i = 0; i < size; i += 4){\n            j = 0;\n            b_line = _mm_load_ps(&matrix_in[i]); // b_line = vec4(matrix[i][0])\n            a_line = _mm_set1_ps(vector_in[j + k*size]);      // a_line = vec4(vector_in[0])\n            r_line = _mm_mul_ps(a_line, b_line); // r_line = a_line * b_line\n            for (j = 1; j < size; j++) {\n                b_line = _mm_load_ps(&matrix_in[j*size + i]); // a_line = vec4(column(a, j))\n                a_line = _mm_set1_ps(vector_in[j + k*size]);  // b_line = vec4(b[i][j])\n                // r_line += a_line * b_line\n                r_line = _mm_add_ps(_mm_mul_ps(a_line, b_line), r_line);\n            }\n            _mm_store_ps(&vector_out[i + k*size], r_line);     // r[i] = r_line\n        }\n    }\n    for (l=0; l < size*size; l++)\n    {\n        printf(\"%f \\n\", vector_out[l]);\n    }\n}\n\nint main(int argc, char *argv[]){\n  if(argc < 2){\n    printf(\"Usage: %s matrix/vector_size\\n\", argv[0]);\n    return 0;\n  }\n\n  int size = atoi(argv[1]);\n  if(size%4 != 0){\n    printf(\"This version implements for \"\"size = 4*n\"\" only\\n\");\n    return 0;\n  }\n\n  float *vector = (float *)memalign(sizeof(float)*4, sizeof(float)*size);//(float *)malloc(sizeof(float)*size);\n  if(vector==NULL){\n    printf(\"can't allocate the required memory for vector\\n\");\n    return 0;\n  }\n\n  float *matrix = (float *)memalign(sizeof(float)*4, sizeof(float)*size*size);\n  if(matrix==NULL){\n    printf(\"can't allocate the required memory for matrix\\n\");\n    free(vector);\n    return 0;\n  }\n\n  float *result_sq = (float *)memalign(sizeof(float)*4, sizeof(float)*size);\n  if(result_sq==NULL){\n    printf(\"can't allocate the required memory for result_sq\\n\");\n    free(vector);\n    free(matrix);\n    return 0;\n  }\n\n  float *result_pl = (float *)memalign(sizeof(float)*4, sizeof(float)*size);\n  if(result_pl==NULL){\n    printf(\"can't allocate the required memory for result_pl\\n\");\n    free(vector);\n    free(matrix);\n    free(result_sq);\n    return 0;\n  }\n\n  matrix_vector_gen(size, matrix, vector);\n\n  double time_sq;\n  double time_sse;\n\n  time_sq = omp_get_wtime();\n  matrix_mult_sq(size, vector, matrix, result_sq);\n  time_sq = omp_get_wtime() - time_sq;\n\n  time_sse = omp_get_wtime();\n  matrix_mult_sse(size, vector, matrix, result_pl);\n  time_sse = omp_get_wtime() - time_sse;\n\n  printf(\"SEQUENTIAL EXECUTION: %f (sec)\\n\",time_sq);\n  printf(\"PARALLEL EXECUTION: %f (sec)\\n\", time_sse);\n\n  //check\n  /*int i;\n  for(i=0; i<size; i++)\n    if((int)result_sq[i] != (int)result_pl[i]){\n      printf(\"wrong at position %d\\n\", i);\n      free(vector);\n      free(matrix);\n      free(result_sq);\n      free(result_pl);\n      return 0;\n    }*/\n\n  free(vector);\n  free(matrix);\n  free(result_sq);\n  free(result_pl);\n  return 1;\n}\n```\n\n    ", "Answer": "\r\nIt seems you are loading and storing exclusively with mm_load_ps and mm_store_ps, which load and store 4 floats in a single instruction.\n\nSince your containers (matrixes and vectors) do not have necessarily a size which is a multiple of 4 floats (16 bytes) this is incorrect.\n\nmemalign ensures that the pointer is aligned (here on 16 bytes) but does not reserve padding at the end so that the allocated block size is a multiple of 16 bytes.\n\nFor instance, when storing a 5-dimension vector, the vector has only 20 bytes allocated in memory, but you write 32 bytes (two mm_store_ps operations)\n\nAdditionally, it seems this is incorrect:\n\n\n  _mm_store_ps(&vector_out[i + k*size], r_line);\n\n\nYou want to store a single float here, if I'm right. Not four packed floats.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication and addition using Mysql\r\n                \r\nI have two tables \n\n```\nTable1:\n\ntable_id_one table_id_two\n1             2\n3             4\n\n\nTable2\n\nid_one   id_two\n5        6\n7        7\n```\n\n\nI want matrix multiplication and addition of table1 and table2 using mysql. The result should be\n\n```\nMultiply\n\nX  Y\n19 22\n43 50\n\nAdd\nX  Y\n6  8\n10 11\n```\n\n\nHow can i do that ?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "2-D convolution as a matrix-matrix multiplication [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     This question does not appear to be about programming within the scope defined in the help center.\r\n                \r\n                    \r\n                        Closed 2 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI know that, in the 1D case, the convolution between two vectors, ```\na```\n and ```\nb```\n, can be computed as ```\nconv(a, b)```\n, but also as the product between the ```\nT_a```\n and ```\nb```\n, where ```\nT_a```\n is the corresponding Toeplitz matrix for ```\na```\n.\n\nIs it possible to extend this idea to 2D?\n\nGiven ```\na = [5 1 3; 1 1 2; 2 1 3]```\n and ```\nb=[4 3; 1 2]```\n, is it possible to convert ```\na```\n in a Toeplitz matrix and compute the matrix-matrix product between ```\nT_a```\n and ```\nb```\n as in the 1-D case?\n    ", "Answer": "\r\nYes, it is possible and you should also use a doubly block circulant matrix (which is a special case of Toeplitz matrix). I will give you an example with a small size of kernel and the input, but it is possible to construct Toeplitz matrix for any kernel. So you have a 2d input ```\nx```\n and 2d kernel ```\nk```\n and you want to calculate the convolution ```\nx * k```\n. Also let's assume that ```\nk```\n is already flipped. Let's also assume that ```\nx```\n is of size ```\nn×n```\n and ```\nk```\n is ```\nm×m```\n.\n\nSo you unroll ```\nk```\n into a sparse matrix of size ```\n(n-m+1)^2 × n^2```\n, and unroll ```\nx```\n into a long vector ```\nn^2 × 1```\n. You compute a multiplication of this sparse matrix with a vector and convert the resulting vector (which will have a size ```\n(n-m+1)^2 × 1```\n) into a ```\nn-m+1```\n square matrix.\n\nI am pretty sure this is hard to understand just from reading. So here is an example for 2×2 kernel and 3×3 input.\n\n * \n\nHere is a constructed matrix with a vector:\n\n\n\nwhich is equal to .\n\nAnd this is the same result you would have got by doing a sliding window of ```\nk```\n over ```\nx```\n.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Repeated Squaring - Matrix Multiplication using NEWMAT\r\n                \r\nI'm trying to use the repeated squaring algorithm (using recursion) to perform matrix exponentiation. I've included header files from the NEWMAT library instead of using arrays. The original matrix has elements in the range (-5,5), all numbers being of type float.\n\n```\n# include \"C:\\User\\newmat10\\newmat.h\"\n# include \"C:\\User\\newmat10\\newmatio.h\"\n# include \"C:\\User\\newmat10\\newmatap.h\"\n\n# include <iostream>\n# include <time.h>\n# include <ctime>\n# include <cstdlib>\n# include <iomanip>\n\nusing namespace std;\n\nMatrix repeated_squaring(Matrix A, int exponent, int n) //Recursive function\n {\n    A(n,n);\n    IdentityMatrix I(n);\n\n    if (exponent == 0) //Matrix raised to zero returns an Identity Matrix\n    return I;\n\n    else \n    {\n\n        if ( exponent%2 == 1 ) // if exponent is odd\n        return (A * repeated_squaring (A*A, (exponent-1)/2, n));\n\n        else //if exponent is even\n        return (A * repeated_squaring( A*A, exponent/2, n));\n    }\n  }\n\n Matrix direct_squaring(Matrix B, int k, int no) //Brute Force Multiplication\n  {\nB(no,no);\nMatrix C = B;\nfor (int i = 1; i <= k; i++)\n    C = B*C;\nreturn C;\n   }\n\n    //----Creating a matrix with elements b/w (-5,5)----\n\n\nfloat unifRandom()\n{\nint a = -5;\nint b = 5;\nfloat temp = (float)((b-a)*( rand()/RAND_MAX) + a);\nreturn temp;\n}\n\nMatrix initialize_mat(Matrix H, int ord)\n{\nH(ord,ord);\nfor (int y = 1; y <= ord; y++)\n    for(int z = 1; z<= ord; z++)\n        H(y,z) = unifRandom();\n\nreturn(H);\n}\n//---------------------------------------------------\n\nvoid main()\n{\nint exponent, dimension;\n\ncout<<\"Insert exponent:\"<<endl;\ncin>>exponent;\ncout<< \"Insert dimension:\"<<endl;   \ncin>>dimension;\n\n\ncout<<\"The number of rows/columns in the square matrix is: \"<<dimension<<endl;\ncout<<\"The exponent is: \"<<exponent<<endl;\n\nMatrix      A(dimension,dimension),B(dimension,dimension);\n    Matrix C(dimension,dimension),D(dimension,dimension);\n\nB= initialize_mat(A,dimension);\n\ncout<<\"Initial Matrix: \"<<endl;\n\ncout<<setw(5)<<setprecision(2)<<B<<endl;\n//-----------------------------------------------------------------------------\n\ncout<<\"Repeated Squaring Result: \"<<endl;\n\nclock_t time_before1 = clock();\n\nC = repeated_squaring (B, exponent , dimension);\ncout<< setw(5) <<setprecision(2) <<C;\n\nclock_t time_after1 = clock();\nfloat diff1 = ((float) time_after1 - (float) time_before1);\ncout << \"It took \" << diff1/CLOCKS_PER_SEC << \" seconds to complete\" << endl<<endl;\n\n//---------------------------------------------------------------------------------\n\ncout<<\"Direct Squaring Result:\"<<endl;\n\nclock_t time_before2 = clock();\n\nD = direct_squaring (B, exponent , dimension);\ncout<<setw(5)<<setprecision(2)<<D;\n\nclock_t time_after2 = clock();\nfloat diff2 = ((float) time_after2 - (float) time_before2);\ncout << \"It took \" << diff2/CLOCKS_PER_SEC << \" seconds to complete\" << endl<<endl;\n\n}\n```\n\n\nI face the following problems:\n\n\nThe random number generator returns only \"-5\" as each element in the output.\nThe Matrix multiplication yield different results with brute force multiplication and using the repeated squaring algorithm.\n\n\nI'm timing the execution time of my code to compare the times taken by brute force multiplication and by repeated squaring.\n\nCould someone please find out what's wrong with the recursion and with the matrix initialization?\n\nNOTE: While compiling this program, make sure you've imported the NEWMAT library.\n\nThanks in advance!\n    ", "Answer": "\r\n```\nrand()```\n returns an int so ```\nrand()/RAND_MAX```\n will truncate to an ```\ninteger = 0```\n. Try your\nrepeated square algorithm by hand ```\nwith n = 1, 2 and 3```\n and you'll find a ```\nsurplus A *```\n\nand a gross inefficiency.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "object oriented matrix multiplication using multithreading\r\n                \r\nI am in need of designing a multi-threaded matrix multiplication using OO principles. Below is the outline of the classes i came up with.\n\n```\nclass matrix{\n\n}\n\n\nclass matrixThread implements runnable{\n\n}\n```\n\n\nthe matrix class will hold the actual matrix. In this application there needs to be 3 matrices so i have to create three of them. And i need to multiply them using 4 threads.So i create 4 matrixThread  objects and invoke the .start method with the actual matrix multiplication code inside the run method.\n\nCould someone please comment on my approach. Is there a better way of doing this ?\n    ", "Answer": "\r\nYour approach should be to copy a solution which works already. Matrix multiplication is a well understood problem and getting the best performance (which makes using multiple threads worth doing) is a bit tricky and you will save yourself some grief by just using an existing solution.  If you just try something which should work, you can find it is slower than using one thread if you do not test  carefully. (As you need to be careful as to the number of threads you create and how the caches are used)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication using vectorized c++\r\n                \r\nI'm trying to write a c++ code to do a matrix multiplication using SIMD but the result is wrong\nhere is my code \n\n```\n    void mat_sse(DATA m1[][SIZE], DATA m2[][SIZE], DATA mout[][SIZE])\n{\n\n    DATA prod = 0;\n\n    __m128 X, Y, Z, M, N;\n\n    for(int i=0; i<SIZE; i=i+1){\n    Z[0] = Z[1] = Z[2] = Z[3] = 0;\n    for(int k=0; k< SIZE; k=k+4){\n\n        for( int j=0; j<SIZE; j=j+4){\n            X = _mm_load_ps(&m1[i][k]);\n            Y = _mm_load_ps(&m2[k][j]);\n            M = _mm_mul_ps(X, Y);\n            Z = _mm_add_ps(M, N);\n            mout[i][j] += Z[0];\n        mout[i][j+1] += Z[1];\n        mout[i][j+2] += Z[2];\n        mout[i][j+3] += Z[3];\n        }\n\n    }\n\n    }\n\n    return ;\n\n}\n```\n\n\nwhere Size is \n```\nconst int SIZE = 40;```\n \n could you please  help ?\n    ", "Answer": "\r\nThere is a lot wrong with that.\n\n```\nfor(int k=0; k< SIZE; k=k+4){\n    for( int j=0; j<SIZE; j=j+4){\n```\n\n\nBoth loops advance by 4, so the body of the inner loop handles 16 steps of the old scalar loop at once. Except it doesn't, it does \"four things\".\n\nAnd they're not the right things:\n\n```\nX = _mm_load_ps(&m1[i][k]);\nY = _mm_load_ps(&m2[k][j]);\nM = _mm_mul_ps(X, Y);\n```\n\n\nSo every iteration of the inner loop takes the same tiny row vector out of ```\nm1```\n, and the next tiny row vector out of ```\nm2```\n, and then multiplies them pointwise. That doesn't work. For example, if we had two 4x4 matrixes: (shown partially)\n\n```\nA B C D   X Y Z W\nE . . .   S . . .\nI . . . × T . . .\nM . . .   U . . .\n```\n\n\nAn iteration of the inner loop would calculate AX, BY, CZ and DW. AX indeed should be in the result, but a real matrix multiplication doesn't involve BY: the rows of ```\nm1```\n are combined with the columns of ```\nm2```\n, so BY and so on where the second entry in a row of ```\nm1```\n is multiplied by the first entry in a column of ```\nm2```\n, cannot happen. There are many different ways to arrange that calculation, but the way implemented here is not a rearrangement, it computes some wrong products and it skips many necessary products.\n\nIt is convenient to load a little row from ```\nm2```\n, and broadcast a single entry from ```\nm1```\n. That way, the product is a little row in ```\nmout```\n, so it can be accumulated and written to the result without further shuffling.\n\nBy the way you sort of did that last part already,\n\n```\nmout[i][j] += Z[0];\nmout[i][j+1] += Z[1];\nmout[i][j+2] += Z[2];\nmout[i][j+3] += Z[3];\n```\n\n\n.. but having it in the loop is bad, and it only makes sense to do when the result of the product are numbers that should be summed into those locations. This load/sum/store thing was in the inner loop because the inner loop was the ```\nj```\n loop, but that can be fixed by exchanging the ```\nj```\n and ```\nk```\n loops: (not tested)\n\n```\nfor (int i = 0; i < SIZE; i++) {\n    for (int j = 0; j < SIZE; j += 4) {\n        __m128 sum = _mm_setzero_ps();\n        for (int k = 0; k < SIZE; k++) {\n            __m128 entry = _mm_set1_ps(m1[i][k]);\n            __m128 row  = _mm_load_ps(&m2[k][j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(entry, row));\n        }\n        _mm_store_ps(&mout[i][j], sum);\n    }\n}\n```\n\n\nThat code is still slow, for various reasons:\n\n\nthe loop-carried dependency through ```\naddps```\n is slower than the available throughput. Use more independent accumulators.\ntoo many loads per arithmetic operation.\nfor mid-to-large matrixes, use cache blocking. Not when ```\nsize = 40```\n though.\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Elasticsearch, how to do matrix multiplication in Elasticsearch?\r\n                \r\nI am new to Elasticsearch, and want to do the followings:\n\nI have to Index two large-scale matrices, I want to do two things:\n1)  Index these matrix using Elasticsearch;\n2)  Do a matrix multiplication on these two matrices\n\nHowever, our matrix data is saved in a 3-column format instead of the typical large matrix data format, because it was processed in Hadoop/Pig: \n(row1, col1, val11), \n(row1, col2, val12), (row1, col3, val13), ……\n\nQuesiton 1: do I have to convert the 3-column matrix data format back to the orginal big matrix format before I do the index?\n\nQuestion 2:  after the matrix data index, how to do the matrix multiplication on two matrices using Elastisearch? Any sample code? \n\nThanks!\n    ", "Answer": "\r\nI don't think Elasticsearch is supposed to do arithmetic operations, especially on matrices. However, it may be possible to use scripts for this purpose. Check these two links:\n\nhttp://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-scripting.html\n\nhttp://www.elasticsearch.org/guide/en/elasticsearch/guide/current/partial-updates.html#_using_scripts_to_make_partial_updates\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Element wise matrix multiplication in Theano\r\n                \r\nI could see element wise matrix multiplication using numpy can be done with * operator. \n\n```\nprint np.mat(np.ones((10,10)))*np.mat(np.ones((10,10)))\n```\n\n\nBut couldnt get it working under theano. The code I tried is\n\n```\nx = T.dmatrix('x')\ny = T.dmatrix('y')\nz = x * y\nf1 = theano.function([x, y], z)\n\nprint f1(np.mat(np.ones((10,10))),np.mat(np.ones((10,10))))\n```\n\n    ", "Answer": "\r\nIf I try the following (which is basically your code):\n\n```\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\n\nx = T.dmatrix('x')\ny = T.dmatrix('y')\nz = x * y\nf1 = theano.function([x, y], z)\n\nprint f1(np.mat(np.ones((10,10))),np.mat(np.ones((10,10))))\n```\n\n\nI get the following:\n\n```\n[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n```\n\n\nSo, it works for me.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "fortran library for sparse matrix multiplication\r\n                \r\nI have a large matrix which I have stored in the following format, given the matrix A;\n\nA =\n\n```\n 1   0    3\n 5   1    -2\n 0   0    7\n```\n\n\n3 vectors;\n\nNVPN = [1 3 4 7] - I arbitrarily put a 1 in the first column, then from the second onwards it is a cumulatively summing the number of non-zero elements per column.\n\nNNVI = [1 2 2 1 2 3] - row index of each non-zero element.\n\nCONT = [1 5 1 3 -2 7] - value of each non-zero element.\n\nI now need to perform matrix*matrix multiplication and matrix*vector multiplication. Does anyone know if the are any FORTRAN libraries, which I can amend to fit my problem, to do this above?\n\nThanks in advance\n    ", "Answer": "\r\nThe MATMUL function allows you to perform matrix products, which is defined in the section 13.7.70 of the FORTRAN 90 standard. See also: GCC reference.\n\n\n\nThere is already a topic on sparse matrix libraries here.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "stuck on Matrix Multiplication using pthreads\r\n                \r\nIm currently trying to finish an assignment in which you use pthreads to speed up the matrix multiplication. The  idea is to have the pthreads each work on there chunk of rows \n\nFor example: 1000 rows and 4 threads would be thread 0 : rows 0-249, thread 1: 250-499, thread 2: 500-749 and  thread 3: 750-999\n\n```\n  blocksOfWork = (BLOCK *) malloc(numberOfThreads*sizeof(BLOCK));\n\n  for(i=0; i < numberOfThreads; i++){\n    blocksOfWork[i].threadId = i;\n    blocksOfWork[i].start_row = i * rows/numberOfThreads;\n    if (i == numberOfThreads -1){\n      blocksOfWork[i].end_row = rows - 1;\n    }\n    else{\n      blocksOfWork[i].end_row = (i+1)*rows/numberOfThreads -1;\n    }\n    blocksOfWork[i].start_col = 0;\n    blocksOfWork[i].end_col = columns -1;\n  }\n```\n\n\nI'm just having a hard time understanding on how to perform the matrix multiplication iteration, I've put a print statement for debugging purpose but I still can't figure it out, ThreadMMulti Function. Any helpful tips in the right direction would be appreciated. Here is the full code\n\n```\n/*Program to generate two square 2D arrays of random doubles and\n   time their multiplication.\n   Program utlizies pthreads to efficiently perform matrix Multiplication\n   Compile by: gcc -o mmult -O3 mmultHW6.c -lpthread\n   Run by:  ./mmult 1000 1000 2\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <math.h>\n#include <pthread.h>\n\n#define TRUE 1\n#define FALSE 0\n#define BOOL int\n\ntypedef struct {\n  int threadId;\n  int start_row;\n  int end_row;\n  int start_col;\n  int end_col;\n} BLOCK;\n\n\n// function prototypes\ndouble ** allocate2DArray(int rows, int columns);\nvoid print2DArray(int rows, int columns, double ** array2D);\nvoid generateRandom2DArray(int rows, int columns,\n               double min, double max, double ** random2DArray);\nBOOL equal2DArrays(int rows, int columns, double ** array1, double ** array2,\n           double tolerance);\nvoid matrixMultiplication(int rows1, int columns1, double ** array1,\n              int rows2, int columns2, double ** array2,\n              double ** product);\nvoid matrixMultiplicationAlt(int rows1, int columns1, double ** array1,\n                 int rows2, int columns2, double ** array2,\n                 double ** product);\nvoid * threadMMult(void * rank);\n\nint numberOfThreads;\ndouble ** A;\ndouble ** B;\ndouble ** C;\ndouble ** C_alt;\n\nint rows, columns;\n\nint main(int argc, char ** argv) {\n\n\n  long i, startTime, endTime,seqTime, paralellTime;\n  BLOCK * blocksOfWork;\n  int errorCode;\n  double tolerence;\n  pthread_t * threadHandles;\n  if (argc !=3) {\n    printf(\"Usage: %s <# of rows><# of columns><# of Threads>\\n\", argv[0]);\n    exit(-1);\n  } // end if\n\n  sscanf(argv[1], \"%d\", &rows);\n  sscanf(argv[1], \"%d\", &numberOfThreads);\n  columns = rows;\n\n\n  // seed the random number generator\n  srand( time(NULL) );\n\n  A = allocate2DArray(rows, columns);\n  B = allocate2DArray(rows, columns);\n  C = allocate2DArray(rows, columns);\n  C_alt = allocate2DArray(rows, columns);\n  generateRandom2DArray(rows, columns, -1.0, +1.0, A);\n  generateRandom2DArray(rows, columns, -1.0, +1.0, B);\n\n  printf(\"after initializing matrices\\n\");\n\n  time(&startTime);\n\n  matrixMultiplicationAlt(rows, columns, A, rows, columns, B, C_alt);\n\n  time(&endTime);\n\n  seqTime = endTime-startTime;\n  printf(\"Matrix Multiplication Alt. time = %ld\\n\",seqTime);\n\n\n  time(&startTime);\n\n  threadHandles = (pthread_t *)\n  malloc(numberOfThreads*sizeof(pthread_t));\n  blocksOfWork = (BLOCK *) malloc(numberOfThreads*sizeof(BLOCK));\n\n  for(i=0; i < numberOfThreads; i++){\n    blocksOfWork[i].threadId = i;\n    blocksOfWork[i].start_row = i * rows/numberOfThreads;\n    if (i == numberOfThreads -1){\n      blocksOfWork[i].end_row = rows - 1;\n    }\n    else{\n      blocksOfWork[i].end_row = (i+1)*rows/numberOfThreads -1;\n    }\n    blocksOfWork[i].start_col = 0;\n    blocksOfWork[i].end_col = columns -1;\n  }\n  for (i=0; i < numberOfThreads; i++) {\n    if (errorCode = pthread_create(&threadHandles[i], NULL, threadMMult,\n                   &blocksOfWork[i]) != 0) {\n      printf(\"pthread %d failed to be created with error code %d\\n\", i, errorCode);\n    } // end if\n  } // end for\n\n  for (i=0; i < numberOfThreads; i++) {\n    if (errorCode = pthread_join(threadHandles[i], (void **) NULL) != 0) {\n      printf(\"pthread %d failed to be joined with error code %d\\n\", i, errorCode);\n    } // end if\n  } // end for\n\n  time(&endTime);\n  paralellTime = endTime-startTime;\n  printf(\"Parallel Matrix Multiplication time = %ld\\n\",paralellTime);\n\n\n  if (equal2DArrays(rows, columns, C, C_alt, 0.000001)) {\n    printf(\"Arrays match with tolerance of %.000001f\\n\", 0.000001);\n  } else {\n    printf(\"Arrays DON'T match with tolerance of %.000001f\\n\", 0.000001);\n  } // end if\n\n  return 0;\n\n} // end main\n\n\n\nvoid * threadMMult(void * arg){\n  BLOCK * block = (BLOCK *) arg;\n  int threadId = block->threadId;\n  int startRow = block->start_row;\n  int endRow = block->end_row;\n  int startCol = block->start_col;\n  int endCol = block->end_col;\n  int i, j, k, sum;\n\n  for (int i=startRow; i<=endRow;i++){\n    for (int j = startCol; j<=endCol; j++){\n      //C[i][j] = 0;\n      for(int k=0; k<= columns-1; k++){\n      //C[i][j] += A[i][k]*B[k][j];\n        printf(\"%lu - C[%d][%d] += A[%d][%d]*B[%d][%d]\\n\", pthread_self()\n        , i,j,i,k,k,j);\n      }\n\n    }\n  }\n\n}\n\n/*******************************************************************\n * Function matrixMultiplicationAlt passed two matrices and returns\n * their product.\n ********************************************************************/\nvoid matrixMultiplicationAlt(int rows1, int columns1, double ** array1,\n                 int rows2, int columns2, double ** array2,\n                 double ** product) {\n  int i, j, k;\n  double ** array2_transpose;\n\n  if (columns1 != rows2) {\n    printf(\"Matrices cannot be multiplied -- incompatible dimensions!\\n\");\n    exit(-1);\n  } // end if\n\n  // Transposes array2\n  array2_transpose = allocate2DArray(columns2, rows2);\n  for (i=0; i < rows2; i++) {\n    for (j=0; j < columns2; j++) {\n      array2_transpose[j][i] = array2[i][j];\n    } /* end for (j */\n  } /* end for (i */\n\n  // Matrix Multiplication uses array1 and array2_transpose\n  for (i=0; i < rows1; i++) {\n    for (j=0; j < columns2; j++) {\n      product[i][j] = 0.0;\n      for (k=0; k < columns1; k++) {\n        product[i][j] += array1[i][k]*array2_transpose[j][k];\n      } /* end for (k */\n    } /* end for (j */\n  } /* end for (i */\n\n} // end matrixMultiplicationAlt\n\n\n\n/*******************************************************************\n * Function allocate2DArray dynamically allocates a 2D array of\n * size rows x columns, and returns it.\n ********************************************************************/\ndouble ** allocate2DArray(int rows, int columns) {\n  double ** local2DArray;\n  int r;\n\n  local2DArray = (double **) malloc(sizeof(double *)*rows);\n\n  for (r=0; r < rows; r++) {\n    local2DArray[r] = (double *) malloc(sizeof(double)*columns);\n  } // end for\n\n  return local2DArray;\n} // end allocate2DArray\n\n\n/*******************************************************************\n * Function generateRandom2DArray is passed the # rows, the # columns,\n * min. value, max. value, and returns random2DArray containing\n * randomly generated doubles.\n ********************************************************************/\nvoid generateRandom2DArray(int rows, int columns,\n               double min, double max, double ** random2DArray) {\n  int r, c;\n  double range, div;\n\n  for (r = 0; r < rows; r++) {\n    for (c = 0; c < columns; c++) {\n      range = max - min;\n      div = RAND_MAX / range;\n      random2DArray[r][c] = min + (rand() / div);\n    } // end for (c...\n  } // end for (r...\n} // end generateRandom2DArray\n\n\n/*******************************************************************\n * Function print2DArray is passed the # rows, # columns, and the\n * array2D.  It prints the 2D array to the screen.\n ********************************************************************/\nvoid print2DArray(int rows, int columns, double ** array2D) {\n  int r, c;\n  for(r = 0; r < rows; r++) {\n    for (c = 0; c < columns; c++) {\n      printf(\"%10.5lf\", array2D[r][c]);\n    } // end for (c...\n    printf(\"\\n\");\n  } // end for(r...\n\n} // end print2DArray\n\n\n\n/*******************************************************************\n * Function equal2DArrays is passed the # rows, # columns, two\n * array2Ds, and tolerance.  It returns TRUE if corresponding array\n * elements are equal within the specified tolerance; otherwise it\n * returns FALSE.\n ********************************************************************/\nBOOL equal2DArrays(int rows, int columns, double ** array1, double ** array2,\n           double tolerance) {\n\n  int r, c;\n\n  for(r = 0; r < rows; r++) {\n    for (c = 0; c < columns; c++) {\n      if (fabs(array1[r][c] - array2[r][c]) > tolerance) {\n        return FALSE;\n      } // end if\n    } // end for (c...\n  } // end for(r...\n  return TRUE;\n\n} // end equal2DArray\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Java array split and matrix multiplication\r\n                \r\nCan someone help me with this, please? I'm trying to do a matrix multiplication, using threads. This is what I have so far:\n//updated\n\n```\npublic class Multiplication {\n\npublic static final int NUM_OF_THREADS = 8;\npublic static final int MATRIX_SIZE = 1000;\n\n\npublic static void main(String args[]) throws InterruptedException {\n\n    long startTime = System.currentTimeMillis();\n    int MatrixA[][] = matrixGenerator();\n    int MatrixB[][] = matrixGenerator();\n\n    int m1rows = MatrixA.length;\n\n    int m1cols = MatrixA[0].length;\n\n    int m2cols = MatrixB[0].length;\n\n    int MatrixC[][] = new int[m1rows][m2cols];\n\n    ExecutorService pool = Executors.newFixedThreadPool(NUM_OF_THREADS);\n    for (int row1 = 0; row1 < m1rows; row1++) {\n        for (int col1 = 0; col1 < m1cols; col1++) {\n            pool.submit(new MultiplicationThreading(row1, col1, MatrixA, MatrixB, MatrixC));\n        }\n    }\n    pool.shutdown();\n    pool.awaitTermination(1, TimeUnit.DAYS);\n    long endTime = System.currentTimeMillis();\n\n    System.out.println(\"Calculated in \"\n            + (endTime - startTime) + \" milliseconds\");\n\n}\n\npublic static int[][] matrixGenerator() {\n\n    int matrix[][] = new int[MATRIX_SIZE][MATRIX_SIZE];\n\n    Random r = new Random();\n    for (int i = 0; i < matrix.length; i++) {\n        for (int j = 0; j < matrix[i].length; j++) {\n            matrix[i][j] = r.nextInt(10000);\n        }\n    }\n    return matrix;\n}\n}\n```\n\n\n//I have updated the code\nI get better timings now. When using 2 threads I get 1.5k milliseconds and when I use 8 threads 1.3k milliseconds\n    ", "Answer": "\r\nYou initialize the ```\nthrd```\n array with ```\nNUM_THREADS == 9```\n elements. If ```\nm1rows*m1cols```\n exceeds that value, you will get this problem, since you attempt to create more than 9 threads and assign them to elements of the array. (You are attempting to create 50 threads).\n\nTwo solutions:\n\n\nInitialize ```\nthrd = new Thread[m1rows*m1cols]```\n\nUse a ```\nList<Thread>```\n.\n\n\n\n\nNote that you won't execute the threads in parallel, because you are calling ```\nThread.join()```\n immediately after calling ```\nThread.start()```\n. This just blocks the current thread until ```\nthrd[threadcount]```\n finishes.\n\nMove the ```\nThread.join()```\n calls into a separate loop, so the threads are all started before you call ```\njoin```\n on any of them.\n\n```\n    for (row = 0; row < m1rows; row++) {\n        for (col = 0; col < m1cols; col++) {\n            // creating thread for multiplications\n            thrd[threadcount] = new Thread(new MultiplicationThreading(row, col, MatrixA, MatrixB, MatrixC));\n            thrd[threadcount].start(); //thread start\n            threadcount++;\n        }\n    }\n    for (Thread thread : thrd) {\n      thread.join();\n    }\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication with threads and semaphore\r\n                \r\nI have to implement matrix multiplication with threads using semaphore. The problem is I don't understand how semaphore works and my result matrix is filled with zeros and program hangs. Could you explain me what I'm doing wrong?\n\nHere's my code:\n\n```\nclass Program\n{\n    private static Semaphore semaphore = new Semaphore(0, 1);\n    static void Main(string[] args)\n    {\n        int size;\n        int[,] a = null, b = null, c = null;\n        bool isNumeric;\n        do\n        {\n            Console.Write(\"Insert size: \");\n            isNumeric = int.TryParse(Console.ReadLine(), out size);\n        }\n        while (!isNumeric || size < 2);\n        Console.WriteLine();\n        SquareMatrix.Init(size, ref a);\n        SquareMatrix.Init(size, ref b);\n        SquareMatrix.Init(size, ref c);\n        SquareMatrix.Fill(a);\n        SquareMatrix.Fill(b);\n        Console.WriteLine(\"Matrix 1:\\n\");\n        SquareMatrix.Display(a);\n        Console.WriteLine(\"Matrix 2:\\n\");\n        SquareMatrix.Display(b);\n        Console.WriteLine();\n        DateTime start = DateTime.Now;\n        for (int i = 0; i < size; i++)\n        {\n            Thread thread = new Thread(() => Multiply(i, size, a, b, c));\n            thread.Name = i.ToString();\n            thread.Start();\n        }\n        DateTime stop = DateTime.Now;\n        Console.WriteLine(\"Result (\" + (stop - start).TotalMilliseconds + \" ms):\\n\");\n        SquareMatrix.Display(c);\n        Console.ReadLine();\n    }\n    public static void Multiply(int i, int size, int[,] a, int[,] b, int[,] c)\n    {\n        semaphore.WaitOne();\n        for (int j = 0; j < size; j++)\n        {\n            c[i, j] = 0;\n            for (int k = 0; k < size; k++)\n            {\n                c[i, j] += a[i, k] * b[k, j];\n            }\n        }\n        semaphore.Release();\n    }\n}\n```\n\n\nAnd SquareMatrix code:\n\n```\nstatic class SquareMatrix\n{\n    private static readonly Random random = new Random();\n    public static void Init(int size, ref int[,] array)\n    {\n        array = new int[size, size];\n    }\n    public static void Fill(int[,] array)\n    {\n        for (int i = 0; i < array.GetLength(0); i++)\n        {\n            for (int j = 0; j < array.GetLength(0); j++)\n            {\n\n                array[i, j] = random.Next(-10, 10);\n            }\n        }\n    }\n    public static void Display(int[,] array)\n    {\n        string result = \"\";\n        for (int i = 0; i < array.GetLength(0); i++)\n        {\n            for (int j = 0; j < array.GetLength(0); j++)\n                result += array[i, j] + \" \";\n            result += \"\\n\";\n        }\n        Console.Write(result + \"\\n\");\n    }\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication using multithreading in C\r\n                \r\nI am trying to implement matrix multiplication using multithreading in C.\nI am calculating the sum of each position in the new matrix and returning it to the ```\nmain```\n function using the ```\npthread_exit```\n. Why are the threads not returning correct value of ```\nsum```\n to the ```\nmain```\n function? I don't understand how to return values using ```\npthread_exit```\n and retrieve them using ```\npthread_join```\n.\nI am bad with pointers, so please help!\n\n```\nvoid * func(void * arg)\n{\n    z++;\n    printf(\"\\n %d thread created\", z);\n\n    int row = (int)arg / m;\n    int col = (int)arg % y;\n\n    sleep(10);\n\n    int sum = 0;\n    for (k = 0; k < n; k++)\n        sum += (ar1[row][k] * ar2[k][col]);\n\n    printf(\"\\n The thread has calculated sum = %d\", sum);\n    printf(\"\\n Thread is complete\");\n\n    void * retval = (void *)sum;\n    pthread_exit(retval);\n}\n\nint main()\n{\n    pthread_t tid[100];\n\n    printf(\"\\n Enter the row and column size of first matrix: \");\n    scanf(\"%d %d\", &m, &n);\n\n    printf(\"\\n Enter the elements of the first matrix: \");\n    for (i = 0; i < m; i++)\n        for (j = 0; j < n; j++)\n            scanf(\"%d\", &ar1[i][j]);\n\n    printf(\"\\n Enter the row and column size of second matrix: \");\n    scanf(\"%d %d\", &x, &y);\n\n    printf(\"\\n Enter the elements of the second matrix: \");\n    for (i = 0; i < x; i++)\n        for (j = 0; j < y; j++)\n            scanf(\"%d\", &ar2[i][j]);\n\n    printf(\"\\n---------------------------------------------------------------------\");\n\n    printf(\"\\n The First Matrix is \\n\");\n    for (i = 0; i < m; i++)\n    {\n        for (j = 0; j < n; j++)\n            printf(\"%d \", ar1[i][j]);\n\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n---------------------------------------------------------------------\");\n\n    printf(\"\\n The Second Matrix is \\n\");\n    for (i = 0; i < x; i++)\n    {\n        for (j = 0; j < y; j++)\n            printf(\"%d \", ar2[i][j]);\n\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n---------------------------------------------------------------------\");\n\n    if (n != x)\n    {\n        printf(\"\\n Multiplication is not possible\");\n        return 0;\n    }\n\n    for (i = 0; i < (m * y); i++)\n    {\n        pthread_create(&tid[i], NULL, func, (void *)i);\n        sleep(1);\n    }\n\n    for (i = 0; i < (m * y); i++)\n    {\n        void ** retval;\n        pthread_join(tid[i], retval);\n\n        int sum = (int)retval;\n        printf(\"%d\", sum);\n    }\n\n    printf(\"\\n---------------------------------------------------------------------\");\n\n    printf(\"\\n The Third Matrix is \\n\");\n    for (i = 0; i < m; i++)\n    {\n        for (j = 0; j < y; j++)\n            printf(\"%d \", ar3[i][j]);\n\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n---------------------------------------------------------------------\");\n\n    return 0;\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "how to implement matrix multiplication in C?\r\n                \r\nI was trying to create an algorithm to perform matrix multiplication.\nI've designed matrix as follows:\n```\n// matrix.h  \n #pragma once  \n    #include <stdlib.h>\n    #include <string.h>\n    struct matrix {\n        size_t rows, cols;\n        double* data;\n    };\n    extern struct matrix* mat_mul(const struct matrix* m1, const struct matrix* m2);\n\n// matrix.c \n#include \"matrix.h\"\n\nvoid mat_constr(struct matrix* m, size_t rows, size_t cols) {\n    m->rows = rows; m->cols = cols; \n    m->data = calloc(rows * cols, sizeof(double)); \n    if (!m->data) {\n        return; \n    }\n}\n\nvoid mat_destr(struct matrix* m) {\n    free(m->data); \n}\n```\n\nmat_constr is matrix constructor, and mat_destr is mat_destructor. To test the algorithm I've used this main\n```\n // main\n int main(void) {\n        struct matrix A; \n        mat_constr(&A, 2, 3); \n        memcpy(A.data, (double[6]) { 1, 2, 3, 4, 5, 6 }, 6 * sizeof(double)); \n        struct matrix B; \n        mat_constr(&B, 3, 2); \n        memcpy(B.data, (double[6]) { 7, 8, 9, 10, 11, 12 }, 6 * sizeof(double)); \n        struct matrix* C = mat_mul(&A, &B); \n        mat_destr(&A); mat_destr(&B); \n        mat_destr(C); \n        return 0; \n    }\n```\n\nand this is the mat_mul function\n```\nstruct matrix* mat_mul(const struct matrix* m1, const struct matrix* m2) {\n    if ((m1 == NULL) || (m2 == NULL)) {\n        return NULL; \n    }\n    if (m1->cols != m2->rows) {\n        return NULL; \n    }\n    struct matrix* result = malloc(sizeof(struct matrix)); \n    if (!result) {\n        return NULL; \n    }\n    mat_constr(result, m1->rows, m2->cols); \n\n    \n    size_t k = 1; \n    for (size_t r = 0; r < m1->rows; r++) {\n        for (size_t c = 0; c < m1->cols; c++) {\n            result->data[r * result->cols + c] = m1->data[r * m1->cols + k] * m2->data[k * m2->cols + c]; \n        }\n        k++; \n        }\n    return result; \n}\n```\n\nin order to perform matrix multiplication, I have to use this sum: sum from k = 1 to m1->cols of a_i k-th column * a_j k-th row (in this forum I don't know how to write using mathjax, because symbols like this $$ $$ doesn't work here).\nthis is the minimal reproducible example:\n```\n// matrix.h\n    #pragma once  \n    #include <stdlib.h>\n    #include <string.h>\n    struct matrix {\n        size_t rows, cols;\n        double* data;\n    };\n    extern struct matrix* mat_mul(const struct matrix* m1, const struct matrix* m2);\n\n\n// matrix.c  \n    #include \"matrix.h\"\n    \n    void mat_constr(struct matrix* m, size_t rows, size_t cols) {\n        m->rows = rows; m->cols = cols; \n        m->data = calloc(rows * cols, sizeof(double)); \n        if (!m->data) {\n            return; \n        }\n    }\n    \n    void mat_destr(struct matrix* m) {\n        free(m->data); \n    }\n    \n    struct matrix* mat_mul(const struct matrix* m1, const struct matrix* m2) {\n        if ((m1 == NULL) || (m2 == NULL)) {\n            return NULL; \n        }\n        if (m1->cols != m2->rows) {\n            return NULL; \n        }\n        struct matrix* result = malloc(sizeof(struct matrix)); \n        if (!result) {\n            return NULL; \n        }\n        mat_constr(result, m1->rows, m2->cols); \n    \n        \n        size_t k = 1; \n        for (size_t r = 0; r < m1->rows; r++) {\n            for (size_t c = 0; c < m1->cols; c++) {\n                result->data[r * result->cols + c] = m1->data[r * m1->cols + k] * m2->data[k * m2->cols + c]; \n            }\n            k++; \n            }\n            \n    \n    \n    \n        return result; \n    \n    }\n    \n    \n    \n    \n    int main(void) {\n        struct matrix A; \n        mat_constr(&A, 2, 3); \n        memcpy(A.data, (double[6]) { 1, 2, 3, 4, 5, 6 }, 6 * sizeof(double)); \n        struct matrix B; \n        mat_constr(&B, 3, 2); \n        memcpy(B.data, (double[6]) { 7, 8, 9, 10, 11, 12 }, 6 * sizeof(double)); \n        struct matrix* C = mat_mul(&A, &B); \n        mat_destr(&A); mat_destr(&B); \n        mat_destr(C); \n        return 0; \n    }\n```\n\nthis solution allocates enough memory, and return the pointer of the new allocated matrix correctly. But the problem is in the last for-loops. According to my linear algebra knowledge, I have to scroll columns by columns the first matrix, and scroll rows by rows the second matrix. But these for-loops are not correct.\nI have only one question: \"why is this method of computing matrix multiplication wrong? how can I solve it?\"\nnote that r * cols + c gives exactly the index of the i-th entry of the matrix.\n    ", "Answer": "\r\nYou are simply missing a nested for loop and a ```\n+=```\n; The correct code for multiplying your 2 matrices would be something like:\n```\nfor (size_t r = 0; r < m1->rows; ++r)\n    for (size_t c = 0; c < m2->cols; ++c)\n        for (size_t k = 0; k < m2->rows; ++k)\n            result->data[r * result->cols + c] += m1->data[r * m1->cols + k] * m2->data[k * m2->cols + c]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication in C++\r\n                \r\nI have a number of ```\n3x3```\n matricess that I want to multiply together For example:\n\n```\nm1*m2*m3*m4*m5\n```\n\n\nAlthough MTL is a recommended way, I don't have this library and can't use it. \n\nCan someone please suggest a conventional way to multiply these ```\n3x3```\n matrices (all matrices m1 to m5). Code snippet (for matrix multiplication and multiplying n matrices together) or pointer to some online code will be very useful \n    ", "Answer": "\r\nHere is a package of very useful math routines including 3x3 matrix multiplication. The C++ template classes are implemented as header files that can be simply dropped into a project. The overloaded operators make code using this package look very clean. You can preview the implementation of the 3D vector template class online.\n\nHere is a list of all the files in the archive, with those specific for 3x3 matrix multiplication highlighted in bold:\n\n\nAssert.c\nAssert.h\nintersect.cpp\nintersect.h\nline2.h\nLine3.h\nmain.cpp\nMath.dsp\nMath.dsw\nMatrix2.h\nMatrix3.h\nmatrix4.h\nMatrixN.h\nplane.h\nquaternion.h\nrandom.h\nRect.h\nSpline.cpp\nSpline.h\nUtility.h\nvector2.h\nvector3.h\nvector4.h\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "how to implement matrix multiplication in C?\r\n                \r\nI was trying to create an algorithm to perform matrix multiplication.\nI've designed matrix as follows:\n```\n// matrix.h  \n #pragma once  \n    #include <stdlib.h>\n    #include <string.h>\n    struct matrix {\n        size_t rows, cols;\n        double* data;\n    };\n    extern struct matrix* mat_mul(const struct matrix* m1, const struct matrix* m2);\n\n// matrix.c \n#include \"matrix.h\"\n\nvoid mat_constr(struct matrix* m, size_t rows, size_t cols) {\n    m->rows = rows; m->cols = cols; \n    m->data = calloc(rows * cols, sizeof(double)); \n    if (!m->data) {\n        return; \n    }\n}\n\nvoid mat_destr(struct matrix* m) {\n    free(m->data); \n}\n```\n\nmat_constr is matrix constructor, and mat_destr is mat_destructor. To test the algorithm I've used this main\n```\n // main\n int main(void) {\n        struct matrix A; \n        mat_constr(&A, 2, 3); \n        memcpy(A.data, (double[6]) { 1, 2, 3, 4, 5, 6 }, 6 * sizeof(double)); \n        struct matrix B; \n        mat_constr(&B, 3, 2); \n        memcpy(B.data, (double[6]) { 7, 8, 9, 10, 11, 12 }, 6 * sizeof(double)); \n        struct matrix* C = mat_mul(&A, &B); \n        mat_destr(&A); mat_destr(&B); \n        mat_destr(C); \n        return 0; \n    }\n```\n\nand this is the mat_mul function\n```\nstruct matrix* mat_mul(const struct matrix* m1, const struct matrix* m2) {\n    if ((m1 == NULL) || (m2 == NULL)) {\n        return NULL; \n    }\n    if (m1->cols != m2->rows) {\n        return NULL; \n    }\n    struct matrix* result = malloc(sizeof(struct matrix)); \n    if (!result) {\n        return NULL; \n    }\n    mat_constr(result, m1->rows, m2->cols); \n\n    \n    size_t k = 1; \n    for (size_t r = 0; r < m1->rows; r++) {\n        for (size_t c = 0; c < m1->cols; c++) {\n            result->data[r * result->cols + c] = m1->data[r * m1->cols + k] * m2->data[k * m2->cols + c]; \n        }\n        k++; \n        }\n    return result; \n}\n```\n\nin order to perform matrix multiplication, I have to use this sum: sum from k = 1 to m1->cols of a_i k-th column * a_j k-th row (in this forum I don't know how to write using mathjax, because symbols like this $$ $$ doesn't work here).\nthis is the minimal reproducible example:\n```\n// matrix.h\n    #pragma once  \n    #include <stdlib.h>\n    #include <string.h>\n    struct matrix {\n        size_t rows, cols;\n        double* data;\n    };\n    extern struct matrix* mat_mul(const struct matrix* m1, const struct matrix* m2);\n\n\n// matrix.c  \n    #include \"matrix.h\"\n    \n    void mat_constr(struct matrix* m, size_t rows, size_t cols) {\n        m->rows = rows; m->cols = cols; \n        m->data = calloc(rows * cols, sizeof(double)); \n        if (!m->data) {\n            return; \n        }\n    }\n    \n    void mat_destr(struct matrix* m) {\n        free(m->data); \n    }\n    \n    struct matrix* mat_mul(const struct matrix* m1, const struct matrix* m2) {\n        if ((m1 == NULL) || (m2 == NULL)) {\n            return NULL; \n        }\n        if (m1->cols != m2->rows) {\n            return NULL; \n        }\n        struct matrix* result = malloc(sizeof(struct matrix)); \n        if (!result) {\n            return NULL; \n        }\n        mat_constr(result, m1->rows, m2->cols); \n    \n        \n        size_t k = 1; \n        for (size_t r = 0; r < m1->rows; r++) {\n            for (size_t c = 0; c < m1->cols; c++) {\n                result->data[r * result->cols + c] = m1->data[r * m1->cols + k] * m2->data[k * m2->cols + c]; \n            }\n            k++; \n            }\n            \n    \n    \n    \n        return result; \n    \n    }\n    \n    \n    \n    \n    int main(void) {\n        struct matrix A; \n        mat_constr(&A, 2, 3); \n        memcpy(A.data, (double[6]) { 1, 2, 3, 4, 5, 6 }, 6 * sizeof(double)); \n        struct matrix B; \n        mat_constr(&B, 3, 2); \n        memcpy(B.data, (double[6]) { 7, 8, 9, 10, 11, 12 }, 6 * sizeof(double)); \n        struct matrix* C = mat_mul(&A, &B); \n        mat_destr(&A); mat_destr(&B); \n        mat_destr(C); \n        return 0; \n    }\n```\n\nthis solution allocates enough memory, and return the pointer of the new allocated matrix correctly. But the problem is in the last for-loops. According to my linear algebra knowledge, I have to scroll columns by columns the first matrix, and scroll rows by rows the second matrix. But these for-loops are not correct.\nI have only one question: \"why is this method of computing matrix multiplication wrong? how can I solve it?\"\nnote that r * cols + c gives exactly the index of the i-th entry of the matrix.\n    ", "Answer": "\r\nYou are simply missing a nested for loop and a ```\n+=```\n; The correct code for multiplying your 2 matrices would be something like:\n```\nfor (size_t r = 0; r < m1->rows; ++r)\n    for (size_t c = 0; c < m2->cols; ++c)\n        for (size_t k = 0; k < m2->rows; ++k)\n            result->data[r * result->cols + c] += m1->data[r * m1->cols + k] * m2->data[k * m2->cols + c]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication implement in JavaScript\r\n                \r\nI implement simple matrix multiplication in javascript by for\n\n```\nvar multipliction = function(matrixA,matrixB){\n    var result = [];\n    for (var i = 0;i < matrixA.length;i++){\n        result.push(new Array());\n        for (var j = 0;j < matrixB.length;j++)\n                result[i].push(0);\n    }\n\n    for (var i = 0;i < matrixA.length;i++)\n        for (var j = 0;j < matrixA[i].length ;j++)\n            for(var k = 0;k < matrixB[j].length;k++)\n                result[i][j] += matrixA[i][k] * matrixB[k][j];\n    return result;\n};\n```\n\n\nbut I think it runs async ,so if some part takes long to execute,it will jump to next and result is't trusted, what's the way to be sure that above code run synchronously ?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Can Strassen algorithm be used for Boolean matrix multiplication?\r\n                \r\nI am wondering if Strassen's algorithm can be used for Boolean matrix multiplication? I know that it is used for regular matrix multiplication but not too sure about Boolean.\n\nAlso, if it can be, is it faster asymptotically than using Four Russians method and which should be used for Boolean multiplication in general? \n    ", "Answer": "\r\nYes, Strassen can be used for Boolean matrix multiplication. You just do the multiplication in integers and then convert >0 entries of the result to 1.\n\nYes, Strassen is asymptotically faster than Four Russians. Up to log factors, Four Russians is still Õ(n^3), whereas Strassen is Õ(n^log2(7)).\n\nSince big-O constants and log factors matter in practice, though, you should probably use Four Russians.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Unexpected result of matrix multiplication in R\r\n                \r\nR program does not return the expected matrix multiplication\n\n```\n    a<- c(0,1,1,0)\n    A<- matrix(a,2,2)\n    B<- matrix(c(1,2,3,4),2,2,byrow=TRUE)\n    A*B\n```\n\n\ngives final answer as ```\nmatrix(c(0,2,3,0), ncol = 2, byrow=TRUE)```\n:\n\n```\n     [,1] [,2]\n[1,]    0    2\n[2,]    3    0\n```\n\n\nbut the actual answer should be ```\nmatrix(c(3,4,1,2), ncol = 2, byrow=TRUE)```\n\n\n```\n     [,1] [,2]\n[1,]    3    4\n[2,]    1    2\n```\n\n    ", "Answer": "\r\nYou can use either ```\n%*%```\n or ```\ncrossprod```\n for matrix multiplication\n\n```\n> A %*% B\n     [,1] [,2]\n[1,]    3    4\n[2,]    1    2\n\n> crossprod(A, B)\n     [,1] [,2]\n[1,]    3    4\n[2,]    1    2 \n```\n\n\nNote that the result is a 2x2 matrix, if you want a vector as in your example, then use ```\nmatrix(crossprod(A, B), ncol=1)```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in python and mysql\r\n                \r\nI have a currency exchange dictionary, as follows:\n\n```\nexchange_rates = {'USD': 1.00000,\n                  'EUR': 1.32875,\n                  'GBP': 1.56718, ...}\n```\n\n\nThen I retrieve the sales information for a product, using:\n\n```\nSELECT price, currency FROM sales\n```\n\n\nThere are perhaps a million rows, which may look like this:\n\n```\n- 2.99    USD\n- 3.01    EUR\n- etc.\n```\n\n\nHow would I do matrix multiplication to get the total sum in USD?\n    ", "Answer": "\r\nInstead of getting one million rows from the database and doing the calculation in Python, give your dictionary to the database and get the database to do the calculation and send you back the result.\n\nYou can do this by making a query similar to the following:\n\n```\nSELECT SUM(price * exchange_rate) AS total\nFROM sales\nLEFT JOIN\n(\n    SELECT 'USD' AS currency, 1.00000 AS exchange_rate\n    UNION ALL\n    SELECT 'EUR', 1.32875\n    UNION ALL\n    SELECT 'GBP', 1.56718\n    -- ...\n) AS exchange\nON exchange.currency = sales.currency\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Is sum or matrix multiplication faster?\r\n                \r\nI have a very simple question, is using ```\nsum```\n or matrix multiplication faster to sum a large vector? More precisely, here an example of problem I am trying to speed up:\n\n```\nd <- 1000\nX <- matrix(rnorm(d^2), nrow = d)\ny <- rnorm(d)\n\n## Solution 1\nsum(X%*%y)\n## Solution 2\nrep(1, d)%*%(X%*%y)\n```\n\n\nI have tried testing the two with ```\nsystem.time()```\n, but the times jump around each other and I can't get a fix on it. The times are very similar so this question has passed from practical to just inquisitive. Perhaps they are exactly the same time (seems unlikely).\n\nHere's the function I've written to test it:\n\n```\ntestSum <- function(d, its){\n  X <- matrix(rnorm(d^2), nrow=d)\n  y <- rnorm(d)\n\n  store <- matrix(NA, nrow = its, ncol = 3)\n  store2 <- matrix(NA, nrow = its, ncol = 3)\n\n  for(i in 1:its) store[i, ] <- system.time(sum(X%*%y))[1:3]\n  for(i in 1:its) store2[i, ] <- system.time(rep(1, d)%*%(X%*%y))[1:3]\n\n  return(list(sumF = mean(store[, 1]),\n              MM = mean(store2[, 1])))\n}\n\ntestSum(1000, 100)\n```\n\n\nAnd the output always looks something like this:\n\n```\n$sumF\n[1] 0.01021\n\n$MM\n[1] 0.01028\n```\n\n\nWhere the top is using sum and the bottom is using matrix multiplication. Any hints, suggestions are welcome! Thanks!\n    ", "Answer": "\r\nYou might be interested in the ```\nmicrobenchmark```\n package, an easy way to time small functions a lot of times:\n\n```\nmicrobenchmark::microbenchmark(sum(X%*%y),rep(1, d)%*%(X%*%y))\n```\n\n\ngives me:\n\n```\nUnit: milliseconds\n                    expr      min       lq     mean   median       uq      max neval\n            sum(X %*% y) 10.01472 10.52420 14.25944 11.11969 13.67134 74.26345   100\n rep(1, d) %*% (X %*% y) 10.13382 10.55444 12.99910 10.87629 12.95769 50.38268   100\n```\n\n\nSo on my (slow) laptop, they are more or less the same.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication vs equations for image transformations in MATLAB\r\n                \r\nI am trying to write some code to rotate an image in MATLAB, that is, equivalent to imrotate. I use matrix multiplication to perform an inverse mapping of the new image to the input image. However, it takes a lot longer than explicitly writing out the equivalent equation. Is there a better way to perform this multiplication?\n\nI would prefer to use matrix multiplication, because I could use the same code for other transformations by replacing the transformation matrix, ```\nRT```\n.\n\n```\nim1 = imread('file.jpg');\n[h, w, p] = size(im1);\ntheta = -pi/6;\nhh = round( h*cos(theta) + w*abs(sin(theta)));\nww = round( w*cos(theta) + h*abs(sin(theta)));\n\nR = [cos(theta) -sin(theta); sin(theta) cos(theta)];\nT = [w/2; h/2];\nRT = [inv(R) T; 0 0 1];\nfor z = 1:p\n    for x = 1:ww\n        for y = 1:hh\n            % Using matrix multiplication\n            i = zeros(3,1);\n            i = RT*[x-ww/2; y-hh/2; 1];\n\n            %Using explicit equations\n            %i(1) = ( (x-ww/2)*cos(theta)+(y-hh/2)*sin(theta)+w/2);\n            %i(2) = (-(x-ww/2)*sin(theta)+(y-hh/2)*cos(theta)+h/2);\n\n            %% Nearest Neighbour\n            i = round(i);\n            if i(1)>0 && i(2)>0 && i(1)<=w && i(2)<=h\n                im2(y,x,z) = im1(i(2),i(1),z);\n            end\n        end\n    end\nend\n\n%Revised code\nim1 = imread('file.jpg');\n[h, w, p] = size(im1);\ntheta = (pi)/3;\nhh = round(h*abs(cos(theta)) + w*abs(sin(theta)));\nww = round(w*abs(cos(theta)) + h*abs(sin(theta)));\nim2 = zeros([hh,ww,p], class(im1));\n\nR = [cos(theta) -sin(theta); sin(theta) cos(theta)];\nT = [w/2; h/2];\nRT = [inv(R) T; 0 0 1];\n\nx=1:ww;\ny=1:hh;\n\n[X, Y] = meshgrid(x,y);\norig_pos = [X(:)' ; Y(:)' ; ones(1,numel(X))];\norig_pos_2 = [X(:)'-(ww/2) ; Y(:)'-(hh/2) ; ones(1,numel(X))];\n\nnew_pos = round(RT*orig_pos_2); % Round to nearest neighbour\n\n% Check if new positions fall from map:\nvalid_pos = new_pos(1,:)>=1 & new_pos(1,:)<=w & new_pos(2,:)>=1 & new_pos(2,:)<=h;\n\norig_pos = orig_pos(:,valid_pos);\nnew_pos = new_pos(:,valid_pos);\n\nsiz = size(im1);\nsiz2 = size(im2);\n\n% Expand the 2D indices to include the third dimension.\nind_orig_pos = sub2ind(siz2,orig_pos(2*ones(p,1),:),orig_pos(ones(p,1),:), (1:p)'*ones(1,length(orig_pos)));\nind_new_pos  = sub2ind(siz, new_pos(2*ones(p,1),:), new_pos(ones(p,1),:), (1:p)'*ones(1,length(new_pos)));\n\nim2(ind_orig_pos) = im1(ind_new_pos);\nimshow(im2);\n```\n\n    ", "Answer": "\r\nYou should vectorize the for loops, it doesn't seem that hard. It'll gain you a lot. Trickiest is the position calculation and ignoring positions that fall off the image after rotation.\n\nSolution:\n\n```\nx=1:ww\ny=1:hh\n\n[X, Y] = meshgrid(x,y);\norig_pos = [X(:)' ; Y(:)' ; ones(1,numel(X))];\n\nnew_pos = round(RT*orig_pos); % round to nearest neighbour\n\n% check if new positions fall from map:\nvalid_pos = new_pos(1,:)>=1 & new_pos(1,:)<=w & new_pos(2,:)>=1 & new_pos(2,:)<=h;\n```\n\n\nYou can do the assignment to the resulting matrix in a for loop to deal with positions to ignore, or just remove them from the source matrix and do the assignment in one blow:\n\n```\norig_pos = orig_pos(:,valid_pos);\nnew_pos = new_pos(:,valid_pos);\n\nsiz = size(im1);\nim2 = zeros(siz,class(im1));\n\n% expand the 2d indices to include the third dimension\nind_orig_pos = sub2ind(siz,orig_pos(2*ones(siz(3),1),:),orig_pos(ones(siz(3),1),:), (1:siz(3))'*ones(1,N));\nind_new_pos  = sub2ind(siz, new_pos(2*ones(siz(3),1),:), new_pos(ones(siz(3),1),:), (1:siz(3))'*ones(1,N));\n\nim2(ind_orig_pos) = im1(ind_new_pos);\n```\n\n\nYour code is probably also slow, because you don't initialize ```\nim2```\n so it is expanded in runtime as needed.\n\nAs reference: using 'peppers.png' as source image, this whole block of code took 0.12s on my pc, your code took several minutes.. end result was the same.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matlab: equivalent of R's matrix multiplication (A %*% B)? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs details or clarity. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Add details and clarify the problem by editing this post.\r\n                \r\n                    \r\n                        Closed 6 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nWorking in Matlab with time-homogenous Markov Chains and looking to figure out how I can perform matrix multiplication in Matlab for matrix A, similar to R's matrix multiplication, i.e., ```\nA %*% A```\n.  It would be even better if I could perform ```\nA^n```\n instead for a given n instead of having to use ```\nA %*% A %*% A```\n, when ```\nn = 3```\n, for example.\n\nAny help is greatly appreciated!\n    ", "Answer": "\r\nFirst of all you can raise a Matrix to a power in MATLAB:\n\n```\nA ^ n = A * A * A * ... * A```\n\n\nActually MATLAB uses pretty sophisticated algorithms behind the scene to accelerate this.\nFor example, if the Matrix is diagonalizable, MATLAB will use that to accelerate the calumniation.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "What is the Logic behind this matrix multiplication?\r\n                \r\nI am trying to multiply these 1 dimensional matrices( or vectors) with each other as follows :\n\n```\na = np.array([1,2,3]).reshape(1,3)\n\nb = np.array([4,5,6]).reshape(1,3)\n\nc = np.dot(a,b)\n```\n\n\n```\nprint(c)```\n outputs ab error as 'shapes (1,3) and (1,3) not aligned' which are correct as per the matrix multiplication laws.\n\nBut when I do ```\nc = a*b```\n and ```\nprint(c)```\n I get a 1 x 3 matrix - ```\narray([[ 4, 10, 18]])```\n.\n\nmy question is how 1 X 3 * 1 X 3 matrix multiplication is yielding a 1 X 3 matrix ? Columns of first matrix should equal the rows of second. Isn't it?\n\nMoreover, it would be great if any of you can shed some more info on how a  dot product of 2 matrices of shapes(i,j) differs from its multiplication ```\na*b```\n?\n    ", "Answer": "\r\nThe ```\ndot```\n method performs a matrix multiplication like you'd expect. The ```\n*```\n operator takes two matrices of the same dimensions and multiplies their corresponding elements, thus producing a result of the same dimensions.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Can't do matrix multiplication with tensorflow\r\n                \r\nIn Tensorflow, I would like to do matrix multiplication using this code:\n\n```\n_X = np.array([[1, 2, 3], [4, 5, 6]])\n_Y = np.array([[1, 1], [2, 2], [3, 3]])\nX = tf.convert_to_tensor(_X)\nY = tf.convert_to_tensor(_Y)\n\nres = tf.matmul(X, Y)\n```\n\n\nHowever, I am getting this error:\n\n```\nTypeError                                 Traceback (most recent call last)\n<ipython-input-29-37c04c70cff8> in <module>()\n      4 Y = tf.convert_to_tensor(_Y)\n      5 \n----> 6 res = tf.matmul(X, Y)\n\n/Downloads/tensorflow-exercises-master/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\n   1799     else:\n   1800       return gen_math_ops._mat_mul(\n-> 1801           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n   1802 \n   1803 \n\n/Downloads/tensorflow-exercises-master/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py in _mat_mul(a, b, transpose_a, transpose_b, name)\n   1261   \"\"\"\n   1262   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n-> 1263                                 transpose_b=transpose_b, name=name)\n   1264   return result\n   1265 \n\n/Downloads/tensorflow-exercises-master/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py in apply_op(self, op_type_name, name, **keywords)\n    588               _SatisfiesTypeConstraint(base_type,\n    589                                        _Attr(op_def, input_arg.type_attr),\n--> 590                                        param_name=input_name)\n    591             attrs[input_arg.type_attr] = attr_value\n    592             inferred_from[input_arg.type_attr] = input_name\n\n/Downloads/tensorflow-exercises-master/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py in _SatisfiesTypeConstraint(dtype, attr_def, param_name)\n     59           \"allowed values: %s\" %\n     60           (param_name, dtypes.as_dtype(dtype).name,\n---> 61            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n     62 \n     63 \n\nTypeError: Value passed to parameter 'a' has DataType int64 not in list of allowed values: float16, float32, float64, int32, complex64, complex128\n```\n\n\nAny idea what could be wrong with the code?\n    ", "Answer": "\r\nHere is the docs for ```\ntf.matmul```\n:\n\n\n  Both matrices must be of the same type. The supported types are:\n  ```\nfloat16```\n, ```\nfloat32```\n, ```\nfloat64```\n, ```\nint32```\n, ```\ncomplex64```\n, ```\ncomplex128```\n.\n\n\nChanging the data type to one of the supported eliminates the error.\n\n```\n_X = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int32)\n_Y = np.array([[1, 1], [2, 2], [3, 3]], dtype=np.int32)\nX = tf.convert_to_tensor(_X)\nY = tf.convert_to_tensor(_Y)\n\nres = tf.matmul(X, Y)\n\nsess = tf.Session()\nres.eval(session=sess)\n#array([[14, 14],\n#       [32, 32]], dtype=int32)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Fast sparse matrix multiplication\r\n                \r\nfor class I have to write my own linear equation solver for sparse matrices.\nI am free to use any type of data structure for sparse matrices and I have to implement several solves, including conjuguate gradient.\n\nI was wondering if there is a famous way to store sparse matrices such that multiplication with a vector is relatively fast.\n\nRight now my sparse matrices are basically implemented a wrapped ```\nstd::map< std::pair<int, int>, double>```\n which stores the data, if any. This transforms the multiplication of a matrix with from vector to a O(n²) complexity to a O(n²log(n)) as I have to perform look-up for each matrix elements.\nI've looked into the Yale Sparse matrix format and it seems that retrieval of an element is also in O(log(n)) so I'm not sure if it would be much faster.\n\nFor reference I have a 800x800 matrix that is populated with 5000 entries. It takes roughly to 450 seconds solve such a system with the conjugate gradient method.\n\nDo you think it's possible to do it much quicker with another data structure?\n\nthanks!\n    ", "Answer": "\r\nThe most common choices are CSC or CSR storage. These are both efficient for matrix-vector multiplication. It's also very easy to code those multiplication routines, if you have to do it yourself. \n\nThat said, Yale storage also yields very efficient matrix-vector multiply. If you are performing matrix element lookup, then you have misunderstood how to use the format. I suggest you study some of the standard sparse libraries to learn how matrix-vector multiplication is implemented.\n\nEven with your current storage you can perform matrix multiplication in O(n) complexity. All sparse matrix-vector multiplication algorithms that I have ever seen boil down to the same steps. For example consider y = Ax.\n\n\nZeroise the result vector, y.\nInitialise an iterator for the non-zero elements of the matrix, A.\nGet the next non-zero element of the matrix, A[i,j] say. Note that the pattern of i,j doesn't follow a regular pattern. It simply reflects the order in which the non-zero elements of A are stored.\ny[i] += A[i,j]*x[j]\nIf there are more elements of A, goto 3.\n\n\nI suspect you are writing the classic double for loop dense multiplication code:\n\n```\nfor (i=0; i<N; i++)\n    for (j=0; j<N; j++)\n        y[i] += A[i,j]*x[j]\n```\n\n\nand that's what is leading you to perform lookups. \n\nBut I'm not suggesting that you stick with your ```\nstd::map```\n storage. That's not going to be super efficient. I'd recommend CSC mainly because it is the most widely used.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Performing Matrix Multiplication After Transposing One Matrix/Vector\r\n                \r\nI'm attempting to complete code for backpropagation, and the final step that I have is computing the change in weights and biases (using a quadrati cost). This step involves performing a matrix multiplication on two arrays after transposing one.\n\n```\n# necessary functions for this example\ndef sigmoid(z):\n    return 1.0/(1.0+np.exp(-z))\n\ndef prime(z):\n    return sigmoid(z) * (1-sigmoid(z))\n\ndef cost_derivative(output_activations, y):\n    return (output_activations-y)\n\n# Mock weight and bias matrices\nweights = [np.array([[ 1, 0, 2], \n                     [2, -1, 0], \n                     [4, -1, 0], \n                     [1, 3, -2],\n                     [0, 0, -1]]), \n           np.array([[2, 0, -1, -1, 2],\n                     [0, 2, -1, -1, 0]])]\n\nbiases = [np.array([-1, 2, 0, 0, 4]), np.array([-2, 1])]\n\n# The mock training example\nq = [(np.array([1, -2, 3]), np.array([0, 1])), \n     (np.array([2, -3, 5]), np.array([1, 0])),\n     (np.array([3, 6, -1]), np.array([1, 0])),\n     (np.array([4, -1, -1]), np.array([0, 0]))]\n\nnabla_b = [np.zeros(b.shape) for b in biases]\nnabla_w = [np.zeros(w.shape) for w in weights]\n\nfor x, y in q:\n        activation = x\n        activations = [x]\n        zs = []\n        for w, b in zip(weights, biases): \n            z = np.dot(w, activation) + b\n            zs.append(z)\n            activation = sigmoid(z)\n            activations.append(activation)\n\n    # Computation of last layer\n    delta = cost_derivative(activations[-1], y) * prime(zs[-1])\n    nabla_b[-1] = delta\n    nabla_w[-1] = np.dot(np.transpose(activations[-2]), delta) + biases\n```\n\n\nI've printed the outputs for ```\ndelta```\n and the first instance gives ```\n[ 0.14541528 -0.14808645]```\n which is a 1x2 matrix and \n\n```\nactivations[-2] = [9.97527377e-01   9.97527377e-01   9.97527377e-01   1.67014218e-05   7.31058579e-01]\n```\n\n\nwhich is a 1x5 matrix. Now transposing ```\nactivations[-2]```\n should give a 1x5 and the resulting multiplication should yield a 5x2 matrix but doesn't\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Higher order matrix multiplication\r\n                \r\nI am trying to do matrix multiplication in C using multiple processes with each of the child process is computing one row of the matrix . But if it is of order of say 200 then there will be 200 processes which would be inefficient for 2 3 CPUs. If I want to keep number of processes to 10 or 12 , how can I proceed with the same . Will there be any change in computation order ?\n    ", "Answer": "\r\nOne way to exploit multiple processes in matrix multiplication is to start with a recursive algorithm. For example, the Strassen algorithm recursively breaks the problem down into smaller and smaller multiplications which can be offloaded to any number of processors. In addition, normal matrix multiplication is of order O(N^3), but the Strassen algorithm can bring this down to O(N^2.8) which can be substantial for larger matrices.\n\nNote: Usually higher-order refers to extended terms in a series expansion, more terms in a polynomial, etc. and typically not the size of a square matrix. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Parallel Matrix Multiplication in Java 6\r\n                \r\nYesterday I asked a question about parallel matrix multiplication in Java 7 using the fork/join framework here. With the help of axtavt I got my example program to work. Now I’m implementing an equivalent program using Java 6 functionality only. I get the same problem as yesterday, dispite applying the the feedback axtavt gave me (I think). Am I overlooking something?\nCode:\n\n```\npackage algorithms;\n\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.TimeUnit;\n\npublic class Java6MatrixMultiply implements Algorithm {\n\n    private static final int SIZE = 1024;\n    private static final int THRESHOLD = 64;\n    private static final int MAX_THREADS = Runtime.getRuntime().availableProcessors();\n\n    private final ExecutorService executor = Executors.newFixedThreadPool(MAX_THREADS);\n\n    private float[][] a = new float[SIZE][SIZE];\n    private float[][] b = new float[SIZE][SIZE];\n    private float[][] c = new float[SIZE][SIZE];\n\n    @Override\n    public void initialize() {\n        init(a, b, SIZE);\n    }\n\n    @Override\n    public void execute() {\n        MatrixMultiplyTask task =  new MatrixMultiplyTask(a, 0, 0, b, 0, 0, c, 0, 0, SIZE);\n        task.split();\n\n        executor.shutdown();    \n        try {\n            executor.awaitTermination(Integer.MAX_VALUE, TimeUnit.DAYS);\n        } catch (InterruptedException e) {\n            System.out.println(\"Error: \" + e.getMessage());\n        }\n    }\n\n    @Override\n    public void printResult() {\n        check(c, SIZE);\n\n        for (int i = 0; i < SIZE && i <= 10; i++) {\n            for (int j = 0; j < SIZE && j <= 10; j++) {         \n                if(j == 10) {\n                    System.out.print(\"...\");\n                }\n                else {\n                    System.out.print(c[i][j] + \" \");\n                }\n            }\n\n            if(i == 10) {\n                System.out.println();\n                for(int k = 0; k < 10; k++) System.out.print(\" ... \");\n            }   \n\n            System.out.println();\n        }       \n\n        System.out.println();\n    }\n\n    // To simplify checking, fill with all 1's. Answer should be all n's.\n    static void init(float[][] a, float[][] b, int n) {\n        for (int i = 0; i < n; ++i) {\n            for (int j = 0; j < n; ++j) {\n                a[i][j] = 1.0F;\n                b[i][j] = 1.0F;\n            }\n        }\n    }\n\n    static void check(float[][] c, int n) {\n        for (int i = 0; i < n; i++) {\n            for (int j = 0; j < n; j++) {\n                if (c[i][j] != n) {\n                    throw new Error(\"Check Failed at [\" + i + \"][\" + j + \"]: \" + c[i][j]);\n                    //System.out.println(\"Check Failed at [\" + i + \"][\" + j + \"]: \" + c[i][j]); \n                }\n            }\n        }       \n    }   \n\n    public class Seq implements Runnable {\n\n        private final MatrixMultiplyTask a;\n        private final MatrixMultiplyTask b;\n\n        public Seq(MatrixMultiplyTask a, MatrixMultiplyTask b, int size) {\n            this.a = a;\n            this.b = b;\n\n            if (size <= THRESHOLD) {\n                executor.submit(this);\n            } else {            \n                a.split();\n                b.split();\n            }\n        }\n\n        public void run() {\n            a.multiplyStride2();\n            b.multiplyStride2();\n        }   \n    }\n\n    private class MatrixMultiplyTask {\n        private final float[][] A; // Matrix A\n        private final int aRow; // first row of current quadrant of A\n        private final int aCol; // first column of current quadrant of A\n\n        private final float[][] B; // Similarly for B\n        private final int bRow;\n        private final int bCol;\n\n        private final float[][] C; // Similarly for result matrix C\n        private final int cRow;\n        private final int cCol;\n\n        private final int size;\n\n        MatrixMultiplyTask(float[][] A, int aRow, int aCol, float[][] B,\n                int bRow, int bCol, float[][] C, int cRow, int cCol, int size) {\n\n            this.A = A;\n            this.aRow = aRow;\n            this.aCol = aCol;\n            this.B = B;\n            this.bRow = bRow;\n            this.bCol = bCol;\n            this.C = C;\n            this.cRow = cRow;\n            this.cCol = cCol;\n            this.size = size;\n        }   \n\n        public void split() {\n            int h = size / 2;\n\n            new Seq(new MatrixMultiplyTask(A,\n                    aRow, aCol, // A11\n                    B, bRow, bCol, // B11\n                    C, cRow, cCol, // C11\n                    h),\n\n            new MatrixMultiplyTask(A, aRow, aCol + h, // A12\n                    B, bRow + h, bCol, // B21\n                    C, cRow, cCol, // C11\n                    h), h);\n\n            new Seq(new MatrixMultiplyTask(A,\n                    aRow, aCol, // A11\n                    B, bRow, bCol + h, // B12\n                    C, cRow, cCol + h, // C12\n                    h),\n\n            new MatrixMultiplyTask(A, aRow, aCol + h, // A12\n                    B, bRow + h, bCol + h, // B22\n                    C, cRow, cCol + h, // C12\n                    h), h);\n\n            new Seq(new MatrixMultiplyTask(A, aRow\n                    + h, aCol, // A21\n                    B, bRow, bCol, // B11\n                    C, cRow + h, cCol, // C21\n                    h),\n\n            new MatrixMultiplyTask(A, aRow + h, aCol + h, // A22\n                    B, bRow + h, bCol, // B21\n                    C, cRow + h, cCol, // C21\n                    h), h);\n\n            new Seq(new MatrixMultiplyTask(A, aRow\n                    + h, aCol, // A21\n                    B, bRow, bCol + h, // B12\n                    C, cRow + h, cCol + h, // C22\n                    h),\n\n            new MatrixMultiplyTask(A, aRow + h, aCol + h, // A22\n                    B, bRow + h, bCol + h, // B22\n                    C, cRow + h, cCol + h, // C22\n                    h), h);\n        }\n\n        public void multiplyStride2() {\n            for (int j = 0; j < size; j += 2) {\n                for (int i = 0; i < size; i += 2) {\n\n                    float[] a0 = A[aRow + i];\n                    float[] a1 = A[aRow + i + 1];\n\n                    float s00 = 0.0F;\n                    float s01 = 0.0F;\n                    float s10 = 0.0F;\n                    float s11 = 0.0F;\n\n                    for (int k = 0; k < size; k += 2) {\n\n                        float[] b0 = B[bRow + k];\n\n                        s00 += a0[aCol + k] * b0[bCol + j];\n                        s10 += a1[aCol + k] * b0[bCol + j];\n                        s01 += a0[aCol + k] * b0[bCol + j + 1];\n                        s11 += a1[aCol + k] * b0[bCol + j + 1];\n\n                        float[] b1 = B[bRow + k + 1];\n\n                        s00 += a0[aCol + k + 1] * b1[bCol + j];\n                        s10 += a1[aCol + k + 1] * b1[bCol + j];\n                        s01 += a0[aCol + k + 1] * b1[bCol + j + 1];\n                        s11 += a1[aCol + k + 1] * b1[bCol + j + 1];\n                    }\n\n                    C[cRow + i][cCol + j] += s00;\n                    C[cRow + i][cCol + j + 1] += s01;\n                    C[cRow + i + 1][cCol + j] += s10;\n                    C[cRow + i + 1][cCol + j + 1] += s11;\n                }\n            }           \n        }\n    }\n}\n```\n\n    ", "Answer": "\r\nI tried adding synchronized as I suggested and this fixed the problem. ;)\n\nI tried\n\n\nsynchronizing each row 299 ms.\nswapping the loops in mutliplyStride so that it goes by column instead of by row. 253 ms\nassumed one lock for each pair of rows (i.e. I locked one row for both updates. 216 ms\nDisable biased locking ```\n-XX:-UseBiasedLocking```\n 207 ms\nuse 2x the number of processors for threads. 199 ms.\nsame except using ```\ndouble```\n instead of ```\nfloat```\n 237 ms.\nno synchronization at all. 174 ms.\n\n\nAs you can see the fifth option is less than 10% slower than no synchronization.  If you want further gains I suggest you alter the way the data is accessed to make them more cache friendly.\n\nIn summary I suggest\n\n```\nprivate final ExecutorService executor = Executors.newFixedThreadPool(MAX_THREADS*2);\n\npublic void multiplyStride2() {\n    for (int i = 0; i < size; i += 2) {\n        for (int j = 0; j < size; j += 2) {\n\n        // code as is......\n\n            synchronized (C[cRow + i]) {\n                C[cRow + i][cCol + j] += s00;\n                C[cRow + i][cCol + j + 1] += s01;\n\n                C[cRow + i + 1][cCol + j] += s10;\n                C[cRow + i + 1][cCol + j + 1] += s11;\n            }\n```\n\n\nInterestingly, if I calculate a block of 2x4 instaed of 2x2 the average times drops to 172 ms. (faster than the previous result with no synchronization) ;)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "MIPS Assembly, matrix multiplication\r\n                \r\nI'm trying to implement matrix multiplication using MIPS assembly. There is an error on the line \"lw $t4, 0($t4)\" on the second loop through the k_loop. The error is: \"Runtime exception at 0x00400090: fetch address not aligned on word boundary 0x1000fffd\". Could someone explain what the error means and what I could do to fix it? Thank you.\n\n```\n            .data\nmatrixA:    .word 1,2,3,4,5,6   #Content of matrixA in array form\nmatrixB:    .word 5,6,7,8,9,10  #Content of matrixB in array form\nsizeA:      .word 3,2       #Defines matrixA as being a 3x2 matrix\nsizeB:      .word 2,3       #Defines matrixB as being a 2x3 matrix\nresult:     .word 0:9       #Initialize result as being an array of length 9 populated with 0\ntab:        .asciiz \"\\t\"\nnewLine:    .asciiz \"\\n\"\n            .globl _main\n\n            .text\n_main:  la $s0, matrixA     #s0 set to base address of matrixA\n        la $s1, matrixB     #s1 set to base address of matrixB\n        la $s2, sizeA       #s2 set to base address of sizeA\n        nop\n        lw $s3, 4($s2)      #s3 set to second val in sizeA (col #)\n        nop\n        lw $s2, 0($s2)      #s2 set to first val in sizeA (row #)\n        la $s4, sizeB       #s4 set to base address of sizeB\n        nop\n        lw $s5, 4($s4)      #s5 set to second val in sizeB (col #)\n        nop\n        lw $s4, 0($s4)      #s4 set to first val in sizeB (row #)\n        la $s6, result      #s6 set to base adress of result\n        add $s7, $s5, $zero #s7 set to col # in result matrix\n        add $t0, $zero, $zero   #Set t0 to zero. i = 0\n        add $t1, $zero, $zero   #Set t1 to zero. j = 0\n        add $t2, $zero, $zero   #Set t2 to zero. k = 0\n        li $t3, 0       #Result position set to zero\ni_loop: beq $t0, $s2, i_end #End i_loop if i = rowsA\n        nop\nj_loop: beq $t1, $s5, j_end #End j_loop if j = colsB\n        nop\nk_loop: beq $t2, $s4, k_end #End k_loop if k = rowsB\n        nop\n\n        #loop body\n\n        li $t4, 0\n        li $t5, 0\n        li $t6, 0\n                            #i * M + k - 1\n        mul $t4, $t0, $s3   #i * #col in matrixA\n        add $t4, $t4, $t2   #t4 + k\n        addi $t4, $t4, -4      #t4 -1\n        add $t4, $t4, $s0   #Now points to value at matrixA[i][k]\n        lw $t4, 0($t4)      #Loads value at matrixA[i][k]\n\n                    #k * M + j - 1\n        mul $t5, $t2, $s5   #k * #col in matrixB\n        add $t5, $t5, $t1   #t5 + j\n        addi $t5, $t5, -4   #t5 -1\n        add $t5, $t5, $s1   #t5 now points to value at matrixB[k][j]\n        lw $t5, 0($t5)      #t5 loads value at matrixB[k][j]\n\n                    #i * M + j - 1\n        mul $t6, $t0, $s7   #i * #col in result\n        add $t6, $t6, $t1   #t6 + j\n        addi $t6, $t6, -4   #t6 -1\n        add $t6, $t6, $s6   #t6 now points to value at result[i][j]\n        lw $t8, 0($t6)      #t6 loads value at result[i][j]\n\n        mul $t7, $t4, $t5   #t7 = matrixA[i][k]*matrixB[k][j]\n\n        add $t9, $t8, $t7   #t8 = result[i][j] + matrixA[i][k]*matrixB[k][j]\n        sw $t9, 0($t6)\n\n        #end loop body\n\n        addi $t2, $t2, 1    #k++\n        j k_loop        #Return to start of k_loop\nk_end:\n        addi $t1, $t1, 1    #j++\n        li $t2, 0       #Resets k counter to 0\n        j j_loop        #Return to start of j_loop\nj_end:\n        addi $t0, $t0, 1    #i++\n        li $t1, 0       #Resets j counter to 0\n        j i_loop        #Return to start of i_loop\n\ni_end:      #print\n```\n\n    ", "Answer": "\r\nThere are three distinct problems, masked by the alignment fault.\n\nYou are computing array indexes [for an ```\nint```\n array]. Before these can be added to the base address of the matrix, they must be converted into byte offsets.\n\nOtherwise, you'll get [as you did get] an alignment fault because mips requires that addresses for words (i.e. ```\nlw/sw```\n) are four byte aligned.\n\nThe second problem is when you try to subtract one from index. You're using a value of ```\n-4```\n even though the comment says ```\n-1```\n. So, on some level, you're mixing and matching index calculations and offset calculations\n\nConsider a simple 1D ```\nint```\n array/vector that starts at address ```\n0x10010000```\n. The index to address mapping would be:\n\n```\nindex   offset  address\n-----   ------  --------\n  0       0     10010000\n  1       4     10010004\n  2       8     10010008\n```\n\n\nIn your code, you have:\n\n```\n    addi    $t4,$t4,-4              # t4 - 1\n    add     $t4,$t4,$s0             # Now points to value at matrixA[i][k]\n    lw      $t4,0($t4)              # Loads value at matrixA[i][k]\n```\n\n\nThe final index (e.g. ```\n$t4```\n) needs to be multiplied by ```\nsizeof(int)```\n [which is 4] before adding in the matrix base address. The idiomatic way to do this is a left shift by 2.\n\nAlso, when adding addresses to addresses or offsets to addresses, you should use the unsigned version of ```\nadd```\n (i.e. ```\naddu```\n) to guard against overflow/wrap which can occur for addresses.\n\n```\n    addi    $t4,$t4,-1              # t4 - 1\n    sll     $t4,$t4,2               # convert index to byte offset\n    addu    $t4,$t4,$s0             # Now points to value at matrixA[i][k]\n    lw      $t4,0($t4)              # Loads value at matrixA[i][k]\n```\n\n\nYou'll need to add this extra step whenever/wherever you do these index calculations.\n\nThe third problem is the final address ```\n0x1000fffd```\n while not four byte aligned, is also below the lowest address allowed for the ```\n.data```\n segment in ```\nmars```\n (i.e ```\n0x10010000```\n), so if you hadn't got the alignment fault, you'd be accessing non-existent memory [which will issue a different type of fault]\n\nSo, you may want to double check your index calculations for correctness to prevent the equivalent of accessing ```\nint myarray[2]; myarray[-1] = 3;```\n [which is UB]\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in Python, multiprocessing\r\n                \r\nI'm very beginner in Python. \nI have problem with matrix multiplication. \nI read matrix from txt file using list of lists (matrices). \n\nWhen I want to use multiprocessing I have problem with divide list and use new lists in Pool function. \n\nHow can I fix this problem?\n\nPlease Help\n\n```\ndef matrix_multiplication(list1, list2):\n    A = numpy.matrix(list1)\n    B = numpy.matrix(list2)\n    return A*B\n\ndef counting(dane):\n\n     left_matrix = matrices[0]\n\n     for matrix in matrices[1:]:\n         left_matrix = numpy.matrix(left_matrix)\n         matrix = numpy.matrix(matrix)\n         left_matrix = matrix_multiplication(left_matrix, matrix)\n\n\nif __name__ == \"__main__\":\n\n\n    matrices = []\n    with open('sample-probka2.txt', 'r') as file:\n        matrix_reader = csv.reader(file, delimiter=';')\n        current_matrix = []\n\n        for row in matrix_reader:\n            if len(row) == 0:\n                matrices.append(current_matrix)\n                current_matrix = []\n            else:\n                current_matrix.append(list(map(float, row)))\n\n    print (matrices)\n\n    counting(matrices)\n\n\n    np = multiprocessing.cpu_count()\n    print('You have', np, 'processors')\n\n\n    matrices2 = numpy.array_split(matrices, np)\n    print(matrices2)\n\n\n    pool = Pool(processes=np)\n    count = pool.starmap(liczenie, matrices2)\n    print count\n```\n\n\nerror from comment, with an attempt to restore formatting:\n\n```\nmultiprocessing.pool.RemoteTraceback:  \nTraceback (most recent call last): \nFile \"/Library/Frameworks/Python.framework/Versions/3.6/lib/pytho‌​n3.6/multiprocessing‌​/pool.py\", \nline 119, in worker result = (True, func(*args, **kwds)) \nFile \"/Library/Frameworks/Python.framework/Versions/3.6/lib/pytho‌​n3.6/multiprocessing‌​/pool.py\", line 47, \nin starmapstar return list(itertools.starmap(args[0], args[1])) TypeError: counting() takes 1 positional argument but 61 were given\n```\n\n    ", "Answer": "\r\nI don't think you want ```\npool.starmap```\n in this instance. what it is doing is unpacking each matrix into 61 elements as it is handed to ```\ncounting()```\n which only expects one argument.\n\nfrom the docs:\n\n\n  starmap(func, iterable[, chunksize])\n  \n  Like map() except that the elements of the iterable are expected to be\n  iterables that are unpacked as arguments.\n  \n  Hence an iterable of [(1,2), (3, 4)] results in [func(1,2),\n  func(3,4)].\n\n\nyou could fix this in a number of ways, but I think the most sensible is to use ```\npool.map```\n instead, as it won't unpack your inputs and leave them as a single variable. you could also define ```\ncounting(*dane)```\n to allow a variable number of inputs that would be concatenated into the list ```\ndane```\n (which you don't use within the function, but I'll leave you to figure out what to do with it..)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Removing NA when preforming matrix multiplication\r\n                \r\nI was wondering if there is a better way to omit ```\nNA```\n when using matrix multiplication.  I'm currently using this approach\n\n```\na <- c(NA,4,3,2)\nb <- c(4,3,1,NA)\n\nlogic <- !is.na(a) & !is.na(b)\n\na[logic]%*%b[logic]\n```\n\n\nWas hoping for something like this...\n\n```\n`%*%`(a, b, na.rm = TRUE)\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Parallel Matrix Multiplication in Java 6\r\n                \r\nYesterday I asked a question about parallel matrix multiplication in Java 7 using the fork/join framework here. With the help of axtavt I got my example program to work. Now I’m implementing an equivalent program using Java 6 functionality only. I get the same problem as yesterday, dispite applying the the feedback axtavt gave me (I think). Am I overlooking something?\nCode:\n\n```\npackage algorithms;\n\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.TimeUnit;\n\npublic class Java6MatrixMultiply implements Algorithm {\n\n    private static final int SIZE = 1024;\n    private static final int THRESHOLD = 64;\n    private static final int MAX_THREADS = Runtime.getRuntime().availableProcessors();\n\n    private final ExecutorService executor = Executors.newFixedThreadPool(MAX_THREADS);\n\n    private float[][] a = new float[SIZE][SIZE];\n    private float[][] b = new float[SIZE][SIZE];\n    private float[][] c = new float[SIZE][SIZE];\n\n    @Override\n    public void initialize() {\n        init(a, b, SIZE);\n    }\n\n    @Override\n    public void execute() {\n        MatrixMultiplyTask task =  new MatrixMultiplyTask(a, 0, 0, b, 0, 0, c, 0, 0, SIZE);\n        task.split();\n\n        executor.shutdown();    \n        try {\n            executor.awaitTermination(Integer.MAX_VALUE, TimeUnit.DAYS);\n        } catch (InterruptedException e) {\n            System.out.println(\"Error: \" + e.getMessage());\n        }\n    }\n\n    @Override\n    public void printResult() {\n        check(c, SIZE);\n\n        for (int i = 0; i < SIZE && i <= 10; i++) {\n            for (int j = 0; j < SIZE && j <= 10; j++) {         \n                if(j == 10) {\n                    System.out.print(\"...\");\n                }\n                else {\n                    System.out.print(c[i][j] + \" \");\n                }\n            }\n\n            if(i == 10) {\n                System.out.println();\n                for(int k = 0; k < 10; k++) System.out.print(\" ... \");\n            }   \n\n            System.out.println();\n        }       \n\n        System.out.println();\n    }\n\n    // To simplify checking, fill with all 1's. Answer should be all n's.\n    static void init(float[][] a, float[][] b, int n) {\n        for (int i = 0; i < n; ++i) {\n            for (int j = 0; j < n; ++j) {\n                a[i][j] = 1.0F;\n                b[i][j] = 1.0F;\n            }\n        }\n    }\n\n    static void check(float[][] c, int n) {\n        for (int i = 0; i < n; i++) {\n            for (int j = 0; j < n; j++) {\n                if (c[i][j] != n) {\n                    throw new Error(\"Check Failed at [\" + i + \"][\" + j + \"]: \" + c[i][j]);\n                    //System.out.println(\"Check Failed at [\" + i + \"][\" + j + \"]: \" + c[i][j]); \n                }\n            }\n        }       \n    }   \n\n    public class Seq implements Runnable {\n\n        private final MatrixMultiplyTask a;\n        private final MatrixMultiplyTask b;\n\n        public Seq(MatrixMultiplyTask a, MatrixMultiplyTask b, int size) {\n            this.a = a;\n            this.b = b;\n\n            if (size <= THRESHOLD) {\n                executor.submit(this);\n            } else {            \n                a.split();\n                b.split();\n            }\n        }\n\n        public void run() {\n            a.multiplyStride2();\n            b.multiplyStride2();\n        }   \n    }\n\n    private class MatrixMultiplyTask {\n        private final float[][] A; // Matrix A\n        private final int aRow; // first row of current quadrant of A\n        private final int aCol; // first column of current quadrant of A\n\n        private final float[][] B; // Similarly for B\n        private final int bRow;\n        private final int bCol;\n\n        private final float[][] C; // Similarly for result matrix C\n        private final int cRow;\n        private final int cCol;\n\n        private final int size;\n\n        MatrixMultiplyTask(float[][] A, int aRow, int aCol, float[][] B,\n                int bRow, int bCol, float[][] C, int cRow, int cCol, int size) {\n\n            this.A = A;\n            this.aRow = aRow;\n            this.aCol = aCol;\n            this.B = B;\n            this.bRow = bRow;\n            this.bCol = bCol;\n            this.C = C;\n            this.cRow = cRow;\n            this.cCol = cCol;\n            this.size = size;\n        }   \n\n        public void split() {\n            int h = size / 2;\n\n            new Seq(new MatrixMultiplyTask(A,\n                    aRow, aCol, // A11\n                    B, bRow, bCol, // B11\n                    C, cRow, cCol, // C11\n                    h),\n\n            new MatrixMultiplyTask(A, aRow, aCol + h, // A12\n                    B, bRow + h, bCol, // B21\n                    C, cRow, cCol, // C11\n                    h), h);\n\n            new Seq(new MatrixMultiplyTask(A,\n                    aRow, aCol, // A11\n                    B, bRow, bCol + h, // B12\n                    C, cRow, cCol + h, // C12\n                    h),\n\n            new MatrixMultiplyTask(A, aRow, aCol + h, // A12\n                    B, bRow + h, bCol + h, // B22\n                    C, cRow, cCol + h, // C12\n                    h), h);\n\n            new Seq(new MatrixMultiplyTask(A, aRow\n                    + h, aCol, // A21\n                    B, bRow, bCol, // B11\n                    C, cRow + h, cCol, // C21\n                    h),\n\n            new MatrixMultiplyTask(A, aRow + h, aCol + h, // A22\n                    B, bRow + h, bCol, // B21\n                    C, cRow + h, cCol, // C21\n                    h), h);\n\n            new Seq(new MatrixMultiplyTask(A, aRow\n                    + h, aCol, // A21\n                    B, bRow, bCol + h, // B12\n                    C, cRow + h, cCol + h, // C22\n                    h),\n\n            new MatrixMultiplyTask(A, aRow + h, aCol + h, // A22\n                    B, bRow + h, bCol + h, // B22\n                    C, cRow + h, cCol + h, // C22\n                    h), h);\n        }\n\n        public void multiplyStride2() {\n            for (int j = 0; j < size; j += 2) {\n                for (int i = 0; i < size; i += 2) {\n\n                    float[] a0 = A[aRow + i];\n                    float[] a1 = A[aRow + i + 1];\n\n                    float s00 = 0.0F;\n                    float s01 = 0.0F;\n                    float s10 = 0.0F;\n                    float s11 = 0.0F;\n\n                    for (int k = 0; k < size; k += 2) {\n\n                        float[] b0 = B[bRow + k];\n\n                        s00 += a0[aCol + k] * b0[bCol + j];\n                        s10 += a1[aCol + k] * b0[bCol + j];\n                        s01 += a0[aCol + k] * b0[bCol + j + 1];\n                        s11 += a1[aCol + k] * b0[bCol + j + 1];\n\n                        float[] b1 = B[bRow + k + 1];\n\n                        s00 += a0[aCol + k + 1] * b1[bCol + j];\n                        s10 += a1[aCol + k + 1] * b1[bCol + j];\n                        s01 += a0[aCol + k + 1] * b1[bCol + j + 1];\n                        s11 += a1[aCol + k + 1] * b1[bCol + j + 1];\n                    }\n\n                    C[cRow + i][cCol + j] += s00;\n                    C[cRow + i][cCol + j + 1] += s01;\n                    C[cRow + i + 1][cCol + j] += s10;\n                    C[cRow + i + 1][cCol + j + 1] += s11;\n                }\n            }           \n        }\n    }\n}\n```\n\n    ", "Answer": "\r\nI tried adding synchronized as I suggested and this fixed the problem. ;)\n\nI tried\n\n\nsynchronizing each row 299 ms.\nswapping the loops in mutliplyStride so that it goes by column instead of by row. 253 ms\nassumed one lock for each pair of rows (i.e. I locked one row for both updates. 216 ms\nDisable biased locking ```\n-XX:-UseBiasedLocking```\n 207 ms\nuse 2x the number of processors for threads. 199 ms.\nsame except using ```\ndouble```\n instead of ```\nfloat```\n 237 ms.\nno synchronization at all. 174 ms.\n\n\nAs you can see the fifth option is less than 10% slower than no synchronization.  If you want further gains I suggest you alter the way the data is accessed to make them more cache friendly.\n\nIn summary I suggest\n\n```\nprivate final ExecutorService executor = Executors.newFixedThreadPool(MAX_THREADS*2);\n\npublic void multiplyStride2() {\n    for (int i = 0; i < size; i += 2) {\n        for (int j = 0; j < size; j += 2) {\n\n        // code as is......\n\n            synchronized (C[cRow + i]) {\n                C[cRow + i][cCol + j] += s00;\n                C[cRow + i][cCol + j + 1] += s01;\n\n                C[cRow + i + 1][cCol + j] += s10;\n                C[cRow + i + 1][cCol + j + 1] += s11;\n            }\n```\n\n\nInterestingly, if I calculate a block of 2x4 instaed of 2x2 the average times drops to 172 ms. (faster than the previous result with no synchronization) ;)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication of each row in data frame\r\n                \r\nThis should be elementary, but cannot get my head around it.\nI have a data frame and want to create a new variable as the matrix multiplication of each row by a pre-specified vector.\n```\n\nlibrary(dplyr)\ndata <- data.frame(matrix(1:6,2))\nvector <- c(1,0,1)\n\n##NOT WORKING\ndata <- data %>%\nmutate(multiplication = as.numeric(data[,]) %*% vector)\n\nmm <- function(x,y){\n  n <- as.numeric(x)\n  m <- n %*% y\n  print(as.numeric(m))\n}\n\n##NOT WORKING\ndata$mm <- lapply(data[,], function(x) mm(x,vector))\n\n```\n\n    ", "Answer": "\r\nYou can use ```\napply```\n:\n```\ndata %>% mutate(multiplication = apply(., 1, function(x) x %*% vector))\n#>   X1 X2 X3 multiplication\n#> 1  1  3  5              6\n#> 2  2  4  6              8\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Numpy Matrix Multiplication with Vectors\r\n                \r\ni wanna do a simple matrix multiplication with 2 Vectors: so that A * B.T = 3x3Matrix.\n\nBut somehow numpy returns a scalar or vector.\n\ni already tried:\n\n```\nnp.dot(a, b.transpose())\nnp.matmul(a, b.transpose())\na * b.transpose()\n```\n\n\nBut nothins works, it seems like a simple operation to me, but i just cannot solve it\n    ", "Answer": "\r\nThe reason why you are getting a scalar because you are multiplying two 1D vectors in numpy, which produces the inner product of 2 vectors. You need to reshape your vector to the shape (3,1), which turns them into a 2D shape and then you get the expected result upon performing the vector multiplication. Check the snippet below \n\n```\n>>> import numpy as np\n>>> A = np.array([1,2,3])\n>>> B = np.array([4,5,6])\n>>> A.shape\n(3,)\n>>> B.shape\n(3,)\n>>> AA = A.reshape(3, 1)\n>>> BB = B.reshape(3, 1)\n>>> AA.shape\n(3, 1)\n>>> BB.shape\n(3, 1)\n>>> np.matmul(AA, np.transpose(BB))\narray([[ 4,  5,  6],\n       [ 8, 10, 12],\n       [12, 15, 18]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Cant have matrix multiplication work properly [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question needs debugging details. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                     Edit the question to include desired behavior, a specific problem or error, and the shortest code necessary to reproduce the problem. This will help others answer the question.\r\n                \r\n                    \r\n                        Closed 6 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nI have been trying to use homogeneous transformations on C++ but i cant get the matrix multiplication to work. Am I doing something wrong in the code?\n\nI checked doing it by hand and it doesnt seem to be wrong. Did i miss something?\n\n```\n#include \"stdafx.h\"\nusing namespace std;\n\nfloat point[3][1];\nfloat point_trans[3][1] = {0,0,0};\nfloat rot[3][3] = { {1,2,3},{4,5,6},{7,8,9} };\nfloat d[3][1] = {0,0,0};\nfloat x,y,z;\n\nfloat transform (float x1, float y1, float z1)\n{\n    point[0][0] = x1; \n    point[1][0] = y1;\n    point[2][0] = z1;\n\n    for(int i=0; i<3; ++i)\n    {\n        for(int j=0; j<1; ++j)\n        {\n            for(int k=0; k<3; ++k)\n            {\n                point_trans[i][j]+=rot[i][k]*point[k][j];\n            }\n        }\n    }\n\n    x1 = point_trans[0][0] + d[0][0];\n    y1 = point_trans[1][0] + d[1][0];\n    z1 = point_trans[2][0] + d[2][0];\n\n    return(x1,y1,z1);\n}\n\nint main()\n{\n    x = 6; y = 7; z = 8;\n\nfor(int i=0;i<3;i++)\n{\n    for(int j=0;j<3;j++)\n    {\n        cout << rot[i][j] << \" \";\n    }\n    cout << endl;\n}\n\n\n    (x,y,z) = transform(x,y,z);\n    cout << \"X:\" << x << \" \" << \"Y:\"<<y<<\" \"<<\"Z:\"<<z<<endl;\n    system(\"pause\");\n    return 0;\n\n}\n```\n\n    ", "Answer": "\r\nYou are writing python code in c++.\n\n```\ndef transform():\n    return (6, 7, 8)\n\nx, y, z = transform()\nprint (x, y, z)\n```\n\n\nThe parentheses create an instance of a composite type (tuple) in python. The output will be 6, 7, 8 because it returns one result, but that result is a three part tuple, and assignment of x, y, z = (6, 7, 8) assigns each part of the tuple to different variables because of how python does assignment with a tuple.\n\nWhat actually happens in c++ when you write (6, 7, 8) is the comma operator, which evaluates the first item and discards the result. https://en.wikipedia.org/wiki/Comma_operator The parentheses just group operators, and have no effect here. Because evaluating a single float value like \"x\" has no side effects, it doesn't do anything, and \"return (x, y, z)\" in c++ code is the same as just writing \"return z\".\n\nBecause the code is c++ you need to do the same thing as what the python code actually did (return one value with three parts), but you need to do it in c++, so go ahead and declare a type. That's one of the key differences -- you have to tell the compiler what the types are. There are of course many ways to do it, but you can't just use python syntax.\n\n```\nstruct coordinate { float x, y, z; };\n\ncoordinate transform(float x1, float y1, float z1)\n{\n    // code\n    return coordinate{ x1, y1, z1 };\n}\n\n// in main\ncoordinate result = transform(x, y, z);\ncout << \"X:\" << result.x << \" \" << \"Y:\" << result.y << \" \" << \"Z:\" << result.z << endl;\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Is it possible to speed up matrix multiplication with texture memory?\r\n                \r\nI am learning cuda.\n\nWould it be possible to speedup something as simple as matrix multiplication with texture memory? The spatial locality is a nice property as addition to my tiling, but could overhead from using texture memory outweigh it?\n\nI can't seem to find any implementations of matrix multiplication that use texture memory.\n    ", "Answer": "\r\nMatrix multiply can be implemented in a variety of ways.\n\nCompared to a naive implementation of matrix multiply that only uses global memory, yes, it's possible to speed it up using texture memory.\n\nCompared to a better-written version of matrix multiply that uses shared memory, it's not likely that texture memory will give much or any benefit.\n\nIf you want the best performance from CUDA matrix multiply, you should use CUBLAS.  Don't write your own matrix multiply code.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to implement matrix multiplication of UMat in opencv?\r\n                \r\nHow to implement matrix multiplication of UMat in opencv\n\n```\n    UMat AA_J2,AAu,J2u;\n    AA.copyTo(AAu);\n    J_2.copyTo(J2u);\n    AA_J2=AAu*J2u;\n```\n\n    ", "Answer": "\r\nYou can use cv::gemm to perform matrix multiplication, addition and more with cv::UMat.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "C++ namespace FW ; Matrix multiplication\r\n                \r\nI'm trying to implement some basic matrix multiplication, for translation.\nIn my opinion the multiplication should work, but I get this error.\n\n\n  binary '*=' : no operator found which takes a right-hand operand of type 'FW::Vec4f' (or there is no acceptable conversion)\n\n\nHere is my code, using std and FW namepsace\n\n```\n    Mat4f World;\n\nfloat x, y, z;\n\nWorld.setCol(0, Vec4f(1, 0, 0, x));\nWorld.setCol(1, Vec4f(0, 1, 0, y));\nWorld.setCol(2, Vec4f(0, 0, 1, z));\nWorld.setCol(3, Vec4f(0, 0, 0, 1));\n\nWorld *= Vec4f(translation_, 1, 1, 1);\n```\n\n    ", "Answer": "\r\nThe result of the multiplication of a matrix with a vector is a vector (not a matrix). So this\n\n```\nWorld *= Vec4f(translation_, 1, 1, 1);\n```\n\n\nmakes no sense. That would be more like it\n\n```\nVec4f r = World * Vec4f(translation_, 1,1,1);\n```\n\n\nMy suggestion: Get your linear algebra polished up.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Strassen's algorithm for matrix multiplication in C++\r\n                \r\nWe were assigned to implemented the following function for Strassen's algorithm for matrix multiplication in C++, using recursion on the base cases for n=1 and n=2\n```\n#include \"strassen_mm.hpp\"\n\n#include <iomanip>\n#include <iostream>\n#include <stdexcept>\n\ntemplate <typename T>\nstatic void printMatrix(const vector<vector<T>>& matrix, string header) {\n    cout << header << \"\\n\";\n    for (const auto& row : matrix) {\n        for (const auto& elem : row) {\n            cout << setw(10) << left << elem;\n        }\n        cout << endl << flush;\n    }\n}\n\ntemplate <typename T>\nstatic std::vector<std::vector<T>> add_zero_row_col(\n    const std::vector<std::vector<T>>& matrix) {\n    // Create a new matrix with an extra row and column of zeros\n    std::vector<std::vector<T>> result(matrix.size() + 1,\n                                       std::vector<T>(matrix[0].size() + 1, 0));\n\n    // Copy the original matrix into the new matrix\n    for (size_t i = 0; i < matrix.size(); i++) {\n        for (size_t j = 0; j < matrix[0].size(); j++) {\n            result[i][j] = matrix[i][j];\n        }\n    }\n\n    return result;\n}\n\ntemplate <typename T>\nstatic void remove_last_row_and_column(std::vector<std::vector<T>>& matrix) {\n    if (matrix.empty() || matrix[0].empty()) {\n        // Matrix is already empty\n        return;\n    }\n\n    matrix.pop_back();  // Remove last row\n\n    for (auto& row : matrix) {\n        if (!row.empty()) {\n            row.pop_back();  // Remove last column from each row\n        }\n    }\n}\n\ntemplate<typename T> static \nvector<vector<T>> operator-(const vector<vector<T>>& a, const vector<vector<T>>& b) {\n    // Check if the matrices have the same dimensions\n    if (a.size() != b.size() || a[0].size() != b[0].size()) {\n        throw std::invalid_argument(\"Matrices must have the same dimensions.\");\n    }\n    \n    // Create a new matrix to hold the result\n    vector<vector<T>> result(a.size(), vector<T>(a[0].size()));\n    \n    // Subtract each element of the matrices and store the result in the new matrix\n    for (int i = 0; i < a.size(); i++) {\n        for (int j = 0; j < a[0].size(); j++) {\n            result[i][j] = a[i][j] - b[i][j];\n        }\n    }\n    \n    return result;\n}\n\ntemplate <typename T>\nstatic vector<vector<T>> operator*(const vector<vector<T>>& a,\n                                   const vector<vector<T>>& b) {\n    // Get the dimensions of the matrices\n    int rows_a = a.size();\n    int cols_a = a[0].size();\n    int rows_b = b.size();\n    int cols_b = b[0].size();\n\n    // Make sure the matrices can be multiplied\n    if (cols_a != rows_b) {\n        cout << \"Error: cannot multiply matrices of these dimensions\" << endl;\n        return {};\n    }\n\n    // Create the result matrix\n    vector<vector<T>> result(rows_a, vector<T>(cols_b));\n\n    // Multiply the matrices\n    for (int i = 0; i < rows_a; i++) {\n        for (int j = 0; j < cols_b; j++) {\n            T sum = 0;\n            for (int k = 0; k < cols_a; k++) {\n                sum += a[i][k] * b[k][j];\n            }\n            result[i][j] = sum;\n        }\n    }\n\n    return result;\n}\n\n// summing up 2 matrices\ntemplate <typename T>\nstatic vector<vector<T>> operator+(const vector<vector<T>>& matrix1,\n                                   const vector<vector<T>>& matrix2) {\n    // check that the matrices have the same size\n    if (matrix1.size() != matrix2.size() ||\n        matrix1[0].size() != matrix2[0].size()) {\n        throw runtime_error(\"Error: matrices have different sizes\");\n    }\n\n    // add the matrices element-wise\n    vector<vector<T>> result(matrix1.size(), vector<T>(matrix1[0].size(), 0));\n    for (int i = 0; i < matrix1.size(); i++) {\n        for (int j = 0; j < matrix1[0].size(); j++) {\n            result[i][j] = matrix1[i][j] + matrix2[i][j];\n        }\n    }\n\n    // return the result\n    return result;\n}\n\n\ntemplate <typename T>\nstatic vector<vector<T>> strassen_mm_internal(const vector<vector<T>>& A,\n                                              const vector<vector<T>>& B,\n                                              bool removelast = false) {\n    if (A.size() == 0 || B.size() == 0) return vector<vector<T>>();\n\n    if (A.size() != A[0].size() || B.size() != B[0].size() ||\n        A.size() != B.size()) {\n        throw runtime_error(\"strassen_mm size check failed \");\n    }\n    auto n = A.size();\n\n    // base case for n=1\n    if (n == 1) {\n        return vector<vector<T>>(1, vector<T>(1, A[0][0] * B[0][0]));\n    }\n\n    // base cae for n=2\n    if (n == 2) {\n        vector<vector<T>> C(2, vector<T>(2, 0));\n        T p1 = A[0][0] * (B[0][1] - B[1][1]);\n        T p2 = (A[0][0] + A[0][1]) * B[1][1];\n        T p3 = (A[1][0] + A[1][1]) * B[0][0];\n        T p4 = A[1][1] * (B[1][0] - B[0][0]);\n        T p5 = (A[0][0] + A[1][1]) * (B[0][0] + B[1][1]);\n        T p6 = (A[0][1] - A[1][1]) * (B[1][0] + B[1][1]);\n        T p7 = (A[0][0] - A[1][0]) * (B[0][0] + B[0][1]);\n        C[0][0] = p5 + p4 - p2 + p6;\n        C[0][1] = p1 + p2;\n        C[1][0] = p3 + p4;\n        C[1][1] = p5 + p1 - p3 - p7;\n        return C;\n    }\n\n    // padd with zero row and zero column if n is odd\n    if (n % 2 == 1) {\n        auto Anew = add_zero_row_col(A);\n        auto Bnew = add_zero_row_col(B);\n        return strassen_mm_internal(Anew, Bnew, true);\n    }\n\n    // Divide the matrices into four smaller submatrices\n    int half = n / 2;\n    vector<vector<T>> A11(half, vector<T>(half));\n    vector<vector<T>> A12(half, vector<T>(half));\n    vector<vector<T>> A21(half, vector<T>(half));\n    vector<vector<T>> A22(half, vector<T>(half));\n    vector<vector<T>> B11(half, vector<T>(half));\n    vector<vector<T>> B12(half, vector<T>(half));\n    vector<vector<T>> B21(half, vector<T>(half));\n    vector<vector<T>> B22(half, vector<T>(half));\n\n    for (int i = 0; i < half; i++) {\n        for (int j = 0; j < half; j++) {\n            A11[i][j] = A[i][j];\n            A12[i][j] = A[i][j + half];\n            A21[i][j] = A[i + half][j];\n            A22[i][j] = A[i + half][j + half];\n            B11[i][j] = B[i][j];\n            B12[i][j] = B[i][j + half];\n            B21[i][j] = B[i + half][j];\n            B22[i][j] = B[i + half][j + half];\n        }\n    }\n\n    auto P1 = strassen_mm_internal((A11 + A22),(B11 + B22));\n    auto P2 = strassen_mm_internal((A21 + A22),B11);\n    auto P3 = strassen_mm_internal(A11,(B12 - B22));\n    auto P4 = strassen_mm_internal(A22,(B21 - B11));\n    auto P5 = strassen_mm_internal((A11+A12),B22);\n    auto P6 = strassen_mm_internal((A21-A11),(B11+B12));\n    auto P7 = strassen_mm_internal((A12 -A22),(B21+B22));\n\n    auto C11= P1+P4-P5+P7;\n    auto C12 = P3 +P5;\n    auto C21 = P2+P4;\n    auto C22 = P1 + P3 -P2 +P6;\n\n    auto size = removelast ? n - 1 : n;\n    vector<vector<T>> C(size, vector<T>(size));\n\n    // Combine the four submatrices into the final result matrix\n    for (int i = 0; i < n / 2; i++) {\n        for (int j = 0; j < n / 2; j++) {\n            C[i][j] = C11[i][j];\n            if (j + n / 2 < size) C[i][j + n / 2] = C12[i][j];\n            if (i + n / 2 < size) C[i + n / 2][j] = C21[i][j];\n            if (i + n / 2 < size && j + n / 2 < size)\n                C[i + n / 2][j + n / 2] = C22[i][j];\n        }\n    }\n\n    return C;\n}\n\n\n\ntemplate <typename T>\nvector<vector<T>> strassen_mm(const vector<vector<T>>& A,\n                              const vector<vector<T>>& B) {\n    return strassen_mm_internal(A, B);\n}\n\ntemplate vector<vector<double>> strassen_mm(const vector<vector<double>>& A,\n                                            const vector<vector<double>>& B);\n\ntemplate vector<vector<float>> strassen_mm(const vector<vector<float>>& A,\n                                           const vector<vector<float>>& B);\n```\n\nI get the correct results but the code performance is very slow (even with -O3 optimization ) - maybe 50 times slower than the simplest  O(n^3) implementation  of matrix multiplication. It is probably because I'm copying data back and forth. Any idea how to improve the performance ?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Constant output for large Matrix Multiplication sizes\r\n                \r\nI am implementing a Matrix Multiplication Code for GPUs, the matrix data type is float and the sizes are very large. So, for large sizes of Matrices I get a constant value 2,147,483,648 which is 2^31.\nI get that it is the max range of float, but is there any way by which I can increase the range of  my output to get correct Matrix Multiplication answer without changing the data type?\n    ", "Answer": "\r\nSo, It was a basic mistake I was doing which restricted the value of my output matrices to 2,147,483,648.\n\n```\nfor(int i = 0; i < k; i++) \n    {\n        sum += A_gpu[row * k + i] * B_gpu[i * m + col];\n    }\n    C_gpu[row * m + col] = sum;\n```\n\n\nThis is a part of my code and the problem was that the variable sum had integer datatype. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication algorithm\r\n                \r\nI have mat2, mat3 and mat4 classes which denote 2x2, 3x3 and 4x4 matrices, respectively. I am trying to implement a multiplication algorithm by overloading the ```\n*=```\n operator. Taking mat4 as an example, here is the declaration:\n\n```\nmat4& operator*=(const mat4 &m);\n```\n\n\nThe multiplication algorithm will return a reference to the calling object. What that means is it will return a reference to ```\nthis```\n. The implementation of the multiplication algorithm is defined thus:\n\n```\nmat4& mat4::operator *=(const mat4& m)\n{\n    for (uint i = 0; i < row(); i++)\n    {\n        for (uint j = 0; j < col(); j++)\n        {\n            for (uint k = 0; k < m.col(); k++)\n            {\n                data[i][j] += (data[i][k] * m.data[k][j]);\n            }\n        }\n    }\n\n    return *this;\n}\n```\n\n\nWhere ```\nuint```\n is a typedef of ```\nunsigned int```\n. Because the operator overload is a class function, there's no need to have a lhs matrix but instead provide a rhs matrix which I call ```\nm```\n. The functions ```\nrow()```\n and ```\ncol()```\n in this case will always return 4 since it is a mat4x4; these functions are part of the mat4 class. The attribute ```\ndata```\n is a 2-dimensional array of floats with a fixed size. The problem is that this algorithm doesn't produce the correct result. For example:\n\n```\nmat4 m1(1.0, 0.0, 0.0, 30.0,\n        0.0, 1.0, 0.0, 30.0,\n        0.0, 0.0, 1.0, 30.0,\n        0.0, 0.0, 0.0, 1.0);\n\nmat4 m2(23.0, 21.0, 0.0, 1.0,\n        10.0, 9.0, 1.0, 0.0,\n        1.0, 2.0, 0.0, 0.0,\n        3.0, 2.0, 9.0, 9.0);\n\nauto result = m1 * m2;\n\ncout << result << endl;\n```\n\n\nJust so you know, I overloaded the ```\n<<```\n operator as well to make ```\ncout```\ns with the matrices possible and easy. Just so you are also aware, my matrices are column-major because I intend to use them with OpenGL. Thus something like ```\nm1.data[3][2]```\n means 4th column, 3rd row. The result is hardly what it is supposed to be:\n\n```\nmat4 = \n[ \n    24   5040   5040    54\n    10   2110   2110    40\n    1    212    213     31\n    0    0      0       1\n]\n```\n\n\nMy issue is that the multiplication algorithm doesn't work and produces the correct result. How do I go about correcting the algorithm so that it produces the correct result as a result of matrix multiplication?\n\nI currently overload the ```\n*```\n operator like so:\n\n```\nmat4 mat4::operator *(const mat4& m) const\n{\n    mat4 result = *this;\n    result *= m;\n    return result;\n}\n```\n\n\nThis utilises the ```\n*=```\n operator overload. Unfortunately the ```\n*```\n operator overload won't work either.\n    ", "Answer": "\r\nThe problem is you are writing over the same matrix as you are reading from. This means you are using some of the values from the resultant matrix in the calculation instead of the values in the original matrix.\n\nTo fix this create a temporary 2 dimensional array to which you can write to:\n\n```\nmat4& mat4::operator *=(const mat4& m)\n{\n    float buffer[4][4]; // Temporary matrix\n    for (uint i = 0; i < row(); i++)\n    {\n        for (uint j = 0; j < col(); j++)\n        {\n            // You might want to set the values in the buffer to 0 just in case:\n            buffer[i][j] = 0.0f;\n            for (uint k = 0; k < m.col(); k++)\n            {\n                buffer[i][j] += data[i][k] * m.data[k][j];\n            }\n        }\n    }\n\n    // Now that all the values of the new matrix have been calculated you can write to data\n    for (uint i = 0; i < row(); i++)\n    {\n        for (uint j = 0; j < col(); j++)\n        {\n           data[i][j] = buffer[i][j];\n        }\n    }\n\n    return *this;\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Naïve Tiled Matrix Multiplication with Python\r\n                \r\nI'm trying to write a function to perform the matrix multiplication operation on two large matrices that are split up into smaller matrices (tiles), and I'm having difficulty conceptualizing a valid approach.\nIn the script below, two tensors/matrices, ```\na```\n and ```\nb```\n, are segmented into multiple sub-tensors/matrices (tiles) of shape ```\ntile_shape```\n. Given these tiles, I would like to perform operations that give the same result as a.dot(b), i.e., vector-matrix multiplication.\nFor simplicity sake, tiles are all the same shape, and are zero padded for cases where the length/width of a given tensor is not divisible by ```\ntile shape```\n. I would like the approach to be modular, so that any given valid input shapes and tile shapes can be specified.  Any help is greatly appreciated!\n```\nimport numpy as np\nimport math\n\nclass Tiles:\n    def __init__(self, tiles, tensor_shape):\n        self.tiles = tiles\n        self.tile_shape = tiles.shape[-2:]\n        self.tensor_shape = tensor_shape\n\ndef gen_tiles(tensor, tile_shape):\n    assert len(tensor.shape) == 2\n    tiles = np.empty((math.ceil(tensor.shape[0] / tile_shape[0]), math.ceil(tensor.shape[1] / tile_shape[1]), tile_shape[0], tile_shape[1]))\n    for i in range(0, tiles.shape[0]):\n        for j in range(0, tiles.shape[1]):\n            tile = tensor[i * tile_shape[0]:max((i + 1) * tile_shape[0], tile_shape[0] - 1), j * tile_shape[1]:max((j + 1) * tile_shape[1], tile_shape[1] - 1)]\n            padded_tile = np.zeros(shape=tile_shape)\n            padded_tile[:tile.shape[0],:tile.shape[1]] = tile\n            tiles[i][j][:][:] = padded_tile\n\n    return Tiles(tiles, tensor.shape)\n\ndef matmul_tiles(a, b):\n    assert a.tensor_shape[1] == b.tensor_shape[0] and a.tile_shape == b.tile_shape\n    result = np.zeros((a.tensor_shape[0], b.tensor_shape[1]))\n    print(a.tiles.shape[0:2])\n    print(b.tiles.shape[0:2])\n    # Compute matrix multiplication using tiles\n\ntile_shape = (2, 2)\na = np.random.randint(10, size=(2, 2))\nb = np.random.randint(10, size=(2, 3))\na_tiles = gen_tiles(a, tile_shape)\nb_tiles = gen_tiles(b, tile_shape)\nproduct = a.dot(b)\ntile_product = matmul_tiles(a_tiles, b_tiles)\nassert np.isclose(product, tile_product)\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Binary matrix multiplication bit twiddling hack\r\n                \r\nAbstract\nHi, suppose you have two different independent 64-bit binary matrices ```\nA```\n and ```\nT```\n (```\nT```\n is another matrix that is stored in transposed form, using the transposed version of matrix allows during multiplication to operate on ```\nT```\n's rows rather than columns which is super cool for binary arithmetic) and you want to multiply these matrices the only thing is that matrix multiplication result is truncated to 64-bits and if you yield to a value greater that ```\n1```\n in some specific matrix cell the resulting matrix cell will contain ```\n1```\n otherwise ```\n0```\n\nExample\n```\n   A        T\n00000001 01111101 \n01010100 01100101 \n10010111 00010100 \n10110000 00011000 <-- This matrix is transposed\n11000100 00111110 \n10000011 10101111 \n11110101 11000100 \n10100000 01100010 \n```\n\nBinary and traditional multiplication results:\n```\n Binary  Traditional\n11000100  11000100\n11111111  32212121\n11111111  32213421\n11111111  21112211\n11101111  22101231\n11001111  11001311\n11111111  54213432\n11001111  11001211\n```\n\nQuestion\nHow do you multiply these matrices in a way described above in most efficient matter?\nP.S\nI was trying to take advantage of binary ```\nand```\n (i.e. ```\n&```\n operator) instead of performing multiplication on separate bits, in that case I had to prepare data for multiplication:\n```\nulong u;\n\nu = T & 0xFF;\nu = (u << 00) + (u << 08) + (u << 16) + (u << 24)\n  + (u << 32) + (u << 40) + (u << 48) + (u << 56);\n```\n\nnow by performing binary ```\nand```\n over two integers ```\nA```\n and ```\nu```\n it would yield to the following:\n```\n   A        u        R        C\n00000001 01111101 00000001    1\n01010100 01111101 01010100    3\n10010111 01111101 00010101    3\n10110000 01111101 00110000    2\n11000100 01111101 01000100    2\n10000011 01111101 00000001    1\n11110101 01111101 01110101    5\n10100000 01111101 00100000    1\n```\n\nIn the example above ```\nR```\n contains result of multiplication of ```\nA```\n bits to ```\nu```\n bits and to obtain the final value we must ```\nsum```\n all bits in a row. Notice that column ```\nC```\n contains values equal to ones found in first column of resulting ```\nTraditional```\n matrix multiplication above. The problem is that during this step I have to operate on a separate bits which I think is sub-optimal approach, I've read through http://graphics.stanford.edu/~seander/bithacks.html looking for a way to do that on parallel but no luck, if anyone has any idea on how to \"flatten\" and \"merge\" the values located in ```\nR```\n column into resulting 64-bit matrix, I would appreciate if you drop me several lines,\nThank you,\nEdit\nWith big thank you to David Eisenstat, the final algorithm would then look like:\n```\nvar A = ...;\nvar T = ...; // T == transpose(t), t is original matrix, algorithm works with transposed matrix\n\nvar D = 0x8040201008040201UL;\n\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D);\n```\n\nThe following piece of code:\n```\n    public static void Main (string[] args){\n        ulong U;\n        var Random = new Xor128 ();\n\n        var timer = DateTime.Now;\n\n        var A = Random.As<IUniformRandom<UInt64>>().Evaluate();\n        var T = Random.As<IUniformRandom<UInt64>>().Evaluate();\n\n        var steps = 10000000;\n\n        for (var i = 0; i < steps; i++) {\n            ulong r = 0;\n\n            var d = 0x8040201008040201UL;\n\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d);\n        }\n\n        Console.WriteLine (DateTime.Now - timer);\n\n\n        var m1 = new Int32[8,8];\n        var m2 = new Int32[8,8];\n        var m3 = new Int32[8,8];\n\n        for (int row = 0; row < 8; row++) {\n            for (int col = 0; col < 8; col++) {\n                m1 [row, col] = Random.As<IUniformRandom<Int32>> ().Evaluate(0, 1);\n                m2 [row, col] = Random.As<IUniformRandom<Int32>> ().Evaluate(0, 1);\n                m3 [row, col] = Random.As<IUniformRandom<Int32>> ().Evaluate(0, 1);\n            }\n        }\n\n        timer = DateTime.Now;\n\n        for (int i = 0; i < steps; i++) {\n            for (int row = 0; row < 8; row++) {\n                for (int col = 0; col < 8; col++) {\n                    var sum = 0;\n\n                    for (int temp = 0; temp < 8; temp++) {\n                        sum += m1 [row, temp] * m2 [temp, row];\n                    }\n\n                    m3 [row, col] = sum;\n                }\n            }\n        }\n\n        Console.WriteLine (DateTime.Now - timer);\n    }\n```\n\nShows me the following results:\n```\n00:00:02.4035870\n00:00:57.5147150\n```\n\nAnd that's a 23x performance improvement under Mac OS X / Mono, thanks everyone\n    ", "Answer": "\r\nI'm not sure about most efficient, but here's something to try. The following sequence of instructions computes the main diagonal of the product A * T'. Rotate both T and D by 8 bits and repeat for 7 more iterations.\n\n```\n// uint64_t A, T;\nuint64_t D = UINT64_C(0x8040201008040201);\nuint64_t P = A & T;\n// test whether each byte is nonzero\nP |= P >> 1;\nP |= P >> 2;\nP |= P >> 4;\nP &= UINT64_C(0x0101010101010101);\n// fill each nonzero byte with ones\nP *= 255;  // or P = (P << 8) - P;\n// leave only the current diagonal\nP &= D;\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Binary matrix multiplication bit twiddling hack\r\n                \r\nAbstract\nHi, suppose you have two different independent 64-bit binary matrices ```\nA```\n and ```\nT```\n (```\nT```\n is another matrix that is stored in transposed form, using the transposed version of matrix allows during multiplication to operate on ```\nT```\n's rows rather than columns which is super cool for binary arithmetic) and you want to multiply these matrices the only thing is that matrix multiplication result is truncated to 64-bits and if you yield to a value greater that ```\n1```\n in some specific matrix cell the resulting matrix cell will contain ```\n1```\n otherwise ```\n0```\n\nExample\n```\n   A        T\n00000001 01111101 \n01010100 01100101 \n10010111 00010100 \n10110000 00011000 <-- This matrix is transposed\n11000100 00111110 \n10000011 10101111 \n11110101 11000100 \n10100000 01100010 \n```\n\nBinary and traditional multiplication results:\n```\n Binary  Traditional\n11000100  11000100\n11111111  32212121\n11111111  32213421\n11111111  21112211\n11101111  22101231\n11001111  11001311\n11111111  54213432\n11001111  11001211\n```\n\nQuestion\nHow do you multiply these matrices in a way described above in most efficient matter?\nP.S\nI was trying to take advantage of binary ```\nand```\n (i.e. ```\n&```\n operator) instead of performing multiplication on separate bits, in that case I had to prepare data for multiplication:\n```\nulong u;\n\nu = T & 0xFF;\nu = (u << 00) + (u << 08) + (u << 16) + (u << 24)\n  + (u << 32) + (u << 40) + (u << 48) + (u << 56);\n```\n\nnow by performing binary ```\nand```\n over two integers ```\nA```\n and ```\nu```\n it would yield to the following:\n```\n   A        u        R        C\n00000001 01111101 00000001    1\n01010100 01111101 01010100    3\n10010111 01111101 00010101    3\n10110000 01111101 00110000    2\n11000100 01111101 01000100    2\n10000011 01111101 00000001    1\n11110101 01111101 01110101    5\n10100000 01111101 00100000    1\n```\n\nIn the example above ```\nR```\n contains result of multiplication of ```\nA```\n bits to ```\nu```\n bits and to obtain the final value we must ```\nsum```\n all bits in a row. Notice that column ```\nC```\n contains values equal to ones found in first column of resulting ```\nTraditional```\n matrix multiplication above. The problem is that during this step I have to operate on a separate bits which I think is sub-optimal approach, I've read through http://graphics.stanford.edu/~seander/bithacks.html looking for a way to do that on parallel but no luck, if anyone has any idea on how to \"flatten\" and \"merge\" the values located in ```\nR```\n column into resulting 64-bit matrix, I would appreciate if you drop me several lines,\nThank you,\nEdit\nWith big thank you to David Eisenstat, the final algorithm would then look like:\n```\nvar A = ...;\nvar T = ...; // T == transpose(t), t is original matrix, algorithm works with transposed matrix\n\nvar D = 0x8040201008040201UL;\n\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D); T = (T << 8) | (T >> 56); D = (D << 8) | (D >> 56);\nU = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & D);\n```\n\nThe following piece of code:\n```\n    public static void Main (string[] args){\n        ulong U;\n        var Random = new Xor128 ();\n\n        var timer = DateTime.Now;\n\n        var A = Random.As<IUniformRandom<UInt64>>().Evaluate();\n        var T = Random.As<IUniformRandom<UInt64>>().Evaluate();\n\n        var steps = 10000000;\n\n        for (var i = 0; i < steps; i++) {\n            ulong r = 0;\n\n            var d = 0x8040201008040201UL;\n\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d); T = (T << 8) | (T >> 56); d = (d << 8) | (d >> 56);\n            U = A & T; U |= U >> 1; U |= U >> 2; U |= U >> 4; U &= 0x0101010101010101UL; U = (U << 8) - U; r |= (U & d);\n        }\n\n        Console.WriteLine (DateTime.Now - timer);\n\n\n        var m1 = new Int32[8,8];\n        var m2 = new Int32[8,8];\n        var m3 = new Int32[8,8];\n\n        for (int row = 0; row < 8; row++) {\n            for (int col = 0; col < 8; col++) {\n                m1 [row, col] = Random.As<IUniformRandom<Int32>> ().Evaluate(0, 1);\n                m2 [row, col] = Random.As<IUniformRandom<Int32>> ().Evaluate(0, 1);\n                m3 [row, col] = Random.As<IUniformRandom<Int32>> ().Evaluate(0, 1);\n            }\n        }\n\n        timer = DateTime.Now;\n\n        for (int i = 0; i < steps; i++) {\n            for (int row = 0; row < 8; row++) {\n                for (int col = 0; col < 8; col++) {\n                    var sum = 0;\n\n                    for (int temp = 0; temp < 8; temp++) {\n                        sum += m1 [row, temp] * m2 [temp, row];\n                    }\n\n                    m3 [row, col] = sum;\n                }\n            }\n        }\n\n        Console.WriteLine (DateTime.Now - timer);\n    }\n```\n\nShows me the following results:\n```\n00:00:02.4035870\n00:00:57.5147150\n```\n\nAnd that's a 23x performance improvement under Mac OS X / Mono, thanks everyone\n    ", "Answer": "\r\nI'm not sure about most efficient, but here's something to try. The following sequence of instructions computes the main diagonal of the product A * T'. Rotate both T and D by 8 bits and repeat for 7 more iterations.\n\n```\n// uint64_t A, T;\nuint64_t D = UINT64_C(0x8040201008040201);\nuint64_t P = A & T;\n// test whether each byte is nonzero\nP |= P >> 1;\nP |= P >> 2;\nP |= P >> 4;\nP &= UINT64_C(0x0101010101010101);\n// fill each nonzero byte with ones\nP *= 255;  // or P = (P << 8) - P;\n// leave only the current diagonal\nP &= D;\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in a cpp file for Matlab\r\n                \r\nHow would I do a matrix multiplication in ```\ncpp```\n format that would after be compiled into a ```\nmex```\n file?\n\nMy normal matrix multiplication in a Matlab script is as follow:\n\n```\ncMatrix = (1 / r) * pfMatrix * wcMatrix; %here pfMatrix is 2x3 and wcMatrix is 3x8\n% Hence cMatrix is 2x8\n% r is a scalar\n```\n\n\nThe pfMatrix, wcMatrix and r are declared correctly in the ```\ncpp```\n file and they have the same values as in the script. However cMatrix doesn't give me the same results. Here the implementation of the Matrix multiplication in the ```\ncpp```\n :\n\n```\n    int i, n, j;\n    for (i = 0; i<1; i++)\n    {\n        for (n = 0; n<7; n++)\n        {\n            for (j = 0; j<2; j++)\n            {\n                d->cMatrix[i][n] += (d->pfMatrix[i][j]) * (d->wcMatrix[j][n]);\n            }\n            d->cMatrix[i][n] = (1 / d->r) * d->cMatrix[i][n];\n        }\n    }\n```\n\n\nEdit:\n\nI modified the loop following Ben Voigt answer. The results in ```\ncMatrix```\n are still not identical to the one calculated from the Matlab script.\n\nFor example :\n\n```\npfMatrix = [7937.91049469652,0,512;0,7933.81033431703,384];\nwcMatrix = [-0.880633810389421,-1.04063381038942,-1.04063381038942,-0.880633810389421,-0.815633810389421,-1.10563381038942,-1.10563381038942,-0.815633810389421;-0.125,-0.125,0.125,0.125,-0.29,-0.29,0.29,0.29;100,100,100,100,100,100,100,100];\nr = 100;\n```\n\n\nIn this case, ```\ncMatrix(1,1)```\n is :\n\n```\n(pfMatrix(1,1)*wcMatrix(1,1) + pfMatrix(1,2)*wcMatrix(2,1) + pfMatrix(1,3)*wcMatrix(3,1)) / r = 442.09\n```\n\n\nHowever, with the ```\nmex```\n file the equivalent result is ```\n959```\n.\n\nEdit #2:\n\nI found the error in an element of ```\npfMatrix```\n that was not declared correctly (missing a division by 2). So the answer of Ben Voigt is working correctly. However, there is still a slight difference between the two results (Matlab script gives 442 and the mex gives 447, could it be a results of different data type?).\n\nEdit #3:\n\nFound the error and it was not related with the matrix multiplication loop.\n    ", "Answer": "\r\nUsing your result matrix as scratch space is not a great idea.  The compiler has to worry about aliasing, which means it can't optimize.\n\nTry an explicit working variable, which also provides a convenient place to zero it:\n\n```\nfor (int i = 0; i < 2; ++i) {\n    for (int n = 0; n < 8; ++n) {\n        double accum = 0.0;\n        for (int j = 0; j < 3; ++j) {\n            accum += (d->pfMatrix[i][j]) * (d->wcMatrix[j][n]);\n        }\n        d->cMatrix[i][n] = accum / d->r;\n    }\n}\n```\n\n\nYour ranges were also wrong, which I've fixed.\n\n(Also note that good performance on large matrices requires banding to get good cache behavior, however that shouldn't be an issue on a product of this size.)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication using pairs\r\n                \r\nI am looking into alternate ways to do a Matrix Multiplication. Instead of storing my matrix as a two-dimensional array, I am using a vector such as \n\n```\nvector<pair<pair<int,int >,int > > \n```\n\n\nto store my matrix. The pair within my pair (pair) stores my indices (i,j) and the other int stores the value for the given (i,j) pair. I thought I might have some luck implementing my sparse array this way.\n\nThe problem is when I try to multiply this matrix with itself. \n\nIf this was a 2-d array implementation, I would have multiplied the matrix as follows:\n\n```\n   for(i=0; i<row1; i++)\n    {\n        for(j=0; j<col1; j++)\n        {\n          C[i][j] = 0;\n         for(k=0; k<col2; k++) \n           C[i][j] += A[i][j] * A[j][k];\n      }\n    }\n```\n\n\nCan somebody point out a way to achieve the same result using my vector of 'pair of pairs'?\n\nThanks\n    ", "Answer": "\r\nSo far you can store one value at one location. If you want to store several nonzero entries in the matrix, you will need more pairs of pairs in a larger structure.\n\n```\nmap<pair<int, int>, int>```\n would be the next logical step. Now you can iterate over rows because the ```\nfirst```\n coordinate is more significant in the ```\nmap```\n's sorting order.\n\nTo iterate over columns, reverse that precedence:\n\n```\ntypedef pair<int, int> mx_coord;\nstruct reverse_compare {\n    bool operator() (mx_coord const &l, mx_coord const &r) const\n        { return l.second < r.second? true :\n                 r.second < l.second? false : l.first < r.first; }\n};\n\ntypedef map< mx_coord, int > matrix;\ntypedef map< mx_coord, int, reverse_compare > matrix_transpose;\n```\n\n\nTo multiply A by B, transpose B and iterate over A and B, multiplying any elements whose less-significant coordinates match, as the ordering naturally lets you go line-by-line and column-by-column.\n\nTo transpose B:\n\n```\nmatrix_transpose b_t( b.begin(), b.end() ); // complexity: n log n\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "C++ matrix multiplication rows and cols\r\n                \r\nHello guys i'm trying to implement large matrix multiplication with c++ here is the code : \n\nmain.cpp\n\n```\n#include <iostream>\n#include <ctime>\n#include \"sauvegarder.h\"\n#include \"restaurer.h\"\nusing namespace std;\n\nconst int ligne = 2048;\nconst int colonne = 2048;\nint main()\n{\n    static float host_matrice_1[ligne][colonne];\n    static float host_matrice_2[ligne][colonne];\n    static float host_matrice_3[ligne][colonne];\n    clock_t sequentiel;\n    cudaEvent_t start, stop;\n    cudaEventCreate(&start);\n    cudaEventCreate(&stop);\n    //clock_t parallele;\n\n    //création des matrices avec des valeurs aléatoire\n\n    for (int i = 0; i < ligne; i++)\n    {\n        for (int j = 0; j < colonne; j++)\n        {\n            host_matrice_1[i][j] = rand() * 1000;\n            host_matrice_2[i][j] = rand() * 1000;\n        }\n    }\n\n    sauvegarder(host_matrice_1, \"matrice_1.txt\");\n    sauvegarder(host_matrice_2, \"matrice_2.txt\");\n\n    //debut de calcul de temps + multiplication\n    sequentiel = clock();\n\n    for (int i = 0; i < ligne; i++)\n    {\n        for (int j = 0; j < colonne; j++)\n        {\n            host_matrice_3[i][j] = 0;\n            for (int k = 0; k < ligne; k++)\n            {\n                host_matrice_3[i][j] = host_matrice_3[i][j] + host_matrice_1[i][k] * host_matrice_2[k][j];\n            }\n        }\n    }\n\n    sequentiel = clock() - sequentiel;\n\n    cout << \"Temps Cpu: \" << ((float)sequentiel) / CLOCKS_PER_SEC * 1000 << \"ms\" << endl;\nsauvegarde.h\n\n#include <iostream>\n#include <fstream>\n\nusing namespace std;\nconst int rows = 2048;\nconst int cols = 2048;\nvoid sauvegarder(static float Mat[rows][cols], string filename);\n```\n\n\nsauvegarde.cpp \n\n```\n#include \"sauvegarder.h\"\n\nvoid sauvegarder(static float Mat[rows][cols], string filename)\n{\n    ofstream output_file(filename);\n\n    for (int ligne = 0; ligne != rows; ligne++)\n    {\n        if (ligne != 0)\n        {\n            output_file << '\\n';\n        }\n        for (int col = 0; col != cols; col++)\n        {\n            if (col != 0)\n            {\n                output_file << '\\t';\n            }\n            output_file << Mat[ligne][col];\n        }\n    }\n}\n```\n\n\nrestaurer.h\n\n```\n#include <iostream>\n#include <fstream>\n#include <sstream>\n#include <string>\n\nusing namespace std;\nconst int ro = 2048;\nconst int co = 2048;\nvoid restorer(static float mat[ro][co], string filename);\n```\n\n\nrestaurer.cpp\n\n```\n#include \"restaurer.h\"\nvoid restorer(static float mat[ro][co], string filename)\n{\n    float x;\n    int row = 0;\n    int col = 0;\n    string lineA;\n    ifstream fileIN(filename);\n\n    //static float tmp;\n    while (getline(fileIN, lineA))\n    {\n        //Pour les chaines de caracteres et pas caractere.\n        istringstream streamA(lineA);\n        col = 0;\n        while (streamA >> x)\n        {\n            mat[row][col] = x;\n            col++;\n        }\n        row++;\n    }\n}\n```\n\n\nthe problem is that when i want to change number of rows and cols i need to change it in every header and even in main.cpp , how can i make it changeable from one header .\n    ", "Answer": "\r\nThat's probably a bad design for a c++ program. You should be using objects or pointers (with dynamic memory allocation) instead of fixed arrays, allowing any size at runtime (except negatives!).\n\nAnyways, responding to your question, you can create a header file with globals, include that header on every required file, and use those constants:\n\n```\n// globals.h\n// Use preprocessor directives to define the constants once (you can also youse `#pragma once`)\n#ifndef __GLOBALS_H_\n#define __GLOBALS_H_\n\nconst int MATRIX_COLS = 2048;\nconst int MATRIX_ROWS = 2048;\n\n#endif /* __GLOBALS_H_ */\n```\n\n\nAnd use it in your code like this:\n\n```\n#include \"restaurer.h\"\n#include \"globals.h\"\n\nvoid restorer(static float mat[MATRIX_ROWS][MATRIX_COLS], string filename) {\n  // ...\n}\n```\n\n\nDon't forget to replace and remove all of yours ```\nco```\n and ```\nro```\n constants.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Percentage values after matrix multiplication\r\n                \r\nBy matrix multiplication I get the following matrix, which, let's say, shows how many customers who purchased product A, sooner or later, also purchased product B, product C and so on. Obviously, the diagonal values represent 100% of all purchases of a particular product. I'm looking for a way of converting all the values to percentage values. Any ideas? I did have a look at apply(), but didn't find a way to implement the diagonal values.\n\n```\n> # Create a matrix with zeros and ones\n> r <- 500\n> c <- 10\n> t1 <- matrix(rbinom(r*c,1,0.5),r,c)\n> colnames(t1) <- letters[1:10]\n> head(t1)\n     a b c d e f g h i j\n[1,] 1 1 1 0 0 1 1 1 1 0\n[2,] 0 0 0 1 1 0 0 0 1 1\n[3,] 0 1 1 1 0 1 1 1 1 0\n[4,] 1 0 1 1 1 0 0 1 0 1\n[5,] 0 1 0 1 0 0 0 0 0 0\n[6,] 1 0 1 0 1 0 1 0 1 1\n> # Matrix multiplication\n> t2 <- t(t1)%*%t1\n> t2\n    a   b   c   d   e   f   g   h   i   j\na 242 130 121 114 133 117 119 126 123 112\nb 130 248 121 115 128 121 113 127 114 119\nc 121 121 236 108 115 117 115 117 112 117\nd 114 115 108 228 116 117 114 110 118  99\ne 133 128 115 116 258 129 124 132 122 130\nf 117 121 117 117 129 251 123 115 128 125\ng 119 113 115 114 124 123 245 128 130 116\nh 126 127 117 110 132 115 128 248 123 113\ni 123 114 112 118 122 128 130 123 251 116\nj 112 119 117  99 130 125 116 113 116 246\n```\n\n    ", "Answer": "\r\n```\nt3 <- apply(t2, 2, function(v) v/max(v))\n```\n\n\nor\n\n```\nfor (i in 1:ncol(t2)) t2[,i] <- t2[,i]/t2[i,i]\n```\n\n\nI'm assuming you want the asymmetric matrix, i.e. percentage of people who purchased product X who also purchased product Y (which is different from percentage of people who purchased product Y who also purchased product X).\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication Algorithm Breaks\r\n                \r\nI'm trying to implement simple matrix multiplication with 3 loops , o(n^3) , I saw this algorithm many times but it doesn't seem to work with , the program breaks right after the first iteration of the second loop , as for my code , it prints until \"second loop\" one time and the it breaks , here's my code\n```\nvector<vector<int>> getMultiplication(vector<vector<int>> a , vector<vector<int>> b , int r1 , int c1 , int r2 , int c2){\n    vector<vector<int>> ans;\n    cout << r1  << \"\\n\" << c1 << \"\\n\" << r2 << \"\\n\" << c2 << \"\\n\";\n    for(int i = 0; i < r1; i++) {\n        cout << \"first loop\" << \"\\n\";\n        for (int j = 0; j < c2; j++){\n            cout << \"second loop\" << \"\\n\";\n            ans[i][j] = 0;\n            for (int k = 0; k < r2; k++) {\n                cout << \"third loop\" << \"\\n\";\n                ans[i][j] += a[i][k] * b[k][j];\n            }\n        }\n    }\n\n    return ans;\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "cuda matrix multiplication by columns\r\n                \r\nI'm trying to do matrix multiplication in cuda.  My implementation is different from the cuda example.  \n\nThe cuda example (from the cuda samples) performs matrix multiplication by multiplying each value in the row of the first matrix by each value in the column of the second matrix, then summing the products and storing it in an output vector at the index of the row from the first matrix.  \n\nMy implementation multiplies each value in the column of the first matrix by the single value of the row of the second matrix, where the row index = column index.  It then has an output vector in global memory that has each of its indices updated.\n\nThe cuda example implementation can have a single thread update each index in the output vector, whereas my implementation can have multiple threads updating each index.\n\nThe results that I get show only some of the values.  For example, if I had it do 4 iterations of updates, it would only do 2 or 1.  \n\nI think that the threads might be interfering with each other since they're all trying to write to the same indices of the vector in global memory.  So maybe, while one thread is writing to an index, the other might not be able to insert its value and update the index?\n\nJust wondering if this assessment makes sense.\n\nFor example.  To multiply the following two matrices:\n\n```\n[3 0 0 2         [1       [a\n 3 0 0 2    x     2   =    b\n 3 0 0 0          3        c\n 0 1 1 0]         4]       d]\n```\n\n\nThe Cuda sample does matrix multiplication in the following way using 4 threads where a,b,c,d are stored in global memory:\n\n```\nThread 0:   3*1 + 0*2 + 0*3 + 2*4 = a\nThread 1:   3*1 + 0*2 + 0*3 + 2*4 = b\nThread 2:   3*1 + 0*2 + 0*3 + 0*4 = c\nThread 3:   0*1 + 1*2 + 1*3 + 0*4 = d\n```\n\n\nMy implementation looks like this:\n\n```\na = b = c = d = 0\n\nThread 0:\n3*1 += a\n3*1 += b\n3*1 += c\n0*1 += d\n\nThread 1:\n0*2 += a\n0*2 += b\n0*2 += c\n1*2 += d\n\nThread 2:\n0*3 += a\n0*3 += b\n0*3 += c\n1*3 += d\n\nThread 3:\n2*4 += a\n2*4 += b\n0*4 += c\n0*4 += d\n```\n\n\nSo at one time all four threads could be trying to update one of the indices.\n    ", "Answer": "\r\nIn order to fix this issue, I used atomicAdd to do the += operation.  When a thread performs the operation 3*1 += a (for example), it does three things.  \n\n\n  \n  It gets the previous value of a \n  It updates the value by doing 3*1 + previous value of a \n  It then stores the new value into a\n  \n\n\nBy using atomicAdd it guarantees that these operations can occur by the thread without interruption from other threads.  If atomicAdd is not used, thread0 could get the previous value of a and while thread0 is updating the value, thread1 could get the previous value of a and perform its own update.  In this way a += operation would not occur because the threads aren't able to finish their operations.\n\nIf a += 3*1 is used instead of atomicAdd(&a, 3*1), then it is possible for thread1 to interfere and change the value of thread0 before thread0 finishes what it's doing.  It creates a race condition. \n\natomicAdd is a += operation.  You would use the following code to perform the operation:\n\n```\n__global__ void kernel(){    \nint a = 0;   \natomicAdd(&a, 3*1);  //is the same as a += 3*1\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix-matrix multiplication between A and B, with A a random matrix\r\n                \r\nI am working on a special matrix-matrix multiplication (```\nAxB```\n) in CUDA, where ```\nA```\n is a random ```\nMxM```\n matrix and ```\nB```\n is ```\nMxN```\n matrix. In following code, ```\nM```\n is just ```\n2000```\n but in practical case, it will be replaced with big number so to give more than ```\n2GB```\n matrix for ```\nA```\n. Actually, all elements of ```\nA```\n will be random and limited to some range so will be generated by a randomize function. \n\nI have written the code below in which each element of ```\nA```\n is randomly randomly picked up from an array so the original ```\nAxB```\n will be modified as a vector of length ```\nM```\n multiplied with ```\nB```\n. Here is how I write my code but it seems that it doesn't work\n\n```\n#include <iostream>\n#include <cusp/complex.h>\n\nusing namespace std;\n\n#define M 2000\n#define N 300\n\ntypedef cusp::complex<double> Complex;\n\n__global__ void MVult(Complex* ad, Complex* bd, Complex* cd, int m1, int n1, int n2) \n{\n  int x = (blockIdx.x * blockDim.x) + threadIdx.x;\n  int y = (blockIdx.y * blockDim.y) + threadIdx.y;\n\n  if(x < n2 && y < m1) \n  {   \n    Complex sum = Complex(0.0, 0.0);\n    int ridx = (rand()%(M-1)); // here I randomize the starting ridx \n    for(int i=0; i<n1; i++) sum += ad[ridx + i] * bd[i * n2 + x];\n    cd[y * n2 + x] = v;\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  std::vector< Complex > _A(2*M+1);\n  std::vector< Complex > _B(M*N);\n  Complex *A, *B, *C;\n\n  cudaMalloc((void**)&A, (2*M+1)*sizeof(Complex));\n  cudaMalloc((void**)&B, M*N*sizeof(Complex));\n  cudaMalloc((void**)&C, M*N*sizeof(Complex));\n\n  for (int i=0; i<2*M+1; i++) _A[i] = Complex((double)i, (double)i);\n  for (int i=0; i<M*N; i++) _B[i] = Complex(1.0, 0.0);\n\n  cudaMemcpy( A, &_A[0], (2*M+1)*sizeof(Complex), cudaMemcpyHostToDevice );\n  cudaMemcpy( B, &_B[0], (M*N)*sizeof(Complex), cudaMemcpyHostToDevice );\n\n  dim3 block(32, 32);           \n  dim3 grid((N+31)/32, (M+31)/32);\n\n  MVult<<<grid, block>>>(A, B, C, M, M, N);\n  cudaMemcpy(&_B[0], &C[0], (M*N)*sizeof(Complex), cudaMemcpyDeviceToHost);\n\n  cudaFree(A);\n  cudaFree(B);\n  cudaFree(C);\n\n  return 0;\n}\n```\n\n\nI try to use CPU loop to loop it ```\nM```\n times and each time run vector and matrix multiplication (done in CUDA), but it is too slow. I am looking for a faster way to solve the problem.\n    ", "Answer": "\r\nYour code will be slow for two main reasons:\n\n\nIn the way you are constructing matrix ```\nA```\n, you are randomly accessing global memory, so preventing coalesced accesses;\nAs pointed out by @talonmies in his comment below, you are implementing your own matrix-vector multiplication routine, which will be surely slower than highly optimized routines as ```\ncuBLAS```\n.\n\n\nTo speed-up your code, instead of using your ```\n__global__```\n function ```\nMVult```\n, you could/should use \n\n\n```\ncuRAND```\n to fill the matrix ```\nA```\n with random numbers;\n```\ncuBLAS```\n to perform the matrix multiplication between ```\nA```\n and ```\nB```\n, and, in particular, ```\ncublasCgemm()```\n for single precision complex calculations. \n\n\nIf matrix ```\nA```\n is too large, then you can try to divide the computation of ```\nA*B```\n into smaller tiles and then using the batch functionality of ```\ncuBLAS```\n (using ```\ncublasSetStream()```\n) to try achieving concurrent execution using CUDA streams.\n\nYou might also wish to take a look at the following example using also thrust:\n\nMatrix multiplication on GPU using CUDA with CUBLAS, CURAND and Thrust\n\nAs also suggested by @talonmies, you might also wish to rethink your approach. For example, if ```\nA```\n is a random matrix, then ```\nA*B```\n will be random too. Is there the possibility to exploit the statistics of ```\nA```\n and possibly a priori knowledge on ```\nB```\n to construct the matrix ```\nA*B```\n directly by a stochastic approach without the need to using matrix multiplications?\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication and solve_ivp\r\n                \r\nI try to simulate a LTI system using Python. The structure is xDot = Ax. I defined the system dynamics as a function I then call using ```\nsolve_ivp```\n. Calling the function itself works, but simulating the system results in the following error\n```\nValueError: matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)\n```\n\nfor the line with the matrix multiplication in the system dynamics definition. Below is the code.\n```\nimport numpy as np\nfrom scipy import integrate\nimport matplotlib.pyplot as plt\n\n# System Parameters\nl = 1 # Pendulum length\ng = 9.81 # gravity\n\n# Initial Conditions\nx0 = np.array([np.pi/2, 0])\n\n# Simulation parameters\ntStart = 0\ntEnd = 4\nt_span = [tStart, tEnd]\nt = np.linspace(tStart,tEnd,10) # Simulation time\n\n# System matrices\nA = np.array([[0, 1],[-g/l, 0]])\n\ndef dynamics(x, t):\n    xdot = -A@x\n    return xdot\n\ny = integrate.solve_ivp(dynamics, t_span, x0)\n```\n\nHow do I need to adjust the system definition to make this work?\n    ", "Answer": "\r\nAccording to the docs the signature of the dynamics should be ```\ndynamics(t, x)```\n with the scalar ```\nt```\n as the first argument. This is how ```\nscipy.integrate.solve_ivp```\n calls the given dynamics.\nIn your case, the error is caused by the fact that the matrix ```\nA```\n is multiplied with the scalar ```\nt```\n and the error message ```\nInput operand 1 does not have enough dimensions```\n indicates that the matrix multiplication goes wrong.\nThe solution therefore is to switch the arguments to ```\ndynamics(t, x)```\n. Inside ```\ndynamics```\n you can ignore the parameter ```\nt```\n as long as your matrix ```\nA```\n is not time-dependent.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Numpy efficient big matrix multiplication\r\n                \r\nTo store big matrix on disk I use numpy.memmap.\n\nHere is a sample code to test big matrix multiplication:\n\n```\nimport numpy as np\nimport time\n\nrows= 10000 # it can be large for example 1kk\ncols= 1000\n\n#create some data in memory\ndata = np.arange(rows*cols, dtype='float32') \ndata.resize((rows,cols))\n\n#create file on disk\nfp0 = np.memmap('C:/data_0', dtype='float32', mode='w+', shape=(rows,cols))\nfp1 = np.memmap('C:/data_1', dtype='float32', mode='w+', shape=(rows,cols))\n\nfp0[:]=data[:]\nfp1[:]=data[:]\n\n#matrix transpose test\ntr = np.memmap('C:/data_tr', dtype='float32', mode='w+', shape=(cols,rows))\ntr= np.transpose(fp1)  #memory consumption?\nprint fp1.shape\nprint tr.shape\n\nres = np.memmap('C:/data_res', dtype='float32', mode='w+', shape=(rows,rows))\nt0 = time.time()\n# redifinition ? res= np.dot(fp0,tr) #takes 342 seconds on my machine, if I multiplicate matrices in RAM it takes 345 seconds (I thinks it's a strange result)\nres[:]= np.dot(fp0,tr) # assignment ?\nprint res.shape\nprint (time.time() - t0)\n```\n\n\nSo my questions are :\n\n\nHow to restrict memory consumtion of aplication which is using this procedure to some value for example to 100Mb(or 1Gb or something else).Also I don't understand how to estimate memory consumtion of procedure (I think memory is only allocated when \"data\" variable is created, but how much memory used when we use memmap files?)\nMaybe there is some optimal solution for multiplication of big matrices stored on disk? For example maybe data not optimally stored on disk or readed from disk, not properly chached, and also dot product use only one core.Maybe I should use something like PyTables?\n\n\nAlso I interested in algorithms solving linear system of equations (SVD and others) with restricted memory usage.\nMaybe this algorithms called out-of-core or iterative and I think there some analogy like hard drive<->ram, gpu ram<->cpu ram, cpu ram<->cpu cache.  \n\nAlso here I found some info about matrix multiplication in PyTables.\n\nAlso I found this in R but I need it for Python or Matlab.\n    ", "Answer": "\r\nDask.array provides a numpy interface to large on-disk arrays using blocked algorithms and task scheduling.  It can easily do out-of-core matrix multiplies and other simple-ish numpy operations.\n\nBlocked linear algebra is harder and you might want to check out some of the academic work on this topic.  Dask does support QR and SVD factorizations on tall-and-skinny matrices.\n\nRegardless for large arrays, you really want blocked algorithms, not naive traversals which will hit disk in unpleasant ways.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Running multiple threads for row matrix multiplication\r\n                \r\nI have a program that takes a text file that has ints in it to look like a matrix. It has 2 of these here is an example.\n1 1 1 1\n1 1 1 1\n1 1 1 1.\nI have to use one single thread for each row dot matrix multiplication and then put it into the new matrix. The error I keep getting it that I get a repeat of the same thread number even though once its done the row matrix multiplication the thread should not be used again. The first part of the code is creating the new 2D array for the products of the row dot multiplication. The next set of code is the run() method doing the actual math. I do not know how to not get repeating threads to keep going. Any help is appreciated. ```\nenter code here```\n\n```\nP = new int[x][z];\n                for(int i = 0; i < x; i++) {\n                    for(int j = 0; j < z; j++) {\n                        Thread t = new Thread(new MatrixThread(A,B,P,i,j,y));\n                        t.setName( \"[\" + i + \"] [\" + j + \"]\");\n                        t.start();\n                    }\n                }\n\nprivate static class MatrixThread implements Runnable {\n        private int[][] A,B,P;\n        private int row,col,y;\n        \n        public MatrixThread(int[][] A, int[][] B, int[][] P, int i, int j,int y) {\n            this.A = A;\n            this.B = B;\n            this.P = P;\n            this.row = i;\n            this.col = j;\n            this.y = y;\n        }\n        public void run() {\n            System.out.println(\"Thread \" + Thread.currentThread().getName() + \" starts calculating\");\n            for(int i = 0; i < y; i++) {\n                P[row][col] += A[row][i]* B[col][i];\n            }\n            System.out.println(\"Thread \" + Thread.currentThread().getName() + \" returns cell value \" + P[row][col]);\n        \n\n        }\n    }\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "cublas matrix multiplication not as expected\r\n                \r\nI am trying to replace my gpu block matrix multiplication with cublas but I am not getting what I expect on a 2x2 test case:\n\n```\n#include \"cuda_runtime.h\"\n#include \"cublas_v2.h\"\n#include \"stdio.h\"\n#include \"omp.h\"\n\n\nint main(int argc, char **argv) {\n\n  const int SZ = 2;\n  const size_t MB = SZ*SZ*sizeof(float);\n\n  cudaSetDevice(0);\n\n  float *m1, *m2, *m3;\n  float *m1_, *m2_, *m3_;\n\n  unsigned int i, j;\n\n  m1 = (float *)malloc(MB);\n  m2 = (float *)malloc(MB);\n  m3 = (float *)malloc(MB);\n\n  cudaMalloc((float **)&m1_, MB);\n  cudaMalloc((float **)&m2_, MB);\n  cudaMalloc((float **)&m3_, MB);\n\n  for (i=0; i<SZ*SZ; i++) {\n    j = (int) (i==1);\n    m1[i] = j;\n    j = (int) (i==3);\n    m3[i] = j;\n    printf(\"m1[%d]=%f m3[%d]=%f\\n\",i,m1[i],i,m3[i]);\n  }\n\n  cublasHandle_t handle;\n  cublasCreate(&handle);\n\n  cublasSetMatrix(SZ,SZ,MB,m1,SZ,m1_,SZ);\n  cublasSetMatrix(SZ,SZ,MB,m3,SZ,m3_,SZ);\n\n  float al = 1.0f;\n  float bt = 0.0f;\n\n  cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,SZ,SZ,SZ,&al,m3_,SZ,m1_,SZ,&bt,m2_,SZ);\n  printf(\"\\n%s\\n\\n\", cudaGetErrorString(cudaDeviceSynchronize()));\n  cublasGetMatrix(SZ,SZ,MB,m2_,SZ,m2,SZ);\n\n  for (i=0; i<SZ*SZ; i++)\n    printf(\"m2[%d]=%f\\n\",i,m2[i]);\n\n  free(m1);\n  free(m2);\n  free(m3);\n\n  cublasDestroy(handle);\n\n  cudaFree(m1_);\n  cudaFree(m2_);\n  cudaFree(m3_);\n\n\n  cudaDeviceReset();\n\n  return 0;\n}\n```\n\n\nSo I expect for ```\nm2```\n to return the following matrix:\n\n```\n[0 1\n 0 0]\n```\n\n\nas a result of the multiplication of\n\n```\n[0 1\n 0 0]\n```\n\n\nand\n\n```\n[0 0\n 0 1]\n```\n\n\nI am using the reversed order for ```\nm1```\n and ```\nm3```\n so that should give me the correct output for ```\nm2```\n when retrieved given that cublas{Set/Get}Matrix works in column-major. But here is the output of the code:\n\n```\nm1[0]=0.000000 m3[0]=0.000000\nm1[1]=1.000000 m3[1]=0.000000\nm1[2]=0.000000 m3[2]=0.000000\nm1[3]=0.000000 m3[3]=1.000000\n\nno error\n\nm2[0]=0.000000\nm2[1]=0.000000\nm2[2]=0.000000\nm2[3]=0.000000\n```\n\n\nI don't know what I'm doing wrong here; I would very much appreciate your input.\n    ", "Answer": "\r\nThe prototype of cublasGetMatrix is:\n\n```\ncublasStatus_t cublasGetMatrix(int rows, int cols, int elemSize, \n                        const void *A, int lda, void *B, int ldb);\n```\n\n\nelemSize should be the size of one element of the Matrix (i.e. ```\nsizeof(float)```\n ). It is the same for cublasSetMatrix:\n\n```\ncublasStatus_t cublasSetMatrix(int rows, int cols, int elemSize,\n                        const void *A, int lda, void *B, int ldb)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication giving wrong output [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has an answer here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        Unable to execute device kernel in CUDA\r\n                            \r\n                                (1 answer)\r\n                            \r\n                    \r\n                Closed 7 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nWhat I am attempting to do is Multiply Matrix A & Matrix B and then from the product matrix I get the index of the maximum value per column. But unfortunately, only the first 128*128 values of the matrix multiplication are correct while others are just garbage. I do not quite understand how this works. I request you to kindly guide me with this ..\n\n```\n#include<stdio.h>\n#include \"cuda.h\"\n#include<stdlib.h>\n\n#define blockD 32\nconst int wA = 128;\nconst int hA = 4096;    \nconst int wB = 4096;\nconst int hB = wA;\n\nmain(void){\n\n    void MatrixMultiplication(float *, float *, float *, float *);\n\n    int size_A = wA * hA * sizeof(float);\n    int size_B = wB * hB * sizeof(float);\n    int size_C = wB * hA * sizeof(float);\n    int size_max = 2 * wB * sizeof(float);\n    float *M, *N, *P, *C;   \n\n    // allocate memory on the CPU\n    M = (float*)malloc(size_A);\n    N = (float*)malloc(size_B);\n    P = (float*)malloc(size_max);\n    C = (float*)malloc(size_C);\n\n    // initialize the matrices\n    for (int y=0; y < hA; y++) {\n        for (int x=0; x < wA; x++){\n            M[y*wA + x] = 32; //x + y*wA; \n       }\n    }\n\n    for (int y=0; y<hB; y++) {\n        for (int x=0; x<wB; x++){\n            N[y*wB + x] = 21; //x + y*wB; \n       }\n    }\n\n\n    MatrixMultiplication(M, N, P, C);\n\n    //Write\n    FILE *f1;\n    int i,j;\n    f1 = fopen(\"C.txt\",\"w\");\n    for(i = hA - 2 ; i < hA; i ++){\n    for(j = 0; j < wB; j++){\n        fprintf(f1,\"%d\\t\",int(C[i*wB + j]));\n    }\n    fprintf(f1,\"\\n\");\n    }\n    fclose(f1);\n\n    // free the memory allocated on the CPU\n    free( M );\n    free( N );\n    free( P ); \n    free( C );\n    cudaDeviceReset();\n    return 0;\n}\n\n\n__device__ void MaxFunction(float* Pd, float* max)\n{\n int x = (threadIdx.x + blockIdx.x * blockDim.x);  \n int y = (threadIdx.y + blockIdx.y * blockDim.y); \n\n int k = 0;\n\n int temp = 0; int temp_idx = 0;\n for (k = 0; k < wB; ++k) {\n            if(Pd[x*wB + k] > temp){\n                temp = Pd[x*wB + k];\n                temp_idx = x*wB + k;\n            }\n  }\n  max[y*2 + 0] = temp;\n  max[y*2 + 1] = temp_idx;\n}\n\n\n__global__ void MatrixMulKernel(float* Md, float* Nd, float* Pd, float* max)\n{\n  // declare cache in the shared memory\n  __shared__ float Mds[blockD][blockD];\n  __shared__ float Nds[blockD][blockD];\n\n  float Pvalue = 0;\n  // Loop over the Md and Nd block dimension required to compute the Pd element\n  for (int m = (wA * blockD * blockIdx.y), n = (blockD * blockIdx.x); \n                            m < ((wA * blockD * blockIdx.y)+wA-1); \n                                        m += blockD, n += (blockD*hB)){\n\n    // collaboratively loading of Md and Nd blocks into shared memory    \n    Mds[threadIdx.y][threadIdx.x] = Md[m + wA * threadIdx.y + threadIdx.x];\n    Nds[threadIdx.y][threadIdx.x] = Nd[n + wA * threadIdx.y + threadIdx.x];\n    __syncthreads();\n\n    // keep track of the running sum    \n    for (int k = 0; k < blockD; k++)\n      Pvalue += Mds[threadIdx.y][k] * Nds[k][threadIdx.x];\n    __syncthreads();\n  }\n\n  // write back to the global memory\n  int p = hB * blockD * blockIdx.y + blockD * blockIdx.x;\n  Pd[p + hB * threadIdx.y + threadIdx.x] = Pvalue;\n  __syncthreads();\n\n  MaxFunction(Pd, max);\n\n}\n\nvoid MatrixMultiplication(float *M, float *N, float *P, float *C) {\n\n    int size_A = wA * hA * sizeof(float);\n    int size_B = wB * hB * sizeof(float);\n    int size_C = wB * hA * sizeof(float);\n    int size_max = 2 * wB * sizeof(float);\n    float *Md, *Nd, *Pd, *max; \n\n    // allocate memory on the GPU\n    cudaMalloc((void**)&Md, size_A);\n    cudaMalloc((void**)&Nd, size_B);\n    cudaMalloc((void**)&Pd, size_C);\n    cudaMalloc((void**)&max, size_max);\n\n    // transfer M and N to device memory\n    cudaMemcpy(Md, M, size_A, cudaMemcpyHostToDevice);\n    cudaMemcpy(Nd, N, size_B, cudaMemcpyHostToDevice);\n\n    // kernel invocation code\n    dim3 dimBlock(blockD, blockD);\n    dim3 dimGrid(wA/blockD, hB/blockD);\n\n    //Execute Kernel\n    MatrixMulKernel<<<dimGrid, dimBlock>>>( Md, Nd, Pd, max);\n\n    // transfer P from device    \n    cudaMemcpy(P, max, size_max, cudaMemcpyDeviceToHost);\n    cudaMemcpy(C, Pd, size_C, cudaMemcpyDeviceToHost);\n\n    // free the memory allocated on the GPU\n    cudaFree(Md);\n    cudaFree(Nd);\n    cudaFree(Pd);\n    cudaFree(max);\n}\n```\n\n    ", "Answer": "\r\nIn your code you seem to have more than one problem. One of the problems is, in place of this:\n\n```\ndim3 dimGrid(wA/blockD, hB/blockD);\n```\n\n\nYou should have this:\n\n```\ndim3 dimGrid(wB/blockD, hA/blockD);\n```\n\n\nUltimately you need one thread in your grid for each output point. Your formulation was giving you a grid of 4 blocks by 4 blocks, whereas you need a grid of 128 blocks by 128 blocks.\n\nThe other problem I found with your code was in these lines in the kernel:\n\n```\nint p = hB * blockD * blockIdx.y + blockD * blockIdx.x;\nPd[p + hB * threadIdx.y + threadIdx.x] = Pvalue;\n```\n\n\nThey are not indexing properly through the output array. Rather than try to sort it out using your scheme, I used this instead:\n\n```\nPd[(threadIdx.x + (blockIdx.x * blockDim.x)) + ((threadIdx.y + (blockIdx.y * blockDim.y))*(gridDim.x*blockDim.x))] = Pvalue;\n```\n\n\nWhen I made the above two changes to your code, I got what I believe are correct results throughout the array.  And it took about 32 seconds on my machine to run it.  (Note that I haven't tried fixing your original max-finding code -- see below for a better approach.)\n\nBased on your previous question, you seemed to be concerned about speed.  If you want to do fast matrix multiply, you should use cublas.  The following code shows how to use cublas to multiply two ordinary C-style matrices (they don't have to be square).  I've also included a column-max finding kernel that will be fast when the number of columns is large (say, over 500 or so.  You have 4096 columns in your example).  For small numbers of columns, there may be quicker ways to perform this function, but small numbers of columns also suggests that the overall problem size may be small and so speed (of this piece of code) will not really be an issue.\n\nHere's the code:\n\n```\n#include <stdio.h>\n#include <cublas_v2.h>\n#define VERBOSE 1\n#define nTPB 64\n#define ROW_A 4\n#define COL_A 4\n#define ROW_B COL_A\n#define COL_B 4\n#define ROW_C ROW_A\n#define COL_C COL_B\n#define SIZ_A (ROW_A*COL_A)\n#define SIZ_B (ROW_B*COL_B)\n#define SIZ_C (ROW_C*COL_C)\n\n\n\n// error check macros\n#define cudaCheckErrors(msg) \\\n    do { \\\n        cudaError_t __err = cudaGetLastError(); \\\n        if (__err != cudaSuccess) { \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", \\\n                msg, cudaGetErrorString(__err), \\\n                __FILE__, __LINE__); \\\n            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n            exit(1); \\\n        } \\\n    } while (0)\n\n// for CUBLAS V2 API\n#define cublasCheckErrors(fn) \\\n    do { \\\n        cublasStatus_t __err = fn; \\\n        if (__err != CUBLAS_STATUS_SUCCESS) { \\\n            fprintf(stderr, \"Fatal cublas error: %d (at %s:%d)\\n\", \\\n                (int)(__err), \\\n                __FILE__, __LINE__); \\\n            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n            exit(1); \\\n        } \\\n    } while (0)\n\n__global__ void col_max(float *mat, float *max, unsigned int *midx, unsigned int rows, unsigned int cols){\n  int idx = threadIdx.x + blockDim.x*blockIdx.x;\n  if (idx < cols){\n    float tempmax = mat[idx];\n    unsigned int tempmidx = 0;\n    for (int i = 1; i< rows; i++)\n      if (mat[idx + (i*cols)] > tempmax){\n        tempmax = mat[idx + (i*cols)];\n        tempmidx = i;}\n    max[idx] = tempmax;\n    midx[idx] = tempmidx;\n  }\n}\n\nint main(){\n\n  float *h_A, *h_B, *h_C, *d_A, *d_B, *d_C, *h_max, *d_max;\n  unsigned int *h_idx, *d_idx;\n\n  h_A = (float *)malloc(SIZ_A*sizeof(float));\n  if (h_A==0) {printf(\"malloc fail\\n\"); return -1;}\n  h_B = (float *)malloc(SIZ_B*sizeof(float));\n  if (h_B==0) {printf(\"malloc fail\\n\"); return -1;}\n  h_C = (float *)malloc(SIZ_C*sizeof(float));\n  if (h_C==0) {printf(\"malloc fail\\n\"); return -1;}\n  h_max = (float *)malloc(COL_C*sizeof(float));\n  if (h_max==0) {printf(\"malloc fail\\n\"); return -1;}\n  h_idx = (unsigned int*)malloc(COL_C*sizeof(unsigned int));\n\n  if (h_idx==0) {printf(\"malloc fail\\n\"); return -1;}\n\n  cudaMalloc((void **)&d_A, SIZ_A*sizeof(float));\n  cudaMalloc((void **)&d_B, SIZ_B*sizeof(float));\n  cudaMalloc((void **)&d_C, SIZ_C*sizeof(float));\n  cudaMalloc((void **)&d_max, COL_C*sizeof(float));\n  cudaMalloc((void **)&d_idx, COL_C*sizeof(unsigned int));\n  cudaCheckErrors(\"cuda malloc fail\");\n\n  // initialize data\n  for (int i=0; i< SIZ_A; i++) h_A[i] = (float)(i+1);\n  for (int i=0; i< SIZ_B; i++) h_B[i] = (float)(i+2);\n\n  cudaMemcpy(d_A, h_A, SIZ_A*sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_B, h_B, SIZ_B*sizeof(float), cudaMemcpyHostToDevice);\n  cudaCheckErrors(\"cuda memcpy 1 fail\");\n  const float alpha = 1.0f;\n  const float beta  = 0.0f;\n  cublasHandle_t handle;\n  cublasCheckErrors(cublasCreate(&handle));\n  // C = A*B\n  // due to cublas expecting column-major storage, parameters\n  // are scrambled\n  cublasCheckErrors(cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, COL_B, ROW_A, COL_A, &alpha, d_B, COL_B, d_A, COL_A, &beta, d_C, COL_C));\n  cudaMemcpy(h_C, d_C, SIZ_C*sizeof(float), cudaMemcpyDeviceToHost);\n  cudaCheckErrors(\"cuda memcpy 2 fail\");\n  col_max<<<(COL_C + nTPB - 1)/nTPB, nTPB>>>(d_C, d_max, d_idx, ROW_C, COL_C);\n  cudaCheckErrors(\"kernel launch fail\");\n  cudaMemcpy(h_max, d_max, COL_C*sizeof(float), cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_idx, d_idx, COL_C*sizeof(unsigned int), cudaMemcpyDeviceToHost);\n  cudaCheckErrors(\"cuda memcpy 3 fail/kernel fail\");\n\n  if (VERBOSE){\n    printf(\"A: \\n\");\n    for (int i=0; i< ROW_A; i++){\n      for (int j=0; j< COL_A; j++)\n        printf(\"%7.5G\", h_A[j+(i*COL_A)]);\n      printf(\"\\n\");}\n    printf(\"B: \\n\");\n    for (int i=0; i< ROW_B; i++){\n      for (int j=0; j< COL_B; j++)\n        printf(\"%7.5G\", h_B[j+(i*COL_B)]);\n      printf(\"\\n\");}\n    printf(\"C = A*B: \\n\");\n    for (int i=0; i< ROW_C; i++){\n      for (int j=0; j< COL_C; j++)\n        printf(\"%7.5G\", h_C[j+(i*COL_C)]);\n      printf(\"\\n\");}\n    printf(\"COLUMN MAX:\\n\");\n    for (int i=0; i< COL_C; i++)\n      printf(\"%7.5G\", h_max[i]);\n    printf(\"\\nCOLUMN MAX IDX:\\n\");\n    for (int i=0; i< COL_C; i++)\n      printf(\"%7d\", h_idx[i]);\n  }\n  printf(\"\\n finished!\\n\");\n  return 0;\n}\n```\n\n\nHere's what I used to compile:\n\n```\n$ nvcc -arch=sm_20 -O3 -o t221 t221.cu -lcublas\n```\n\n\nAnd here's the sample output:\n\n```\n$ cuda-memcheck ./t221\n========= CUDA-MEMCHECK\nA:\n      1      2      3      4\n      5      6      7      8\n      9     10     11     12\n     13     14     15     16\nB:\n      2      3      4      5\n      6      7      8      9\n     10     11     12     13\n     14     15     16     17\nC = A*B:\n    100    110    120    130\n    228    254    280    306\n    356    398    440    482\n    484    542    600    658\nCOLUMN MAX:\n    484    542    600    658\nCOLUMN MAX IDX:\n      3      3      3      3\n finished!\n========= ERROR SUMMARY: 0 errors\n$\n```\n\n\nWhen I extended my code to handle the same sizes you indicated, (A = 4096x128, B=128x4096) it took about 1 second on my machine.  So it's much faster than your code.  However, when I take your code and comment out your call to ```\nMaxFunction```\n in the kernel, it also only takes about 1 second to compute the matrix multiply result.  So if you wanted to keep your matrix multiply code (i.e. not use cublas) you could break the code into 2 kernels, and use your multiply routine in the first kernel with my max-finding routine (```\ncol_max```\n) in the second kernel, and also probably get a pretty fast result.\n\nAs @talonmies indicated, if you are running on a windows machine, be sure you are aware of the ramifications of windows TDR. (search that in the upper right corner search box if needed)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication with Object Arrays in Python\r\n                \r\nI am wondering how matrix multiplication can be supported in numpy with arrays of ```\ndtype=object```\n. I have homomorphically encrypted numbers that are encapsulated in a class ```\nCiphertext```\n for which I have overriden the basic math operators like ```\n__add__```\n, ```\n__mul__```\n etc.\n\nI have created numpy array where each entry is an instance of my class ```\nCiphertext```\n and numpy understands how to broadcast addition and multiplication operations just fine. \n\n```\n    encryptedInput = builder.encrypt_as_array(np.array([6,7])) # type(encryptedInput) is <class 'numpy.ndarray'>\n    encryptedOutput = encryptedInput + encryptedInput\n    builder.decrypt(encryptedOutput)                           # Result: np.array([12,14])\n```\n\n\nHowever, numpy won't let me do matrix multiplications\n\n```\nout = encryptedInput @ encryptedInput # TypeError: Object arrays are not currently supported\n```\n\n\nI don't quite understand why this happens considering that addition and multiplication works. I guess it has something to do with numpy not being able to know the shape of the object, since it could be a list or something fance. \n\nNaive Solution: I could write my own class that extends ```\nndarray```\n and overwrite the ```\n__matmul__```\n operation, but I would probably lose out on performance and also this approach entails implementing broadcasting etc., so I would basically reinvent the wheel for something that should work as it is right now. \n\nQuestion: How can I use the standard matrix multiplication provided by numpy on arrays with ```\ndtype=objects```\n where the objects behave exactly like numbers?\n\nThank you in advance!\n    ", "Answer": "\r\nFor whatever reason matmul doesn't work, but the tensordot function works as expected. \n\n```\nencryptedInput = builder.encrypt_as_array(np.array([6,7]))\nout = np.tensordot(encryptedInput, encryptedInput, axes=([1,0])) \n    # Correct Result: [[ 92. 105.]\n    #                  [120. 137.]]\n```\n\n\nNow it's just a hassle to adjust the axes. I still wonder whether this is actually faster than a naive implementation with for loops.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication with PyTorch\r\n                \r\nI'm sorry if this is a basic question, but I am reasonably new to Pytorch and have been trying to perform linear regression. I've been stuck on the following problem for about 3 hours and have tried everything, so I hope you're able to help.\nI want to predict grades using a set of four inputs (time studied, travel time, failures and absenses). For my outputs I have grades on 3 tests. There are 395 students in the dataset.\nI've listed all my code at the bottom, but I'll paste the relevant part here too:\nSo far I've created input and output tensors and have created a model for matrix multiplication. Here's my code:\n```\nw = torch.randn(395,4, requires_grad=True)\nb = torch.randn(4, requires_grad=True)\nprint(w)\nprint(b)\n \ndef model(x):\n    return x @ w.t() + b\n\npredictions = model(inputs)\nprint(predictions)\n```\n\nI know this isn't the linear regression yet, but I'm really struggling with the matrix multiplication aspect of it. Whenever I run the print(predictions) code I get the following message:\n```\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-277-c6db141153ac> in <module>\n----> 1 preds = model(inputs)\n      2 print(preds)\n\n<ipython-input-276-3b94bfbc599e> in model(x)\n      1 def model(x):\n----> 2     return x @ w.t() + b\n\nRuntimeError: Expected object of scalar type Double but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out\n```\n\nI have a feeling the numbers for w and b are wrong (395,4) and (4), but I have no idea why or what to change them to. Is there any chance someone could point me in the right direction please?\nThanks in advance!\nHere's my whole code:\n'''\n```\nimport torch\nimport numpy as np\nfrom numpy import genfromtxt\n\ndata = np.genfromtxt('student-mat.csv', delimiter=',',dtype=float)\ndata\n\ntravel_time = data[1:, 0:1]\nstudy_time = data[1:, 1:2]\nfailures = data[1:, 2:3]\nabsenses = data[1:, 3:4]\ngrade_one = data[1:, 4:5]\ngrade_two = data[1:, 5:6]\ngrade_three = data[1:, 6:7]\ndata_input = data[1:, 0:4]\noutput = data[1:, 4:7]\n\ninputs = torch.from_numpy(data_input)\noutputs = torch.from_numpy(grade_one)\nprint(inputs)\nprint(grade_one)\n\nw = torch.randn(395,4, requires_grad=True)\nb = torch.randn(4, requires_grad=True)\nprint(w)\nprint(b)\n\ndef model(x):\n    return x @ w.t() + b\n\npreds = model(inputs)\nprint(preds)\n```\n\nDataset - https://archive.ics.uci.edu/ml/datasets/Student+Performance\n    ", "Answer": "\r\nThe error message says it all. The tensors involved contain elements of different data types. By default, ```\nw```\n and ```\nb```\n have elements of type ```\ntorch.float32```\n, while ```\ndata_input```\n is a NumPy array with the Python default floating point type, i.e. double. That datatype will be preserved when you convert with ```\nfrom_numpy```\n. Try using ```\ndtype=np.float32```\n in your ```\nnp.genfromtxt```\n call.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication with PyTorch\r\n                \r\nI'm sorry if this is a basic question, but I am reasonably new to Pytorch and have been trying to perform linear regression. I've been stuck on the following problem for about 3 hours and have tried everything, so I hope you're able to help.\nI want to predict grades using a set of four inputs (time studied, travel time, failures and absenses). For my outputs I have grades on 3 tests. There are 395 students in the dataset.\nI've listed all my code at the bottom, but I'll paste the relevant part here too:\nSo far I've created input and output tensors and have created a model for matrix multiplication. Here's my code:\n```\nw = torch.randn(395,4, requires_grad=True)\nb = torch.randn(4, requires_grad=True)\nprint(w)\nprint(b)\n \ndef model(x):\n    return x @ w.t() + b\n\npredictions = model(inputs)\nprint(predictions)\n```\n\nI know this isn't the linear regression yet, but I'm really struggling with the matrix multiplication aspect of it. Whenever I run the print(predictions) code I get the following message:\n```\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-277-c6db141153ac> in <module>\n----> 1 preds = model(inputs)\n      2 print(preds)\n\n<ipython-input-276-3b94bfbc599e> in model(x)\n      1 def model(x):\n----> 2     return x @ w.t() + b\n\nRuntimeError: Expected object of scalar type Double but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out\n```\n\nI have a feeling the numbers for w and b are wrong (395,4) and (4), but I have no idea why or what to change them to. Is there any chance someone could point me in the right direction please?\nThanks in advance!\nHere's my whole code:\n'''\n```\nimport torch\nimport numpy as np\nfrom numpy import genfromtxt\n\ndata = np.genfromtxt('student-mat.csv', delimiter=',',dtype=float)\ndata\n\ntravel_time = data[1:, 0:1]\nstudy_time = data[1:, 1:2]\nfailures = data[1:, 2:3]\nabsenses = data[1:, 3:4]\ngrade_one = data[1:, 4:5]\ngrade_two = data[1:, 5:6]\ngrade_three = data[1:, 6:7]\ndata_input = data[1:, 0:4]\noutput = data[1:, 4:7]\n\ninputs = torch.from_numpy(data_input)\noutputs = torch.from_numpy(grade_one)\nprint(inputs)\nprint(grade_one)\n\nw = torch.randn(395,4, requires_grad=True)\nb = torch.randn(4, requires_grad=True)\nprint(w)\nprint(b)\n\ndef model(x):\n    return x @ w.t() + b\n\npreds = model(inputs)\nprint(preds)\n```\n\nDataset - https://archive.ics.uci.edu/ml/datasets/Student+Performance\n    ", "Answer": "\r\nThe error message says it all. The tensors involved contain elements of different data types. By default, ```\nw```\n and ```\nb```\n have elements of type ```\ntorch.float32```\n, while ```\ndata_input```\n is a NumPy array with the Python default floating point type, i.e. double. That datatype will be preserved when you convert with ```\nfrom_numpy```\n. Try using ```\ndtype=np.float32```\n in your ```\nnp.genfromtxt```\n call.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to time a matrix multiplication in C?\r\n                \r\nI want to ask for help to measure the execution time of matrix multiplication below. I'm running the code in Windows. I've try to using time.h, but it can't measured. Where I have to put the timer?\n\n```\n#include<stdio.h>\n#include<math.h>\n#include<time.h>\n\nvoid main()\n{\n    int m1[10][10],i,j,k,m2[10][10],add[10][10],mult[10][10],r1,c1,r2,c2;\n    /*double dif;\n    time_t start, end;*/\n\n    printf(\"Enter number of rows and columns of first matrix MAX 10\\n\");\n    scanf(\"%d%d\",&r1,&c1);\n    printf(\"Enter number of rows and columns of second matrix MAX 10\\n\");\n    scanf(\"%d%d\",&r2,&c2);\n    if(r2==c1)\n    {\n        printf(\"Enter rows and columns of First matrix \\n\");\n        printf(\"Row wise\\n\");\n        for(i=0;i<r1;i++)\n        {\n            for(j=0;j<c1;j++)\n                scanf(\"%d\",&m1[i][j]);\n        }\n        printf(\"You have entered the first matrix as follows:\\n\");\n        for(i=0;i<r1;i++)\n        {\n            for(j=0;j<c1;j++)\n                printf(\"%d\\t\",m1[i][j]);\n            printf(\"\\n\");\n        }\n        printf(\"Enter rows and columns of Second matrix \\n\");\n        printf(\"Again row wise\\n\");\n        for(i=0;i<r2;i++)\n        {\n            for(j=0;j<c2;j++)\n                scanf(\"%d\",&m2[i][j]);\n        }\n        printf(\"You have entered the second matrix as follows:\\n\");\n        for(i=0;i<r2;i++)\n        {\n            for(j=0;j<c2;j++)\n                printf(\"%d\\t\",m2[i][j]);\n            printf(\"\\n\");\n        }\n        /*time (&start);*/\n        printf(\"Now we multiply both the above matrix \\n\");\n        printf(\"The result of the multiplication is as follows:\\n\");\n        /*a11xA11+a12xA21+a13xA31 a11xA12+a12xA22+a13xA32 a11xA13+a12xA23+a13xA33*/\n        for(i=0;i<r1;i++)\n        {\n            for(j=0;j<c2;j++)\n            {\n                mult[i][j]=0;\n                for(k=0;k<r1;k++)\n                {\n                    mult[i][j]+=m1[i][k]*m2[k][j];\n                    /*mult[0][0]=m1[0][0]*m2[0][0]+m1[0][1]*m2[1][0]+m1[0][2]*m2[2][0];*/\n                }\n                printf(\"%d\\t\",mult[i][j]);\n            }\n            printf(\"\\n\");\n            /*time (&end);\n            dif (difftime (end, start);\n            printf(\"Time of execution is : %f\\n\",dif)*/\n        }\n        getch();\n    }\n    else\n    {\n        printf(\"Matrix multiplication cannot be done\");\n    }\n}\n```\n\n\nI want the measurement as accurate as possible.\n    ", "Answer": "\r\nI think  you'd be best off with your 'end time' code outside the loops you've currently got, immediately before the call to ```\ngetch()```\n.  This would give you the maximum chance of counting more than 1 second.  To get a decent measure, you probably need to repeat the whole multiplication a number of times (so that the total elapsed time is measured in 10s of seconds).  You should avoid printing in the loop, too; the printing time will likely dominate the calculation time.\n\nThe rest of your trouble is that the ```\ntime()```\n system call provides 1 second resolution on the timing.  You really need a timing routine with sub-second resolution such as ```\ngettimeofday()```\n (microsecond) or ```\nclock_gettime()```\n (nanosecond).  Note that resolution and accuracy are different.  (You could use ```\nclock()```\n instead, which is Standard C but normally provides much less resolution.  Historically, there was also ```\nftime()```\n and ```\ntimes()```\n that could be used.  These gave millisecond resolution.)  There are other system calls available on Windows.  You will still want a significant repeat count to make the timing useful (1000 times, or 10,000 times, or 1,000,000 times) because it does not take long to do a 10x10 matrix multiplication.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication Parallelized implementation (OpenMP)\r\n                \r\nI ran a matrix multiplication code serially and parallelized.There was no significant improvement with the parallel version.  \n\n```\n    dimension =4000;\n\n    //#pragma omp parallel for shared(A,B,C) private(i,j,k)\n    {\n    for(int i=0; i<dimension; i++){\n        for(int j=0; j<dimension; j++){\n           for(int k=0; k<dimension; k++){\n             C[i][j] += A[i][k] * B[k][j];\n            }\n        }       \n    }\n    }\n```\n\n\nOutput:\n                time ./a.out\n\n```\nreal    4m58,760s\nuser    4m58,706s\nsys     0m0,036s\n```\n\n\nfor serial code (I put the #pragma... in a comment,rest of code is same) \nI got following output\n\n```\nreal    4m51,240s\nuser    4m51,210s\nsys     0m0,024s\n```\n\n    ", "Answer": "\r\nYou need to compile code with ```\n-fopenmp```\n for the pragma to work. Also, you don't need to comment the pragma to run without OpenMP, just don't compile with OpenMP.\n\nWith OpenMP: ```\ngcc -fopenmp -o a.out code.c```\n\nWithout OpenMP: ```\ngcc -o a.out code.c```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Element by Element Matrix Multiplication in Scala\r\n                \r\nI have an input ```\nmllib```\n ```\nmatrix```\n like,\n\n```\nmatrix1: org.apache.spark.mllib.linalg.Matrix =\n1.0  0.0  2.0  1.0\n0.0  3.0  1.0  1.0\n2.0  1.0  0.0  0.0\n```\n\n\nThe dimensions of ```\nmatrix1```\n is ```\n3*4```\n. \nI need to do an element by element ```\nmatrix```\n multiplication with another matrix so that dimensions of two matrices will be the same in all cases. Let us assume I have another matrix named ```\nmatrix2```\n like\n\n```\nmatrix2: org.apache.spark.mllib.linalg.Matrix =\n3.0  0.0  2.0  1.0\n1.0  9.0  5.0  1.0\n2.0  5.0  0.0  0.0\n```\n\n\nwith dimensions ```\n3*4```\n\nMy resultant matrix should be,\n\n```\nresult: org.apache.spark.mllib.linalg.Matrix =\n3.0  0.0   4.0  1.0\n0.0  27.0  5.0  1.0\n4.0  5.0   0.0  0.0\n```\n\n\nHow can I achieve this in Scala ? (Note: inbuilt function ```\nmultiply```\n of spark ```\nmllib```\n works as per exact matrix multiplication.) \n    ", "Answer": "\r\nBelow is one way of doing it. Here we iterate both the matrix column wise and find their element multiplication. This solution assumes that both the matrix are of same dimensions. \nFirst let's create test matrix as given in question.\n\n```\n//creating example matrix as per the question\nval m1: Matrix = new DenseMatrix(3, 4, Array(1.0, 0.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0))\nval m2: Matrix = new DenseMatrix(3, 4, Array(3.0, 1.0, 2.0, 0.0, 9.0, 5.0, 2.0, 5.0, 0.0, 1.0, 1.0, 0.0))\n```\n\n\nNow let's define a function which takes two ```\nMatrix```\n and returns their element  multiplication.\n\n```\n//define a function to calculate element wise multiplication\ndef elemWiseMultiply(m1: Matrix, m2: Matrix): Matrix = {\n  val arr = new ArrayBuffer[Array[Double]]()\n  val m1Itr = m1.colIter //operate on each columns\n  val m2Itr = m2.colIter\n  while (m1Itr.hasNext)\n    //zip both the columns and then multiple element by element\n    arr += m1Itr.next.toArray.zip(m2Itr.next.toArray).map { case (a, b) => a * b }\n  //return the resultant matrix\n  new DenseMatrix(m1.numRows, m1.numCols, arr.flatten.toArray)\n}\n```\n\n\nYou can then call this function for your element multiplication.\n\n```\n//call the function to m1 and m2\nelemWiseMultiply(m1, m2)\n\n//output\n//3.0  0.0   4.0  1.0\n//0.0  27.0  5.0  1.0\n//4.0  5.0   0.0  0.0\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in java (RE-POST)\r\n                \r\nApologies for the re-post; the earlier time I'd posted I did not have all the details.\n\nMy colleague, who quit the firm was a C# programmer, was forced to write Java code that involved (large, dense) matrix multiplication.\n\nHe's coded his own DataTable class in Java, in order to be able to\n\na) create indexes to sort and join with other DataTables\n\nb) do matrix multiplication.\n\nThe code in its current form is NOT maintainable/extensible.\nI want to clean up the code, and thought using something like R within Java will help me focus on business logic rather than sorting, joining, matrix multiplication, etc. \n\nPlus, I'm very new to the concept of DataTable; I just want to replace the DataTable with 2D arrays, and let R handle the rest.\n\n(I currently do not know how to join 2 large datasets in java very efficiently\n\nPlease let me know what you think. Also, are there any simple examples that I can take a look at?\n    ", "Answer": "\r\nDon't take this too harshly but you seem to be preparing to replace one chunk of unmaintainable code with another chunk of unmaintainable code.  How do I reach this remarkable conclusion ?  By your own admission your Java expertise is not quite up to the task you face and you propose to replace a pure Java solution with Java+R.\n\nI suggest that you identify your core skills and use whatever toolset you are most comfortable with to refactor the code.  If you don't I foresee a post on SO in a year or so from your replacement complaining about the unmaintainable code you left behind ! \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Numpy Matrix Multiplication Explanation\r\n                \r\nI am working through some math exercises and I do not understand why my numpy matrix multiplication is not working.\nSo I have:\n```\nt = np.array([[6,-1],[2,3]])\nc = np.array([[1,1], [1,2]])\ncinv = np.linalg.inv(c)\n```\n\nWhich gives me:\n```\nt:\n   [[ 6 -1]\n    [ 2  3]]\nc:\n   [[1 1]\n    [1 2]]\ncinv:\n   [[ 2. -1.]\n    [-1.  1.]]\n```\n\nNow when I run my equation I get the following:\n```\ncinv*t*c\narray([[12.,  1.],\n       [-2.,  6.]])\n```\n\nWhich this is not correct. I did it over a couple times and the correct answer is (5,0)(0,4). Why is the multiplication being carried out by position instead of row * column?\nCan someone help me out with what I am doing wrong here?\n    ", "Answer": "\r\nUsing ```\n*```\n does elementwise multiplication, not dot product. Use ```\n@```\n for a dot product multiplication. This is Numpy's choice for overloading operators. In fact, in the original Python design however, ```\n@```\n was designated for matrix multiplication, which is probably why this is the case.\n```\nimport numpy as np\n\n\nt = np.array([[6,-1],[2,3]])\nc = np.array([[1,1], [1,2]])\ncinv = np.linalg.inv(c)\n\nprint(cinv@t@c)\n\"\"\"\nResult:\n[[5. 0.]\n [0. 4.]]\n\"\"\"\n```\n\nOften times, I find it a lot easier to read to use strict functions and not the overloaded operators (though they can get crowded fast).\n```\nnp.dot(A, B)```\n or ```\nA.dot(B)```\n work as dot products\nHere's some documentation on what each symbol does, explicitly.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Does Divide & Conquer Matrix Multiplication perform the same amount of additions/subtractions as the Classical Matrix multiplication?\r\n                \r\nDoes Divide & Conquer Matrix Multiplication perform the same amount of additions/subtractions as the Classical Matrix multiplication?\n\nI know that they do specifically for Multiplications as they both share the same O(n^3) complexity...\n\nbut when I try to count them in the program i'm making, the additions/subtracts are coming to a different numbers, and I'm not sure if this is correct.\n\nIf anyone knows for sure please let me know, thanks.\n    ", "Answer": "\r\nLet's assume square matrices.\n\nIf you count the number of additions (there are no subtractions) in classic matrix multiplication, you get N^3 additions. There are N^2 elements, and each element is the dot-product of a row and column consisting of N-1 additions, so almost exactly N^3 additions.\n\nTo count the number of additions in divide-and-conquer matrix multiplication, let's see how it works:\n\nSplit up NxN matrix into four (N/2)x(N/2) matrices, then treat it as a 2x2 matrix and perform block multiplication recursively. For example multiplying two 8x8 matrices:\n\n```\n┌┌A A A A┐┌B B B B┐┐ ┌┌a a a a┐┌b b b b┐┐\n││A A A A││B B B B││ ││a a a a││b b b b││\n││A A A A││B B B B││ ││a a a a││b b b b││\n│└A A A A┘└B B B B┘│ │└a a a a┘└b b b b┘│\n│┌C C C C┐┌D D D D┐│*│┌c c c c┐┌d d d d┐│\n││C C C C││D D D D││ ││c c c c││d d d d││\n││C C C C││D D D D││ ││c c c c││d d d d││\n└└C C C C┘└D D D D┘┘ └└c c c c┘└d d d d┘┘\n```\n\n\nThe new matrix will be:\n\n```\n┌┌       ┐┌       ┐┐\n││ Aa+Bc ││ Ab+Bd ││\n││       ││       ││\n│└       ┘└       ┘│\n│┌       ┐┌       ┐│\n││ Ca+Dc ││ Cb+Dd ││\n││       ││       ││\n└└       ┘└       ┘┘\n(where for example Aa is a 4x4 matrix multiplication)\n```\n\n\nEach multiplication of [N/2xN/2]*[N/2xN/2] is a subproblem of size N/2. We must do 8 of these subproblems. This gives us a recurrence from the above:\n\n```\nadditions[N] = 8*additions[N/2] + N^2\n```\n\n\nThat is, if we pay the price of N^2 additions, we are allowed to break down the problem of size N into 8 subproblems of size N/2.\nWe can solve using the Master Theorem (or more general Akra-Bazzi Theorem), or by inspection:\n\n```\nadditions[N] = 8*(8*(8*(8*(..1..) +(N/8)^2) +(N/4)^2) +(N/2)^2) +N^2\n```\n\n\nUsing the Master Theorem, ```\nadditions[N] = O(N^(log_2(8))) = O(N^3)```\n\n\nWhy would we do this since it's the same order of growth? We wouldn't. It turns out that in order to get better asymptotic complexity, you don't want to do this, you want to use an algebraic trick called Strassen's method. See http://www.cs.berkeley.edu/~jordan/courses/170-fall05/notes/dc.pdf on page 4. Our new recurrence relation comes from counting the number of multiplications and additions as shown on that page. There are 18 additions of [N/2xN/2] matrices required to form an NxN matrix.\n\n```\nadditions[N] = 7*additions[N/2] + 18*(N/2)^2\n             = 7*additions[N/2] + (18/4)*(N/2)^2\n```\n\n\nAs we see, we have to do one fewer subproblem, but at the cost of doing more work in combining. The master theorem says that ```\nadditions[N] = O(N^(log_2(7))) ~= O(N^2.807)```\n.\n\nSo asymptotically, there will be FEWER additions, but only asymptotically. The real story is revealed when we simulate both recurrence relations:\n\n```\n#!/usr/bin/python3\n\nn = 1  # NxN matrix\n\nnormal = 1\nnaive = 1\nstrassen = 1\n\nprint('NUMBER OF ADDITIONS')\nprint('       NxN |   normal     naive  strassen | best')\nprint('-'*60)\nwhile n < 1000000000:\n    n *= 2\n\n    normal = (n-1)*n**2\n    naive = 8*naive + n**2\n    strassen = 7*strassen + (18/4)*n**2\n\n    print('{:>10} | {:>8.2e}  {:>8.2e}  {:>8.2e} | {}'.format(\n        n,\n        normal, naive, strassen/normal,\n        'strassen' if strassen<n**3 else 'normal'\n    ))\n```\n\n\nResults:\n\n```\nNUMBER OF ADDITIONS\n       NxN |   normal     naive  strassen | best\n------------------------------------------------------------\n         2 | 4.00e+00  1.20e+01  2.50e+01 | normal\n         4 | 4.80e+01  1.12e+02  2.47e+02 | normal\n         8 | 4.48e+02  9.60e+02  2.02e+03 | normal\n        16 | 3.84e+03  7.94e+03  1.53e+04 | normal\n        32 | 3.17e+04  6.45e+04  1.12e+05 | normal\n        64 | 2.58e+05  5.20e+05  7.99e+05 | normal\n       128 | 2.08e+06  4.18e+06  5.67e+06 | normal\n       256 | 1.67e+07  3.35e+07  4.00e+07 | normal\n       512 | 1.34e+08  2.68e+08  2.81e+08 | normal\n      1024 | 1.07e+09  2.15e+09  1.97e+09 | normal\n      2048 | 8.59e+09  1.72e+10  1.38e+10 | normal\n      4096 | 6.87e+10  1.37e+11  9.68e+10 | normal\n      8192 | 5.50e+11  1.10e+12  6.78e+11 | normal\n     16384 | 4.40e+12  8.80e+12  4.75e+12 | normal\n     32768 | 3.52e+13  7.04e+13  3.32e+13 | strassen\n     65536 | 2.81e+14  5.63e+14  2.33e+14 | strassen\n    131072 | 2.25e+15  4.50e+15  1.63e+15 | strassen\n    262144 | 1.80e+16  3.60e+16  1.14e+16 | strassen\n    524288 | 1.44e+17  2.88e+17  7.98e+16 | strassen\n   1048576 | 1.15e+18  2.31e+18  5.59e+17 | strassen\n   2097152 | 9.22e+18  1.84e+19  3.91e+18 | strassen\n   4194304 | 7.38e+19  1.48e+20  2.74e+19 | strassen\n   8388608 | 5.90e+20  1.18e+21  1.92e+20 | strassen\n  16777216 | 4.72e+21  9.44e+21  1.34e+21 | strassen\n  33554432 | 3.78e+22  7.56e+22  9.39e+21 | strassen\n  67108864 | 3.02e+23  6.04e+23  6.57e+22 | strassen\n 134217728 | 2.42e+24  4.84e+24  4.60e+23 | strassen\n 268435456 | 1.93e+25  3.87e+25  3.22e+24 | strassen\n 536870912 | 1.55e+26  3.09e+26  2.25e+25 | strassen\n1073741824 | 1.24e+27  2.48e+27  1.58e+26 | strassen\n```\n\n\nAs we can see, with respect to additions only, Strassen outperforms the traditional normal matrix-multiplication with respect to number of additions, but only once your matrices exceed the size of roughly 30000x30000.\n\n(Also note that the naive divide-and-conquer multiplication performs asymptotically the same, in terms of additions, as traditional matrix multiplication. However it still performs \"worse\" by initially a factor of 3, but as the matrix size increases, asymptotically worse by a factor of exactly 2 . Of course this tells us nothing about the true complexity which involves multiplications, but if it did, we might still want to use it if we had a parallel algorithm which could take advantage of the different computation structure.)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "OpenMP matrix multiplication nested loops\r\n                \r\nThis is a matrix multiplication code with one ```\ni```\n loop parallelized and another with ```\nj```\n loop parallelized. With both the versions the value of ```\nC```\n array is correct (I have tested with small matrix sizes). There is also no performance improvement from one over other.\nCan anyone please tell me what is the difference in these 2 versions? Will the array ```\nC```\n be accurate in both the versions regardless of the size of the matrix? Thanks in advance\n\n```\nvoid mat_multiply ( void )\n{\n    int t;\n    int i, j, k;    \n    #pragma omp parallel for private(k) // parallelize i loop\n    for(i = 0; i < dimension; i++)\n    {\n        for(j = 0; j < dimension; j++) \n        {\n            for(k = 0; k < dimension; k++)\n            {\n                C[dimension*i+j] += A[dimension*i+k] *  B[dimension*k+j];       \n            }\n        }\n    }\n }\n```\n\n\n```\n void mat_multiply ( void )\n {\n     int t;\n     int i, j, k;   \n\n     for(i = 0; i < dimension; i++)\n     {\n         #pragma omp parallel for private(k) // parallelize j loop\n         for(j = 0; j < dimension; j++) \n         {\n             for(k = 0; k < dimension; k++)\n             {\n                 C[dimension*i+j] += A[dimension*i+k] *  B[dimension*k+j];      \n             }\n         }\n     }\n }\n```\n\n    ", "Answer": "\r\nAt first, it seems that the first version has a lower thread creation overhead, since it will only create the threads once. While in the second version it seems that the threads will be created ```\ndimension```\n times.\nBut according to this\n\nOne may be worried about the creation of new threads within the inner\nloop. Worry not, the libgomp in GCC is smart enough to actually only\ncreates the threads once. Once the team has done its work, the threads\nare returned into a \"dock\", waiting for new work to do.\nIn other words, the number of times the clone system call is executed\nis exactly equal to the maximum number of concurrent threads. The\nparallel directive is not the same as a combination of pthread_create\nand pthread_join.\n\nOn the first version, you should guarantee that the variable ```\nj```\n is also private.\nInstead of having two approaches you can just have one where the nested loop is parallelized. In OpenMP 3.0, the parallelization of nested loops can be handled by the collapse clause in the for directive, namely:\n```\nvoid mat_multiply ( void ) {\n   \n    #pragma omp parallel for collapse(2)\n    for(int i = 0; i < dimension; i++)\n      for(int j = 0; j < dimension; j++)\n        for(int k = 0; k < dimension; k++)\n            C[dimension*i+j] += A[dimension*i+k] *  B[dimension*k+j];        \n  }\n```\n\nBtw: Have a look into a block approach, you can see an example here (starting in slide 62).\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "SVD of Matrix Multiplication in Matlab\r\n                \r\nI am currently trying to find the singular values of a large amount of matrix multiplications (about 1000 matrices) of 4 by 4 matrices in matlab. I am running into issues of overflow quite a bit but is not the main source of my question. I have done the matrix multiplication in two different ways. My first method is to calculate the matrix multiplication directly. i.e. ```\nMn*….*M1=M```\n. This method gives me a matrix with elements on the order 1.0e+80. And then from here finding the singular values from ```\n[D]=svd(M)```\n. \nMy second method is using QR factorization. I first do ```\n[Q1,R1]=qr(M1)```\n. Then for the next step, I calculate ```\n[Q2,R2]=M2*Q1```\n. This makes it so that ```\nM=Qn* Rn*…*R2*R1```\n. I know that ```\nRn*…*R2*R1```\n should have the same singular values as M so hopefully ```\n[D]=svd(Rn*…*R2*R1)```\n should give me the same answer as in my first method. However the singular values are on the order of 1.0e+61 larger in the first method as compared to the second method. What source could be causing this massive discrepancy, which method is more reliable, and is there a better way of approaching this problem? Many thanks in advance\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Java multi-thread matrix multiplication\r\n                \r\nTrying to get a multi-threaded matrix multiplication to work in Java. It is given a (m x n) matrix, a (n x k) matrix and 't' threads to perform the operation on.\nMy program works when the matrices are square and t == n. When running with t < n, the other threads do not pick up the additional operations, and it returns a partially completed matrix. When the matrices are not square, the additional threads return array out of bounds errors and do not run. I would really appreciate any advice. Here are the relevant code snippets\nBeginning threads. multipliers is an array of MatrixMultiplier, a class defined later.\n```\nMultiply multiply = new Multiply(cols_mat, rows_mat2);\n\nfor (int i = 0; i < threads; i++) {\n    multipliers[i] = new MatrixMultiplier(multiply);\n}\n\nfor (int i = 0; i < threads; i++) {\n    my_threads[i] = new Thread(multipliers[i]);\n}\n\nfor (int i = 0; i < threads; i++) {\n    my_threads[i].start();\n}\n\nfor (int i = 0; i < threads; i++) {\n    my_threads[i].join();\n}\n```\n\nMultiply class which defines the matrix multiplication\n```\nclass Multiply extends MatrixMultiplication {\n    private int i;\n    private int j;\n    private int chance;\n\n    public Multiply(int i, int j) {\n        this.i = i;\n        this.j = j;\n        chance = 0;\n    }\n\n    public synchronized void multiplyMatrix() {\n        int sum = 0;\n        int a = 0;\n        for (a = 0; a < i; a++) {\n            sum = 0;\n            for (int b = 0; b < j; b++) {\n                sum = sum + mat[chance][b] * mat2[b][a];\n            }\n            result[chance][a] = sum;\n        }\n\n        if (chance >= i)\n            return;\n        chance++;\n    }\n}\n```\n\nAnd the matrix multiplier\n```\nclass MatrixMultiplier implements Runnable {\n    private final Multiply mul;\n\n    public MatrixMultiplier(Multiply mul) {\n        this.mul = mul;\n    }\n\n    @Override\n    public void run() {\n        mul.multiplyMatrix();\n    }\n}\n```\n\nWhere I personally think the issue lies is with ```\nif (chance >= i) return;```\n but I have not found a way to incorporate a thread's column responsibilities with the program still working. Again, any advice pointing me in the right direction would be greatly appreciated.\n    ", "Answer": "\r\nThere are several issues with your code.\nThe t threads assume that only t multiplications are required to produce your result matrix.  This is not to be the case when m != k or t != m or t != k.  The threads are worker threads that will only process your requests.  I would consider making each MatrixMultiplier have access to the mxn, nxk, mxk matrices and a rolcolumn entries container.\n```\nclass MatricMultiplier {\n    private double a[][], b[][], results[][];\n    private Queue<..> entries;\n    ....\n}\n```\n\nThe run method will then use the entries container to calculate the sum for a given <row,column> entry of the resulting mxk matrix.  The run method could become:\n```\nrun() {\n    for (Entry entry = entries.poll(); entry != null; entry = entries.poll()) {\n        int row = entry.row;\n        int col = entry.col;\n        double sum = 0.0;\n        for (int i = 0; i < a[row].length; i++) {\n            sum += a[row][i] * b[i][col];\n        }\n        results[row][col] = sum;\n    }\n}\n```\n\nThere are three things to note here that is different than what you have.\n\nyou are not using a synchronization block\neach entry is calculating the answer for a unique row/column of the result matrix\nthe Multiple class is not required any longer\n\nYou can then create t threads that process each entry in the entries container and will exit when the entries container is empty.\nNote that the entries container should be one of the concurrent Queue containers available in the java.util.concurrent package.\nThe remaining task is how to create the rowcolumn entries container.  Here is some code that you could use:\n```\nQueue<..> entries = new Concurrent...<..>();\nint rowSize = a.length;\nint colSize = b[0].length;\nfor (int row = 0; row < rowSize; row++) {\n    for (int col = 0; col < colSize; col++) {\n        entries.add(new RowColumnEntry(row, col));\n    }\n}\n```\n\nNoting that the ```\na```\n and ```\nb```\n are the ```\nm×n```\n and ```\nn×k```\n matrices.\nHope this helps.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to make matrix multiplication function in C? (static variables & arbitrary matrix size)\r\n                \r\n```\n#include <stdio.h>\n#include <stdlib.h>\n\nvoid mat_mul(double** A, double** B,double **C, int M, int N, int K)\n{\n    \n    for (int i = 0; i < M; i++) {\n        for (int j = 0; j < N; j++) {\n            for (int k = 0; k < K; k++) {\n                C[i][j] += A[i][k] * B[k][j];\n            }\n        }\n    }\n    \n    \n}\n\nint main() {\n    double A[3][3];\n    double C[3][3] = { 0 };\n    double B[3][3];\n\n\n    for (int i = 0; i < 3; i++) B[i][i] = 1;\n    for (int i = 0; i < 3; i++) {\n        for (int j = 0; j < 3; j++) {\n            A[i][j] = 3 * i + j;\n        }\n    }\n    for (int i = 0; i < 3; i++) {\n        for (int j = 0; j < 3; j++) {\n            printf(\" %lf\", A[i][j]);\n        }\n        printf(\"\\n\");\n    }\n\n    mat_mul(A, B, C, 3, 3, 3);\n\n    return 0;\n}\n\n```\n\nI want to make matrix multiplication function in C with static variables & arbitrary matrix size.\nAbove code has error.\nHow can I fix that error?\nAnd I want to make function for any size matrix multiplication not only 3 by 3 matrix.\n    ", "Answer": "\r\nA pointer to pointer is not an array, nor a 2D array, nor can it be used to point at an array. A conforming compiler will not let this code through since it isn't valid C.\nFix this by forgetting that you ever heard of pointer to pointer in relation with 2D arrays. Instead change the function to something like this:\n```\nvoid mat_mul(size_t x, size_t y, double a[x][y], double b[x][y], double c[x][y]);\n```\n\nThis works as long as you pass a correct 2D array, no matter how it was allocated. You can allocate one dynamically like this:\n```\n#include <stdlib.h>\n\n// get x and y from user input etc:\nint x = something;\nint y = something;\n\ndouble (*array)[y] = malloc( sizeof(double[x][y]) );\n...\nfree(array);\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "OpenCV: Matrix multiplication with a matrix containing Vec3d and a matrix containing doubles\r\n                \r\nI am using OpenCV for some time and now I hit the point where I need a multiplication of this type:\n\n\n  Define a matrix ```\nT```\n, which contains elements of the type ```\nVec3d```\n1  . Matrix ```\nT```\n has the size: M X N. Matrix ```\nT```\n has to be multiplied with a Vector ```\nPhi```\n, which has the size: N X 1, containing ```\ndouble```\ns as values. Each element of the result has to be the result of a matrix multiplication of both matrices.\n\n\nI don't want to do a component-wise multiplication, but a \"real\" matrix multiplication, e.g. multiplying the first element of ```\nT```\n2 with the first element of matrix ```\nJ```\n, then multiplying the second element of matrix ```\nT```\n3 with the second element of matrix ```\nJ```\n. Do this until you completed the first row of ```\nT```\n and then sum up the results. The result is a M X 1.\n\nFor example, if ```\nT```\n would be a 3 X 2 matrix and ```\nPhi```\n a 2 X 1 matrix, then the calculation should be ```\nT_11 * phi_11 + T_12 * phi_21```\n for the first value of the result. Currently I'm using two for loops which are slow:\n\n```\nfor (int i = 0; i<M; ++i){\n    cv::Mat summedResult = cv::Mat(3, 1, CV_64F, double(0));\n    for (uint32 j = 0; j<N; ++j){\n        summedResult = summedResult + \n        (cv::Mat(mMatrixT.at<cv::Vec3d>(i, j)) * mMatrixPhi.at<double>(j));\n    }\n    // The result matrix contains values of type Vec3d again\n    mResultMatrix.at<cv::Vec3d>(i) = cv::Vec3d(summedResult);\n}\n```\n\n\nMore generally: Is it possible to efficiently multiply matrices containing ```\nVec3ds```\n and ```\ndouble```\ns in OpenCV?\n\n\n\n1. three dimensional vector containing doubles. \n\n2. coordinate: 1,1  \n\n3. coordinate: 1,2 \n    ", "Answer": "\r\nI still don't know what kind of result you expect, but maybe try this:\n\nAssuming that you have a MxN matrix of Vec3d and a Nx1 Matrix of type double, your result will be a Mx1 matrix of type Vec3d:\n\n```\nfor (int i = 0; i<M; ++i)\n    {\n        cv::Vec3d summedResult; // here this must be a Vec3d instead of a matrix, if I assume the right result expection\n        for (uint32 j = 0; j<N; ++j)\n        {\n            summedResult = summedResult + (mMatrixT.at<cv::Vec3d>(i, j) * mMatrixPhi.at<double>(j));\n        }\n        // The result matrix contains values of type Vec3d again\n        mResultMatrix.at<cv::Vec3d>(i) = summedResult;\n    }\n```\n\n\nEDIT: \n\nah sorry, didnt read to the end that your provided code works but is too slow... well, I expect that there is no optimization for that because mathematically this isnt defined. What you can do is to convert your Vec3d mat to a Mx(3*N) matrix and convert your Nx1 mat to a (3*N)x1 mat (3 times the same value before the next value) and use the OpenCV matrix product directly. But probably that's not faster because of the 3* bigger size of both matrices ;) \n\nEDIT: will be a different result, since each element will be the sum of the Vec3d elements...\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Perform matrix multiplication with cosine similarity function\r\n                \r\nI have two lists:\n\n```\nlist_1 = [['flavor', 'flavors', 'fruity_flavor', 'taste'],\n          ['scent', 'scents', 'aroma', 'smell', 'odor'],\n          ['mental_illness', 'mental_disorders','bipolar_disorder']\n          ['romance', 'romances', 'romantic', 'budding_romance']]\n\nlist_2 = [['love', 'eating', 'spicy', 'hand', 'pulled', 'noodles'],\n          ['also', 'like', 'buy', 'perfumes'],\n          ['suffer', 'from', 'clinical', 'depression'],\n          ['really', 'love', 'my', 'wife']]\n```\n\n\nI would like to compute the cosine similarity between the two lists above in such a way where the cosine similarity between the first sub-list in list1 and all sublists of list 2 are measured against each other. Then the same thing but with the second sub-list in list 1 and all sub-lists in list 2, etc.\n\nThe goal is to create a len(list_2) by len(list_1) matrix, and each entry in that matrix is a cosine similarity score. Currently I've done this the following way:\n\n```\nimport gensim\nimport numpy as np\nfrom gensim.models import KeyedVectors\n\nmodel = KeyedVectors.load_word2vec_format('./data/GoogleNews-vectors-negative300.bin.gz', binary=True) \nsimilarity_mat = np.zeros([len(list_2), len(list_1)])\n\nfor i, L2 in enumerate(list_2):\n    for j, L1 in enumerate(list_1):\n        similarity_mat[i, j] = model.n_similarity(L2, L1)\n```\n\n\nHowever, I'd like to implement this with matrix multiplication and no for loops. \n\nMy two questions are:\n\n\nIs there a way to do some sort of element-wise matrix multiplication but with ```\ngensim's n_similiarity() method```\n to generate the required matrix?\nWould it be more efficient and faster using the current method or matrix multiplication?\n\n\nI hope my question was clear enough, please let me know if I can clarify even further.\n    ", "Answer": "\r\nHere's an approach, but it's not clear from the question whether you understand the underlying mechanics of the calculation, which might be causing the block.\n\nI've changed the input strings to give more exact word matches, and given the two strings different dimensions to make it a bit clearer:\n\n```\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np\n\nlist_1 = [['flavor', 'flavors', 'fruity_flavor', 'taste'],\n         ['scent', 'my', 'aroma', 'smell', 'odor'],\n         ['mental_illness', 'mental_disorders','bipolar_disorder'],\n         ['romance', 'romances', 'romantic', 'budding_romance']]\n\nlist_2 = [['love', 'eating', 'spicy', 'hand', 'pulled', 'noodles'],\n          ['also', 'like', 'buy', 'perfumes'],\n          ['suffer', 'from', 'clinical', 'depression'],\n          ['really', 'love', 'my', 'wife'],\n          ['flavor', 'taste', 'romantic', 'aroma', 'what']]\n\ncnt = CountVectorizer()\n\n# Combine each sublist into single str, and join everything into corpus\ncombined_lists = ([' '.join(item) for item in list_1] +\n                  [' '.join(item) for item in list_2])\ncount_matrix = cnt.fit_transform(combined_lists).toarray()\n\n# Split them again into list_1 and list_2 word counts\ncount_matrix_1 = count_matrix[:len(list_1),]\ncount_matrix_2 = count_matrix[len(list_1):,]\nmatch_matrix = np.matmult(count_matrix_1, count_matrix_2.T)\n```\n\n\nOutput of match_matrix:\n\n```\narray([[0, 0, 0, 0, 2],\n       [0, 0, 0, 1, 1],\n       [0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1]], dtype=int64)\n```\n\n\nYou can see that the 1st string in ```\nlist_1```\n has 2 matches with the 5th string in ```\nlist_2```\n, and so on.\n\nSo the first part of the calculation (the dot product) has been calculated. Now we need the magnitudes:\n\n```\nmagnitudes = np.array([np.linalg.norm(count_matrix[i,:])\n                       for i in range(len(count_matrix))])\n```\n\n\nNow we can use matrix multiplication to turn that into a matrix of divisors (we need to reshape magnitudes into n x 1 and 1 x n matrices for this to produce an n x n matrix:\n\n```\ndivisor_matrix = np.matmul(magnitudes.reshape(len(magnitudes),1),\n                           magnitudes.reshape(1,len(magnitudes)))\n```\n\n\nNow since we didn't compare every single sublist, but only the list_1 with the list_2 sublists, we need to take a subsection of this divisor matrix to get the right magnitudes:\n\n```\ndivisor_matrix = divisor_matrix[:len(list_1), len(list_1):]\n```\n\n\nOutput:\n\n```\narray([[4.89897949, 4.        , 4.        , 4.        , 4.47213595],\n       [5.47722558, 4.47213595, 4.47213595, 4.47213595, 5.        ],\n       [4.24264069, 3.46410162, 3.46410162, 3.46410162, 3.87298335],\n       [4.89897949, 4.        , 4.        , 4.        , 4.47213595]])\n```\n\n\nNow we can calculate the final matrix of cosine similarity scores:\n\n```\ncos_sim = match_matrix / divisor_matrix\n```\n\n\nOutput:\n\n```\narray([[0.       , 0.       , 0.       , 0.       , 0.4472136],\n       [0.       , 0.       , 0.       , 0.2236068, 0.2      ],\n       [0.       , 0.       , 0.       , 0.       , 0.       ],\n       [0.       , 0.       , 0.       , 0.       , 0.2236068]])\n```\n\n\nNote these scores differ from the example given, since in the example every cosine similarity score would be 0.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Method of matrix multiplication between two numpy matrices of log2 elements\r\n                \r\nI have two ```\nnumpy```\n matrices ```\na_log2```\n and ```\nb_log2```\n of ```\nlog2```\n elements and I want to perform matrix multiplication between them.\n```\na = np.array([[0.4, 0.4, 0.2],\n          [0.1, 0.5, 0.4]])\n\nb = np.array([[0.3, 0.7],\n          [0.5, 0.5],\n          [0.2, 0.8]])\n\na_log2 = np.log2(a)\nb_log2 = np.log2(b)\n```\n\nI used to perform matrix multiplication of ```\ne-based logarithms```\n using ```\nscipy.special.logsumexp```\n. Here is the code I use (thanks to Erik Parkinson for his answer in this thread Handling matrix multiplication in log space in Python):\n```\ndef log_space_product(A,B):\n   Astack = np.stack([A]*A.shape[0]).transpose((2,1,0))\n   Bstack = np.stack([B]*B.shape[1]).transpose((1,0,2))\n   log_sum_exp = logsumexp(Astack+Bstack, axis=0)\n   return log_sum_exp\n```\n\nNow, I need your help in performing matrix multiplication between ```\na_log2```\n and ```\nb_log2```\n because ```\nscipy.special.logsumexp```\n was not defined for ```\nbase-2 logarithms```\n.\nNote:\nI was firstly planning to convert the matrix elements into ```\nnatural logarithms```\n using ```\na_loge[i, j] = np.log(2**a_log2[i, j])```\n and ```\nb_loge[i, j] = np.log(2**b_log2[i, j])```\n, and then using the aforementioned ```\nlog_space_product()```\n method to perform the matrix multiplication.\nBut I resisted myself doing that because the matrices I will eventually work with have ```\n> 1000```\n rows and ```\n> 20```\n columns. (Don't get confused with the numbers of rows and the number of columns here. I do ensure that the matrix multiplication properties are maintained.)\n    ", "Answer": "\r\nRemember that log2(x) = ln(x)/ln(2). We can rewrite that as ln(x) = c log2(x) with c = ln(2).  So conversion to/from log spaces with a different base is literally one multiplication.\n```\nfrom scipy.special import logsumexp\n\ndef log_space_product(A, B, base=np.e):\n    c = np.log(base)\n    Astack = np.stack([A]*A.shape[0]).transpose(2,1,0)\n    Bstack = np.stack([B]*B.shape[1]).transpose(1,0,2)\n    return (1/c) * logsumexp(c*(Astack+Bstack), axis=0)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication using transpose in C\r\n                \r\nI am a beginner in C.\nI was trying to write some code that would carry out matrix multiplication using transpose. \nIs there any way I can improve the code in terms of execution time?\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <time.h>\n\nint main()\n{   \n\n  int a[3][3] = {{1,0, 1}, {2, 2, 4},{1, 2, 3}};\n\n        int b[3][3] ={ { 2, 3, 1}, { 6, 6, 2 }, { 9, 9, 0 } };\n        int result[3][3];\n        double tmp;\n        int i,j,k;\n        for (i=0; i<3; i++) //i = col\n          {\n            for (k=0; k<3; k++)\n            {\n              tmp = a[i][k];\n              for (j=0; j<3; j++) //j = row\n              {\n                result[i][j] += tmp * b[k][j];\n                printf(\"%d\\t\",result[i][j]);\n              }\n            }\n          }\n}\n```\n\n    ", "Answer": "\r\nIf your matrix is ```\nint```\n, you really shouldn't use a ```\ndouble```\n as a temporary. Converting integer to floating-point and back again for no purpose is very wasteful, it can cost a lot.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Avoiding for loop in matrix multiplication\r\n                \r\nFor a matrix, A, of shape (m,n) and a diagonal matrix, lambda_diag, of shape (n,n).\n```\nimport numpy as np\nm, n = (44, 10)\nA = np.random.random((m,n))\nlambd = np.random.random(size=n)\nlambda_diag = np.diag(lambd)\n```\n\nI would like to calculate A @ lambda_diag @ At (where @ is the numpy matrix multiplication operator, and At is the transposed matrix).\nI would like to do this for values from (1:n). This is what I would do normally:\n```\nA_new = np.empty_like(A)\nA_new[:, 0] =  (A[:, 0] ** 2) * lambd[0]\nfor i in range(1, A.shape[1]):\n    A_new[:, i] = np.diag(\n        A[:, : i + 1]\n        @ np.diag(lambd[: i + 1])\n        @ A[:, : i + 1].T\n    ).flatten()\n```\n\nHowever the use of for loop is slow, and in general it seem cumbersome.\nDoes numpy have an inbuilt solution for this? Like how you would use ```\nnp.einsum()```\n.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Speed of matrix multiplication with Octave\r\n                \r\nI was curious just how fast matrix multiplication is with Octave 3.8.2, so I used the following code to time the multiplication of two 5000X5000 matrices:\n\n```\nX = rand(5000,5000);\nY = rand(5000,5000);\nBEFORE = time();\nZ = X*Y;\nAFTER = time();\ndisp(AFTER - BEFORE);\n```\n\n\nThe result was about 1 minute on average.  Using almost identical code, I did the same computation in Python with numpy matrices.  It took about 7.5 s.  \n\nI was surprised by these results, because I was under the impression that Octave is highly optimized for matrix computations.  Are my results typical?  Do people generally prefer Python over Octave when it comes to large scale matrix computations?  \n\nEDIT: Here is the numpy code...\n\n```\nX = numpy.matrix(numpy.random.rand(5000,5000))\nY = numpy.matrix(numpy.random.rand(5000,5000))\nBEFORE = time.process_time()\nZ = X*Y;\nAFTER = time.process_time()\nprint(AFTER - BEFORE)\n```\n\n    ", "Answer": "\r\nI cannot reproduce such bad results\n\n```\ntimesum = 0\nmaxtime = 0\nmintime = 100\nfor n = 1:100\n  x = rand(5000,5000);\n  y = rand(5000,5000);\n  tic\n  Z = x*y;\n  tmptime = toc;\n  timesum += tmptime;\n  maxtime = max(maxtime, tmptime);\n  mintime = min(mintime, tmptime);  \nend\ndisp(\"meantime\")\ndisp(timesum/100)\ndisp(\"maxtime\")\ndisp(maxtime)\ndisp(\"mintime\")\ndisp(mintime)\n\n\noctave:1> test1\ntimesum =                    0\nmaxtime =                    0\nmintime =                  100\nmeantime\n    4.34704959154129\nmaxtime\n      5.297199010849\nmintime\n    4.09799385070801\noctave:2> \n```\n\n\nOctave 4.0.0 on Haswell i5 Mobile.\n\nThe result with Matlab is nearly the same\n\n```\nmeantime\n    4.0443\n\nmaxtime\n    5.5522\n\nmintime\n    3.9679\n```\n\n\nThat's no surprise. They are using, more or less, the same libraries.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Optimizing Matrix Multiplication in Python\r\n                \r\nI'm currently working on a project that involves multiplying large matrices in Python. The matrices have dimensions A (m x n), B (n x p), and C (m x p), where m, n, and p can be very large (e.g., millions).\nTo perform the matrix multiplication, I have implemented a basic algorithm using nested loops. However, I've noticed that this implementation is quite slow when dealing with these large matrices. Thus, I'm looking for ways to optimize the code and improve its performance.\nHere's the current implementation I have:\n```\ndef matrix_multiplication(A, B):\n    m = len(A)\n    n = len(A[0])\n    p = len(B)\n\n    C = [[0] * p for _ in range(m)]\n\n    for i in range(m):\n        for j in range(p):\n            for k in range(n):\n                C[i][j] += A[i][k] * B[k][j]\n\n    return C\n\n# Example usage\nA = [[1, 2], [3, 4]]\nB = [[5, 6], [7, 8]]\nresult = matrix_multiplication(A, B)\nprint(result)\n```\n\nI would greatly appreciate your expertise and suggestions on how I can optimize this matrix multiplication algorithm in Python. Are there any built-in functions or libraries that can significantly improve the performance? Additionally, I'm open to considering alternative programming languages or techniques if they can provide better performance for this specific task.\nI tried implementing a matrix multiplication algorithm in Python using nested loops. My expectation was that the code would correctly multiply the matrices and return the resulting matrix. However, when I executed the code, I encountered an error.\nHere's the code I used:\n```\ndef matrix_multiplication(A, B):\n    m = len(A)\n    n = len(A[0])\n    p = len(B)\n\n    C = [[0] * p for _ in range(m)]\n\n    for i in range(m):\n        for j in range(p):\n            for k in range(n):\n                C[i][j] += A[i][k] * B[k][j]\n\n    return C\n\n# Example usage\nA = [[1, 2], [3, 4]]\nB = [[5, 6], [7, 8]]\nresult = matrix_multiplication(A, B)\nprint(result)\n```\n\nI expected the code to multiply the matrices A and B correctly and store the result in matrix C. Then, I expected the result variable to contain the multiplied matrix, which I would print to the console.\nHowever, when I ran the code, I encountered the following error:\n```\nIndexError: list index out of range\n```\n\nThank you in advance for your recommendations!\nThis error suggests that there is an issue with the dimensions of the matrices or the indexing within the nested loops. I'm not sure what went wrong and how to resolve this error.\n    ", "Answer": "\r\nThere is a typo in your code:\n```\n# p = len(B[0])\np = len(B)\n```\n\n```\nlen(B)```\n so that you can iterate on rows of ```\nB```\n matrix.\n\nUsing ```\nnumpy```\n, it is beautiful:\n```\nresult = np.dot(A, B)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "CPU Time for matrix matrix multiplication\r\n                \r\nI am trying to decide wether several similar but independent problems should be dealt with simultaneously or sequentially (possibly in parallel on different computers). In order to decide, I need to compare the cpu times of the following operations : \n\n\ntime_1 is the time for computing X(with shape (n,p)) @ b (with shape (p,1)).\ntime_k is the time for computing X(with shape (n,p)) @ B (with shape (p,k)).\n\n\nwhere X, b and B are random matrices. The difference between the two operations is the width of the second matrix. \n\nNaively, we expect that time_k = k x time_1. With faster matrix multiplication algorithms (Strassen algorithm, Coppersmith–Winograd algorithm), time_k could be smaller than k x time_1 but the complexity of these algorithms remains much larger than what I observed in practice. Therefore my question is :\nHow to explain the large difference in terms of cpu times for these two computations ? \n\n\n\nThe code I used is the following : \n\n```\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\n\np     = 100\nwidth = np.concatenate([np.arange(1, 20), np.arange(20, 100, 10), np.arange(100, 4000, 100)]).astype(int)\n\nmean_time = []\nfor nk, kk in enumerate(width):\n    timings = []\n    nb_tests = 10000 if kk <= 300 else 100\n    for ni, ii in enumerate(range(nb_tests)):\n        print('\\r[', nk, '/', len(width), ', ',  ni, '/', nb_tests, ']', end = '')\n        x     = np.random.randn(p).reshape((1, -1))\n        coef  = np.random.randn(p, kk)\n        d     = np.zeros((1, kk))\n        start = time.time()\n        d[:]  = x @ coef\n        end   = time.time()\n        timings.append(end - start)\n\n    mean_time.append(np.mean(timings))\n\nmean_time = np.array(mean_time)\n\n\nfig, ax = plt.subplots(figsize =(14,8))\nplt.plot(width, mean_time, label =  'mean(time\\_k)')\nplt.plot(width, width*mean_time[0], label = 'k*mean(time\\_1)')\nplt.legend()\nplt.xlabel('k')\nplt.ylabel('time (sec)')\nplt.show()\n```\n\n    ", "Answer": "\r\nThis detail of the reason is very complex. You know that when PC run the ```\nX @ b```\n, it will execute many other required instructions, maybe ```\nload data from RAM to cache```\n and so on. In other words, the cost time contains two parts - the 'real calculate instructions' in CPU represented by ```\nCost_A```\n and 'other required instructions' represented by ```\nCost_B```\n. I have a idea, just my guess, that it's the ```\nCost_B```\n lead to ```\ntime_k << k x time_1```\n.\n\nFor the shape of b is small (eg 1000 x 1), the 'other required instructions' cost relatively the most time. For the shape of b is huge (eg 1000 x 10000), it's relatively small. The following group of experiments could give a less rigorous proof. We can see that when the shape of b increases from (1000 x 1) to (1000 x ) the cost time increases very slowly.\n\n```\nimport numpy as np\nimport time\n\nX = np.random.random((1000, 1000))\n\nb = np.random.random((1000, 1))\nb3 = np.random.random((1000, 3))\nb5 = np.random.random((1000, 5))\nb7 = np.random.random((1000, 7))\nb9 = np.random.random((1000, 9))\nb10 = np.random.random((1000, 10))\nb30 = np.random.random((1000, 30))\nb60 = np.random.random((1000, 60))\nb100 = np.random.random((1000, 100))\nb1000 = np.random.random((1000, 1000))\n\ndef test_cost(X, b):\n    begin = time.time()\n    for i in range(100):\n        _ = X @ b\n    end = time.time()\n    print((end-begin)/100.)\n\ntest_cost(X, b)\ntest_cost(X, b3)\ntest_cost(X, b5)\ntest_cost(X, b7)\ntest_cost(X, b9)\ntest_cost(X, b10)\ntest_cost(X, b30)\ntest_cost(X, b60) \ntest_cost(X, b100)\ntest_cost(X, b1000)\n\noutput:\n0.0003210139274597168\n0.00040063619613647463\n0.0002452659606933594\n0.00026523590087890625\n0.0002449488639831543\n0.00024344682693481446\n0.00040068864822387693\n0.000691361427307129\n0.0011700797080993653\n0.009680757522583008\n```\n\n\nFor more, I do a set of experiments with ```\npref```\n in linux. For the ```\npref```\n, the ```\nCost_B```\n maybe more big. I have 8 python files, the first one is as follows.\n\n```\nimport numpy as np\nimport time\ndef broken2():\n    mtx = np.random.random((1, 1000))\n    c = None\n    c = mtx ** 2\n\nbroken2()\n```\n\n\nI had process the output to table A, as follows.\n\n\nI do a simple analysis that I divide the error of the number of operation  (likes, cache-misses) in neighbor experiments by the error of ```\ntime elapsed(seconds)```\n . Then, I get the following table B. From the table, we can find that as the shape of b increasing the linear relation between of shape and cost time is more obvious. And maybe the main reason that lead to ```\ntime_k << k x time_1```\n is ```\ncache misses```\n(load data from RAM to cache), for it stabilized firstly. \n\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Creating different matrix by same matrix-matrix multiplication inside loop using python\r\n                \r\nI have a square matrix of dimension n*n. I have to define a function which takes this matrix ```\nA```\n as input and also a value ```\nk```\n. \nMatrix A is random matrix generated by numpy random function.\nSuppose k=4 then we have to produce three different matrices such that:\n\n```\n matrix_2=A*A\n matrix_3=A*A*A\n matrix_4=A*A*A*A\n```\n\n\nWhere all multiplication above are matrix multiplication( where columns A = Row of B), not element wise multiplication.\n\nk can have any value given by user. How can we implement this using for loop in python.\n    ", "Answer": "\r\nUse ```\nlist```\n or ```\ndict```\n for a variable number of variables. In this case, you can use a dictionary comprehension, with dictionary keys aligned with the power:\n\n```\nfrom numpy.linalg import matrix_power\n\nnp.random.seed(0)\n\nn = 2\nA = np.random.random((n, n))\n\ndef make_arrays(arr, k):\n    return {i: matrix_power(arr, i) for i in range(1, k+1)}\n\nres = make_arrays(A, 4)\n```\n\n\nResult:\n\n```\n{1: array([[0.5488135 , 0.71518937],\n           [0.60276338, 0.54488318]]),\n 2: array([[0.73228622, 0.78220024],\n           [0.65924031, 0.72798764]]),\n 3: array([[0.87337022, 0.94993107],\n           [0.80060427, 0.86814988]]),\n 4: array([[1.05190103, 1.14222656],\n           [0.96267139, 1.04562393]])}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Vector matrix multiplication, float vector, binary matrix\r\n                \r\nI'd like to multiply a float vector of size N with a matrix of size NxM.\n\nThe matrix is a binary matrix (containing only zero and 1) and is relatively sparse: density of non-zero values is between 1-5%.\n\nCurrently, I'm forming this as a dense vector and sparse float matrix multiplication. \n\nBut that's just an overkill isn't it?\n\nWhat if I store the columns of matrix as bitset and then multiplication is simply using bitset for indexing vector and then summing it up.\n\nI assume I could form this as a vectorized operation in SSE/AVX, something like load + and + sum or load + mask + sum\n\nI'd appreciate if you could point me to the right intrinsics for doing this, the main question is what is the best way in dealing with unpacking the bitset?\n    ", "Answer": "\r\nSo each element of your result vector is a masked sum of input vector?  And those masks come from columns of the matrix so they're not contiguous bits.\n\nA masked sum using a contiguous bitmap is trivial with AVX512 (just use merge-masked add, or zero-masked loads).  With SSE/AVX2 you'd use is there an inverse instruction to the movemask instruction in intel avx2? + ```\n_mm256_and_ps```\n.  Or some variation on that which optimizes across mask vectors, e.g. with a 32-bit broadcast load and then shifting that for the next step.  Instead of doing another unaligned dword broadcast for each byte.\n\nBut with your mask bits not contiguous you have a choice:\n\n\nDo each output vector element separately, with a horizontal sum at the end.  Requires gathering bits and making a vector mask.  Probably hard except for the M=32 case where the bit stride already lines them up with contiguous 32-bit floats.\naccumulate a vector of 4 or 8 output elements, using contiguous groups of 4 or 8 mask bits.  So you vectorize over the outer loop, doing broadcast loads in the inner loop over the input vector.    USE THIS. You should actually unroll with multiple vector sums to hide FP add latency.\n\n\nBroadcast-loads like ```\n__m256 v = _mm256_set1_ps(invec[i])```\n are basically free (```\nvbroadcastss```\n is a pure load uop, no ALU shuffle uop).  You don't need any other shuffling of floats, just pure vertical SIMD, even at the end of the loop: you just ```\n_mm256_storeu_ps```\n into the output vector.\n\nAnd you're using contiguous groups of mask bits so the usual inverse-movemask Q&As are useful.\n\n```\n  // untested, rough outline of what it might look like\n\n  uint8_t matrix[rows * cols];  // bit matrix in chunks of 8 bits\n  float invec[N], outvec[N];    // A normal function will just take pointer inputs.\n\n  constexpr int unroll = 4;\n  for(int outpos = 0 ; outpos < M-8*unroll+1 ; outpos += 8 * unroll) {\n      __m256 sum0, sum1, sum2, sum3;  //optionally use an array of accumulators, sums[unroll];\n      sum0 = sum1 = sum2 = sum3 = _mm256_setzero_ps();\n            // optionally peel the first inner iteration to just load+mask without adding to 0.0\n      for (int inpos = 0 ; in < N ; in++ ){\n          __m256 inv = _mm256_set1_ps(invec[inpos]);\n          __m256 mask0 = inverse_movemask(matrix[outpos*stride + inpos + 0]);  // 8 bits -> 8 vector elements\n          __m256 mask1 = inverse_movemask(matrix[outpos*stride + inpos + 1]);\n          ...\n\n          sum0 = _mm256_add_ps(sum0, _mm256_and_ps(inv, mask0) );  // add in[i] or 0.0 according to mask\n          sum1 = _mm256_add_ps(sum1, _mm256_and_ps(inv, mask1) );\n          ...\n      }\n      __m256_storeu_ps(&outvec[outpos + 0*8], sum0);\n      __m256_storeu_ps(&outvec[outpos + 1*8], sum1);\n      __m256_storeu_ps(&outvec[outpos + 2*8], sum2);\n      ...\n  }\n\n  not-unrolled __m256 and/or __m128 cleanup for M % (8*unroll) != 0\n\n  cleanup for M % 4 != 0 using __m128 broadcast loads \n    for the last 1..3 rows of masks\n    maybe use a masked store (AVX2 vmaskmov) or pad your output vector\n```\n\n\nEach inner loop iteration masks one float ```\n8 * unroll```\n different ways, and accumulates into the corresponding ```\n8 * unroll```\n different running totals.  (Across ```\nunroll```\n vectors of 8 floats each.)\n\n\n\nThis is also great for memory bandwidth\n\nYou only ever read each bitmap bit once in a vec*mat product, but the input vector is effectively used ```\nM```\n times.  Looping over contiguous bitmap rows gives good locality, not requiring any of those cache lines to be loaded more than once.\n\nEven with AVX512 and 2x ```\n_mm512_mask_add_ps```\n per clock, 1 bit per FP element added is not much bandwidth for the bitmap loads.\n\nHowever, you loop over your input vector ```\nM/(8*unroll)```\n times.  The masked adds for each sum vector use different mask bits but the same broadcasted input ```\nfloat```\n.  Since the matrix elements are 32x smaller than the vector elements, this is not bad.\n\nOne float loaded per 4x or 8x ```\nvaddps```\n instructions is very good computational intensity.  Especially without AVX512, where bitmap -> vector mask will cost cycles.\n\nTo help even more with cache / memory bandwidth, cache-blocking / loop-tiling for L2 cache size (256kiB) might be possible to help with reuse of input vector elements.  But I'm not sure if you can usefully block for both input and output.  Unlike a mat*mat product, there's only O(n^2) work to do.  Rereading input and just writing one output stream is probably fine, but you could find a middle ground that adds partial results into partial chunks of the output vector.  But then aren't reading the bit matrix in one contiguous stream anymore.  As long as you stop at cache-line boundaries it's probably fine.\n\n\n\nIf your ```\nNxM```\n matrix happens to have ```\nM = 32```\n then that matches the size of a ```\nfloat```\n exactly, and ```\n_mm256_loadu_si256```\n will get a vector that has the mask bits for ```\noutvec[0]```\n in the low bit of every element.  And the mask bits for ```\noutvec[31]```\n in the high bit.   You can use ```\n_mm256_blendv_ps```\n to apply them to the input of a sum, and left-shift by 1 to move the next bit up to the top position.  (An alternative to ```\nvblendvps```\n is ```\npsrad```\n by 31 + ```\nandps```\n: an arithmetic right shift to broadcast the top bit to all positions).\n\nBut this might not be any better than the other way, even for this special case.  You can unroll over multiple output elements in different vectors so you can reuse the float vector a few times.\n\n\n\nWith AVX512F you can just use the matrix rows as ```\n__mmask16```\n values for a masked add like ```\n_mm512_mask_add_ps```\n.\n```\nsum = _mm512_mask_add_ps(sum, matrix[col*rowstride + row], sum, invec[i]);```\n if ```\nmatrix```\n is an array of ```\nuint16_t```\n.\n\nOr with AVX512BW, ```\nkmovq```\n 64 bits of mask into a ```\nk```\n register and ```\nkshift```\n it down, to match up with an unroll over 4 vector accumulators.  Unfortunately ```\nkmov k, [mem]```\n is 2 uops on Skylake-X: load + port 5, not just a load uop that can write to mask regs.  So one load an 3x unpack with ```\nkshift```\n is pure win vs. 4x ```\nkmovw k1, [mem]```\n / ```\nkmovw k2, [mem+2]```\n etc.  No way to get each 16 bits of mask data at the bottom of a ```\nk```\n register without a port5 uop for each one.  So it competes with 512-bit FMA/add/mul throughput on SKX cores that have 2 FMA units, otherwise just front-end throughput cost.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication with ndarray\r\n                \r\nHow to perform a vector and matrix multiplication\n where v is a vector (v1, v2, v3) and A is a 3x3 matrix? Python complains about shapes not aligned, maybe because v is an ndarray. Any ideas on how to do this operation? the final result should be a scalar at each coordinate point (v1, v2, v3). The basic code below breaks when trying to carry the multiplication.\n\n```\nimport numpy as np\na = np.linspace(0, 10, 21)\nb = np.linspace(0, 20, 41)\na, b = np.meshgrid(a,b)\nv = np.array([a*b, a+b, a])\nA = np.ones([3,3])\ns = v.T @ A @ v     # doesn't work\n```\n\n\nError\n\n```\n----> 1 s = v.T @ A @ v    \nValueError: shapes (21,41,3) and (3,41,21) not aligned: 3 (dim 2) != 41 (dim 1)\n```\n\n\nEdit: the matrix operation should be done at each point v, where v is usually a large array (of vectors). For example take a 1m cube with its center at the origin, and evaluate the matrix operation at each grid point, say every 10cm in each coordinate axis.\n\nedit 2 example for a single point at (x,y,z)\n\n```\nA = np.zeros([3,3])\nA[0][0] = 1\nA[1][1] = 2\nA[2][2] = 3\nx,y,z = 1, 1, 0\nv = np.array([x, y, z])\ns = v.T @ A @ v   # should give s=3\n```\n\n\nThe next step is to make the code work for a large array of vectors v. Except it's a little more involved because the vector coordinates (x,y,z) need to be parameterized in terms of coordinates (a,b). The original code above tries to do that, but doesn't work and may not be the best approach. Any other ideas?\n    ", "Answer": "\r\nIt seems by the mention of the vector ```\nv```\n of three elements, you meant an ndarray with three elements along its first axis, with each elements holding a n-dim array data. For the listed sample, you have the same as a 3D array.\nIt also seems that the output is to be reduced to a scalar for each of the vector of three elements, i.e. the output would be 2D.\nSo, to solve your case, we need to use tensor multiplication for the first : ```\nV.T @ A```\n sum-reducing the first axes, giving us a 3D array. Then, use ```\neinsum```\n to keep the first two axes aligned and sum-reduce the last ones, like so -\n\n```\np1 = np.tensordot(v,A,axes=((0,0)))\nout = np.einsum('jkl,ljk->jk',p1,v)\n```\n\n\nAlternatively, using ```\neinsum```\n we can do all in one step, like so -\n\n```\nout = np.einsum('ijk,il,ljk->jk',v,A,v)\n```\n\n\nWe can possibly make it faster with ```\neinsum's```\n optional arg : ```\noptimize```\n set as ```\nTrue```\n :\n\n```\nnp.einsum(..., optimize=True)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Efficient SSE NxN matrix multiplication\r\n                \r\nI'm trying to implement ```\nSSE```\n version of large matrix by matrix multiplication.\n I'm looking for an efficient algorithm based on ```\nSIMD```\n implementations.\n\nMy desired method looks like:\n\n```\nA(n x m) * B(m x k) = C(n x k)\n```\n\n\nAnd all matrices are considered to be 16-byte aligned float array.\n\nI searched the net and found some articles describing 8x8 multiplication and even smaller. I really need it as efficient as possible and I don't want to use ```\nEigen```\n library or similar libraries. (Only ```\nSSE3```\n to be more specific).\n\nSo I'd appreciate if anyone can help me find some articles or resources on how to start implementing this.\n    ", "Answer": "\r\nThe main challenge in implementation of arbitrary-size matrix-matrix multiplication is not the use of SIMD, but reuse of cached data. The paper Anatomy of High-Performance Matrix Multiplication by Goto and Van de Geijn is a must-read if you want to implement cache-friendly matrix-matrix multiplication, and it also discusses the choice of kernels to be SIMD-friendly. After reading this paper expect to achieve 50% of machine peak on matrix-matrix multiplication after two weeks of efforts.\n\nHowever, if the purpose of this work is not pure learning, I strongly recommend to use a highly optimized library. On x86 your best options are OpenBLAS (BSD-licensed, supports dynamic CPU dispatching), BLIS (BSD-licensed, easily portable to new processors), and Intel MKL (commercial, supports dynamic CPU dispatching on Intel processors). For performance reasons it is better to avoid ATLAS unless you target a very exotic architecture which is not supported by other libraries.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication with goroutine drops performance\r\n                \r\nI am optimizing matrix multiplication via goroutines in Go.\n\nMy benchmark shows, introducing concurrency per row or per element largely drops performance:\n\n```\ngoos: darwin\ngoarch: amd64\nBenchmarkMatrixDotNaive/A.MultNaive-8                            2000000               869 ns/op               0 B/op          0 allocs/op\nBenchmarkMatrixDotNaive/A.ParalMultNaivePerRow-8                  100000             14467 ns/op              80 B/op          9 allocs/op\nBenchmarkMatrixDotNaive/A.ParalMultNaivePerElem-8                  20000             77299 ns/op             528 B/op         65 allocs/op\n```\n\n\nI know some basic prior knowledge of cache locality, it make sense that per element concurrency drops performance. However, why per row still drops the performance even in naive version?\n\nIn fact, I also wrote a block/tiling optimization, its vanilla version (without goroutine concurrency) even worse than naive version (not present here, let's focus on naive first). \n\nWhat did I do wrong here? Why? How to optimize here?\n\nMultiplication:\n\n```\npackage naive\n\nimport (\n    \"errors\"\n    \"sync\"\n)\n\n// Errors\nvar (\n    ErrNumElements = errors.New(\"Error number of elements\")\n    ErrMatrixSize  = errors.New(\"Error size of matrix\")\n)\n\n// Matrix is a 2d array\ntype Matrix struct {\n    N    int\n    data [][]float64\n}\n\n// New a size by size matrix\nfunc New(size int) func(...float64) (*Matrix, error) {\n    wg := sync.WaitGroup{}\n    d := make([][]float64, size)\n    for i := range d {\n        wg.Add(1)\n        go func(i int) {\n            defer wg.Done()\n            d[i] = make([]float64, size)\n        }(i)\n    }\n    wg.Wait()\n    m := &Matrix{N: size, data: d}\n    return func(es ...float64) (*Matrix, error) {\n        if len(es) != size*size {\n            return nil, ErrNumElements\n        }\n        for i := range es {\n            wg.Add(1)\n            go func(i int) {\n                defer wg.Done()\n                m.data[i/size][i%size] = es[i]\n            }(i)\n        }\n        wg.Wait()\n        return m, nil\n    }\n}\n\n// At access element (i, j)\nfunc (A *Matrix) At(i, j int) float64 {\n    return A.data[i][j]\n}\n\n// Set set element (i, j) with val\nfunc (A *Matrix) Set(i, j int, val float64) {\n    A.data[i][j] = val\n}\n\n// MultNaive matrix multiplication O(n^3)\nfunc (A *Matrix) MultNaive(B, C *Matrix) (err error) {\n    var (\n        i, j, k int\n        sum     float64\n        N       = A.N\n    )\n\n    if N != B.N || N != C.N {\n        return ErrMatrixSize\n    }\n\n    for i = 0; i < N; i++ {\n        for j = 0; j < N; j++ {\n            sum = 0.0\n            for k = 0; k < N; k++ {\n                sum += A.At(i, k) * B.At(k, j)\n            }\n            C.Set(i, j, sum)\n        }\n    }\n    return\n}\n\n// ParalMultNaivePerRow matrix multiplication O(n^3) in concurrency per row\nfunc (A *Matrix) ParalMultNaivePerRow(B, C *Matrix) (err error) {\n    var N = A.N\n\n    if N != B.N || N != C.N {\n        return ErrMatrixSize\n    }\n\n    wg := sync.WaitGroup{}\n    for i := 0; i < N; i++ {\n        wg.Add(1)\n        go func(i int) {\n            defer wg.Done()\n            for j := 0; j < N; j++ {\n                sum := 0.0\n                for k := 0; k < N; k++ {\n                    sum += A.At(i, k) * B.At(k, j)\n                }\n                C.Set(i, j, sum)\n            }\n        }(i)\n    }\n    wg.Wait()\n    return\n}\n\n// ParalMultNaivePerElem matrix multiplication O(n^3) in concurrency per element\nfunc (A *Matrix) ParalMultNaivePerElem(B, C *Matrix) (err error) {\n    var N = A.N\n\n    if N != B.N || N != C.N {\n        return ErrMatrixSize\n    }\n\n    wg := sync.WaitGroup{}\n    for i := 0; i < N; i++ {\n        for j := 0; j < N; j++ {\n            wg.Add(1)\n            go func(i, j int) {\n                defer wg.Done()\n                sum := 0.0\n                for k := 0; k < N; k++ {\n                    sum += A.At(i, k) * B.At(k, j)\n                }\n                C.Set(i, j, sum)\n            }(i, j)\n        }\n    }\n    wg.Wait()\n    return\n}\n```\n\n\nBenchmark:\n\n```\npackage naive\n\nimport (\n    \"os\"\n    \"runtime/trace\"\n    \"testing\"\n)\n\ntype Dot func(B, C *Matrix) error\n\nvar (\n    A = &Matrix{\n        N: 8,\n        data: [][]float64{\n            []float64{1, 2, 3, 4, 5, 6, 7, 8},\n            []float64{9, 1, 2, 3, 4, 5, 6, 7},\n            []float64{8, 9, 1, 2, 3, 4, 5, 6},\n            []float64{7, 8, 9, 1, 2, 3, 4, 5},\n            []float64{6, 7, 8, 9, 1, 2, 3, 4},\n            []float64{5, 6, 7, 8, 9, 1, 2, 3},\n            []float64{4, 5, 6, 7, 8, 9, 1, 2},\n            []float64{3, 4, 5, 6, 7, 8, 9, 0},\n        },\n    }\n    B = &Matrix{\n        N: 8,\n        data: [][]float64{\n            []float64{9, 8, 7, 6, 5, 4, 3, 2},\n            []float64{1, 9, 8, 7, 6, 5, 4, 3},\n            []float64{2, 1, 9, 8, 7, 6, 5, 4},\n            []float64{3, 2, 1, 9, 8, 7, 6, 5},\n            []float64{4, 3, 2, 1, 9, 8, 7, 6},\n            []float64{5, 4, 3, 2, 1, 9, 8, 7},\n            []float64{6, 5, 4, 3, 2, 1, 9, 8},\n            []float64{7, 6, 5, 4, 3, 2, 1, 0},\n        },\n    }\n    C = &Matrix{\n        N: 8,\n        data: [][]float64{\n            []float64{0, 0, 0, 0, 0, 0, 0, 0},\n            []float64{0, 0, 0, 0, 0, 0, 0, 0},\n            []float64{0, 0, 0, 0, 0, 0, 0, 0},\n            []float64{0, 0, 0, 0, 0, 0, 0, 0},\n            []float64{0, 0, 0, 0, 0, 0, 0, 0},\n            []float64{0, 0, 0, 0, 0, 0, 0, 0},\n            []float64{0, 0, 0, 0, 0, 0, 0, 0},\n            []float64{0, 0, 0, 0, 0, 0, 0, 0},\n        },\n    }\n)\n\nfunc BenchmarkMatrixDotNaive(b *testing.B) {\n    f, _ := os.Create(\"bench.trace\")\n    defer f.Close()\n    trace.Start(f)\n    defer trace.Stop()\n\n    tests := []struct {\n        name string\n        f    Dot\n    }{\n        {\n            name: \"A.MultNaive\",\n            f:    A.MultNaive,\n        },\n        {\n            name: \"A.ParalMultNaivePerRow\",\n            f:    A.ParalMultNaivePerRow,\n        },\n        {\n            name: \"A.ParalMultNaivePerElem\",\n            f:    A.ParalMultNaivePerElem,\n        },\n    }\n    for _, tt := range tests {\n        b.Run(tt.name, func(b *testing.B) {\n            for i := 0; i < b.N; i++ {\n                tt.f(B, C)\n            }\n        })\n    }\n}\n```\n\n    ", "Answer": "\r\nPerforming 8x8 matrix multipliciation is relatively small work.\n\nGoroutines (although may be lightweight) do have overhead. If the work they do is \"small\", the overhead of launching, synchronizing and throwing them away may outweight the performance gain of utilizing multiple cores / threads, and overall you might not gain performance by executing such small tasks concurrently (hell, you may even do worse than without using goroutines). Measure.\n\nIf we increase the matrix size to 80x80, running the benchmark we already see some performance gain in case of ```\nParalMultNaivePerRow```\n:\n\n```\nBenchmarkMatrixDotNaive/A.MultNaive-4               2000     1054775 ns/op\nBenchmarkMatrixDotNaive/A.ParalMultNaivePerRow-4    2000      709367 ns/op\nBenchmarkMatrixDotNaive/A.ParalMultNaivePerElem-4    100    10224927 ns/op\n```\n\n\n(As you see in the results, I have 4 CPU cores, running it on your 8-core machine might show more performance gain.)\n\nWhen rows are small, you are using goroutines to do minimal work, you may improve performance by not \"throwing\" away goroutines once they're done with their \"tiny\" work, but you may \"reuse\" them. See related question: Is this an idiomatic worker thread pool in Go?\n\nAlso see related / possible duplicate: Vectorise a function taking advantage of concurrency\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Does scipy support multithreading for sparse matrix multiplication when using MKL BLAS?\r\n                \r\nAccording to MKL BLAS documentation\n\"All matrix-matrix operations (level 3) are threaded for both dense and sparse BLAS.\"\nhttp://software.intel.com/en-us/articles/parallelism-in-the-intel-math-kernel-library\n\nI have built Scipy with MKL BLAS. Using the test code below, I see the expected multithreaded speedup for dense, but not sparse, matrix multiplication.  Are there any changes to Scipy to enable multithreaded sparse operations?\n\n```\n# test dense matrix multiplication\nfrom numpy import *\nimport time    \nx = random.random((10000,10000))\nt1 = time.time()\nfoo = dot(x.T, x)\nprint time.time() - t1\n\n# test sparse matrix multiplication\nfrom scipy import sparse\nx = sparse.rand(10000,10000)\nt1 = time.time()\nfoo = dot(x.T, x)\nprint time.time() - t1\n```\n\n    ", "Answer": "\r\nAs far as I know, the answer is no. But, you can build your own wrapper around the MKL sparse multiply routines. You asked about the multiplying two sparse matrices. Below is some a wrapper code I used for multiplying one sparse matrix times a dense vector, so it shouldn't be hard to adapt (look at the Intel MKL reference for mkl_cspblas_dcsrgemm). Also, be aware of how your scipy arrays are stored: default is coo, but csr (or csc) may be better choices. I chose csr, but MKL supports most types (just call the appropriate routine).\n\nFrom what I could tell, both scipy's default and MKL are multithreaded. By changing ```\nOMP_NUM_THREADS```\n I could see a difference in performance.\n\nTo use the function below, if you havea a recent version of MKL, just make sure you have ```\nLD_LIBRARY_PATHS```\n set to include the relevant MKL directories. For older versions, you need to build some specific libraries. I got my information from IntelMKL in python\n\n```\ndef SpMV_viaMKL( A, x ):\n \"\"\"\n Wrapper to Intel's SpMV\n (Sparse Matrix-Vector multiply)\n For medium-sized matrices, this is 4x faster\n than scipy's default implementation\n Stephen Becker, April 24 2014\n stephen.beckr@gmail.com\n \"\"\"\n\n import numpy as np\n import scipy.sparse as sparse\n from ctypes import POINTER,c_void_p,c_int,c_char,c_double,byref,cdll\n mkl = cdll.LoadLibrary(\"libmkl_rt.so\")\n\n SpMV = mkl.mkl_cspblas_dcsrgemv\n # Dissecting the \"cspblas_dcsrgemv\" name:\n # \"c\" - for \"c-blas\" like interface (as opposed to fortran)\n #    Also means expects sparse arrays to use 0-based indexing, which python does\n # \"sp\"  for sparse\n # \"d\"   for double-precision\n # \"csr\" for compressed row format\n # \"ge\"  for \"general\", e.g., the matrix has no special structure such as symmetry\n # \"mv\"  for \"matrix-vector\" multiply\n\n if not sparse.isspmatrix_csr(A):\n     raise Exception(\"Matrix must be in csr format\")\n (m,n) = A.shape\n\n # The data of the matrix\n data    = A.data.ctypes.data_as(POINTER(c_double))\n indptr  = A.indptr.ctypes.data_as(POINTER(c_int))\n indices = A.indices.ctypes.data_as(POINTER(c_int))\n\n # Allocate output, using same conventions as input\n nVectors = 1\n if x.ndim is 1:\n    y = np.empty(m,dtype=np.double,order='F')\n    if x.size != n:\n        raise Exception(\"x must have n entries. x.size is %d, n is %d\" % (x.size,n))\n elif x.shape[1] is 1:\n    y = np.empty((m,1),dtype=np.double,order='F')\n    if x.shape[0] != n:\n        raise Exception(\"x must have n entries. x.size is %d, n is %d\" % (x.size,n))\n else:\n    nVectors = x.shape[1]\n    y = np.empty((m,nVectors),dtype=np.double,order='F')\n    if x.shape[0] != n:\n        raise Exception(\"x must have n entries. x.size is %d, n is %d\" % (x.size,n))\n\n # Check input\n if x.dtype.type is not np.double:\n    x = x.astype(np.double,copy=True)\n # Put it in column-major order, otherwise for nVectors > 1 this FAILS completely\n if x.flags['F_CONTIGUOUS'] is not True:\n    x = x.copy(order='F')\n\n if nVectors == 1:\n    np_x = x.ctypes.data_as(POINTER(c_double))\n    np_y = y.ctypes.data_as(POINTER(c_double))\n    # now call MKL. This returns the answer in np_y, which links to y\n    SpMV(byref(c_char(\"N\")), byref(c_int(m)),data ,indptr, indices, np_x, np_y ) \n else:\n    for columns in xrange(nVectors):\n        xx = x[:,columns]\n        yy = y[:,columns]\n        np_x = xx.ctypes.data_as(POINTER(c_double))\n        np_y = yy.ctypes.data_as(POINTER(c_double))\n        SpMV(byref(c_char(\"N\")), byref(c_int(m)),data,indptr, indices, np_x, np_y ) \n\n return y\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "async in matrix multiplication\r\n                \r\nI'm trying to make concurrent matrix multiplication in my code. The teacher said to me I have to use async in my do_multiply function, but I don't know how to do it. I think that do_multiply has to start a thread and then has to wait for the result. Here is my do_multiply function:\n\n```\n    void do_multiply(matrix_wrap<T> result, matrix_wrap<T> lhs, matrix_wrap<T> rhs) {\n              const unsigned height = result.get_height();\n              const unsigned width = result.get_width();\n              const unsigned span = lhs.get_width();\n              assert(span==rhs.get_height());\n              for (unsigned i=0; i!=height; ++i)\n                 for (unsigned j=0; j!=width; ++j) {\n                       result(i, j) = 0;\n                       for (unsigned k = 0; k != span; ++k)\n                         result(i, j) += lhs(i, k) * rhs(k, j);                   \n                  }\n\n               }\n```\n\n\nWhere lhs is the first matrix and rhs the second one. \nI think I have to write something like:\n\n```\n auto f = std::async(std::launch::async, add, std::ref(result(i,j)));\n f.get();\n```\n\n\ninstead of \n\n```\nresult(i, j) += lhs(i, k) * rhs(k, j);\n```\n\n\nbut I really don't know how and if it works, I only have errors so the code is not builded. Any suggestion?\n    ", "Answer": "\r\nThe multiplication of an MxN matrix and an NxP matrix will result in a matrix with size MxP. Note that when multiplying the values, you have to perform separate operations for each component of the matrix. What you should try is launching the computation of each matrix element separately. Since each task is writing to a different memory location, there will be no race conditions do you don't have to worry about synchronization. \n\nMake sure you wait for all the tasks to complete before returning! It should look something like this: \n\n```\nvoid do_multiply(matrix_wrap<T> result, matrix_wrap<T> lhs, matrix_wrap<T> rhs) {\n    // here you should probably assert that the result, lhs, and rhs are of compatible\n    // sizes. \n\n    // lambda function that will be launched once for each output matrix element.\n    auto compute_element = [&result, &lhs, &rhs](int row, int col)\n    {\n        T value = T(0);\n        ... //compute value here. \n        result(row, col) = value;\n    };\n\n    std::vector<std::future<void>> tasks;\n    tasks.reserve(result.rows() * result.cols());\n    //launch all async tasks. \n    for(int row = 0; row < result.rows(); row++)\n    {\n        for (int col = 0; col < result.cols(); col++)\n        {\n            auto task = std::async(std::launch::async, compute_element, row, col);\n            taks.push_back(move(task));\n        }\n    }\n\n    //task.get() will only return once the task is finished. \n    for(auto& task: tasks)\n    {\n        task.get();\n    }\n    //now all tasks are finished, so we can be sure that all elements\n    //of the result matrix are populated. \n}\n```\n\n\nNote that for small matricies (less than hundreds of rows and columns), doing the multiplication this way is most likely slower that just doing it in a single thread. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "3d matrix multiplication into multiple 2d matrix multiplications\r\n                \r\nI have two 3d matrices ```\nX```\n and ```\nY```\n both of which have the shape ```\n(5, 1825, 77)```\n. I'd like to do five 2d matrix multiplications, i.e., ```\nX[i, :, :]@Y[i, :, :].T```\n without using a for loop. Is there a way to do this in numpy?\n    ", "Answer": "\r\nThis is interesting for those (like me) who try to avoid for loops at any cost:\n```\nshape = 5, 1825, 77\nX = np.random.random(shape)\nY = np.random.random(shape)\n\np_for = np.empty((shape[0], shape[1], shape[1]))\nfor i in range(shape[0]):\n    p_for[i] = X[i] @ Y[i].T\n\np_matmul = X @ np.moveaxis(Y, -1, 1)\nassert np.allclose(p_for, p_matmul)\n\np_einsum = np.einsum(\"ijk,ilk->ijl\", X, Y)\nassert np.allclose(p_for, p_einsum)\n```\n\nThe tree methods produce the same result, but, as @JérômeRichard points out:\n```\n%%timeit\nprod = np.empty((shape[0], shape[1], shape[1]))\nfor i in range(5):\n    prod[i] = X[i, :, :] @ Y[i, :, :].T\n50.4 ms ± 7.18 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n%timeit X @ np.moveaxis(Y, -1, 1)\n115 ms ± 1.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n%timeit np.einsum(\"ijk,ilk->ijl\", X, Y)\n544 ms ± 3.22 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Why is matrix multiplication faster with numpy than with ctypes in Python?\r\n                \r\nI was trying to figure out the fastest way to do matrix multiplication and tried 3 different ways:\n\n\nPure python implementation: no surprises here.\nNumpy implementation using ```\nnumpy.dot(a, b)```\n\nInterfacing with C using ```\nctypes```\n module in Python.\n\n\nThis is the C code that is transformed into a shared library:\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n\nvoid matmult(float* a, float* b, float* c, int n) {\n    int i = 0;\n    int j = 0;\n    int k = 0;\n\n    /*float* c = malloc(nay * sizeof(float));*/\n\n    for (i = 0; i < n; i++) {\n        for (j = 0; j < n; j++) {\n            int sub = 0;\n            for (k = 0; k < n; k++) {\n                sub = sub + a[i * n + k] * b[k * n + j];\n            }\n            c[i * n + j] = sub;\n        }\n    }\n    return ;\n}\n```\n\n\nAnd the Python code that calls it:\n\n```\ndef C_mat_mult(a, b):\n    libmatmult = ctypes.CDLL(\"./matmult.so\")\n\n    dima = len(a) * len(a)\n    dimb = len(b) * len(b)\n\n    array_a = ctypes.c_float * dima\n    array_b = ctypes.c_float * dimb\n    array_c = ctypes.c_float * dima\n\n    suma = array_a()\n    sumb = array_b()\n    sumc = array_c()\n\n    inda = 0\n    for i in range(0, len(a)):\n        for j in range(0, len(a[i])):\n            suma[inda] = a[i][j]\n            inda = inda + 1\n        indb = 0\n    for i in range(0, len(b)):\n        for j in range(0, len(b[i])):\n            sumb[indb] = b[i][j]\n            indb = indb + 1\n\n    libmatmult.matmult(ctypes.byref(suma), ctypes.byref(sumb), ctypes.byref(sumc), 2);\n\n    res = numpy.zeros([len(a), len(a)])\n    indc = 0\n    for i in range(0, len(sumc)):\n        res[indc][i % len(a)] = sumc[i]\n        if i % len(a) == len(a) - 1:\n            indc = indc + 1\n\n    return res\n```\n\n\nI would have bet that the version using C would have been faster ... and I'd have lost ! Below is my benchmark which seems to show that I either did it incorrectly, or that ```\nnumpy```\n is stupidly fast:\n\n\n\nI'd like to understand why the ```\nnumpy```\n version is faster than the ```\nctypes```\n version, I'm not even talking about the pure Python implementation since it is kind of obvious.\n    ", "Answer": "\r\nNumPy uses a highly-optimized, carefully-tuned BLAS method for matrix multiplication (see also: ATLAS). The specific function in this case is GEMM (for generic matrix multiplication). You can look up the original by searching for ```\ndgemm.f```\n (it's in Netlib).\n\nThe optimization, by the way, goes beyond compiler optimizations. Above, Philip mentioned Coppersmith–Winograd. If I remember correctly, this is the algorithm which is used for most cases of matrix multiplication in ATLAS (though a commenter notes it could be Strassen's algorithm).\n\nIn other words, your ```\nmatmult```\n algorithm is the trivial implementation. There are faster ways to do the same thing.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Shared memory matrix multiplication kernel\r\n                \r\nI am attempting to implement a shared memory based matrix multiplication kernel as outlined in the CUDA C Programming Guide. The following is the kernel:\n```\n __global__ void matrixMultiplyShared(float * A, float * B, float * C,\n                     int ARows, int AColumns,\n                     int BRows, int BColumns,\n                     int CRows, int CColumns) {\n     float * CSub = &C[CColumns * 16 * blockIdx.y + 16 * blockIdx.x];\n     float CValue = 0;\n for (int k = 0; k < (AColumns / 16); ++k) {\n         float * ASub =  &A[AColumns * 16 * blockIdx.y + 16 * k];\n         float * BSub = &B[AColumns*16*k + 16*blockIdx.y];\n         __shared__ float As[16][16];\n         __shared__ float Bs[16][16];\n         As[threadIdx.y][threadIdx.x] = ASub[threadIdx.y*AColumns+threadIdx.x];\n         Bs[threadIdx.y][threadIdx.x] = BSub[threadIdx.y*AColumns+threadIdx.x];\n         __syncthreads();\n         for (int n = 0; n < 16; ++n)\n        CValue += As[threadIdx.y][n] * Bs[n][threadIdx.x];\n         __syncthreads();\n     }\n     CSub[threadIdx.x*CColumns+threadIdx.y]=CValue;\n }\n```\n\nWhile the following shows the kernel launch:\n```\n dim3 dimBlock(16, 16, 1);\n dim3 dimGrid;\n dimGrid.x = (CColumns + dimBlock.x - 1)/dimBlock.x;\n dimGrid.y = (CRows + dimBlock.y - 1)/dimBlock.y;\n matrixMultiplyShared<<<dimGrid , dimBlock>>>(deviceA , deviceB , deviceC , ARows , AColumns, BRows ,BColumns , CRows , CColumns);\n```\n\nUnfortunately this seems to produce incorrect results.\nAny assistance/explanations would be greatly appreciated.\n    ", "Answer": "\r\nThere are at least 2 basic errors in your kernel, both relatively trivial.  Where you have this:\n\n```\n     float * BSub = &B[AColumns*16*k + 16*blockIdx.y];\n```\n\n\nYou should use this:\n\n```\n     float * BSub = &B[AColumns*16*k + 16*blockIdx.x];\n```\n\n\nAnd where you have this:\n\n```\n CSub[threadIdx.x*CColumns+threadIdx.y]=CValue;\n```\n\n\nYou should use this:\n\n```\n CSub[threadIdx.y*CColumns+threadIdx.x]=CValue;\n```\n\n\nThis should allow you to get basic correctness under the following conditions:\n\n\nsquare matrices\nmatrix dimensions evenly divisible by tile dimension\n\n\nFixing the square matrix limitation is not difficult.  Fixing the dimension limitation on the tile dimension involves considerable changes to the kernel, in order to:\n\n\nnot process out-of-range elements\nproperly populate your shared memory area with values that are appropriate in the \"border\" regions\n\n\nSince your code doesn't comprehend any of this, I wasn't sure if you're asking about it and chose not to address those issues specifically.\n\nI was able to get the following adaptation of your code working as a basic example:\n(note that for the benefit of reduced code size to look at, I have dispensed with usual CUDA error checking.  Please don't use this as a representative example of good coding.  Do proper error checking.  The point of my answer is not to explain good CUDA error checking but to show an algorithmically correct example.)\n\n```\n#include <stdio.h>\n#include <math.h>\n#define TILE_DIM 16\n#define DIMX 256\n#define DIMY 256\n#define RES 0.1\n\n__global__ void matrixMultiplyShared(float * A, float * B, float * C,\n                     int ARows, int AColumns,\n                     int BRows, int BColumns,\n                     int CRows, int CColumns) {\n     float CValue = 0;\n     if (((blockIdx.y * blockDim.y + threadIdx.y)< CRows) && ((blockIdx.x * blockDim.x + threadIdx.x) < CColumns)) {\n       for (int k = 0; k < (AColumns / TILE_DIM); ++k) {\n         float * ASub =  &A[AColumns * TILE_DIM * blockIdx.y + TILE_DIM * k];\n         float * BSub = &B[AColumns*TILE_DIM*k + TILE_DIM*blockIdx.x];\n         __shared__ float As[TILE_DIM][TILE_DIM];\n         __shared__ float Bs[TILE_DIM][TILE_DIM];\n         As[threadIdx.y][threadIdx.x] = ASub[threadIdx.y*AColumns+threadIdx.x];\n         Bs[threadIdx.y][threadIdx.x] = BSub[threadIdx.y*AColumns+threadIdx.x];\n         __syncthreads();\n         for (int n = 0; n < TILE_DIM; ++n)\n         CValue += As[threadIdx.y][n] * Bs[n][threadIdx.x];\n         __syncthreads();\n       }\n       C[((blockIdx.y * blockDim.y + threadIdx.y)*CColumns)+(blockIdx.x*blockDim.x)+threadIdx.x]=CValue;\n     }\n }\n\n\nvoid matrixMultiplyCPU(float * A, float * B, float * C,\n                     int ARows, int AColumns,\n                     int BRows, int BColumns,\n                     int CRows, int CColumns) {\n  for (int i = 0; i<ARows; i++)\n    for (int j=0; j<BColumns; j++){\n      float Ctemp = 0.0;\n      for (int k=0; k<AColumns; k++)\n        Ctemp += A[i*AColumns + k] * B[k*BColumns+j];\n      C[i*CColumns+j] = Ctemp;\n      }\n\n}\nint main(){\n int CColumns = DIMY, CRows=DIMX, AColumns=DIMY, ARows=DIMX, BColumns=DIMY, BRows=DIMX;\n dim3 dimBlock(TILE_DIM, TILE_DIM, 1);\n dim3 dimGrid;\n dimGrid.x = (CColumns + dimBlock.x - 1)/dimBlock.x;\n dimGrid.y = (CRows + dimBlock.y - 1)/dimBlock.y;\n float *deviceA, *deviceB, *deviceC;\n float hostA[DIMY][DIMX];\n float hostB[DIMY][DIMX];\n float hostC[DIMY][DIMX];\n float hostCp[DIMY][DIMX];\n for (int x = 0; x<DIMX; x++)\n   for (int y = 0; y<DIMY; y++) {\n     hostA[y][x] = rand()/(float)RAND_MAX;\n     hostB[y][x] = rand()/(float)RAND_MAX;\n     }\n  cudaMalloc((void **)&deviceA, DIMX*DIMY*sizeof(float));\n  cudaMalloc((void **)&deviceB, DIMX*DIMY*sizeof(float));\n  cudaMalloc((void **)&deviceC, DIMX*DIMY*sizeof(float));\n  cudaMemcpy(deviceA, hostA, DIMX*DIMY*sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(deviceB, hostB, DIMX*DIMY*sizeof(float), cudaMemcpyHostToDevice);\n  matrixMultiplyShared<<<dimGrid , dimBlock>>>(deviceA , deviceB , deviceC , ARows , AColumns, BRows ,BColumns , CRows , CColumns);\n  cudaMemcpy(hostC, deviceC, DIMX*DIMY*sizeof(float), cudaMemcpyDeviceToHost);\n  matrixMultiplyCPU(&(hostA[0][0]) , &(hostB[0][0]) , &(hostCp[0][0]) , ARows , AColumns, BRows ,BColumns , CRows , CColumns);\n\n for (int y = 0; y<DIMY; y++)\n   for (int x = 0; x<DIMX; x++)\n     if (fabs(hostCp[y][x] - hostC[y][x]) > RES)\n       {\n       printf(\"Error at offset y=%d,x=%d, CPU = %f, GPU = %f\\n\", y, x, hostCp[y][x], hostC[y][x]);\n       return 1;\n       }\n printf(\"Finished!\\n\");\n return 0;\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Geometric Matrix Multiplication\r\n                \r\nI'm working on a project building a geometric (as opposed to arithmetic) neural net. To construct the transfer function, I would like to use geometric summation instead of arithmetic summation.\n\nTo make things clearer, I'm just going to describe in code:\n\n```\ndef arithmetic_matrix_multiplication(matrix1, matrix2):\n    new_matrix = np.zeros(len(matrix1),len(matrix2[0]))\n    for i in range(len(matrix1)):\n        for j in range(len(matrix2[0])):\n            for k in range(len(matrix2)):\n                new_matrix[i][j] += matrix1[i][k]*matrix2[k][j]\n    return new_matrix\n\ndef geometric_matrix_multiplication(matrix1, matrix2):\n    new_matrix = np.ones(len(matrix1),len(matrix2[0]))\n    for i in range(len(matrix1)):\n        for j in range(len(matrix2[0])):\n            for k in range(len(matrix2)):\n                new_matrix[i][j] *= matrix1[i][k]*matrix2[k][j]\n    return new_matrix\n```\n\n\nAs you can see, it's a pretty minimal change. The only problem is that, in the same way I would never actually write and use the above arithmetic code (I would use ```\nnumpy.dot```\n), I would really not like to actually use the geometric code above. Is there any way to leverage numpy's matrix multiplication to achieve the geometric result? I haven't been able to think of one, and I haven't found anything obvious past the solution above, which is far from optimal.\n    ", "Answer": "\r\nYou are all complicating things unnecessarily... Since you have a single operation, multiplication, which is commutative, you can swap the order in which you perform them at will, i.e. you don't need to multiply items of ```\nmatrix1```\n with items of ```\nmatrix2```\n, and once you have computed all of them, multiply them together. Instead, you can first multiply all the relevant items of ```\nmatrix1```\n together, then all the relevant items of ```\nmatrix2```\n together, and then multiply the two resulting values. So you can write your function as the very simple:\n\n```\ndef fast_geometric_matrix_multiplication(matrix1, matrix2):\n    return np.prod(matrix1, axis=1)[:, None] * np.prod(matrix2, axis=0)\n```\n\n\nIt has the additional advantage that, if you are multiplying matrices of shapes ```\n(m, k)```\n and ```\n(k, n)```\n, you would expect to be having to do ```\nm*n*2*k```\n multiplications, while this method only requires ```\nm*k + n*k + m*n```\n, which is bound to be much smaller than what you presently are doing for almost any array shapes.\n\nAnd of course:\n\n```\nIn [24]: a = np.random.rand(100, 200)\n    ...: b = np.random.rand(200, 50)\n    ...: \n\nIn [25]: np.allclose(geometric_matrix_multiplication(a, b),\n    ...:             fast_geometric_matrix_multiplication(a, b))\nOut[25]: True\n\nIn [26]: %timeit geometric_matrix_multiplication(a, b)\n1 loops, best of 3: 1.39 s per loop\n\nIn [27]: %timeit fast_geometric_matrix_multiplication(a, b)\n10000 loops, best of 3: 74.2 us per loop\n\nIn [28]: %timeit np.prod(a[:, None, :]*b[..., None].T, axis=2)\n100 loops, best of 3: 5.97 ms per loop\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "3d matrix multiplication into multiple 2d matrix multiplications\r\n                \r\nI have two 3d matrices ```\nX```\n and ```\nY```\n both of which have the shape ```\n(5, 1825, 77)```\n. I'd like to do five 2d matrix multiplications, i.e., ```\nX[i, :, :]@Y[i, :, :].T```\n without using a for loop. Is there a way to do this in numpy?\n    ", "Answer": "\r\nThis is interesting for those (like me) who try to avoid for loops at any cost:\n```\nshape = 5, 1825, 77\nX = np.random.random(shape)\nY = np.random.random(shape)\n\np_for = np.empty((shape[0], shape[1], shape[1]))\nfor i in range(shape[0]):\n    p_for[i] = X[i] @ Y[i].T\n\np_matmul = X @ np.moveaxis(Y, -1, 1)\nassert np.allclose(p_for, p_matmul)\n\np_einsum = np.einsum(\"ijk,ilk->ijl\", X, Y)\nassert np.allclose(p_for, p_einsum)\n```\n\nThe tree methods produce the same result, but, as @JérômeRichard points out:\n```\n%%timeit\nprod = np.empty((shape[0], shape[1], shape[1]))\nfor i in range(5):\n    prod[i] = X[i, :, :] @ Y[i, :, :].T\n50.4 ms ± 7.18 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n%timeit X @ np.moveaxis(Y, -1, 1)\n115 ms ± 1.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n%timeit np.einsum(\"ijk,ilk->ijl\", X, Y)\n544 ms ± 3.22 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "The faster way to do matrix multiplication between a matrix and a diagonal matrix?\r\n                \r\nI am coding a computational package in python using numpy, in the package, I would do the matrix multiplication between an arbitrary large square matrix (e.g of size 100*100) and a diagonal matrix of same size frequently. \n\nI have an O(n^2) method, but I think that further improvement could be made.\n\n```\n\"\"\"\nA is of size 100*100\nB is a diagonal matrix \nwant to do np.dot(A,B) quickly\n\"\"\"\nA=np.random.rand(100,100)\ndiag_elements=np.random.rand(100)\nB=np.diag(diag_elements)\n\nanswer1= np.dot(A,B) ###O(n^3) method, quite slow\n\nC=np.zeros((100,100)) \nC=C+diag_elements\nanswer2=np.multiply(A,C) ##O(n^2) method, 3times faster for n=100\n\n```\n\n\nThe anwer2 is O(n^2) but I think it's not good enough, because the operation C+=diag_elements are wasting 1/3 time and could be avoided possibly. \n\nI expect that some numpy function could do the matrix multiplication more elegently and faster. Could someone help me out?\n    ", "Answer": "\r\nWhy don't you simply multiply A by the diagonal?\n\n```\nanswer3 = np.multiply(A,diag_elements)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Google Cloud: matrix multiplication with Bigquery or some other service?\r\n                \r\nI am using Google Analytics and processing the data with Bigquery, I need to do a matrix multiplication. \n\nWhat is the most feasible way of implementing matrix multiplication in Google Cloud? Can it be done directly in Bigquery?\n\n\n    ", "Answer": "\r\nAssuming MatrixA is a table with below columns:    \n\n```\ni, k, value   \n```\n\n\nand MatrixB - has schema as    \n\n```\nk, j, value    \n```\n\n\nand also assuming that range of k-values is the same in both tables:   \n\nThis would mimic below matrices :    \n\n```\nMatrix A\n 2 -3  4\n-1  0  2\n\nMatrix B\n-1  2  3\n 0  1  7\n 1  1 -2\n```\n\n\nBelow code for multiplication is for BigQuery Standard SQL   \n\n```\n#standardSQL\nWITH MatrixA AS (\n  SELECT 1 AS i, 1 AS k, 2 AS val UNION ALL\n  SELECT 1, 2, -3 UNION ALL\n  SELECT 1, 3, 4 UNION ALL\n  SELECT 2, 1, -1 UNION ALL\n  SELECT 2, 2, 0 UNION ALL\n  SELECT 2, 3, 2 \n), MatrixB AS (\n  SELECT 1 AS k, 1 AS j, -1 AS val UNION ALL\n  SELECT 1, 2, 2 UNION ALL\n  SELECT 1, 3, 3 UNION ALL\n  SELECT 2, 1, 0 UNION ALL\n  SELECT 2, 2, 1 UNION ALL\n  SELECT 2, 3, 7 UNION ALL\n  SELECT 3, 1, 1 UNION ALL\n  SELECT 3, 2, 1 UNION ALL\n  SELECT 3, 3, -2 \n)\nSELECT i, j, SUM(a.val * b.val) val\nFROM MatrixA AS a\nCROSS JOIN MatrixB AS b\nWHERE a.k = b.k\nGROUP BY i, j\nORDER BY i, j   \n```\n\n\nresult will be as below   \n\n```\nRow i   j   val  \n1   1   1   2    \n2   1   2   5    \n3   1   3   -23  \n4   2   1   3    \n5   2   2   0    \n6   2   3   -7     \n```\n\n\nwhich represents MatrixA * MatrixB    \n\n```\n2   5  -23\n3   0   -7\n```\n\n\nas a note:  you can use    \n\n```\nFROM MatrixA AS a\nJOIN MatrixB AS b\nON a.k = b.k  \n```\n\n\ninstead of   \n\n```\nFROM MatrixA AS a\nCROSS JOIN MatrixB AS b\nWHERE a.k = b.k   \n```\n\n\njust matter of your preferences   \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Is there is a gradient descent implementation that uses matrix matrix multiplication?\r\n                \r\nI'm using the below gradient descent implementation in Octave for ML.\n\nI tried first to increase number of CPU cores and run Octave multithreaded using OpenBlas but still I didn't get the results I'm looking for, so I tried using Nvidia's toolkit and their Tesla K80 GPU\n\nI'm loading Octave using the drop in nvblas following instructions in this article:\n\nDrop-in Acceleration of GNU Octave\n\nWhen I checked nvidia-smi I found the GPU to be idle although my testing using a matrix matrix multiplication is yielding ~9 teraflops\n\nLater I came to understand that the matrix vector multiplication used for the above mentioned implementation is not supported as per the nvblas documentation\n\nSo my question is there is a gradient descent implementation that uses matrix matrix multiplication or something equivalent that can replace the gradient descent implementation I have?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matlab/octave - Generalized matrix multiplication\r\n                \r\nI would like to do a function to generalize matrix multiplication. Basically, it should be able to do the standard matrix multiplication, but it should allow to change the two binary operators product/sum by any other function.\n\nThe goal is to be as efficient as possible, both in terms of CPU and memory. Of course, it will always be less efficient than A*B, but the operators flexibility is the point here.\n\nHere are a few commands I could come up after reading various interesting threads:\n\n```\nA = randi(10, 2, 3);\nB = randi(10, 3, 4);\n\n% 1st method\nC = sum(bsxfun(@mtimes, permute(A,[1 3 2]),permute(B,[3 2 1])), 3)\n% Alternative: C = bsxfun(@(a,b) mtimes(a',b), A', permute(B, [1 3 2]))\n\n% 2nd method\nC = sum(bsxfun(@(a,b) a*b, permute(A,[1 3 2]),permute(B,[3 2 1])), 3)\n\n% 3rd method (Octave-only)\nC = sum(permute(A, [1 3 2]) .* permute(B, [3 2 1]), 3)\n\n% 4th method (Octave-only): multiply nxm A with nx1xd B to create a nxmxd array\nC = bsxfun(@(a, b) sum(times(a,b)), A', permute(B, [1 3 2]));\nC = C2 = squeeze(C(1,:,:)); % sum and turn into mxd\n```\n\n\nThe problem with methods 1-3 are that they will generate n matrices before collapsing them using sum(). 4 is better because it does the sum() inside the bsxfun, but bsxfun still generates n matrices (except that they are mostly empty, containing only a vector of non-zeros values being the sums, the rest is filled with 0 to match the dimensions requirement).\n\nWhat I would like is something like the 4th method but without the useless 0 to spare memory.\n\nAny idea?\n    ", "Answer": "\r\nHere is a slightly more polished version of the solution you posted, with some small improvements.\n\nWe check if we have more rows than columns or the other way around, and then do the multiplication accordingly by choosing either to multiply rows with matrices or matrices with columns (thus doing the least amount of loop iterations).\n\n\n\nNote: This may not always be the best strategy (going by rows instead of by columns) even if there are less rows than columns; the fact that MATLAB arrays are stored in a column-major order in memory makes it more efficient to slice by columns, as the elements are stored consecutively. Whereas accessing rows involves traversing elements by strides (which is not cache-friendly -- think spatial locality).\n\nOther than that, the code should handle double/single, real/complex, full/sparse (and errors where it is not a possible combination). It also respects empty matrices and zero-dimensions.\n\n```\nfunction C = my_mtimes(A, B, outFcn, inFcn)\n    % default arguments\n    if nargin < 4, inFcn = @times; end\n    if nargin < 3, outFcn = @sum; end\n\n    % check valid input\n    assert(ismatrix(A) && ismatrix(B), 'Inputs must be 2D matrices.');\n    assert(isequal(size(A,2),size(B,1)),'Inner matrix dimensions must agree.');\n    assert(isa(inFcn,'function_handle') && isa(outFcn,'function_handle'), ...\n        'Expecting function handles.')\n\n    % preallocate output matrix\n    M = size(A,1);\n    N = size(B,2);\n    if issparse(A)\n        args = {'like',A};\n    elseif issparse(B)\n        args = {'like',B};\n    else\n        args = {superiorfloat(A,B)};\n    end\n    C = zeros(M,N, args{:});\n\n    % compute matrix multiplication\n    % http://en.wikipedia.org/wiki/Matrix_multiplication#Inner_product\n    if M < N\n        % concatenation of products of row vectors with matrices\n        % A*B = [a_1*B ; a_2*B ; ... ; a_m*B]\n        for m=1:M\n            %C(m,:) = A(m,:) * B;\n            %C(m,:) = sum(bsxfun(@times, A(m,:)', B), 1);\n            C(m,:) = outFcn(bsxfun(inFcn, A(m,:)', B), 1);\n        end\n    else\n        % concatenation of products of matrices with column vectors\n        % A*B = [A*b_1 , A*b_2 , ... , A*b_n]\n        for n=1:N\n            %C(:,n) = A * B(:,n);\n            %C(:,n) = sum(bsxfun(@times, A, B(:,n)'), 2);\n            C(:,n) = outFcn(bsxfun(inFcn, A, B(:,n)'), 2);\n        end\n    end\nend\n```\n\n\nComparison\n\nThe function is no doubt slower throughout, but for larger sizes it is orders of magnitude worse than the built-in matrix-multiplication:\n\n```\n        (tic/toc times in seconds)\n      (tested in R2014a on Windows 8)\n\n    size      mtimes       my_mtimes \n    ____    __________     _________\n     400     0.0026398       0.20282\n     600      0.012039       0.68471\n     800      0.014571        1.6922\n    1000      0.026645        3.5107\n    2000       0.20204         28.76\n    4000        1.5578        221.51\n```\n\n\n\n\nHere is the test code:\n\n```\nsz = [10:10:100 200:200:1000 2000 4000];\nt = zeros(numel(sz),2);\nfor i=1:numel(sz)\n    n = sz(i); disp(n)\n    A = rand(n,n);\n    B = rand(n,n);\n\n    tic\n    C = A*B;\n    t(i,1) = toc;\n    tic\n    D = my_mtimes(A,B);\n    t(i,2) = toc;\n\n    assert(norm(C-D) < 1e-6)\n    clear A B C D\nend\n\nsemilogy(sz, t*1000, '.-')\nlegend({'mtimes','my_mtimes'}, 'Interpreter','none', 'Location','NorthWest')\nxlabel('Size N'), ylabel('Time [msec]'), title('Matrix Multiplication')\naxis tight\n```\n\n\n\n\nExtra\n\nFor completeness, below are two more naive ways to implement the generalized matrix multiplication (if you want to compare the performance, replace the last part of the ```\nmy_mtimes```\n function with either of these). I'm not even gonna bother posting their elapsed times :)\n\n```\nC = zeros(M,N, args{:});\nfor m=1:M\n    for n=1:N\n        %C(m,n) = A(m,:) * B(:,n);\n        %C(m,n) = sum(bsxfun(@times, A(m,:)', B(:,n)));\n        C(m,n) = outFcn(bsxfun(inFcn, A(m,:)', B(:,n)));\n    end\nend\n```\n\n\nAnd another way (with a triple-loop):\n\n```\nC = zeros(M,N, args{:});\nP = size(A,2); % = size(B,1);\nfor m=1:M\n    for n=1:N\n        for p=1:P\n            %C(m,n) = C(m,n) + A(m,p)*B(p,n);\n            %C(m,n) = plus(C(m,n), times(A(m,p),B(p,n)));\n            C(m,n) = outFcn([C(m,n) inFcn(A(m,p),B(p,n))]);\n        end\n    end\nend\n```\n\n\n\n\nWhat to try next?\n\nIf you want to squeeze out more performance, you're gonna have to move to a C/C++ MEX-file to cut down on the overhead of interpreted MATLAB code. You can still take advantage of optimized BLAS/LAPACK routines by calling them from MEX-files (see the second part of this post for an example). MATLAB ships with Intel MKL library which frankly you cannot beat when it comes to linear algebra computations on Intel processors.\n\nOthers have already mentioned a couple of submissions on the File Exchange that implement general-purpose matrix routines as MEX-files (see @natan's answer). Those are especially effective if you link them against an optimized BLAS library.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "3D Elementwise Matrix Multiplication in CUDA?\r\n                \r\nI have a 2D Matrix Multiplication program using the following kernel:\n\n```\n__global__ void multKernel(int *a, int *b, int *c, int N)\n{\n    int column  = threadIdx.x + blockDim.x * blockIdx.x;\n    int row     = threadIdx.y + blockDim.y * blockIdx.y;\n\n    int index = row * N + column;\n\n    if(column < N && row < N)\n    {\n        c[index] = a[index] * b[index];\n    }\n}\n```\n\n\nNow, I'd like to create a 3D matrix multiplication kernel, but I'm having trouble finding examples of how do create one (also, I'm terrible at reading mathematical formulae, it's something I need to improve on).\n\nI know the GPU example will involve using\n\n```\nthreadIdx.z\n```\n\n\nand so on, but I'm a bit lost with how to do it.\n\nCould anyone point me in the right direction to either some formulae or sample code? Or even provide a basic example? I have a CPU example which should work, I think.\n\n```\nvoid matrixMult3D(int *a, int *b, int *c, int *z, int N)\n{\n    int index;\n\n    for(int column = 0; column < N; column++)\n    {\n        for(int row = 0; row < N; row++)\n        {\n            for (int z = 0; z < N; z++)\n            {\n                index = row * N + column + z;\n                c[index] = a[index] * b[index] * z[index];\n            }\n        }\n    }\n}\n```\n\n\nAm I at least on the right track?\n    ", "Answer": "\r\nBecause what you are actually doing is just an element-wise product (I hesitate to call it a Hadamard Product because that isn't defined for hyper matrices AFAIK), you don't need to do anything differently from the simplest 1D version of your kernel code. Something like this:\n\n```\ntemplate<int ndim>\n__global__ void multKernel(int *a, int *b, int *c, int *z, int N)\n{\n    int idx  = threadIdx.x + blockDim.x * blockIdx.x;\n    int stride = blockDim.x * gridDim.x;\n\n    int idxmax = 1;\n    #pragma unroll\n    for(int i=0; i < ndim; i++) {\n        idxmax *= N;\n    }\n    for(; idx < idxmax; idx+=stride) {\n       c[index] = a[index] * b[index] * z[index];\n    }\n}\n```\n\n\n[disclaimer: code written in browser, never compiled or run. use at own risk]\n\nwould work for any dimension of array with dimensions N (ndim=1), N*N (ndim=2), N*N*N (ndim=3), etc.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication: Small difference in matrix size, large difference in timings\r\n                \r\nI have a matrix multiply code that looks like this:\n\n```\nfor(i = 0; i < dimension; i++)\n    for(j = 0; j < dimension; j++)\n        for(k = 0; k < dimension; k++)\n            C[dimension*i+j] += A[dimension*i+k] * B[dimension*k+j];\n```\n\n\nHere, the size of the  matrix is represented by ```\ndimension```\n.\nNow, if the size of the matrices is 2000, it takes 147 seconds to run this piece of code, whereas if the size of the matrices is 2048, it takes 447 seconds. So while the difference in no. of multiplications is (2048*2048*2048)/(2000*2000*2000) = 1.073, the difference in the timings is 447/147 = 3. Can someone explain why this happens? I expected it to scale linearly, which does not happen. I am not trying to make the fastest matrix multiply code, simply trying to understand why it happens. \n\nSpecs: AMD Opteron dual core node (2.2GHz), 2G RAM, gcc v 4.5.0\n\nProgram compiled as ```\ngcc -O3 simple.c```\n\n\nI have run this on Intel's icc compiler as well, and seen similar results.\n\nEDIT:\n\nAs suggested in the comments/answers, I ran the code with dimension=2060 and it takes 145 seconds.\n\nHeres the complete program:\n\n```\n#include <stdlib.h>\n#include <stdio.h>\n#include <sys/time.h>\n\n/* change dimension size as needed */\nconst int dimension = 2048;\nstruct timeval tv; \n\ndouble timestamp()\n{\n        double t;\n        gettimeofday(&tv, NULL);\n        t = tv.tv_sec + (tv.tv_usec/1000000.0);\n        return t;\n}\n\nint main(int argc, char *argv[])\n{\n        int i, j, k;\n        double *A, *B, *C, start, end;\n\n        A = (double*)malloc(dimension*dimension*sizeof(double));\n        B = (double*)malloc(dimension*dimension*sizeof(double));\n        C = (double*)malloc(dimension*dimension*sizeof(double));\n\n        srand(292);\n\n        for(i = 0; i < dimension; i++)\n                for(j = 0; j < dimension; j++)\n                {   \n                        A[dimension*i+j] = (rand()/(RAND_MAX + 1.0));\n                        B[dimension*i+j] = (rand()/(RAND_MAX + 1.0));\n                        C[dimension*i+j] = 0.0;\n                }   \n\n        start = timestamp();\n        for(i = 0; i < dimension; i++)\n                for(j = 0; j < dimension; j++)\n                        for(k = 0; k < dimension; k++)\n                                C[dimension*i+j] += A[dimension*i+k] *\n                                        B[dimension*k+j];\n\n        end = timestamp();\n        printf(\"\\nsecs:%f\\n\", end-start);\n\n        free(A);\n        free(B);\n        free(C);\n\n        return 0;\n}\n```\n\n    ", "Answer": "\r\nHere's my wild guess: cache\n\nIt could be that you can fit 2 rows of 2000 ```\ndouble```\ns into the cache. Which is slighly less than the 32kb L1 cache. (while leaving room other necessary things)\n\nBut when you bump it up to 2048, it uses the entire cache (and you spill some because you need room for other things)\n\nAssuming the cache policy is LRU, spilling the cache just a tiny bit will cause the entire row to be repeatedly flushed and reloaded into the L1 cache.\n\nThe other possibility is cache associativity due to the power-of-two. Though I think that processor is 2-way L1 associative so I don't think it matters in this case. (but I'll throw the idea out there anyway)\n\nPossible Explanation 2: Conflict cache misses due to super-alignment on the L2 cache.\n\nYour ```\nB```\n array is being iterated on the column. So the access is strided. Your total data size is ```\n2k x 2k```\n which is about 32 MB per matrix. That's much larger than your L2 cache.\n\nWhen the data is not aligned perfectly, you will have decent spatial locality on B. Although you are hopping rows and only using one element per cacheline, the cacheline stays in the L2 cache to be reused by the next iteration of the middle loop.\n\nHowever, when the data is aligned perfectly (2048), these hops will all land on the same \"cache way\" and will far exceed your L2 cache associativity. Therefore, the accessed cache lines of ```\nB```\n will not stay in cache for the next iteration. Instead, they will need to be pulled in all the way from ram.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "N×M matrix multiplication for python\r\n                \r\ni am actually writing a code to actually perform matrix multiplication on a n×m matrix\nthe closest that i got is the following \n\n```\nX = [[15,2,9],\n    [1 ,3,4],\n    [7 ,2,9]]\n\nY = [[5,8,1,2],\n    [6,7,3,0],\n    [4,5,9,1]]\n\nresult = [[0,0,0,0],\n         [0,0,0,0],\n         [0,0,0,0]]\n\nfor i in range(len(X)):\n   for j in range(len(Y[0])):\n       for k in range(len(Y)):\n           result[i][j] += X[i][k] * Y[k][j]\n\nfor numbs in result:\n   print(numbs)\n```\n\n\nHowever i cannot seem to find a way to actually perform a n×m multiplication\nand its limited to the size of my lists, \n\nhow can i allow the user to decide what is the dimension and allow him to input the matrix that is as big as he wants with one condition that the two matrices are n×m m×n \n    ", "Answer": "\r\nYour question seems to be unclear, although I'm pretty sure there are duplicates.\n\nIf your question was to perform multiplication of two dimensional array, here is how to create n x m or m x n matrix:\n\n```\nn = int(input())\nm = int(input())\n\nmatrix = [[0 for i in range(m) for j in range(n)]\n```\n\n\nFor entering the values,\n\n```\nfor i in range(n):\n    for j in range(m):\n        l[i][j] = input()\n```\n\n\nThen, you may use the rest of your code to calculate the resulting array.\n\nAnd for displaying the elements of the resulting matrix,\n\n```\nfor i in range(n):\n    for j in range(m):\n        print l[i][j],\n    print\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "OpenCV Assertion failed on Matrix multiplication\r\n                \r\nI'm multiplying two matrices with OpenCV, A in NxM and B is MxP.\n\nAccording to the documentation:\n\n\n  All the arrays must have the same type and the same size (or ROI\n  size).  For types that have limited range this operation is saturating.\n\n\nHowever, by the theory of matrix multiplication:\n\n\n  Assume two matrices are to be multiplied (the generalization to any\n  number is discussed below). If A is an n×m matrix and B is an m×p\n  matrix, the result would be AB of their multiplication is an n×p matrix defined\n  only if the number of columns m in A is equal to the number of rows m\n  in B.\n\n\nshouldn't this code be working?\n\n```\n- (CvMat *) multMatrix:(CvMat *)AMatrix BMatrix:(CvMat *)BMatrix \n{\n  CvMat *result = cvCreateMat(AMatrix->rows, BMatrix->cols, kMatrixType);\n  cvMul(AMatrix, BMatrix, result, 1.0);\n  return result;\n}\n```\n\n\nI get the following exception:\n\n\n  OpenCV Error: Assertion failed (src1.size == dst.size &&\n  src1.channels() == dst.channels()) in cvMul, file\n  /Users/Aziz/Documents/Projects/opencv_sources/trunk/modules/core/src/arithm.cpp,\n  line 2728\n\n\nkMatrixType is CV_32F, A is 6x234, B is 234x5 and result is 6x5...\n\nAm I doing something wrong? Or is this an OpenCV restriction to matrix multiplication ?\n    ", "Answer": "\r\nYou are doing element-wise multiplication with ```\ncvMul```\n. \n\nYou should look at ```\ncvMatMul```\n for doing proper matrix multiplication.\n\nhttp://opencv.willowgarage.com/wiki/Matrix_operations\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Why is matrix multiplication in .NET so slow?\r\n                \r\nI don't quite understand what makes matrix multiplication in C#/.NET (and even Java) so slow.\n\nTake a look at this benchmark (source): Trying to find an updated benchmark.\n\n\n\nC#'s integer and double performance is damn close to C++ compiled with MSVC++. 87% as fast for double and 99% as fast for 32-bit integer. Pretty damn good, I'd say. But then look at matrix multiplication. The gap widens to C# being about 19% as fast. This is a pretty huge discrepancy that I don't understand. Matrix multiplication is just a bunch of simple math. How is it getting so slow? Shouldn't it be roughly as fast as an equivalent number of simple floating point or integer operations?\n\nThis is especially of a concern with games and with XNA, where matrix and vector performance are critical for things like physics engines. Some time ago, Mono added support for SIMD instructions through some nifty vector and matrix classes. It closes the gap and makes Mono faster than hand-written C++, although not as fast as C++ with SIMD. (source)\n\n\n\n\nWhat's going on here?\n\nEdit: Looking closer, I misread the second graph. C# appears pretty close. Is the first benchmark just doing something horribly wrong? Sorry, I missed the version number on the first benchmark. I grabbed it as a handy reference for the \"C# linear algebra is slow\" that I've always heard. I'll try to find another.\n    ", "Answer": "\r\nWith large matrices like this, the CPU cache becomes the limiting factor.  What's hyper-important is how the matrix is stored.  And the benchmark code is comparing apples and oranges.  The C++ code used jagged arrays, the C# code uses two-dimensional arrays.\n\nRewriting the C# code to use jagged arrays as well doubled its speed.  Rewriting the matrix multiply code to avoid the array index boundary check seemed pointless, nobody would use code like this for real problems.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Running time for matrix multiplication in R (operator %*%)\r\n                \r\nIs there any way to estimate how long (roughly) take a matrix multiplication in R according the dimension of the matrices?\nI have a  multiplication of a matrix of dimensions 14500 rows by 130000 columns for its transpose (130000 x 14500).\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Tiling in Matrix multiplication with OpenMP task\r\n                \r\nI have following working code for matrix multiplication (with tiling) which is producing results correctly:\n\n```\nvoid ProcessTile(int d1stride, int d2stride, int d3stride) {\n\n        for (int i=d1stride ; i<(d1stride+BLOCKSIZE) ; i++) //covering rows of tile\n        {\n            for (int j=d2stride ; j<(d2stride+BLOCKSIZE) ; j++) //covering columns of tile (or rows if transpose)\n            {\n                __m128 vsum = _mm_set1_ps(0.0f);\n                for (int k=d3stride ; k<(d3stride+BLOCKSIZE); k+=4) //covering convolution of vectors in a tile\n                {\n                    __m128 vx = _mm_load_ps(&x2[i][k]);  //loads up 4 floats into a __m128\n                    __m128 vy = _mm_load_ps(&y2[j][k]);  //loads up 4 floats into a __m128\n                    vsum = _mm_add_ps(vsum, _mm_mul_ps(vx, vy));\n                }\n                vsum = _mm_hadd_ps(vsum, vsum);\n                vsum = _mm_hadd_ps(vsum, vsum);\n                vsum = _mm_add_ps(vsum, _mm_load_ss (&r2[i][j]));\n                _mm_store_ss(&r2[i][j], vsum);\n            }\n        }\n}\n\nMatrixMultiply()\n{    \n#pragma omp parallel\n    {\n        #pragma omp single\n        {\n            for(i=0 ; i<N ; i+=BLOCKSIZE) //covering tiled-rows of entire matrix\n            {\n                for(j=0 ; j<N ; j+=BLOCKSIZE) // covering tiled-columns of entire matrix\n                {\n                    #pragma omp task firstprivate(i,j,k)\n                    for(k=0 ; k<N ; k+=BLOCKSIZE) //covering tiled-multiplication of two matrix-vectors\n                    {\n                        ProcessTile(i,j,k);\n                    }\n                }\n            }\n        }\n    }\n\n}\n```\n\n\nHowever I am looking to do tiling on fine granularity level which is not working at the moment. I'll explain the working/approach with a snapshot attached\nmatrix multiplication with tiling diagram  \n\nThe purpose of the above code is to generate OpenMP tasks and actual work is happening in ProcessTile(...). Snapshot has 8x8 matrix with BLOCKSIZE of 4 (i.e. 4 tiles in all matrices and each tile is 2x2 size).\n\nThe working scenario which is producing expected correct results and performance \n\n```\nC[0][0] = (A[0][0]xB[0][0]) + (A[0][1]xB[1][0]) //This is tiled multiplication i.e. A[0][0] is 2x2 matrix etc.\n```\n\n\nThe scenario which is not working and I am looking to make work is to change innermost task generating loop from  \n\n```\n#pragma omp task firstprivate(i,j,k)\nfor(k=0 ; k<N ; k+=BLOCKSIZE) //covering tiled-multiplication of two matrix-vectors\n{\n    ProcessTile(i,j,k);\n}\n```\n\n\nto\n\n```\nfor(k=0 ; k<N ; k+=BLOCKSIZE) //covering tiled-convolution of two matrix-vectors\n{\n   #pragma omp task firstprivate(i,j,k)\n   ProcessTile(i,j,k);\n} \n```\n\n\nAbove change results in the following generation of tasks and tilled multiplication\n\n```\nC[0][0] += (A[0][0]xB[0][0]) //tiled multiplication done by 'task X'\n\nC[0][0] += (A[0][1]xB[1][0]) //tiled multiplication done by 'task Y'\n```\n\n\nMy answers go wrong when I made the above change. The reason I am looking to do this way to have independent memory regions for each task/thread inside each matrix.\n\nBoth tasks are doing accumulative operation so not sure why getting wrong answers. What I might be missing? Is there any way I can communicate info to the task generation code which goes along the lines of 'task Y' starts after when 'task X' finishes? I am not sure if such dependency is required for such an accumulative operation or a good way to solve the problem. Maybe there is another way.  \n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Numpy matrix multiplication with custom dot product\r\n                \r\nThe default matrix multiplication is computed as\n\n```\nc[i,j] = sum(a[i,k] * b[k,j])\n```\n\n\nI am trying to use a custom formula instead of the dot product to get\n\n```\nc[i,j] = sum(a[i,k] == b[k,j])\n```\n\n\nIs there an efficient way to do this in numpy?\n    ", "Answer": "\r\nYou could use broadcasting:\n\n```\nc = sum(a[...,np.newaxis]*b[np.newaxis,...],axis=1)  # == np.dot(a,b)\n\nc = sum(a[...,np.newaxis]==b[np.newaxis,...],axis=1)\n```\n\n\nI included the ```\nnewaxis```\n in ```\nb```\n just make it clear how that array is expanded.  There are other ways of adding dimensions to arrays (reshape, repeat, etc), but the effect is the same.  Expand ```\na```\n and ```\nb```\n to the same shape to do element by element multiplying (or ==), and then sum on the correct axis. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Avoid propagation of NA in matrix multiplication\r\n                \r\nI have some difficulties with propagation of missing values in the context of matrix multiplication. \nMy first matrix ```\nX```\n is the gas flow measurements each hour for 5 flowmeters:\n\n```\nX=structure(c(16, 19, 28, 32, 30, 22, 16, 13, 8, 6, 5, 3, 5, 5, 6, 13, 7, 10, 4, 2, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 7, 7, 6, 6, 5, 5, 4, 4, 4, -16, -17, -20, -31, -25, -25, -16, -12, -13, -15, -9, -7), .Dim = c(12L, 5L), .Dimnames = list(NULL, c(\"meter1\", \"meter2\", \"meter3\", \"meter4\", \"meter5\")))\n####      meter1 meter2 meter3 meter4 meter5\n#### [1,]     16      5      0      7    -16\n#### [2,]     19      5      0      8    -17\n#### ...\n```\n\n\nMy second matrix ```\nZ```\n says how these gas flows are distributed to feed 4 cities: for instance (first column of ```\nZ```\n), for city1 the total net flow is defined as the sum of ```\n(1)*Meter1 + (-1)*Meter2 + (1)*Meter5```\n. \n\n```\nZ=structure(c(1, -1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0), .Dim = c(5L, 4L), .Dimnames = list(NULL, c(\"city1\", \"city2\", \"city3\", \"city4\")))\n####      city1 city2 city3 city4\n#### [1,]     1     0     0     0\n#### [2,]    -1     1     0     0\n#### [3,]     0     1     0     0\n#### [4,]     0     0     1     0\n#### [5,]     1     0     0     0\n```\n\n\nSo to calculate the net flow per city I just have to do a matrix multiplication:\n\n```\nX %*% Z\n####      city1 city2 city3 city4\n#### [1,]    -5     5     7     0\n#### [2,]    -3     5     8     0\n#### ...\n```\n\n\nMy problem is that there are lots of missing values in my ```\nX```\n matrix (here 9 ```\nNA```\n):\n\n```\nset.seed(3); for (i in 1:10) X[sample.int(nrow(X), 1), sample.int(ncol(X), 1)] <- NA\n```\n\n\nWhen I do the matrix multiplication the ```\nNA```\n propagates to the whole row even if it is located on a zero value column (which does'nt impacts the sum). So I get 24 ```\nNA```\n after the multiplication. However, if I do the calculation city by city only with the meters that are non-null, i only get 11 ```\nNA```\n:\n\n```\nsum(is.na(cbind(X[, 1] - X[, 2] + X[, 5], X[, 2] + X[, 3], X[, 4], 0)))\n#### [1] 11\n```\n\n\nI would like to know if there is a way to do this calculation of the flows for each city that does'n propagate my ```\nNA```\n so much. In the reality my matrices are much bigger but a city is never alimented by more than 4 meters (it is quite sparse). i'd like to avoid coding each column by hand (because if there is any change in the network the script won't work anymore).\nThanks,\n    ", "Answer": "\r\nYes, I am sure this is what you need:\n\n```\nlibrary(Matrix)\nZZ <- Matrix(Z, sparse = TRUE)\nX %*% ZZ\n\n#12 x 4 Matrix of class \"dgeMatrix\"\n#      city1 city2 city3 city4\n# [1,]    -5     5     7     0\n# [2,]    NA    NA    NA     0\n# [3,]    NA     6     8     0\n# [4,]   -12    13     7     0\n# [5,]    NA    NA     7     0\n# [6,]   -13    10     6     0\n# [7,]    -4    NA    NA     0\n# [8,]    -1     2    NA     0\n# [9,]    -6     1     5     0\n#[10,]   -11     2     4     0\n#[11,]    NA    NA     4     0\n#[12,]    -5     1     4     0\n```\n\n\nAs you expected, there are only 11 ```\nNA```\n.\n\n\n\nFollow-up\n\n\n  It throws an error when I try to convert the result to a data frame: ```\ndata.frame(X %*% ZZ)```\n. How can I do it?\n\n\nUse ```\ndata.frame(as.matrix(X %*% ZZ))```\n.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication with bitwise operators\r\n                \r\nI want to create a bitmask vector that masks which values are greater than a given value. Something like [1, 2, 3, 4, 5] * [>3, >3, >3, >3, >3] = [0, 0, 0, 1, 1]. I want to be able to run this on theano to get faster computation time for matrix operations. Is there a linear algebra procedure that can be written using bitwise operators or bits to create this bitmask? I am currently looping through this matrix and I would like to move the computation to a GPU using theano which requires more matrix multiplication. Thanks for any help.\n    ", "Answer": "\r\nYou can get exactly what you want with logical operations between matrices.\nFor example\n\n```\nprint((np.r_[1, 2, 3, 4, 5] > 3))\n```\n\n\nwill give\n\n```\n[False False False  True  True]\n```\n\n\nAnd if you want integers you can do\n\n```\nprint((np.r_[1, 2, 3, 4, 5] > 3).astype(int) )\n```\n\n\nand get\n\n```\n[0 0 0 1 1]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "NumPy Matrix Multiplication Efficiency for Matrix With Known Structure\r\n                \r\nI have two NxN matrices that I want to multiply together: A and B. In NumPy, I used:\n\n```\nimport numpy as np\nC = np.dot(A, B)\n```\n\n\nHowever, I happen to know that for matrix B only row n and column n are non-zero (this comes directly from the analytical formula that produced the matrix and is without a doubt always the case).\n\nHoping to take advantage of this fact and reduce the number of multiplications needed to produce C, I replaced the above with:\n\n```\nimport numpy as np\nfor row in range(0, N):\n    for col in range(0, N):\n        if col != n:\n            C[row, col] = A[row, n]*B[n, col]    #Just one scalar multiplication\n        else:\n            C[row, col] = np.dot(A[row], B[:, n])\n```\n\n\nAnalytically, this should reduce the total complexity as follows: In the general case (not using any fancy tricks, just basic matrix multiplication) C = AB, where A and B are both NxN, should be O(N^3). That is, all N rows must multiply all N columns, and each of these dot products contains N multiplications => O(NNN) = O(N^3).#\n\nExploiting the structure of B as I've done above however should go as O(N^2 + N^2) = O(2N^2) = O(N^2). That is, All N rows must multiply all N columns, however, for all of these (except those involving 'B[:, n]') only one scalar multiplication is required: only one element of 'B[:, m]' is non-zero for m != n. When n == m, which will occur N times (once for each row of A that must multiply column n of B), N scalar multiplications must occur.#\n\nHowever, the first block of code (using np.dot(A, B)) is substantially faster. I'm aware (via information like: Why is matrix multiplication faster with numpy than with ctypes in Python?) that the low level implementation details of np.dot are likely to blame for this. So my question is this: How can I exploit the structure of matrix B to improve multiplication efficiency without sacrificing the implementation efficiency of NumPy, without building my own low level matrix multiplication in c?\n\nThis method is part of a numerical optimization over many variables, hence, O(N^3) is intractable whereas O(N^2) will likely get the job done.\n\nThank you for any help. Also, I'm new to SO, so please pardon any newbie errors.\n    ", "Answer": "\r\nIf I understood ```\nA```\n and ```\nB```\n correctly, then I do not understand the ```\nfor```\n loops and why you are not just multiplying by the two non-zero vectors:\n\n```\n# say A & B are like this:\nn, N = 3, 5\nA = np.array( np.random.randn(N, N ) )\n\nB = np.zeros_like( A )\nB[ n ] = np.random.randn( N )\nB[:, n] = np.random.randn( N )\n```\n\n\ntake the non-zero row and column of B:\n\n```\nrowb, colb = B[n,:], np.copy( B[:,n] )\ncolb[ n ] = 0\n```\n\n\nmultiply ```\nA```\n by those two vector:\n\n```\nX = np.outer( A[:,n], rowb )\nX[:,n] += np.dot( A, colb )\n```\n\n\nto verify check:\n\n```\nX - np.dot( A, B )\n```\n\n\nwith ```\nN=100```\n:\n\n```\n%timeit np.dot(A, B)\n1000 loops, best of 3: 1.39 ms per loop\n\n%timeit colb = np.copy( B[:,n] ); colb[ n ] = 0; X = np.outer( A[:,n], B[n,:] ); X[:,n] += np.dot( A, colb )\n10000 loops, best of 3: 98.5 µs per loop\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "compute matrix multiplication without IML (SAS)\r\n                \r\nI found the way to compute matrix multiplication without IML from the answer of 'Dmitry Shopin'.\nhttps://stackoverflow.com/a/22007409/17754000\n```\n%macro prod_mat_merge(in_A =,in_B=,ou_AB=);\n/*determine number of rows and columns in the 2nd matrix*/\n%let B_id=%sysfunc(open(&in_B));\n%let B_rows=%sysfunc(attrn(&B_id,nobs));\n%let B_cols=%sysfunc(attrn(&B_id,nvars));\n%let rc=%sysfunc(close(&B_id));\n\n/*transpose the 2nd matrix*/\nproc transpose data=&in_B out=t&in_B(drop=_:);run;\n\n/*making Cartesian product of the 1st and transposed 2nd matrices*/\ndata &ou_AB;\n    do until(eofA);\n        set &in_A end=eofA;\n        do i=1 to n;\n            set t&in_B nobs=n point=i;\n            output;\n        end;\n    end;\nrun;\n\n/*multiplication*/\ndata &ou_AB;\n    /*new columns for products, equal to number of columns in the 2nd matrix*/\n    array p[&B_cols];\n    do j=1 to &B_cols;\n        p[j]=0;\n        set &ou_AB;\n        array col _ALL_;\n        /*multiply corresponding pairs of columns*/\n        do i=&B_cols+2 to &B_cols+1+&B_rows;\n            p[j]+col[i]*col[i+&B_rows];\n        end;\n    end;\n    output;\n    keep p:;\nrun;\n%mend prod_mat_merge;\n```\n\nHowever, I expect that P[j] will all be the same because the loop for i is independent of j.\n```\n    do i=&B_cols+2 to &B_cols+1+&B_rows;\n        p[j]+col[i]*col[i+&B_rows];\n    end;\n```\n\nAlso I think that the array P should have (A_rows*&B_cols) rows and (&B_cols) columns.\nBut the result P is a (A_rows × &B_cols) matrix.\nHow does it happen?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Reshape matrix before matrix multiplication\r\n                \r\nI have a snippet of the ```\nforward```\n step of \"Transformer Neural Network\" using Pytorch.\n\nSource: https://github.com/pbloem/former/blob/master/former/transformers.py\nSimplified to below code by me.\n\nWith:\n\n```\nb: batch_size```\n, ```\nt: input sequence length```\n, ```\nk: embedding length```\n, ```\nself.num_vocabs: output classes```\n\n```\nself.toprobs(x)```\n: a ```\nnn.Linear```\n layer with in/output features ```\n(k, num_vocabs)```\n.\n\n```\n    def forward(self, x):\n        tokens = self.token_embedding(x)\n        b, t, k = tokens.size()\n\n        x = self.transformer_block(tokens)\n\n        x = x.view(b * t, k)\n        x = self.toprobs(x)\n        x = x.view(b, t, self.num_vocabs)\n\n        output = F.log_softmax(x, dim=2)\n\n        return output\n```\n\nGiven: ```\nb = 2, t = 2, k = 3, self.num_vocabs = 256```\n.\n\nThe output shape of ```\nx```\n after ```\nx = self.transformer_block(tokens)```\n is ```\n(2, 2, 3)```\n.\nReshape ```\nx```\n to ```\n(b * t, k) -> (4, 3)```\n, then pass throught ```\nself.toprobs(x)```\n I got ```\n(4, 256)```\n, then reshape again back to ```\n(2, 2, 256)```\n.\n\nQuestion:\n\nWhy ```\nx```\n need to reshape to ```\n(b * t, k)```\n? If I keep ```\nx```\n shape at ```\n(2, 2, 3)```\n and pass throght ```\nself.toprobs(x)```\n, I stil have the same results and shape ```\n(2, 2, 256)```\n.\nIs there any beneficial in accelerate or memory usage of matrix multiplication step?\n\n```\n    def forward(self, x):\n        tokens = self.token_embedding(x)\n        b, t, k = tokens.size()\n\n        x = self.transformer_block(tokens)\n\n        # Same result without matrix reshape\n        x = self.toprobs(x)\n\n        output = F.log_softmax(x, dim=2)\n\n        return output\n```\n\n    ", "Answer": "\r\nI think this is just one particular person's implementation decision. Maybe they felt that it was easier to think about the dimensions this way, since they may feel that it's more explicit about what specific dimension is being transformed. Personally, I'd probably prefer not to change the batch dimension.\nView doesn't actually change the underlying data on the tensor (a view of a tensor shares the same storage). The behavior of nn.Linear is only based on the final dimension, which isn't being changed in the view operation in your code snippet (```\nH```\n in the linked doc). Based on the docs, I doubt there's any performance difference, and it makes sense to me that you'd see the same results either way.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Square Matrix multiplication using Java\r\n                \r\nI'm trying to write a simple square matrix multiplication method using multidimensional arrays. \n\n```\npackage matrixmultiplication;\n\nimport java.util.Scanner;\n\n\npublic class Matrixmultiplication \n{\n    public static void main(String[] args) \n    {\n        Scanner scan = new Scanner(System.in);\n        int [][] a,b,c;\n        int size;\n        System.out.print(\"Enter the Size of the matrix :\");\n        size = scan.nextInt();\n        a=b=c=new int[size][size];\n        System.out.println(\"Enter the elements of the First matrix\");\n        for(int i=0;i<size;i++)\n        {\n            for(int j=0;j<size;j++)\n            {\n                System.out.print(\"Enter the element a[\" + i +\"][\"+ j + \"] : \");\n                a[i][j] = scan.nextInt();\n            }\n        }\n        System.out.println(\"Enter the elements of the Second matrix\");\n        for(int i=0;i<size;i++)\n        {\n            for(int j=0;j<size;j++)\n            {\n                System.out.print(\"Enter the element b[\" + i +\"][\"+ j + \"] : \");\n                b[i][j] = scan.nextInt();\n            }\n        } \n\n        System.out.println(\"The Product of the two matrix is : \");\n        for(int i=0;i<size;i++)\n        {\n            for(int j=0;j<size;j++)\n            {\n                int sum = 0;\n                for(int k=0;k<size;k++)\n                {\n                    sum +=(a[i][k] * b[k][j]);\n                }\n                c[i][j] = sum;\n                System.out.print(c[i][j] + \"\\t\");\n            }\n            System.out.println();\n        }         \n\n    }\n\n}\n```\n\n\nWhen I run this program in Netbeans ,I get the following output:\n\n```\nEnter the Size of the matrix :2\nEnter the elements of the First matrix\nEnter the element a[0][0] : 1\nEnter the element a[0][1] : 1\nEnter the element a[1][0] : 1\nEnter the element a[1][1] : 1\nEnter the elements of the Second matrix\nEnter the element b[0][0] : 1\nEnter the element b[0][1] : 1\nEnter the element b[1][0] : 1\nEnter the element b[1][1] : 1\nThe Product of the two matrix is : \n2   3   \n3   10\n```\n\n\nThe Correct output of this program should be :\n\n```\n2  2\n2  2\n```\n\n\nCan someone tell me what is wrong with this code.\n    ", "Answer": "\r\nThe problem is here:\n\n```\na=b=c=new int[size][size];\n```\n\n\nThis creates just one array, and makes all of the variables point to it. So, updating the elements of ```\nc```\n is also updating the elements of ```\na```\n and ```\nb```\n.\n\nCreate 3 arrays instead:\n\n```\na=new int[size][size];\nb=new int[size][size];\nc=new int[size][size];\n```\n\n\nIdeone demo\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Numpy matrix multiplication with custom dot product\r\n                \r\nThe default matrix multiplication is computed as\n\n```\nc[i,j] = sum(a[i,k] * b[k,j])\n```\n\n\nI am trying to use a custom formula instead of the dot product to get\n\n```\nc[i,j] = sum(a[i,k] == b[k,j])\n```\n\n\nIs there an efficient way to do this in numpy?\n    ", "Answer": "\r\nYou could use broadcasting:\n\n```\nc = sum(a[...,np.newaxis]*b[np.newaxis,...],axis=1)  # == np.dot(a,b)\n\nc = sum(a[...,np.newaxis]==b[np.newaxis,...],axis=1)\n```\n\n\nI included the ```\nnewaxis```\n in ```\nb```\n just make it clear how that array is expanded.  There are other ways of adding dimensions to arrays (reshape, repeat, etc), but the effect is the same.  Expand ```\na```\n and ```\nb```\n to the same shape to do element by element multiplying (or ==), and then sum on the correct axis. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication-style addition in numpy\r\n                \r\nI have a row vector ```\na```\n and a column vector ```\nb```\n in numpy. If I was to do matrix multiplication on the two vectors, I would obtain a matrix ```\nm```\n where ```\nm[i,j] = a[i]b[j]```\n. I was wondering if there was a simple way of performing this style of operation for addition - i.e, obtaining  a matrix ```\nn```\n where ```\nn[i,j] = a[i] + b[j]```\n. Is there a built-in method for performing something like this?\n    ", "Answer": "\r\nI guess you mean ```\nnp.add```\n?\n\n```\nimport numpy as np    \n\nx1 = np.arange(3).reshape((3, 1))\nx2 = np.arange(3).reshape((1, 3))\nresult = np.add(x1, x2)\n\nprint(x1, '\\n')\nprint(x2, '\\n')\nprint(result)\n```\n\n\nOutput:\n\n```\n[[0]\n [1]\n [2]] \n\n[[0 1 2]] \n\n[[0 1 2]\n [1 2 3]\n [2 3 4]]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Segmentation fault while matrix multiplication using openMp?\r\n                \r\nMy matrix multiplication code is \n\n```\nint matMul(int ld, double** matrix)\n{ \n\n  //local variables initialize\n\n  omp_set_num_threads(nthreads);\n\n\n  \\#pragma omp parallel private(tid,diag,ld) shared(i,j,k,matrix)\n\n  {\n    /* Obtain and print thread id */\n\n    tid = omp_get_thread_num();\n\n    for ( k=0; k<ld; k++)  {\n    if (matrix[k][k] == 0.0) {\n      error = 1;\n      return error;\n    }\n    diag = 1.0 / matrix[k][k];\n\\#pragma omp for \n\n    for ( i=k+1; i < ld; i++) {\n\n      matrix[i][k] = diag * matrix[i][k];\n\n    }\n    for ( j=k+1; j<ld; j++) {\n\n      for ( i=k+1; i<ld; i++) {\n\n        matrix[i][j] = matrix[i][j] - matrix[i][k] * matrix[k][j];\n\n      }\n\n    }\n  } \n\n  }  \n  return error;\n\n}\n```\n\n\nI assume that it is because of matrix object only but why will it be null even though it is passed as a parameter.. \n    ", "Answer": "\r\nI ran into the same problem while compiling my code under Linux using GCC 4.2. The line that is causing the problem is: \n\n```\nomp_set_num_threads(nthreads);\n```\n\n\nYou should try to set the number of threads by specifying it under ```\npragma```\n ```\nomp```\n for: \n\n```\n#pragma omp for num_threads(nthreads)\n```\n\n\nHope it helps!\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Column Wise [R] Matrix Multiplication\r\n                \r\nNOTE: I am not referring to matrix multiplication as in here - not even with the twist of the transposed discussed on the other post.\n\n\n\nI have these two matrices...\n\nMatrix ```\nA```\n:\n\n```\nA <- matrix(c(1,1,1,-1,1,1,1,-1,1,-1,-1,1), ncol=4)\n       [,1]    [,2]     [,3]     [,4]  \n[1,]    1       -1        1        -1       \n[2,]    1        1       -1        -1     \n[3,]    1        1        1         1     \n```\n\n\n...and matrix ```\nB```\n:\n\n```\nB <- matrix(c(1,2,3,2,1,3,2,3,1), ncol=3)\n       [,1]    [,2]     [,3] \n[1,]    1        2        2 \n[2,]    2        1        3 \n[3,]    3        3        1 \n```\n\n\nI want to get with [R] code:\n\n```\n       [,1]    [,2]    [,3] \n[1,]    1*1     1*2     1*2 \n[2,]    1*2     1*1     1*3\n[3,]    1*3     1*3     1*1 \n\n       [,1]    [,2]    [,3] \n[1,]   -1*1    -1*2    -1*2 \n[2,]    1*2     1*1     1*3\n[3,]    1*3     1*3     1*1 \n\n       [,1]    [,2]    [,3] \n[1,]    1*1     1*2     1*2 \n[2,]   -1*2    -1*1    -1*3\n[3,]    1*3     1*3     1*1 \n\n       [,1]    [,2]    [,3] \n[1,]   -1*1    -1*2    -1*2 \n[2,]   -1*2    -1*1    -1*3\n[3,]    1*3     1*3     1*1 \n```\n\n\nIt's not linear algebraic multiplication because there is no sum at the end of the multiplications. It's not a Kronecker product. I have tried with ```\napply(A, 2, function(x) A * B```\n but it doesn't work, because although I can specify that I want the columns of ```\nA```\n one at a time, I don't know how to do the same for the columns of ```\nB```\n.\n\nI am not set on any particular type of object (list, matrix, array) as the output.\n\nThe question is: How can I multiply element-wise and column-wise these two matrices to end up with either another matrix or a \"list\" object or array?\n    ", "Answer": "\r\nYou can try something like the following:\n\n```\n> lapply(as.data.frame(A), `*`, B)\n$V1\n     [,1] [,2] [,3]\n[1,]    1    2    2\n[2,]    2    1    3\n[3,]    3    3    1\n\n$V2\n     [,1] [,2] [,3]\n[1,]   -1   -2   -2\n[2,]    2    1    3\n[3,]    3    3    1\n\n$V3\n     [,1] [,2] [,3]\n[1,]    1    2    2\n[2,]   -2   -1   -3\n[3,]    3    3    1\n\n$V4\n     [,1] [,2] [,3]\n[1,]   -1   -2   -2\n[2,]   -2   -1   -3\n[3,]    3    3    1\n```\n\n\n\n\nRegarding your follow up question in the comments below, if your end aim is for the column sums of each of these sub-matrices, you can achieve this with:\n\n```\n> lapply(as.data.frame(A), function(x) colSums(x * B))\n$V1\n[1] 6 6 6\n\n$V2\n[1] 4 2 2\n\n$V3\n[1] 2 4 0\n\n$V4\n[1]  0  0 -4\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to find the error in my matrix multiplication calculator\r\n                \r\n```\npackage practise;\nimport java.util.Scanner;\npublic class Practise {\n\n    public static void main(String[] args) {\n        \n        \n        Scanner sc = new Scanner(System.in);\n        System.out.println(\"Enter Dimensions Of Matrix A : \");\n        int rowsa = sc.nextInt();\n        int colsa = sc.nextInt();\n        System.out.println(\"Enter Dimensions Of Matrix B : \");\n        int rowsb = sc.nextInt();\n        int colsb = sc.nextInt();\n        int a[][] = new int[rowsa][colsa];\n        int b[][] = new int[rowsb][colsb];\n        int c[][] = new int[rowsa][colsb];\n        \n        \n        for(int i = 0;i<rowsa;i++) {\n            \n            for(int j = 0;j<colsa;j++) {\n                \n                a[i][j] = sc.nextInt();\n                \n            }   \n            }\n            for(int i = 0;i<rowsb;i++) {\n                \n                for(int j = 0;j<colsb;j++) {\n                    \n                    b[i][j] = sc.nextInt();\n                            \n                }           \n            \n            }\n            \n            \n            if(colsa == rowsb){\n                \n                for(int j = 0;j<colsb;j++) {\n                    \n                    for(int i =0;i<rowsa;i++) {\n                        \n                        c[rowsa][colsb] = a[j][i] * b[i][j] ;\n                    }\n                    \n                }\n            }\n            else{System.out.println(\"Matrix Multiplication Not Possible\");}\n            \n            \n            System.out.println(\"The Result is:\"+ c[rowsa][colsb]);\n            \n        }\n        \n        \n        \n        \n    }\n```\n\nI am trying to make a matrix multiplication calculator using the Row * Column formula of maths. It is throwing this error\n```\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: Index 3 out of bounds for length 3\n    at practise/practise.Practise.main(Practise.java:45)\n```\n\n    ", "Answer": "\r\n```\nint c[][] = new int[rowsa][colsb];\n[...]\nc[rowsa][colsb] = a[j][i] * b[i][j] ;\n```\n\nThis is your problem. ```\nc```\n has columns ranging from index ```\n0```\n to ```\nrowsa - 1```\n (making it ```\nrowsa```\n columns). Then you try to write to position ```\nrowsa```\n which is clearly outside of the array. (the same goes for colsb btw).\nQuick example:\n```\nrowsa = 3;\ncolsb = 3;\n\nint c[][] = new int[rowsa][colsb]\n```\n\nNow ```\nc```\n looks like:\n```\n    row\\col  0 1 2\n          0  0 0 0\n          1  0 0 0\n          2  0 0 0\n```\n\nSo which Element are you trying to get with ```\nc[rowsa][colsb]```\n also known as ```\nc[3][3]```\n? This one (marked as ```\nX```\n):\n```\nrow\\col  0 1 2\n      0  0 0 0\n      1  0 0 0\n      2  0 0 0\n               X\n```\n\nExcept that's not even inside your array (hence: ArrayIndexOutOfBoundsException)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Sparse boolean matrix multiplication\r\n                \r\nDoes anybody know the efficient implementation of sparse boolean matrix multiplication? I'm interested in both CPU and GPGPU implementations because it is necessary to multiply matrices of different sizes (from 8x8 to up to 10^8x10^8). Currently, I use cuSPARSE library, but it supports only numerical matrices (float, double etc) and this fact leads to huge overhead (by memory and time) which is critical in my task.\n    ", "Answer": "\r\nSince a boolean matrix can be viewed as the adjacency matrix of some (bipartite) graph, its product with another matrix can be interpreted as the distance 2 connections between the nodes of two subgraphs linked by a common set of nodes.\nTo avoid wasting space and exploit some amount of bit parallelism, you could try using some form of succint data structure for graph storage and manipulation.\nOne such family of data structures which could be useful in your case is the K2-tree (or Kn in general), which uses an approach to store the adjacencies similar to spatial decompositions such as quad- and oct- trers.\nUltimately, the best algorithm and data structure will heavily depend on the dimension and sparsity patterns of your matrices.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Numpy: Question about Matrix Multiplication\r\n                \r\nSo I am using someone else's GitHub code, but we get different results for our matrix multiplication.\nThe GitHub Code has:\n```\n# d_norm is shape (67,)\n# evec_hnl is shape (67,67)\n\nresult = d_norm*evec_hnl \n\n# result has shape (67,67)\n```\n\nBut when I do the same code I get:\n```\n# d_norm is shape (60,)\n# evec_hnl is shape (60,60)\n\nresult = d_norm*evec_hnl \n\n# result has shape (1,60)\n```\n\nI need my answer to be a square matrix with dimensions (60, 60), just like how in the GitHub code its a square matrix. Why do we get different results for the same code? What am I missing?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "LAPACK Matrix multiplication with C++\r\n                \r\nI am fairly new to C++ and trying to use LAPACK libraries for matrix multiplication.\nI tried to run the routine dgemm which is give below. I am expecting an output A*B. but every time I get the answer B*A. Is its the way routine works or anything wrong with my code.\n\nMy code:\n\n```\n#include \"stdafx.h\"\n#include<iostream>\n\nusing namespace std;\n\nextern \"C\" void dgemm_(const char *TRANSA, const char *TRANSB, const int *M, const int *N, const int *K, double *ALPHA, double *A, const int *LDA, double *B, const int *LDB, double *BETA, double *C, const int *LDC);\n\nint main(void)\n{\n    double A[4] = {1,2,3,4};\n    double B[4] = {5,6,7,8};\n    char TRANS = 'N';\n    int M = 2;\n    int N = 2;\n    int K = 2;\n    double ALPHA = 1.0;\n    int LDA = 2;\n    int LDB = 2;\n    double BETA = 0.0;\n    double C[4];\n    int LDC = 2;\n\n    dgemm_(&TRANS, &TRANS, &M, &N, &K, &ALPHA, A, &LDA, B, &LDB, &BETA, C, &LDC);\n\n    cout << C[0] << endl;\n    cout << C[1] << endl;\n    cout << C[2] << endl;\n    cout << C[3] << endl;\n    getchar();\n    return 0;\n}\n```\n\n\nAny inputs will be very helpful.\n    ", "Answer": "\r\nI've not studied the details of your call to dgemm, and I cannot tell how you are interpreting the result matrix. But it seems pretty likely that you are mixing up col major and row major interpretations somewhere. Most likely the calculation uses col major, but you are assuming row major.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication within ParLapply or foreach in R\r\n                \r\nI have a question about doing matrix multiplication with the parallel package in R.\n\nI encountered a wired situation that the matrix multiplication, 500*5 times 5*5, idled when running it on a cluster. I think the code itself is correct based on the fact that it ran successfully on my own computer.\n\nI really can't think any reason why this is happening. Thanks ahead if anyone can explain this. Let me know if you need more information.\n\nHere is the code\n\n```\nlibrary(doParallel)\n\nmedForest <- function(\n  x.b, x.e, treat, y.b, y.e, ntree, nCore=detectCores()-1\n  ) {\n  cl <- makeCluster(nCore,type=\"FORK\",outfile=\"debug.txt\")\n  registerDoParallel(cl)\n  forest <- foreach(i = 1:ntree, .combine = list, .multicombine = TRUE)  %dopar%  \n          {\n              tree <- UniAssoc(x.b = x.b, x.e = x.e, treat = treat,\n                               y.b = y.b, y.e = y.e)\n              return(tree)\n          }\n  stopImplicitCluster()\n  stopCluster(cl)\n  return(forest)\n}\n\nUniAssoc <- function(x.b, x.e, treat, y.b, y.e,) {\n  diff.x <- x.e[,,drop=FALSE] - x.b[,,drop=FALSE]\n  diff.y <- y.e - y.b\n\n  CCA.result <- cancor(scale(diff.x),scale(diff.y))\n\n  # Not error but idle forever\n  # diff.y is 500*5 matrix, CCA.result$ycoef is 5*5 matrix\n  direction <- scale(diff.y)%*%CCA.result$ycoef\n\n  # Will run if diff.y is reduced to a 450*5 matrix\n  # No idle\n  #direction <- scale(diff.y)%*%CCA.result$ycoef\n  return(direction)\n}\n```\n\n\nMy question is why the first matrix multiplication will idle forever on a campus cluster. It is not a legitimate behavior. And I am looking what can be the cause for this situation intuitively.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Parallel matrix multiplication in C with MPI\r\n                \r\nI am new at parallel programming using MPI in C. So I am working on a matrix multiplication for example A*B. Here's my code in C but I have not yet any idea how I can implement the MPI in my code.\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n\ntypedef struct sMatrix {\n        int size;\n        int *tab;\n        double time;\n} Matrix;\n\nvoid init_mat(Matrix *m, int t){\n        m->size=t;\n        m->tab=malloc(t*t*sizeof(int));\n        m->time=0;\n}\n\nvoid free_mat(Matrix *m){\n        free(m->tab);\n        m->size=0;\n        m->time=0;\n}\n\nvoid generate_mat_random(Matrix *m){\n        int i;\n        for(i=0;i<(m->size*m->size); i++){\n                m->tab[i]=rand()%10;                \n        }\n}\n\nvoid generate_mat(Matrix *m){\n        int i;\n        int cmp=1;\n        for(i=0;i<(m->size*m->size); i++){\n                m->tab[i]=cmp;                \n                cmp++;\n        }\n        cmp=1;\n}\n\nvoid display_mat(Matrix *m){\n        int i,j;\n        for(i=0;i<m->size;i++){\n                for(j=0;j<m->size;j++){\n                        printf(\"%3d   \",m->tab[i*m->size+j]);\n                }\n                printf(\"\\n\");\n        }\n}\n\nvoid display_mat_file(Matrix *m, char outputFilename[]){\n        FILE *ofp;\n        ofp = fopen(outputFilename, \"w\");\n        if (ofp == NULL) {\n                    fprintf(stderr, \"Can't open output file %s!\\n\", outputFilename);\n                    exit(1);\n          }\n\n        int i,j;\n        for(i=0;i<m->size;i++){\n                for(j=0;j<m->size;j++){\n                        fprintf(ofp, \"%3d   \",m->tab[i*m->size+j]);\n                }\n                fprintf(ofp,\"\\n\");\n        }\n\n        fprintf(ofp,\"\\n\");\n        fprintf(ofp,\"Time :%f \\n\", m->time);\n\n        fclose(ofp);\n}\n\n//m=m1*m2\n void multiply_MM(Matrix *m, Matrix m1, Matrix m2){\n        clock_t begin, end;\n\n        int i,j,k,s;\n        int sum;\n        begin=clock();\n\n        for( i=0;i<m->size;i++){\n                for( j=0;j<m->size;j++){\n                        k=0;\n                        sum=0;\n                        for( s=0;s<m->size;s++){\n                                sum = sum + m1.tab[i*m->size+s]*m2.tab[k*m->size+j];\n                                k++;        \n                        }        \n                        m->tab[i*m->size+j]=sum;\n                }\n        }\n\n        end=clock();\n        m->time = (double)(end - begin) / CLOCKS_PER_SEC;\n}\n\nint main(int argc, char* argv[]){\n        Matrix A;\n        Matrix B;\n        Matrix C;\n\n        printf(\"Initialisation of matrix A and B\\n\");\n\n        init_mat(&A, 2000);\n        init_mat(&B, 2000);\n        init_mat(&C, 2000);\n\n        generate_mat_random(&A);\n        generate_mat_random(&B);\n\n        multiply_MM(&C, A, B);\n\n        display_mat_file(&C,\"2000x2000.txt\");\n\n        printf(\"End of multiplication\\n\");\n        printf(\"Time for multiplication: %f\\n\",C.time);\n\n        free_mat(&A);\n        free_mat(&B);\n        free_mat(&C);\n\n        return 0;\n}\n```\n\n\nCan anyone suggest what methods I should use from MPI and where to use them in the ```\nmain()```\n?\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication for color space conversion\r\n                \r\nIn raw image processing you usually do two color space conversions using two 3x3 matrices: rgb2xyz and xyz2camera.\n\nYou could then get rgb2camera by either of these two matrix multiplications:\n(1) rgb2camera = (rgb2xyz)(xyz2camera)\nor:\n(2) rgb2camera = (xyz2camera)(rgb2xyz)\n\nAnd then get camera2rgb by inverting the rgb2camera matrix.\n\nHowever, matrix multiplication is not commutative so (1) and (2) give different results. I have seen both methods in various on-line articles, but which is correct? To me, (1) looks correct (mathematically), but (2) seems to give the more correct image (visually) for the sample image I have.\n    ", "Answer": "\r\nMathematically if you first multiply by A and then by B the correct combined matrix is BA, not AB. They go in reverse order. You can think of this as putting the vector last always so it looks logical. So the second one should be correct. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "sparse matrix multiplication in torch c++\r\n                \r\nI know that in the pytorch, you can use torch.sparse.mm(mat1,mat2) to do matrix multiplication between two sparse matrix. I wonder that if there is a function in torch c++ that can do the same thing(two sparse matrix mul)? I tried to use mat1.mm(mat2), but it seems like it only supports mat2 to be dense.\nThanks in advance!\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to simplify for loops using matrix multiplication?\r\n                \r\nIs there a more efficient way to replace these 2 for loops with matrix multiplication?\n```\ndef cost_func(x, y):\n     \n    for i in range(24):\n        for j in range(24):\n            cost = np.sum(W[i][j]*(y[j] - x[i]))       \n    \n    return cost\n```\n\nW is a matrix (25,25) and x,y are vectors with 25 elements.\n    ", "Answer": "\r\nNot 100% sure what you are trying to achieve here since as @Tim Roberts pointed out you are not saving the costs. Also the ```\nnp.sum```\n is confusing assuming ```\nx```\n and ```\ny```\n are 1d vectors. But if they are 1d vectors you could do:\n```\nimport numpy as np\nx = np.arange(24)\ny = np.arange(24)\nW = np.random.uniform(0, 1, (24, 24))\ncost = (W * (y.reshape(1, -1) - x.reshape(-1, 1)))\n\n# cost[i][j] = W[i][j]*(y[j] - x[i])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Improving the performance of Matrix Multiplication\r\n                \r\nThis is my code for speeding up matrix multiplication, but it is only 5% faster than the simple one.\nWhat can i do to boost it as much as possible?\n\n*The tables are being accessed for example as: C[sub2ind(i,j,n)] for the C[i, j] position.\n\n```\nvoid matrixMultFast(float * const C,            /* output matrix */\n                float const * const A,      /* first matrix */\n                float const * const B,      /* second matrix */\n                int const n,                /* number of rows/cols */\n                int const ib,               /* size of i block */\n                int const jb,               /* size of j block */\n                int const kb)               /* size of k block */\n{\n\nint i=0, j=0, jj=0, k=0, kk=0;\nfloat sum;\n\nfor(i=0;i<n;i++)\n    for(j=0;j<n;j++)\n        C[sub2ind(i,j,n)]=0;\n\nfor(kk=0;kk<n;kk+=kb)\n{\n    for(jj=0;jj<n;jj+=jb)\n    {\n        for(i=0;i<n;i++)\n        {\n            for(j=jj;j<jj+jb;j++)\n            {\n                sum=C[sub2ind(i,j,n)];\n                for(k=kk;k<kk+kb;k++)\n                    sum += A[sub2ind(i,k,n)]*B[sub2ind(k,j,n)];\n                C[sub2ind(i,j,n)]=sum;\n            }\n        }\n    }\n}\n} // end function 'matrixMultFast4'\n```\n\n\n*It is written in C and it needs to support C99\n    ", "Answer": "\r\nThere are many, many things you can do to improve the efficiency of matrix multiplication.\n\nTo examine how to improve the basic algorithm, let's first take a look at our current options. The naive implementation, of course, has 3 loops with a time complexity of the order of ```\nO(n^3)```\n. There is another method called Strassen's Method which achieves a appreciable speedup and has the order of ```\nO(n^2.73)```\n (but in practice is useless since it offers no appreciable means of optimization).\n\nThis is in theory. Now consider how matrices are stored in memory. Row major is the standard, but you find column major too. Depending on the scheme, transposing your matrix might improve speed due to fewer cache misses. Matrix multiplication in theory is just a bunch of vector dot products and addition. The same vector is to be operated upon by multiple vectors, thus it makes sense to keep that vector in cache for faster access. \n\nNow, with the introduction of multiple cores, parallelism and the cache concept, the game changes. If we look a little closely, we see that a dot product is nothing but a bunch of multiplications followed by summations. These multiplications can be done in parallel. Hence, we can now look at parallel loading of numbers.\n\nNow let's make things a little more complicated. When talking about matrix multiplication, there is a distinction between single floating point and double floating point in their size. Often the former is 32 bits while the latter, 64 (of course, this depends on the CPU). Each CPU only has a fixed number of registers, meaning the bigger your numbers, the lesser you can fit in the CPU. Moral of the story is, stick to single floating point unless you really need double.\n\nNow that we've gone through the basics of how we can tune matrix multiplication, worry not. You need do nothing of what has been discussed above since there are already subroutines to do it. As mentioned in the comments, there's GotoBLAS, OpenBLAS, Intel's MKL, and Apple's Accelerate framework. MKL/Accelerate are proprietary, but OpenBLAS is a very competitive alternative.\n\nHere's a nice little example that multiplies 2 8k x 8k matrices in a few milliseconds on my Macintosh:\n\n```\n#include <sys/time.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <Accelerate/Accelerate.h>\n\nint SIZE = 8192;\n\ntypedef float point_t;\n\npoint_t* transpose(point_t* A) {    \n    point_t* At = (point_t*) calloc(SIZE * SIZE, sizeof(point_t));    \n    vDSP_mtrans(A, 1, At, 1, SIZE, SIZE);\n\n    return At;\n}\n\npoint_t* dot(point_t* A, point_t* B) {\n    point_t* C = (point_t*) calloc(SIZE * SIZE, sizeof(point_t));       \n    int i;    \n    int step = (SIZE * SIZE / 4);\n\n    cblas_sgemm (CblasRowMajor, \n       CblasNoTrans, CblasNoTrans, SIZE/4, SIZE, SIZE,\n       1.0, &A[0], SIZE, B, SIZE, 0.0, &C[0], SIZE);\n\n    cblas_sgemm (CblasRowMajor, \n       CblasNoTrans, CblasNoTrans, SIZE/4, SIZE, SIZE,\n       1.0, &A[step], SIZE, B, SIZE, 0.0, &C[step], SIZE);\n\n    cblas_sgemm (CblasRowMajor, \n       CblasNoTrans, CblasNoTrans, SIZE/4, SIZE, SIZE,\n       1.0, &A[step * 2], SIZE, B, SIZE, 0.0, &C[step * 2], SIZE);\n\n    cblas_sgemm (CblasRowMajor, \n       CblasNoTrans, CblasNoTrans, SIZE/4, SIZE, SIZE,\n       1.0, &A[step * 3], SIZE, B, SIZE, 0.0, &C[step * 3], SIZE);      \n\n    return C;\n}\n\nvoid print(point_t* A) {\n    int i, j;\n    for(i = 0; i < SIZE; i++) {\n        for(j = 0; j < SIZE; j++) {\n            printf(\"%f  \", A[i * SIZE + j]);\n        }\n        printf(\"\\n\");\n    }\n}\n\nint main() {\n    for(; SIZE <= 8192; SIZE *= 2) {\n        point_t* A = (point_t*) calloc(SIZE * SIZE, sizeof(point_t));\n        point_t* B = (point_t*) calloc(SIZE * SIZE, sizeof(point_t));\n\n        srand(getpid());\n\n        int i, j;\n        for(i = 0; i < SIZE * SIZE; i++) {\n            A[i] = ((point_t)rand() / (double)RAND_MAX);\n            B[i] = ((point_t)rand() / (double)RAND_MAX);\n        }\n\n        struct timeval t1, t2;\n        double elapsed_time;\n\n        gettimeofday(&t1, NULL);\n        point_t* C = dot(A, B);\n        gettimeofday(&t2, NULL);\n\n        elapsed_time = (t2.tv_sec - t1.tv_sec) * 1000.0;      // sec to ms\n        elapsed_time += (t2.tv_usec - t1.tv_usec) / 1000.0;   // us to ms\n\n        printf(\"Time taken for %d size matrix multiplication: %lf\\n\", SIZE, elapsed_time/1000.0);\n\n        free(A);\n        free(B);\n        free(C);\n\n    }\n    return 0;\n}\n```\n\n\nAt this point I should also mention SSE (Streaming SIMD Extension), which is basically something you shouldn't do unless you've worked with assembly. Basically, you're vectorising your C code, to work with vectors instead of integers. This means you can operate on blocks of data instead of single values. The compiler gives up and just translates your code as is without doing its own optimizations. If done right, it can speed up your code like nothing before - you can touch the theoretical floor of ```\nO(n^2)```\n even! But it is easy to abuse SSE, and most people unfortunately do, making the end result worse than before.\n\nI hope this motivates you to dig deeper. The world of matrix multiplication is a large and fascinating one. Below, I attach links for further reading.\n\n\nOpenBLAS\nMore about SSE\nIntel Intrinsics\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "What is the quickest method of matrix multiplication?\r\n                \r\nI've been working on a rather extensive program as of late, and i'm currently at a point where I have to utilize matrix multiplication. Thing is, for this particular program, speed is crucial. I'm familiar with a number of matrix setups, but I would like to know which method will run the fastest. I've done extensive research, but turned up very little results. Here is a list of the matrix multiplication algorithms I am familiar with:       \n\n\nIterative algorithm       \nDivide and Conquer algorithm\nSub Cubic algorithms\nShared Memory Parallelism\n\n\nIf anyone needs clarification on the methods I listed, or on the question in general, feel free to ask.\n    ", "Answer": "\r\nThe Strassen algorithm and the naive (O(n^3)) one are the most used in practice.\n\nMore complex algorithms with tighter asymptotic bounds are not used because they benefits would be apparent only for extremely large matrices, due to their complexity, e.g. Coppersmith algorithm.\n\nAs others pointed out you might want to use a library like ATLAS which will automatically tune the algorithm depending on the characteristcs of the platform where you are executing, e.g. L1/L2 cache sizes.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Cuda matrix multiplication- wrong result\r\n                \r\nthis is my code for matrix multiplication, but when i run it i get correct result for first row  but wrong ones for second and third(mostly big negative numbers). This is my first programm so i  used some code that i found on net\n\n```\n #include <iostream>\n\n__global__ void MnozenjeMatrica(int* d_c, int* d_a, int* d_b)\n{\nint row = blockIdx.y * blockDim.y + threadIdx.y;\nint col = blockIdx.x * blockDim.x + threadIdx.x;    \n\nint d = 0;\nfor(int i=0; i<3; i++)\n{\n    int x = d_a[row * 3 + i];\n    int y = d_b[i * 3 + col];\n    d += x * y;\n}\n\nd_c[row * 3 + col] = d; \n}\n\nint main()\n{\nconst int SIZE = 9 * sizeof(int); \n\nint a[3][3] = {{2, 4, 6}, {1, 3, 5}, {8, 4, 1}};\nint b[3][3] = {{5, 8, 34}, {5, 7, 5}, {1, 4, 31}};\nint c[3][3] = {{5, 8, 34}, {5, 7, 5}, {1, 4, 31}};\n\nint* d_a;\nint* d_b;\nint* d_c;\n\ncudaMalloc((void**) &d_a, SIZE);\ncudaMalloc((void**) &d_b, SIZE);\ncudaMalloc((void**) &d_c, SIZE);\n\ncudaMemcpy(d_a, a, SIZE, cudaMemcpyHostToDevice);\ncudaMemcpy(d_b, b, SIZE, cudaMemcpyHostToDevice);\n\nMnozenjeMatrica<<<3, 3>>>(d_c, d_a, d_b);\ncudaMemcpy(c, d_c, SIZE, cudaMemcpyDeviceToHost);\n\nfor(int i=0; i<3; i++)\n{\n    for(int j=0;  j<3; j++)\n    {\n        printf(\"%d\\t\", c[i][j]);\n    }\n    printf(\"\\n\");\n}\n\n\n }\n```\n\n    ", "Answer": "\r\nCompletely agree with @talonmies.  \n\nMore suggestions:\n\n\nThere are plenty of people who have posted questions about cuda\nmatrix multiplication, you might take a look at some of those to get\nsome ideas.\nYou're not doing any cuda error checking on kernel\ncalls and cuda calls (but it's recommended)\nYou might try running your code with ```\ncuda-memcheck```\n, and see what it says.\nYou could debug this kernel pretty quickly with a few choice ```\nprintf```\n statements.  This is mostly C code after all, you should consider using basic C troubleshooting techniques.\n\n\nSince I was able to quickly spot this, I can tell you that your kernel is depending on a 2-D threadblock structure to do anything useful:\n\n```\nint row = blockIdx.y * blockDim.y + threadIdx.y;\nint col = blockIdx.x * blockDim.x + threadIdx.x;\n```\n\n\nBut you are launching a 1D grid of 1D threadblocks:\n\n```\nMnozenjeMatrica<<<3, 3>>>(d_c, d_a, d_b);\n                  ^  ^\n                  |  1-D threadblock (3 threads)\n                  1-D grid (3 blocks)\n```\n\n\nSo I'm not surprised it only works for a single row.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How many many steps needed for n*n matrix multiplication?\r\n                \r\nI have got a strange question in previous year question and that is , if an algorithm needs 21 steps for a 7*7 matrix multiplication then how many steps would it need for n*n matrix multiplication ? \n\nI have tried to do 7*7 matrix multiplication and calculated how many multiplications done . Then I tried to relate the n of multiplications with the steps . But it does not work . \n\nFrom many people , I have heard that the answer is 3n but they cannot explain the cause of being 3n as the answer . \n\nCan you simply give me an idea how can I solve this question ? \n    ", "Answer": "\r\nConsider that for each row.dot(column) you have to do the same thing, and you have to do this for each row.column pair - so it seems like each dimension would give you ```\n21/7=3```\n steps, since you have 7 row.column pairs needing a total of 21 steps.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication using pointers in c\r\n                \r\n```\n#include<stdio.h>\n\nint mul(int *a[3][3], int *b[3][3]);\n\nint i,j,k,*c[3][3],*a[3][3],*b[3][3];\n\nint main()\n{\n    printf(\"enter the elements of 1st 3*3 matrix:A\");\n    for(i=0;i<3;i++)\n    {\n        for(j=0;j<3;j++)\n        {\n            scanf(\"%d\",&a[i][j]);\n        }\n    }\n    printf(\"enter the elements of 1st 3*3 matrix:B\");\n    for(i=0;i<3;i++)\n    {\n        for(j=0;j<3;j++)\n        {\n            scanf(\"%d\",&b[i][j]);\n        }\n    }\n    mul(a,b);\n    printf(\"result=\");\n    for(i=0;i<3;i++)\n    {\n        for(j=0;j<3;j++)\n        {\n            printf(\"\\t%d\\t\",*c[i][j]);\n        }\n        printf(\"\\n\");\n    }\n}\n\nint mul(int *a[3][3], int *b[3][3])\n{\n    for(i=0;i<3;i++)\n    {\n        for(j=0;j<3;j++)\n        {\n            *c[i][j]=0;\n            for(k=0;k<3;k++)\n            {\n                c[i][j] = *a[i][k] * *b[k][j] + *c[i][j];\n            }\n        }\n    }\n}\n```\n\n\nI am trying to do matrix multiplication using pointers but I am not getting any result. \n\nI searched on google but cannot understand any of them.\n\nalso any of them were far different  than mine.\n\nplease help me.\n    ", "Answer": "\r\nWhen manually multiplying matrices with pointers, you might want to represent them as one single ```\narray[]```\n, instead of a vector of ```\narray[]```\n's.\nThis way, it is easier to move the pointers. Consider this implementation:\n```\nvoid matmul(double *dest, const double *lhs, const double *rhs,\n            size_t rows, size_t mid, size_t cols) {\n    memset(dest, 0, rows * cols * sizeof(double));\n \n    for (size_t i = 0; i < rows; ++i) {\n        const double *rhs_row = rhs;\n        for (size_t j = 0; j < mid; ++j) {\n            for (size_t k = 0; k < cols; ++k) {\n                dest[k] += lhs[j] * rhs_row[k];\n            }\n            rhs_row += cols;\n        }\n        dest += cols;\n        lhs += mid;\n    }\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Optimization of matrix multiplication in vb.net\r\n                \r\nI'm currently trying to do some work on a neural network class in visual basic. My main drag at the moment is the multiplication of the matrices is so slow! Here's the code I use right now;\n\n```\n   Public Function MultiplyMatricesParallel(ByVal matA As Double()(), ByVal matB As Double()()) As Double()()\n    Dim matACols As Integer = matA(0).GetLength(0)\n    Dim matBCols As Integer = matB(0).GetLength(0)\n    Dim matARows As Integer = matA.GetLength(0)\n    Dim result(matARows - 1)() As Double\n    For i = 0 To matARows - 1\n        ReDim result(i)(matBCols - 1)\n    Next\n    Dim tempMat()() As Double = MatrixTranspose(matB)\n    Parallel.For(0, matARows, Sub(i)\n                                  For j As Integer = 0 To matBCols - 1\n                                      Dim temp As Double = 0\n                                      Dim maA() As Double = matA(i)\n                                      Dim maB() As Double = tempMat(j)\n                                      For k As Integer = 0 To matACols - 1\n                                          temp += maA(k) * maB(k)\n                                      Next\n                                      result(i)(j) += temp\n                                  Next\n                              End Sub)\n    Return result\nEnd Function\n```\n\n\nI just jagged arrays as they are quicker in vb than rectangular arrays. Of course they really are rectangular otherwise the matrix multiplication wouldn't work (or make sense). Any advice/help would be appreciated, for reference the matrix size can change but it's currently around 7,000 x 2,000 at the maximum.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication A^T * A in PySpark\r\n                \r\nI asked a similar question yesterday - Matrix Multiplication between two RDD[Array[Double]] in Spark - however I've decided to shift to pyspark to do this. I've made some progress loading and reformatting the data - Pyspark map from RDD of strings to RDD of list of doubles - however the matrix multiplcation is difficult. Let me share my progress first:\n\n```\nmatrix1.txt\n1.2 3.4 2.3 \n2.3 1.1 1.5\n3.3 1.8 4.5\n5.3 2.2 4.5\n9.3 8.1 0.3\n4.5 4.3 2.1 \n```\n\n\nit's difficult to share files, however this is what my matrix1.txt file looks like. It is a space-delimited text file including the values of a matrix. Next is the code:\n\n```\n# do the imports for pyspark and numpy\nfrom pyspark import SparkConf, SparkContext\nimport numpy as np\n\n# loadmatrix is a helper function used to read matrix1.txt and format\n# from RDD of strings to RDD of list of floats\ndef loadmatrix(sc):\n    data = sc.textFile(\"matrix1.txt\").map(lambda line: line.split(' ')).map(lambda line: [float(x) for x in line])\n    return(data) \n\n# this is the function I am struggling with, it should take a line of the \n# matrix (formatted as list of floats), compute an outer product with itself\ndef AtransposeA(line):\n    # pseudocode for this would be...\n    # outerprod = compute line * line^transpose     \n    # return(outerprod)\n\n# here is the main body of my file    \nif __name__ == \"__main__\":\n    # create the conf, sc objects, then use loadmatrix to read data\n    conf = SparkConf().setAppName('SVD').setMaster('local')\n    sc = SparkContext(conf = conf)\n    mymatrix = loadmatrix(sc)\n\n    # this is pseudocode for calling AtransposeA\n    ATA = mymatrix.map(lambda line: AtransposeA(line)).reduce(elementwise add all the outerproducts)\n\n    # the SVD of ATA is computed below\n    U, S, V = np.linalg.svd(ATA)\n\n    # ...\n```\n\n\nMy approach is as follows - to do matrix multiplication A^T * A, I create a function that computes outer products of rows of A. The elementwise sum of all of the outerproducts is the product I want. I then call AtransposeA() in a map function, that way is it performed on each row of the matrix, and finally I use a reduce() to add the resulting matrices.  \n\nI'm struggling thinking about how the AtransposeA function should look. How can I do an outerproduct in pyspark like this? Thanks in advance for help!\n    ", "Answer": "\r\nFirst, consider why you want to use ```\nSpark```\n for this. It sounds like all your data fits in memory, in which case you can use ```\nnumpy```\n and ```\npandas```\n in a very straight-forward way.\n\nIf your data isn't structured so that rows are independent, then it probably can't be parallelized by sending groups of rows to different nodes, which is the whole point of using ```\nSpark```\n.\n\nHaving said that... here is some ```\npyspark```\n (2.1.1) code that I think does what you want.\n\n```\n# read the matrix file\ndf = spark.read.csv(\"matrix1.txt\",sep=\" \",inferSchema=True)\ndf.show()\n+---+---+---+\n|_c0|_c1|_c2|\n+---+---+---+\n|1.2|3.4|2.3|\n|2.3|1.1|1.5|\n|3.3|1.8|4.5|\n|5.3|2.2|4.5|\n|9.3|8.1|0.3|\n|4.5|4.3|2.1|\n+---+---+---+\n# do the sum of the multiplication that we want, and get\n# one data frame for each column\ncolDFs = []\nfor c2 in df.columns:\n    colDFs.append( df.select( [ F.sum(df[c1]*df[c2]).alias(\"op_{0}\".format(i)) for i,c1 in enumerate(df.columns) ] ) )\n# now union those separate data frames to build the \"matrix\"\nmtxDF = reduce(lambda a,b: a.select(a.columns).union(b.select(a.columns)), colDFs )\nmtxDF.show()\n+------------------+------------------+------------------+\n|              op_0|              op_1|              op_2|\n+------------------+------------------+------------------+\n|            152.45|118.88999999999999|             57.15|\n|118.88999999999999|104.94999999999999|             38.93|\n|             57.15|             38.93|52.540000000000006|\n+------------------+------------------+------------------+\n```\n\n\nThis seems to be the same result that you get from ```\nnumpy```\n.\n\n```\na = numpy.genfromtxt(\"matrix1.txt\")\nnumpy.dot(a.T, a)\narray([[ 152.45,  118.89,   57.15],\n       [ 118.89,  104.95,   38.93],\n       [  57.15,   38.93,   52.54]])\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Scipy: Sparse matrix multiplication memory error\r\n                \r\nI want to perform matrix multiplication between a sparse matrix and its transpose, (their are big matrices). Specifically, I have:\n```\nC = csc_matrix(...)\nCt = csc_matrix.transpose(C)\nL = Ct*C\n```\n\nand shapes:\n```\nC.shape\n(1791489, 28508141)\nCt.shape\n(28508141, 1791489)\n```\n\nAnd I am getting the following error:\n```\nTraceback (most recent call last):\n\n  File \"C:\\...\\modularity.py\", line 373, in <module>\n    L = Ct*C\n\n  File \"C:\\...\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\", line 480, in __mul__\n    return self._mul_sparse_matrix(other)\n\n  File \"C:\\...\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\", line 518, in _mul_sparse_matrix\n    indices = np.empty(nnz, dtype=idx_dtype)\n\nMemoryError: Unable to allocate 1.11 TiB for an array with shape (152087117507,) and data type int64\n```\n\nI cannot figure out why, why does it try to allocate memory for such a huge array ?\nUpdate: Currently I am trying to do the multiplication in chunks like this\n```\nchunksize=1000\nnumiter = Ct.shape[0]//chunksize\nblocks=[]\nfor i in range(numiter):\n    A = Ct[i*chunksize:(i+1)*chunksize].dot(C)\n    blocks.append(A)\n```\n\nBut I get:\n```\nMemoryError: Unable to allocate 217. MiB for an array with shape (57012620,) and data type int32\n```\n\n    ", "Answer": "\r\nFor future viewers who want to multiply huge sparse matrices I solved my problem using PyTables and saved the result of the multiplication in chunks. Still it creates a big file but at least is compressed. The code I used goes like this:\n```\nimport tables as tb\n\nf = tb.open_file('D:\\dot.h5', 'w')\nl, m, n = Ct.shape[0], Ct.shape[1], C.shape[1]\nfilters = tb.Filters(complevel=8, complib='blosc')\nout_data = f.create_earray(f.root, 'data', tb.Int32Atom(), shape=(0,), filters=filters)\nout_indices = f.create_earray(f.root, 'indices', tb.Int32Atom(),shape=(0,), filters=filters)\nout_indptr = f.create_earray(f.root, 'indptr', tb.Int32Atom(), shape=(0,), filters=filters)\nout_indptr.append(np.array([0])) #this is needed as a first indptr\nmax_indptr = 0\n#buffersize\nbl = 10000\nfor i in range(0, l, bl):\n res = Ct[i:min(i+bl, l),:].dot(C)\n out_data.append(res.data)\n indices = res.indices\n indptr = res.indptr\n out_indices.append(indices)\n out_indptr.append(max_indptr+indptr[1:])\n max_indptr += indices.shape[0]\n```\n\nSo if for example you want access to the 2nd row of your final matrix you simply can:\n```\nL2 = csr_matrix((a.data[a.indptr[2]:a.indptr[2+1]], a.indices[a.indptr[2]:a.indptr[2+1]], np.array([0,len(a.indices[a.indptr[2]:a.indptr[2+1]])])), shape=(1,n))\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Can't perform matrix multiplication on float matrix in numpy [duplicate]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                This question already has answers here:\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                    \r\n                        can't multiply sequence by non-int of type 'float' error?\r\n                            \r\n                                (2 answers)\r\n                            \r\n                    \r\n                Closed 1 year ago.\r\n        \r\n\r\n\r\n    \r\n\r\nToday as I'm trying to implement linear regression by hand, I encountered an issue in numpy that stops me from performing the intended matrix multiplication. Because the two matrix contains float numbers (not sure if that is the issue), the notebook kept on returning\n```\nTypeError: can't multiply sequence by non-int of type 'float'\n```\n\nHere is the notebook at the data I used, please help!\n    ", "Answer": "\r\nYou probably meant to use ```\nnp.matmul```\n or ```\n@```\n (shorthand) rather than the ```\n*```\n shorthand, which makes soft-copies duplicates in a Python list (and so can't create a fractional number, only integral ones)\nSee the notes in the numpy.dot docs https://numpy.org/doc/stable/reference/generated/numpy.dot.html\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication through function in C\r\n                \r\nI just want to create a program that can solve the Matrix multiplication. I can solve this problem with only using main function but I did not solve this in using different function. In my code 1st I make 4 function. The 1st function will give the number of rows and column form user. 2nd function will collect the values of matrix. 3rd function will print the value of function. 4th function will  show the result of multiplication of the matrix. Here is my code and the errors that compiler give me for this code.\n```\n#include <stdio.h>\nvoid inputRowColForGun(int Ar, int Ac, int Br, int Bc)\n{\n do\n {\n     printf(\"Enter the value of row & column of A: \");\n     scanf(\"%d %d\", &Ar, &Ac);\n     printf(\"\\n\");\n     printf(\"Enter the value of row & column of B: \");\n     scanf(\"%d %d\", &Br, &Bc);\n     printf(\"\\n\");\n     if (Ac == Br)\n     {\n         break;\n     }\n     printf(\"Error ! Your A matrix column and B matrix row should be same.\\n\");\n } while (Ac != Br);\n}\n\nvoid inputmat(int Ar, int Ac, int A[Ar][Ac])\n{\n for (int a = 0; a < Ar; a++)\n {\n     for (int b = 0; b < Ac; b++)\n     {\n         printf(\"Enter the value of Mat%d%d : \", a + 1, b + 1);\n         scanf(\"%d\", &A[a][b]);\n     }\n     printf(\"\\n\");\n }\n}\n\nvoid printmat(int r, int c, int A[r][c])\n{\n printf(\"\\n\\nMatrix=\\n\");\n for (int e = 0; e < r; e++)\n {\n     for (int f = 0; f < c; f++)\n     {\n         printf(\" %d\", A[e][f]);\n     }\n     printf(\"\\n\");\n }\n}\n\nvoid resultOfGun(int A[Ar][Ac], int B[Br][Bc], int Ar, int Ac, int Br, int Bc)\n{\n printf(\"\\nA*B = \\n\");\n for (int i = 0; i < Ar; i++)\n {\n     for (int j = 0; j < Bc; j++)\n     {\n         int R = 0;\n         for (int k = 0; k < Ac; k++)\n         {\n             R = R + A[i][k] * B[k][j];\n         }\n         printf(\" %d \", R);\n     }\n     printf(\"\\n\");\n }\n}\n\nvoid main()\n{\n int Ar, Ac, Br, Bc;\n printf(\"=== Matrix's Multiplication === \\n\\n\\n\");\n inputRowColForGun(Ar, Ac, Br, Bc);\n int A[Ar][Ac], B[Br][Bc];\n inputmat(A, Ar, Ac);\n inputmat(B, Br, Bc);\n printmat(A, Ar, Ac);\n printmat(B, Br, Bc);\n resultOfGun(A, B, Ar, Ac, Br, Bc);\n}\n```\n\n```\nErrors:\n\nPS D:\\Github\\Learn c> cd \"d:\\Github\\Learn c\\\" ; if ($?) { gcc tempCodeRunnerFile.c -o tempCodeRunnerFile } ; if ($?) { .\\tempCodeRunnerFile \n}\ntempCodeRunnerFile.c:47:24: error: 'Ar' undeclared here (not in a function)\n void resultOfGun(int A[Ar][Ac], int B[Br][Bc], int Ar, int Ac, int Br, int Bc)\n                        ^~\ntempCodeRunnerFile.c:47:28: error: 'Ac' undeclared here (not in a function)\n void resultOfGun(int A[Ar][Ac], int B[Br][Bc], int Ar, int Ac, int Br, int Bc)\n                            ^~\ntempCodeRunnerFile.c:47:39: error: 'Br' undeclared here (not in a function)\n void resultOfGun(int A[Ar][Ac], int B[Br][Bc], int Ar, int Ac, int Br, int Bc)\n                                       ^~\ntempCodeRunnerFile.c:47:43: error: 'Bc' undeclared here (not in a function)\n void resultOfGun(int A[Ar][Ac], int B[Br][Bc], int Ar, int Ac, int Br, int Bc)\n                                           ^~\ntempCodeRunnerFile.c: In function 'main':\ntempCodeRunnerFile.c:71:14: warning: passing argument 1 of 'inputmat' makes integer from pointer without a cast [-Wint-conversion]\n     inputmat(A, Ar, Ac);\n              ^\ntempCodeRunnerFile.c:21:19: note: expected 'int' but argument is of type 'int (*)[(sizetype)(Ac)]'\n void inputmat(int Ar, int Ac, int A[Ar][Ac])\n               ~~~~^~\ntempCodeRunnerFile.c:71:21: warning: passing argument 3 of 'inputmat' makes pointer from integer without a cast [-Wint-conversion]\n     inputmat(A, Ar, Ac);\n                     ^~\ntempCodeRunnerFile.c:21:35: note: expected 'int (*)[(sizetype)(Ac)]' but argument is of type 'int'\n void inputmat(int Ar, int Ac, int A[Ar][Ac])\n                               ~~~~^~~~~~~~~\ntempCodeRunnerFile.c:72:14: warning: passing argument 1 of 'inputmat' makes integer from pointer without a cast [-Wint-conversion]\n     inputmat(B, Br, Bc);\n              ^\ntempCodeRunnerFile.c:21:19: note: expected 'int' but argument is of type 'int (*)[(sizetype)(Bc)]'\n void inputmat(int Ar, int Ac, int A[Ar][Ac])\n               ~~~~^~\ntempCodeRunnerFile.c:72:21: warning: passing argument 3 of 'inputmat' makes pointer from integer without a cast [-Wint-conversion]\n     inputmat(B, Br, Bc);\n                     ^~\ntempCodeRunnerFile.c:21:35: note: expected 'int (*)[(sizetype)(Ac)]' but argument is of type 'int'\n void inputmat(int Ar, int Ac, int A[Ar][Ac])\n                               ~~~~^~~~~~~~~\ntempCodeRunnerFile.c:73:14: warning: passing argument 1 of 'printmat' makes integer from pointer without a cast [-Wint-conversion]\n     printmat(A, Ar, Ac);\n              ^\ntempCodeRunnerFile.c:34:19: note: expected 'int' but argument is of type 'int (*)[(sizetype)(Ac)]'\n void printmat(int r, int c, int A[r][c])\n               ~~~~^\ntempCodeRunnerFile.c:73:21: warning: passing argument 3 of 'printmat' makes pointer from integer without a cast [-Wint-conversion]\n     printmat(A, Ar, Ac);\n                     ^~\ntempCodeRunnerFile.c:34:33: note: expected 'int (*)[(sizetype)(c)]' but argument is of type 'int'\n void printmat(int r, int c, int A[r][c])\n                             ~~~~^~~~~~~\ntempCodeRunnerFile.c:74:14: warning: passing argument 1 of 'printmat' makes integer from pointer without a cast [-Wint-conversion]\n     printmat(B, Br, Bc);\n              ^\ntempCodeRunnerFile.c:34:19: note: expected 'int' but argument is of type 'int (*)[(sizetype)(Bc)]'\n void printmat(int r, int c, int A[r][c])\n               ~~~~^\ntempCodeRunnerFile.c:74:21: warning: passing argument 3 of 'printmat' makes pointer from integer without a cast [-Wint-conversion]\n     printmat(B, Br, Bc);\n                     ^~\ntempCodeRunnerFile.c:34:33: note: expected 'int (*)[(sizetype)(c)]' but argument is of type 'int'\n void printmat(int r, int c, int A[r][c])\n                             ~~~~^~~~~~~\ntempCodeRunnerFile.c:75:17: error: type of formal parameter 1 is incomplete\n     resultOfGun(A, B, Ar, Ac, Br, Bc);\n                 ^\ntempCodeRunnerFile.c:75:20: error: type of formal parameter 2 is incomplete\n     resultOfGun(A, B, Ar, Ac, Br, Bc);\n                    ^\nPS D:\\Github\\Learn c> \n\n```\n\nplease solve this problem. Thank you very much\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "threaded matrix multiplication function\r\n                \r\nI'm trying to write two matrix multiplication functions, one standard and one that is threaded. However, I can't figure out how to call the threaded function correctly. \n\nHere is the code:\n\n```\n#include <iostream>\n#include <future>\n#include <sys/time.h>\n#include <stdio.h>\n#include <thread>\n\nusing namespace std;\n\ndouble get_wallTime() {\n    struct timeval tp;\n    gettimeofday(&tp, NULL);\n    return (double) (tp.tv_sec + tp.tv_usec/1000000.0);\n}\n\n\n\nstatic void matrixMultiply(double** a, double** b, double** product, int size) {\n\n    for (int i = 0; i < size; i++) {\n       for (int j = 0; j < size; j++) {\n          for (int k = 0; k < size; k++) {\n          product[i][j] += a[i][k] * b[k][j];\n          }\n       }\n    }\n\n\n}\n\nstatic void matrixMultiplyThreaded(double** a, double** b, double** product, int dimLower, int dimUpper, int dim) {\n    for (int i = dimLower; i < dimUpper; i++) {\n        for (int j = 0; j < dim; j++) {\n            for (int k = 0; k < dim; k++) {\n                product[i][j] += a[i][k] * b[k][j];\n            }\n        }\n    }\n}\n\nint main(int argc, char *argv[]) {\n    if (argc < 3) {\n       cout << \"Not enough arguments.\";\n    }\n    int numTimes = atoi(argv[1]);\n    char *threadOrNo = argv[2];\n    int size = atoi(argv[3]);\n    double a[size][size], b[size][size] = {};\n    double product[size][size] = {};\n\n    for (int i=0; i<size; i++) {\n       for (int j=0; j < size; j++) {\n          a[i][j] = 2;\n          b[i][j] = 3;\n       }\n    }\n    double t1 = get_wallTime();\n    if (*threadOrNo == 'y') {\n       int dim1 = size / 2;\n       for (int n = 0; n < numTimes; n++) {\n          std::thread first (matrixMultiplyThreaded, a, b, product, 0, dim1, size);\n\n          std::thread second (matrixMultiplyThreaded, a, b, product, dim1, size, size);\n          first.join();\n          second.join();\n          }\n    }\n    else { \n       for (int m = 0; m < numTimes; m++) {\n\n          matrixMultiply(a[size][size],b[size][size], product[size][size], size);\n    }\n    }\n    double t2 = get_wallTime();\n    double totalTime = t2 - t1;\n    cout << \"time : \" << totalTime;\n\n\n}\n```\n\n\nIf anyone could give any advice I would be eternally grateful. Specifically, what's the right way to implement threads for the threaded function? \n\nHere is the first error message I receive, which I've tried to fix several times:\n\n```\nmultiplyMatrix.cpp: In function 'int main(int, char**)':\nmultiplyMatrix.cpp:64:82: error: no matching function for call to 'std::thread::thread(void (&)(double**, double**, double**, int, int, int), double [size][size], double [size][size], double [size][size], int, int&, int&)'\n           std::thread first (matrixMultiplyThreaded, a, b, product, 0, dim1, size);\n```\n\n    ", "Answer": "\r\nI couldn't compile your code because of other errors, but for the part that launches threads, you should use lambdas:\n\n```\nstd::thread first([=]() { matrixMultiplyThreaded(a, b, product, 0, dim1, size); });\nstd::thread second([=]() { matrixMultiplyThreaded(a, b, product, dim1, size, size); });\n```\n\n\nAmong other errors, you can't statically allocate arrays (```\na```\n, ```\nb```\n and ```\nproduct```\n) with a variable (which is a dynamic value). Do as follows:\n\n```\ndouble **a = new double*[size];\ndouble **b = new double*[size];\ndouble **product = new double*[size];\nfor (int i = 0; i < size; i++)\n{\n    a[i] = new double[size];\n    b[i] = new double[size];\n    product[i] = new double[size];\n}\n```\n\n\nAnd don't forget to ```\nfree```\n those afterwards, unless you're willing to use shared_ptr or shared_array.\n\nI wouldn't publish two versions of ```\nmatrixMultiply```\n. Delete ```\nmatrixMultiply```\n and use only ```\nmatrixMultiplyThreaded```\n (which should be renamed, then). If you reaaaaally want to expose a ```\nmatrixMultiply```\n without the dim parameters, code in in terms of ```\nmatrixMultiplyThreaded```\n:\n\n```\nstatic void matrixMultiply(double** a, double** b, double** product, int size) {\n    matrixMultiplyThreaded(a, b, product, 0, size, size);\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Python PYMC3 matrix multiplication\r\n                \r\nI have started to learn PYMC3. i am trying to write a simple matrix multiplication using PYMC3. basically would like to learn and understand how the arithmetic operations can be done in PYMC3.\nBelow is my code,\n```\nimport numpy as np\nimport pymc3 as pm \n\n\ndimension_N = 3\nmin = 0\nmax = 100\n\nMatrix_A = np.random.randint(min,max,(dimension_N,dimension_N)).astype(np.uint8)\nMatrix_B = np.random.randint(min,max,(dimension_N,dimension_N)).astype(np.uint8)\nMatrix_C = np.zeros((dimension_N,dimension_N))\n\nwith pm.Model() as model:\n    c = pm.Normal(\"c\", mu=0, sigma=1)\n    a = pm.Normal(\"a\", mu=0, sigma=1, observed=Matrix_A)\n    b = pm.Normal(\"b\", mu=0, sigma=1, observed=Matrix_B)\n    c = a.dot(b)\n\n    gph = pm.fit()\n```\n\nNot sure if this is the correct code.  Can you please help me ? from my observation variable c returns 0.  Can you please tell me what went wrong ?\n    ", "Answer": "\r\nSetting aside that the model here is not clear, we can still answer how matrix multiplication should be done when working with PyMC3 ```\nRandomVariable```\n objects. Namely, RV's in PyMC3 are ```\ntheano.tensor.TensorVaribale```\n objects, and therefore, should use the ```\ntheano.tensor.dot```\n method to matrix multiply them. E.g.,\n```\nimport theano.tensor as tt\n\ntt.dot(a,b)\n```\n\nGenerally, consult the Theano Tensor Functionality documentation for API to do efficient math with PyMC3.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication in C - error values in result matrix\r\n                \r\nSo I coded traditional matrix multiplication in C (I'm a beginner to C), but for some reason my result isn't correct, although I don't see any glaring errors. My input file looks like:\n\n3  2\n2  2\n2  2\n2  2\n2  3\n1  1   1\n1  1   1\n\nThe 3 2 and 2 3 in the first and fifth lines represent the number of rows and columns in the subsequent matrices. The result should be a 3x3 matrix, all 4s. However, this code returns\n\n4197299 4       4\n4       4       4\n-1912599044     32621   572\n\nI'm inclined to believe this might be due to the way I declared the matrices. Instead of using malloc, I scanned the row and column values from the input file and directly instantiated the required matrices. I'm very new to C, so the concept of dynamic memory allocation isn't 100% clear yet. I could be totally off the mark, but I'm not sure. What confuses me especially is that about half of the matrix returned correct values. Why is this the case? Below is my code.\n```\n#include<stdio.h>\n#include<stdlib.h>\n\n\nint main(int argc, char** argv){\n  int i, j, k, row1, col1, row2, col2, temp;\n  if(argc != 2){\n    printf(\"error\\n\");\n    exit(1);\n  }\n\n  FILE *file = fopen(argv[1], \"r\");\n  if(file == NULL){\n    printf(\"error\\n\");\n    exit(1);\n  }\n  //MATRIX 1\n  fscanf(file, \" %d\\t%d\", &row1, &col1);\n  int matrix1[row1][col1];\n\n  for(i = 0; i<row1; i++){\n    for(j=0; j<col1; j++){\n      fscanf(file, \"%d\", &temp);\n      matrix1[i][j] = temp;\n    }\n  }\n  //MATRIX TWO\n  fscanf(file, \" %d\\t%d\", &row2, &col2);\n  int matrix2[row2][col2];\n  int product[row1][col2]; //DECLARING PRODUCT MATRIX\n  for(i = 0; i<row2; i++){\n    for(j=0; j<col2; j++){\n      fscanf(file, \"%d\", &temp);\n      matrix2[i][j] = temp;\n    }\n  }  \n  \n  for(i = 0; i<row1; i++){\n    for(j = 0; j<col2; j++){\n      for(k = 0; k<col1; k++){\n    product[i][j] += matrix1[i][k]*matrix2[k][j]; //MULTIPLICATION STEP\n      }\n    }\n  }\n\n  for(i = 0; i<row1; i++){\n    for(j = 0; j<col2; j++){\n      printf(\"%d\\t\", product[i][j]); //PRINTING THE PRODUCT\n    }\n    printf(\"\\n\");\n  }\n  \n  return 0;\n}\n```\n\n    ", "Answer": "\r\n```\nfor(i = 0; i<row1; i++){\n    for(j = 0; j<col2; j++){\n      product[i][j] = 0; // should be zero before summing\n      for(k = 0; k<col1; k++){\n          product[i][j] += matrix1[i][k]*matrix2[k][j]; //MULTIPLICATION STEP\n      }\n    }\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Multithreading matrix multiplication in C#\r\n                \r\nI have a task - write multithreading matrix multiplication. Each vector product must be calculated in new thread.(If we have matrices n by m and m by k we must have n by k threads). Also I must show order of calculation for elements of result matrix. I wrote code and got strange result - order of calculation is almost sequentially. But I calculate each element in new thread, so I must get random order of calculation for elements of the result matrix. What is wrong? This is my code.\n\n```\nusing System;\nusing System.Threading;\nusing System.Collections.Generic;\n\nnamespace MatrixMultiplication\n{\nclass Matrix\n{\n    public int Row{get; set;}\n    public int Column { get; set;}\n    double[,] arr;\n    Matrix() { }\n    public Matrix(int row,int column)\n    {\n        Row = row;\n        Column = column;\n        arr = new double[row, column];\n    }\n    public double[] GetColumn(int i)\n    {\n        double[] res=new double[Row];\n        for (int j = 0; j < Row; j++)\n            res[j] = arr[j, i];\n        return res;\n    }\n    public double[] GetRow(int i)\n    {\n        double[] res = new double[Column];\n        for (int j = 0; j < Column; j++)\n            res[j] = arr[i, j];\n        return res;\n    }\n    public double this[int i,int j]\n    {\n        get { return arr[i, j]; }\n        set { arr[i, j] = value; }\n    }\n    public Matrix RandomValues()\n    {\n        Random rnd=new Random();\n        for (int i = 0; i < Row; i++)\n            for (int j = 0; j < Column; j++)\n                arr[i, j] =rnd.Next(10);\n        return this;\n    }\n\n    public void Print()\n    {\n        for(int i=0;i<Row;i++){\n            for (int j = 0; j < Column; j++)\n                Console.Write(arr[i,j]+\" \");\n            Console.WriteLine();\n        }\n    }\n\n    public static Matrix operator*(Matrix a, Matrix b)\n    {\n        Matrix result=new Matrix(a.Row,b.Column);\n        List<Thread> threads = new List<Thread>();\n        for (int i = 0; i <a.Row*b.Column;i++ )\n        {\n            int tempi = i; \n            Thread thread = new Thread(()=>VectorMult(tempi, a, b, result));\n            thread.Start();\n            threads.Add(thread);\n        }\n        foreach (Thread t in threads)\n            t.Join();\n        return result;\n    }\n\n    public  static void VectorMult(int tmp, Matrix a, Matrix b,Matrix result){\n        int i = tmp / b.Column;\n        int j = tmp % b.Column;\n        double[] x = a.GetRow(i);\n        double[] y = b.GetColumn(j);\n        for (int k = 0; k < x.Length; k++)\n            result[i, j] += x[k] * y[k];\n        Console.WriteLine(\"Calculate element{0}{1}\", i, j);\n    }\n  }\n\n  class Program\n  {\n     static void Main(string[] args)\n     {\n         int n = int.Parse(Console.ReadLine());\n         int m = int.Parse(Console.ReadLine());\n         int k = int.Parse(Console.ReadLine());\n         Matrix A = new Matrix(n,m).RandomValues();\n         Matrix B = new Matrix(m,k).RandomValues();\n         A.Print();\n         Console.WriteLine(new String('-',20));\n         B.Print();\n         Console.WriteLine(new String('-', 20));\n         Matrix C = A * B;\n         C.Print();\n    }\n  }\n}\n```\n\n    ", "Answer": "\r\nWhat you're describing is normal - see this post from earlier today which demonstrates how processes in separate threads don't always operate in the expected sequence. They might do so much or most of the time, but then you get some unexpected behavior.\n\nDo the calculations need to occur in a specific sequence, or do you just need to be able to see the sequence in which they occurred?\n\nIf you're starting new threads then it's impossible to control the sequence. (You've already seen that.) You also can't capture the order in which they were completed, because completion of a calculation and recording the result (the console or any other output) isn't an atomic operation. \n\nThis could happen:\n\n\nCalculation A finishes\nCalculation B finishes\nCalculation B is recorded\nCalculation A is recorded\n\n\nMultithreading isn't great when operations have to occur in a specific sequence. \n\nYou can insert the results of your calculation into a ```\nConcurrentQueue```\n as they are completed, and the sequence will be mostly correct. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Why matrix multiplication with SSE is slower?\r\n                \r\nI have a matrix class(4x4)\n\n```\nclass matrix {\npublic:\nmatrix() {}\nmatrix(float m11,float m21,float m31,float m41,\n       float m12,float m22,float m32,float m42,\n       float m13,float m23,float m33,float m43,\n       float m14,float m24,float m34,float m44);\nmatrix(const float*);\nmatrix(const matrix&);\n\nmatrix operator *(const matrix& other)const;\n\nstatic const matrix identity;\nprivate:\nunion {\n    float m[16];\n    struct {\n        float m11,m21,m31,m41;\n        float m12,m22,m32,m42;\n        float m13,m23,m33,m43;\n        float m14,m24,m34,m44;\n    };\n    struct {\n        float element[4][4];\n    };\n};\n};\n```\n\n\nbelow is the first implementation of the multiplication operator, \n\n```\nmatrix matrix::operator*(const matrix &other) const{\nreturn matrix(\n    m11*other.m11+m12*other.m21+m13*other.m31+m14*other.m41,\n    m21*other.m11+m22*other.m21+m23*other.m31+m24*other.m41,\n    m31*other.m11+m32*other.m21+m33*other.m31+m34*other.m41,\n    m41*other.m11+m42*other.m21+m43*other.m31+m44*other.m41,\n    m11*other.m12+m12*other.m22+m13*other.m32+m14*other.m42,\n    m21*other.m12+m22*other.m22+m23*other.m32+m24*other.m42,\n    m31*other.m12+m32*other.m22+m33*other.m32+m34*other.m42,\n    m41*other.m12+m42*other.m22+m43*other.m32+m44*other.m42,\n    m11*other.m13+m12*other.m23+m13*other.m33+m14*other.m43,\n    m21*other.m13+m22*other.m23+m23*other.m33+m24*other.m43,\n    m31*other.m13+m32*other.m23+m33*other.m33+m34*other.m43,\n    m41*other.m13+m42*other.m23+m43*other.m33+m44*other.m43,\n    m11*other.m14+m12*other.m24+m13*other.m34+m14*other.m44,\n    m21*other.m14+m22*other.m24+m23*other.m34+m24*other.m44,\n    m31*other.m14+m32*other.m24+m33*other.m34+m34*other.m44,\n    m41*other.m14+m42*other.m24+m43*other.m34+m44*other.m44\n);\n}\n```\n\n\nand i try to use sse instructions to accelerate with the version below,\n\n```\nmatrix matrix::operator*(const matrix &other) const{\nfloat r[4][4];\n__m128 c1=_mm_loadu_ps(&m11);\n__m128 c2=_mm_loadu_ps(&m12);\n__m128 c3=_mm_loadu_ps(&m13);\n__m128 c4=_mm_loadu_ps(&m14);\nfor (int i = 0;i < 4; ++i) {\n    __m128 v1 = _mm_set1_ps(other.element[i][0]);\n    __m128 v2 = _mm_set1_ps(other.element[i][1]);\n    __m128 v3 = _mm_set1_ps(other.element[i][2]);\n    __m128 v4 = _mm_set1_ps(other.element[i][3]);\n\n    __m128 col = _mm_add_ps(\n        _mm_add_ps(_mm_mul_ps(v1,c1),_mm_mul_ps(v2,c2)),\n        _mm_add_ps(_mm_mul_ps(v3,c3),_mm_mul_ps(v4,c4))\n    );\n    _mm_storeu_ps(r[i], col);\n}\nreturn matrix(&r[0][0]);\n}\n```\n\n\nBut on my macbookpro, doing 100000 matrix multiplication costs about 6ms for the first version, and about 8ms for the second version.\ni want to know why this happens.\nPerhaps because of cpu pipeline makes the first version runs concurrent computations and the load/save lags the second version?\n    ", "Answer": "\r\nYou benefit from massive instruction parallelism in the first (scalar) case, when you allow the compiler to optimize the code as it sees best. By arranging the code so as to minimize data dependencies, even though that may result in more total instructions being required, each instruction can be run simultaneously on different execution units. There are lots of registers available, so most of the values can be kept enregistered, minimizing the need for costly memory reads, and even when memory reads are necessary, they can be done nearly for free while other operations are completing, thanks to out-of-order execution scheduling. I would further speculate that you are benefitting from μ-op caching here, the benefit of which is compensating for the increased code size.\n\nIn the second (parallel) case, you're creating significant data dependencies. Even when the compiler emits optimal object code (and this isn't necessarily going to be the case when you use intrinsics), there is a cost involved in forcing this parallelism. You can see that if you ask the compiler to show you an assembly listing. There are tons of ```\nshufps```\n instructions required to pack and reorder the floating-point operands within the SSE registers between operations. That only takes a single cycle on modern Intel architectures*, but the subsequent ```\naddps```\n and ```\nmulps```\n operations cannot execute in parallel. They have to wait for it to complete. Chances are very good that this code is hitting up against a hard μ-op throughput bottleneck. (You may also be paying an unaligned data penalty in this code, but that is minimal on modern architectures.)\n\nIn other words, you've traded parallelism (at the expense of larger code) for increased data dependencies (albeit with smaller code). At least, that would be my semi-educated guess, looking at the disassembly for your example code. In this case, your benchmark tells you very clearly that it did not work out in your favor.\n\nThings might change if you instructed the compiler to assume AVX support. If the target architecture does not support AVX, the compiler has no choice but to transform your ```\n_mm_set1_ps```\n intrinsic into a pair of ```\nmovss```\n, ```\nshufps```\n instructions. If you enable AVX support, you'll get a single ```\nvbroadcastss```\n instruction instead, which may be faster, especially with AVX2 support, where you can broadcast from register-to-register (instead of only from memory-to-register). With AVX support, you also get the benefit of VEX-encoded instructions.\n\n\n\n* Although on certain older architectures like Core 2, ```\nshufps```\n was an integer-based instruction, and therefore resulted in a delay when it was followed by a floating-point instruction like ```\naddps```\n or ```\nmulps```\n. I can't remember when exactly this was fixed, but certainly it is not a problem on Sandy Bridge and later.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Handling matrix multiplication in log space in Python\r\n                \r\nI am implementing a Hidden Markov Model and thus am dealing with very small probabilities. I am handling the underflow by representing variables in log space (so x → log(x)) which has the side effect that multiplication is now replaced by addition and addition is handled via ```\nnumpy.logaddexp```\n or similar.\n\nIs there an easy way to handle matrix multiplication in log space?\n    ", "Answer": "\r\nThis is the best way I could come up with to do it.\n\n```\nfrom scipy.special import logsumexp\ndef log_space_product(A,B):\n    Astack = np.stack([A]*A.shape[0]).transpose(2,1,0)\n    Bstack = np.stack([B]*B.shape[1]).transpose(1,0,2)\n    return logsumexp(Astack+Bstack, axis=0)\n```\n\n\nThe inputs A and B are the logs of the matrices A0 and B0 you want to multiply, and the functions returns the log of A0B0. The idea is that the i,j spot in log(A0B0) is the log of the dot product of the ith row of A0 and the jth column of B0. So it is the logsumexp of the ith row of A plus the jth column of B.\n\nIn the code, Astack is built so the i,j spot is a vector containing the ith row of A, and Bstack is built so the i,j spot is a vector containing the jth column of B. Thus Astack + Bstack is a 3D tensor whose i,j spot is the ith row of A plus the jth column of B. Taking logsumexp with axis = 0 then gives the desired result.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Cuda to make Matrix Multiplication\r\n                \r\nhave a problem making a Matrix Multiplication using cuda. I have to do A*A*A*A and save it in hB. With Cublas it's ok, but I can't make it with CUDA. Dimension can be a high value like 2000. This is my code:\n\n```\n__global__ void CudaMM(float *A, float *B, int N)\n{\n\n    int row = blockIdx.y*blockDim.y + threadIdx.y;\n    int col = blockIdx.x*blockDim.x + threadIdx.x;\n\n    float sum = 0.f;\n    for (int n = 0; n < N; ++n)\n        sum += A[row*N+n]*A[n*N+col];\n\n    B[row*N+col] = sum;\n}\n\nvoid CudaMult(int dimension,float *hMatrice,float *hB,float *d_A,float *d_B){\n    int N,K;\n    K = 100;            \n    N = K*BLOCK_SIZE;\n\n    dim3 threadBlock(BLOCK_SIZE,BLOCK_SIZE);\n    dim3 grid(K,K);\n\n    cudaMemcpy(d_A,hMatrice,dimension*dimension*sizeof(float),cudaMemcpyHostToDevice);\n\nCudaMM<<<grid,threadBlock>>>(d_A,d_B,N);\n\ncudaMemcpy(hB,d_B,dimension*dimension*sizeof(float),cudaMemcpyDeviceToHost);\n\n\n}\n\nvoid CublasFindConnect(int dimension,float* mat,float* B){\n\n\n    float *d_A,*d_B;\n    cudaMalloc(&d_A,dimension*dimension*sizeof(float));\n    cudaMalloc(&d_B,dimension*dimension*sizeof(float));\n\n    int w=0;\n    while(w<5){\n\n        CudaMult(dimension,mat,B,d_A,d_B);\n\n          // Copy Matrix computed B to previous M\n\n            for (m=0; m<dimension; m++) {\n\n                for (n=0; n<dimension; n++) {\n                    mat[m*dimension+n]=B[m*dimension+n];\n                    B[m*dimension+n]=0;\n                }\n            }\n\n     w++;\n    }\n\ncudaFree(d_A);\ncudaFree(d_B);\n\n}\n```\n\n\nI've installed last CUDA 6 that it doesn't require cudaMemCpy, because memory is shared.\n    ", "Answer": "\r\n\nI would suggest you start by doing proper cuda error checking on the code you have shown, and see what results you get.  \nIt will be better if you show a complete code as well.  For example what is ```\nBLOCK_SIZE```\n?  The idea is not to tell me what ```\nBLOCK_SIZE```\n is, but to show a complete code.\nAs an aside, the feature you are referring to in CUDA 6 has specific requirements (such as the use of ```\ncudaMallocManaged()```\n) that you're not meeting, but nevertheless your code is not dependent on Unified Memory, so it's irrelevant.\n\n\nOne problem I can see in your code is that your ```\ndimension```\n variable is arbitrary (you say it can be up to a large number like 2000) but your computation size is fixed at ```\nN=K*BLOCK_SIZE;```\n.  Presumably if your BLOCK_SIZE is some value like 16 or 32, then it will meet your approximate max ```\ndimension```\n size of ~2000.  \n\nThe problem arises because your grid size is potentially larger than your valid array size.  You are launching an ```\nN```\nx```\nN```\n grid, but ```\nN```\n can be larger than ```\ndimension```\n.  This means some of the launched threads can attempt to access the matrices (```\nA```\n and ```\nB```\n) outside of their valid dimensions.\n\nYou can fix this with a \"thread check\" in your kernel, something like this:\n\n```\n__global__ void CudaMM(float *A, float *B, int N)\n{\n\n    int row = blockIdx.y*blockDim.y + threadIdx.y;\n    int col = blockIdx.x*blockDim.x + threadIdx.x;\n\n    if ((row < N) && (col < N)) {\n\n      float sum = 0.f;\n      for (int n = 0; n < N; ++n)\n        sum += A[row*N+n]*A[n*N+col];\n\n      B[row*N+col] = sum;\n    }\n}\n```\n\n\nand you will need to modify your kernel invocation to:\n\n```\nCudaMM<<<grid,threadBlock>>>(d_A,d_B,dimension);\n```\n\n\nYou might also want to consider choosing grid sizes based on your actual ```\ndimension```\n, rather than fixed at ```\n100*BLOCK_SIZE```\n, but that is not essential to get the code to work.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "threaded matrix multiplication function\r\n                \r\nI'm trying to write two matrix multiplication functions, one standard and one that is threaded. However, I can't figure out how to call the threaded function correctly. \n\nHere is the code:\n\n```\n#include <iostream>\n#include <future>\n#include <sys/time.h>\n#include <stdio.h>\n#include <thread>\n\nusing namespace std;\n\ndouble get_wallTime() {\n    struct timeval tp;\n    gettimeofday(&tp, NULL);\n    return (double) (tp.tv_sec + tp.tv_usec/1000000.0);\n}\n\n\n\nstatic void matrixMultiply(double** a, double** b, double** product, int size) {\n\n    for (int i = 0; i < size; i++) {\n       for (int j = 0; j < size; j++) {\n          for (int k = 0; k < size; k++) {\n          product[i][j] += a[i][k] * b[k][j];\n          }\n       }\n    }\n\n\n}\n\nstatic void matrixMultiplyThreaded(double** a, double** b, double** product, int dimLower, int dimUpper, int dim) {\n    for (int i = dimLower; i < dimUpper; i++) {\n        for (int j = 0; j < dim; j++) {\n            for (int k = 0; k < dim; k++) {\n                product[i][j] += a[i][k] * b[k][j];\n            }\n        }\n    }\n}\n\nint main(int argc, char *argv[]) {\n    if (argc < 3) {\n       cout << \"Not enough arguments.\";\n    }\n    int numTimes = atoi(argv[1]);\n    char *threadOrNo = argv[2];\n    int size = atoi(argv[3]);\n    double a[size][size], b[size][size] = {};\n    double product[size][size] = {};\n\n    for (int i=0; i<size; i++) {\n       for (int j=0; j < size; j++) {\n          a[i][j] = 2;\n          b[i][j] = 3;\n       }\n    }\n    double t1 = get_wallTime();\n    if (*threadOrNo == 'y') {\n       int dim1 = size / 2;\n       for (int n = 0; n < numTimes; n++) {\n          std::thread first (matrixMultiplyThreaded, a, b, product, 0, dim1, size);\n\n          std::thread second (matrixMultiplyThreaded, a, b, product, dim1, size, size);\n          first.join();\n          second.join();\n          }\n    }\n    else { \n       for (int m = 0; m < numTimes; m++) {\n\n          matrixMultiply(a[size][size],b[size][size], product[size][size], size);\n    }\n    }\n    double t2 = get_wallTime();\n    double totalTime = t2 - t1;\n    cout << \"time : \" << totalTime;\n\n\n}\n```\n\n\nIf anyone could give any advice I would be eternally grateful. Specifically, what's the right way to implement threads for the threaded function? \n\nHere is the first error message I receive, which I've tried to fix several times:\n\n```\nmultiplyMatrix.cpp: In function 'int main(int, char**)':\nmultiplyMatrix.cpp:64:82: error: no matching function for call to 'std::thread::thread(void (&)(double**, double**, double**, int, int, int), double [size][size], double [size][size], double [size][size], int, int&, int&)'\n           std::thread first (matrixMultiplyThreaded, a, b, product, 0, dim1, size);\n```\n\n    ", "Answer": "\r\nI couldn't compile your code because of other errors, but for the part that launches threads, you should use lambdas:\n\n```\nstd::thread first([=]() { matrixMultiplyThreaded(a, b, product, 0, dim1, size); });\nstd::thread second([=]() { matrixMultiplyThreaded(a, b, product, dim1, size, size); });\n```\n\n\nAmong other errors, you can't statically allocate arrays (```\na```\n, ```\nb```\n and ```\nproduct```\n) with a variable (which is a dynamic value). Do as follows:\n\n```\ndouble **a = new double*[size];\ndouble **b = new double*[size];\ndouble **product = new double*[size];\nfor (int i = 0; i < size; i++)\n{\n    a[i] = new double[size];\n    b[i] = new double[size];\n    product[i] = new double[size];\n}\n```\n\n\nAnd don't forget to ```\nfree```\n those afterwards, unless you're willing to use shared_ptr or shared_array.\n\nI wouldn't publish two versions of ```\nmatrixMultiply```\n. Delete ```\nmatrixMultiply```\n and use only ```\nmatrixMultiplyThreaded```\n (which should be renamed, then). If you reaaaaally want to expose a ```\nmatrixMultiply```\n without the dim parameters, code in in terms of ```\nmatrixMultiplyThreaded```\n:\n\n```\nstatic void matrixMultiply(double** a, double** b, double** product, int size) {\n    matrixMultiplyThreaded(a, b, product, 0, size, size);\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Strassen matrix multiplication implementation\r\n                \r\nI have written the below code for Strassen matrix multiplication. I know it's big but you don't need to go through the whole thing. My problem is that during compile time, the Strassen function with parameters of a[][num],b[][num] and c[][num] doesn't have a fixed value of num. This is where i am going wrong. I need to take the input of num in the main and that is why it cannot be globally given a value. How can i fix this? My code:\n\n```\n#include <stdio.h>\n\nint num;\n\nvoid strassen(int a[][num], int b[][num], int c[][num], int size) {\n\nint p1[size/2][size/2], p2[size/2][size/2], p3[size/2][size/2], p4[size/2][size/2], p5[size/2][size/2], p6[size/2][size/2], p7[size/2][size/2];\n\nint temp1[size/2][size/2], temp2[size/2][size/2];\n\nint q1, q2, q3, q4, q5, q6, q7, i, j;\n\nif(size >= 2) { //give recursive calls\n\n//p1\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp1[i][j] = a[i][j] + a[i + size / 2][j + size / 2];\n\n}\n\n}\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp2[i][j] = b[i][j] + b[i + size / 2][j + size / 2];\n\n}\n\n}\n\nnum = size / 2;\n\nstrassen(temp1, temp2, p1, size / 2);\n\n//p2\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp1[i][j] = a[i + size / 2][j] + a[i + size / 2][j + size / 2];\n\n}\n\n}\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp2[i][j] = b[i][j];\n\n}\n\n}\n\nnum = size / 2;\n\nstrassen(temp1, temp2, p2, size / 2);\n\n//p3\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp1[i][j] = a[i][j];\n\n}\n\n}\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp2[i][j] = b[i][j + size / 2] - b[i + size / 2][j + size / 2];\n\n}\n\n}\n\nnum = size / 2;\n\nstrassen(temp1, temp2, p3, size / 2);\n\n//p4\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp1[i][j] = a[i + size / 2][j + size / 2];\n\n}\n\n}\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp2[i][j] = b[i + size / 2][j] - b[i][j];\n\n}\n\n}\n\nnum = size / 2;\n\nstrassen(temp1, temp2, p4, size / 2);\n\n//p5\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp1[i][j] = a[i][j] + a[i][j + size / 2];\n\n}\n\n}\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp2[i][j] = b[i + size / 2][j + size / 2];\n\n}\n\n}\n\nnum = size / 2;\n\nstrassen(temp1, temp2, p5, size / 2);\n\n//p6\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp1[i][j] = a[i + size / 2][j] - a[i][j];\n\n}\n\n}num = size / 2;\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp2[i][j] = b[i][j] + b[i][j + size / 2];\n\n}\n\n}\n\nnum = size / 2;\n\nstrassen(temp1, temp2, p6, size / 2);\n\n//p7\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp1[i][j] = a[i][j + size / 2] - a[i + size / 2][j + size / 2];\n\n}\n\n}\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\ntemp2[i][j] = b[i + size / 2][j] + b[i + size / 2][j + size / 2];\n\n}\n\n}\n\nnum = size / 2;\n\nstrassen(temp1, temp2, p7, size / 2);\n\n//c11\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\nc[i][j] = p1[i][j] + p4[i][j] - p5[i][j] + p7[i][j];\n\n}\n\n}\n\n//c12\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\nc[i][j + size / 2] = p3[i][j] + p5[i][j];\n\n}\n\n}\n\n//c21\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\nc[i + size / 2][j] = p2[i][j] + p4[i][j];\n\n}\n\n}\n\n//c22\n\nfor(i = 0; i < size / 2; i++) {\n\nfor(j = 0; j < size / 2; j++) {\n\nc[i + size / 2][j + size / 2] = p1[i][j] + p3[i][j] - p2[i][j] + p6[i][j];\n\n}\n\n}\n\n}\n\nelse if(size == 1) {\n\nc[0][0] = a[0][0] * b[0][0];\n\n}\n\n}\n\nint padding(int num) {\n\nint original_num = num, lower_power = 0, i, actual_num = 1;\n\nif(num == 1)\n\nreturn 1;\n\nwhile(num > 1) {\n\nlower_power++;\n\nnum /= 2;\n\n}\n\nfor(i = 0; i < lower_power; i++) {\n\nactual_num *= 2;\n\n}\n\nif(actual_num == original_num)\n\nreturn original_num;\n\nelse\n\nreturn actual_num * 2;\n\n}\n\nint main() {\n\nint i, j, temp;\n\nprintf(\"Enter the size of nxn matrix:\\n\");\n\nscanf(\"%d\", &num);\n\ntemp = num;\n\nif(num <= 0)\n\nreturn 0;\n\nnum = padding(num);\n\nint a[num][num], b[num][num], c[num][num];\n\nprintf(\"Enter matrix a:\\n\");    //accept inputs for a and b from the user\n\nfor(i = 0; i < temp; i++) {\n\nfor(j = 0; j < temp; j++) {\n\nscanf(\"%d\", &a[i][j]);\n\n}\n\nfor(j = temp; j < num; j++) {\n\na[i][j] = 0;\n\n}\n\n}\n\nfor(i = temp; i < num; i++)\n\nfor(j = 0; j < num; j++)\n\na[i][j] = 0;\n\nprintf(\"\\nEnter matrix b:\\n\");\n\nfor(i = 0; i < temp; i++) {\n\nfor(j = 0; j < temp; j++) {\n\nscanf(\"%d\", &b[i][j]);\n\n}\n\nfor(j = temp; j < num; j++) {\n\nb[i][j] = 0;\n\n}\n\n}\n\nfor(i = temp; i < num; i++)\n\nfor(j = 0; j < num; j++)\n\nb[i][j] = 0;\n\nprintf(\"Matrix a:\\n\");  //printing the actual matrices for strassen's multiplication\n\nfor(i = 0; i < num; i++) {\n\nfor(j = 0; j < num; j++) {\n\nprintf(\"%d \", a[i][j]);\n\n}\n\nprintf(\"\\n\");\n\n}\n\nprintf(\"\\nMatrix b:\\n\");\n\nfor(i = 0; i < num; i++) {\n\nfor(j = 0; j < num; j++) {\n\nprintf(\"%d \", b[i][j]);\n\n}\n\nprintf(\"\\n\");\n\n}\n\nstrassen(a, b, c, num);\n\nprintf(\"\\nMatrix c is:\\n\");\n\nfor(i = 0; i < temp; i++) {\n\nfor(j = 0; j < temp; j++) {\n\nprintf(\"%d \", c[i][j]);\n\n}\n\nprintf(\"\\n\");\n\n}\n\nreturn 0;\n\n}\n```\n\n    ", "Answer": "\r\nYou can (perhaps even should) use ```\nint **```\n instead, and pass ```\nnum```\n as an argument. As a simplified example, here is how you might compute the sum of a dynamically sized array:\n\n```\nint sum(int *in, int len) {\n    int out = 0;\n    for(int i = 0; i < len; i++)\n        out += in[i];\n    return out;\n}\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Is there any way to optimize matrix multiplication in C?\r\n                \r\nMy code as follows, and in the main function, I recall ```\nMat_product```\n function about ```\n223440```\n times, use ```\n179ns```\n, ```\n23%```\n in the whole runtime.\n\n```\nstruct Matrix_SE3 {\n    float R[3][3];\n    double P[3];  //here i need use double type.\n};\n\nstruct Matrix_SE3 Mat_product(struct Matrix_SE3 A, struct Matrix_SE3 B) {\n    struct Matrix_SE3 result = { { { 0, 0, 0 }, { 0, 0, 0 }, { 0, 0, 0 } }, { 0,\n            0, 0 } };\n    for (int i = 0; i < 3; i++) {\n        result.P[i] += A.P[i];\n        for (int j = 0; j < 3; j++) {\n            result.P[i] += A.R[i][j] * B.P[j];\n            for (int k = 0; k < 3; k++)\n                result.R[i][j] += A.R[i][k] * B.R[k][j];\n        }\n    }\n    return result;\n}\n```\n\n\nwhere $R$ is the rotation matrix, and $P$ represent the position, the function is calculated at two special euclidean group $SE(3)$ matrix multiplication and return $SE(3)$ matrix.\n\nMaybe this is a duplicate of Optimized matrix multiplication in C, the difference is my code use ```\nstruct```\n to describe matrix, does it affect the efficiency of calculation?\n    ", "Answer": "\r\nNot sure what are the P and R par in your code, but you should never use the ijk ordering for matrix multiplication. \n\nBecause of the row-major ordering, when accessing B.R[k][j] in your inner loop, many accesses will lead to a cache miss, reducing performances significantly, even with your small matrices.\n\nThe proper way to perform matrix multiplication is to iterate in the ikj order.\n\n```\nfor (int i = 0; i < 3; i++) {\n    double r;\n    result.P[i] += A.P[i];\n    for (int k = 0; k < 3; k++) {\n        r=A.R[i][k];\n        for (int j = 0; j < 3; j++) {\n            result.P[i] += A.R[i][j] * B.P[j];  \n            result.R[i][j] += r * B.R[k][j];\n        }\n    }\n}\n```\n\n\nAll accesses will properly be performed in row major order order and will benefit from the cache behavior. \n\nAnd do not forget to use -O3 optimization. Most compilers will use sse/avx instructions to optimize the code. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "MPI row-wise matrix multiplication in C\r\n                \r\nI'm trying to write a program to do row-wise matrix multiplication using MPI's. The program is supposed to only allocate memory for the row-band of the matrix. I'm getting a segmentation fault, and I'm not sure what is causing it. I'm also not very familiar with MPI's. Here is my code so far: \n\n```\n/* process p-1 reads in the matrix n/p rows at a time and sends it to\nthe other processes */\nfloat** read_matrix(char *filename, int p, int id, int *n)\n{ \n  /* open file */\n  FILE *fp = fopen(filename, \"r\");\n  MPI_Status stat;\n\n  /* reads in the dimension of the matrix (n x n); if not square\n     matrix, quit */\n  int dim1, dim2, d;\n  d = fscanf(fp, \"%d\", &dim1);\n  d = fscanf(fp, \"%d\", &dim2);\n  *n = dim1;\n\n  if(dim1 != dim2){\n    printf(\"%s\\n\", \"Error: matrix not square\");\n    exit(0);\n  }\n  if(dim1 % p != 0){\n    printf(\"%s\\n\", \"Error: matrix cannot be divided into processes\");\n  }\nint i;\n\n  /* allocate an array 'storage_mat' of floats of n x (n/p) in size */\n  float **storage_mat = malloc(sizeof(float) * dim1/p);\n\n  for(i = 0; i < dim1/p; i++){\n    storage_mat[i] = malloc(dim1 * sizeof(float));\n  }\n\n\n   if(id == p-1) {\n    for(i=0; i< p; i++) {\n      int j, col;\n      /* read (n/p) rows of the matrix and fill in the array */\n         for(j = 0; j < dim1/p; j++){\n          for(col = 0; col < dim1; col++){\n             d = fscanf(fp, \"%f\", &storage_mat[j][col]);\n            }\n          }\n\n        }\n\n        if(i < p-1){\n           // mpi send the array storage_mat to process rank i \n            MPI_Send(&storage_mat, 1, MPI_FLOAT, i, i, MPI_COMM_WORLD);\n       }\n\n      }\n      else {\n      /* mpi receive the array storage_mat from process rank p-1 */\n         MPI_Recv(&storage_mat, 1, MPI_FLOAT, p-1, 1, MPI_COMM_WORLD, &stat);\n    }\n\n  /* close file */\n  fclose(fp);\n\n    int j;\n    for(j = 0; j < dim1/p; j++){\n      for(i = 0; i < dim1; i++){\n        printf(\"%f \", storage_mat[j][i]);\n      }\n\n}\n\n  return storage_mat;\n\n}\n\n /* process 0 writes out the matrix n/p rows at a time on behalf of all\n    other processes */\n void write_matrix(char* filename, float** storage_mat, int id, int dim1, int p)\n {\n    /* open file */\n    FILE *fp = fopen(filename, \"w\");\n    int j, i;\n    MPI_Status stat;\n\n    if(!id) {\n     for(i=0; i<p; i++) {\n       /* write (n/p) rows of the matrix from the array storage_mat */\n      for(j = 0; j < dim1/p; j++){\n        for(i = 0; i < dim1; i++){\n        fprintf(fp, \"%f \", storage_mat[j][i]);\n      }\n    }\n        if(i < p-1) {\n     /* mpi receive the array storage_mat from process rank i */\n      MPI_Recv(&storage_mat, 1, MPI_FLOAT, i, 1, MPI_COMM_WORLD, &stat);\n      }\n\n   } \n\n } else {\n     /* mpi send the array storage_mat to process rank 0 */\n        MPI_Send(&storage_mat, 1, MPI_FLOAT, 0, i, MPI_COMM_WORLD);\n        }\n\n  /* close file */\n        fclose(fp);\n\n\n }\n\nmain(int argc, char** argv)\n{\n  /* initialize mpi, and find out the rank (id) and the total number\n     of processes (p) */\n  int id, p, n;\n  MPI_Init(&argc, &argv); //initialize mpi\n  MPI_Comm_rank(MPI_COMM_WORLD, &id); // get the rank\n  MPI_Comm_size(MPI_COMM_WORLD, &p); // get num processes\n\n\n  /* parse command line arguments: fileA (the name of the file that\n     contains the matrix A), fileB (the name of the file that contains\n     matrix B), and fileC (the name of the file to store matrix C) */\n  char *fileA, *fileB, *fileC;\n\n  if(argc != 4){\n    printf(\"%s\\n\", \"Error: incorrect number of files\");\n    exit(0);\n  }\n  fileA = argv[1];\n  fileB = argv[2];\n  fileC = argv[3];\n\n  //check if files ae valid\n  FILE *fp1 = fopen(fileA, \"r\");\n  FILE *fp2 = fopen(fileB, \"r\");\n  FILE *fp3 = fopen(fileC, \"r\");\n\n if(fp1 == NULL || fp2 == NULL || fp3 == NULL){\n  printf(\"%s\\n\", \"Error: Not all files accessable\");\n  exit(0);\n\n\n }\n\n  float** storage_matA = read_matrix(fileA, p, id, &n);\n\n  float ** storage_matB = read_matrix(fileB, p, id, &n);\n\n   /* allocate space and intialize to zero for storage_matC as an array\n      of floats of n x (n/p) in size */\n  float **storage_matC = malloc(sizeof(float) * n/p);\n int i;\n  for(i = 0; i < n/p; i++){\n    storage_matC[i] = malloc(n * sizeof(float));\n  }\n\n  // initialize to 0\n  int j;\n    for(j = 0; j < n/p; j++){\n      for(i = 0; i < n; i++){\n        storage_matC[j][i] = 0;\n      }\n    }\n\n   /* create the auxiliary array of pointers so that the elements in A,\n     B and C can be accessed using matA[i][j], etc. */\n   int k;\n   for(i=0; i<p; i++) {\n\n    for(i = 0; i < n/p; i++){\n      for(j = 0; j < n; j++){\n          storage_matC[i][j] += storage_matA[i][j] * storage_matB[i][j];\n      }\n    }\n    /* calculate the partial sum for matC given the row band of A and\n     B (see notes on row-wise matrix multiplication). */\n    MPI_Status stat;\n     if(i < p-1) {\n        /* mpi send storage_matB to the next process (id+1)%p */\n       MPI_Send(&storage_matB, 1, MPI_FLOAT, (id+1)%p, i, MPI_COMM_WORLD);\n       /* mpi receive storage_matB from the previous process */\n       MPI_Recv(&storage_matB, 1, MPI_FLOAT, (id-1)%p, 1, MPI_COMM_WORLD, &stat);\n     }\n }\n\n  write_matrix(fileC, storage_matC, id, n , p);\n\n  /* reclaim matrices, finalize mpi */\n  free(storage_matB);\n  free(storage_matC);\n  free(storage_matA);\n  MPI_Finalize();\n}\n```\n\n    ", "Answer": "\r\n```\nfloat **storage_mat = malloc(sizeof(float) * dim1/p);\n```\n\n\nshould be\n\n```\nfloat **storage_mat = malloc(sizeof(float *) * dim1/p);\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication using SSE intrinsics\r\n                \r\nI am trying to do Matrix multiplication using SSE. I have written a simple program for 4x4 matrices. Everything seems fine but when I print result , its some garbage values. please help to figure out problem/s. Secondly program stops working when I free memory, not a proper end of program.\n\n```\n#include <stdlib.h>\n#include <stdio.h>\n#include <time.h>\n#include <float.h>\n#include <xmmintrin.h>\n\nvoid main() {\n    float **a, **b, **c;\n    int a_r = 4, a_c = 4, b_c = 4, b_r = 4;\n    int i, j, k;\n\n    /* allocate memory for matrix one */\n    a = (float **)malloc(sizeof(float) * a_r);\n    for (i = 0; i < a_c; i++) {\n        a[i] = (float *)malloc(sizeof(float) * a_c);\n    }\n    /* allocate memory for matrix two */\n    b = (float **)malloc(sizeof(float) * b_r);\n    for (i = 0; i < b_c; i++) {\n        b[i] = (float *)malloc(sizeof(float) * b_c);\n    }\n    /* allocate memory for sum matrix */\n    c = (float **)malloc(sizeof(float) * a_r);\n    for (i = 0; i < b_c; i++) {\n        c[i] = (float *)malloc(sizeof(float) * b_c);\n    }\n    printf(\"Initializing matrices...\\n\");\n\n    //initializing first matrix\n    for (i = 0; i < a_r; i++) {\n        for (j = 0; j < a_c; j++) {\n            a[i][j] = 2;\n        }\n    }\n    // initializing second matrix\n    for (i = 0; i < b_r; i++) {\n        for (j = 0; j < b_c; j++) {\n            b[i][j] = 2;\n        }\n    }\n    /* initialize product matrix */\n    for (i = 0; i < a_r; i++) {\n        for (j = 0; j < b_c; j++) {\n            c[i][j] = 0;\n        }\n    }\n\n    int count = 0;\n    /* multiply matrix one and matrix two */\n    for (i = 0; i < a_r; i++) {\n        for (j = 0; j < a_c; j++) {\n            count = 0;\n            __m128 result = _mm_setzero_ps();\n            for (k = 0; k < 4; k += 4) {\n                __m128 row1 = _mm_loadu_ps(&a[i][k]);\n                __m128 row2 = _mm_loadu_ps(&b[k][j]);\n                result = _mm_mul_ps(row1, row2);\n\n                for (int t = 1; t < 4; t++) {\n                    __m128 row3=_mm_loadu_ps(&a[t * 4]);\n                    __m128 row4=_mm_loadu_ps(&b[i][t]);\n                    __m128 row5 = _mm_mul_ps(row3,row4);\n                    result = _mm_add_ps(row5, result);\n                }\n                _mm_storeu_ps(&c[i][j], result);\n            }\n        }\n    }\n    printf(\"******************************************************\\n\");\n    printf (\"Done.\\n\");\n\n    for (i = 0; i < a_r ; i++) {\n        for (j = 0; j < b_c; j++) {\n            printf (\"%f   \", c[i][j]);   // issue here when I print results.\n        }\n        printf(\"\\n\");\n    }     //  Here program stops working.\n\n    /*free memory*/\n    for (i = 0; i < a_r; i++) {\n        free(a[i]);\n    }\n    free(a);\n    for (i = 0; i < a_c; i++) {\n        free(b[i]);\n    }\n    free(b);\n    for (i = 0; i < b_c; i++) {\n        free(c[i]);\n    }\n    free(c);\n}\n```\n\n\nplease have look at address printed for output matrix. how to get aligned addresses, I have ```\n_aligned_malloc```\n, but still not aligned.\n\n\n    ", "Answer": "\r\nThe allocation for the matrix indirect pointers is incorrect. it should read:\n\n```\na = (float **)malloc(sizeof(float*) * a_r);\n```\n\n\nA safer way to write these allocations is this:\n\n```\na = malloc(sizeof(*a) * a_r);\n```\n\n\nNote that you could allocate 2D matrices directly:\n\n```\nfloat (*a)[4][4] = malloc(sizeof(*a));\n```\n\n\nOr better, as Cody Gray suggested:\n\n```\nfloat (*a)[4][4] = _aligned_malloc(sizeof(*a));\n```\n\n\n```\n_aligned_malloc```\n is a non standard function that ensures proper alignment for SSE operands.\n\nIf fact you probably do not even need to allocate these matrices with ```\nmalloc()```\n:\n\n```\nfloat a[4][4];\n```\n\n\nBut with this latter choice, you must ensure proper alignment for the SSE operations to succeed.\n\nThe rest of the code has other problems:\n\n\n```\nvoid main()```\n is incorrect. It should be ```\nint main(void)```\n\nThe second matrix operand should be transposed so you can read multiple values at a time. The second load would become:\n\n```\n__m128 row2 = _mm_loadu_ps(&b[j][k]);\n```\n\nThe summation phase seems incorrect too. And the final store is definitely incorrect, should just be:\n\n```\nc[i][j] = sum;\n```\n\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix is represented as a single array in memory and Problem with matrix multiplication\r\n                \r\nI tried to make the Matrix header file. I also gave it a go at representing the matrix with a single array. Every method I wrote worked just fine. On the contrary, I couldn't figure out the problem with the matrix multiplication.\nIt seems fine though. I have stripped some code to make it small.\nany help is appreciated.\n\n```\n#ifndef MATRIX_HPP\n#define MATRIX_HPP\n\n#include <iostream>\n#include <random>\n#include <chrono>\n#include <ctime>\n#include <iomanip>\nusing std::cout;\nusing std::endl;\nusing std::ios;\n\nstatic std::ostream & pretty_print(std::ostream & output) {\n    output.setf(ios::showpoint);\n    output.setf(ios::showpos);\n    output.width(6);\n    output.precision(2);\n\n    return output;\n}\n\nclass Matrix {\npublic:\n    // Constructor functions\n    Matrix();\n    Matrix(size_t r, size_t c, double v = 0);\n    Matrix(size_t r, size_t c, double *array);\n    Matrix(const Matrix &mat);\n\n    // helping functions\n    void randomize(double a = -1, double b = 1);\n    void addMat(const Matrix &mat);\n    void subMat(const Matrix &mat);\n    void multiply_matrix(const Matrix &mat);\n    Matrix transpose();\n    double* toArray();\n    void display();\n\n    // Static functions\n    static Matrix matMul(const Matrix &mat1, const Matrix &mat2);\n    static Matrix transpose(const Matrix &mat);\n    static Matrix fromArray(double *arr, size_t size);\n\n    // Overloaded operator functions and some friend functions\n    /*friend ostream& operator<<(ostream &dout, Matrix &mat);\n    friend istream& operator>>(istream &din, Matrix &mat);*/\nprivate:\n    size_t rows;\n    size_t cols;\n    double *matrix;\n\n    // Random number engine\n    static uint32_t generate_seed();\n    static double get_random(double a,double b);\n};\n// Private static functions\nuint32_t Matrix::generate_seed() {\n    {\n        std::random_device random;\n        if (random.entropy() > 0.0) {\n            return random();\n        }\n    }\n\n    return std::chrono::high_resolution_clock::now().time_since_epoch().count();\n}\n\n//--------------------------------------------------------------------\n\ndouble Matrix::get_random(double a, double b) {\n    static std::mt19937 random(Matrix::generate_seed());\n    std::uniform_real_distribution<double> double_dist{a, b};\n    return double_dist(random);\n}\n\n//--------------------------------------------------------------------\n\nMatrix::Matrix() {\n    rows = 0;\n    cols = 0;\n    matrix = new double[rows * cols];\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; ++j) {\n            *(matrix + i * cols + j) = 0;\n        }\n    }\n}\n\n//--------------------------------------------------------------------\n\nMatrix::Matrix::Matrix(size_t r, size_t c, double v) {\n    rows = r;\n    cols = c;\n    matrix = new double[rows * cols];\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; ++j) {\n            *(matrix + i * cols + j) = v;\n        }\n    }\n}\n\n//--------------------------------------------------------------------\n\nMatrix::Matrix(size_t r, size_t c, double *array) {\n    rows = r;\n    cols = c;\n    matrix = new double[rows * cols];\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; ++j) {\n            *(matrix + i * cols + j) = *(array + i * cols + j);\n        }\n    }\n}\n\n//----------------------------------------------------------------\n\nMatrix::Matrix(const Matrix &mat) {\n    rows = mat.rows;\n    cols = mat.cols;\n    matrix = new double[rows * cols];\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; ++j) {\n            *(matrix + i * cols + j) = *(mat.matrix + i * rows + cols);\n        }\n    }\n}\n\n//------------------------------------------------------------------\n\nvoid Matrix::randomize(double a, double b) {\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j++) {\n            *(matrix + i * cols + j) = Matrix::get_random(a, b);\n        }\n    }\n}\n\n//-----------------------------------------------------------------------\n\nMatrix Matrix::transpose() {\n    Matrix result(cols, rows);\n    for (size_t i = 0; i < result.rows; i++) {\n        for (size_t j = 0; j < result.cols; j++) {\n            *(result.matrix + i * result.cols + j) = *(matrix + j * cols + i);\n        }\n    }\n\n    return result;\n}\n\n//-----------------------------------------------------------------------\n\nvoid Matrix::display() {\n    cout<<\"[\";\n    for (size_t i = 0; i < rows; i++) {\n        cout<<\"[\";\n        for (size_t j = 0; j < cols; j++) {\n            if (j != cols - 1) {\n                cout<<pretty_print<<*(matrix + i * cols + j)<<\", \";\n            } else if (i != rows - 1 && j == cols - 1) {\n                cout<<pretty_print<<*(matrix + i * cols + j)<<\"],\"<<endl<<\" \";\n            } else if (i == rows - 1 && j == cols - 1) {\n                cout<<pretty_print<<*(matrix + i * cols + j)<<\"]]\"<<endl;\n            }\n        }\n    }\n    cout<<endl;\n}\n\n//-----------------------------------------------------------------------\n\nMatrix Matrix::matMul(const Matrix& mat1, const Matrix& mat2) {\n    if (mat1.cols == mat2.rows) {\n        Matrix result(mat1.rows, mat2.cols);\n\n        double sum; // mat1[i][k] * mat2[k][j];\n        for (size_t i = 0; i < result.rows; i++) {\n            for (size_t j = 0; j < result.cols; j++) {\n                sum = 0;\n                for (size_t k = 0; k < mat1.cols; k++) {\n                    sum += *(mat1.matrix + i * mat1.cols + k) * *(mat2.matrix + k * mat2.cols + j);\n                }\n                *(result.matrix + i * result.cols + j) = sum;\n            }\n        }\n        return result;\n    } else {\n        cout<<\"Matrix multiplication is not possible!\"<<endl;\n        return Matrix();\n    }\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "VBA: Error in code for Matrix Multiplication\r\n                \r\nI am trying to write a general code for matrix multiplication but when I am trying to verify it, the output is always a null matrix. So it seems that the values of the temp matrix are not getting updated. \n\nPlease suggest some changes for it to work. The code is copied below:\n\n```\nPublic Function matrixmultiply(x() As Double, y() As Double) As Double()\n\nDim nrow1 As Integer, nrow2 As Integer, ncol1 As Integer, ncol2 As Integer, i As   Integer, j As Integer, k As Integer, temp() As Double\n\nnrow1 = UBound(x, 1) - LBound(x, 1) + 1\nncol1 = UBound(x, 2) - LBound(x, 2) + 1\n\nnrow2 = UBound(y, 1) - LBound(y, 1) + 1\nncol2 = UBound(y, 2) - LBound(y, 2) + 1\n\nReDim matrixmultiply(1 To nrow1, 1 To ncol2)\nReDim temp(1 To nrow1, 1 To ncol2)\n\nFor i = 1 To nrow1\n    For j = 1 To ncol2\n    d = 2\n        For k = 1 To col1\n            temp(i, j) = temp(i, j) + x(i, k) * y(k, j)\n        Next k\n    Next j\nNext i\n\nmatrixmultiply = temp\n\nEnd Function\n\n\nPrivate Sub CommandButton1_Click()\n\nDim x(1 To 3, 1 To 3) As Double, y(1 To 3, 1 To 3) As Double, z() As Double\nDim i As Integer, j As Integer\n\nFor i = 1 To 3\n    For j = 1 To 3\n        x(i, j) = Cells(i, j).Value\n        y(i, j) = Cells(i, j + 5).Value\n    Next j\nNext i\n\nz = matrixmultiply(x, y)\n\nFor i = 1 To 3\n    For j = 1 To 3\n        Cells(i, j + 12).Value = z(i, j)\n    Next j\nNext i\n\nEnd Sub\n```\n\n    ", "Answer": "\r\nSilly mistake in the line:\n\n```\nFor k = 1 To col1\n```\n\n\nIt should, instead, be \n\n```\nFor k = 1 To ncol1\n```\n\n\nUsing ```\nOption Explicit```\n would have saved a lot of hurt!\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How do you do parallel matrix multiplication in Julia?\r\n                \r\nIs there a good way to do parallel matrix multiplication in julia? I tried using DArrays, but it was significantly slower than just a single-thread multiplication. \n    ", "Answer": "\r\nParallel in what sense? If you mean single-machine, multi-threaded, then Julia does this by default as OpenBLAS (the underlying linear algebra library used) is multithreaded.\n\nIf you mean multiple-machine, distributed-computing-style, then you will be encountering a lot of communications overhead that will only be worth it for very large problems, and a customized approach might be needed.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Hybrid OpenMP/MPI matrix multiplication\r\n                \r\nI would like to do matrix multiplication by traditional way which is block, one MPI task which spawn thread, my problem is how define send and when receive results from OpenMP. if any one can help me will be great even a simple sample will be great.\n    ", "Answer": "\r\nThere are different ways you can approach this problem.  One is to break up the first matrix into groups of rows, and send one group to each rank.  From there, use OpenMP to parallelize the multiplication.  Finally, recombine the results into a single matrix.  Using this approach, you could use MPI_Send to send the groups out to each rank.  Assuming rank 0 has the full matrix, you would use something like:\n\n```\nfloat A[ndim1*ndim2];\nfloat B[ndim2*ndim3];\nfloat C[ndim1*ndim3];\n\nnrows=ndim1/nranks;\n\nfor (int i=1;i++;i<nranks)\n{\n  startrow=nrows*i;\n  nelems=nrows*ndim2;\n  if (i==nranks-1)  // Better ways to do this, but this is a simple example\n  {\n    nelems+=(ndim1%nranks)*ndim2;\n  }\n  MPI_Send[&A[startrow], nelems, MPI_FLOAT, i, 0, MPI_COMM_WORLD);\n}\n```\n\n\nNotice that this starts with rank 1, there's no need to send from rank 0 to itself.  But we'll have rank 0 working on part of the matrix as well.\n\nTo receive in each of the ranks, use\n\n```\nnelems=nrows*ndim2;\nif (myrank==nranks-1)\n{\n  nelems=(ndim1%nranks)*ndim2;\n}\nMPI_Recv(localA, nelems, MPI_FLOAT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n```\n\n\nYou'll just need to copy the first nrows of A into localA directly.  You'll also need to send the entire B array to each rank, as well as needed dimensions (unless these values are already there from other means).\n\nOnce all of the data is in each rank, split the rows using OpenMP to handle one row at a time.\n\n```\n#pragma omp parallel for private(iA,iB,iC)\nfor (int i=0;i<localnrows;i++)\n{\n  for (int j=0;j<ndim3;j++)\n  {\n    for (int k=0;k<ndim2;k++)\n    {\n      iA=i*ndim3+k;\n      iB=k*ndim2+j;\n      iC=i*ndim2+j;\n      localC[iC]=localA[iA]*B[iB];\n    }\n  }\n}\n```\n\n\nThen pass the localC arrays back to rank 0 similarly to how localA was passed, swapping MPI_Send and MPI_Recv.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Tensorflow matrix multiplication is slower than numpy\r\n                \r\n```\nimport tensorflow as tf\nimport numpy as np\nfrom time import time\n\ndef print_timer(func):\n  start_time = time()\n  func()\n  end_time = time()\n  print(end_time - start_time)\n\nN = 4\nA = np.random.randn(N, 1000, 16000)\nB = np.random.randn(N, 16000, 10)\nsess = tf.Session()\n\n\nA_ = tf.constant(A)\nB_ = tf.constant(B)\n\ndef np_test():\n  r = np.empty([N, 1000, 10])\n  for i in range(N):\n    r[i] = np.matmul(A[i], B[i])\n\nprint_timer(lambda: np.matmul(A, B))\nprint_timer(lambda: sess.run(tf.matmul(A,B)))\n```\n\n\nWhen I ran this code, I got the result as below:\n\n```\n1.3403866291046143\n4.291470527648926\n```\n\n\nwhich are the running time.\n\nI don't know why tensorflow.matmul is slower than numpy.matmul.\nI am running this code on the P40 NVIDIA GPU and the tensorflow version I am using is 1.4.\n\nWhen I tried running this code on tensorflow 1.8, I got the same result.\n\nIf tensorflow runs matrix multiplication in parallel, shouldn't the run times for the matrix multiplication on the GPU be much faster than those that are run on numpy, which are run on the CPU?\n    ", "Answer": "\r\nYou have ```\ntf.matmul```\n inside the evaluation, meaning that you are mearuring the time of the creation of the operation together with its computation time.\n\nTry this instead:\n\n```\nimport tensorflow as tf\nimport numpy as np\n\nsess = tf.InteractiveSession()\n\nN = 4\nA = np.random.randn(N, 1000, 16000)\nB = np.random.randn(N, 16000, 10)\nA_ = tf.constant(A)\nB_ = tf.constant(B)\n\nAB_ = A_ @ B_\n\n%timeit np.matmul(A, B)\n%timeit sess.run(AB_)\n```\n\n\nSome remarks:\n\n\nDon't reinvent the wheel, use ```\ntimeit```\n to measure computatio times.\nYou can use ```\n@```\n as a shortcut for matrix multiplication since python 3.5.\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication using assembly on 8051?\r\n                \r\nI am newbie when it comes to assembly and 8051, so I need a little help. I want to make this matrix multiplication. i can't figure out why this goes on a infinite loop i tried my level best to debug but i can't. can any one pin point the error?\nmultiplying matrix A  m by n with matrix B o by p\n\n```\nmov dptr,#8001h\nmov r0,#04h\nmov r1,#03h\n\n;getting values of m,n,o,p saving at 3h,4h,5h,6h registers\nacall load\n\n\n;store matrix A\nmov a,03h\nmov b,04h\nmul ab\nmov r0,a\nmov r1,#10h\nmov dptr,#8100h\nacall load\n\n;store matrix B\nmov a,05h\nmov b,06h\nmul ab\nmov r0,a\nmov r1,#20h\nmov dptr,#8200h\nacall load\n\n;multiply A with B and store it in C\nmov 0dh,#00h\nloop1:\n    mov 0eh,#00h\n    loop2:\n        ;C element location calc\n        mov a,0dh\n        mov b,06h\n        mul ab\n        add a,0eh\n        add a,#30h\n        mov 0ch,a\n        mov r0,a\n        mov @r0,#00h\n\n        ;initilize k\n        mov 0fh,#00h\n        loop3:\n\n            ;A element location calc\n            mov a,0dh\n            mov b,04h\n            mul ab\n            add a,0fh\n            add a,#10h\n            mov 0ah,a\n\n            ;B element location calc\n            mov a,0fh\n            mov b,06h\n            mul ab\n            add a,0eh\n            add a,#20h\n            mov 0bh,a\n\n            ;A*B of elements\n            mov 00h,0ah\n            mov a,@r0\n            mov r1,0bh\n            mov b,@r1\n            mul ab\n\n            ;c+=a*b\n            mov b,a\n            mov r0,0ch\n            mov a,@r0\n            add a,b\n            mov @r0,a\n\n            ;increment k and loop\n            inc 0fh\n            mov a,0fh\n            cjne a,04h,loop3\n\n        ;increment j and loop\n        inc 0eh\n        mov a,0eh\n        cjne a,06h,loop2\n\n    ;increment i and loop\n    inc 0dh\n    mov a,0dh\n    cjne a,03h,loop1\n\n;output MATRIX C\nmov dptr,#8300h\nmov r1,#30h\nmov a,03h\nmov b,06h\nmul ab\nmov r0,a\n\n;output values from ram to memory no of values at r0, address of matrix in r1\nl2:\n    mov a,@r1\n    movx @dptr,a\n    inc r1\n    inc dptr\n    djnz r0,l2\n\nsjmp endd\n;if not equal write 1 at 8000h\n\n\n;loading values from memory to ram no of values at r0, address of ram in r1\nload:\nl1:\n    movx a,@dptr\n    inc dptr\n    mov @r1,a\n    inc r1\n    djnz r0,l1\nret \nendd: \nend\n```\n\n    ", "Answer": "\r\n```\nmov dptr,#8001h ;start taking m,n,o,p\nmov r0,#04h ;loop variable\nmov r1,#03h ;location of ram to save\n\n;getting values of m,n,o,p saving at 3h,4h,5h,6h registers\nacall load ;loading values\n;comparing n,o\nmov a,04h\ncjne a,05h,no\n;if equal write 0 at 8000h \nacall multi\nljmp endd\n;if not equal write 1 at 8000h\nno:\n    mov dptr,#8000h\n    mov a,#01h\n    movx @dptr,a\n    ljmp endd\n\nmulti:  \nmov dptr,#8000h\nmov a,#00h\nmovx @dptr,a    \n\n;store matrix A\nmov a,03h;get m\nmov b,04h;get n\nmul ab;m*n\nmov r0,a;no of elements in A\nmov r1,#10h;ram location for matrix\nmov dptr,#8100h;get matrix\nacall load;call load\n\n;store matrix B\nmov a,05h;get 0\nmov b,06h;get p\nmul ab;0*p\nmov r0,a;no of elements in B\nmov r1,#20h;ram location for matrix\nmov dptr,#8200h;get matrix\nacall load;call load\n\n;multiply A with B and store it in C\nmov 0dh,#00h\nloop1:\n    mov 0eh,#00h\n    loop2:\n        ;C element location calc\n        mov a,0dh\n        mov b,06h\n        mul ab\n        add a,0eh\n        add a,#30h\n        mov 0ch,a\n        mov r0,a\n        mov @r0,#00h\n\n        ;initilize k\n        mov 0fh,#00h\n        loop3:\n\n            ;A element location calc\n            mov a,0dh\n            mov b,04h\n            mul ab\n            add a,0fh\n            add a,#10h\n            mov 0ah,a\n\n            ;B element location calc\n            mov a,0fh\n            mov b,06h\n            mul ab\n            add a,0eh\n            add a,#20h\n            mov 0bh,a\n\n            ;A*B of elements\n            mov 00h,0ah\n            mov a,@r0\n            mov r1,0bh\n            mov b,@r1\n            mul ab\n\n            ;c+=a*b\n            mov b,a\n            mov r0,0ch\n            mov a,@r0\n            add a,b\n            mov @r0,a\n\n            ;increment k and loop\n            inc 0fh\n            mov a,0fh\n            cjne a,04h,loop3\n\n        ;increment j and loop\n        inc 0eh\n        mov a,0eh\n        cjne a,06h,loop2\n\n    ;increment i and loop\n    inc 0dh\n    mov a,0dh\n    cjne a,03h,loop1\n\n;output MATRIX C\nmov dptr,#8300h\nmov r1,#30h\nmov a,03h\nmov b,06h\nmul ab\nmov r0,a\n\n;output values from ram to memory no of values at r0, address of matrix in r1\nl2:\n    mov a,@r1\n    movx @dptr,a\n    inc r1\n    inc dptr\n    djnz r0,l2\n\nret\n\n;loading values from memory to ram no of values at r0, address of ram in r1\nload:\nl1:\n    movx a,@dptr\n    inc dptr\n    mov @r1,a\n    inc r1\n    djnz r0,l1\nret \nendd: \nend\n```\n\n\nfound my mistakes and corrected it here is final result\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "VBA: Error in code for Matrix Multiplication\r\n                \r\nI am trying to write a general code for matrix multiplication but when I am trying to verify it, the output is always a null matrix. So it seems that the values of the temp matrix are not getting updated. \n\nPlease suggest some changes for it to work. The code is copied below:\n\n```\nPublic Function matrixmultiply(x() As Double, y() As Double) As Double()\n\nDim nrow1 As Integer, nrow2 As Integer, ncol1 As Integer, ncol2 As Integer, i As   Integer, j As Integer, k As Integer, temp() As Double\n\nnrow1 = UBound(x, 1) - LBound(x, 1) + 1\nncol1 = UBound(x, 2) - LBound(x, 2) + 1\n\nnrow2 = UBound(y, 1) - LBound(y, 1) + 1\nncol2 = UBound(y, 2) - LBound(y, 2) + 1\n\nReDim matrixmultiply(1 To nrow1, 1 To ncol2)\nReDim temp(1 To nrow1, 1 To ncol2)\n\nFor i = 1 To nrow1\n    For j = 1 To ncol2\n    d = 2\n        For k = 1 To col1\n            temp(i, j) = temp(i, j) + x(i, k) * y(k, j)\n        Next k\n    Next j\nNext i\n\nmatrixmultiply = temp\n\nEnd Function\n\n\nPrivate Sub CommandButton1_Click()\n\nDim x(1 To 3, 1 To 3) As Double, y(1 To 3, 1 To 3) As Double, z() As Double\nDim i As Integer, j As Integer\n\nFor i = 1 To 3\n    For j = 1 To 3\n        x(i, j) = Cells(i, j).Value\n        y(i, j) = Cells(i, j + 5).Value\n    Next j\nNext i\n\nz = matrixmultiply(x, y)\n\nFor i = 1 To 3\n    For j = 1 To 3\n        Cells(i, j + 12).Value = z(i, j)\n    Next j\nNext i\n\nEnd Sub\n```\n\n    ", "Answer": "\r\nSilly mistake in the line:\n\n```\nFor k = 1 To col1\n```\n\n\nIt should, instead, be \n\n```\nFor k = 1 To ncol1\n```\n\n\nUsing ```\nOption Explicit```\n would have saved a lot of hurt!\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "multi threading programming matrix multiplication\r\n                \r\nI am trying to do matrix multiplication 1000*1000using multiple threads. I want to tabulate the number of thread and time taken in C programming language using pthreads. I passing a structure that tells the count of core and thread count to run the loop.\n\n```\n#include<stdio.h>\n#include<stdlib.h>\n#include<pthread.h>\n#include<sys/time.h>\n\n#define n 1000\nint a[n][n];\nint b[n][n];\nint c[n][n];\n//int count=0;\n\nstruct thr{\nint core;\nint num;\n};\nvoid *mult(void *arg)\n{   \n    struct thr th = thr* arg;\n    int i,j,k;\n    for(i=(th.core)*n/(th.num); i<(th.core+1)*n/(th.num); i++)\n        for(j=0; j<n; j++)\n            for(k=0; k<n; k++)\n                c[i][j]+=a[i][k]*b[k][j];\n    return NULL;\n}\nint main()\n{\n    int i,j=0,k,m;\n    int f[50];\n    for(i=0;i<n;i++)\n    {\n        for(k=0; k<n; k++)\n        {\n            a[i][k]=rand()%10;\n            b[i][k]=rand()%10;\n        }\n    }\n    for(i=1;i<1001;i++)\n    {\n        if((1000/i)==0)\n        {\n            f[j]=i;\n            j++;\n        }\n    }\n\n    long int time[j];\n    struct timeval t0, t1,timetaken;\n    for(i=f[k]; k<j; k++)\n    {   \n        pthread_t th[i];\n        //gettimeofday(&t0, NULL);\n        clock_t start=clock();\n        struct thr t;\n        t.core=0;\n        t.num=i;\n        for(j=0; j<i; j++)\n        {\n            t.core++;\n            pthread_create(&th[j],NULL,mult,(thr)&t);\n        }\n        for(j=0;j<i;j++)\n            pthread_join(th[j],NULL);\n        //gettimeofday(&t1,NULL);\n        //timersub(&t1, &t0, &timetaken);\n        clock_t end=clock();\n        for(m=0; m<j; m++)\n            time[m]=end-start;\n    }\n\n    for(i=0;i<j;i++)\n        printf(\"%d threads %ld\\n\",f[i],time[i]);\n\n    printf(\"\\na*b\\n\");\n    for(i=0;i<n;i++)\n    {\n        for(j=0;j<n;j++)\n        {\n            printf(\"%d\\t\",c[i][j]);\n        }\n        printf(\"\\n\");\n    }\n    return 0;\n}\n```\n\n\nIt is showing an error.\n\n```\nmult.c: In function ‘mult’:\nmult.c:18:18: error: ‘thr’ undeclared (first use in this function)\n  struct thr th = thr* arg;\n                  ^~~\nmult.c:18:18: note: each undeclared identifier is reported only once for each function it appears in\nmult.c: In function ‘main’:\nmult.c:60:37: error: ‘thr’ undeclared (first use in this function)\n    pthread_create(&th[j],NULL,mult,(thr)&t);\n```\n\n\nplease help me solve this\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Tensorflow matrix multiplication is slower than numpy\r\n                \r\n```\nimport tensorflow as tf\nimport numpy as np\nfrom time import time\n\ndef print_timer(func):\n  start_time = time()\n  func()\n  end_time = time()\n  print(end_time - start_time)\n\nN = 4\nA = np.random.randn(N, 1000, 16000)\nB = np.random.randn(N, 16000, 10)\nsess = tf.Session()\n\n\nA_ = tf.constant(A)\nB_ = tf.constant(B)\n\ndef np_test():\n  r = np.empty([N, 1000, 10])\n  for i in range(N):\n    r[i] = np.matmul(A[i], B[i])\n\nprint_timer(lambda: np.matmul(A, B))\nprint_timer(lambda: sess.run(tf.matmul(A,B)))\n```\n\n\nWhen I ran this code, I got the result as below:\n\n```\n1.3403866291046143\n4.291470527648926\n```\n\n\nwhich are the running time.\n\nI don't know why tensorflow.matmul is slower than numpy.matmul.\nI am running this code on the P40 NVIDIA GPU and the tensorflow version I am using is 1.4.\n\nWhen I tried running this code on tensorflow 1.8, I got the same result.\n\nIf tensorflow runs matrix multiplication in parallel, shouldn't the run times for the matrix multiplication on the GPU be much faster than those that are run on numpy, which are run on the CPU?\n    ", "Answer": "\r\nYou have ```\ntf.matmul```\n inside the evaluation, meaning that you are mearuring the time of the creation of the operation together with its computation time.\n\nTry this instead:\n\n```\nimport tensorflow as tf\nimport numpy as np\n\nsess = tf.InteractiveSession()\n\nN = 4\nA = np.random.randn(N, 1000, 16000)\nB = np.random.randn(N, 16000, 10)\nA_ = tf.constant(A)\nB_ = tf.constant(B)\n\nAB_ = A_ @ B_\n\n%timeit np.matmul(A, B)\n%timeit sess.run(AB_)\n```\n\n\nSome remarks:\n\n\nDon't reinvent the wheel, use ```\ntimeit```\n to measure computatio times.\nYou can use ```\n@```\n as a shortcut for matrix multiplication since python 3.5.\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Triple pointer as a param - Matrix Multiplication\r\n                \r\nI am working on a Matrix Multiplication problem and I am dynamically allocating arrays\n\nHere is what I currently have:\n\nglobal:\n\n```\nint **a;\n```\n\n\nin my allocatematrix function: (m - row, k - col)\n\n```\n    a = (int **)malloc(m * sizeof(int *));\n    for (i=0; i<m; i++)\n    {\n         a[i] = (int *)malloc(k * sizeof(int));\n    }\n\n    // Note that arr[i][j] is same as *(*(arr+i)+j)\n    // just to test my array allocation is working\n    for (i = 0; i < m; i++)\n    {\n      for (j = 0; j < k; j++)\n      {\n         a[i][j] = ++count;  // OR *(*(arr+i)+j) = ++count\n      }\n    }\n\n\n    for (i = 0; i <  m; i++)\n    {\n      for (j = 0; j < k; j++)\n      {\n         printf(\"%d \", a[i][j]);\n      }\n      printf(\"\\n\");\n    }\n\n    // I would like to pass my pointer to pointer\n    // into a subroutine, such that it transforms the \n    // the global double array, but it keeps blowing up here\n    loadMatrix(fp, &a, m, k);\n```\n\n\nload matrix function:\n\n```\n// read in the file\nvoid loadMatrix(FILE *fp, int ***arr, int size1, int size2)\n{\n    //fp = fopen(name, \"r\");\n    if (fp == NULL)\n    {\n        printf(\"Error while opening file!\\n\");\n        exit(0);\n    }\n\n    int i, j;\n    for(i = 0; i < size1; i++)\n    {\n        for(j = 0; j < size2; j++)\n        {\n            int value = 0;\n            fscanf(fp, \"%d\", &value);\n            printf(\"Current Value: %d\\n\", value);\n            //value =  (((arr + i)) + j);\n            // line below is where I think I have the issue \n            *(*(*(arr+i)+j)) = value;\n        }\n    }\n}\n```\n\n\nsample run: with this line commented ((*(arr+i)+j)) = value;\n\n```\n3 2 3 \n1 2 \n3 4 \n5 6 \nCurrent Value: 1\nCurrent Value: 4\nCurrent Value: 2\nCurrent Value: 5\nCurrent Value: 3\nCurrent Value: 6\n```\n\n\nwith out commented out:\n\n```\n3 2 3 \n1 2 \n3 4 \n5 6 \nCurrent Value: 1\nCurrent Value: 4\nCurrent Value: 2\nSegmentation fault (core dumped)\n```\n\n    ", "Answer": "\r\nYou don't need a ```\nint ***```\n pointer, if you are passing a pointer, the data it points to will be modified by the function, what you can do is this\n\n```\n// read in the file\nvoid loadMatrix(FILE *fp, int **arr, int size1, int size2)\n{\n    if (arr == NULL)\n        return;\n    if (fp == NULL)\n    {\n        printf(\"Error while opening file!\\n\");\n        exit(0);\n    }\n\n    int i, j;\n    for (i = 0 ; i < size1 ; i++)\n    {\n        for (j = 0 ; j < size2 ; j++)\n        {\n            int value = 0;\n            /* test that fscanf() succeeded reading an integer */\n            if (fscanf(fp, \"%d\", &arr[i][j]) != 1)\n                arr[i][j] = 0; /* this just prevents that arr[i][j] be uninitialized */\n        }\n    }\n}\n```\n\n\nWhere you say you test your allocation is working, that doesn't test anything, the only test you can performa is the return value from ```\nmalloc()```\n, if the allocation fails it returns ```\nNULL```\n, so testing that your allocation worked is done like this\n\n```\na = malloc(m * sizeof(int *));\nif (a == NULL)\n    pleaseDoSomethingAboutIt_AllocationFailed_DoNotContinue();\nfor (i = 0 ; i < m ; i++)\n{\n     a[i] = malloc(k * sizeof(int));\n     if (a[i] == NULL)\n     {\n         while (--i)\n             free(a[i]);\n         free(a);\n         pleaseDoSomethingAboutIt_AllocationFailed_DoNotContinue();\n     }\n}\n```\n\n\nIf the allocation fails, and you still dereference the pointer, like in your test, you will invoke undefined behavior, and hence you can't test for anything, because you can't know what is going to happen.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Program error that measures the parameters of matrix multiplication\r\n                \r\nI'm writing a program that measures the performance of matrix multiplication with ```\nrdtsc()```\n, Read Time Stamp Counter.\nHowever, when I combined the matrix multiplication program and performance measurement program, errors appeared.\nI would appreciate if you could let know me how to change my current code for debugging.\nEnvironment: macOS Mojave version 10.14.5, terminal 2.9.5\nWhen I execute the program for matrix multiplication itself, ```\nmatrixmul.c```\n, the compilation succeeds and the output is correct. However, if I add the performance measurement it fails to compile.\nHere's ```\nmatrixmul.c```\n:\n```\n#include<stdio.h>\n\n#define N 3\nint main(int argc, char *argv[])\n{\n    double A[N][N] = {\n        {1.0, 3.0, 1.0},\n        {3.0, 1.0, 3.0},\n        {1.0, 1.0, 1.0}\n    };\n\n    double B[N][N] = {\n        {6.0, 1.0, 0.0},\n        {0.0, 1.0, 6.0},\n        {6.0, 1.0, 1.0}\n    };\n\n    double C[N][N] = {\n        {0.0, 0.0, 0.0},\n        {0.0, 0.0, 0.0},\n        {0.0, 0.0, 0.0}\n    };\n    int i, j, k;\n\n    for(i=0; i<N; i++)\n        for(j=0; j<N; j++)\n            for(k=0; k<N; k++)\n                C[i][j] += A[i][k]*B[k][j];\n\n    for(i=0; i<N; i++)\n        for(j=0; j<N; j++)\n            printf(\"C[%d][%d] = %f\\n\", i, j, C[i][j]);\n}\n```\n\nOutput:\n```\n$ ./matrixmul\nC[0][0] = 6.000000\nC[0][1] = 5.000000\nC[0][2] = 19.000000\nC[1][0] = 18.000000\nC[1][1] = 7.000000\nC[1][2] = 9.000000\nC[2][0] = 6.000000\nC[2][1] = 3.000000\nC[2][2] = 7.000000\n```\n\nHere's ```\nmeasurement.c```\n:\n```\n#include <stdio.h>\n#include \"rdtsc.h\"\n\n#define N 3\nint main(int argc, char *argv[])\n{\n    unsigned long long start = rdtsc();\n\n    double A[N][N] = {\n        {1.0, 3.0, 1.0},\n        {3.0, 1.0, 3.0},\n        {1.0, 1.0, 1.0}\n    };\n\n    double B[N][N] = {\n        {6.0, 1.0, 0.0},\n        {0.0, 1.0, 6.0},\n        {6.0, 1.0, 1.0}\n    };\n\n    double C[N][N] = {\n        {0.0, 0.0, 0.0},\n        {0.0, 0.0, 0.0},\n        {0.0, 0.0, 0.0}\n    };\n    int i, j, k;\n\n    for(i=0; i<N; i++)\n        for(j=0; j<N; j++)\n            for(k=0; k<N; k++)\n                C[i][j] += A[i][k]*B[k][j];\n\n    for(i=0; i<N; i++)\n        for(j=0; j<N; j++)\n            printf(\"C[%d][%d] = %f\\n\", i, j, C[i][j]);\n        \n    unsigned long long stop = rdtsc();\n    printf(\"measured time : %I64d [clock]\\n\", stop - start);\n\n    return 0;\n}\n```\n\nHere's ```\nrdtsc.h```\n (this program is located in the same folder of ```\nmeasurement.c```\n):\n```\n#ifndef RDTSC_H_\n#define RDTSC_H_\n\ninline unsigned long long rdtsc() {\n    unsigned long long ret;\n    __asm__ volatile (\"rdtsc\" : \"=A\" (ret));\n    return ret;\n}\n\n#endif /* RDTSC_H_ */\n```\n\nOutput:\n```\n$ gcc -o measurement measurement.c\nmeasurement.c:38:30: warning: length modifier 'I64' results in undefined\n      behavior or no effect with 'd' conversion specifier [-Wformat]\n    printf(\"measured time : %I64d [clock]\\n\", stop - start);\n                            ~^~~~\n1 warning generated.\nUndefined symbols for architecture x86_64:\n  \"_rdtsc\", referenced from:\n      _main in measurement-510357.o\nld: symbol(s) not found for architecture x86_64\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n```\n\ntrial following the answer\nI have fixed my code and executed it again, but still I had one error.\nerror message\n```\n$ gcc -o measurement measurement.c\nmeasurement.c:38:53: error: use of undeclared identifier 'start'\n    printf(\"measured time : %lld [clock]\\n\", stop - start);\n                                                    ^\n1 error generated.\n```\n\nmeasurement.c\n```\n#include <stdio.h>\n#include \"rdtsc.h\"\n\n#define N 3\nint main(int argc, char *argv[])\n{\n    //unsigned long long start = rdtsc();\n\n    double A[N][N] = {\n        {1.0, 3.0, 1.0},\n        {3.0, 1.0, 3.0},\n        {1.0, 1.0, 1.0}\n    };\n\n    double B[N][N] = {\n        {6.0, 1.0, 0.0},\n        {0.0, 1.0, 6.0},\n        {6.0, 1.0, 1.0}\n    };\n\n    double C[N][N] = {\n        {0.0, 0.0, 0.0},\n        {0.0, 0.0, 0.0},\n        {0.0, 0.0, 0.0}\n    };\n    int i, j, k;\n\n    for(i=0; i<N; i++)\n        for(j=0; j<N; j++)\n            for(k=0; k<N; k++)\n                C[i][j] += A[i][k]*B[k][j];\n\n    for(i=0; i<N; i++)\n        for(j=0; j<N; j++)\n            printf(\"C[%d][%d] = %f\\n\", i, j, C[i][j]);\n        \n    unsigned long long stop = rdtsc();\n    printf(\"measured time : %lld [clock]\\n\", stop - start);\n\n    return 0;\n}\n```\n\nrdtsc.h\n```\n#ifndef RDTSC_H_\n#define RDTSC_H_\n\nunsigned long long rdtsc() {\n    unsigned long long ret;\n    __asm__ volatile (\"rdtsc\" : \"=A\" (ret));\n    return ret;\n}\n\n#endif /* RDTSC_H_ */\n```\n\n    ", "Answer": "\r\nThere's really no need to make the ```\nrdtsc```\n function ```\ninline```\n, it only confuses the compiler about whether or not to export the function. Just remove it or add ```\nextern```\n before it to explicitly tell the compiler to export the function. This will work:\n\n```\n#ifndef RDTSC_H_\n#define RDTSC_H_\n\nunsigned long long rdtsc() {\n    unsigned long long ret;\n    __asm__ volatile (\"rdtsc\" : \"=A\" (ret));\n    return ret;\n}\n\n#endif /* RDTSC_H_ */\n```\n\n\nAlso, as ```\nclang```\n says, ```\n%I64d```\n is an invalid format modifier. Use ```\n%lld```\n instead for ```\nlong long int```\n.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Plotting a matrix multiplication\r\n                \r\nI am trying to plot a matrix multiplication as a function of time and run into a problem of not being able to include the original state into the plot (where ```\nn = c(100,1000,50)```\n ).\n\nI tried searching for a solution in other SO posts, but could only find the next function, which, I think, is not good because if I write it into the ```\nif (time ==1){}```\n section, it skipps the original state just the same. Eventually, I came up with this, which does not work either:\n\n```\nn = c(100,1000,50) #original state\nG = matrix(c(0.6,0.4,0,0.005,0.9,0.1,0,0,0.5),3,3) \n\npopulation = function(time = 100){\n  x = seq(0,100,1)\n  plot(x = seq(0,100,1),y = seq(0,1000,10), col=\"white\", xlab = \"time\", ylab = \"sample\")\n  if(time == 1){\n    points(x[1],n[1], col = \"red\") \n    points(x[1],n[2], col = \"blue\")\n    points(x[1],n[3], col = \"black\")\n  }\n  for(i in 1:(time-1)){\n    n = G%*%n\n    print(n)\n    points(x[i],n[1], col = \"red\") \n    points(x[i],n[2], col = \"blue\")\n    points(x[i],n[3], col = \"black\")\n\n  }\n  return(n)\n\n} \n\npopulation(100)\n```\n\n\nAny hints would be much appreciated.\n    ", "Answer": "\r\nI'd rather use the function ```\nmatplot```\n because it's easier to really control what it actually produces. Also, the code becomes much clearer.\n\n```\nN <- matrix(NA, 3, 100)\nN[, 1] <- c(100, 1000, 50)\nG <- matrix(c(0.6, 0.4, 0, 0.005, \n              0.9, 0.1, 0, 0, 0.5), 3, 3) \nfor (i in 2:ncol(N)) {\n  N[,i] <- G %*% N[, i-1]\n}\nmatplot(x=0:99, t(N), type = \"p\", pch=1,\n        xlab = \"time\", ylab = \"N\")\n```\n\n\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to further optimize performance of Matrix Multiplication?\r\n                \r\nI am trying to optimize my matrix multiplication code running on a single core. How can I futher improve the performance in regards to loop unrolling, FMA/SSE? I'm also curious to know why the performance won't increase if you use four instead of two sums in the inner loop.\n\nThe problem size is a 1000x1000 matrix multiplication. Both gcc 9 and icc 19.0.5 are available. Intel Xeon @ 3.10GHz, 32K L1d Cache, Skylake Architecture. Compiled with ```\ngcc -O3 -mavx```\n.\n\n```\nvoid mmult(double* A, double* B, double* C)\n{\n    const int block_size = 64 / sizeof(double);\n\n    __m256d sum[2], broadcast;\n\n    for (int i0 = 0; i0 < SIZE_M; i0 += block_size) {\n    for (int k0 = 0; k0 < SIZE_N; k0 += block_size) {\n    for (int j0 = 0; j0 < SIZE_K; j0 += block_size) {\n\n        int imax = i0 + block_size > SIZE_M ? SIZE_M : i0 + block_size;\n        int kmax = k0 + block_size > SIZE_N ? SIZE_N : k0 + block_size;\n        int jmax = j0 + block_size > SIZE_K ? SIZE_K : j0 + block_size;\n\n        for (int i1 = i0; i1 < imax; i1++) {\n\n            for (int k1 = k0; k1 < kmax; k1++) {\n\n                broadcast = _mm256_broadcast_sd(A+i1*SIZE_N+k1);\n                for (int j1 = j0; j1 < jmax; j1+=8) {\n                    sum[0] = _mm256_load_pd(C+i1*SIZE_K+j1+0);\n                    sum[0] = _mm256_add_pd(sum[0], _mm256_mul_pd(broadcast, _mm256_load_pd(B+k1*SIZE_K+j1+0)));\n                    _mm256_store_pd(C+i1*SIZE_K+j1+0, sum[0]);\n\n                    sum[1] = _mm256_load_pd(C+i1*SIZE_K+j1+4);\n                    sum[1] = _mm256_add_pd(sum[1], _mm256_mul_pd(broadcast, _mm256_load_pd(B+k1*SIZE_K+j1+4)));\n                    _mm256_store_pd(C+i1*SIZE_K+j1+4, sum[1]);\n\n                    // doesn't improve performance.. why?\n                    // sum[2] = _mm256_load_pd(C+i1*SIZE_K+j1+8);\n                    // sum[2] = _mm256_add_pd(sum[2], _mm256_mul_pd(broadcast, _mm256_load_pd(B+k1*SIZE_K+j1+8)));\n                    // _mm256_store_pd(C+i1*SIZE_K+j1+8, sum[2]);\n\n                    // sum[3] = _mm256_load_pd(C+i1*SIZE_K+j1+12);\n                    // sum[3] = _mm256_add_pd(sum[3], _mm256_mul_pd(broadcast, _mm256_load_pd(B+k1*SIZE_K+j1+12)));\n                    // _mm256_store_pd(C+i1*SIZE_K+j1+4, sum[3]);\n                }\n            }\n        }\n    }\n    }\n    }\n}\n```\n\n    ", "Answer": "\r\nThis code has 2 loads per FMA (if FMA-contraction happens), but Skylake only supports at most one load per FMA in theory (if you want to max out 2/clock FMA throughput), and even that is usually too much in practice.  (Peak through is 2 loads + 1 store per clock, but it usually can't quite sustain that).  See Intel's optimization guide and https://agner.org/optimize/\n\nThe loop overhead is not the biggest problem, the body itself forces the code to run at half speed.\n\nIf the ```\nk```\n-loop was the inner loop, a lot of accumulation could be chained, without having to load/store to and from ```\nC```\n. This has a downside: with a loop-carried dependency chain like that, it would be up to to code to explicitly ensure that there is enough independent work to be done.\n\nIn order to have few loads but enough independent work, the body of the inner loop could calculate the product between a small column vector from ```\nA```\n and a small row vector from ```\nB```\n, for example using 4 scalar broadcasts to load the column and 2 normal vector loads from ```\nB```\n, resulting in just 6 loads for 8 independent FMAs (even lower ratios are possible), which is enough independent FMAs to keep Skylake happy and not too many loads. Even a 3x4 footprint is possible, which also has enough independent FMAs to keep Haswell happy (it needs at least 10).\n\nI happen to have some example code, it's for single precision and C++ but you'll get the point:\n\n```\nsumA_1 = _mm256_load_ps(&result[i * N + j]);\nsumB_1 = _mm256_load_ps(&result[i * N + j + 8]);\nsumA_2 = _mm256_load_ps(&result[(i + 1) * N + j]);\nsumB_2 = _mm256_load_ps(&result[(i + 1) * N + j + 8]);\nsumA_3 = _mm256_load_ps(&result[(i + 2) * N + j]);\nsumB_3 = _mm256_load_ps(&result[(i + 2) * N + j + 8]);\nsumA_4 = _mm256_load_ps(&result[(i + 3) * N + j]);\nsumB_4 = _mm256_load_ps(&result[(i + 3) * N + j + 8]);\n\nfor (size_t k = kk; k < kk + akb; k++) {\n    auto bc_mat1_1 = _mm256_set1_ps(*mat1ptr);\n    auto vecA_mat2 = _mm256_load_ps(mat2 + m2idx);\n    auto vecB_mat2 = _mm256_load_ps(mat2 + m2idx + 8);\n    sumA_1 = _mm256_fmadd_ps(bc_mat1_1, vecA_mat2, sumA_1);\n    sumB_1 = _mm256_fmadd_ps(bc_mat1_1, vecB_mat2, sumB_1);\n    auto bc_mat1_2 = _mm256_set1_ps(mat1ptr[N]);\n    sumA_2 = _mm256_fmadd_ps(bc_mat1_2, vecA_mat2, sumA_2);\n    sumB_2 = _mm256_fmadd_ps(bc_mat1_2, vecB_mat2, sumB_2);\n    auto bc_mat1_3 = _mm256_set1_ps(mat1ptr[N * 2]);\n    sumA_3 = _mm256_fmadd_ps(bc_mat1_3, vecA_mat2, sumA_3);\n    sumB_3 = _mm256_fmadd_ps(bc_mat1_3, vecB_mat2, sumB_3);\n    auto bc_mat1_4 = _mm256_set1_ps(mat1ptr[N * 3]);\n    sumA_4 = _mm256_fmadd_ps(bc_mat1_4, vecA_mat2, sumA_4);\n    sumB_4 = _mm256_fmadd_ps(bc_mat1_4, vecB_mat2, sumB_4);\n    m2idx += 16;\n    mat1ptr++;\n}\n_mm256_store_ps(&result[i * N + j], sumA_1);\n_mm256_store_ps(&result[i * N + j + 8], sumB_1);\n_mm256_store_ps(&result[(i + 1) * N + j], sumA_2);\n_mm256_store_ps(&result[(i + 1) * N + j + 8], sumB_2);\n_mm256_store_ps(&result[(i + 2) * N + j], sumA_3);\n_mm256_store_ps(&result[(i + 2) * N + j + 8], sumB_3);\n_mm256_store_ps(&result[(i + 3) * N + j], sumA_4);\n_mm256_store_ps(&result[(i + 3) * N + j + 8], sumB_4);\n```\n\n\nThis means that the ```\nj```\n-loop and the ```\ni```\n-loop are unrolled, but not the ```\nk```\n-loop, even though it is the inner loop now. Unrolling the ```\nk```\n-loop a bit did help a bit in my experiments.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Pandas Dataframe Matrix Multiplication using @\r\n                \r\nI am attempting to perform matrix multiplication between a Pandas DataFrame and a Pandas Series. I've set them up like so:\n```\nc = pd.DataFrame({\n    \"s1\":[.04, .018, .0064],\n    \"s2\":[.018, .0225, .0084],\n    \"s3\":[.0064, .0084, .0064],\n    })\nx = pd.Series([0,0,0], copy = False)\n```\n\nI want to perform ```\nx @ c @ x```\n, but I keep getting a ```\nValueError: matrices are not aligned```\n error flag. Am I not setting up my matrices properly? I'm not sure where I am going wrong.\n    ", "Answer": "\r\n```\nx @ c```\n returns a Series object which has different indices as ```\nx```\n. You can use the underlying numpy array to do the calculation:\n```\n(x @ c).values @ x.values\n# 0.39880000000000004\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Is matrix multiplication speed faster for sparse matrixes than dense matrixes? [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                \r\n                    \r\n                            \r\n                                Closed. This question is opinion-based. It is not currently accepting answers.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n        \r\n            \r\n        \r\n            \r\n                \r\n                        \r\n                            \r\n                        \r\n                    Want to improve this question? Update the question so it can be answered with facts and citations by editing this post.\r\n                \r\n                    \r\n                        Closed 3 years ago.\r\n                    \r\n                \r\n\r\n                \r\n            \r\n        \r\n            \r\n                    \r\n                        Improve this question\r\n                    \r\n            \r\n\r\n\r\n    \r\n\r\nIs matrix multiplication speed faster for sparse matrixes than dense matrixes? \nTo give a simplified example, \ndoes \n\"[[0,0],[0,0]] multiplies [[1,1],[1,1]]\" \nfaster than \n\"[[256,256],[256,256]] multiplies [[1,1],[1,1]]\" ?\n    ", "Answer": "\r\nThe machine code algorithm to do a multiplication goes like this:\n\n```\nint mul(int a,int b)\n {\n    int result = 0;\n    bit sign = sign(a) ^ sign(b);\n    a = abs(a); b = abs(b);\n\n    while (b != 0)\n     {\n        b = b>>1; // shift b right, bit0 into carry\n        if (carrySet()) result += a;\n        a = a<<1; // shift a left\n        // note: checks for overflow being left out\n     }\n    return (sign==0 ? sum : -sum);\n }\n```\n\n\nYou'll easily see that the more bits are set in the right operand, the more computations are necessary to sum up the left operand.\nSo, provided that your matrix multiplication boils down to machine code multiplications like this, a sparse matrix will multiply significantly faster than a dense matrix.\n\nThe question I cannot answer here is if the ```\nFPU```\n will do this in a more efficient manner. You'll want to read some specs here. But even if a FPU (or GPU) is doing some sort of tweaking, I doubt the basic multiplication grinding loop looks very much different (interested in comments about this.)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Parallelized Matrix Multiplication\r\n                \r\nI am trying to parallelize the multiplication of two matrix ```\nA```\n,```\nB```\n.\nUnfortunately the serial implementation is still faster than the parallel one or the speedup is too low. (with matrix dimension = 512 the speedup is like ```\n1.3```\n). Probably something is fundamentally wrong. Can someone out there give me a tip?\n```\ndouble[][] matParallel2(final double[][] matrixA,\n                        final double[][] matrixB,\n                        final boolean parallel) {\n    int rows = matrixA.length;\n    int columnsA = matrixA[0].length;\n    int columnsB = matrixB[0].length;\n\n    Runnable task;\n    List<Thread> pool = new ArrayList<>();\n\n    double[][] returnMatrix = new double[rows][columnsB];\n    for (int i = 0; i < rows; i++) {\n        int finalI = i;\n        task = () -> {\n            for (int j = 0; j < columnsB; j++) {\n                //  returnMatrix[finalI][j] = 0;\n                for (int k = 0; k < columnsA; k++) {\n                    returnMatrix[finalI][j] +=\n                            matrixA[finalI][k] * matrixB[k][j];\n                }\n            }\n        };\n        pool.add(new Thread(task));\n    }\n    if (parallel) {\n        for (Thread trd : pool) {\n            trd.start();\n        }\n    } else {\n        for (Thread trd : pool) {\n            trd.run();\n        }\n    }\n    try {\n        for (Thread trd : pool) {\n            trd.join();\n        }\n    } catch (\n            Exception e) {\n        e.printStackTrace();\n    }\n    return returnMatrix;\n}\n```\n\n    ", "Answer": "\r\nThere's nothing fundamentally wrong.\nCreating a thread means a huge overhead, compared to a few multiplications. Currently, for 512*512 matrices, you create 512 threads. Your CPU surely has less than 512 cores, so only e.g. 8 or 16 of them will really run in parallel on different cores, but the ~500 others also consumed the creation overhead without increasing parallel execution.\nTry to limit the number of threads to something closer to the number of CPU cores, either with your own logic, or by using a framework, e.g. the java.util.concurrent package.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "understanding Matrix multiplication in CUDA\r\n                \r\nI am trying to learn CUDA. I started to try matrix multiplication with the help of this article based on GPU.\nMy main problem is that I am unable too understand how to access 2D array in Kernel since accessing a 2D array is a bit different than the conventional method (matrix[i][j]).\nThis is the part where i am stuck:\n\n```\nfor (int i = 0; i < N; i++) {\n    tmpSum += A[ROW * N + i] * B[i * N + COL];\n}\nC[ROW * N + COL] = tmpSum;\n```\n\n\nI could understand how ROW and COLUMN were derived.\n\n```\nint ROW = blockIdx.y*blockDim.y+threadIdx.y;\nint COL = blockIdx.x*blockDim.x+threadIdx.x;\n```\n\n\nAny explanation with an example is highly appreciated. Thanks!\n    ", "Answer": "\r\nMatrices are stored contiguously, i.e. every row after the other at consecutive locations. What you see here is called flat adressing, i.e turning the two element index to an offset from the first element. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Fast LAPACK/BLAS for matrix multiplication\r\n                \r\nI'm exploring the Armadillo C++ library for linear algebra at the moment. As far as I understood it uses LAPACK/BLAS library for basic matrix operations (e.g. matrix multiplication). As a Windows user I downloaded LAPACK/BLAS from here: http://icl.cs.utk.edu/lapack-for-windows/lapack/#running. The problem is that matrix multiplications are very slow comparing to Matlab or even R. For example, Matlab multiplies two 1000x1000 matrices in ~0.15 seconds on my computer, R needs ~1 second, while C++/Armadillo/LAPACK/BLAS needs more than 10 seconds for that. \n\nSo, Matlab is based on highly optimized libraries for linear algebra. My question is if there exists a faster LAPACK/BLAS brary to use from Armadillo? Alternatively, is there a way to extract Matlab linear algebra libraries somehow and use them in C++?\n    ", "Answer": "\r\nLAPACK doesn't do matrix multiplication. It's BLAS that provides matrix multiplication.\n\nIf you have a 64 bit operating system, I recommend to first try a 64 bit version of BLAS.  This will get you an immediate doubling of performance.\n\nSecondly, have a look at a high-performance implementation of BLAS, such as OpenBLAS.  OpenBLAS uses both vectorisation and parallelisation (ie. multi-core). It is a free (no cost) open source project.\n\nMatlab internally uses the Intel MKL library, which you can also use with the Armadillo library.  Intel MKL is closed source, but is free for non-commercial use. Note that OpenBLAS can obtain matrix multiplication performance that is on par or better than Intel MKL.\n\nNote that high performance linear algebra is generally easier to accomplish on Linux and Mac OS X than on Windows.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Batch sparse matrix multiplication in Tensorflow\r\n                \r\nIs there a way to perform batch sparse matrix multiplication in Tensorflow? These are the shapes I am trying to multiply:\n\n[ n , m , i , j ] x [ n , m , j , k ] = [ n , m , i , k ]\n\nSo, there is a batch component in both sides, and each 2D inner matrix pair should be multiplied accordingly. Is there a way with the currently implemented functions?\n\nThanks. \n    ", "Answer": "\r\nYou didn't mention if you tried anything so I'll just post this now.\n\nFrom the tensorflow documentation, tf.matmul supports batched \nmultiplication.\n\n```\nmatmul(\na,\nb,\ntranspose_a=False,\ntranspose_b=False,\nadjoint_a=False,\nadjoint_b=False,\na_is_sparse=False,\nb_is_sparse=False,\nname=None\n)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "OpenCV - Directly copying matrix multiplication result to a subset of another matrix\r\n                \r\nI try to directly copying matrix multiplication result to a subset of another matrix:\n\n```\ncv::Mat a,b,c;\n//fill matrices a and b and set matrix c to correct size\ncv::Mat ab=a*b;\nab.copyTo(c(cv::Rect(0,0,3,3)));\n```\n\n\nisn' it possible to directly copy the result to matrix c like e.g. (I know this doesn't work):\n\n```\n(a*b).copyTo(c(cv::Rect(0,0,3,3)));\n//or \nc(cv::Rect(0,0,3,3)).setTo(a*b);\n```\n\n\nWouldn't it be more efficient?\n    ", "Answer": "\r\nTry this:  \n\n```\ncv::Mat subC = c(cv::Rect(0,0,3,3));\nsubC = a*b;\n```\n\n\nNo copying here.\n\nOr more succinctly:\n\n```\nc(cv::Rect(0,0,3,3)) = a*b;\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "CUDA Matrix Multiplication: Outputting Zero\r\n                \r\nTrying to run a program to do Matrix Multiplication in CUDA. I think I have everything set up correctly and the program runs and executes. Problem is the output. Anyone see whats wrong with my code? Appearently the output matrix has a value of 0 no matter what the inputs are. I think the issue is that i have to convert from using int Width as a parameter in the Kernal function to using the number of rows/columns instead. I didnt think would/should be a problem but something is going wrong... Thanks for the help!\n\n```\n#define TILE_WIDTH 16\n\n// Compute C = A * B\n__global__ void matrixMultiply(float * A, float * B, float * C,\n               int numARows, int numAColumns,\n               int numBRows, int numBColumns,\n               int numCRows, int numCColumns) \n{\n    //@@ Insert code to implement matrix multiplication here\n    float Cvalue = 0.0;\n    int Row = blockIdx.y * blockDim.y + threadIdx.y;\n    int Col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if ((Row < numCRows) && (Col < numCColumns)) \n    {       \n        float Pvalue = 0;\n        for (int k = 0; k < numCRows; ++k) Pvalue += A[Row*numCColumns+k] * B[k*numCRows+Col];\n        C[Row*numCRows+Col] = Cvalue;\n    }\n\n}\n\nint main(int argc, char ** argv) {\nwbArg_t args;\nfloat * hostA; // The A matrix\nfloat * hostB; // The B matrix\nfloat * hostC; // The output C matrix\nfloat * deviceA;\nfloat * deviceB;\nfloat * deviceC;\nint numARows; // number of rows in the matrix A\nint numAColumns; // number of columns in the matrix A\nint numBRows; // number of rows in the matrix B\nint numBColumns; // number of columns in the matrix B\nint numCRows; // number of rows in the matrix C (you have to set this)\nint numCColumns; // number of columns in the matrix C (you have to set this)\n\nargs = wbArg_read(argc, argv);\nwbTime_start(Generic, \"Importing data and creating memory on host\");\nhostA = (float *) wbImport(wbArg_getInputFile(args, 0), &numARows, &numAColumns);\nhostB = (float *) wbImport(wbArg_getInputFile(args, 1), &numBRows, &numBColumns);\n//@@ Set numCRows and numCColumns\nnumCRows = numBRows;\nnumCColumns = numAColumns;  \nint sizeA = numARows * numAColumns * sizeof(float);\nint sizeB = numBRows * numBColumns * sizeof(float);\nint sizeC = numCRows * numCColumns * sizeof(float);\n//@@ Allocate the hostC matrix\nhostC = (float *) malloc(sizeC);\nwbTime_stop(Generic, \"Importing data and creating memory on host\");\n\nwbLog(TRACE, \"The dimensions of A are \", numARows, \" x \", numAColumns);\nwbLog(TRACE, \"The dimensions of B are \", numBRows, \" x \", numBColumns);\n\nwbTime_start(GPU, \"Allocating GPU memory.\");\n//@@ Allocate GPU memory here\ncudaMalloc((void **) &deviceA, sizeA);      \ncudaMalloc((void **) &deviceB, sizeB);\ncudaMalloc((void **) &deviceC, sizeC);\nwbTime_stop(GPU, \"Allocating GPU memory.\");\n\nwbTime_start(GPU, \"Copying input memory to the GPU.\");\n//@@ Copy memory to the GPU here\ncudaMemcpy(deviceA, hostA, sizeA, cudaMemcpyHostToDevice);\ncudaMemcpy(deviceB, hostB, sizeB, cudaMemcpyHostToDevice);\nwbTime_stop(GPU, \"Copying input memory to the GPU.\");\n\n//@@ Initialize the grid and block dimensions here\ndim3 dimGrid(numCRows/TILE_WIDTH, numCColumns/TILE_sWIDTH, 1);\ndim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);\n\nwbTime_start(Compute, \"Performing CUDA computation\");\n//@@ Launch the GPU Kernel here\nmatrixMultiply<<<dimGrid,dimBlock>>>(deviceA, deviceB, deviceC,\n                                        numARows, numAColumns,\n                                        numBRows, numBColumns,\n                                        numCRows, numCColumns);\ncudaThreadSynchronize();\nwbTime_stop(Compute, \"Performing CUDA computation\");\n\nwbTime_start(Copy, \"Copying output memory to the CPU\");\n//@@ Copy the GPU memory back to the CPU here      \ncudaMemcpy(hostC, deviceC, sizeC, cudaMemcpyDeviceToHost);\nwbTime_stop(Copy, \"Copying output memory to the CPU\");\n\nwbTime_start(GPU, \"Freeing GPU Memory\");\n//@@ Free the GPU memory here    \ncudaFree(deviceA);\ncudaFree(deviceB);\ncudaFree(deviceC);\nwbTime_stop(GPU, \"Freeing GPU Memory\");\n\nwbSolution(args, hostC, numCRows, numCColumns);\n\nfree(hostA);\nfree(hostB);\nfree(hostC);\n\nreturn 0;\n}\n```\n\n    ", "Answer": "\r\nOkay so the reason it was returning zero was because my results were never being saved into my output matrix cause my code has saving in a unused, but initialized, value over and over again through the loop. Also i screwed up the numCRows and numCColumns values but that was more readily identifiably after my code started to actually run. \n\n```\n__global__ void matrixMultiply(float * A, float * B, float * C,\n               int numARows, int numAColumns,\n               int numBRows, int numBColumns,\n               int numCRows, int numCColumns) \n{\n    //@@ Insert code to implement matrix multiplication here\n    int Row = blockIdx.y * blockDim.y + threadIdx.y;\n    int Col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if ((Row < numCRows) && (Col < numCColumns)) \n    {       \n        float Cvalue = 0;\n        for (int k = 0; k < numCRows; ++k) \n        {\n          Cvalue += A[Row*numAColumns+k] * B[k*numBColumns+Col];\n        }\n          C[Row*numCColumns+Col] = Cvalue;\n    }\n\n}\n```\n\n\nAlso in the main code:\n\n```\nnumCRows = numARows;\nnumCColumns = numBColumns;  \n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Cache-friendly optimization: Object oriented matrix multiplication and in-function tiled matrix multiplication\r\n                \r\nAfter writing a matrix class that represents whole matrix in two 1D-buffers using  this implementation , I've reached the matrix maltiplication part in my project and inclined to some cache-friendly-optimizations now. Stumbled upon two options(question is in lower part of this page):\n\n1)Selecting blocked/tiled sub-matrices just in the multiplication time.\n\n\nDone in c++ DLL function, so no function overhead.\nSince the code will be more complex, additional optimizations will be harder to apply.\n\n\n2)Building a matrix class from sub matrix classes(smaller patches) so multiplication is generally done on sub-matrix classes.\n\n\nObject oriented approach leaves space for additional optimizations for sub-matrices.\nObject headers and padding behavior of C# can help overcome critical strides?\nFunction overhead can be a problem after calling it many times instead of a few times.\n\n\nExample matrix multiplication: C=A.B\n\n```\n A\n 1 2 3 4   is used as  1 2    3 4  \n 4 3 4 2               4 3    4 2  \n 1 3 1 2                           \n 1 1 1 2               1 3    1 2  \n                       1 1    1 2\n\n\n B\n 1 1 1 1  --->         1 1    1 1\n 1 1 1 1               1 1    1 1\n 1 1 1 1 \n 1 1 1 1               1 1    1 1\n                       1 1    1 1\n\n\n Multiplication:       1 2 * 1 1   +   3 4 * 1 1    ==>  upper-left tile of result\n                       4 3   1 1       4 2   1 1  \n\n\n                       same for the upper-right of result\n\n                       1 3 * 1 1   +   1 2 * 1 1    ==> lower left tile of result\n                       1 1   1 1       1 2   1 1\n\n                       same for lower-right tile of result\n\n        Multiplication is O(n³) but summation is O(n²).\n```\n\n\nQuestion: Has anyone tried both(functional and object oriented) and made performance comparisons? Right now, my naive multiplication without any of these cache targeted optimizations, takes:\n\n```\n Matrix Size   Single Threaded Time    Multithreaded Time\n * 128x128   :     5    ms                 1ms-5ms(time sample error is bigger)\n * 256x256   :     25   ms                 7     ms\n * 512x512   :     140  ms                 35    ms\n * 1024x1024 :     1.3  s                  260   ms\n * 2048x2048 :     11.3 s                  2700  ms \n * 4096x4096 :     88.1 s                  24    s\n * 8192x8192 :     710  s                  177   s\n\n Giga-multiplications of variables per second\n               Single threaded         Multithreaded           Multi/single ratio               \n * 128x128   :     0.42                    2.0 - 0.4               ?\n * 256x256   :     0.67                    2.39                   3.67x  \n * 512x512   :     0.96                    3.84                   4.00x\n * 1024x1024 :     0.83                    3.47                   4.18x\n * 2048x2048 :     0.76                    3.18                   4.18x\n * 4096x4096 :     0.78                    2.86                   3.67x\n * 8192x8192 :     0.77                    3.09                   4.01x\n```\n\n\n(average results for 1.4GHz fx8150 with avx-optimized code using 32-bit floats)(c++ avx-intrinsics in dll functions within Parallel.For() of visual studio C#) \n\nWhich size of matrices above could be suffered from cache misses, critical strides and other bad things? Do you know how can I get performance counters of those using intrinsics?\n\nThans for your time.\n\nEdit: Inlining optimization within DLL:\n\n```\n Matrix Size   Single Threaded Time    Multithreaded Time           Multi/Single radio\n * 128x128   :  1     ms(%400)          390us avrage in 10k iterations(6G mult /s)\n * 256x256   :  12    ms(%108 faster)   2     ms   (%250 faster)         6.0x\n * 512x512   :  73    ms(%92 faster)    15    ms   (%133 faster)         4.9x\n * 1024x1024 :  1060  ms(%22 faster)    176   ms   (%48 faster)          6.0x\n * 2048x2048 :  10070 ms(%12 faster)    2350  ms   (%15 faster)          4.3x\n * 4096x4096 :  82.0  s(%7 faster)      22    s    (%9 faster)           3.7x\n * 8192x8192 :  676   s(%5 faster)      174   s    (%2 faster)           4.1x\n```\n\n\nAfter the inlining, the shadowed performance of smaller multiplications become visible.\nThere is still DLL-function-C# overhead. 1024x1024 case seems to be starting point of cache-misses. While work is increased by only seven times, the execution time is increased to fifteen times.\n\nEdit:: Going to try Strassen's algorithm for 3-layers deep with object oriented approach this week. Main matrix will be composed of 4 sub matrices. Then they will be composed of 4 sub-subs each. Then they will be composed of 4 sub-sub-subs each. This should give nearly (8/7)(8/7)(8/7)= +%50 speedup. If it works, will convert DLL-function to patch-optimized one which will use more cache.\n    ", "Answer": "\r\nApplying Strassen's Algorithm for just one layer(such as four of 256x256 as 512x512) as an object-oriented approach(the super class is ```\nStrassen```\n and the submatrices are ```\nmatrix```\n classes):\n\n```\n Matrix Size   Single Threaded Time    Multithreaded Time           Multi/Single radio\n * 128x128   :  **%50 slowdown**        **slowdown**              \n * 256x256   :  **%30 slowdown**        **slowdown**         \n * 512x512   :  **%10 slowdown**        **slowdown**            \n * 1024x1024 :  540   ms(%96 faster)    130   ms   (%35 faster)     4.15     \n * 2048x2048 :  7500  ms(%34 faster)    1310  ms   (%79 faster)     5.72    \n * 4096x4096 :  70.2  s(%17 faster)     17    s    (%29 faster)     4.13\n * 6144x6144 :          x               68    s               \n * 8192x8192 :  outOfMemoryException    outOfMemoryException     \n```\n\n\nThe overhead between DLL-function and C# is still in effect so small matrices could not get faster. But when there is a speedup, its always more than 8/7(%14) because using smaller chunks is better for cache usage.\n\nWill write a benchmark class that repeatedly tests for different leaf sizes of Stressen's Algorithm versus naive one to find the critical size. (for my system, it is 512x512).\n\nSuperclass will recursively build the sub-matrix tree until it reaches the 512x512 size and will use naive algorithm for 512x512 nodes. Then in the DLL-function, a patched/blocking algorithm(will add this next week) will make it some more faster. But I dont know how to select proper size of patch because I dont know how to get cache-line size of cpu. Will search for that after recursive Strassen is done.\n\nMy implementation of Strassen's Algorithm needs five times more memory(working on it). \n\nEdit: some of recursivity is done, updating the table as resuts come.\n\n```\n Matrix Size   Single Threaded Time    Multithreaded Time           \n * 2048x2048 :  x                       872     ms  average(double layer)    \n * 2560x2560 :  x                       1527    ms  average(double layer)  \n```\n\n\nParallelized the tree parsing, decreased memory footprint and introduced full recursivity:\n\n```\n Matrix Size   Single Threaded Time    Multithreaded Time                         m/s\n * 1024x1024 :  547   ms               123     ms  average(single layer)          4.45x\n * 2048x2048 :  3790  ms               790     ms  average(double layer)          4.79x\n * 4096x4096 :  26.4  s                5440    ms  average(triple layer)          4.85x\n * 8192x8192 :  185   s                38      s   average(quad layer)            4.87x\n * 8192x8192(4GHz):   x                15      s   average(quad layer)            4.87x\n```\n\n\nMultiplications per second (x10^9):\n\n```\n Matrix Size   Single Threaded         Multithreaded                          \n * 1024x1024 :  1.71                   7.64     (single layer)          \n * 2048x2048 :  1.73                   8.31     (double layer)          \n * 4096x4096 :  1.74                   8.45     (triple layer)         \n * 8192x8192 :  1.74                   8.48     (quad layer)           \n * 8192x8192(4GHz):   x                21.49    (quad layer)           \n Strassen's cpu flops is multiplied by 7/8 for each layer.\n```\n\n\nJust found out that using a similarly priced gpu can do 8kx8k under 1 second using opencl.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Flops in tensorflow : Matrix multiplication\r\n                \r\nInspired by this question I tried to measure the FLOPS required by tensorflow for a matrix-matrix multiplication. \n\nFor two matrices A and B with sizes (m x p) and (p x n), respectively, the resulting matrix C=AB with size (m x n) has mn entries. For each entry, p multiplications and (p-1) summations are required. Hence, the total number of operations is ```\nmn(2p-1)```\n.  \n\nWith the code from the linked question/answer, tensorflow outputs ```\nm*n*2p```\n, see code below.\n\nWhy is this approximation returned and not the theoretical value? In the worst case, p=1, this approximation is factor 2 larger than the correct value.\n\n```\nimport numpy as np\nimport tensorflow as tf\ng = tf.Graph()\nrun_meta = tf.RunMetadata()\nwith g.as_default():\n    A=tf.convert_to_tensor(np.random.rand(13,9))\n    B=tf.convert_to_tensor(np.random.rand(9,7))\n    C = tf.matmul(A,B) # shape=[13,7]\n\n    opts = tf.profiler.ProfileOptionBuilder.float_operation()    \n    flops = tf.profiler.profile(g, run_meta=run_meta, cmd='op', options\n=opts)\n    if flops is not None:\n        print('Flops should be ', 13*7*(2*9-1))\n        print('Approximation 2*13*7*9=',2*13*7*9) \n        print('TF stats gives',flops.total_float_ops)\n\n#Output: \n#Flops should be  1547\n#Approximation 2*13*7*9= 1638\n#TF stats gives 1638\n```\n\n    ", "Answer": "\r\nI think this is because in practice, summations are often coded like this (pseudo-code below):\n\n```\ntotal = 0\nfor i in 0...p\n  total += x[i] * y[i]\n```\n\n\nthat is, the first element ```\nx[0] * y[0]```\n is summed to ```\ntotal```\n (which is 0 then), which yields ```\np```\n summations rather than ```\np-1```\n.\n\nYou could try to be smart and avoid this extra summation:\n\n```\ntotal = x[0] * y[0]\nfor i in 1...p\n  total += x[i] * y[i]\n```\n\n\n... but then what happens if ```\np==0```\n? Ouch we need to add an extra comparison:\n\n```\nif p > 0\n  total = x[0] * y[0]\n  for i in 1...p\n    total += x[i] * y[i]\nelse\n  total = 0\n```\n\n\nThe thing is, this comparison is not a flop and will not appear in your flop count -- yet in practice it is as costly, if not more costly, than a simple add.\n\nBottom line:\n\n\nThe flop calculation is probably correct if the implementation does not \"optimize away\" the initial sum\nThis \"optimization\" may actually not speed up you code\nTake flops measures with a grain of salt, and don't worry too much about vanishing components.\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Efficient Matrix multiplication in RISC-V\r\n                \r\nI am struggling with matrix multiplication in RISC-V\nInput is 128*128 matrix with unsigned short integer entry\nI've wrote a naive one\nThe goal is to reduce the clock cycles\n• Below 20,000,000 cycles (2%)\n• Below 18,000,000 cycles (2%)\n• Below 16,000,000 cycles (2%)\n• Below 14,000,000 cycles (2%)\n• Below 12,000,000 cycles (2%)\n• Below 10,000,000 cycles (1%)\n• Below 9,000,000 cycles (1%)\n• Below 8,000,000 cycles (1%)\n• Below 7,000,000 cycles (1%)\n• Below 6,000,000 cycles (1%)\nMine is about 19M\nand bruteforce in C with O3 is 16M\nI know there's the a better algorithm to do matrix multiplication o(n^3)\nbut here n is only 128, I wonder if there's other way to reduce cycles by the O(n^3) algo\nis there anything can I do to boost my code?\n```\n.global matrix_mul\n.type matrix_mul, %function\n\n.align 2\n# void matrix_mul(unsigned int A[][], unsigned int B[][], unsinged int C[][]);\nmatrix_mul:\n    \n    # for i = 0 to 127\n    #   for j = 0 to 127\n    #       for k = 0 to 127\n    #           C[i][j] += A[i][k] * B[k][j] % 1024\n\n    # insert code here\n        addi t0, zero, 128 # size\n        add s11, zero, a1 # B\n\n        add t1, zero, zero # i = 0 \nloop1:  # loop1 #\n        add t2, zero, zero # j = 0\n        # loop2 #\nloop2:   \n        add t3, zero, zero # k = 0\n        add t4, zero, zero # sum = 0\n        # loop3 #\nloop3:\n        lhu t5, 0(a0) # A[i][k]\n        lhu t6, 0(s11) # B[k][j]\n        mul t5, t5, t6 # A*B\n        add t4, t4, t5 # C += A*B\n        andi t4, t4, 1023 # mod 1024\n        addi a0, a0, 2 # A[i][k+1]\n        addi s11, s11, 256 # B[k+1][j]\n        addi t3, t3, 1 # k++ \n        blt t3, t0, loop3 # k<size , continue\n        # loop3 end #\n        sh t4, 0(a2) # store back to C[i][j]\n        addi a2, a2, 2 # C[i][j+1]\n        addi a0, a0, -256 # A go back\n        addi a1, a1, 2 # B[k][j+1]\n        add  s11, zero, a1 # B\n        addi t2, t2, 1 # j++\n        blt t2, t0, loop2 # j<size , continue\n        # loop2 end #\n        addi a0, a0, 256 # A[i+1][k]\n        addi a1, a1, -256 # B go back (because line 40 add 2*128=256)\n        add s11, zero, a1 # B\n        addi t1, t1, 1 # i++\n        blt t1, t0, loop1 # i<size , continue\n        # loop1 end #\n\n    # Green card here: https://www.cl.cam.ac.uk/teaching/1617/ECAD+Arch/files/docs/RISCVGreenCardv128-20151013.pdf\n\n    ret\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication Using SSE Error __m128 to *float conversion?\r\n                \r\nI'm trying to program matrix multiplication using SSE Intrinsic. I'm not sure if my code is correct and I can't compiler it either because I get an error:\n\n```\nError   1   error C2440: 'type cast' : cannot convert from 'float' to '__m128 *\n```\n\n\nCan someone double check my program so that my matrix multiplication is correct? Note also that this is for a square matrix.\n\nHere is my code.\n\n```\nvoid Intrinsics (float * matrix_a, float * matrix_b, float * matrix_result, const int num_row, const int num_col) {\n    __declspec(align(16)) float * a = matrix_a;\n    __declspec(align(16)) float * b = matrix_b;\n    __declspec(align(16)) float * c = matrix_result;\n\n    for(int i = 0; i < num_row; ++i)\n    {\n       for(int j = 0; j < num_col; ++j)\n        {\n            __m128 *m3 = (__m128*)a[i];     // The error is here.\n            __m128 *m4 = (__m128*)b[j];\n            float* res;\n            *(c + (j * num_col + i)) = 0;\n          for(int k = 0; k < num_col; k += 4)\n            {\n                __m128 m5 = _mm_mul_ps(*m3,*m4);\n                res = (float*)&m5;\n                *(c + (j * num_col + i)) += res[0]+res[1]+res[2]+res[3];\n                m3++;\n                m4++;\n            }\n        }\n    }\n}\n```\n\n    ", "Answer": "\r\nI assume that it's ```\n__m128 *m3 = (__m128*)a[i];```\n and the line after that that produce the error. You are trying to typecast a ```\nfloat```\n to a pointer to __m128 which compiler is right to complain about.\n\nI don't know the details of the intended algorithm. Assuming that the intent is to access four floats a[i]..a[i+3] as a single __m128, you need something like this:\n\n```\n__m128 *m3 = (__m128*)&a[i];\n__m128 *m4 = (__m128*)&b[j];\n```\n\n\nor equivalent:\n\n```\n__m128 *m3 = (__m128*)(a + i);\n__m128 *m4 = (__m128*)(b + j);\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "OpenMP Matrix Multiplication Issues\r\n                \r\nI am trying to multiple the values of a matrix.\n```\n#include <stdio.h>\n#include <omp.h>\n#include <time.h>\n#include <stdlib.h>\n#include <omp.h>\n\n#define N 2048\n#define FactorIntToDouble 1.1; \n#define THREAD_NUM 4\n\ndouble firstMatrix [N] [N] = {0.0};\ndouble secondMatrix [N] [N] = {0.0};\ndouble matrixMultiResult [N] [N] = {0.0};\n\n// Sync\nvoid matrixMulti() {\n    for(int row = 0 ; row < N ; row++){\n        for(int col = 0; col < N ; col++){\n            double resultValue = 0;\n            for(int transNumber = 0 ; transNumber < N ; transNumber++) {\n                resultValue += firstMatrix [row] [transNumber] * secondMatrix [transNumber] [col] ;\n            }\n\n            matrixMultiResult [row] [col] = resultValue;\n        \n        }\n    }\n}\n\n\nvoid matrixInit() {\n    for(int row = 0 ; row < N ; row++ ) {\n        for(int col = 0 ; col < N ;col++){\n            srand(row+col);\n            firstMatrix [row] [col] = ( rand() % 10 ) * FactorIntToDouble;\n            secondMatrix [row] [col] = ( rand() % 10 ) * FactorIntToDouble;\n        }\n    }\n    \n}\n\n// Parallel\nvoid matrixMulti2(int start, int end) {\n    printf(\"Op: %d - %d\\n\", start, end);\n    for(int row = start ; row < end ; row++){\n        for(int col = 0; col < N ; col++){\n            double resultValue = 0;\n            for(int transNumber = 0 ; transNumber < N ; transNumber++) {\n                resultValue += firstMatrix [row] [transNumber] * secondMatrix [transNumber] [col] ;\n            }\n\n            matrixMultiResult [row] [col] = resultValue;\n        }\n    }\n}\n\n\nvoid process1(){\n    clock_t t1 = clock(); \n    #pragma omp parallel\n    {\n    int thread = omp_get_thread_num();\n    int thread_multi = N / 4;\n    \n    int start = (thread) * thread_multi;\n        \n        int end = 0;\n        if(thread == (THREAD_NUM - 1)){\n            end = (start + thread_multi);\n        }else{\n            end = (start + thread_multi) - 1;\n        }\n        \n        matrixMulti2(start, end);\n        \n    \n    }\n    \n    clock_t t2 = clock(); \n    printf(\"time 2: %ld\\n\", t2-t1);\n}\n\n\nint main(){\n    matrixInit();\n    \n    clock_t t1 = clock(); \n    matrixMulti();\n    \n    clock_t t2 = clock(); \n    printf(\"time: %ld\", t2-t1);\n    \n    process1();\n\n    return 0;\n}\n\n```\n\nI have both a parallel and sync version. But the parallel version is longer than the sync version.\nCurrent the sync takes around 90 seconds and the parallel over 100.  Which makes no sense to me.\nMy logic was to split the matrix into 4 parts from the first 4 statement.  Which I believe is logical.\nAfter I finish this part. I would like to figure out how to speed up this process for the parallel even more.  Possibly using Strassen's Matrix Multiplication.  I just don't know where to start or how to get to this point.\nI've already spent around 5 hours trying to figure this out.\n    ", "Answer": "\r\nHere it is:\n```\n// Sync\nvoid matrixMulti() {\n    #pragma omp parallel for collapse(2)\n    for(int row = 0 ; row < N ; row++){\n        for(int col = 0; col < N ; col++){\n            double resultValue = 0;\n            for(int transNumber = 0 ; transNumber < N ; transNumber++) {\n                resultValue += firstMatrix [row] [transNumber] * secondMatrix [transNumber] [col] ;\n            }\n\n            matrixMultiResult [row] [col] = resultValue;\n        \n        }\n    }\n}\n```\n\nUpdate: Here is what I got on an 8 core system using gcc 10.3 -O3 -fopenmp flags (I show you the program's output and result of linux time command) :\n```\nmain()```\n was changed to measure the time with ```\nomp_get_wtime()```\n because in linux ```\nclock()```\n measures processor time:\n```\ndouble t1 = omp_get_wtime(); \nmatrixMulti();    \ndouble t2 = omp_get_wtime(); \nprintf(\"time: %f\", t2-t1);\n```\n\nSerial program:\n```\ntime: 25.895234\n\nreal    0m33.296s\nuser    0m33.139s\nsys     0m0.152s\n```\n\nusing: ```\n#pragma omp parallel for```\n\n```\n time: 3.573521\n\n real    0m11.120s\n user    0m32.205s\n sys     0m0.136s\n```\n\nusing: ```\n#pragma omp parallel for collapse(2)```\n\n```\ntime: 5.466674\n\nreal    0m12.786s\nuser    0m49.978s\nsys     0m0.248s\n```\n\nThe results suggest that initialization of matrix takes ca. 8 s, so it may also be worth parallelizing. Without ```\ncollapse(2)```\n the program runs faster, so do not use ```\ncollapse(2)```\n clause.\nNote that on your system you may got different speed improvement or even decrease depending on your hardware. Speed of matrix multiplication strongly depends on the speed of memory read/write. Shared-Memory Multicore systems (i.e most PCs, laptops) may not show any speed increase upon parallelization of this program, but Distributed-Memory Multicore systems (i.e. high-end serves) definitely show performance increase. For more details please read e.g. this.\nUpdate2: On Ryzen 7 5800X I got ```\n41.6 s```\n vs ```\n1.68 s```\n, which is a bigger increase than the number of cores. It is because more cache memory is available when all the cores is used.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Different Output in matrix Multiplication Python vs Swift\r\n                \r\nI'm writing a code of matrix multiplication in swift and python but both code generate a different output. \nI also write this code in C++ but it generate same output as in python, I checked swift code again and again but I got no difference\nI'm trying to multiply these two matrix\n\nMatrix A\n\n```\n1 0 1\n0 0 0\n1 0 1\n```\n\n\nMatrix B\n\n```\n0 0 0 0 0 0 0 0 0 0\n0 1 2 3 4 5 6 7 8 0\n0 2 3 4 5 6 7 8 9 0\n0 3 4 5 6 7 8 9 5 0\n0 4 5 6 7 8 9 3 4 0\n0 4 5 6 7 8 9 2 3 0\n0 5 6 7 8 9 0 4 6 0\n0 6 7 8 9 1 2 3 8 0\n0 7 8 9 1 2 3 0 5 0\n0 8 9 2 4 5 6 4 8 0\n0 0 0 0 0 0 0 0 0 0\n```\n\n\nHere's my Python Code\n\n```\nrow,col = 8,9 \nresult = [[0 for x in range(row)] for y in range(col)]\nrow,col=0,0\nfor matrixB_Row in range(0,9):\n    for matrixB_Col in range(0,8):\n        for matrixA_Row in range(0,3):\n            for i in range(0,3):\n                for matrixA_Col in range(0,3):\n                    result[row][col] = result[row][col]+(matrixA[matrixA_Row][matrixA_Col]*matrixA[matrixB_Row][matrixB_Col])\n                    matrixA_Col+=1\n                    matrixB_Row+=1\n                i+=1\n                matrixB_Col+=1\n                matrixB_Row = matrixB_Row-3\n            matrixB_Col = matrixB_Col-3\n            matrixA_Row+=1\n        col+=1\n        matrixB_Col+=1\n    row+=1\n    col=0\n    matrixB_Row=+1\n    matrixB_Col=0\n```\n\n\nHere's my swift code\n\n```\nvar Row = 0, Col = 0, MatrixB_Col = 0, MatrixB_Row = 0, MatrixA_Col = 0, MatrixA_Row = 0, i = 0\n        var result = [[Int]](repeating: [Int](repeating: 0, count: 8), count: 9)\n        while MatrixB_Row < 9\n        {\n            MatrixB_Col = 0\n            while MatrixB_Col < 8{\n                MatrixA_Row = 0\n                while MatrixA_Row < 3 {\n                    i = 0\n                    while i < 3 {\n                        MatrixA_Col = 0\n                        while MatrixA_Col < 3{\n                            result[Row][Col] += (matrixA[MatrixA_Row][MatrixA_Col] * matrixB[MatrixB_Row][MatrixB_Col]);\n                            MatrixA_Col+=1\n                            MatrixB_Row+=1\n                        }\n                        i+=1\n                        MatrixB_Col+=1\n                        MatrixB_Row = MatrixB_Row - 3\n                    }\n                    MatrixA_Row+=1\n                    MatrixB_Col = MatrixB_Col - 3\n                }\n                MatrixB_Col+=1\n                Col+=1\n            }\n            Row+=1\n            Col=0\n            MatrixB_Row+=1\n            MatrixB_Col = 0\n        }\n```\n\n    ", "Answer": "\r\nMultiplication in your python code:\n\n```\nresult[row][col] = result[row][col]+(matrixA[matrixA_Row][matrixA_Col]*matrixA[matrixB_Row][matrixB_Col])\n```\n\n\nHere you're using elements only from matrix A for multiplication.\n\nMultiplication in your swift code:\n\n```\nresult[Row][Col] += (matrixA[MatrixA_Row][MatrixA_Col] * matrixB[MatrixB_Row][MatrixB_Col]);\n```\n\n\nHere you're using both matrix A and matrix B.\nThat's why the results are different - you have an error in your python code.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Scipy sparse matrix multiplication much slower than numpy array\r\n                \r\nI have constructed the following case to test one-dimensional sparse matrix multiplication vs numpy arrays.\n\n```\nfrom scipy.sparse import csc_matrix\nsp = csc_matrix((1, 36710))\nsp[0,4162] = 0.2335\nsp[0,21274] = 0.1367\nsp[0,27322] = 0.261\nsp[0,27451] = 0.9266\n\n%timeit sp.dot(sp.T)\narr = sp.toarray()[0]\n%timeit arr.dot(arr)\n```\n\n\nThe result is as follows:\n\n```\n267 µs ± 6.58 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n9.9 µs ± 230 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n```\n\n\nAlso they are both slower than a plain dict storing entries and a for-loop for the multiplication (~1µs).\n\nThe result is the same after trying different type of sparse matrix, including csr/coo. Why is sparse matrix multiplication ~30 times slower than numpy dense array multiplication? Is it because the matrix is too sparse?\n    ", "Answer": "\r\nIn hpaulj's answer, M*M is not a matrix multiplication -- it's just an element-wise multiplication. This is why M*M is much faster than matrix multiplication. So in all case matrix multiplication is much slower for csr matrix.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication using a single pipe [closed]\r\n                    \r\n            \r\n        \r\n            \r\n                    \r\n                        \r\n                    \r\n                \r\n                    \r\n                            \r\n                                It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and  cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened,  visit the help center.\r\n                                \r\n                            \r\n                    \r\n                \r\n            \r\n                Closed 10 years ago.\r\n        \r\n\r\n\r\n    \r\n\r\nI want to write a ```\nc```\n code such that the child sends two matrix to the parent using pipes, the parent will then do the matrix multiplication and send the resulting matrix back to the child.\nI know how to write this program using two pipes, but i want to know how to write this program using a single pipe.\n\nCan anyone please provide the ```\nc```\n code for the same?\n    ", "Answer": "\r\nPipes are not bi-directional.\n\nTry sockets. Or use two pipes.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "C : Matrix Multiplication stuck if matrix size 4096x4096\r\n                \r\nHere is the code, matrix multiplication in C, the matrix's fill is integer. Optimization for loop nest and loop unrolling. Run well till N is 7168. For N 8196, insufficient memory.If you run it, just screen, wait till get time result. This is an alarm from my computer (Asus A456UQ) or code is still wrong? \n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include<time.h>\n#include <sys/time.h>\n#include<assert.h>\n\n#define mat(m, col, row) \\\nm.data[row*m.cols + col]\n\n#define N 8192\ntypedef struct\n{\n    int cols, rows;\n    int *data;\n}matrix_t;\n\nvoid matrix_init(matrix_t *matrix, int cols, int rows)\n{\n    int i,j;\n    matrix->cols = cols;\n    matrix->rows = rows;\n    matrix->data = malloc(sizeof(int)*cols*rows);\n\n    if (!matrix->data)\n    {\n        fprintf(stderr, \"Insufficient memory for a %dx%d matrix\", cols, rows);\n        exit(EXIT_FAILURE);\n    }\n\n    // 0 fill\n    memset(matrix->data, 0, cols*rows);\n\n}\n\nvoid matrix_print(matrix_t *matrix)\n{\n    int i, n;\n\n    n = matrix->cols * matrix->rows;\n\n    printf(\"--M%dx%d--\\n\", matrix->rows, matrix->cols);\n    for (i=0; i<n; i++)\n    {\n        printf(\"%d \", matrix->data[i]);\n\n        if ((i+1)%matrix->cols == 0) printf(\"\\n\");\n    }\n}\n\nvoid free_array(matrix_t *matrix) {\n    free(matrix->data);\n    matrix->data = NULL;\n    matrix->cols = matrix->rows = 0;\n}\n\nvoid mul_matrix(matrix_t A, matrix_t B, matrix_t C){\n    int ii, kk,ib,kb,j,i,k;\n    int acc00, acc01, acc10,acc11;\n\n    int size = A.cols;\n    ib=16;\n    kb=16;\n\n    for (ii = 0; ii < size; ii += ib)\n    {\n        for (kk = 0; kk < size; kk += kb)\n        {\n            for (j=0; j < size; j += 2)\n            {\n                for(i = ii; i < ii + ib; i += 2 )\n                {\n                    if (kk == 0)\n                        acc00 = acc01 = acc10 = acc11 = 0;\n                    else\n                    {\n                        acc00 = mat(C,i,j);\n                        acc01 = mat(C,i,(j+1));\n                        acc10 = mat(C,(i+1),j);\n                        acc11 = mat(C,(i+1),(j+1));\n                    }\n                }\n                for (k = kk; k < kk + kb; k++)\n                {\n                    acc00 += mat(A,i,k) * mat(B,k,j);\n                    acc01 += mat(A,i,k) * mat(B,k,j+1);\n                    acc10 += mat(A,(i+1),k) * mat(B,k,j);\n                    acc11 += mat(A,(i+1),k) * mat(B,k,(j+1));\n                }\n\n                mat(C,i,j) = acc00;\n                mat(C,i,(j+1)) = acc01;\n                mat(C,(i+1),j) = acc10;\n                mat(C,(i+1),(j+1)) = acc11;\n\n            }\n        }\n    }\n}\n/*\nvoid mul_matrix(matrix_t A, matrix_t B, matrix_t C){\n    int i,j,k;\n    int t;\n    int size = A.cols;\n\n\n    for (int j=0; j<size; j++) {\n       // iterates the j-th row of c\n       for (int i=0; i<size; i++) {\n           mat(C,i,j)=0;\n       }\n\n       // iterates the j-th row of b\n       for (int k=0; k<size; k++) {\n          t = mat(B,k,j);\n          // iterates the j-th row of c\n          // iterates the k-th row of a\n          for (int i=0; i<size; i++) {\n            mat(C,i,j) += mat(A,i,k) * t;\n          }\n       }\n    }\n\n */\n\n/*\n\n    for (i = 0; i < size; i++){\n        for (j = 0; j < size; j++) {\n            mat(C,i,j) = 0;\n            for (k = 0; k < size; k++)\n                mat(C,i,j) += mat(A,i,k) * mat(B, k,j);\n        }\n    }\n}\n*/\nvoid sum_matrix (matrix_t A, matrix_t B, matrix_t C){\n    int i,j;\n    int size = A.cols;\n\n    for(i=0; i< size; i++) {\n        for (j=0; j<size; j++)\n            mat(C,i,j) = mat(A,i,j) + mat(B, i,j);\n    }\n\n}\n\nvoid sub_matrix (matrix_t A, matrix_t B, matrix_t C){\n    int i,j;\n    int size = A.cols;\n\n    for(i=0; i< size; i++) {\n        for (j=0; j<size; j++)\n            mat(C,i,j) = mat(A,i,j) - mat(B, i,j);\n    }\n\n}\n\nint main(int argc, char **argv)\n{\n    matrix_t x;\n    matrix_t y;\n    matrix_t z;\n    matrix_t m1,m2,m3,m4,m5,m6,m7;\n    matrix_t a11,a12,a21,a22;\n    matrix_t b11,b12,b21,b22;\n    matrix_t aresult, bresult;\n    matrix_t c11,c12,c21,c22;\n\n\n\n    int i,j,k =0;\n\n    int half = N/2;\n\n    matrix_init(&x, N, N);\n    matrix_init(&y, N, N);\n    matrix_init(&z, N, N);\n    //for(i = 0; i<N; i++)\n      //  for(j = 0; j<N; j++)\n         //   mat(z,i,j) =0;\n    //matrix_print(&z);\n\n    matrix_init(&a11, half, half);\n    matrix_init(&a12, half, half);\n    matrix_init(&a21, half, half);\n    matrix_init(&a22, half, half);\n    matrix_init(&b11, half, half);\n    matrix_init(&b12, half, half);\n    matrix_init(&b21, half, half);\n    matrix_init(&b22, half, half);\n\n    matrix_init(&aresult,half,half);\n    matrix_init(&bresult,half,half);\n\n    matrix_init(&m1, half, half);\n    matrix_init(&m2, half, half);\n    matrix_init(&m3, half, half);\n    matrix_init(&m4, half, half);\n    matrix_init(&m5, half, half);\n    matrix_init(&m6, half, half);\n    matrix_init(&m7, half, half);\n\n    matrix_init(&c11, half, half);\n    matrix_init(&c12, half, half);\n    matrix_init(&c21, half, half);\n    matrix_init(&c22, half, half);\n\n\n    struct timeval  tv1, tv2;\n\n    //srand((unsigned)time(NULL));\n\n\n    for(i = 0; i<N; i++)\n        for(j = 0; j<N; j++)\n            mat(x,i,j) =1;// rand() % 10;\n\n    for(i = 0; i<N; i++)\n        for(j = 0; j<N; j++)\n            mat(y,i,j) =1;// rand() % 10;\n\n\n\n\n    gettimeofday(&tv1, NULL);\n\n\n    //dividing the matrices in 4 sub-matrices:\n    for(i=0; i<half; i++){\n        for (j=0; j<half;j++){\n            mat(a11,i,j)= mat(x,i,j);\n            mat(a12,i,j)= mat(x,i,j+half);\n            mat(a21,i,j)= mat(x,i+half,j);\n            mat(a22,i,j)= mat(x,i+half,j+half);\n\n            mat(b11,i,j)= mat(y,i,j);\n            mat(b12,i,j)= mat(y,i,j+half);\n            mat(b21,i,j)= mat(y,i+half, j);\n            mat(b22,i,j)= mat(y, i+half, j+half);\n        }\n    }\n    //matrix_print(&a11);\n    //matrix_print(&a12);\n    //matrix_print(&a21);\n    //matrix_print(&a22);\n\n    // Calculating m1 to m7:\n    sum_matrix(a11,a22,aresult);\n    sum_matrix(b11,b22,bresult);\n    mul_matrix(aresult,bresult,m1);\n\n    sum_matrix(a21,a22,aresult);\n    mul_matrix(aresult,b11,m2);\n\n    sub_matrix(b12,b22,aresult);\n    mul_matrix(a11,aresult,m3);\n\n    sub_matrix(b21,b11, aresult);\n    mul_matrix(a22,aresult,m4);\n\n    sum_matrix(a11,a12,aresult);\n    mul_matrix(aresult,b22,m5);\n\n    sub_matrix(a21,a11,aresult);\n    sum_matrix(b11,b12,bresult);\n    mul_matrix(aresult,bresult,m6);\n\n    sub_matrix(a12,a22,aresult);\n    sum_matrix(b21,b22,bresult);\n    mul_matrix(aresult,bresult,m7);\n\n    sum_matrix(m1,m4,aresult);\n    sub_matrix(aresult,m5,bresult);\n    sum_matrix(bresult,m7,c11);\n\n    sum_matrix(m3,m5,c12);\n    sum_matrix(m2,m4,c21);\n    sub_matrix(m1,m2, aresult);\n    sum_matrix(aresult,m3,bresult);\n    sum_matrix(bresult,m6,c22);\n\n    //matrix_print(&c11);\n    //matrix_print(&c12);\n    //matrix_print(&c21);\n    //matrix_print(&c22);\n\n    //combine matrix\n\n    for(i=0; i < half; i++){\n        for (j=0; j<half;j++){\n            mat(z,i,j)= mat(c11,i,j);\n            mat(z,(i+half),j)= mat(c12,i,j);\n            mat(z,i,(j+half))= mat(c21,i,j);\n            mat(z,(i+half),(j+half))= mat(c22,i,j);\n       }\n    }\n\n\n\n\n\n\n\n\n\n    gettimeofday(&tv2, NULL);\n\n    //matrix_print(&x);\n    //matrix_print(&y);\n    //matrix_print(&z);\n    printf (\"\\n \\nTotal time = %f seconds\\n\",(double) (tv2.tv_usec - tv1.tv_usec) / 1000000 + (double) (tv2.tv_sec - tv1.tv_sec));\n\n    free_array(&x);\n    free_array(&y);\n    free_array(&z);\n\n    free_array(&m1);\n    free_array(&m2);\n    free_array(&m3);\n    free_array(&m4);\n    free_array(&m5);\n    free_array(&m6);\n    free_array(&m7);\n\n    free_array(&a11);\n    free_array(&a12);\n    free_array(&a21);\n    free_array(&a22);\n    free_array(&b11);\n    free_array(&b12);\n    free_array(&b21);\n    free_array(&b22);\n\n    free_array(&aresult);\n    free_array(&bresult);\n\n    free_array(&c11);\n    free_array(&c12);\n    free_array(&c21);\n    free_array(&c22);\n    return 0;\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Parallel matrix multiplication in rust\r\n                \r\nI want to parallelize matrix multiplication in Rust. I've written a sequential algorithm (```\nmul```\n function) and a parallel one (```\nmul_par```\n).\nThe ```\nmul_parallel```\n is supposed to work in almost the same way as the sequential version, but it divides the work into a number of chunks equal to the number of CPUs found by ```\nnum_cpus::get()```\n.\nEach chunk is spawned in a separate thread. Here's my code:\n```\n#[derive(Debug)]\nstruct RsMatrix {\n    data: Arc<Vec<Vec<f64>>>,\n    rows: usize,\n    cols: usize,\n}\n\n\nimpl RsMatrix {\n    /// Creates a new matrix from a 2D array of floats.\n    fn new(data: Vec<Vec<f64>>) -> Result<Self, String> {\n        // check if all rows have the same length\n        let row_len = data[0].len();\n        if !data.iter().all(|row| row.len() == row_len) {\n            return Err(String::from(\"All rows must have the same length\"));\n        }\n        let rows = data.len();\n        let cols = row_len;\n        Ok(Self { data: Arc::new(data), rows, cols })\n    }\n\n    /// Multiplies matrices.\n    fn mul(&self, other: &Self) -> Result<Self, String> {\n        if self.cols != other.rows {\n            return Err(format!(\n                \"Invalid matrix dimensions. \\\n                The number of columns of the first matrix should be equal to the number of rows \\\n                of the second matrix. Got {} and {} instead.\",\n                self.cols, other.rows,\n            ));\n        }\n\n        let mut result = vec![vec![0.0; other.cols]; self.rows];\n\n        for row_a in 0..self.rows {\n            for col_b in 0..other.cols {\n                for i in 0..self.cols {\n                    result[row_a][col_b] += self.data[row_a][i] * other.data[i][col_b];\n                }\n            }\n        }\n\n        Ok(Self::new(result)?)\n    }\n\n    fn mul_par(&self, other: &Self) -> Result<Self, String> {\n        if self.cols != other.rows {\n                return Err(format!(\n                    \"Invalid matrix dimensions. \\\n                    The number of columns of the first matrix should be equal to the number of rows \\\n                    of the second matrix. Got {} and {} instead.\",\n                self.cols, other.rows,\n            ));\n        }\n\n        use num_cpus;\n        let num_threads = num_cpus::get();\n        let result = Arc::new(Mutex::new(vec![vec![0.0; other.cols]; self.rows]));\n        let chunk_size: usize = (self.rows as f32 / num_threads as f32).ceil() as usize;\n        let mut handles = Vec::with_capacity(num_threads);\n\n        for th in 0..num_threads {\n            let start = th * chunk_size;\n            if start >= self.rows {\n                break;\n            };\n            let result = Arc::clone(&result);\n            let self_data = Arc::clone(&self.data);\n            let other_data = Arc::clone(&other.data);\n\n            let is_last_thread = th == num_threads - 1;\n            let end = if is_last_thread {\n                self.rows\n            } else {\n                (th + 1) * chunk_size\n            };\n\n            let other_cols = other.cols;\n            let self_cols = self.cols;\n\n            let handle = thread::spawn(move || {\n                for row_a in start..end {\n                    for col_b in 0..other_cols {\n                        let mut sum = 0.0;\n                        for i in 0..self_cols {\n                            sum += self_data[row_a][i] * other_data[i][col_b];\n                        }\n                        result.lock().unwrap()[row_a][col_b] = sum;\n                    }\n                }\n            });\n            handles.push(handle);\n        }\n\n        for handle in handles {\n            handle.join().unwrap();\n        }\n\n        let result = Arc::try_unwrap(result).unwrap().into_inner().unwrap();\n        Ok(Self::new(result)?)\n    }\n```\n\nThe problem with my code is that when I run a simple benchmark that I've prepared (multiplying 100x100 matrices), the parallel version is much slower. What could be a reason for that?\n```\nRunning 100 tests of 1000x100 * 100x100 matrix multiplication\nStarting benchmark\nRust implementation total: 2.9226980209350586s\nRust implementation per iteration: 0.029226980209350585s\nRust implementation (parallel) total: 8.718234777450562s\nRust implementation (parallel) per iteration: 0.08718234777450562s\n```\n\n\nMy benchmarks are rather simple and they look somewhat like this:\n```\n// matrix code skipped\n\nuse rand;\nuse rand::Rng;\n\n\nconst ROW_COUNT_A: usize = 100;\nconst COL_COUNT_A: usize = 100;\nconst ROW_COUNT_B: usize = 100;\nconst COL_COUNT_B: usize = 100;\nconst NUM_TESTS: usize = 1000;\n\n\nfn generate_test_matrices() -> Vec<(RsMatrix, RsMatrix)> {\n    let mut result = Vec::with_capacity(NUM_TESTS);\n    let mut rng = rand::thread_rng();\n\n    for _ in 0..NUM_TESTS {\n        let matrix_a = (0..ROW_COUNT_A)\n            .map(|_| {\n                (0..COL_COUNT_A)\n                    .map(|_| rng.gen())\n                    .collect::<Vec<f64>>()\n            })\n            .collect::<Vec<Vec<f64>>>();\n        let matrix_a = RsMatrix::new(matrix_a).unwrap();\n        let matrix_b = (0..ROW_COUNT_B)\n            .map(|_| {\n                (0..COL_COUNT_B)\n                    .map(|_| rng.gen())\n                    .collect::<Vec<f64>>()\n            })\n            .collect::<Vec<Vec<f64>>>();\n        let matrix_b = RsMatrix::new(matrix_b).unwrap();\n        result.push((matrix_a, matrix_b));\n    }\n\n    result\n}\n\nfn test_matrix_mul(test_data: &Vec<(RsMatrix, RsMatrix)>) {\n    for (matrix_a, matrix_b) in test_data {\n        let _ = matrix_a.mul(&matrix_b).unwrap();\n    }\n}\n\nfn test_matrix_mul_parallel(test_data: &Vec<(RsMatrix, RsMatrix)>) {\n    for (matrix_a, matrix_b) in test_data {\n        let _ = matrix_a.mul_par(&matrix_b).unwrap();\n    }\n}\n\nfn main() {\n    let test_data = generate_test_matrices();\n    // check time execution of sequential multiplication\n    let start = std::time::Instant::now();\n    test_matrix_mul(&test_data);\n    let duration = start.elapsed();\n    println!(\"Time elapsed in sequential multiplication is: {:?}\", duration);\n\n    // check time execution of parallel multiplication\n    let start = std::time::Instant::now();\n    test_matrix_mul_parallel(&test_data);\n    let duration = start.elapsed();\n    println!(\"Time elapsed in parallel multiplication is: {:?}\", duration);\n}\n```\n\nThe output I get from that is:\n```\nTime elapsed in sequential multiplication is: 2.71852745s\nTime elapsed in parallel multiplication is: 8.5174711s\n```\n\n    ", "Answer": "\r\nThe mutex ```\nlock```\n is the main problem, because it is a single threaded choke point for all the parallel threads.\nFurther, since the introduction of ```\nstd::thread::scope```\n, the usage of ```\nArc```\n in this example is  no longer required and might further (even if only a little bit) increase your performance.\nThe ```\nlock```\n however, is by far the biggest problem. If we don't use ```\nArc```\n here, our possibilities become a lot more.\nThere's two ways to implement it without ```\nlock```\n that I can think of right now:\n\nsplitting the output into parallel slices, with ```\nsplit_at_mut()```\n\nby using ```\nrayon```\n and, more specifically, its parallel iterators\n\nHere's code for all of those, including code for the ```\nMutex```\n based variant without ```\nArc```\n:\n\n```\nlib.rs```\n\n\n```\nuse rayon::prelude::*;\nuse std::{sync::Mutex, thread};\n\n#[derive(Debug, PartialEq)]\npub struct RsMatrix {\n    data: Vec<Vec<f64>>,\n    rows: usize,\n    cols: usize,\n}\n\nimpl RsMatrix {\n    /// Creates a new matrix from a 2D array of floats.\n    pub fn new(data: Vec<Vec<f64>>) -> Result<Self, String> {\n        // check if all rows have the same length\n        let row_len = data[0].len();\n        if !data.iter().all(|row| row.len() == row_len) {\n            return Err(String::from(\"All rows must have the same length\"));\n        }\n        let rows = data.len();\n        let cols = row_len;\n        Ok(Self { data, rows, cols })\n    }\n\n    /// Multiplies matrices.\n    pub fn mul(&self, other: &Self) -> Result<Self, String> {\n        if self.cols != other.rows {\n            return Err(format!(\n                \"Invalid matrix dimensions. \\\n                The number of columns of the first matrix should be equal to the number of rows \\\n                of the second matrix. Got {} and {} instead.\",\n                self.cols, other.rows,\n            ));\n        }\n\n        let mut result = vec![vec![0.0; other.cols]; self.rows];\n\n        for row_a in 0..self.rows {\n            for col_b in 0..other.cols {\n                for i in 0..self.cols {\n                    result[row_a][col_b] += self.data[row_a][i] * other.data[i][col_b];\n                }\n            }\n        }\n\n        Ok(Self::new(result)?)\n    }\n\n    pub fn mul_par_mutex(&self, other: &Self) -> Result<Self, String> {\n        if self.cols != other.rows {\n            return Err(format!(\n                    \"Invalid matrix dimensions. \\\n                    The number of columns of the first matrix should be equal to the number of rows \\\n                    of the second matrix. Got {} and {} instead.\",\n                self.cols, other.rows,\n            ));\n        }\n\n        let num_threads = num_cpus::get();\n        let result = Mutex::new(vec![vec![0.0; other.cols]; self.rows]);\n        let chunk_size: usize = (self.rows as f32 / num_threads as f32).ceil() as usize;\n\n        thread::scope(|s| {\n            for th in 0..num_threads {\n                let start = th * chunk_size;\n                if start >= self.rows {\n                    break;\n                };\n                let result = &result;\n                let self_data = &self.data;\n                let other_data = &other.data;\n\n                let is_last_thread = th == num_threads - 1;\n                let end = if is_last_thread {\n                    self.rows\n                } else {\n                    (th + 1) * chunk_size\n                };\n\n                let other_cols = other.cols;\n                let self_cols = self.cols;\n\n                s.spawn(move || {\n                    for row_a in start..end {\n                        for col_b in 0..other_cols {\n                            let mut sum = 0.0;\n                            for i in 0..self_cols {\n                                sum += self_data[row_a][i] * other_data[i][col_b];\n                            }\n                            result.lock().unwrap()[row_a][col_b] = sum;\n                        }\n                    }\n                });\n            }\n        });\n\n        let result = result.into_inner().unwrap();\n        Ok(Self::new(result)?)\n    }\n\n    pub fn mul_par_split_at_mut(&self, other: &Self) -> Result<Self, String> {\n        if self.cols != other.rows {\n            return Err(format!(\n                    \"Invalid matrix dimensions. \\\n                    The number of columns of the first matrix should be equal to the number of rows \\\n                    of the second matrix. Got {} and {} instead.\",\n                self.cols, other.rows,\n            ));\n        }\n\n        let num_threads = num_cpus::get();\n        let mut result = vec![vec![0.0; other.cols]; self.rows];\n        let chunk_size: usize = (self.rows as f32 / num_threads as f32).ceil() as usize;\n\n        thread::scope(|s| {\n            let mut offset = 0;\n            let mut leftover_result = result.as_mut_slice();\n\n            for _ in 0..num_threads {\n                let split_pos = chunk_size.min(leftover_result.len());\n                let result;\n                (result, leftover_result) = leftover_result.split_at_mut(split_pos);\n\n                let start = offset;\n                offset += result.len();\n\n                let self_data = &self.data;\n                let other_data = &other.data;\n\n                let end = start + result.len();\n\n                let other_cols = other.cols;\n                let self_cols = self.cols;\n\n                s.spawn(move || {\n                    for row_a in start..end {\n                        for col_b in 0..other_cols {\n                            let mut sum = 0.0;\n                            for i in 0..self_cols {\n                                sum += self_data[row_a][i] * other_data[i][col_b];\n                            }\n                            result[row_a - start][col_b] = sum;\n                        }\n                    }\n                });\n            }\n        });\n\n        Ok(Self::new(result)?)\n    }\n\n    pub fn mul_par_rayon(&self, other: &Self) -> Result<Self, String> {\n        if self.cols != other.rows {\n            return Err(format!(\n                    \"Invalid matrix dimensions. \\\n                    The number of columns of the first matrix should be equal to the number of rows \\\n                    of the second matrix. Got {} and {} instead.\",\n                self.cols, other.rows,\n            ));\n        }\n\n        let mut result = vec![vec![0.0; other.cols]; self.rows];\n\n        result.par_iter_mut().enumerate().for_each(|(row_a, data)| {\n            for col_b in 0..other.cols {\n                for i in 0..self.cols {\n                    data[col_b] += self.data[row_a][i] * other.data[i][col_b];\n                }\n            }\n        });\n\n        Ok(Self::new(result)?)\n    }\n}\n```\n\n\n```\nbench/matmul.rs```\n\n\n```\nuse std::hint::black_box;\n\nuse criterion::{criterion_group, criterion_main, Criterion};\nuse rand::prelude::*;\n\nuse rust_playground::RsMatrix;\n\npub fn create_random_matrix(x: usize, y: usize) -> RsMatrix {\n    let mut rng = rand::thread_rng();\n    let data: Vec<Vec<f64>> = (0..y)\n        .map(|_| {\n            let mut row = vec![0.0; x];\n            rng.fill(row.as_mut_slice());\n            row\n        })\n        .collect();\n\n    RsMatrix::new(data).unwrap()\n}\n\nmacro_rules! do_bench {\n    ($c:expr, $name:ident, $m1:expr, $m2:expr) => {{\n        let correct = $m1.mul(&$m2).unwrap();\n        assert_eq!(correct, $m1.$name(&$m2).unwrap());\n        $c.bench_function(stringify!($name), |b| {\n            b.iter(|| black_box($m1.$name(&$m2).unwrap()))\n        });\n    }};\n}\n\npub fn criterion_benchmark(c: &mut Criterion) {\n    let matrix1 = black_box(create_random_matrix(100, 100));\n    let matrix2: RsMatrix = black_box(create_random_matrix(100, 100));\n\n    do_bench!(c, mul, matrix1, matrix2);\n    do_bench!(c, mul_par_mutex, matrix1, matrix2);\n    do_bench!(c, mul_par_split_at_mut, matrix1, matrix2);\n    do_bench!(c, mul_par_rayon, matrix1, matrix2);\n}\n\ncriterion_group!(benches, criterion_benchmark);\ncriterion_main!(benches);\n```\n\n```\nmul                     time:   [3.4327 ms 3.4607 ms 3.4960 ms]\nmul_par_mutex           time:   [3.2972 ms 3.3377 ms 3.3880 ms]\nmul_par_split_at_mut    time:   [3.1037 ms 3.1472 ms 3.2026 ms]\nmul_par_rayon           time:   [1.6733 ms 1.6939 ms 1.7222 ms]\n```\n\nWhat's the takeaway?\n\nThere isn't much to gain from parallelism in matrix-matrix-multiplication. Things like cache effects and memory throughput are most likely a higher contributor. Also, for larger matrices the strassen algorithm becomes a lot faster. Always optimize algorithmically before parallelizing.\nIf you parallelize, don't do it manually. Use an automatic load-balancing framework like ```\nrayon```\n.\n\nI hope you learned something :)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "8x8 float32_t Matrix multiplication using ARM NEON is slower?\r\n                \r\nI'm wondering what intrinsics make the SIMD slower than normal matrix multiplication and what should I do to make the multiplication of large matrix faster using SIMD.  Here we have ```\nmatrixA[8][8]```\n, ```\nmatrixB[8][8]```\n and result ```\nmatrixC[8][8]```\n. Because the maximum number of elements for float32_t is 4, so I did 2 vmul and vadd, which seem to be quite not optimized. I work on ARMv7-A Cortex A8.\n\n```\nvoid matrix_mult_neon (void)\n{\n    int i;\n\n    float32x4x2_t vectB1, vectB2, vectB3, vectB4, vectB5, vectB6, vectB7, vectB8;\n    vectB1 = vld2q_f32(matrixB[0]);\n    vectB2 = vld2q_f32(matrixB[1]);\n    vectB3 = vld2q_f32(matrixB[2]);\n    vectB4 = vld2q_f32(matrixB[3]);\n    vectB5 = vld2q_f32(matrixB[4]);\n    vectB6 = vld2q_f32(matrixB[5]);\n    vectB7 = vld2q_f32(matrixB[6]);\n    vectB8 = vld2q_f32(matrixB[7]);\n\n\n    float32x4x2_t vectT1, vectT2, vectT3, vectT4, vectT5, vectT6, vectT7, vectT8; \n    for (i = 0; i < 8; i++)\n    {\n        vectT1.val[0] = vmulq_n_f32(vectB1.val[0], matrixA[i][0]);\n        vectT1.val[1] = vmulq_n_f32(vectB1.val[1], matrixA[i][0]);\n        vectT2.val[0] = vmulq_n_f32(vectB2.val[0], matrixA[i][1]);\n        vectT2.val[1] = vmulq_n_f32(vectB2.val[1], matrixA[i][1]);\n        vectT3.val[0] = vmulq_n_f32(vectB3.val[0], matrixA[i][2]);\n        vectT3.val[1] = vmulq_n_f32(vectB3.val[1], matrixA[i][2]);\n        vectT4.val[0] = vmulq_n_f32(vectB4.val[0], matrixA[i][3]);\n        vectT4.val[1] = vmulq_n_f32(vectB4.val[1], matrixA[i][3]);\n        vectT5.val[0] = vmulq_n_f32(vectB5.val[0], matrixA[i][4]);\n        vectT5.val[1] = vmulq_n_f32(vectB5.val[1], matrixA[i][4]);\n        vectT6.val[0] = vmulq_n_f32(vectB6.val[0], matrixA[i][5]);\n        vectT6.val[1] = vmulq_n_f32(vectB6.val[1], matrixA[i][5]);\n        vectT7.val[0] = vmulq_n_f32(vectB7.val[0], matrixA[i][6]);\n        vectT7.val[1] = vmulq_n_f32(vectB7.val[1], matrixA[i][6]);\n        vectT8.val[0] = vmulq_n_f32(vectB8.val[0], matrixA[i][7]);\n        vectT8.val[1] = vmulq_n_f32(vectB8.val[1], matrixA[i][7]);\n\n\n        vectT1.val[0] = vaddq_f32(vectT1.val[0], vectT2.val[0]);\n        vectT1.val[0] = vaddq_f32(vectT1.val[0], vectT3.val[0]);\n        vectT1.val[0] = vaddq_f32(vectT1.val[0], vectT4.val[0]);\n        vectT1.val[0] = vaddq_f32(vectT1.val[0], vectT5.val[0]);\n        vectT1.val[0] = vaddq_f32(vectT1.val[0], vectT6.val[0]);\n        vectT1.val[0] = vaddq_f32(vectT1.val[0], vectT7.val[0]);\n        vectT1.val[0] = vaddq_f32(vectT1.val[0], vectT8.val[0]);\n\n        vectT1.val[1] = vaddq_f32(vectT1.val[1], vectT2.val[1]);\n        vectT1.val[1] = vaddq_f32(vectT1.val[1], vectT3.val[1]);\n        vectT1.val[1] = vaddq_f32(vectT1.val[1], vectT4.val[1]);\n        vectT1.val[1] = vaddq_f32(vectT1.val[1], vectT5.val[1]);\n        vectT1.val[1] = vaddq_f32(vectT1.val[1], vectT6.val[1]);\n        vectT1.val[1] = vaddq_f32(vectT1.val[1], vectT7.val[1]);\n        vectT1.val[1] = vaddq_f32(vectT1.val[1], vectT8.val[1]);\n\n        vst2q_f32(matrixC_neon[i], vectT1);\n    }\n}\n```\n\n\nMy normal matrix multiplication function:\n\n```\nvoid matrix_mult (void)\n{\n    float tempProduct;\n    int i, j, k;\n\n    for (i = 0; i < 8; i++)\n    {\n        for (j = 0; j < 8; j++)\n        {\n            tempProduct = 0;\n            for (k = 0; k < 8; k++)\n            {\n                tempProduct = tempProduct + matrixA[i][k] * matrixB[k][j];\n            }\n            matrixC[i][j] = tempProduct;\n        }\n    }\n}\n```\n\n\nI use ```\ngettimeofday()```\n function in the library ```\n<sys/time.h>```\n to calculate time in nanoseconds.\n    ", "Answer": "\r\nThe Problem:\n\n\n```\naarch32```\n has a NEON register bank of the size 256bytes total\nA 8x8 float matrix is already 256bytes large, and you need three of them. (768)\nYou have to read the matrix B \"vertically\", which means it's physically impossible to do it the \"streaming\" way for maximum data locality.\nYou do vector-scalar multiply which takes four times as much total than vector-vector multiplication.\nYou load Mat A via ```\nVFP```\n. And ```\nVFP```\n on the ```\nCortex-A8```\n particularly is unbelievably slow, in addtion to the ```\nNEON```\n<->```\nVFP```\n switching overhead. Unlike auto-vectorization, intrinsic do pretty much everything the way you tell it to do. And you gave the wrong instruction.\n\n\nThe Solution:\n\nWe transpose matrix B and do dot-product math line by line.\n\nI hope the code below works for you, and if performance is crucial, consider writing in assembly since compilers aren't very trustworthy when it comes to NEON performance, even in intrinsics.\n\n```\nstatic __always_inline float32x2_t dotProduct(float32x4x2_t input1, float32x4x2_t input2)\n{\n    float32x2_t d0, d1;\n    float32x4_t q0;\n    input1.val[0] = vmulq_f32(input1.val[0], input2.val[0]);\n    input1.val[1] = vmulq_f32(input1.val[1], input2.val[1]);\n\n    q0 = vaddq_f32(input1.val[0], input1.val[1]);\n    d0 = vget_low_f32(q0);\n    d1 = vget_high_f32(q0);\n    d0 = vpadd_f32(d0, d1);\n    d0 = vpadd_f32(d0, d1);\n    return d0;\n}\n\nvoid matMulF_neon(float *pDst, float *pMatA, float *pMatB)\n{\n    float32x4x4_t   line01, line23, line45, line67;\n    float32x4x2_t   b[8], *pA, *pB, temp;\n    float32x2x4_t   result;\n    uint32_t        i;\n\n    // vld4 for easier transpose\n    line01 = vld4q_f32(pMatB++);\n    line23 = vld4q_f32(pMatB++);\n    line45 = vld4q_f32(pMatB++);\n    line67 = vld4q_f32(pMatB);\n\n    // transpose MatB\n    vuzpq_f32(line01.val[0], line45.val[0]);\n    vuzpq_f32(line01.val[1], line45.val[1]);\n    vuzpq_f32(line01.val[2], line45.val[2]);\n    vuzpq_f32(line01.val[3], line45.val[3]);\n\n    vuzpq_f32(line23.val[0], line67.val[0]);\n    vuzpq_f32(line23.val[1], line67.val[1]);\n    vuzpq_f32(line23.val[2], line67.val[2]);\n    vuzpq_f32(line23.val[3], line67.val[3]);\n\n    // store MatB to stack\n    b[0].val[0] = line01.val[0];\n    b[0].val[1] = line01.val[1];\n    b[1].val[0] = line01.val[2];\n    b[1].val[1] = line01.val[3];\n    b[2].val[0] = line23.val[0];\n    b[2].val[1] = line23.val[1];\n    b[3].val[0] = line23.val[2];\n    b[3].val[1] = line23.val[3];\n\n    b[4].val[0] = line45.val[0];\n    b[4].val[1] = line45.val[1];\n    b[5].val[0] = line45.val[2];\n    b[5].val[1] = line45.val[3];\n    b[6].val[0] = line67.val[0];\n    b[6].val[1] = line67.val[1];\n    b[7].val[0] = line67.val[2];\n    b[7].val[1] = line67.val[3];\n\n    pA = (float32x4x2_t *) pMatA;\n    i = 8;\n    do\n    {\n        // just the right amount of data for aarch32 NEON register bank size\n        pB = b;\n        temp = *pA++;\n        result.val[0] = dotProduct(*pB++, temp);\n        result.val[1] = dotProduct(*pB++, temp);\n        result.val[2] = dotProduct(*pB++, temp);\n        result.val[3] = dotProduct(*pB++, temp);\n        vst4_lane_f32(pDst++, result, 0);\n\n        result.val[0] = dotProduct(*pB++, temp);\n        result.val[1] = dotProduct(*pB++, temp);\n        result.val[2] = dotProduct(*pB++, temp);\n        result.val[3] = dotProduct(*pB, temp);\n        vst4_lane_f32(pDst++, result, 0);\n    } while (--i);\n}\n```\n\n\n/////////////////////////// EDIT\n\nI checked the disassembly and the generated code is FUBAR. (Linaro GCC 7.1.1)\n\nI'd go the assembly route. Writing NEON codes in intrinsics is pure waste of time IMO.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Why does matrix multiplication in NumPy not call the __add__ method?\r\n                \r\nHow does the method ```\n__mul__```\n in the class ```\nmatrix```\n in NumPy work?\nI want to implement a binary matrix multiplication, and I have a class ```\nBinary```\n:\n```\nclass Binary(int):\n    def __init__(self, val):\n        if val != 0:\n            self.val = 1\n        else:\n            self.val = 0\n\n    def __add__(self, other):\n        print('add')\n        return self.val ^ other\n\n    def __radd__(self, other):\n        print('radd')\n        return self.val ^ other\n```\n\nMy test:\n```\nfrom Binary import Binary\nfrom numpy import matrix\n\ni = Binary(1)\no = Binary(0)\na = matrix([i, i, o, i, i, o, o], dtype=Binary)\nb = matrix([[o, o, i],\n           [o, i, o],\n           [o, i, i],\n           [i, o, o],\n           [i, o, i],\n           [i, i, o],\n           [i, i, i]], dtype=Binary)\nprint(a * b)\n```\n\nResult:\n```\n./test.py\n[[2 1 2]]\n```\n\nThe method ```\n__add__```\n is not used. Whereas there is a summation in matrix multiplication.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Efficient way to perform matrix multiplication repeatedly\r\n                \r\nI am trying to do the matrix multiplication ```\nS_g```\n for each i, and each g with i. This is what I have tried so far, but it takes a huge amount of time to complete. Is there a more computationally efficient method to do exactly the same thing?\n\nThe main thing to note from this formula is the ```\nS_g```\n uses X_gamma and Y[,i] in matrix multiplication set-up. X_gamma is dependent on value ```\ng```\n. Therefore, for each i, I have to perform ```\ng```\n matrix multiplications.\n\nHere is the logic:\n\n\nFor each i, the computation needs to be done for each g. Then, for each g, X_gamma is selected as a subset of X. Here is how X_gamma is determined. Let's take g = 3. When we look at 'set[3,]', we have that column B is the only one with value != 0. Therefore, I select the column B in X, and that would be X_gamma.\n\n\nMy main problem is that IN REALITY, ```\ng = 13,000```\n, and ```\ni = 700```\n.\n\n```\n library(foreach)\n library(doParallel) ## parallel backend for the foreach function\n registerDoParallel()\n\n T = 3\n c = 100\n\n X <- zoo(data.frame(A = c(0.1, 0.2, 0.3), B = c(0.4, 0.5, 0.6), C = c(0.7,0.8,0.9)),\n     order.by = seq(from = as.Date(\"2013-01-01\"), length.out = 3, by = \"month\")) \n\n Y <- zoo(data.frame(Stock1 = rnorm(3,0,0.5), Stock2 = rnorm(3,0,0.5), Stock3 = rnorm(3,0,0.5)), \n    order.by = seq(from = as.Date(\"2013-01-01\"), length.out = 3, by = \"month\"))\n\n l <- rep(list(0:1),ncol(X))\n set = do.call(expand.grid, l)\n colnames(set) <- colnames(X)\n\n I = diag(T)\n\n\n denom <- foreach(i=1:ncol(Y)) %dopar% {    \n    library(zoo)\n    library(stats)\n    library(Matrix)\n    library(base)\n\n    result = c()\n    for(g in 1:nrow(set)) {\n        X_gamma = X[,which(colnames(X) %in% colnames(set[which(set[g,] != 0)]))]\n        S_g = Y[,i] %*% (I - (c/(1+c))*(X_gamma %*% solve(crossprod(X_gamma)) %*% t(X_gamma))) %*% Y[,i] \n        result[g] = ((1+c)^(-sum(set[g,])/2)) * ((S_g)^(-T/2))\n    }\n    sum(result) \n }\n```\n\n\nThank you for your help!\n    ", "Answer": "\r\nThe most obvious problem is that you fell victim to one of the classic blunders: not preallocating the output vector ```\nresult```\n.  Appending one value at a time can be very inefficient for large vectors.\n\nIn your case, ```\nresult```\n doesn't need to be a vector: you can accumulate the results in a single value:\n\n```\nresult = 0\nfor(g in 1:nrow(set)) {\n    # snip\n    result = result + ((1+c)^(-sum(set[g,])/2)) * ((S_g)^(-T/2))\n}\nresult\n```\n\n\nBut I think the most important performance improvement that you could make is to precompute expressions that are currently being computed repeatedly in the ```\nforeach```\n loop.  You can do that with a separate ```\nforeach```\n loop.  I also suggest using ```\nsolve```\n differently to avoid the second matrix multiplication:\n\n```\nX_gamma_list <- foreach(g=1:nrow(set)) %dopar% {\n  X_gamma <- X[, which(set[g,] != 0)]\n  I - (c/(1+c)) * (X_gamma %*% solve(crossprod(X_gamma), t(X_gamma)))\n}\n```\n\n\nThese computations are now performed only once, rather than once for each column of ```\nY```\n, which is 700 times less work in your case.\n\nIn a similar vein, it makes sense to factor out the expression ```\n((1+c)^(-sum(set[g,])/2))```\n, as suggested by tim riffe, as well as ```\n-T / 2```\n while we're at it:\n\n```\na <- (1+c) ^ (-rowSums(set) / 2)\nnT2 <- -T / 2\n```\n\n\nTo iterate over the columns of the ```\nzoo```\n object ```\nY```\n, I suggest using the ```\nisplitCols```\n function from the ```\nitertools```\n package.  Make sure you load ```\nitertools```\n at the top of your script:\n\n```\nlibrary(itertools)\n```\n\n\n```\nisplitCols```\n let's you send only the columns that are needed for each task, rather than sending the entire object to all workers.  The only trick is that you need to remove the ```\ndim```\n attribute from the resulting ```\nzoo```\n objects for your code to work, since ```\nisplitCols```\n uses ```\ndrop=TRUE```\n.\n\nFinally, here's the main ```\nforeach```\n loop:\n\n```\ndenom <- foreach(Yi=isplitCols(Y, chunkSize=1), .packages='zoo') %dopar% {\n  dim(Yi) <- NULL  # isplitCols uses drop=FALSE\n  result <- 0\n  for(g in seq_along(X_gamma_list)) {\n    S_g <- Yi %*% X_gamma_list[[g]] %*% Yi\n    result <- result + a[g] * S_g ^ nT2\n  }\n  result\n}\n```\n\n\nNote that I would not perform the inner loop in parallel.  That would only make sense if there weren't enough columns in ```\nY```\n to keep all of your processors busy.  Parallelizing the inner loop could result in tasks that are too short, effectively unchunking the computation and making the code run much slower.  It's much more important to perform the inner loop efficiently since ```\ng```\n is large.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Precision error on matrix multiplication\r\n                \r\nCoding a matrix multiplication in my program, I get precision errors (inaccurate results for large matrices).\n\nHere's my code. The current object has data stored in a flattened array, row after row. Other matrix B has data stored in a flattened array, column after column (so I can use pointer arithmetic).\n\n```\nprotected double[,] multiply (IMatrix B)\n{\n    int columns = B.columns;\n    int rows = Rows;\n    int size = Columns;\n\n    double[,] result = new double[rows,columns];\n    for (int row = 0; row < rows; row++)\n    {\n       for (int col = 0; col < columns; col++)\n       {\n           unsafe\n           {\n               fixed (float* ptrThis = data)\n               fixed (float* ptrB = B.Data)\n               {\n                   float* mePtr = ptrThis + row*rows;\n                   float* bPtr = ptrB + col*columns;\n                   double value = 0.0;\n                   for (int i = 0; i < size; i++)\n                   {\n                       value += *(mePtr++) * *(bPtr++);\n                   }\n                   result[row, col] = value;\n               }\n           }\n       }\n    }\n}\n```\n\n\nActually, the code is a bit more complicated : I do the multiply thing for several chunks (so instead of having i from 0 to size, I go from localStart to localStop), then sum up the resulting matrices.\n\nMy problem : for a big matrix I get precision error :\n\n```\nNUnit.Framework.AssertionException: Error at (0,1)\n    expected: <6.4209571409444209E+18>\n     but was: <6.4207619776304906E+18>\n```\n\n\nAny idea ?\n    ", "Answer": "\r\nPerhaps all you have to do is use Kahan summation. But you can never expect to get exactly a specific result with floating-point math.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Parallel Matrix Multiplication using TPL\r\n                \r\nOf the different ways to implement matrix multiplication code in TPL using Parallel.For, what will provide better speedup of the following schemes (assume you have an 8-core machine and matrix size to be multiplied is at least 5000x5000). \n1. Only the outer loop i is implemented as Parallel.For.\n2. Only the inner loop k is implement as Parallel.For.\n3. All three loops i, j, k are implemented as Parallel.For.\n\nCode:\n\n```\nParallel.For (0, n, i =>\n{\n   for (int j = 0; j < n; j++)\n   {\n      for (int k = 0; k < n; k++)\n      C[i, j] += A[i, k] * B[k, j];\n   }\n});\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Why does matrix multiplication in NumPy not call the __add__ method?\r\n                \r\nHow does the method ```\n__mul__```\n in the class ```\nmatrix```\n in NumPy work?\nI want to implement a binary matrix multiplication, and I have a class ```\nBinary```\n:\n```\nclass Binary(int):\n    def __init__(self, val):\n        if val != 0:\n            self.val = 1\n        else:\n            self.val = 0\n\n    def __add__(self, other):\n        print('add')\n        return self.val ^ other\n\n    def __radd__(self, other):\n        print('radd')\n        return self.val ^ other\n```\n\nMy test:\n```\nfrom Binary import Binary\nfrom numpy import matrix\n\ni = Binary(1)\no = Binary(0)\na = matrix([i, i, o, i, i, o, o], dtype=Binary)\nb = matrix([[o, o, i],\n           [o, i, o],\n           [o, i, i],\n           [i, o, o],\n           [i, o, i],\n           [i, i, o],\n           [i, i, i]], dtype=Binary)\nprint(a * b)\n```\n\nResult:\n```\n./test.py\n[[2 1 2]]\n```\n\nThe method ```\n__add__```\n is not used. Whereas there is a summation in matrix multiplication.\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "How to implement a matrix multiplication in Keras?\r\n                \r\nI just want to implement a function that given a matrix X returns the covariance matrix of X (X^T*X), which is just a simple matrix multiplication.\n\nIn Tensorflow it's gonna be easy: tf.matmul(X, tf.transpose(X))\n\nBut I didn't expect that it's a nightmare with Keras. The APIs in Keras like multiply and dot don't fit my request. I also tried different ways (Lambda layer and mixed with TF operations) but still failed, occurred lots of errors.\n\nHope someone may help. Thanks.\n    ", "Answer": "\r\nActually you do have the analogous in Keras. Try ```\ndot(x, transpose(x))```\n.\n\nA working example comparing the two platforms follows.\n\n```\nimport keras.backend as K\nimport numpy as np\nimport tensorflow as tf\n\n\ndef cov_tf(x_val):\n    x = tf.constant(x_val)\n    cov = tf.matmul(x, tf.transpose(x))\n    return cov.eval(session=tf.Session())\n\ndef cov_keras(x_val):\n    x = K.constant(x_val)\n    cov = K.dot(x, K.transpose(x))\n    return cov.eval(session=tf.Session())\n\nif __name__ == '__main__':\n    x = np.random.rand(4, 5)\n    delta = np.abs(cov_tf(x) - cov_keras(x)).max()\n    print('Maximum absolute difference:', delta)\n```\n\n\nThe maximum absolute difference is printed and gives me something around ```\n1e-7```\n.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "armadillo complex matrix multiplication early approximation\r\n                \r\nHow can I increase the precision of armadillo complex matrix multiplication result. It approximates at 4 decimal place [ this is an example of the result (35.9682,-150.246) ] but i wanted a precision of atleast 8 decimal places. Thanks\n    ", "Answer": "\r\nAs you don't seem to believe what I said in the comments:\n\n```\n#include <armadillo>\n\nusing namespace std;\nusing namespace arma;\n\nint main(int argc, char** argv) {\n  mat A = randu<mat>(4,5);\n  mat B = randu<mat>(4,5);\n\n  mat C = A*B.t();\n  cout << C << endl;\n\n  cout.precision(11);\n  cout.setf(ios::fixed);\n  C.raw_print(cout, \"With increased precisions:\");\n\n  return 0;\n}\n```\n\n\nwhich does as expected:\n\n```\nedd@max:/tmp$ g++ -o eze eze.cpp -larmadillo -lblas -llapack \nedd@max:/tmp$ ./eze  \n   0.9713   1.3566   0.7946   1.6896\n   1.2593   1.1457   0.9011   1.6260\n   1.1954   0.8484   1.0444   1.6753\n   1.6225   1.5009   1.2935   2.2019\n\nWith increased precisions:\n0.97126557882 1.35660885673 0.79462856896 1.68955180769\n1.25933041551 1.14565671740 0.90105251304 1.62595390611\n1.19543745264 0.84844286454 1.04436441020 1.67528315350\n1.62246223165 1.50087016389 1.29351914350 2.20190979625\nedd@max:/tmp$ \n```\n\n\nMorale: printed precision is almost never computed precision.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Draw a vector field from matrix multiplication r\r\n                \r\nI'm trying to print a vector field based on a matrix multiplication. The problem is that the function that will print values to make the matrix multiplication can only take a single number. When a range of number is put into the ```\nall.p```\n function, the output is not usable to do the matrix multiplication. Is there a way to change ```\nall.p```\n so that with multiple inputs, the matrix multiplication can still be valid, and the vector field can be computed? The code fails at the ```\nvectorfield```\n function as this function with put the values into the range 0 to 1, but the ```\nall.p```\n can't take multiple inputs.\n```\ngeno.fit = matrix(c(0.791,1.000,0.834,\n                    0.670,1.006,0.901,\n                    0.657,0.657,1.067), \n                  nrow = 3, \n                  ncol = 3,\n                  byrow = T)\n\nall.p <- function(p) {\n  if (length(p)>1) {\n    stop(\"More numbers in input than expected\")\n  }\n  P = p^2\n  PQ = 2*p*(1-p)\n  Q = (1-p)^2  \n  return(list=c(P=P,PQ=PQ,Q=Q))\n}\n\n\n\nlibrary(pracma)\nf <- function(x, y) all.p(x) %*% geno.fit %*% all.p(y)\nxx <- c(0, 1); yy <- c(0, 1)\n\nvectorfield(fun = f, xlim = xx, ylim = yy, scale = 0.1)\n\nfor (xs in seq(0, 1, by = 0.25)) {\n  sol <- rk4(f, 0, 1, xs, 100)\n  lines(sol$x, sol$y, col=\"darkgreen\")\n}\ngrid()\n```\n\nI also tried to use a for loop.\n```\nf <- function(x, y, n = 16) {\n  space3 = matrix(NA,nrow = n,ncol = n)\n  for (i in 1:(length(x))) {\n    for (j in 1:(length(y))) {\n      # Calculate mean fitness \n      space3[i,j] = all.p(x[i]) %*% geno.fit %*% all.p(y[j])\n    }\n  }\n  return(space3)\n  }\nxx <- c(0, 1); yy <- c(0, 1)\nf(seq(0,1,length.out = 16), seq(0,1,length.out = 16))\nvectorfield(fun = f, xlim = xx, ylim = yy, scale = 0.1)\n```\n\nBelow is the code to make the gradient ascend (without the vectors).\n```\nlibrary(fields) # for image.plot \nres = 0.01\nseq.x = seq(0,1,by = res)\nspace = outer(seq.x,seq.x,\"*\") \n\npace2 = space\nfor (i in 1:length(seq.x)) {\n  for (j in 1:length(seq.x)) {\n    space[i,j] = all.p(1-seq.x[i]) %*% geno.fit %*% all.p(1-seq.x[j])\n  }\n}\nround(t(space),3)\nnew.space = t(space)\nimage.plot(new.space)\nby.text = 8\nfor (i in seq(1,length(seq.x),by = by.text)) {\n  for (j in seq(1,length(seq.x),by = by.text)) {\n    text(seq.x[i],seq.x[j],\n         labels = round(new.space[i,j],4),\n         cex = new.space[i,j]/2, \n         col = \"black\")\n  }\n}\ncontour(new.space,ylim=c(1,0),add = T, nlevels = 50)\n```\n\n\nI was able to make the vector field function work, but it's not showing what I was expecting from the previous gradient ascend vector field:\n\nHow can the 2 be reconciled? (i.e., plotting the vectors on the gradient ascend image which would show the proper direction of the vectors in the steepest ascend)\n    ", "Answer": "\r\nHere is my solution:\n```\nlibrary(fields) # for image.plot \nlibrary(plotly)\nlibrary(raster)\n\n# Genotype fitness matrix -------------------------------------------------\ngeno.fit = matrix(c(0.791,1.000,0.834,\n                    0.670,1.006,0.901,\n                    0.657,0.657,1.067), \n                  nrow = 3, \n                  ncol = 3,\n                  byrow = T)\n# Resolution \nres = 0.01\n# Sequence of X \nseq.x = seq(0,1,by = res)\n# Make a matrix \nspace = outer(seq.x,seq.x,\"*\") \n\n# Function to calculate the AVERAGE fitness for a given frequency of an allele to get the expected frequency of genotypes in a population\nall.p <- function(p) { # Takes frequency of an allele in the population \n  if (length(p)>1) { # Has to be only 1 number \n    stop(\"More numbers in input than expected\")\n  }\n  P = p^2 # Gets the AA \n  PQ = 2*p*(1-p) # gets the Aa\n  Q = (1-p)^2 # Gets the aa \n  return(list=c(P=P, # Return the values \n                PQ=PQ,\n                Q=Q)) \n}\n# Examples \nall.p(0)\nall.p(1)\n# Plot the matrix of all combinations of genotype frequencies\nimage.plot(space,\n           ylim=c(1.05,-0.05), \n           ylab= \"Percentage of Chromosome EF of TD form\",\n           xlab= \"Percentage of Chromosome CD of BL form\")\n# Backup the data \nspace2 = space\n# calculate the average fitness for EVERY combination of frequency of 2 genotypes \nfor (i in 1:length(seq.x)) {\n  for (j in 1:length(seq.x)) {\n    # Calculate mean fitness \n    space[i,j] = all.p(1-seq.x[i]) %*% geno.fit %*% all.p(1-seq.x[j])\n  }\n}\n# Show the result \nround(t(space),3)\n\n# Transform the space\nnew.space = t(space)\nimage.plot(new.space, \n           # ylim=c( 1.01,-0.01), \n           ylab= \"Percentage of Chromosome EF of TD (Tidbinbilla) form\",\n           xlab= \"Percentage of Chromosome CD of BL (Blundell) form\")\n# Add the numbers to get a better sense of the average fitness values at each point \nby.text = 8\nfor (i in seq(1,length(seq.x),by = by.text)) {\n  for (j in seq(1,length(seq.x),by = by.text)) {\n    text(seq.x[i],seq.x[j],\n         labels = round(new.space[i,j],4),\n         cex = new.space[i,j]/2, \n         col = \"black\") # col = \"gray70\"\n  }\n}\n# Add contour lines \ncontour(new.space,ylim=c(1,0),add = T, nlevels = 50)\n\n# Plotly 3D graph  --------------------------------------------------------\n# To get the 3D plane in an INTERACTIVE graph \nxyz=cbind(expand.grid(seq.x,\n                      seq.x),\n          as.vector(new.space))\n\nplot_ly(x = xyz[,1],y = xyz[,2],z = xyz[,3],\n        color = xyz[,3])\n\n\n# Vector field on the Adaptive landscape ----------------------------------\nlibrary(tidyverse)\nlibrary(ggquiver)\nraster2quiver <- function(rast, aggregate = 50, colours = terrain.colors(6), contour.breaks = 200)\n{\n  names(rast) <- \"z\"\n  quiv <- aggregate(rast, aggregate)\n  terr <- terrain(quiv, opt = c('slope', 'aspect'))\n  quiv$u <- -terr$slope[] * sin(terr$aspect[])\n  quiv$v <- -terr$slope[] * cos(terr$aspect[])\n  quiv_df <- as.data.frame(quiv, xy = TRUE)\n  rast_df <- as.data.frame(rast, xy = TRUE)\n  \n  print(ggplot(mapping = aes(x = x, y = y, fill = z)) + \n          geom_raster(data = rast_df, na.rm = TRUE) + \n          geom_contour(data = rast_df, \n                       aes(z=z, color=..level..),\n                       breaks = seq(0,3, length.out = contour.breaks), \n                       size = 1.4)+\n          scale_color_gradient(low=\"blue\", high=\"red\")+\n          geom_quiver(data = quiv_df, aes(u = u, v = v), vecsize = 1.5) +\n          scale_fill_gradientn(colours = colours, na.value = \"transparent\") +\n          theme_bw())\n  \n  return(quiv_df)\n}\n\nr <-raster(\n  space,\n  xmn=range(seq.x)[1], xmx=range(seq.x)[2],\n  ymn=range(seq.x)[1], ymx=range(seq.x)[2],\n  crs=CRS(\"+proj=utm +zone=11 +datum=NAD83\")\n)\n\n# Draw the adaptive landscape\nraster2quiver(rast = r, aggregate = 2, colours = tim.colors(100)) \n```\n\nNot exactly what I wanted, but it does what I was looking for!\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "cpumemory.pdf - cache optimized matrix multiplication\r\n                \r\nI'm reading cpumemory.pdf from\nUlrich Drepper and I'm unable to understand following part about optimizing\ncache access in matrix multiplication from chapter 6.2.1 (page 49-50):\n\nFirst naive method for matrix multiplication is shown:\n\n```\nfor (i = 0; i < N; ++i)\n    for (j = 0; j < N; ++j)\n        for (k = 0; k < N; ++k)\n            res[i][j] += mul1[i][k] * mul2[k][j];\n```\n\n\n```\nmul2```\n is accessed by columns so for each column one cache line is wasted. Ulrich says:\n\n\n  With sizeof(double) being 8 this means that, to fully utilize the cache line,\n  we should unroll the middle loop 8 times.\n\n\nFor brevity I unrolled middle loop only 2 times.\n\n```\nfor (i = 0; i < N; ++i)\n    for (j = 0; j < N; j += 2)\n        for (k = 0; k < N; ++k) {\n            res[i][j+0] += mul1[i][k] * mul2[k][j+0];\n            res[i][j+1] += mul1[i][k] * mul2[k][j+1];\n        }\n```\n\n\nNow it's obvious that if cache line is 2 double values wide it'll be fully\nutilized. But then Ulrich continues:\n\n\n  Continuing this thought, to effectively use the res matrix as well, i.e., to\n  write 8 results at the same time, we should unroll the outer loop 8 times as\n  well. \n\n\nFor brevity I unrolled outer loop only 2 times again.\n\n```\nfor (i = 0; i < N; i += 2)\n    for (j = 0; j < N; j+=2)\n        for (k = 0; k < N; ++k) {\n            res[i+0][j+0] += mul1[i+0][k] * mul2[k][j+0];\n            res[i+0][j+0] += mul1[i+0][k] * mul2[k][j+0];\n            res[i+1][j+0] += mul1[i+1][k] * mul2[k][j+0];\n            res[i+1][j+1] += mul1[i+1][k] * mul2[k][j+1];\n        }\n```\n\n\nTo me it seems even worse than previous version because now ```\nmul1```\n is accessed\nby columns. Please explain what Ulrich meant.\n    ", "Answer": "\r\nThere are three matrices inside the cache: the left input, the right input and the result.\n\nThe left input is accessed just fine by original code because it is row-major, and the innermost loop increments k, so it marches down the cache line..  the second matrix is accessed well by the single unrolling, because now all the columns in a cache line are used before the cache line is evicted..  \n\nThe question is the result matrix..  it is also row-major, but the cache line is indexed by j, not by k..  and you are right..  j has already been unrolled, so it uses all the elements on a cache line within the result matrix..  so there doesn't appear to be anything gained by the second unrolling..  all it does is add two extra cache lines.. an extra for the left matrix and an extra for the result matrix!  It doesn't improve the coverage of elements of any cache lines!\n\nHowever, it does happen to reuse the right matrix's cache line twice.. that reduces the total number of times the lines of the right matrix have to be brought in..  and it does not increase the number of times the left and right matrix cache lines will be brought in..  so perhaps that reuse of the entire line is where the advantage comes from..  I guess the question is whether this is properly blocked to the cache size, and what the set associativity of the cache is..  if all lines of all three matrices stay in the cache, then this has no advantage..  (but it doesn't make anything worse!) \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication: Strassen vs. Standard\r\n                \r\nI tried to implement the Strassen algorithm for matrix multiplication with C++, but the result isn't that, what I expected. As you can see strassen always takes more time then standard implementation and only with a dimension from a power of 2 is as fast as standard implementation. What went wrong?\n\n\n```\nmatrix mult_strassen(matrix a, matrix b) {\nif (a.dim() <= cut)\n    return mult_std(a, b);\n\nmatrix a11 = get_part(0, 0, a);\nmatrix a12 = get_part(0, 1, a);\nmatrix a21 = get_part(1, 0, a);\nmatrix a22 = get_part(1, 1, a);\n\nmatrix b11 = get_part(0, 0, b);\nmatrix b12 = get_part(0, 1, b);\nmatrix b21 = get_part(1, 0, b);\nmatrix b22 = get_part(1, 1, b);\n\nmatrix m1 = mult_strassen(a11 + a22, b11 + b22); \nmatrix m2 = mult_strassen(a21 + a22, b11);\nmatrix m3 = mult_strassen(a11, b12 - b22);\nmatrix m4 = mult_strassen(a22, b21 - b11);\nmatrix m5 = mult_strassen(a11 + a12, b22);\nmatrix m6 = mult_strassen(a21 - a11, b11 + b12);\nmatrix m7 = mult_strassen(a12 - a22, b21 + b22);\n\nmatrix c(a.dim(), false, true);\nset_part(0, 0, &c, m1 + m4 - m5 + m7);\nset_part(0, 1, &c, m3 + m5);\nset_part(1, 0, &c, m2 + m4);\nset_part(1, 1, &c, m1 - m2 + m3 + m6);\n\nreturn c; \n}\n```\n\n\n\nPROGRAM\nmatrix.h http://pastebin.com/TYFYCTY7 \nmatrix.cpp http://pastebin.com/wYADLJ8Y \nmain.cpp http://pastebin.com/48BSqGJr \n\n```\ng++ main.cpp matrix.cpp -o matrix -O3```\n.\n    ", "Answer": "\r\nSome thoughts:\n\n\nHave you optimized it to consider that a non-power of two sized matrix is filled in with zeroes? I think the algorithm assumes you don't bother multiplying these terms. This is why you get the flat areas where the running time is constant between 2^n and 2^(n+1)-1. By not multiplying terms you know are zero you should be able to improve these areas. Or perhaps Strassen is only meant to work with 2^n sized matrices.\nConsider that a \"large\" matrix is arbitrary and the algorithm is only slightly better than the naive case, O(N^3) vs O(N^2.8). You may not see measurable gains until bigger matrices are tried. For example, I was did some Finite Element modeling where 10,000x10,000 matrices were considered \"small\". Its hard to tell from your graph but it looks like the 511 case may be faster in the Stassen case.\nTry testing with various optimization levels including no optimizations at all.\nThis algorithm seems to assume that multiplications are much more expensive than additions. This was certainly true 40 years ago when it was first developed but I believe in more modern processors the difference between add and multiply has gotten smaller. This may reduce the effectiveness of the algorithm which seems to reduce multiplications but increase additions.\nHave you looked at some of the other Strassen implementations out there for ideas? Try benchmarking a known good implementation to see exactly how much faster you can get.\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Optimizing batched matrix multiplication opencl code\r\n                \r\nBelow is an opencl kernel which performs blocked matrix multiplication for multiple independent matrices. selectMatrixA and selectMatrixB store multiple matrices (same size and square matrices) in row major order. \n\n```\n// Matrix multiplication: C = A * B.\n\n\n#define BLOCK_SIZE 20\n#define MATRIX_SIZE 100 * 100\n\n#define BLOCK_DIMX 5 // Number of blocks in the x dimension\n\n__kernel void\nbatchedMatrixMul(__global float *selectMatrixC, __global float *selectMatrixA, __global   \nfloat *selectMatrixB, int wA, int wB)\n{\n    // Block index\n    int bx = get_group_id(0);\n    int by = get_group_id(1);\n\n\n    __global float *C = selectMatrixC + (bx/BLOCK_DIMX) * MATRIX_SIZE;\n    __global float *A = selectMatrixA + (bx/BLOCK_DIMX) * MATRIX_SIZE;\n    __global float *B = selectMatrixB + (bx/BLOCK_DIMX) * MATRIX_SIZE;\n\n\n\n    int tx = get_local_id(0);\n    int ty = get_local_id(1);\n\n    float Csub = 0;\n\n    // Identify the row and column of the C matrix to work on\n\n    int Row = (by * BLOCK_SIZE)  + ty;\n    int Col = ((bx %(BLOCK_DIMX)) * BLOCK_SIZE) + tx;\n\n    // Declaration of the local memory array As used to store the sub-matrix of A\n    __local float As[BLOCK_SIZE][BLOCK_SIZE];\n\n    // Declaration of the local memory array Bs used to store the sub-matrix of B\n    __local float Bs[BLOCK_SIZE][BLOCK_SIZE];\n\n    // Loop over all the sub-matrices of A and B required to compute the block sub-matrix\n    for (int m = 0; m < wA / BLOCK_SIZE; ++m) \n    {\n\n        // Load the matrices from global memory to local memory. Each thread loads one   \n        //element of each matrix\n        As[ty][tx] = A[Row * wA + m * BLOCK_SIZE + tx];\n        Bs[ty][tx] = B[(m * BLOCK_SIZE + ty)*wA + Col];\n\n        // Synchronize to make sure the matrices are loaded\n        barrier(CLK_LOCAL_MEM_FENCE);\n\n        // Multiply the two matrices together each thread computes one element of the block \n        //sub-matrix\n        for (int k = 0; k < BLOCK_SIZE; ++k)\n            Csub += As[ty][k] * Bs[k][tx];\n\n        // Synchronize to make sure that the preceding computation is done before loading \n        //two new sub-matrices of A and B in the next iteration\n        barrier(CLK_LOCAL_MEM_FENCE);\n\n    }\n\n    // Write the block sub-matrix to device memory each thread writes one element\n    C[Row * wA + Col] = Csub;\n\n}\n```\n\n\nHere is how I launch the kernel:\n\n```\nlocalWorkSize[0] = BLOCK_SIZE;\nlocalWorkSize[1] = BLOCK_SIZE;\n\n// for a 100 X 100 matrix, MATRIX_DIMX = MATRIX_DIMY = 100\nglobalWorkSize[0] = MATRIX_DIMX * NUM_MATRICES;\nglobalWorkSize[1] = MATRIX_DIMY ;\n\ncl_event             event;\nerrcode = clEnqueueNDRangeKernel(clCommandQueue, \n          clKernel, 2, NULL, globalWorkSize, \n          localWorkSize, 0, NULL, &event);\n```\n\n\nBelow are some performance numbers when running this on an NVIDIA Grid K520:\n\n```\n1. matrix size:100 X 100 . Number of matrices = 20000. Time taken for multiplication = \n0.262 seconds. As shown in the code, the block size was set to 20. Block size of 10 was \nslower. This calculates to around 152 GFLOPS\n\n2. matrix size: 10000 X 10000. Number of matrices = 1. Time taken for multiplication = 10.6 \nseconds. Here also the block size was 20. Using a block size of 50 is not possible due to   \nthe size of the local memory.\n```\n\n\nCan someone please help me to understand why the code is running slow, and why 2. is so much slower than 1. I am new to OpenCL, and I am wanting to learn how to optimize code based on the underlying architectural details.\n    ", "Answer": "\r\nThe reason why your first test is so much faster is because there is a difference in the amount of work each test is doing. Actually, a factor of 50x.\n\nBig-O for square matrix multiplication is O(n^3). See: why is the time complexity of square matrix multiplication defined as O(n^3)? As a result, the 10k squared matrix actually takes 1 million times more work to multiply than a single 100x100 multiplication. Your 20000 executions of the 100x100 multiplication does not make up for the massive amount of work needed to multiply the large matrices once.\n\nMatrix multiplication is just many dot-products.Your algorithm only breaks the dot products into groups to easy handling, and does not use any special tricks to reduce the numbers in my calculations below.\n\nFor your small matrix test:\n\n```\nTotal dot products: 10^4\nMADs per dot product: 10^2\nTotal matrix-multiply operations: 20000 = 2*10^4\nTotal multiply-adds: 2* 10^(4+2+4) = 2*10^10 = 20,000,000,000\n```\n\n\n20 Billion.\n\nLarge matrix test:\n\n```\nTotal dot products: 10^8\nMADs per dot product: 10^4\nTotal multiply operations: 1 (or 10^0)\nGrand total multiply-adds: 10 ^ (8 + 4 + 0) = 10^12 = 1,000,000,000,000  \n```\n\n\n1000 Billion.\n\nYour 10000x10000 test was technically running faster -- crunching 50x more operations in only 40x more run time.\n\nRead more about 'special tricks' here: http://en.wikipedia.org/wiki/Strassen_algorithm. Even though this algorithm is not considered practical for GPU computing. Mor complicated algorithms also exist, but the brute-force approach on graphics hardware seems to be used most often.\n\nWhy is your kernel running slowly in general? There are a number of different optimizations you can use to speed things up. Below are just a few you can google and experiment with yourself. You will probably come across some I haven't mentioned here.\n\n\nOptimize work group and block sizes. see opencl PREFERRED_WORK_GROUP_SIZE\nUse float4 datatype. opencl includes a dot product function which computes dot product for floatn datatypes.\nTranspose matrix B before running the kernel. you can use another kernel to do the transposition.\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "loop unrolling for matrix multiplication\r\n                \r\nI need to make a good implementation  for matrix multiplication better than the naive method \nhere is the methods i used :\n1- removed false dependencies which made the performance a lot better \n2- used a recursive approach\nand then there is something i need to try loop unrolling. The thing is each time i used it , it makes the performance worst i can't find an explanation for it \ni need help here is the code \n\n```\n for (i = 0; i < M; i++)\n    for (j = 0; j < N; j++) {\n    double sum = 0;\n        #pragma unroll(5)\n          for (k = 0; k < K; k++)\n        {\n        sum +=  A[i + k*LDA] * B[k + j*LDB];\n        }\n        C[i + j*LDC] = sum ;\n    }\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Batch matrix multiplication in Julia\r\n                \r\nI'm trying to multiply N-dimensional (N>=3) arrays in Julia as batches of matrices, i.e. perform matrix multiplication along the last two dimensions, keeping the other dimensions intact.\n\nFor example, if ```\nx```\n has dimensions ```\n(d1,d2,4,3)```\n and ```\ny```\n has dimensions ```\n(d1,d2,3,2)```\n, the result of the multiplication should have ```\n(d1,d2,4,2)```\n, i.e. a batch of matrix multiplications should be performed.\n\nThis is exactly what happens in Python's ```\nnumpy.matmul```\n:\n\n\n  If either argument is N-D, N > 2, it is treated as a stack of matrices residing in the last two indexes and broadcast accordingly.\n\n\n```\nnp.matmul(randn(10,10,4,3), randn(10,10,3,2)).shape\n(10, 10, 4, 2)\n```\n\n\nIs there a way to reproduce the behaviour of ```\nnumpy.matmul```\n in Julia?\n\nI hoped ```\n.*```\n would work, but:\n\n```\njulia> randn(10,10,4,3) .* randn(10,10,3,2)\nERROR: DimensionMismatch(\"arrays could not be broadcast to a common size\")\nStacktrace:\n [1] _bcs1 at ./broadcast.jl:485 [inlined]\n [2] _bcs at ./broadcast.jl:479 [inlined] (repeats 3 times)\n [3] broadcast_shape at ./broadcast.jl:473 [inlined]\n [4] combine_axes at ./broadcast.jl:468 [inlined]\n [5] instantiate at ./broadcast.jl:256 [inlined]\n [6] materialize(::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{4},Nothing,typeof(*),Tuple{Array{Float64,4},Array{Float64,4}}}) at ./broadcast.jl:798\n [7] top-level scope at REPL[80]:1\n```\n\n\nI understand a list comprehension might work in 3-D, but this would get really messy in higher dimensions. Is the best solution to reshape (or view) all but the last 2 dimensions, use a list comprehension, and reshape it back? Or is there a better way?\n\nP.S. The closest thing I could find was this, but it's not quite the same. New to Julia, so might be missing something obvious to Julia users.\n    ", "Answer": "\r\nI'm not aware of any such functionality, but there may well be in some package. I think that in Julia it's more natural to organize the data as arrays of matrices, and broadcast the matrix multiplication over them:\n\n```\nD = [rand(50, 60) for i in 1:4, j in 1:3]\nE = [rand(60, 70) for i in 1:4, j in 1:3]\nD .* E  # now you can use dot broadcasting!\n```\n\n\nThat said, it's easy to make your own. I would make one change, though. Julia is column major, while numpy is \"last dimension major\", therefore you should let the matrices resided along the first two dimensions, not the last two.\n\nFirst, I'll define an in-place method that multiplies into an array ```\nC```\n, and then a non-in-place method that calls the in-place version (I'll skip dimension checking etc):\n\n```\n# In-place version, note the use of the @views macro, \n# which is essential to get in-place behaviour\n\nusing LinearAlgebra: mul!  # fast in-place matrix multiply\n\nfunction batchmul!(C, A, B)\n    for j in axes(A, 4), i in axes(A, 3)\n        @views mul!(C[:, :, i, j], A[:, :, i, j], B[:, :, i, j])\n    end\n    return C\nend\n\n# The non-in-place version\nfunction batchmul(A, B)\n    T = promote_type(eltype(A), eltype(B))\n    C = Array{T}(undef, size(A, 1), size(B)[2:end]...)\n    return batchmul!(C, A, B)\nend\n```\n\n\nYou could also make it multi-threaded. On my computer 4 threads gives a 2.5x speedup (actually, for larger values of the last two dimensions, I get a 3.5x speedup) How much of a speedup you get depends on the sizes and shapes of the arrays involved:\n\n```\nfunction batchmul!(C, A, B)\n    Threads.@threads for j in axes(A, 4)\n        for i in axes(A, 3)\n            @views mul!(C[:, :, i, j], A[:, :, i, j], B[:, :, i, j])\n        end\n    end\n    return C\nend\n```\n\n\nEdit: I noticed just now that you want general N-D, not just 4-D. Shouldn't be too hard to generalize, though. Anyway, all the more reason to go for arrays of matrices, where broadcasting will automatically work for all dimensionalities. \n\nEdit2: Couldn't leave it, so here's one for the N-D case (there's still more to do, like handling non-1-based indexing (update: ```\naxes```\n should fix this)):\n\n```\nfunction batchmul!(C, A, B)\n    Threads.@threads for I in CartesianIndices(axes(A)[3:end])\n        @views mul!(C[:, :, Tuple(I)...], A[:, :, Tuple(I)...], B[:, :, Tuple(I)...])\n    end\n    return C\nend\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Retrieving documents based on matrix multiplication\r\n                \r\nI have a model that represents a collection of documents in multidimensional vector space. So, for example, for 100k documents, my model represents them in the form of 300 dimensional vectors. So, finally, I get a matrix of size ```\n[100K, 300]```\n. For retrieving those documents according to relevance to the given query,  I do matrix multiplication. For example, I represent a given query as a ```\n[300, 1]```\n. Then I get the cosine similarity scores using matrix multiplication as follows : \n```\n[100K, 300]*[300, 1] = [100K, 1]```\n. \nNow how can I retrieve top 1000 documents from this collection with highest cosine similarity. The trivial way would be to sort based on cosine similarity and grab the first 1000 docs. Is there any way to retrieve the documents this way using some function in pytorch? \n\nI mean, how can I get the indices of highest 1000 values from a 1D torch tensor?p\n    ", "Answer": "\r\nOnce you have the similarity scores after the dot product.\nyou can get the top 1000 indices as follows\n\n```\ntop_indices = torch.argsort(sims)[:1000]\nsimilar_docs = sims[top_indices]\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication using divide&conquer\r\n                \r\nI am working on a code to perform matrix multiplication using divide&conquer method. My code goes as this:\n\n```\n#include <stdio.h>\n#include <time.h>\n#include <stdlib.h>\n#define SIZE 8  //Able to change size\n\nvoid add(int **a, int **b, int size, int **c)\n{\n    int i, j;\n    for(i=0; i<size; i++)\n    {\n        for(j=0; j<size; j++)\n        {\n            c[i][j]=a[i][j]+b[i][j];\n        }\n    }\n}\n\nvoid subtract(int **a, int **b, int size, int **c)\n{\n    int i, j;\n    for(i=0; i<size; i++)\n    {\n        for(j=0; j<size; j++)\n        {\n            c[i][j]=a[i][j]-b[i][j];\n        }\n    }\n}\n\nvoid multiply(int **c, int **d, int size, int **result)\n{\n    if(size==1)\n    {\n        result[0][0]=c[0][0]*d[0][0]; /*Could this base case calculation be wrong?*/\n    }\n    else\n    {\n        int i, j;\n        int new_size=size/2;\n\n        int **c11=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            c11[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **c12=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            c12[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **c21=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            c21[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **c22=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            c22[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **d11=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            d11[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **d12=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            d12[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **d21=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            d21[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **d22=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            d22[i]=(int *)malloc(new_size*sizeof(int));\n        }\n\n        int **temp1=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            temp1[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **temp2=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            temp2[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **temp3=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            temp3[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **temp4=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            temp4[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **temp5=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            temp4[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **temp6=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            temp6[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **temp7=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            temp7[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **temp8=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            temp8[i]=(int *)malloc(new_size*sizeof(int));\n        }\n\n        int **res1=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            res1[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **res2=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            res2[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **res3=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            res3[i]=(int *)malloc(new_size*sizeof(int));\n        }\n        int **res4=(int **)malloc(new_size*sizeof(int *));\n        for(i=0; i<new_size; i++)\n        {\n            res4[i]=(int *)malloc(new_size*sizeof(int));\n        }\n\n        for(i=0; i<new_size; i++)\n        {\n            for(j=0; j<new_size; j++)\n            {\n                c11[i][j]=c[i][j];\n                c12[i][j]=c[i][j+new_size];\n                c21[i][j]=c[i+new_size][j];\n                c22[i][j]=c[i+new_size][j+new_size];\n                d11[i][j]=d[i][j];\n                d12[i][j]=d[i][j+new_size];\n                d21[i][j]=d[i+new_size][j];\n                d22[i][j]=d[i+new_size][j+new_size];\n            }\n        }\n\n        multiply(c11, d11, new_size, temp1);\n        multiply(c12, d21, new_size, temp2);\n        multiply(c11, d12, new_size, temp3);\n        multiply(c12, d22, new_size, temp4);\n        multiply(c21, d11, new_size, temp5);\n        multiply(c22, d21, new_size, temp6);\n        multiply(c21, d12, new_size, temp7);\n        multiply(c22, d22, new_size, temp8);\n        add(temp1, temp2, new_size, res1);\n        add(temp3, temp4, new_size, res2);\n        add(temp5, temp6, new_size, res3);\n        add(temp7, temp8, new_size, res4);\n\n        int x=0;\n        int y=0;\n        int z=0;\n        int w=0;\n        for(i=0; i<2*new_size; i++)\n        {\n            for(j=0; j<2*new_size; j++)\n            {\n                if(i<new_size && j<new_size)\n                {\n                    result[i][j]=res1[i][j];\n                }\n                if(i<new_size && j>=new_size)\n                {\n                    x=j-new_size;\n                    result[i][j]=res2[i][x];\n                }\n                if(i>=new_size && j<new_size)\n                {\n                    y=i-new_size;\n                    result[i][j]=res3[y][j];\n                }\n                if(i>=new_size && j>=new_size)\n                {\n                    z=i-new_size;\n                    w=j-new_size;\n                    result[i][j]=res4[z][w];\n                }\n            }\n        }\n    free(c11);\n    free(c12);\n    free(c21);\n    free(c22);\n    free(d11);\n    free(d12);  \n    free(d21);  \n    free(d22);\n    free(temp1);\n    free(temp2);\n    free(temp3);\n    free(temp4);\n    free(temp5);\n    free(temp6);\n    free(temp7);\n    free(temp8);\n    free(res1);\n    free(res2);\n    free(res3);\n    free(res4);\n    }\n}\n\nint main(void)\n{   \n    int i, j;\n\n    int **A=(int **)malloc(SIZE*sizeof(int *));\n    for(i=0; i<SIZE; i++)\n    {\n        A[i]=(int *)malloc(SIZE*sizeof(int));\n    }\n    int **B=(int **)malloc(SIZE*sizeof(int *));\n    for(i=0; i<SIZE; i++)\n    {\n        B[i]=(int *)malloc(SIZE*sizeof(int));\n    }\n    int **C=(int **)malloc(SIZE*sizeof(int *));\n    for(i=0; i<SIZE; i++)\n    {\n        C[i]=(int *)malloc(SIZE*sizeof(int));\n    }\n\n    int count=0;\n    int sum=0;\n    srand(time(NULL));\n    for(i=0; i<SIZE; i++)\n    {\n        for(j=0; j<SIZE; j++)\n        {\n            A[i][j]=rand()%1000;\n        }\n    }\n\n    for(i=0; i<SIZE; i++)\n    {\n        for(j=0; j<SIZE; j++)\n        {\n            B[i][j]=rand()%1000;\n        }\n    }\n\n    for(i=0; i<SIZE; i++)\n    {\n        for(j=0; j<SIZE; j++)\n        {\n            C[i][j]=0;\n        }\n    }\n\n    for(i=0; i<SIZE; i++)\n    {\n        for(j=0; j<SIZE; j++)\n        {\n            printf(\"%5d\", A[i][j]);\n        }\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n\");\n\n    for(i=0; i<SIZE; i++)\n    {\n        for(j=0; j<SIZE; j++)\n        {\n            printf(\"%5d\", B[i][j]);\n        }\n        printf(\"\\n\");\n    }\n    multiply(A, B, SIZE, C);\n\n    for(i=0; i<SIZE; i++)\n    {\n        for(j=0; j<SIZE; j++)\n        {\n            printf(\"%5d\", C[i][j]);\n        }\n        printf(\"\\n\");\n    }\n    free(A);\n    free(B);\n    free(C);\n\n}\n```\n\n\nThe code is meant to generate random two n*n matrices, split the big matrices into half, and multiply the submatrices recursively as you might know. After the calculation I display the result of the multiplication. I put the calculated submatrices in the result matrix.\n\nI've tried using debuggers, but the program just quits after a few moments. From my former experience, I suspect that there might be some problems with the initialization of variables, but it seems fine to me at this moment.\n\nCould anyone point out what I've missed? Sorry for the redundant mallocs in the middle. I'm going to make a function after I find the code is properly working. Thank you very much in advance.\n    ", "Answer": "\r\nYour code contains:\n\n```\n    int **temp5=(int **)malloc(new_size*sizeof(int *));\n    for(i=0; i<new_size; i++)\n    {\n        temp4[i]=(int *)malloc(new_size*sizeof(int));\n    }\n```\n\n\n```\ntemp4```\n is a typo; the contents of ```\ntemp5[i]```\n are never set.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Binary Matrix Multiplication with OR Instead of Sum\r\n                \r\nI am trying to determine how to perform binary matrix multiplication in Python / Numpy / Scipy where instead of plus (addition), OR is used, meaning when we \"multiply\" the two matrices below\n\n```\n1  0\n1  1\n0  1\n\n1  1  0\n0  1  1\n```\n\n\nwe should get\n\n```\n[[1., 1., 0],\n[1., 1., 1.],\n[0, 1., 1.]]\n```\n\n\nAny ideas? \n    ", "Answer": "\r\n```\n> a = np.matrix([[1,1,0],[0,1,1]], dtype=bool)\n> a.T * a \nmatrix([[ True,  True, False],\n        [ True,  True,  True],\n        [False,  True,  True]], dtype=bool)\n```\n\n\nNormal numpy arrays have access to matrix-style multiplication via the ```\ndot```\n function.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication - view/projection, world/projection, etc\r\n                \r\nIn HLSL there's a lot of matrix multiplication and while I understand how and where to use them I'm not sure about how they are derived or what their actual goals are.\n\nSo I was wondering if there was a resource online that explains this, I'm particularly curious about what is the purpose behind multiplying a world matrix by a view matrix and a world+view matrix by a projection matrix.\n    ", "Answer": "\r\nYou can get some info, from a mathematical viewpoint, on this wikipedia article or on msdn.\n\nEssentially, when you render a 3d model to the screen, you start with a simple collection of vertices scattered in 3d space. These vertices all have their own positions expressed in \"object space\". That is, they usually have coordinates which have no meaning in the scene that is being rendered, but only express the relations between one vertex and the other of the same model.\nFor instance, the positions of the vertices of a model could only range from -1 to 1 (or similar, it depends on how the model has been created).\n\nIn order to render the model in the correct position, you have to scale, rotate and translate it to the \"real\" position in your scene. This position you are moving to is expressed in \"world space\" coordinates which also express the real relationships between vertices in your scene. To do so, you simply multiply each vertex' position with its World matrix. This matrix must be created to include the translation/rotation/scale parameters you need to apply, in order for the object to appear in the correct position in the scene.\n\nAt this point (after multiplying all vertices of all your models with a world matrix) your vertices are expressed in world coordinates, but you still cannot render them correctly because their position is not relative to your \"view\" (i.e. your camera). So, this time you multiply everything using a View matrix which reflects the position and orientation of the viewpoint from which you are rendering the scene.\n\nAll vertices are now in the correct position, but in order to simulate perspective you still have to multiply everything with a Projection matrix. This last multiplication determines how the position of the vertices changes based on distance from the camera.\n\nAnd now finally all vertices, starting from their position in \"object space\", have been moved to the final position on the screen, where they will be rendered, rasterized and then presented.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication Error in C\r\n                \r\nI have been working on some code to implement a discrete cosine transform using C. This is the code I am using for my matrix multiplication. \n\n```\nfloat Yt[8][8][4];\nfloat Y8[8][8][4]={{{0.980785,-0.555570,0.555570 ...}}};\nfloat A[8][8]={{0.707107,0.707107 ... }};\n\nfor(k=0;k<4;++k){\n        for(i=0;i<8;++i){\n            for(j=0;j<8;++j){\n            Yt[i][j][k]=0;\n            }}}\n\nfor(k=0;k<4;++k){\n    for(i=0;i<8;++i){\n         for(j=0;j<8;++j){\n            for(l=0;l<8;++l){\n                Yt[i][j][k]+=A[i][l]*Y8[l][j][k];\n                }}}}\n```\n\n\nY8 is the same 8x8 matrix, repeated 4 times.\nMy code successfully compiles and runs. However, the output that I receive is obviously incorrect. ```\nYt[i][j][k] for k=0,1,2,3```\n should all be the same value, but I end up with the correct values for k=0,1 and different values for k=2,3.\n\nCan anyone see why I am getting incorrect values for the last two matrices? \n    ", "Answer": "\r\n@chux makes a good call about initializing they value of ```\nYt```\n before using it. You might do something like this:\n\n```\nfor(k=0;k<4;++k){\n  for(i=0;i<8;++i){\n    for(j=0;j<8;++j){\n      double temp = 0.0;\n      for(l=0;l<8;++l){\n        temp += A[i][l]*Y8[l][j][k];\n      }\n      Yt[i][j][k] = temp;\n    }\n  }\n}\n```\n\n\nThis would allow the compiler to use a register for the accumulation, then access ```\nYt```\n (with its three indexing operations) just once. \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "ValueError in matrix multiplication\r\n                \r\nThis is really basic but I am facing some issues with matrix multiplication in my code.\n\nAs per np.matmul(x1,x2) documentation --> if x1 and x2 have a shape (n,k) and (k,m) then the output is of the signature (n,k),(k,m)->(n,m).\nI have 2 arrays of similar signature mentioned above but when I use np.matmul,  I get a valueError that \"Shape of passed values is (1004, 20), indices imply (1004, 1)\"\n\n```\n\ntest1 = pd.DataFrame(np.random.randint(0,10, size=(1004,1)))\ntest2 = pd.DataFrame(np.ones([1,20]))\n\nnp.matmul(test1,test2)\n\n```\n\n\nI expect to see an output array of size (1004,20). Is there any issue here? \nThanks a lot in advance\n    ", "Answer": "\r\nI can get the code to work if you do not call pandas:\n\n```\nimport numpy as np\n\ntest1 = np.random.randint(0,10, size=(1004,1)) \ntest2 = np.ones([1,20]) \n\noutput = np.matmul(test1,test2)        \nprint(output.shape) \n\n>>> (1004, 20)\n\n```\n\n\nSimilarly, the builtin pandas multiplication gives you the right shape, (but lots of ```\nNaNs```\n):\n\n```\ntest1 = pd.DataFrame(np.random.randint(0,10, size=(1004,1))) \ntest2 = pd.DataFrame(np.ones([1,20])) \n\noutput = test1 * test2 \n\nprint(test1.shape) \nprint(test2.shape) \nprint(output.shape)\n\n>>> (1004, 1)\n>>> (1, 20)\n>>> (1004, 20)\n```\n\n\nSeems that your problem comes from calling the numpy function over the dataframes.  The error seems to come from inside the ```\nndarray```\n constructor.  This means ```\nnumpy```\n fails to build the ```\nndarray```\n returned in np.matmul, perhaps because it was expecting input arrays.  If you really want to mix the libraries like this, you can always grab the underlying ```\nndarray```\n that pandas uses, the DataFrame.values:\n\n```\ntest1 = pd.DataFrame(np.random.randint(0,10, size=(1004,1))) \ntest2 = pd.DataFrame(np.ones([1,20])) \n\noutput_ndarray = np.matmul(test1.values, test2.values) \nprint(output_ndarray.shape)(1004, 20)\n>>> (1004, 20)\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Fast way for matrix multiplication in Python\r\n                \r\nDoes anybody know a fast way to compute matrices such as:\n\n```\nZ{i,j}  = \\sum_{p,k,l,q} \\frac{A_{ip} B_{pk} C_{kl} D_{lq} E_{qj} }{a_p - b_q - c}\n```\n\n\n\n\nFor normal matrix multiplication I would use ```\nnumpy.dot(a,b),```\n but now I got to divide the  elements by ```\n$a_p$```\n and ```\n$b_q$```\n. \n\nAny suggestions?\n\nAny suggestions on how to compute\n\n```\n$$ C_{i,j} =  \\sum _p = \\frac{E_{i,p} B_{p,j}}{m_p} $$\n```\n\n\nwill be of great help as well.\n    ", "Answer": "\r\nNote that ```\n(E[i, p] * B[p, j]) / m[p]```\n is equal to ```\nE[i, p] * (B[p, j] / m[p])```\n, so you can simply divide ```\nm```\n into ```\nB```\n before calling ```\nnp.dot```\n.\n\n```\ndef f(E, B, m):\n    B = np.asarray(B)  # matrix\n    m = np.asarray(m).reshape((B.shape[0], 1))  # row vector\n    return np.dot(E, B / m)  # m is broadcasted to match B\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Rowwise matrix multiplication of two matrix columns in dplyr\r\n                \r\n\nI have a tibble called ```\nto_rotate```\n:\n\n```\n# A tibble: 32 x 3\n   personID bun_xyz               mat_y            \n      <int> <list>                <list>           \n 1        1 <dbl[,3] [1,381 x 3]> <dbl[,3] [3 x 3]>\n 2        2 <dbl[,3] [3,714 x 3]> <dbl[,3] [3 x 3]>\n 3        3 <dbl[,3] [3,157 x 3]> <dbl[,3] [3 x 3]>\n 4        4 <dbl[,3] [3,705 x 3]> <dbl[,3] [3 x 3]>\n# ... with 28 more rows\n\n```\n\n\nI would like to do rowwise matrix multiplication of the two list columns, but how do I do it? \n\nI tried this:\n\n```\nto_rotate %>%\n    rowwise() %>%\n    mutate(rotated = map2(bun_xyz, mat_y, ~ .x %*% .y))\n```\n\n\nbut I get the error:\n\n```\nError: Mapped vectors must have consistent lengths:\n* `.x` has length 4143\n* `.y` has length 9\n```\n\n\nIf I just take one row and do it \"manually\", everything is fine:\n\n```\n> rotated_1 = to_rotate$bun_xyz[[1]] %*% to_rotate$mat_y[[1]]\n> head(rotated_1)\n\n          [,1]      [,2]      [,3]\n[1,] 0.4411675 0.7639250 0.3506840\n[2,] 0.4438372 0.7625611 0.3518184\n[3,] 0.4458833 0.7618375 0.3535549\n[4,] 0.4452629 0.7607695 0.3538486\n[5,] 0.4404777 0.7533813 0.3511128\n[6,] 0.4398552 0.7514426 0.3508681\n```\n\n\n(```\nbun_xyz```\n are some 3D-coordinates which need to be rotated around the y-axis. ```\nmat_y```\n is the matrix that can do this)\n    ", "Answer": "\r\nRemoving ```\nrowwise()```\n did the trick:\n\n```\nto_rotate %>%\n    mutate(rotated = map2(bun_xyz, mat_y, ~ .x %*% .y))\n```\n\n\nThanks Mossa Nova for pointing this out in a comment.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Multithreaded Matrix Multiplication C++\r\n                \r\nI am writing Multithreaded Matrix Multiplication in C++ and calculating the result in row major order(one after another row).\n\nI am diving the resultant rows calculations among the threads.\nI pass as a parameter to thread the starting row number, where to start calculating resultant rows and a row Count i.e how many rows to calculate.\nWhen I execute the code, I get some rows with zeroes instead of the product entries.\nHere is the calculation code: \n\n```\nfor(int i= arg->startingRow;i<arg->startingRow+ arg->rowCount;i++){\n  for(int j=0;j<m2->cols;j++){\n     result->data[j+ i*m2->cols] = 0;\n     for(int k=0;k<m1->cols; k++){\n        result->data[j+ i *m2->cols] += m1->data[k + i *m1->cols] * m2->data[j + k*m2->cols];\n     }\n  }\n}\n```\n\n    ", "Answer": "", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Python - matrix multiplication code problem\r\n                \r\nI have this exercise where I get to build a simple neural network with one input layer and one hidden layer... I made the code below to perform a simple matrix multiplication, but it's not doing it properly as when I do the multiplication by hand. What am I doing wrong in my code?   \n\n```\n          #toes %win  #fans\nih_wgt = ([0.1, 0.2, -0.1],  #hid[0]\n           [-0.1, 0.1, 0.9],  #hid[1]\n           [0.1, 0.4, 0.1])  #hid[2]\n\n          #hid[0] hid[1] #hid[2]\nho_wgt = ([0.3, 1.1, -0.3], #hurt?\n           [0.1, 0.2, 0.0],  #win?\n           [0.0, 1.3, 0.1])  #sad?\n\nweights = [ih_wgt, ho_wgt]\n\ndef w_sum(a,b):\n    assert(len(a) == len(b))\n    output = 0\n    for i in range(len(a)):\n        output += (a[i] * b[i])\n    return output\n\ndef vect_mat_mul(vec, mat): \n  assert(len(vec) == len(mat)) \n  output = [0, 0, 0]\n  for i in range(len(vec)): \n    output[i]= w_sum(vec, mat[i])\n    return output\n\ndef neural_network(input, weights):\n  hid = vect_mat_mul(input, weights[0])\n  pred = vect_mat_mul(hid, weights[1])\n  return pred\n\n\ntoes = [8.5, 9.5, 9.9, 9.0]\nwlrec = [0.65, 0.8, 0.8, 0.9]\nnfans = [1.2, 1.3, 0.5, 1.0]\n\ninput = [toes[0],wlrec[0],nfans[0]]\n\npred = neural_network(input, weights)\nprint(pred)\n```\n\n\nthe output of my code is:\n\n\n  [0.258, 0, 0]\n\n\nThe way I attempted to solve it by hand is as follows:\nI multiplied the input vector [8.5, 0.65, 1.2] with the input weight matrix\n\n```\nih_wgt = ([0.1, 0.2, -0.1],  #hid[0]\n           [-0.1, 0.1, 0.9],  #hid[1]\n           [0.1, 0.4, 0.1])  #hid[2]\n```\n\n\n\n  [0.86, 0.295, 1.23]\n\n\nthe output vector is then fed into the network as an input vector which is then multiplied by the hidden weight matrix\n\n```\nho_wgt = ([0.3, 1.1, -0.3], #hurt?\n           [0.1, 0.2, 0.0],  #win?\n           [0.0, 1.3, 0.1])  #sad?\n```\n\n\nthe correct output prediction:\n\n\n  [0.2135, 0.145, 0.5065]\n\n\nYour help would be much appreciated! \n    ", "Answer": "\r\nYou're almost there! Only a simple indentation thing is the reason:\n\n```\ndef vect_mat_mul(vec, mat): \n  assert(len(vec) == len(mat)) \n  output = [0, 0, 0]\n  for i in range(len(vec)): \n    output[i]= w_sum(vec, mat[i])\n  return output                      # <-- This one was inside the for loop\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Batch matrix multiplication in Julia\r\n                \r\nI'm trying to multiply N-dimensional (N>=3) arrays in Julia as batches of matrices, i.e. perform matrix multiplication along the last two dimensions, keeping the other dimensions intact.\n\nFor example, if ```\nx```\n has dimensions ```\n(d1,d2,4,3)```\n and ```\ny```\n has dimensions ```\n(d1,d2,3,2)```\n, the result of the multiplication should have ```\n(d1,d2,4,2)```\n, i.e. a batch of matrix multiplications should be performed.\n\nThis is exactly what happens in Python's ```\nnumpy.matmul```\n:\n\n\n  If either argument is N-D, N > 2, it is treated as a stack of matrices residing in the last two indexes and broadcast accordingly.\n\n\n```\nnp.matmul(randn(10,10,4,3), randn(10,10,3,2)).shape\n(10, 10, 4, 2)\n```\n\n\nIs there a way to reproduce the behaviour of ```\nnumpy.matmul```\n in Julia?\n\nI hoped ```\n.*```\n would work, but:\n\n```\njulia> randn(10,10,4,3) .* randn(10,10,3,2)\nERROR: DimensionMismatch(\"arrays could not be broadcast to a common size\")\nStacktrace:\n [1] _bcs1 at ./broadcast.jl:485 [inlined]\n [2] _bcs at ./broadcast.jl:479 [inlined] (repeats 3 times)\n [3] broadcast_shape at ./broadcast.jl:473 [inlined]\n [4] combine_axes at ./broadcast.jl:468 [inlined]\n [5] instantiate at ./broadcast.jl:256 [inlined]\n [6] materialize(::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{4},Nothing,typeof(*),Tuple{Array{Float64,4},Array{Float64,4}}}) at ./broadcast.jl:798\n [7] top-level scope at REPL[80]:1\n```\n\n\nI understand a list comprehension might work in 3-D, but this would get really messy in higher dimensions. Is the best solution to reshape (or view) all but the last 2 dimensions, use a list comprehension, and reshape it back? Or is there a better way?\n\nP.S. The closest thing I could find was this, but it's not quite the same. New to Julia, so might be missing something obvious to Julia users.\n    ", "Answer": "\r\nI'm not aware of any such functionality, but there may well be in some package. I think that in Julia it's more natural to organize the data as arrays of matrices, and broadcast the matrix multiplication over them:\n\n```\nD = [rand(50, 60) for i in 1:4, j in 1:3]\nE = [rand(60, 70) for i in 1:4, j in 1:3]\nD .* E  # now you can use dot broadcasting!\n```\n\n\nThat said, it's easy to make your own. I would make one change, though. Julia is column major, while numpy is \"last dimension major\", therefore you should let the matrices resided along the first two dimensions, not the last two.\n\nFirst, I'll define an in-place method that multiplies into an array ```\nC```\n, and then a non-in-place method that calls the in-place version (I'll skip dimension checking etc):\n\n```\n# In-place version, note the use of the @views macro, \n# which is essential to get in-place behaviour\n\nusing LinearAlgebra: mul!  # fast in-place matrix multiply\n\nfunction batchmul!(C, A, B)\n    for j in axes(A, 4), i in axes(A, 3)\n        @views mul!(C[:, :, i, j], A[:, :, i, j], B[:, :, i, j])\n    end\n    return C\nend\n\n# The non-in-place version\nfunction batchmul(A, B)\n    T = promote_type(eltype(A), eltype(B))\n    C = Array{T}(undef, size(A, 1), size(B)[2:end]...)\n    return batchmul!(C, A, B)\nend\n```\n\n\nYou could also make it multi-threaded. On my computer 4 threads gives a 2.5x speedup (actually, for larger values of the last two dimensions, I get a 3.5x speedup) How much of a speedup you get depends on the sizes and shapes of the arrays involved:\n\n```\nfunction batchmul!(C, A, B)\n    Threads.@threads for j in axes(A, 4)\n        for i in axes(A, 3)\n            @views mul!(C[:, :, i, j], A[:, :, i, j], B[:, :, i, j])\n        end\n    end\n    return C\nend\n```\n\n\nEdit: I noticed just now that you want general N-D, not just 4-D. Shouldn't be too hard to generalize, though. Anyway, all the more reason to go for arrays of matrices, where broadcasting will automatically work for all dimensionalities. \n\nEdit2: Couldn't leave it, so here's one for the N-D case (there's still more to do, like handling non-1-based indexing (update: ```\naxes```\n should fix this)):\n\n```\nfunction batchmul!(C, A, B)\n    Threads.@threads for I in CartesianIndices(axes(A)[3:end])\n        @views mul!(C[:, :, Tuple(I)...], A[:, :, Tuple(I)...], B[:, :, Tuple(I)...])\n    end\n    return C\nend\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix Multiplication OpenMP Counter-Intuitive Results\r\n                \r\nI am currently porting some code over to OpenMP at my place of work. One of the tasks I am doing is figuring out how to speed up matrix multiplication for one of our applications.\n\nThe matrices are stored in row-major format, so A[i*cols +j] gives the A_i_j element of the matrix A.\n\nThe code looks like this (uncommenting the pragma parallelises the code):\n\n```\n#include <omp.h>\n#include <iostream>\n#include <iomanip>\n#include <stdio.h>\n\n#define NUM_THREADS 8\n#define size 500\n#define num_iter 10\n\nint main (int argc, char *argv[])\n{\n//    omp_set_num_threads(NUM_THREADS);\n\n    int *A = new int [size*size];\n    int *B = new int [size*size];\n    int *C = new int [size*size];\n\n    for (int i=0; i<size; i++)\n    {\n        for (int j=0; j<size; j++)\n        {\n            A[i*size+j] = j*1;\n            B[i*size+j] = i*j+2;\n            C[i*size+j] = 0;\n        }\n    }\n\n    double total_time = 0;\n    double start = 0;\n\n    for (int t=0; t<num_iter; t++)\n    {\n        start = omp_get_wtime();\n\n        int i, k;\n\n//        #pragma omp parallel for  num_threads(10) private(i, k) collapse(2) schedule(dynamic)\n        for (int j=0; j<size; j++)\n        {\n            for (i=0; i<size; i++)\n            {\n                for (k=0; k<size; k++)\n                {\n                    C[i*size+j] += A[i*size+k] * B[k*size+j];\n                }\n            }\n        }\n\n        total_time += omp_get_wtime() - start;\n    }\n\n    std::setprecision(5);\n    std::cout << total_time/num_iter << std::endl;\n\n    delete[] A;\n    delete[] B;\n    delete[] C;\n\n    return 0;\n}\n```\n\n\nWhat is confusing me is the following: why is dynamic scheduling faster than static scheduling for this task? Timing the runs and taking an average shows that static scheduling is slower, which to me is a bit counterintuitive since each thread is doing the same amount of work.\n\nAlso, am I correctly speeding up my matrix multiplication code?\n    ", "Answer": "\r\nParallel matrix multiplication is non-trivial (have you even considered cache-blocking?). Your best bet is likely to be to use a BLAS Library for this, rather than writing it yourself. (Remember, \"The best code is the code I do not have to write\").\n\n Wikipedia: Basic Linear Algebra Subprograms points to many implementations, a lot of which (including Intel Math Kernel Library) have free licenses.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication with get _row get_column - python\r\n                \r\nI have a class Matrix(object) with get_row and get_column definitions. How can I make a matrix multiplication with them?\n\n```\ndef get_row(self,r):\n    get_row = self._m[r]\n    return get_row   \n\n\ndef get_column(self,c):\n    get_column=[]\n    for row in self._m:\n        get_column.append(row[c])\n    return get_column\n```\n\n\nm2=Matrix(2,[[1,2],[3,4]])\nm3=Matrix(2,[[5,6],[7,8]])\n\ngc= m2.get_column(1) ----> [2,4]\ngr=m2.get_row(1) ----> [3,4]\n\nThe following code works but I have to do it using get_row and get_column\n\n\r\n\r\n```\nnollmatris=[[0 for r in range(self._size)] for c in range(self._size)]\r\n  for i in range(len(self._m)):         \r\n     for j in range(len(other._m[0])):  \r\n        for k in range(len(other._m)):  \r\n           nollmatris[i][j] += self._m[i][k] * other._m[k][j]\r\nfor svar in nollmatris:\r\n    print(svar)```\n\r\n\r\n\r\n\n    ", "Answer": "\r\nI assume this is homework, since if it's not homework the answer is \"get numpy.\"  \n\nIf that's not possible, your best bet is to use a ```\nzip()```\n as the iterator in a ```\nfor```\n loop.   \n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Recursive function to calculate matrix multiplication\r\n                \r\nI'm trying to write a recursive function to calculate matrix multiplication.\n\nEDITED :\n\nThis is the code :\n\n```\ndef mult_mat(x, nbr):\n    result = [[2, 4],\n              [1, 3]]\n\n    if nbr == 1:\n        return result\n    else:\n        for i in range(len(x)):\n            for j in range(len(result[0])):\n                for k in range(len(result)):\n                    result[i][j] += x[i][k] * result[k][j]\n        mult_mat(result, nbr-1)\n\n    return result\n\n\nm = [[2, 4],\n      [1, 3]]\n\n# the number of times m1 will be multiplied\nn = 3\nres = mult_mat(m, n)\nfor r in res:\n    print(r)\n```\n\n\nAs an example, for ```\nn = 3```\n I am trying to get the result:\n\n```\nm1 * m1```\n will be  ```\n[[8, 20], [5, 3]] = result```\n and ```\nresult * m1```\n will be ```\n[[36, 92], [23, 59]]```\n and so on.\n\nthe output of this code is:\n\n```\n[10, 24]\n[44, 108]\n```\n\n\nand what i want is this :\n\n```\n[36, 92]\n[23, 59]\n```\n\n    ", "Answer": "\r\nOkay, let's understand conceptually what you want to achieve with recursion. You want to multiply a matrix, ```\nM```\n, with itself. ```\nmult_mat(M, 2)```\n will give ```\nM * M```\n, therefore, ```\nmult_mat(M, 1)```\n just returns ```\nM```\n itself.\n\nIn the multiplication, you have 3 matrices going on. ```\nx```\n and ```\ny```\n are the two matrices you're multiplying together, which you store in ```\nresult```\n. Now, let's look what happens for the first few multiplications.\n\n```\nx * x             # n = 2\n\nx * (x * x)       # n = 3\n                  # here, we initially calculate x * x,\n                  # which we pass as y in the next stack for x * y\n```\n\n\nAs you can see, for ```\nn = 2```\n, you multiply ```\nx```\n by itself, but for ```\nn > 2```\n, ```\ny```\n is different than ```\nx```\n, so you must pass it on to the function somehow. We can code this idea as follows.\n\n```\ndef mult_mat(x, nbr, y=None):\n    if nbr == 1:\n        # if y is None, it means we called `mult_mat(x, 1)`, so return `x`\n        if y is not None:\n            return y\n        return x\n\n    if y is None:\n        y = x\n    result = [[0, 0],\n              [0, 0]]\n    for i in range(len(x)):\n        for j in range(len(result[0])):\n            for k in range(len(result)):\n                result[i][j] += x[i][k] * y[k][j]\n    return mult_mat(x, nbr-1, result)\n\nm = [[2, 4],\n      [1, 3]]\n\n# the number of times m1 will be multiplied\nn = 3\nres = mult_mat(m, n)\nfor r in res:\n    print(r)\n```\n\n\nIt's may look like ugly code and that's probably because there are better ways to achieve what you want without recursion. However, I couldn't think of a different way while implementing recursion. My solution logically flowed from the points I laid out at the beginning.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "matrix multiplication error between 3d and 2d\r\n                \r\nI am performing 3d matrix multiplication with 2d but getting error\n\n```\n[a b c] = size(im_f);\n[a d]= size(H);\n\nim_nf = zeros([a d c]);\n\nim_nf = cellfun(@(im_f) im_f*H,mat2cell(im_f,a,b,ones(1,c)),'UniformOutput',false);\nim_nf = cat(3,im_nf{:});\n```\n\n\nbut it is giving error:\n\n```\n??? Error using ==> mtimes\nInner matrix dimensions must agree.\n\nError in ==> homofil>@(im_f)im_f*H at 27\n\nim_nf = cellfun(@(im_f) im_f*H,mat2cell(im_f,a,b,ones(1,c)),'UniformOutput',false);`???             Error using ==> mtimes\nInner matrix dimensions must agree.\n\nError in ==> homofil>@(im_f)im_f*H at 27\nim_nf = cellfun(@(im_f) im_f*H,mat2cell(im_f,a,b,ones(1,c)),'UniformOutput',false);\n```\n\n\n```\nhomofil```\n is file name\n\nsize of ```\nim_f```\n is ```\n[ 307   409     3 ]```\n\n\nsize of ```\nH```\n is ```\n[ 307        1227 ]```\n\n\nHow can this error be corrected?\n    ", "Answer": "\r\nIn the ```\ncellfun```\n you are trying to multiply ```\nim_f```\n of size ```\n[307 409]```\n by ```\nH```\n of size ```\n[307 1227]```\n - this is why you have \"Inner matrix dimensions must agree\" error.\n\nEither change the order of ```\nim_f```\n and ```\nH```\n:\n\n```\nim_nf = cellfun(@(im_f) H*im_f,mat2cell(im_f,a,b,ones(1,c)),'UniformOutput',false); \n```\n\n\nOr transpose ```\nim_f```\n:\n\n```\nim_nf = cellfun(@(im_f) im_f.'*H,mat2cell(im_f,a,b,ones(1,c)),'UniformOutput',false);\n```\n\n\nBTW, nice usage of ```\nmat2cell```\n and ```\ncellfun```\n ;)\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Matrix multiplication with parallel programming in numpy python\r\n                \r\nI'm new in python, but I need to convert normal matrix multiplication code to parallel with numpy,\nI need to convert this function to parallel way:\n```\n\ndef RowByColumn(A, B):\n    matrix=[]\n    for i in range(len(A)):\n        matrix.append([])\n        for j in range(len(B)):\n            matrix[i].append(matrix_multiplication(getRow(A,i),getColumn(B,j)))\n    return matrix\n\n\n```\n\nHow can I to apply multiprocessing module or other parallel processing modules in python, could anyone help me how?\n    ", "Answer": "\r\nI do not recommend multiprocessing, as processes are slow to create, and also has a big communication overhead. You can use numba, which will compile your function and make it really fast. The library works really well with numpy. Also, it is very easy to include parallelization with threads:\n```\nimport numpy as np\nfrom numba import njit, prange\n\n@njit(parallel=True)\ndef mat_mult(A, B):\n    assert A.shape[1] == B.shape[0]\n    res = np.zeros((A.shape[0], B.shape[1]), )\n    for i in prange(A.shape[0]):\n        for k in range(A.shape[1]):\n            for j in range(B.shape[1]):\n                res[i,j] += A[i,k] * B[k,j]\n    return res\n\nm, n, c = 1000, 1500, 1200\nA = np.random.randint(1, 50, size = (m, n))\nB = np.random.randint(1, 50, size = (n, c))\n\nres = mat_mult(A, B)\n```\n\nUse ```\nprange```\n to parallelize the loops. I have only parallelized the outer loop, but you can also apply this to the inner loops.\nNote also the order of the loops I have used, which makes continuous memory accesses reducing cache misses.\nIn my laptop, the parallel function takes about 1.4 seconds to be executed, while numpy's matrix multiplication ```\nA@B```\n takes 4.4 seconds, so there is some improvement.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "Text Matrix multiplication\r\n                \r\nThese are my two text matrices:\n\n```\nA <- matrix(c(\"AIP-A\",\"CSV-A\"), ncol = 1, byrow = TRUE)\nB <- matrix(c(\"AIP-B\",\"CSV-B\"), ncol = 1, byrow = TRUE)\n```\n\n\nI am trying to get the multiplication of these matrices and the output should look like this:\n\n```\nAIP-A,AIP-B\nAIP-A,CSV-B\nCSV-A,AIP-B\nCSV-A,CSV-B\n```\n\n\nA*B does not work because it is looking for numeric inputs. Maybe the same result can be achieved by some other technique. \nI am ok with 4x2 output matrix, a 4x1 matrix ,a character vector, data.frame and data.table\n    ", "Answer": "\r\nYou can use ```\nouter```\n for outer product of arrays with ```\npaste```\n to get your desired  output:\n\n```\nc(outer(A, B, paste, sep = \",\"))\n# [1] \"AIP-A,AIP-B\" \"CSV-A,AIP-B\" \"AIP-A,CSV-B\" \"CSV-A,CSV-B\"\n```\n\n\nor\n\n```\nmatrix(outer(A, B, paste, sep = \",\"), ncol = 1)\n#     [,1]         \n#[1,] \"AIP-A,AIP-B\"\n#[2,] \"CSV-A,AIP-B\"\n#[3,] \"AIP-A,CSV-B\"\n#[4,] \"CSV-A,CSV-B\"\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "q kdb matrix multiplication precision\r\n                \r\nI am doing the matrix multiplication / dot product of two vectors, but losing significant precision in the process. \nMy two tables are:\n\n```\nA:flip (`WORLD`MOMENTUM`VOLATIL`VALUE`SIZE`SIZENONL`GROWTH`LIQUID`LEVERAGE`ENERGY`OILGAS`OILEXPL`CHEMICAL`CONSTPP`DIVMETAL`PRECMETL`STEEL`CAPGOODS`COMMSVCS`TRANSPRT`AIRLINES`AUTOCOMP`CONSDUR`CONSVCS`MEDIA`RETAIL`FOODRETL`FOODPRD`HSHLDPRD`HEALTH`BIOTECH`PHARMAC`BANKS`DIVFINAN`INSURAN`REALEST`INTERNET`SOFTWARE`COMMUNIC`COMPUTER`SEMICOND`TELECOM`UTILITY`ARE`ARG`AUS`AUT`BEL`BHR`BRA`CAN`CHE`CHL`CHN`CHX`COL`CZE`DEU`DNK`EGY`ESP`FIN`FRA`GBR`GRC`HKG`HUN`IDN`IND`IRL`ISR`ITA`JOR`JPN`KOR`KWT`MAR`MEX`MYS`NLD`NOR`NZL`OMN`PAK`PER`PHL`POL`PRT`QAT`RUS`SAU`SGP`SWE`THA`TUR`TWN`USA`ZAF`AREC`ARGC`AUSC`AUTC`BELC`BHRC`BRAC`CANC`CHEC`CHLC`CHNC`COLC`CZEC`DEUC`DNKC`EGYC`EMUC`ESPC`FINC`FRAC`GBRC`GRCC`HKGC`HUNC`IDNC`INDC`IRLC`ISRC`ITAC`JORC`JPNC`KORC`KWTC`MARC`MEXC`MYSC`NLDC`NORC`NZLC`OMNC`PAKC`PERC`PHLC`POLC`PRTC`QATC`RUSC`SAUC`SGPC`SWEC`THAC`TURC`TWNC`USAC`ZAFC)!(enlist 610216.7;enlist -167790.7;enlist -61640.11;enlist 1211006f;enlist -805318.3;enlist -144186.8;enlist 484780.3;enlist 729160.8;enlist -1223112f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist -63589.8;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 47259.38;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist -42577.22;enlist 0f;enlist 721972.9;enlist 0f;enlist -32170.51;enlist 0f;enlist 0f;enlist 0f;enlist -152106.2;enlist 131428.1;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 610216.7;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 0f;enlist 610216.7;enlist 0f;enlist 0f;enlist 0f);\nB:flip (enlist `WORLD)!(enlist 48.29499 -5.301547 17.17246 2.146016 1.69432 0.295386 1.296268 1.381681 1.931021 7.972107 1.824557 10.18463 6.161642 4.141302 20.12705 -44.44252 22.11896 6.354314 -0.455013 -1.28214 -5.993917 9.041717 -1.749305 -5.074565 -2.914975 -4.31613 -9.272181 -11.28901 -8.72011 -7.808923 -0.938631 -8.579992 6.898276 8.94749 6.497003 -1.967439 -2.090085 -0.254925 1.320048 5.30489 5.746626 -8.236259 -14.77134 -9.308569 -14.18904 -7.501979 3.634038 -3.201371 -32.09656 -5.156152 -8.858147 0.763125 -20.76443 -16.71714 -2.192779 -22.27704 -5.303177 3.503334 -2.870094 -1.125126 6.617578 -1.169103 7.511715 -4.384823 10.17381 0.769835 -3.488056 -18.70038 -6.739745 -4.994236 -7.670161 7.711241 -29.75733 5.311001 -22.09107 -33.23776 -38.32805 -17.19578 -14.23223 6.033368 -2.48355 -7.678366 -17.67733 -27.92534 -15.13988 -11.78941 -11.99404 -0.087656 -12.29577 -6.127644 -8.919363 2.165941 -0.196319 -9.859482 -6.289163 -12.44774 3.835522 -11.39685 6.8e-005 10.45363 30.1068 3.294173 3.294173 0.11509 33.12787 25.92562 -1.497061 20.91031 3.470695 32.76403 5.528537 3.294173 3.31778 -0.172639 3.294173 3.294173 3.294173 3.294173 13.11109 3.294173 0.708191 14.87056 8.111332 11.23322 3.294173 10.9295 3.294173 0.056315 -25.3915 26.04028 -0.344381 3.045744 41.80897 15.30789 3.294173 18.46745 24.13028 0.065611 0.511451 7.17594 9.577834 19.91554 3.294173 0.448114 33.1457 0.036037 9.321848 13.95029 7.793591 30.57135 11.67946 0 44.67686);\n```\n\n\nI have tried a few combinations of ```\nmmu```\n and ```\n$```\n, including:\n\n```\n(raze value flip A) mmu flip value flip B\n(flip value flip A) mmu flip value flip B\n```\n\n\nThe result I get is 41,756,840, the correct result is 41,756,847.  I cannot see where the problem is, any ideas welcome, thank you.\n    ", "Answer": "\r\nThe correct answer given your data is neither 41,756,840 nor 41,756,847.  If you increase the display precision, you will see\n\n```\nq)\\P 16\nq)(flip value flip A) mmu flip value flip B\n41756847.29598875\n```\n\n\nIt looks like you are misinterpreting the limited precision display somewhere.\n\nI would also like to note that your problem becomes more manageable if you notice that only a few entries are nonzero in A\n\n```\nq)show a:(where 0<>a)#a:first A\nWORLD   | 610216.7\nMOMENTUM| -167790.7\nVOLATIL | -61640.11\nVALUE   | 1211006\nSIZE    | -805318.3\nSIZENONL| -144186.8\nGROWTH  | 484780.3\nLIQUID  | 729160.8\nLEVERAGE| -1223112\nCONSTPP | -63589.8\nCONSDUR | 47259.38\nDIVFINAN| -42577.22\nREALEST | 721972.9\nSOFTWARE| -32170.51\nTELECOM | -152106.2\nUTILITY | 131428.1\nTUR     | 610216.7\nTURC    | 610216.7\n```\n\n\nThe corresponding values in B can be found as\n\n```\nq)show b:(key a)!B.WORLD where 0<>value first A\nWORLD   | 48.29499\nMOMENTUM| -5.301547\nVOLATIL | 17.17246\nVALUE   | 2.146016\nSIZE    | 1.69432\nSIZENONL| 0.295386\nGROWTH  | 1.296268\nLIQUID  | 1.381681\nLEVERAGE| 1.931021\nCONSTPP | 4.141302\nCONSDUR | -1.749305\nDIVFINAN| 8.94749\nREALEST | -1.967439\nSOFTWARE| -0.254925\nTELECOM | -8.236259\nUTILITY | -14.77134\nTUR     | -6.289163\nTURC    | 30.57135\n```\n\n\nand the dot product is\n\n```\nq)(value a) mmu value b\n41756847.29598875\n```\n\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "LAPACK/BLAS matrix multiplication in fortran returns zeros\r\n                \r\nI'm a fortran beginner and simply wanted to try if i get a matrix multiplication to work.\n\n```\n    program testlapack\n    implicit none\n\n    COMPLEX, DIMENSION(2, 2) :: A, B, Output\n\n    A = reshape((/ 4, 0, 0, 2 /), shape(A))\n    B = reshape((/ 6, 0, 0, 3 /), shape(B))\n    Output = reshape((/ 1, 0, 0, 1 /), shape(Output))\n\n    call DGEMM('n','n',2,2,2,1.0,A,2,B,2,0.0,Output,2)\n\n    Write(*,*) Output\n\n    end program testlapack\n```\n\n\nI was expecting a simple A * B multiplication written into the Output-array. Instead, lapack is returning a 2x2 matrix with only zeros. The compilation with ifort -llpack yields no errors.\n\nWhere's my problem?\nThanks\n    ", "Answer": "\r\nI suspect that passing complex arguments to a subroutine expecting real arguments might be the cause of your problem.  Perhaps you meant to use ```\nzgemm```\n rather than ```\ndgemm```\n ?\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
{"Question": "c++ dynamic memory allocation - matrix multiplication\r\n                \r\nI am trying to do a large matrix multiplication, e.g. 1000x1000. Unfortunately, it only works for very small matrices. For the big ones, the program just turns on and that's all - no results. Here's the code:\n```\n#include <iostream>\n\nusing namespace std;\n\nint main() {\n    int matrix_1_row;\n    int matrix_1_column;\n    matrix_1_row = 10;\n    matrix_1_column = 10;\n\n    int** array_1 = new int* [matrix_1_row];\n    // dynamically allocate memory of size matrix_1_column for each row\n    for (int i = 0; i < matrix_1_row; i++)\n    {\n        array_1[i] = new int[matrix_1_column];\n    }\n    // assign values to allocated memory\n    for (int i = 0; i < matrix_1_row; i++)\n    {\n        for (int j = 0; j < matrix_1_column; j++)\n        {\n            array_1[i][j] = 3;\n        }\n    }\n\n    int matrix_2_row;\n    int matrix_2_column;\n    matrix_2_row = 10;\n    matrix_2_column = 10;\n    // dynamically create array of pointers of size matrix_2_row\n    int** array_2 = new int* [matrix_2_row];\n    // dynamically allocate memory of size matrix_2_column for each row\n    for (int i = 0; i < matrix_2_row; i++)\n    {\n        array_2[i] = new int[matrix_2_column];\n    }\n    // assign values to allocated memory\n    for (int i = 0; i < matrix_2_row; i++)\n    {\n        for (int j = 0; j < matrix_2_column; j++)\n        {\n            array_2[i][j] = 2;\n        }\n    }\n\n    // Result\n    int result_row = matrix_1_row;\n    int result_column = matrix_2_column;\n    // dynamically create array of pointers of size result_row\n    int** array_3 = new int* [result_row];\n    // dynamically allocate memory of size result_column for each row\n    for (int i = 0; i < result_row; i++)\n    {\n        array_3[i] = new int[result_column];\n    }\n\n\n    // Matrix multiplication\n    for (int i = 0; i < matrix_1_row; i++)\n    {\n        for (int j = 0; j < matrix_2_column; j++)\n        {\n            array_3[i][j] = 0;\n            for (int k = 0; k < matrix_1_column; k++)\n            {\n                array_3[i][j] += array_1[i][k] * array_2[k][j];\n            }\n        }\n    }\n\n\n    //RESULTS\n    for (int i = 0; i < result_row; i++)\n    {\n        for (int j = 0; j < result_column; j++)\n        {\n            std::cout << array_3[i][j] << \"\\t\";\n        }\n    }\n\n\n    // deallocate memory using delete[] operator 1st matrix\n    for (int i = 0; i < matrix_1_row; i++)\n    {\n        delete[] array_1[i];\n    }\n    delete[] array_1;\n    // deallocate memory using delete[] operator 2nd matrix\n    for (int i = 0; i < matrix_2_row; i++)\n    {\n        delete[] array_2[i];\n    }\n    delete[] array_2;\n    // deallocate memory using delete[] operator result\n    for (int i = 0; i < result_row; i++)\n    {\n        delete[] array_3[i];\n    }\n    delete[] array_3;\n\n    return 0;\n}\n```\n\nAnyone have an idea how to fix it? At what point did I go wrong? I used pointers, dynamic memory allocation.\n    ", "Answer": "\r\nInstead of working with arrays directly named as matrix, try something simple and scalable, then optimize. Something like this:\n```\nclass matrix \n{ \n    private: \n    // sub-matrices \n    std::shared_ptr<matrix> c11;     \n    std::shared_ptr<matrix> c12;     \n    std::shared_ptr<matrix> c21;     \n    std::shared_ptr<matrix> c22; \n \n    // properties \n    const int n; \n    const int depth; \n    const int maxDepth; \n \n    // this should be shared-ptr too. Too lazy. \n    int data[16]; // lowest level matrix = 4x4 without sub matrix \n \n \n    // multiplication memory \n    std::shared_ptr<std::vector<matrix>> m; \n     \n    public: \n    matrix(const int nP=4,const int depthP=0,const int maxDepthP=1): \n        n(nP),depth(depthP),maxDepth(maxDepthP) \n    { \n        if(depth<maxDepth) \n        { \n            // allocate c11,c22,c21,c22 \n            // allocate m1,m2,m3,...m7 \n        } \n    } \n \n    // matrix-matrix multiplication \n    matrix operator * (const matrix & mat) \n    { \n        // allocate result \n \n        // multiply \n        if(depth!=maxDepth) \n        { \n            // Strassen's multiplication algorithm \n            *m[0] = (*c11 + *c22) * (*mat.c11 + *mat.c22); \n            ... \n            *m[6] = (*c12 - *c22) * (*mat.c21 + *mat.c22); \n \n            *c11 = *m[0] + *m[3] - *m[4] + *m[6]; \n            .. \n            *c22 = .. \n        } \n        else \n        { \n            // innermost submatrices (4x4) multiplied normally \n            result.data[0] = data[0]*mat.data[0] + .... \n            ... \n            result.data[15]= ... \n        } \n        return result; \n    } \n \n    // matrix-matrix adder \n    matrix operator + (const matrix & mat) \n    { \n        // allocate result \n \n        // add \n        if(depth!=maxDepth) \n        { \n            *result.c11 = *c11 + *mat.c11; \n            *result.c12 = *c12 + *mat.c12; \n            *result.c21 = *c21 + *mat.c21; \n            *result.c22 = *c22 + *mat.c22; \n        } \n        else \n        { \n            // innermost matrix \n            result.data[0] = ... \n        } \n        return result; \n    } \n}; \n```\n\nThis way, it costs less time-complexity and still looks simple to read. After it works, you can use single-block of matrix array inside of class to optimize for more speed, preferably only allocating once at root matrix and use\n```\nstd::span \n```\n\nfor access from submatrices for newer C++ versions. It is even parallelizable easily as each matrix can distribute its work to at least 4 threads and they can to 16 threads, 64 threads, etc. But of course too many threads are just as bad as too many allocations and should be optimized in a better way.\n    ", "Knowledge_point": "Matrix Multiplication", "Tag": "算法分析"}
